<!DOCTYPE html><html  data-capo=""><head><script type="importmap">
  {
    "imports": {
      "@patternfly/elements/": "/scripts/v1/@patternfly/elements/",
      "@patternfly/pfe-clipboard/": "/scripts/v1/@patternfly/pfe-clipboard/",
      "@rhds/elements/": "/scripts/v1/@rhds/elements/elements/",
      "@cpelements/elements/": "/scripts/v1/@cpelements/elements/elements/"
    },
    "scopes": {
      "/": {
        "@floating-ui/core": "/scripts/v1/@floating-ui/core/dist/floating-ui.core.mjs",
        "@floating-ui/dom": "/scripts/v1/@floating-ui/dom/dist/floating-ui.dom.mjs",
        "@floating-ui/utils": "/scripts/v1/@floating-ui/utils/dist/floating-ui.utils.mjs",
        "@floating-ui/utils/dom": "/scripts/v1/@floating-ui/utils/dom/dist/floating-ui.utils.dom.mjs",
        "@lit/reactive-element": "/scripts/v1/@lit/reactive-element/reactive-element.js",
        "@lit/reactive-element/decorators/": "/scripts/v1/@lit/reactive-element/decorators/",
        "@patternfly/pfe-core": "/scripts/v1/@patternfly/pfe-core/core.js",
        "@patternfly/pfe-core/": "/scripts/v1/@patternfly/pfe-core/",
        "@rhds/tokens/media.js": "/scripts/v1/@rhds/tokens/js/media.js",
        "lit": "/scripts/v1/lit/index.js",
        "lit-element/lit-element.js": "/scripts/v1/lit-element/lit-element.js",
        "lit-html": "/scripts/v1/lit-html/lit-html.js",
        "lit-html/": "/scripts/v1/lit-html/",
        "lit/": "/scripts/v1/lit/",
        "tslib": "/scripts/v1/tslib/tslib.es6.mjs",
        "@cpelements/rh-table/dist/rh-table.js": "/scripts/v1/@cpelements/rh-table/dist/rh-table.js"
      }
    }
  }
</script><meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Managing file systems | Red Hat Product Documentation</title>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<script type="text/javascript" id="trustarc" src="//static.redhat.com/libs/redhat/marketing/latest/trustarc/trustarc.js"></script>
<script src="//www.redhat.com/dtm.js"></script>
<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Red+Hat+Display:wght@400;500;700&family=Red+Hat+Text:wght@400;500;700&display=swap">
<link rel="stylesheet" href="/styles/rh-table--lightdom.min.css">
<style>.section .titlepage{gap:.75rem}.section .titlepage,div.edit{align-items:center;display:flex}div.edit{font-size:.9rem;margin-bottom:8px}div.edit>a{align-items:center;display:flex}.edit pf-icon{margin-right:4px}</style>
<style>#error[data-v-df31ff14]{align-items:center;display:flex;flex-direction:column;justify-content:center;min-height:80vh}h1[data-v-df31ff14]{font-size:calc(var(--rh-font-size-body-text-md, 1rem)*4);font-weight:700;margin-bottom:0}h1[data-v-df31ff14],h1 span[data-v-df31ff14]{line-height:var(--rh-line-height-heading,1.3)}h1 span[data-v-df31ff14]{color:var(--rh-color-text-brand-on-light,#e00);display:block;text-transform:uppercase}h1 span[data-v-df31ff14],p[data-v-df31ff14]{font-size:var(--rh-font-size-body-text-lg,1.125rem)}aside[data-v-df31ff14]{align-items:center;background:var(--rh-color-surface-lightest,#fff);border:var(--rh-border-width-sm,1px) solid var(--rh-color-border-subtle-on-light,#c7c7c7);border-radius:var(--rh-border-radius-default,3px);border-top:calc(var(--rh-border-width-md, 2px)*2) solid var(--rh-color-text-brand-on-light,#e00);box-shadow:var(--rh-box-shadow-sm,0 2px 4px 0 hsla(0,0%,8%,.2));display:flex;flex-direction:column;justify-content:space-between;margin-top:var(--rh-space-2xl,32px);padding:var(--rh-space-xl,24px)}aside[data-v-df31ff14],aside>div[data-v-df31ff14]{width:100%}.text-container[data-v-df31ff14]{margin:auto;max-width:442px;text-align:center}.desktop[data-v-df31ff14]{display:none}.sr-only[data-v-df31ff14]{height:1px;overflow:hidden;padding:0;position:absolute;width:1px;clip:rect(0,0,0,0);border:0;clip-path:inset(50%);white-space:nowrap}form[data-v-df31ff14]{display:flex}button[data-v-df31ff14],input[data-v-df31ff14]{border:1px solid var(--rh-color-black-500,#8a8d90);box-sizing:border-box;height:40px}input[data-v-df31ff14]{border-right:none;flex:1;font-family:var(--rh-font-family-heading,RedHatDisplay,"Red Hat Display","Noto Sans Arabic","Noto Sans Hebrew","Noto Sans JP","Noto Sans KR","Noto Sans Malayalam","Noto Sans SC","Noto Sans TC","Noto Sans Thai",Helvetica,Arial,sans-serif);font-size:var(--rh-font-size-body-text-md,1rem);padding-left:var(--rh-space-md,8px);width:100%}button[data-v-df31ff14]{-webkit-appearance:none;-moz-appearance:none;appearance:none;background:transparent;border-left:none;display:flex;width:var(--rh-size-icon-04,40px)}button[data-v-df31ff14]:before{background:var(--rh-context-light-color-text-link,#06c);content:"";cursor:pointer;display:block;height:28px;margin:auto;width:28px}.search-icon[data-v-df31ff14]{margin:auto}ul[data-v-df31ff14]{max-width:275px;padding:0}ul li[data-v-df31ff14]{display:inline-block;list-style:none;margin-right:var(--rh-space-xl,24px);padding:var(--rh-space-xs,4px) 0}ul li a[data-v-df31ff14]{color:var(--rh-context-light-color-text-link,#06c);text-decoration:none}@media (min-width:992px){aside[data-v-df31ff14]{flex-direction:row}.mobile[data-v-df31ff14]{display:none}.desktop[data-v-df31ff14]{display:block}input[data-v-df31ff14]{width:auto}}</style>
<style>@keyframes fade-in{0%{opacity:0;visibility:hidden}1%{visibility:visible}to{opacity:1;visibility:visible}}@media (min-height:48em){.rhdocs{--rh-table--maxHeight:calc(100vh - 12.5rem)}}*,.rhdocs *,.rhdocs :after,.rhdocs :before,:after,:before{box-sizing:border-box}.rhdocs img,.rhdocs object,.rhdocs svg,img,object,svg{display:inline-block;max-width:100%;vertical-align:middle}.rhdocs hr{border:0;border-top:.0625rem solid #d2d2d2;clear:both;margin:1rem 0}.rhdocs a{color:#06c;text-decoration:underline}.rhdocs a:focus,.rhdocs a:hover{color:#036}.rhdocs a.anchor-heading{color:#151515;cursor:pointer;text-decoration:none;word-break:break-all}.rhdocs p{margin:1.49963rem 0}.rhdocs li>p{margin:0}.rhdocs h1,.rhdocs h2,.rhdocs h3,.rhdocs h4,.rhdocs h5,.rhdocs h6{font-family:RedHatDisplay,Red Hat Display,Helvetica Neue,Arial,sans-serif;font-weight:500;margin:0 0 .625rem}.rhdocs h1{font-size:2.25rem;margin:2rem 0}.rhdocs h2{font-size:1.625rem;margin:2rem 0}.rhdocs h3{font-size:1.5rem;font-weight:400}.rhdocs h4,.rhdocs h5{font-size:1.25rem}.rhdocs h5{font-weight:400}.rhdocs h6{font-size:1.125rem;font-weight:500;line-height:1.6667}.rhdocs ol,.rhdocs ul{margin:1rem 0;padding:0 0 0 1.5rem}.rhdocs ol ::marker,.rhdocs ul ::marker{font:inherit}.rhdocs li{margin:0 0 .5em;padding:0}.rhdocs li>p{margin:.5rem 0}.rhdocs li>ol,.rhdocs li>ul{margin:0}.rhdocs dl dd{margin:.5rem 0 .5rem 1rem}.rhdocs dl dd>p{margin:.5rem 0}.rhdocs .informaltable,.rhdocs .table-contents,.rhdocs .table-wrapper{max-height:var(--rh-table--maxHeight);overflow:auto}.rhdocs table{border:0;font-size:1rem;line-height:1.6667;table-layout:fixed}.rhdocs table caption{color:#585858;margin-bottom:.5rem;margin-top:.5rem;text-align:left}.rhdocs table td,.rhdocs table th{border:0;border-bottom:.0625rem solid #d2d2d2;border-bottom:.0625rem solid var(--pfe-table--Border,#d2d2d2);padding:.5em 1rem}.rhdocs table td.halign-left,.rhdocs table th.halign-left{text-align:left}.rhdocs table td.halign-center,.rhdocs table th.halign-center,table td.halign-center,table th.halign-center{text-align:center}.rhdocs table td.halign-right,.rhdocs table th.halign-right{text-align:right}.rhdocs table td.valign-top,.rhdocs table th.valign-top{vertical-align:top}.rhdocs table td.valign-middle,.rhdocs table th.valign-middle{vertical-align:middle}.rhdocs table td.valign-bottom,.rhdocs table th.valign-bottom{vertical-align:bottom}.rhdocs table thead td,.rhdocs table thead th{background:#f5f5f5;font-weight:600}.rhdocs rh-table table,.rhdocs rh-table.rh-table--expanded-vertically{max-height:-moz-max-content;max-height:max-content}.rhdocs pre.nowrap{overflow:auto;overflow-wrap:normal;white-space:pre;word-break:normal}.rhdocs .codeblock__wrapper pre{background:transparent}.rh-table--full-screen code,.rhdocs .content--md code,.rhdocs .content--sm code,.rhdocs .rh-table--full-screen code{overflow-wrap:normal;word-break:normal}.rhdocs[class] pre code,[class] pre code{background:inherit;color:inherit;font-family:inherit;font-size:inherit;font-weight:inherit;line-height:inherit;padding:0}.rhdocs .keycap,.rhdocs kbd{background-color:#eee;background-image:linear-gradient(180deg,#ddd,#eee,#fff);border-radius:.1875rem;box-shadow:0 -.0625rem 0 0 #fff,0 .0625rem 0 .1875rem #aaa;font-family:RedHatMono,Red Hat Mono,Consolas,monospace;font-size:90%;font-weight:400;margin:0 .25rem;padding:.125rem .375rem}.keycap strong,.rhdocs .keycap strong{font-weight:inherit}.rhdocs kbd.keyseq,kbd.keyseq{background:transparent;border:0;box-shadow:none;padding:0}.rhdocs kbd.keyseq kbd,kbd.keyseq kbd{display:inline-block;margin:0 .375rem}.rhdocs kbd.keyseq kbd:first-child,kbd.keyseq kbd:first-child{margin-left:0}.rhdocs b.button{font-size:90%;font-weight:700;padding:.1875rem}.rhdocs b.button:before{content:"["}.rhdocs b.button:after{content:"]"}html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}.rhdocs audio,.rhdocs canvas,.rhdocs progress,.rhdocs video{display:inline-block;vertical-align:baseline}.rhdocs audio:not([controls]){display:none;height:0}[hidden],template{display:none}.rhdocs a{background:transparent}.rhdocs a:active,.rhdocs a:hover{outline:0}.rhdocs a.anchor-heading:hover:before{color:#151515;content:"#";margin-left:-1.6rem;position:absolute}.rhdocs a.anchor-heading:focus-visible{color:#151515}@media screen and (max-width:990px){.rhdocs a.anchor-heading:hover:before{font-size:16px;margin-left:-1rem;padding-top:8px}.rhdocs h1 a.anchor-heading:hover:before{padding-top:12px}.rhdocs h4 a.anchor-heading:hover:before,.rhdocs h5 a.anchor-heading:hover:before{padding-top:4px}.rhdocs h6 a.anchor-heading:hover:before{padding-top:2px}}.rhdocs abbr[title]{border-bottom:.0625rem dotted}.rhdocs dfn{font-style:italic}.rhdocs h1{font-size:2em;margin:.67em 0}.rhdocs mark{background:#ff0;color:#000}.rhdocs small{font-size:80%}.rhdocs sub,.rhdocs sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}.rhdocs sup{top:-.5em}.rhdocs sub{bottom:-.25em}.rhdocs img{border:0}.rhdocs svg:not(:root){overflow:hidden}.rhdocs figure{margin:1em 2.5rem}.rhdocs hr{box-sizing:content-box;height:0}.rhdocs code,.rhdocs kbd,.rhdocs pre,.rhdocs samp{font-family:monospace,monospace;font-size:1em}.rhdocs button,.rhdocs optgroup,.rhdocs select,.rhdocs textarea,.rhdocsinput{color:inherit;font:inherit;margin:0}.rhdocs button.copy-link-btn{background:none;border:2px solid #fff;font:1px Red Hat Text}.rhdocs button.copy-link-btn:hover{border-bottom:2px solid #06c}.rhdocs button.copy-link-btn .link-icon{padding-bottom:4px}.rhdocs button{overflow:visible}.rhdocs button,.rhdocs select{text-transform:none}.rhdocs button,.rhdocs html input[type=button],.rhdocs input[type=reset],.rhdocs input[type=submit]{-moz-appearance:button;appearance:button;-webkit-appearance:button;cursor:pointer}.rhdocs button[disabled],.rhdocs html input[disabled]{cursor:default}.rhdocs button::-moz-focus-inner,.rhdocs input::-moz-focus-inner{border:0;padding:0}.rhdocs input{line-height:normal}.rhdocs input[type=checkbox],.rhdocs input[type=radio]{box-sizing:border-box;padding:0}.rhdocs input[type=number]::-webkit-inner-spin-button,.rhdocs input[type=number]::-webkit-outer-spin-button{height:auto}.rhdocs input[type=search]{-moz-appearance:textfield;appearance:textfield;-webkit-appearance:textfield;box-sizing:content-box}.rhdocs input[type=search]::-webkit-search-cancel-button,.rhdocs input[type=search]::-webkit-search-decoration{-webkit-appearance:none}.rhdocs fieldset{border:.0625rem solid silver;margin:0 .125rem;padding:.35em .625em .75em}.rhdocs legend{border:0;padding:0}.rhdocs textarea{overflow:auto}.rhdocs optgroup{font-weight:700}.rhdocs table{border-collapse:collapse;border-spacing:0}.rhdocs td,.rhdocs th{padding:0}.rhdocs ._additional-resources[class][class][id]:last-child{margin-top:-2rem}.rhdocs ._additional-resources[class][class]:only-child{grid-column:1/-1}._additional-resources[class][class] .additional-resources__heading,._additional-resources[class][class] .heading,._additional-resources[class][class] h1,._additional-resources[class][class] h2,._additional-resources[class][class] h3,._additional-resources[class][class] h4,._additional-resources[class][class] h5,._additional-resources[class][class] h6,._additional-resources[class][class] p.title{display:block;font-family:RedHatDisplay,Red Hat Display,Helvetica Neue,Arial,sans-serif;font-size:1.125rem;font-weight:700;line-height:1.5rem;margin:0 0 .5rem;padding:0;text-transform:uppercase}._additional-resources[class][class] ul{border:0;list-style:none;margin:0;padding:0;position:relative}.related-topic-content__wrapper ._additional-resources[class][class] ul{display:block}._additional-resources[class][class] ul:after{background-color:#fff;bottom:0;content:"";display:block;height:.125rem;position:absolute;width:100%}._additional-resources[class][class] li{border-bottom:.0625rem solid #d2d2d2;box-sizing:content-box;margin:0;padding:1rem 1.5rem 1rem 0;-moz-column-break-inside:avoid;break-inside:avoid}._additional-resources[class][class] li:only-child{grid-column:1/-1}._additional-resources[class][class] li:last-child{border:0}@media (min-width:1100px){._additional-resources[class][class] li:last-child{border-bottom:.0625rem solid #d2d2d2}}._additional-resources[class][class] li p:only-child{margin:0;padding:0}._additional-resources[class][class] li a{text-decoration:none}._additional-resources[class][class] li a:focus,._additional-resources[class][class] li a:hover{text-decoration:underline}.rhdocs table .admonitionblock>div:nth-child(2),.rhdocs table .caution>div:nth-child(2),.rhdocs table .important>div:nth-child(2),.rhdocs table .note>div:nth-child(2),.rhdocs table .tip>div:nth-child(2),.rhdocs table .warning>div:nth-child(2){margin:.5rem 0}.rhdocs table .admonitionblock>div:nth-child(2)>:first-child,.rhdocs table .caution>div:nth-child(2)>:first-child,.rhdocs table .important>div:nth-child(2)>:first-child,.rhdocs table .note>div:nth-child(2)>:first-child,.rhdocs table .tip>div:nth-child(2)>:first-child,.rhdocs table .warning>div:nth-child(2)>:first-child{margin-top:0}.rhdocs table .admonitionblock>div:nth-child(2)>:last-child,.rhdocs table .caution>div:nth-child(2)>:last-child,.rhdocs table .important>div:nth-child(2)>:last-child,.rhdocs table .note>div:nth-child(2)>:last-child,.rhdocs table .tip>div:nth-child(2)>:last-child,.rhdocs table .warning>div:nth-child(2)>:last-child{margin-bottom:0}.rhdocs .codeblock__wrapper+.codeblock__wrapper,.rhdocs pre+pre,.rhdocs pre[class]+pre[class]{margin-top:2rem}.rhdocs .codeblock__wrapper{background:#f8f8f8;overflow:visible;position:relative;transform:translate(0);z-index:0}.codeblock__wrapper:before{background-repeat:no-repeat;background-size:6.25rem 100%;bottom:var(--scrollbar__height,1px);content:"";display:block;height:7.125rem;max-height:100%;max-height:calc(100% - var(--scrollbar__height, 2px));position:absolute;right:var(--scrollbar__width,6px);top:.0625rem;width:4.0625rem;z-index:1}.rhdocs .codeblock__inner-wrapper,.rhdocs pre{max-height:calc(100vh - 6.25rem)}@media (min-height:48em){.rhdocs .codeblock__inner-wrapper,.rhdocs pre{max-height:calc(100vh - 12.5rem)}}.rhdocs .codeblock__inner-wrapper{display:grid;grid-template-columns:1fr 4.375rem}.rhdocs .codeblock__wrapper--expanded .codeblock__inner-wrapper{max-height:-moz-max-content;max-height:max-content}.codeblock__copy span{display:block;height:0;position:absolute;visibility:hidden;width:0}.codeblock__copy:focus{outline:.0625rem dashed currentcolor}.codeblock__copy svg#icon--copy{height:1rem;width:1rem}.codeblock__expand{-webkit-appearance:none;-moz-appearance:none;appearance:none;background:#f0efef;border:0;cursor:pointer;height:1.75rem;left:calc(100% - 2.75rem - var(--scrollbar__width, 0px));position:absolute;text-indent:-9999em;top:3.25rem;width:1.75rem;z-index:2}.codeblock__expand:before{background:#6a6e73;content:"";height:100%;left:0;-webkit-mask-image:url("data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 320 512'%3E%3C!--! Font Awesome Pro 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license (Commercial License) Copyright 2022 Fonticons, Inc.--%3E%3Cpath d='M182.6 9.4c-12.5-12.5-32.8-12.5-45.3 0l-96 96c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l41.4-41.4v293.4l-41.4-41.3c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3l96 96c12.5 12.5 32.8 12.5 45.3 0l96-96c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L192 402.7V109.3l41.4 41.4c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3l-96-96z'/%3E%3C/svg%3E");mask-image:url("data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 320 512'%3E%3C!--! Font Awesome Pro 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license (Commercial License) Copyright 2022 Fonticons, Inc.--%3E%3Cpath d='M182.6 9.4c-12.5-12.5-32.8-12.5-45.3 0l-96 96c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l41.4-41.4v293.4l-41.4-41.3c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3l96 96c12.5 12.5 32.8 12.5 45.3 0l96-96c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L192 402.7V109.3l41.4 41.4c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3l-96-96z'/%3E%3C/svg%3E");-webkit-mask-position:center center;mask-position:center center;-webkit-mask-repeat:no-repeat;mask-repeat:no-repeat;-webkit-mask-size:auto 1rem;mask-size:auto 1rem;position:absolute;top:0;width:100%}.codeblock__wrapper--expanded .codeblock__expand{background:#2b9af3}.codeblock__wrapper--expanded .codeblock__expand:before{background:#fff}.codeblock__expand:focus:before,.codeblock__expand:hover:before{background:#06c}.codeblock__wrapper--expanded .codeblock__expand:focus:before,.codeblock__wrapper--expanded .codeblock__expand:hover:before{background:#fff}.codeblock__expand:focus{outline:.0625rem dashed currentcolor}.rhdocs .calloutlist>ol,.rhdocs .colist>ol{counter-reset:colist;list-style:none;margin:1rem 0 2rem;padding:0}.rhdocs .calloutlist>ol>li,.rhdocs .colist>ol>li{counter-increment:colist;font-size:1rem;margin:.5rem 0;padding-left:1.75rem;position:relative}.rhdocs .calloutlist>ol>li .colist-num,.rhdocs .colist>ol>li .colist-num{display:none}.calloutlist>ol>li:before,.colist>ol>li:before{content:counter(colist);left:0;position:absolute;top:.1875rem}.calloutlist dt{clear:left;float:left;margin:0;padding:0 .5rem 0 0}.included-in-guides[class],.included-in-guides[class][id]:last-child{background:#fff;border:.0625rem solid #d2d2d2;border-radius:.1875rem;margin:2em 0 4em;padding:2rem 2rem 1rem}.included-in-guides[class][id]:last-child{margin-top:-2rem}.included-in-guides[class]:only-child{grid-column:1/-1}.included-in-guides[class] .additional-resources__heading,.included-in-guides[class] .heading,.included-in-guides[class] h1,.included-in-guides[class] h2,.included-in-guides[class] h3,.included-in-guides[class] h4,.included-in-guides[class] h5,.included-in-guides[class] h6,.included-in-guides[class] p.title{display:block;font-family:RedHatDisplay,Red Hat Display,Helvetica Neue,Arial,sans-serif;font-size:1.125rem;font-weight:700;line-height:1.5rem;margin:0 0 .5rem;padding:0;text-transform:uppercase}.included-in-guides[class] ul{border:0;list-style:none;margin:0;padding:0;position:relative}.related-topic-content__wrapper .included-in-guides[class] ul{display:block}.included-in-guides[class] ul:after{background-color:#fff;bottom:0;content:"";display:block;height:.125rem;position:absolute;width:100%}.included-in-guides[class] li{border-bottom:.0625rem solid #d2d2d2;box-sizing:content-box;margin:0;padding:1rem 1.5rem 1rem 0;-moz-column-break-inside:avoid;break-inside:avoid}.included-in-guides[class] li:only-child{grid-column:1/-1}.included-in-guides[class] li:last-child{border:0}@media (min-width:1100px){.included-in-guides[class] li:last-child{border-bottom:.0625rem solid #d2d2d2}}.included-in-guides[class] li p:only-child{margin:0;padding:0}.included-in-guides[class] li a{text-decoration:none}.included-in-guides[class] li a:focus,.included-in-guides[class] li a:hover{text-decoration:underline}.menuseq{display:inline-flex;overflow:hidden;text-indent:-9999em}.menuseq .menu,.menuseq .menuitem,.menuseq .submenu{display:block;position:relative;text-indent:0}.menuseq .menu+.menu:before,.menuseq .menu+.menuitem:before,.menuseq .menu+.submenu:before,.menuseq .menuitem+.menu:before,.menuseq .menuitem+.menuitem:before,.menuseq .menuitem+.submenu:before,.menuseq .submenu+.menu:before,.menuseq .submenu+.menuitem:before,.menuseq .submenu+.submenu:before{content:">";display:inline-block;font-weight:700;padding:0 .25em}.related-topic-content__wrapper{margin:2em 0}.related-topic-content__wrapper--for-guide{margin-bottom:-2.5rem;padding-bottom:.0625rem;position:relative;z-index:1}.related-topic-content__wrapper--for-guide:before{background:#f0f0f0;content:"";display:block;height:100%;left:-3rem;position:absolute;right:-4.5rem;top:0;width:auto;z-index:-1}@media (min-width:1100px){.related-topic-content__wrapper--for-guide:before{left:-2.5rem;right:-3.625rem}}.related-topic-content__wrapper--for-guide summary{padding:1em 2em 1em 2.1875rem}@media (min-width:950px){.related-topic-content__inner-wrapper{display:grid;gap:2em;grid-template-columns:repeat(2,minmax(0,1fr))}}.local-render .rhdocs-content{margin:0 auto}.rhdocs cp-documentation{display:block;padding-bottom:2.5rem}.rhdocs cp-documentation.PFElement,.rhdocs cp-documentation[pfelement]{padding:0}rh-table{display:block}::-webkit-scrollbar,:host .rhdocs ::-webkit-scrollbar{height:.625rem;width:.625rem}::-webkit-scrollbar,::-webkit-scrollbar-track,:host .rhdocs ::-webkit-scrollbar,:host .rhdocs ::-webkit-scrollbar-track{background-color:#d6d6d6}::-webkit-scrollbar-thumb,:host .rhdocs ::-webkit-scrollbar-thumb{background-color:#8e8e8e}*,:host .rhdocs *{scrollbar-color:#8e8e8e #d6d6d6}.rhdocs p:empty,p:empty{display:none}.rhdocs[class] h1 code,.rhdocs[class] h2 code,.rhdocs[class] h3 code,.rhdocs[class] h4 code,.rhdocs[class] h5 code,.rhdocs[class] h6 code,[class] h1 code,[class] h2 code,[class] h3 code,[class] h4 code,[class] h5 code,[class] h6 code{background:transparent;border:0;color:inherit;font:inherit;margin:0;padding:0}.pane-page-title h1,.rhdocs__header__primary-wrapper h1{font-family:RedHatDisplay,Red Hat Display,Helvetica Neue,Arial,sans-serif;font-size:2.25rem;line-height:1.333}.rhdocs details[class]{list-style:none;margin:1rem 0 3rem;padding:0}.rhdocs-toc[class]{background:#f2f2f2;margin:1rem 0 2rem;padding:1rem}.rhdocs-toc[class]>:last-child{margin-bottom:0}.rhdocs-toc[class] .rhdocs-toctitle{font-size:1.25rem;font-weight:400;line-height:1.6667;margin-top:0;text-transform:none}.rhdocs-toc[class] li{margin-bottom:.25em;padding-left:.5em}.preamble{margin:0 0 2rem}.sect1{margin:2rem 0 1rem}:host .sect1,cp-documentation .sect1{margin:0 0 2rem;padding:.0625rem 0 0}:host(.cp-documentation--has-external-header) .sect1:first-child>h2:first-child,:host(.cp-documentation--has-external-header) .sect1:first-child>h3:first-child{margin-top:0}.listingblock,.literalblock{margin:1rem 0}.quoteblock,.verseblock{border-left:.25rem solid #d2d2d2;margin:1rem 0;padding:1rem 1rem 1rem 2rem}.quoteblock.pullleft,.verseblock.pullleft{float:left;margin-right:3rem;width:25rem}@media (min-width:768px){.quoteblock.pullleft,.verseblock.pullleft{margin-left:-1rem}}.quoteblock.pullright,.verseblock.pullright{float:right;margin-left:3rem;width:25rem}@media (min-width:768){.quoteblock.pullright,.verseblock.pullright{margin-right:-2rem}}@media (min-width:1100px){.quoteblock.pullright,.verseblock.pullright{margin-right:-10rem}}.quoteblock>:first-child,.verseblock>:first-child{margin-top:0}.quoteblock .content,.verseblock .content{font-family:RedHatText,Red Hat Text,Helvetica Neue,Arial,sans-serif;font-size:1.25rem;line-height:1.6667}.quoteblock .attribution,.verseblock .attribution{font-size:.875rem;font-style:italic;font-weight:600;line-height:1.6667;text-transform:uppercase}.quoteblock .attribution .citetitle,.verseblock .attribution .citetitle{color:#585858}.quoteblock .attribution cite,.verseblock .attribution cite{font-size:1em}.quoteblock blockquote{font-style:italic;margin:0;padding:0}.quoteblock blockquote .content>:first-child{margin-top:0}.quoteblock blockquote .content>:first-child:before{color:#e00;content:"â€œ";display:block;float:left;font-size:2.75rem;font-style:normal;line-height:1.125em;margin-right:.5rem}.quoteblock blockquote .content>:first-child .content>:first-child:before{content:none}.imageblock{margin:1rem 0}.imageblock.pullleft{float:left;margin-right:3rem;width:25rem}@media (min-width:768px){.imageblock.pullleft{margin-left:-1rem}}.imageblock.pullright{float:right;margin-left:3rem;width:25rem}@media (min-width:768){.imageblock.pullright{margin-right:-2rem}}@media (min-width:1100px){.imageblock.pullright{margin-right:-10rem}}.imageblock.interrupter{margin:2rem 0}@media (min-width:768px){.imageblock.interrupter{margin-left:-1rem;margin-right:-2rem}.imageblock.interrupter .caption{margin-left:1rem;margin-right:2rem}}@media (min-width:1100px){.imageblock.interrupter{margin-right:-10rem}.imageblock.interrupter .caption{margin-right:10rem}}.imageblock.interrupter img{max-width:100%}.imageblock .caption{color:#585858;display:block;font-size:.875rem;line-height:1.6667;margin:.5rem 0 0}.rhdocs-footnotes{border-top:.0625rem solid #d2d2d2;margin:3rem 0 1rem;padding:1rem 0 0}.rhdocs-footnotes>ol{margin:0;padding:0 0 0 1.5rem}@supports (counter-reset:footnotenum){.rhdocs-footnotes>ol{counter-reset:footnotenum;list-style:none;padding:0}.rhdocs-footnotes>ol>li{counter-increment:footnotenum}.rhdocs-footnotes>ol>li:before{color:#585858;content:"[" counter(footnotenum) "]";display:inline-block;margin-right:.25rem}}.rhdocs-footer{background:#ededed;color:#151515;font-size:.875rem;line-height:1.6667;margin:3rem 0 0;padding:1rem}.center{margin-left:auto;margin-right:auto}.stretch{width:100%}.visually-hidden{overflow:hidden;position:absolute;clip:rect(0,0,0,0);border:0;height:.0625rem;margin:-.0625rem;padding:0;width:.0625rem}.rh-docs-legal-notice{margin-top:4em}pre,pre[class]{margin:0;padding:1.25em 1em;position:relative}code[class*=language-],pre[class*=language-]{color:#151515;-moz-tab-size:4;-o-tab-size:4;tab-size:4}code.language-none,code.language-text,code.language-txt,pre.language-none,pre.language-text,pre.language-txt{color:#151515}code[class*=language-] ::-moz-selection,code[class*=language-]::-moz-selection,pre[class*=language-] ::-moz-selection,pre[class*=language-]::-moz-selection{background:#cceae7;color:#263238}code[class*=language-] ::selection,code[class*=language-]::selection,pre[class*=language-] ::selection,pre[class*=language-]::selection{background:#cceae7;color:#263238}:not(pre)>code[class*=language-]{border-radius:.2em;padding:.1em;white-space:normal}.token.atrule{color:#40199a}.token.attr-name{color:#06c}.token.attr-value,.token.attribute{color:#b300b3}.token.boolean{color:#40199a}.token.builtin,.token.cdata,.token.char,.token.class,.token.class-name{color:#06c}.token.comment{color:#6a6e73}.token.constant{color:#40199a}.token.deleted{color:#c9190b}.token.doctype{color:#6a6e73}.token.entity{color:#c9190b}.token.function{color:#40199a}.token.hexcode{color:#b300b3}.token.id,.token.important{color:#40199a;font-weight:700}.token.inserted{color:#06c}.token.keyword{color:#40199a}.token.number{color:#b300b3}.token.operator{color:#06c}.token.prolog{color:#6a6e73}.token.property{color:#06c}.token.pseudo-class,.token.pseudo-element{color:#b300b3}.token.punctuation,.token.regex{color:#06c}.token.selector{color:#c9190b}.token.string{color:#b300b3}.token.symbol{color:#40199a}.token.unit{color:#b300b3}.token.url,.token.variable{color:#c9190b}.rhdocs.local-render{margin:0 auto;max-width:45.8125rem;padding:0 1.5rem}@media print{.field code,.field pre,code[class*=language-],pre,pre[class*=language-]{white-space:pre-wrap!important;word-wrap:break-word!important;overflow-wrap:break-word!important;word-break:break-word!important}}.book-nav__list[class]{display:flex;justify-content:space-between;line-height:var(--jupiter__lineHeight--xs,1.3333);list-style:none;margin:5rem 0 0;padding:0}@media (min-width:1200px){.book-nav__list[class]{display:grid;gap:2rem;grid-template-columns:repeat(2,minmax(0,1fr))}}.book-nav__item a{display:inline-block;font-size:.875rem;font-weight:500;padding-left:1.25rem;position:relative;text-transform:uppercase}.book-nav__item a:before{background:url(/sites/dxp-docs/penumbra-dist/jupiter/images/arrow-down-solid.svg) no-repeat;background-size:contain;content:"";display:block;height:.875rem;left:0;position:absolute;top:.125rem;transform:rotate(90deg);width:.875rem}.book>.titlepage:not(:last-child),.rhdocs .chapter,section[id]{padding-bottom:3.75rem}.book>.titlepage .chapter:last-child,.book>.titlepage section[id]:last-child,.chapter .chapter:last-child,.chapter section[id]:last-child,section[id] .chapter:last-child,section[id] section[id]:last-child{margin-bottom:-3.75rem}.rhdocs .codeblock__wrapper+section[id],pre+section[id]{padding-top:3.75rem}.rhdocs .cta-link{font-size:inherit}.rhdocs a{word-wrap:break-word;overflow-wrap:break-word}.rhdocs .caution,.rhdocs .important,.rhdocs .note,.rhdocs .tip,.rhdocs .warning{padding:.8888888889em;position:relative}.rhdocs .QSIPopOver{bottom:18.75rem!important;top:auto!important}.rhdocs .alert{position:relative}.rhdocs button.dismiss-button{background:none;border:0;cursor:pointer;height:2.5rem;margin-top:-1.25rem;padding:0;position:absolute;right:.3125rem;text-align:center;top:50%;width:2.5rem;z-index:50}.rhdocs button.dismiss-button:after{content:"\f109";display:inline-block;filter:alpha(opacity=30);font-family:rh-web-iconfont;font-size:1.3125rem;font-style:normal;font-variant:normal;font-weight:400;line-height:1;line-height:2.5rem;opacity:.3;text-decoration:inherit;text-rendering:optimizeLegibility;text-transform:none!important;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;font-smoothing:antialiased}.rhdocs .book>.titlepage,.rhdocs .chapter,.rhdocs section[id]{padding-bottom:var(--rh-space-4xl,64px)}.rhdocs .alert{border:0;border-radius:0}.rhdocs .alert>h2:first-child,.rhdocs .alert>h3:first-child,.rhdocs .alert>h4:first-child,.rhdocs .alert>h5:first-child,.rhdocs .alert>h6:first-child,.rhdocs .alert>p:first-child{margin-top:0!important}.rhdocs .alert>p:last-child{margin-bottom:0!important}.rhdocs .alert-w-icon[class]{padding-left:2.8125rem}.rhdocs .alert-w-icon .alert-icon{float:left;font-size:1.125rem;margin-left:-1.875rem;margin-right:.625rem}.rhdocs .alert-w-icon .alert-icon[class*=" rh-icon-"],.rhdocs .alert-w-icon .alert-icon[class^=rh-icon-]{font-size:2.25rem;line-height:1em;margin-left:-2.5rem;margin-top:-.375rem}.rhdocs .alert-w-icon .alert-icon[class*=" icon-innov-prev"],.rhdocs .alert-w-icon .alert-icon[class^=icon-innov-prev]{font-size:1.3125rem;margin-top:.25rem}.rhdocs .alert-w-icon.alert-plain{background:none;color:#151515;padding-left:5rem}.rhdocs .alert-w-icon.alert-plain .alert-icon{font-size:3rem;margin-left:-4.375rem;margin-right:0}.rhdocs .alert-w-icon.alert-plain.alert-success .alert-icon{color:#3f9c35}.rhdocs .alert-w-icon.alert-plain.alert-info .alert-icon{color:#0088ce}.rhdocs .alert-w-icon.alert-plain.alert-warning .alert-icon{color:#f0ab00}.rhdocs .alert-w-icon.alert-plain.alert-danger .alert-icon{color:#e00}#target_banner .copy-url{float:right;margin-top:0}#target_banner .dropdown-menu{font-size:inherit}.titlepage .svg-img[data*="title_logo.svg"]{margin:1.5rem 0;width:15rem}.para{margin:1.49963rem 0}.para[class]{margin-bottom:1.49963rem}dd{margin-bottom:2.5rem}.rhdocs .card-light,.rhdocs .card-light-gray,.rhdocs .card-light-grey{background:#f0f0f0;border:.0625rem solid #f0f0f0;color:#151515}.rhdocs .card-light-gray.push-bottom:first-child,.rhdocs .card-light-grey.push-bottom:first-child,.rhdocs .card-light.push-bottom:first-child{margin-bottom:3.125rem!important}.rhdocs .card-light a.card-link,.rhdocs .card-light h1,.rhdocs .card-light h2,.rhdocs .card-light h3,.rhdocs .card-light h4,.rhdocs .card-light h5,.rhdocs .card-light h6,.rhdocs .card-light-gray a.card-link,.rhdocs .card-light-gray h1,.rhdocs .card-light-gray h2,.rhdocs .card-light-gray h3,.rhdocs .card-light-gray h4,.rhdocs .card-light-gray h5,.rhdocs .card-light-gray h6,.rhdocs .card-light-grey a.card-link,.rhdocs .card-light-grey h1,.rhdocs .card-light-grey h2,.rhdocs .card-light-grey h3,.rhdocs .card-light-grey h4,.rhdocs .card-light-grey h5,.rhdocs .card-light-grey h6{color:#151515}.rhdocs .card-light-gray.card-active:after,.rhdocs .card-light-grey.card-active:after,.rhdocs .card-light.card-active:after{border-top-color:#f0f0f0}.rhdocs .card-md,.rhdocs .card-narrow{display:block;padding:1.1875rem;white-space:normal;word-wrap:break-word}.rhdocs .card .card-heading.card-heading-sm,.rhdocs .card-sm .card .card-heading{font-size:1.0625em;font-weight:500;line-height:1.5}.rhdocs .card .card-heading.card-heading-flush{margin-bottom:.25rem}.rhdocs .card .card-heading.card-heading-red{color:#d10000}.rhdocs .card>p{margin-top:0}.rhdocs .card>p:last-child{margin-bottom:0}.rhdocs .new-experience{background-color:#e7f1fa;border:.0625rem solid #bee1f4;font-size:1rem;margin:1.5rem;padding:1.5rem;position:relative;z-index:1}@media (min-width:48rem){.new-experience{display:flex}.new-experience--contained{left:50%;position:relative;transform:translateX(-50%);width:calc(100vw - 2.5rem)}}.new-experience__primary-content{flex-grow:1}@media (min-width:48rem){.new-experience__primary-content{margin-right:1.25rem}}.new-experience__title{font-size:inherit;font-weight:inherit;line-height:1.6;margin:0;padding:0}.new-experience__title+a,.new-experience__title+pfe-cta{display:inline-block;margin-top:1.5em}.new-experience__secondary-content{min-width:12.5rem}@media (min-width:48rem){.new-experience__secondary-content{text-align:right}}.example{border-left:.3125rem solid #ccc;margin-bottom:2rem;padding:1rem 0 1rem 1rem}dl.calloutlist[class]{display:grid;gap:1.25em .75em;grid-template-columns:min-content 1fr}dl.calloutlist[class] dt{float:none;margin:0;padding:0}dl.calloutlist[class] dd{margin:0;padding:0}dl.calloutlist[class] dd>:first-child{margin-top:0}dl.calloutlist[class] dd>:last-child{margin-bottom:0}.toast{background-color:#000;background-color:rgba(0,0,0,.9);bottom:.9375rem;box-shadow:0 .125rem .3125rem 0 rgba(0,0,0,.26);color:#fff;left:.9375rem;max-width:32.8125rem;min-width:6.25rem;padding:.9375rem;position:fixed;right:.9375rem;transform:translate3d(0,150%,0);transition:transform .2s cubic-bezier(.465,.183,.153,.946);will-change:transform;z-index:999}.toast.show{transform:translateZ(0)}.toast a{color:#fff;text-decoration:underline}.toast a:focus,.toast a:hover{color:#2b9af3}.toast a.btn{text-decoration:none}.toast .btn.btn-link{color:#fff}.toast .close{color:#fff;opacity:.3;text-decoration:none}.toast .close:focus,.toast .close:hover{color:#fff;opacity:.5}.no-csstransforms3d.csstransitions .toast{transition:all .2s cubic-bezier(.465,.183,.153,.946)}.no-csstransforms3d .toast{opacity:0;visibility:hidden}.no-csstransforms3d .toast.show{opacity:1;visibility:visible}.annotator-outer[class][class]{display:none;flex-direction:column;flex-grow:1;height:auto;margin:0;position:static;width:auto}@media (min-width:1400px){.annotator-outer[class][class]{display:flex}}.annotator-frame[class] *{height:auto}@media (min-width:1400px){.annotator-frame .h-sidebar-iframe[class]{position:static;width:calc(100% + 1.5rem)}}.annotator-toolbar[class][class]{position:static;width:auto}.annotator-toolbar>ul,.annotator-toolbar>ul>li{display:block;height:auto;list-style:none;margin:0;padding:0;width:auto}.annotator-toolbar>ul>li{display:flex;justify-content:flex-end}.annotator-frame[class] .annotator-frame-button--sidebar_toggle,.annotator-outer .annotator-frame-button[class][class],.app-content-wrapper *{font-family:RedHatText,Red Hat Text,Helvetica Neue,Arial,sans-serif!important}.annotator-outer .annotator-frame-button[class][class]{font-size:.9375rem;font-weight:500;height:auto;line-height:1.333;margin-right:1.875rem;padding:.75em 1em;position:static}@media (min-width:1400px){.annotator-outer .annotator-frame-button[class][class]{margin-right:0}}.annotator-outer iframe{flex-grow:1;margin-bottom:1.25rem}@media (min-width:1400px){.annotator-outer iframe{min-height:37.5rem}}.producttitle{color:#000;font-size:1.25rem;text-transform:uppercase}.producttitle .productnumber{color:var(--jupiter__palette__red--50,#e00)}.cp-modal-open,.zoom-open{overflow:hidden}.cp-modal,.cp-video-modal,.zoom-modal{bottom:0;display:none;filter:alpha(opacity=0);left:0;opacity:0;outline:0;overflow:hidden;position:fixed;right:0;top:0;transition:all .2s cubic-bezier(.465,.183,.153,.946);z-index:1040;z-index:1050;-webkit-overflow-scrolling:touch}.rhdocs .in.cp-modal,.rhdocs .in.cp-video-modal,.rhdocs .in.zoom-modal{display:block;filter:alpha(opacity=100);opacity:1;overflow-x:hidden;overflow-y:auto}.rhdocs .cp-modal .close,.rhdocs .cp-video-modal .close,.rhdocs .zoom-modal .close{background-color:#fff;border-radius:50%;color:#1a1a1a;font-size:1.75rem;height:28px;height:1.75rem;line-height:1.75rem;margin-bottom:.375rem;margin-top:0;opacity:.9;position:absolute;right:-.5rem;text-shadow:none;top:0;width:28px;width:1.75rem}.cp-modal .close:after,.cp-video-modal .close:after,.zoom-modal .close:after{line-height:1.75rem}.cp-modal-wrap,.zoom-wrap{margin:.625rem;padding-top:.5rem;position:relative}@media (min-width:48rem){.rhdocs .cp-modal-wrap,.rhdocs .zoom-wrap{margin:2.8125rem auto;width:38.4375rem}}@media (min-width:62rem){.rhdocs .cp-modal-wrap,.rhdocs .zoom-wrap{width:49.8958rem}}@media (min-width:75rem){.rhdocs .cp-modal-wrap,.rhdocs .zoom-wrap{width:60.3125rem}}.rhdocs .cp-modal-body :last-child{margin-bottom:0}.rhdocs .cp-modal-backdrop,.rhdocs .zoom-backdrop{background-color:#000;bottom:0;display:none;filter:alpha(opacity=0);left:0;opacity:0;position:fixed;right:0;top:0;transition:opacity .2s cubic-bezier(.465,.183,.153,.946);z-index:1040}.rhdocs .in.cp-modal-backdrop,.rhdocs .in.zoom-backdrop{display:block;filter:alpha(opacity=80);opacity:.8}.rhdocs .cp-modal-body{background:#fff;padding:1.875rem}.rhdocs .cp-modal[data-cp-modal-video=true] .cp-modal-body,.rhdocs .cp-video-modal .cp-modal-body{padding:0}.rhdocs [data-action=zoom]{position:relative}.rhdocs [data-action=zoom]:after{background:rgba(0,0,0,.4);bottom:0;color:#fff;display:inline-block;font-family:rh-web-iconfont;font-style:normal;font-variant:normal;font-weight:400;line-height:1;padding:.375rem;position:absolute;right:0;text-decoration:inherit;text-decoration:none!important;text-rendering:optimizeLegibility;text-transform:none!important;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;font-smoothing:antialiased}.rhdocs [data-action=zoom]:focus:after,.rhdocs [data-action=zoom]:hover:after{background:rgba(0,0,0,.9)}.rhdocs .zoom-wrap .zoom-larger{text-align:center}.rhdocs .zoom-wrap .zoom-larger a{color:#fff}.rhdocs .zoom-wrap .zoom-larger a:focus,.rhdocs .zoom-wrap .zoom-larger a:hover{color:#fff;text-decoration:underline}.rhdocs .zoom-wrap .zoom-larger a:after{content:"â¿»";display:inline-block;margin-left:.25rem}.rhdocs .zoom-body{background:#fff;border-radius:.5rem;margin:0 0 1rem;padding:1rem;text-align:center}.rhdocs .zoom-body .video-wrapper{height:0;overflow:hidden;padding-bottom:56.25%;position:relative}.rhdocs .zoom-body .video-wrapper[data-aspect-ratio="4:3"]{padding-bottom:75%}.rhdocs .zoom-body iframe{height:100%;left:0;position:absolute;top:0;width:100%}.rhdocs .para>.title[class],.rhdocs p.title[class]{font-size:1rem;font-style:normal;font-weight:700;line-height:1.6667;margin:1.25rem 0 0;text-transform:none}.rhdocs .para>.title[class]+.content>:first-child,.rhdocs .para>.title[class]+p,.rhdocs p.title[class]+.content>:first-child,.rhdocs p.title[class]+p{margin-top:0}.rhdocs [class] pre .caution,.rhdocs [class] pre .important,.rhdocs [class] pre .note,.rhdocs [class] pre .tip,.rhdocs [class] pre .warning{background:transparent;border:0;color:inherit;font:inherit;margin:0;padding:0}.rhdocs [class] pre .caution:after,.rhdocs [class] pre .important:after,.rhdocs [class] pre .note:after,.rhdocs [class] pre .tip:after,.rhdocs [class] pre .warning:after{content:none}.rhdocs [class] code.email{background-color:transparent;font:inherit;padding:0}.rhdocs [class] .author{margin-bottom:1.5rem}.rhdocs [class] .author .author{margin-bottom:0}.rhdocs table{margin:2rem 0}.rhdocs [class] table{width:auto}.rhdocs table .table-contents table{max-width:100%;overflow:auto}.rhdocs rh-table table{margin:0;max-width:9999em;overflow:visible}.rhdocs td,.rhdocs th{border-left:0;padding:.5em 1rem;transition:background .25s ease-out}.rhdocs td.content--md[class][class],.rhdocs th.content--md[class][class]{min-width:13em}.rhdocs td.content--lg[class][class],.rhdocs th.content--lg[class][class]{min-width:20em}.rhdocs thead th{padding-top:1.5em}.rhdocs caption{color:currentColor;color:var(--pfe-table__caption--Color,currentColor);font-weight:700;margin-bottom:.5rem;margin-top:.5rem;text-align:center}.rhdocs .revhistory table td,.rhdocs .revhistory table th{border-color:transparent}.rhdocs .revhistory table td{padding:.625rem .875rem}.rhdocs .revhistory table.simplelist{margin:0}@media print{#masthead{display:none!important}}.rh-table--is-full-screen #to-top{display:none}.rhdocs{--rh-table--maxHeight:calc(100vh - 6.25rem);color:#151515;font-family:var(--rh-font-family-body-text,RedHatText,"Red Hat Text","Noto Sans Arabic","Noto Sans Hebrew","Noto Sans JP","Noto Sans KR","Noto Sans Malayalam","Noto Sans SC","Noto Sans TC","Noto Sans Thai",Helvetica,Arial,sans-serif);font-size:var(--rh-body-copy-lage,1.125rem);line-height:1.6667;-moz-tab-size:4;-o-tab-size:4;tab-size:4}.rhdocs rh-codeblock::slotted(#content){border-radius:.25rem;padding:var (--rh-space-lg,16px)}.rhdocs rh-codeblock .screen{display:grid;grid-template-columns:1fr 4.375rem}.rhdocs rh-codeblock[class][class][class][class][class]{max-width:99999em}.rhdocs .codeblock__copy span{display:block;height:0;position:absolute;visibility:hidden;width:0}.rhdocs .codeblock__copy:focus{outline:.0625rem dashed currentcolor}.rhdocs .codeblock__copy svg#icon--copy{height:1rem;width:1rem}.rhdocs pre{border:0;max-height:-moz-max-content;max-height:max-content}.rhdocs pre,pre[class]{margin:0;padding:1.25em 1em;position:relative}.rhdocs rh-code-block>div.codeblock__inner-wrapper>pre,.rhdocs rh-code-block>div.codeblock__inner-wrapper>pre[class]{margin:0;padding:0;position:relative}.rhdocs code[class*=language-],pre[class*=language-]{color:#151515;-moz-tab-size:4;-o-tab-size:4;tab-size:4}.rhdocs code.literal{background:#eee;border-radius:.25rem;color:#000;font-size:.875rem;line-height:1.6667;overflow-wrap:break-word;padding:.125em .5em;word-break:break-word}.rhdocs code.literal,.rhdocs kbd,.rhdocs span.keycap{font-family:RedHatMono,Red Hat Mono,Consolas,monospace}.rhdocs kbd,.rhdocs span.keycap{background-color:#eee;background-image:linear-gradient(180deg,#ddd,#eee,#fff);border-radius:.1875rem;box-shadow:0 -.0625rem 0 0 #fff,0 .0625rem 0 .1875rem #aaa;font-size:90%;font-weight:400;margin:0 .25rem;padding:.125rem .375rem}.rhdocs ol,.rhdocs ul{margin:1rem 0;padding:0 0 0 1.5rem}.rhdocs ._additional-resources[class][class],.rhdocs ._additional-resources[class][class][id]:last-child{background:#fff;border:.0625rem solid #d2d2d2;border-radius:.1875rem;margin:2em 0 4em;padding:2rem 2rem 1rem}.rhdocs ._additional-resources[class][class] ul{border:0;list-style:none;margin:0;padding:0;position:relative}.rhdocs ._additional-resources[class][class] li{border-bottom:.0625rem solid #d2d2d2;box-sizing:content-box;margin:0;padding:1rem 1.5rem 1rem 0;-moz-column-break-inside:avoid;break-inside:avoid}.rhdocs ._additional-resources[class][class] li:last-child{border:0}.rhdocs section.section#additional_resource .additional-resources__heading,.rhdocs section.section#additional_resource .heading,.rhdocs section.section#additional_resource h1,.rhdocs section.section#additional_resource h2,.rhdocs section.section#additional_resource h3,.rhdocs section.section#additional_resource h4,.rhdocs section.section#additional_resource h5,.rhdocs section.section#additional_resource h6,.rhdocs section.section#additional_resource p.title{display:block;font-family:RedHatDisplay,Red Hat Display,Helvetica Neue,Arial,sans-serif;font-size:1.125rem;font-weight:700;line-height:1.5rem;margin:0 0 .5rem;padding:0;text-transform:uppercase}.rhdocs section.section:first-of-type{margin-top:var(--rh-space-4xl,64px)}.rhdocs section.section p{margin-bottom:var(--rh-space-lg,16px);margin-top:0;word-wrap:break-word}.rhdocs .section.section h1,.rhdocs .section.section h2,.rhdocs .section.section h3,.rhdocs .section.section h4,.rhdocs .section.section h5,.rhdocs .section.section h6,.rhdocs h1,.rhdocs h2,.rhdocs h3,.rhdocs h4,.rhdocs h5,.rhdocs h6{font-family:RedHatDisplay,Red Hat Display,Helvetica Neue,Arial,sans-serif;font-weight:400;line-height:1.3333}.rhdocs h1:first-of-type,.rhdocs h2:first-of-type,.rhdocs h3:first-of-type,.rhdocs h4:first-of-type,.rhdocs h5:first-of-type,.rhdocs h6:first-of-type{margin-top:0}.rhdocs h1,.rhdocs h2,.rhdocs h3,.rhdocs h4,.rhdocs h5,.rhdocs h6{font-family:RedHatDisplay,Red Hat Display,Helvetica,Arial,sans-serif;font-weight:400;line-height:1.3333}.rhdocs h2,.rhdocs section.section h2{font-size:var(--rh-font-size-heading-md,1.75rem)}.rhdocs h3,.rhdocs section.section h3{font-size:1.5rem;font-weight:400}.rhdocs dl dt{font-weight:600;margin:.5rem 0}.rhdocs dl{display:block;margin-block-end:1em;margin-block-start:1em;margin-inline-end:0;margin-inline-start:0}.rhdocs .para{margin:1.49963rem 0}.rhdocs dl.calloutlist[class] dt{float:none;margin:0;padding:0}.rhdocs dl.calloutlist[class] dd>:last-child{margin-bottom:0}.rhdocs dl.calloutlist[class]{display:grid;gap:1.25em .75em;grid-template-columns:fit-content(40%) 1fr}.rhdocs .calloutlist dt{clear:left;display:flex;flex-wrap:wrap;float:left;margin:0;padding:0 .5rem 0 0}.rhdocs .calloutlist dt a:not(:first-child){padding-left:4px}.rhdocs dl.calloutlist[class] dd{margin:0;padding:0}.rhdocs .callout,.rhdocs .colist>ol>li:before,.rhdocs .conum{background:#06c;border-radius:50%;color:#fff;display:inline-block;font-family:RedHatText,Red Hat Text,Helvetica Neue,Arial,sans-serif;font-size:.75rem;font-style:normal;font-weight:600;height:1.25rem;line-height:1.35rem;padding:0;position:relative;text-align:center;top:-.125em;vertical-align:middle;width:1.25rem}.rhdocs img,.rhdocs object,.rhdocs svg{display:inline-block;max-width:100%;vertical-align:middle}.rhdocs .titlepage .svg-img[data*="title_logo.svg"]{margin:1.5rem 0;width:15rem}.rhdocs[class] .author{margin-bottom:1.5rem}.rhdocs[class] .author .author{margin-bottom:0}.rhdocs .para>.title[class],p.title[class]{font-size:1rem;font-style:normal;font-weight:700;line-height:1.6667;margin:1.25rem 0 0}.rhdocs .example{border-left:.3125rem solid #ccc;margin-bottom:2rem;padding:1rem 0 1rem 1rem}.rhdocs code{background:#eee;color:#000;font-family:RedHatMono,Red Hat Mono,Consolas,monospace;font-size:.875rem;line-height:1.6667;overflow-wrap:break-word;padding:.125em .5em;word-break:break-word}.rhdocs .para[class]{margin-bottom:1.49963rem}.rhdocs[class] code.email{background-color:transparent;font:inherit;padding:0}rh-alert.admonition #description,rh-alert.admonition p{font-size:var(--rh-font-size-body-text-md,1rem)}rh-alert{width:-moz-fit-content;width:fit-content}.rhdocs .producttitle{color:#000;font-size:1.25rem;text-transform:uppercase}.rhdocs dl{margin:1rem 0}.rhdocs dl dt{font-weight:600;margin:.5rem 0}.rhdocs ol ol{list-style:lower-roman}.rhdocs .codeblock--processed pf-clipboard-copy::part(input),.rhdocs .codeblock--processed pf-clipboard-copy::part(span){display:none}.token.tag{color:#c9190b}.calloutlist div.para{margin:0}rh-alert.admonition{margin-bottom:var(--rh-space-lg,1rem)}.guibutton,.guimenu,.guimenuitem{font-weight:700}.guibutton{font-size:90%;padding:.1875rem}.guibutton:before{content:"["}.guibutton:after{content:"]"}.docs-content-container,.rhdocs{--rh-table--maxHeight:calc(100vh - 6.25rem);color:#151515;font-family:RedHatText,Red Hat Text,Helvetica Neue,Arial,sans-serif;font-size:1.125rem;line-height:1.6667;-moz-tab-size:4;-o-tab-size:4;tab-size:4}pre[hidden]{display:none}.codeblock[class][class][class][class][class]{max-width:99999em}.codeblock__wrapper{background:var(--rh-color-surface-lighter,#f2f2f2);margin:1rem 0;overflow:visible;position:relative;transform:translate(0);z-index:0}.codeblock__inner-wrapper:after{content:"";display:block;min-height:.625rem;width:4.375rem}.codeblock__copy{--pfe-clipboard--icon--Color--hover:#06c;-webkit-appearance:none;-moz-appearance:none;appearance:none;background:#f0efef;height:1.75rem;left:calc(100% - 2.75rem - var(--scrollbar__width, 0px));padding:.3125rem .375rem;position:absolute;top:1rem;width:1.75rem;z-index:2}.codeblock__inner-wrapper pre{border:0;max-height:-moz-max-content;max-height:max-content}.pfe-clipboard:not([copied]) .pfe-clipboard__text--success,:host(:not([copied])) .pfe-clipboard__text--success{display:none!important}.codeblock[class]{margin:0;overflow:visible;padding-right:0}pre{display:block;font-size:.8125rem;line-height:1.42857;margin:0 0 .625rem;word-break:break-all;word-wrap:break-word;background-color:var(--rh-color-surface-lighter,#f2f2f2);border:.0625rem solid #ccc;border-radius:.25rem;color:#333}.docs-content-container pre,.rhdocs pre{background:var(--rh-color-surface-lighter,#f2f2f2);color:#151515;font-family:RedHatMono,Red Hat Mono,Consolas,monospace;font-size:.875rem;line-height:1.6667;overflow-wrap:normal;white-space:pre;word-break:normal}.rhdocs pre[class]{line-height:1.6667;overflow-x:auto}rh-codeblock pre[class][class]{overflow-x:auto}.pfe-clipboard__text--success{background-color:#ddd;border:1px solid #000;border-radius:2px}*,:after,:before{box-sizing:border-box}:root{--rh-space-xs:4px;--rh-space-sm:6px;--rh-space-md:8px;--rh-space-lg:16px;--rh-space-xl:24px;--rh-space-2xl:32px;--rh-space-3xl:48px;--rh-space-4xl:64px;--rh-space-5xl:80px;--rh-space-6xl:96px;--rh-space-7xl:128px;--rh-font-size-body-text-xs:.75rem;--rh-font-size-body-text-sm:.875rem;--rh-font-size-body-text-md:1rem;--rh-font-size-body-text-lg:1.125rem;--rh-font-size-body-text-xl:1.25rem;--rh-font-size-body-text-2xl:1.5rem;--rh-font-size-heading-xs:1.25rem;--rh-font-size-heading-sm:1.5rem;--rh-font-size-heading-md:1.75rem;--rh-font-size-heading-lg:2.25rem;--rh-font-size-heading-xl:2.5rem;--rh-font-size-heading-2xl:3rem;--pfe-navigation--logo--maxWidth:200px;--pfe-navigation__logo--height:40px;--pfe-navigation--fade-transition-delay:500ms;--pfe-navigation__nav-bar--highlight-color:var(--rh-color-brand-red-on-dark,#e00);--pf-global--icon--FontSize--sm:.75rem}body,html{font-family:Red Hat Text,sans-serif;font-size:var(--rh-font-size-body-text-md,1rem);line-height:var(--rh-line-height-body-text,1.5);margin:0}h1,h2,h3,h4,h5,h6{font-family:Red Hat Display,sans-serif;font-weight:400;line-height:var(--rh-line-height-heading,1.3)}h1{font-size:var(--rh-font-size-heading-2xl,3rem);line-height:62px}h2{font-size:var(--rh-font-size-heading-xl,2.5rem);line-height:48px}h3{font-size:var(--rh-font-size-heading-lg,2.25rem)}h4{font-size:var(--rh-font-size-heading-md,2.25rem)}h5{font-size:var(--rh-font-size-heading-sm,2.25rem)}h6{font-size:var(--rh-font-size-heading-xs,2.25rem)}main{line-height:30px}section{padding-bottom:3rem;padding-top:3rem}img{height:auto;max-width:100%}a{color:var(--rh-color-interactive-blue-darker,#06c);text-decoration:none}a:hover{color:var(--rh-color-interactive-blue-darkest,#004080)}rh-alert.html-container a{text-decoration:underline}.container{padding-left:12px;padding-right:12px}.container,.container-fluid{margin-left:auto;margin-right:auto;width:100%}.container-fluid{padding:12px}@media (min-width:576px){.container{max-width:540px}}@media (min-width:768px){.container{max-width:720px}}@media (min-width:992px){.container{max-width:960px}}@media (min-width:1200px){.container{min-width:1140px}}@media (min-width:1400px){.container{min-width:1320px}}.grid{display:grid;gap:var(--rh-space-xl,24px)}.grid-center{margin:auto}.grid.grid-col-2{grid-template-columns:repeat(2,1fr)}.grid.grid-col-3{grid-template-columns:repeat(3,1fr)}.grid.grid-col-4{grid-template-columns:repeat(4,1fr)}.grid.grid-col-5{grid-template-columns:repeat(5,1fr)}.grid.grid-col-6{grid-template-columns:repeat(6,1fr)}.grid.grid-col-7{grid-template-columns:repeat(7,1fr)}.grid.grid-col-8{grid-template-columns:repeat(8,1fr)}.grid.grid-col-9{grid-template-columns:repeat(9,1fr)}.grid.grid-col-10{grid-template-columns:repeat(10,1fr)}.grid.grid-col-11{grid-template-columns:repeat(11,1fr)}.grid.grid-col-12{grid-template-columns:repeat(12,1fr)}@media (min-width:768px){.grid.grid-col-md-2{grid-template-columns:repeat(2,1fr)}.grid.grid-col-md-3{grid-template-columns:repeat(3,1fr)}.grid.grid-col-md-4{grid-template-columns:repeat(4,1fr)}.grid.grid-col-md-5{grid-template-columns:repeat(5,1fr)}.grid.grid-col-md-6{grid-template-columns:repeat(6,1fr)}.grid.grid-col-md-7{grid-template-columns:repeat(7,1fr)}.grid.grid-col-md-8{grid-template-columns:repeat(8,1fr)}.grid.grid-col-md-9{grid-template-columns:repeat(9,1fr)}.grid.grid-col-md-10{grid-template-columns:repeat(10,1fr)}.grid.grid-col-md-11{grid-template-columns:repeat(11,1fr)}.grid.grid-col-md-12{grid-template-columns:repeat(12,1fr)}}@media (min-width:992px){.grid.grid-col-lg-2{grid-template-columns:repeat(2,1fr)}.grid.grid-col-lg-3{grid-template-columns:repeat(3,1fr)}.grid.grid-col-lg-4{grid-template-columns:repeat(4,1fr)}.grid.grid-col-lg-5{grid-template-columns:repeat(5,1fr)}.grid.grid-col-lg-6{grid-template-columns:repeat(6,1fr)}.grid.grid-col-lg-7{grid-template-columns:repeat(7,1fr)}.grid.grid-col-lg-8{grid-template-columns:repeat(8,1fr)}.grid.grid-col-lg-9{grid-template-columns:repeat(9,1fr)}.grid.grid-col-lg-10{grid-template-columns:repeat(10,1fr)}.grid.grid-col-lg-11{grid-template-columns:repeat(11,1fr)}.grid.grid-col-lg-12{grid-template-columns:repeat(12,1fr)}}.span-1{grid-column:span 1}.span-2{grid-column:span 2}.span-3{grid-column:span 3}.span-4{grid-column:span 4}.span-5{grid-column:span 5}.span-6{grid-column:span 6}.span-7{grid-column:span 7}.span-8{grid-column:span 8}.span-9{grid-column:span 9}.span-10{grid-column:span 10}.span-11{grid-column:span 11}.span-12{grid-column:span 12}@media (min-width:399px){.span-xs-1{grid-column:span 1}.span-xs-2{grid-column:span 2}.span-xs-3{grid-column:span 3}.span-xs-4{grid-column:span 4}.span-xs-5{grid-column:span 5}.span-xs-6{grid-column:span 6}.span-xs-7{grid-column:span 7}.span-xs-8{grid-column:span 8}.span-xs-9{grid-column:span 9}.span-xs-10{grid-column:span 10}.span-xs-11{grid-column:span 11}.span-xs-12{grid-column:span 12}}@media (min-width:768px){.span-md-1{grid-column:span 1}.span-md-2{grid-column:span 2}.span-md-3{grid-column:span 3}.span-md-4{grid-column:span 4}.span-md-5{grid-column:span 5}.span-md-6{grid-column:span 6}.span-md-7{grid-column:span 7}.span-md-8{grid-column:span 8}.span-md-9{grid-column:span 9}.span-md-10{grid-column:span 10}.span-md-11{grid-column:span 11}.span-md-12{grid-column:span 12}}@media (min-width:992px){.span-lg-1{grid-column:span 1}.span-lg-2{grid-column:span 2}.span-lg-3{grid-column:span 3}.span-lg-4{grid-column:span 4}.span-lg-5{grid-column:span 5}.span-lg-6{grid-column:span 6}.span-lg-7{grid-column:span 7}.span-lg-8{grid-column:span 8}.span-lg-9{grid-column:span 9}.span-lg-10{grid-column:span 10}.span-lg-11{grid-column:span 11}.span-lg-12{grid-column:span 12}}@media (min-width:1025px){.span-xl-1{grid-column:span 1}.span-xl-2{grid-column:span 2}.span-xl-3{grid-column:span 3}.span-xl-4{grid-column:span 4}.span-xl-5{grid-column:span 5}.span-xl-6{grid-column:span 6}.span-xl-7{grid-column:span 7}.span-xl-8{grid-column:span 8}.span-xl-9{grid-column:span 9}.span-xl-10{grid-column:span 10}.span-xl-11{grid-column:span 11}.span-xl-12{grid-column:span 12}}@media (min-width:1200px){.span-2xl-1{grid-column:span 1}.span-2xl-2{grid-column:span 2}.span-2xl-3{grid-column:span 3}.span-2xl-4{grid-column:span 4}.span-2xl-5{grid-column:span 5}.span-2xl-6{grid-column:span 6}.span-2xl-7{grid-column:span 7}.span-2xl-8{grid-column:span 8}.span-2xl-9{grid-column:span 9}.span-2xl-10{grid-column:span 10}.span-2xl-11{grid-column:span 11}.span-2xl-12{grid-column:span 12}}.flex{display:flex;flex-direction:column;gap:var(--rh-space-lg,16px)}.flex-row{flex-direction:row}.flex-column{flex-direction:column}@media (min-width:768px){.flex-md-row{flex-direction:row}.flex-md-column{flex-direction:column}}.typography-h1{font-size:var(--rh-font-size-heading-2xl,3rem)}.typography-h2{font-size:var(--rh-font-size-heading-xl,2.5rem)}.typography-h3{font-size:var(--rh-font-size-heading-lg,2.25rem)}.typography-h4{font-size:var(--rh-font-size-heading-md,1.75rem)}.typography-h5{font-size:var(--rh-font-size-heading-sm,1.5rem)}.typography-h6{font-size:var(--rh-font-size-heading-xs,1.25rem)}.content section{padding:0}.content h1,.content h2,.content h3,.content h4,.content h5,.content h6{margin:var(--rh-space-lg,16px) 0}.sr-only{height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px;clip:rect(0,0,0,0);border:0}.list-unstyled{list-style:none;padding-left:0}.tooltip-content{align-items:center;display:flex;font-family:Red Hat Text;justify-content:center;text-transform:none}.tooltip-content .check-icon{margin-left:var(--rh-space-md,8px)}.doc-image-link{display:inline-block;text-decoration:none}.modal-img{display:block;width:100%}.modal-helper-text{margin-top:.5rem;text-align:center}.modal-helper-text a{color:#000;cursor:pointer}.modal-helper-text a:hover{text-decoration:underline}.modal-helper-text a:after{content:"⿻";margin-left:.25rem}pf-modal.pf-img-modal{--pf-c-modal-box--MaxHeight:90vh;overflow-y:scroll}pf-modal.pf-img-modal::part(close-button){background-color:#fff;border-radius:50%;color:#000;margin-right:-2rem;margin-top:-2rem}pf-modal.pf-img-modal::part(close-button):hover{opacity:.7}h2.truste-title{line-height:normal;margin-top:0}rh-alert p[slot=header]{color:#002952}@media (width < 992px){html:has(nav.mobile-nav .mobile-nav-wrapper){scroll-behavior:smooth;scroll-padding-top:4rem}html:has(nav.mobile-nav .mobile-jump-links){scroll-padding-top:7rem}html:has(nav.mobile-nav.hide-mobile-nav){scroll-padding-top:2rem}}.highlight{background:#fff4cc;color:#000}</style>
<style>rh-alert[data-v-84359384]{width:100%}</style>
<style>.search-btn[data-v-edc0d12c]{align-items:center;background-color:var(--rh-color-canvas-black,#151515);border:3px solid var(--rh-color-canvas-black,#151515);cursor:pointer;display:flex;flex-direction:column;height:100%;justify-content:center;outline:none;padding:14px var(--rh-space-md,8px)}.search-btn[data-v-edc0d12c]:focus{border-top:3px solid var(--rh-color-accent-brand-on-light,#e00);outline:2px dotted var(--rh-color-white,#fff)}.search-btn .search-icon[data-v-edc0d12c]{height:26px;padding:2px 0 var(--rh-space-xs,4px);width:20px}.search-btn .search-icon[data-v-edc0d12c],.search-icon-helper-text[data-v-edc0d12c]{color:var(--rh-color-white,#fff)}.search-mobile[data-v-edc0d12c]{margin-bottom:var(--rh-space-2xl,32px)}.search-mobile form[data-v-edc0d12c]{display:flex;gap:var(--rh-space-md,8px);margin:auto}.search-box[data-v-edc0d12c]{width:35rem}nav[data-v-edc0d12c]{background-color:#151515;justify-content:space-between;width:100%}a[data-v-edc0d12c],a[data-v-edc0d12c]:visited{color:#fff;display:inline-block;font-size:var(--rh-font-size-body-text-md,1rem)}.skip-link[class][class][data-v-edc0d12c]{font-size:var(--pf-global--FontSize--sm,.875rem);line-height:18px}.skip-link[class][class][data-v-edc0d12c]:focus{border-radius:.21429em;height:auto;left:50%;padding:.42857em .57143em;position:fixed;top:8px;transform:translateX(-50%);width:auto;z-index:99999;clip:auto;background:#fff;background:var(--pfe-navigation__skip-link--BackgroundColor,var(--pfe-theme--color--surface--lightest,#fff));color:#06c;color:var(--pfe-navigation__skip-link--Color,var(--pfe-theme--color--link,#06c));text-decoration:none}.visually-hidden[data-v-edc0d12c]{border:1px solid #06c;height:1px;overflow:hidden;padding:0;position:absolute;width:1px;clip:rect(0,0,0,0);white-space:nowrap}h3[data-v-edc0d12c]{color:#464646;font-family:var(--rh-font-family-heading,"Red Hat Display",Helvetica,Arial,sans-serif);font-size:var(--rh-font-size-body-text-lg,1.125rem)}.language-picker[data-v-edc0d12c]{align-items:center;background-color:#fff;display:flex;flex-direction:column;padding:var(--rh-space-xl,24px);width:100%}.language-picker h3[data-v-edc0d12c]{margin:0;padding:0 1rem 1rem}.language-picker ul[data-v-edc0d12c]{margin:0;padding:0}.language-picker a[data-v-edc0d12c]{color:#06c}.language-picker li[data-v-edc0d12c]{list-style:none}.language-dropdown[data-v-edc0d12c]{background:#fff;box-shadow:0 3px 6px rgba(0,0,0,.098);display:block!important;position:absolute;right:0;width:100%;z-index:104}.pfe-navigation.pfe-navigation--processed>[slot=secondary-links][data-v-edc0d12c]{height:auto;overflow:visible;visibility:visible;width:auto}.upper-navigation[data-v-edc0d12c]{padding:0 var(--rh-space-2xl,32px)}.upper-nav-container[data-v-edc0d12c]{border-bottom:1px solid #404040;margin:0}.upper-nav-hidden[data-v-edc0d12c]:not(:focus):not(:active){clip:rect(0 0 0 0);clip-path:inset(50%);height:1px;overflow:hidden;position:absolute;white-space:nowrap;width:1px}.upper-nav-menu[data-v-edc0d12c]{align-items:center;display:flex;justify-content:flex-end;line-height:1.444;list-style:none;margin-bottom:0;margin-top:0;padding-left:0}.upper-nav-menu[data-v-edc0d12c],.upper-nav-menu>li[data-v-edc0d12c]{position:relative}.upper-nav-menu>li:not(:first-child)>a[data-v-edc0d12c]:before,.upper-nav-menu>li:not(:first-child)>button[data-v-edc0d12c]:before{background-color:#404040;content:"";height:40%;left:0;position:absolute;top:30%;width:1px}li[data-v-edc0d12c]{display:list-item;margin:0;padding:0;text-align:-webkit-match-parent}.upper-nav-menu button.upper-nav-links[data-v-edc0d12c]{border:0;border-top:3px solid transparent;cursor:pointer;line-height:1.444}.upper-nav-menu button.upper-nav-links[aria-expanded=true][data-v-edc0d12c]{outline-color:#151515}.upper-nav-menu button.upper-nav-links[aria-expanded=true] .upper-nav-arrow[data-v-edc0d12c]{filter:invert(0) sepia(2%) saturate(21%) hue-rotate(257deg) brightness(108%) contrast(100%);transform:rotate(270deg)}.upper-nav-menu button.upper-nav-links[aria-expanded=true][data-v-edc0d12c]:before{display:none}.upper-nav-menu .upper-nav-links[data-v-edc0d12c]{background-color:var(--pfe-navigation--BackgroundColor,var(--pfe-theme--color--surface--darkest,#151515));border-top:3px solid transparent;color:#fff;display:block;font-family:var(--rh-font-family-body-text,"Red Hat Text","RedHatText",Arial,sans-serif);font-size:var(--rh-font-size-body-text-sm,.875rem);outline:none;padding:12px 12px 14px;text-decoration:none}.upper-nav-menu .upper-nav-links[data-v-edc0d12c]:hover{border-top-color:#b8bbbe}.upper-nav-menu .upper-nav-links[data-v-edc0d12c]:focus-within{outline:1px dashed var(--rh-color-white,#fff);outline-offset:-1px}.upper-nav-menu .upper-nav-links[data-v-edc0d12c]:focus-within:before{display:none}.upper-nav-dropdown-container[data-v-edc0d12c]{background:#fff;box-shadow:0 3px 6px rgba(0,0,0,.098);display:none;padding:5px 30px 24px;position:absolute;right:0;top:100%;width:500px;z-index:105}.upper-nav-dropdown-container>ul[data-v-edc0d12c]{-moz-column-count:2;column-count:2;list-style-type:none;padding:0;width:auto}.upper-nav-dropdown-container>ul li[data-v-edc0d12c]{color:#151515;font-family:var(--rh-font-family-heading,"Red Hat Display",Helvetica,Arial,sans-serif);font-size:var(--rh-font-size-body-text-sm,.875rem);list-style-type:none;margin-bottom:0}.upper-nav-dropdown-container>ul li span[data-v-edc0d12c]{font-weight:var(--rh-font-weight-body-text-medium,500)}.upper-nav-dropdown-container>ul ul[data-v-edc0d12c]{padding-left:0;padding-top:9px}.upper-nav-dropdown-container>ul>li[data-v-edc0d12c]{padding-top:19px;-moz-column-break-inside:avoid;break-inside:avoid}.upper-nav-dropdown-container>ul>li>ul>li[data-v-edc0d12c]{line-height:1.45;padding:4px 0}.upper-nav-menu .upper-nav-arrow[data-v-edc0d12c]{display:inline-block;filter:invert(100%) sepia(8%) saturate(7%) hue-rotate(1turn) brightness(100%) contrast(93%);height:18px;margin-left:5px;transform:rotate(90deg);vertical-align:middle;width:8px}#pfe-navigation__secondary-links .show[data-v-edc0d12c],.upper-navigation .show[data-v-edc0d12c]{display:block}.upper-nav-menu .upper-nav-links[aria-expanded=true][data-v-edc0d12c]:active,.upper-nav-menu .upper-nav-links[aria-expanded=true][data-v-edc0d12c]:focus,.upper-nav-menu .upper-nav-links[aria-expanded=true][data-v-edc0d12c]:hover{background-color:#fff;color:#151515}.upper-nav-menu .upper-nav-links[aria-expanded=true][data-v-edc0d12c]{background-color:#fff;border-top-color:#b8bbbe;color:#000;position:relative;z-index:1}.upper-nav-dropdown-container>ul a[data-v-edc0d12c]{color:var(--rh-color-accent-base-on-light,#06c);font-family:var(--rh-font-family-body-text,"Red Hat Text","RedHatText",Arial,sans-serif);font-size:14px;text-decoration:none}.pfe-navigation__search[data-v-edc0d12c]{background-color:var(--rh-color-white,#fff)}.pfe-navigation__search form[data-v-edc0d12c]{display:flex;gap:var(--rh-space-md,8px);margin:auto;max-width:992px}pfe-navigation [slot=secondary-links] .buttons[data-v-edc0d12c]{display:flex;flex-wrap:wrap;gap:var(--rh-space-md,8px);margin-top:4px}pfe-navigation [slot=secondary-links] .buttons a[data-v-edc0d12c]{border:1px solid #d2d2d2;border-radius:3px;color:#06c;cursor:pointer;flex-basis:calc(50% - 5px);font-family:var(--rh-font-family-body-text,"Red Hat Text","RedHatText",Arial,sans-serif);font-weight:var(--rh-font-weight-code-regular,400);padding:1em;text-align:center;text-decoration:none}pfe-navigation [slot=secondary-links] .mobile-lang-select[data-v-edc0d12c]{border:1px solid #d2d2d2;border-bottom-color:#3c3f42;cursor:pointer;display:flex;margin:3rem 0;position:relative}pfe-navigation [slot=secondary-links] .mobile-lang-select label[data-v-edc0d12c]{bottom:100%;color:#000;font-family:var(--rh-font-family-body-text,"Red Hat Text","RedHatText",Arial,sans-serif);font-size:14px;font-weight:500;margin-bottom:5px;position:absolute}pfe-navigation [slot=secondary-links] .mobile-lang-select select[data-v-edc0d12c]{-webkit-appearance:none;-moz-appearance:none;appearance:none;background-color:#fff;border-style:none;color:#000;flex-basis:100%;font-family:var(--rh-font-family-body-text,"Red Hat Text","RedHatText",Arial,sans-serif);font-size:16px;line-height:24px;padding:6px 24px 6px 8px}select[data-v-edc0d12c]{background-image:url("data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http://www.w3.org/2000/svg' width='10' height='6' fill='none' viewBox='0 0 10 6'%3E%3Cpath fill='%23151515' d='M.678 0h8.644c.596 0 .895.797.497 1.195l-4.372 4.58c-.298.3-.695.3-.993 0L.18 1.196C-.216.797.081 0 .678 0'/%3E%3C/svg%3E");background-position:98% 50%;background-repeat:no-repeat}#inputLabel[data-v-edc0d12c]{align-items:center;display:flex;position:relative}#inputLabel form[data-v-edc0d12c]{width:100%}.input-box[data-v-edc0d12c]{font-family:var(--rh-font-family-body-text,"Red Hat Text","RedHatText",Arial,sans-serif);font-size:var(--rh-font-size-body-text-md,1rem);height:36px;padding:0 8px;width:100%}.input-box[data-v-edc0d12c]::-moz-placeholder{color:#6a6e73;font-family:var(--rh-font-family-body-text,"Red Hat Text","RedHatText",Arial,sans-serif);font-size:var(--rh-font-size-body-text-md,1rem);font-weight:var(--rh-font-weight-code-regular,400);line-height:24px}.input-box[data-v-edc0d12c]::placeholder{color:#6a6e73;font-family:var(--rh-font-family-body-text,"Red Hat Text","RedHatText",Arial,sans-serif);font-size:var(--rh-font-size-body-text-md,1rem);font-weight:var(--rh-font-weight-code-regular,400);line-height:24px}@media(max-width:960px){.search-box[data-v-edc0d12c]{width:28rem}}@media (max-width:768px){.right-navigation[data-v-edc0d12c],.upper-navigation[data-v-edc0d12c]{display:none}}@media (min-width:767px){.pfe-navigation__search form[data-v-edc0d12c]{padding:var(--rh-space-2xl,32px) 0}}</style>
<style>.element-invisible,.sr-only,.visually-hidden{height:1px;overflow:hidden;padding:0;position:absolute;width:1px;clip:rect(0,0,0,0);border:0;white-space:nowrap}@keyframes reveal-nav{0%{max-height:72px;max-height:var(--pfe-navigation__nav-bar--Height,72px);opacity:0;visibility:hidden}99%{max-height:72px;max-height:var(--pfe-navigation__nav-bar--Height,72px)}to{max-height:9999em;opacity:1;visibility:visible}}@keyframes reveal-nav-parts{0%{max-height:72px;max-height:var(--pfe-navigation__nav-bar--Height,72px);opacity:0;visibility:hidden}1%{visibility:visible}99%{max-height:72px;max-height:var(--pfe-navigation__nav-bar--Height,72px)}to{max-height:9999em;opacity:1;visibility:visible}}@media print{.pfe-navigation__menu,pfe-navigation [slot]{display:none!important}}pfe-navigation{--pfe-broadcasted--text:var(--pfe-theme--color--text,#151515);--pfe-broadcasted--text--muted:var(--pfe-theme--color--text--muted,#6a6e73);--pfe-broadcasted--link:var(--pfe-theme--color--link,#06c);--pfe-broadcasted--link--hover:var(--pfe-theme--color--link--hover,#004080);--pfe-broadcasted--link--focus:var(--pfe-theme--color--link--focus,#004080);--pfe-broadcasted--link--visited:var(--pfe-theme--color--link--visited,#6753ac);--pfe-broadcasted--link-decoration:var(--pfe-theme--link-decoration,none);--pfe-broadcasted--link-decoration--hover:var(--pfe-theme--link-decoration--hover,underline);--pfe-broadcasted--link-decoration--focus:var(--pfe-theme--link-decoration--focus,underline);--pfe-broadcasted--link-decoration--visited:var(--pfe-theme--link-decoration--visited,none)}@supports (display:grid){pfe-navigation{animation:reveal-nav .1618s 4s 1 forwards;max-height:72px;max-height:var(--pfe-navigation__nav-bar--Height,72px)}pfe-navigation>*{animation:reveal-nav-parts .1618s 4s 1 forwards;opacity:0;transition:opacity .1618s ease-in-out;transition:opacity var(--pfe-reveal-duration,.1618s) ease-in-out;visibility:hidden}}pfe-navigation.pfe-navigation--processed,pfe-navigation.pfe-navigation--processed>*{animation:none;opacity:1;visibility:visible}pfe-navigation pfe-primary-detail{display:none}pfe-navigation[pfelement]{display:block}pfe-navigation-dropdown{color:#151515;color:var(--pfe-navigation__dropdown--Color,#151515)}#pfe-navigation[breakpoint=desktop] .hidden-at-desktop[class][class][class],#pfe-navigation[breakpoint=mobile] .hidden-at-mobile[class][class][class],#pfe-navigation[breakpoint=tablet] .hidden-at-tablet[class][class][class],pfe-navigation[breakpoint=desktop] .hidden-at-desktop[class][class][class],pfe-navigation[breakpoint=mobile] .hidden-at-mobile[class][class][class],pfe-navigation[breakpoint=tablet] .hidden-at-tablet[class][class][class]{display:none}#pfe-navigation,#pfe-navigation *,pfe-navigation,pfe-navigation *{box-sizing:border-box}#pfe-navigation [pfelement] .pfe-navigation__log-in-link,pfe-navigation [pfelement] .pfe-navigation__log-in-link{display:none}#pfe-navigation,pfe-navigation{align-items:stretch;background:#151515;background:var(--pfe-navigation__nav-bar--Background,#151515);color:#fff;color:var(--pfe-navigation__nav-bar--Color--default,var(--pfe-theme--color--ui-base--text,#fff));display:flex;font-family:Red Hat Text,RedHatText,Arial,Helvetica,sans-serif;font-family:var(--pfe-navigation--FontFamily,Red Hat Text,RedHatText,Arial,Helvetica,sans-serif);font-size:1rem;font-size:var(--pf-global--FontSize--md,1rem);height:72px;height:var(--pfe-navigation__nav-bar--Height,72px);height:auto;line-height:1.5;margin:0;max-width:9999em;min-height:72px;min-height:var(--pfe-navigation__nav-bar--Height,72px);padding:0 16px;position:relative;z-index:95;z-index:var(--pfe-navigation--ZIndex,var(--pfe-theme--zindex--navigation,95))}@media (min-width:768px){#pfe-navigation,pfe-navigation{flex-wrap:wrap;margin:0;max-width:9999em;padding:0 16px}}@media (min-width:1200px){#pfe-navigation,pfe-navigation{margin:0 auto;padding:0 32px}}#pfe-navigation .pfe-navigation__dropdown,#pfe-navigation pfe-navigation-dropdown,pfe-navigation .pfe-navigation__dropdown,pfe-navigation pfe-navigation-dropdown{display:none}#pfe-navigation>[slot=account],#pfe-navigation>[slot=search],#pfe-navigation>[slot=secondary-links],pfe-navigation>[slot=account],pfe-navigation>[slot=search],pfe-navigation>[slot=secondary-links]{height:0;overflow:hidden;visibility:hidden;width:0}@media (min-width:768px){#pfe-navigation nav.pfe-navigation,pfe-navigation nav.pfe-navigation{align-items:stretch;display:flex;flex-wrap:wrap}}@media (min-width:992px){#pfe-navigation nav.pfe-navigation,pfe-navigation nav.pfe-navigation{flex-wrap:nowrap}}#pfe-navigation .pfe-navigation__logo-wrapper,pfe-navigation .pfe-navigation__logo-wrapper{align-items:center;display:flex;justify-content:flex-start;margin:0;min-width:150px;padding:10px 16px 10px 0}@media (min-width:768px){.pfe-navigation--no-main-menu #pfe-navigation .pfe-navigation__logo-wrapper,.pfe-navigation--no-main-menu pfe-navigation .pfe-navigation__logo-wrapper{margin-right:auto}}.pfe-navigation--collapse-secondary-links .pfe-navigation--no-main-menu #pfe-navigation .pfe-navigation__logo-wrapper,.pfe-navigation--collapse-secondary-links .pfe-navigation--no-main-menu pfe-navigation .pfe-navigation__logo-wrapper{margin-right:0}#pfe-navigation .pfe-navigation__logo-link,pfe-navigation .pfe-navigation__logo-link{border-radius:3px;display:block;margin-left:-8px;outline:0;padding:6px 8px;position:relative}#pfe-navigation .pfe-navigation__logo-link:focus,pfe-navigation .pfe-navigation__logo-link:focus{outline:0}#pfe-navigation .pfe-navigation__logo-link:focus:after,pfe-navigation .pfe-navigation__logo-link:focus:after{border:1px dashed #fff;bottom:0;content:"";display:block;left:0;position:absolute;right:0;top:0}#pfe-navigation .pfe-navigation__logo-image,pfe-navigation .pfe-navigation__logo-image{display:block;height:auto;width:100%}@media (min-width:576px){#pfe-navigation .pfe-navigation__logo-image,pfe-navigation .pfe-navigation__logo-image{height:40px;height:var(--pfe-navigation__logo--height,40px);width:auto}}@media print{#pfe-navigation .pfe-navigation__logo-image,pfe-navigation .pfe-navigation__logo-image{display:none}}#pfe-navigation .pfe-navigation__logo-image:only-child,pfe-navigation .pfe-navigation__logo-image:only-child{display:block}@media (min-width:576px){#pfe-navigation .pfe-navigation__logo-image.pfe-navigation__logo-image--small,pfe-navigation .pfe-navigation__logo-image.pfe-navigation__logo-image--small{height:32px;height:var(--pfe-navigation__logo--height,32px)}}@media print{#pfe-navigation .pfe-navigation__logo-image.pfe-navigation__logo-image--screen,pfe-navigation .pfe-navigation__logo-image.pfe-navigation__logo-image--screen{display:none!important}}@media screen{#pfe-navigation .pfe-navigation__logo-image.pfe-navigation__logo-image--print,pfe-navigation .pfe-navigation__logo-image.pfe-navigation__logo-image--print{display:none!important}}#pfe-navigation .pfe-navigation__logo-image.pfe-navigation__logo-image--screen.pfe-navigation__logo-image--print,pfe-navigation .pfe-navigation__logo-image.pfe-navigation__logo-image--screen.pfe-navigation__logo-image--print{display:inline-block!important}#pfe-navigation .pfe-navigation__fallback-links a,#pfe-navigation .pfe-navigation__log-in-link,#pfe-navigation .pfe-navigation__menu-link,#pfe-navigation .pfe-navigation__secondary-link,pfe-navigation .pfe-navigation__fallback-links a,pfe-navigation .pfe-navigation__log-in-link,pfe-navigation .pfe-navigation__menu-link,pfe-navigation .pfe-navigation__secondary-link{--pfe-icon--color:var(--pfe-navigation__dropdown--link--Color,var(--pfe-theme--color--link,#06c));align-items:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;background:0 0;border:0;color:#06c;color:var(--pfe-navigation__dropdown--link--Color,var(--pfe-theme--color--link,#06c));color:#fff;color:var(--pfe-navigation__nav-bar--Color--default,var(--pfe-theme--color--ui-base--text,#fff));cursor:pointer;display:flex;font-family:inherit;font-size:1rem;font-size:var(--pf-global--FontSize--md,1rem);justify-content:flex-start;justify-content:center;margin:0;outline:0;padding:8px 24px;position:relative;text-align:center;text-decoration:none;white-space:nowrap;width:100%}@media print{#pfe-navigation .pfe-navigation__fallback-links a,#pfe-navigation .pfe-navigation__log-in-link,#pfe-navigation .pfe-navigation__menu-link,#pfe-navigation .pfe-navigation__secondary-link,pfe-navigation .pfe-navigation__fallback-links a,pfe-navigation .pfe-navigation__log-in-link,pfe-navigation .pfe-navigation__menu-link,pfe-navigation .pfe-navigation__secondary-link{display:none!important}}@media (min-width:768px){#pfe-navigation .pfe-navigation__fallback-links a,#pfe-navigation .pfe-navigation__log-in-link,#pfe-navigation .pfe-navigation__menu-link,#pfe-navigation .pfe-navigation__secondary-link,pfe-navigation .pfe-navigation__fallback-links a,pfe-navigation .pfe-navigation__log-in-link,pfe-navigation .pfe-navigation__menu-link,pfe-navigation .pfe-navigation__secondary-link{--pfe-icon--color:var(--pfe-navigation__nav-bar--Color--default,var(--pfe-theme--color--ui-base--text,#fff));color:#fff;color:var(--pfe-navigation__nav-bar--Color--default,var(--pfe-theme--color--ui-base--text,#fff));display:flex;flex-direction:column;font-size:12px;font-size:var(--pfe-navigation--FontSize--xs,12px);height:72px;height:var(--pfe-navigation__nav-bar--Height,72px);justify-content:flex-end;padding:14px 8px;width:auto}@supports (display:grid){#pfe-navigation .pfe-navigation__fallback-links a,#pfe-navigation .pfe-navigation__log-in-link,#pfe-navigation .pfe-navigation__menu-link,#pfe-navigation .pfe-navigation__secondary-link,pfe-navigation .pfe-navigation__fallback-links a,pfe-navigation .pfe-navigation__log-in-link,pfe-navigation .pfe-navigation__menu-link,pfe-navigation .pfe-navigation__secondary-link{align-items:center;display:grid;grid-template-rows:26px 18px;justify-items:center}}#pfe-navigation .pfe-navigation__fallback-links a[class]:focus,#pfe-navigation .pfe-navigation__fallback-links a[class]:hover,#pfe-navigation .pfe-navigation__log-in-link[class]:focus,#pfe-navigation .pfe-navigation__log-in-link[class]:hover,#pfe-navigation .pfe-navigation__menu-link[class]:focus,#pfe-navigation .pfe-navigation__menu-link[class]:hover,#pfe-navigation .pfe-navigation__secondary-link[class]:focus,#pfe-navigation .pfe-navigation__secondary-link[class]:hover,pfe-navigation .pfe-navigation__fallback-links a[class]:focus,pfe-navigation .pfe-navigation__fallback-links a[class]:hover,pfe-navigation .pfe-navigation__log-in-link[class]:focus,pfe-navigation .pfe-navigation__log-in-link[class]:hover,pfe-navigation .pfe-navigation__menu-link[class]:focus,pfe-navigation .pfe-navigation__menu-link[class]:hover,pfe-navigation .pfe-navigation__secondary-link[class]:focus,pfe-navigation .pfe-navigation__secondary-link[class]:hover{box-shadow:inset 0 4px 0 0 #06c;box-shadow:inset 0 4px 0 0 var(--pfe-navigation__nav-bar--highlight-color,var(--pfe-theme--color--ui-accent,#06c))}}#pfe-navigation .pfe-navigation__fallback-links a:focus,#pfe-navigation .pfe-navigation__fallback-links a:hover,#pfe-navigation .pfe-navigation__log-in-link:focus,#pfe-navigation .pfe-navigation__log-in-link:hover,#pfe-navigation .pfe-navigation__menu-link:focus,#pfe-navigation .pfe-navigation__menu-link:hover,#pfe-navigation .pfe-navigation__secondary-link:focus,#pfe-navigation .pfe-navigation__secondary-link:hover,pfe-navigation .pfe-navigation__fallback-links a:focus,pfe-navigation .pfe-navigation__fallback-links a:hover,pfe-navigation .pfe-navigation__log-in-link:focus,pfe-navigation .pfe-navigation__log-in-link:hover,pfe-navigation .pfe-navigation__menu-link:focus,pfe-navigation .pfe-navigation__menu-link:hover,pfe-navigation .pfe-navigation__secondary-link:focus,pfe-navigation .pfe-navigation__secondary-link:hover{box-shadow:inset 4px 0 0 0 #06c;box-shadow:inset 4px 0 0 0 var(--pfe-navigation__nav-bar--highlight-color,var(--pfe-theme--color--ui-accent,#06c))}@media (min-width:768px){#pfe-navigation .pfe-navigation__fallback-links a:focus,#pfe-navigation .pfe-navigation__fallback-links a:hover,#pfe-navigation .pfe-navigation__log-in-link:focus,#pfe-navigation .pfe-navigation__log-in-link:hover,#pfe-navigation .pfe-navigation__menu-link:focus,#pfe-navigation .pfe-navigation__menu-link:hover,#pfe-navigation .pfe-navigation__secondary-link:focus,#pfe-navigation .pfe-navigation__secondary-link:hover,pfe-navigation .pfe-navigation__fallback-links a:focus,pfe-navigation .pfe-navigation__fallback-links a:hover,pfe-navigation .pfe-navigation__log-in-link:focus,pfe-navigation .pfe-navigation__log-in-link:hover,pfe-navigation .pfe-navigation__menu-link:focus,pfe-navigation .pfe-navigation__menu-link:hover,pfe-navigation .pfe-navigation__secondary-link:focus,pfe-navigation .pfe-navigation__secondary-link:hover{box-shadow:inset 0 4px 0 0 #06c;box-shadow:inset 0 4px 0 0 var(--pfe-navigation__nav-bar--highlight-color,var(--pfe-theme--color--ui-accent,#06c))}}.pfe-navigation--collapse-secondary-links #pfe-navigation .pfe-navigation__fallback-links a:focus,.pfe-navigation--collapse-secondary-links #pfe-navigation .pfe-navigation__fallback-links a:hover,.pfe-navigation--collapse-secondary-links #pfe-navigation .pfe-navigation__log-in-link:focus,.pfe-navigation--collapse-secondary-links #pfe-navigation .pfe-navigation__log-in-link:hover,.pfe-navigation--collapse-secondary-links #pfe-navigation .pfe-navigation__menu-link:focus,.pfe-navigation--collapse-secondary-links #pfe-navigation .pfe-navigation__menu-link:hover,.pfe-navigation--collapse-secondary-links #pfe-navigation .pfe-navigation__secondary-link:focus,.pfe-navigation--collapse-secondary-links #pfe-navigation .pfe-navigation__secondary-link:hover,.pfe-navigation--collapse-secondary-links pfe-navigation .pfe-navigation__fallback-links a:focus,.pfe-navigation--collapse-secondary-links pfe-navigation .pfe-navigation__fallback-links a:hover,.pfe-navigation--collapse-secondary-links pfe-navigation .pfe-navigation__log-in-link:focus,.pfe-navigation--collapse-secondary-links pfe-navigation .pfe-navigation__log-in-link:hover,.pfe-navigation--collapse-secondary-links pfe-navigation .pfe-navigation__menu-link:focus,.pfe-navigation--collapse-secondary-links pfe-navigation .pfe-navigation__menu-link:hover,.pfe-navigation--collapse-secondary-links pfe-navigation .pfe-navigation__secondary-link:focus,.pfe-navigation--collapse-secondary-links pfe-navigation .pfe-navigation__secondary-link:hover{box-shadow:inset 4px 0 0 0 #06c;box-shadow:inset 4px 0 0 0 var(--pfe-navigation__nav-bar--highlight-color,var(--pfe-theme--color--ui-accent,#06c))}#pfe-navigation .pfe-navigation__fallback-links a:focus,#pfe-navigation .pfe-navigation__log-in-link:focus,#pfe-navigation .pfe-navigation__menu-link:focus,#pfe-navigation .pfe-navigation__secondary-link:focus,pfe-navigation .pfe-navigation__fallback-links a:focus,pfe-navigation .pfe-navigation__log-in-link:focus,pfe-navigation .pfe-navigation__menu-link:focus,pfe-navigation .pfe-navigation__secondary-link:focus{outline:0}#pfe-navigation .pfe-navigation__fallback-links a:focus:after,#pfe-navigation .pfe-navigation__log-in-link:focus:after,#pfe-navigation .pfe-navigation__menu-link:focus:after,#pfe-navigation .pfe-navigation__secondary-link:focus:after,pfe-navigation .pfe-navigation__fallback-links a:focus:after,pfe-navigation .pfe-navigation__log-in-link:focus:after,pfe-navigation .pfe-navigation__menu-link:focus:after,pfe-navigation .pfe-navigation__secondary-link:focus:after{border:1px dashed;bottom:0;content:"";display:block;left:0;position:absolute;right:0;top:0}#pfe-navigation .pfe-navigation__fallback-links a pfe-icon,#pfe-navigation .pfe-navigation__log-in-link pfe-icon,#pfe-navigation .pfe-navigation__menu-link pfe-icon,#pfe-navigation .pfe-navigation__secondary-link pfe-icon,pfe-navigation .pfe-navigation__fallback-links a pfe-icon,pfe-navigation .pfe-navigation__log-in-link pfe-icon,pfe-navigation .pfe-navigation__menu-link pfe-icon,pfe-navigation .pfe-navigation__secondary-link pfe-icon{pointer-events:none}#pfe-navigation .pfe-navigation__fallback-links a .secondary-link__icon-wrapper,#pfe-navigation .pfe-navigation__fallback-links a>pfe-icon,#pfe-navigation .pfe-navigation__log-in-link .secondary-link__icon-wrapper,#pfe-navigation .pfe-navigation__log-in-link>pfe-icon,#pfe-navigation .pfe-navigation__menu-link .secondary-link__icon-wrapper,#pfe-navigation .pfe-navigation__menu-link>pfe-icon,#pfe-navigation .pfe-navigation__secondary-link .secondary-link__icon-wrapper,#pfe-navigation .pfe-navigation__secondary-link>pfe-icon,pfe-navigation .pfe-navigation__fallback-links a .secondary-link__icon-wrapper,pfe-navigation .pfe-navigation__fallback-links a>pfe-icon,pfe-navigation .pfe-navigation__log-in-link .secondary-link__icon-wrapper,pfe-navigation .pfe-navigation__log-in-link>pfe-icon,pfe-navigation .pfe-navigation__menu-link .secondary-link__icon-wrapper,pfe-navigation .pfe-navigation__menu-link>pfe-icon,pfe-navigation .pfe-navigation__secondary-link .secondary-link__icon-wrapper,pfe-navigation .pfe-navigation__secondary-link>pfe-icon{--pfe-icon--size:18px;padding-right:5px}@media (min-width:768px){#pfe-navigation .pfe-navigation__fallback-links a .secondary-link__icon-wrapper,#pfe-navigation .pfe-navigation__fallback-links a>pfe-icon,#pfe-navigation .pfe-navigation__log-in-link .secondary-link__icon-wrapper,#pfe-navigation .pfe-navigation__log-in-link>pfe-icon,#pfe-navigation .pfe-navigation__menu-link .secondary-link__icon-wrapper,#pfe-navigation .pfe-navigation__menu-link>pfe-icon,#pfe-navigation .pfe-navigation__secondary-link .secondary-link__icon-wrapper,#pfe-navigation .pfe-navigation__secondary-link>pfe-icon,pfe-navigation .pfe-navigation__fallback-links a .secondary-link__icon-wrapper,pfe-navigation .pfe-navigation__fallback-links a>pfe-icon,pfe-navigation .pfe-navigation__log-in-link .secondary-link__icon-wrapper,pfe-navigation .pfe-navigation__log-in-link>pfe-icon,pfe-navigation .pfe-navigation__menu-link .secondary-link__icon-wrapper,pfe-navigation .pfe-navigation__menu-link>pfe-icon,pfe-navigation .pfe-navigation__secondary-link .secondary-link__icon-wrapper,pfe-navigation .pfe-navigation__secondary-link>pfe-icon{padding-right:0;padding:2px 0 4px}}.pfe-navigation--collapse-secondary-links #pfe-navigation .pfe-navigation__fallback-links a .secondary-link__icon-wrapper,.pfe-navigation--collapse-secondary-links #pfe-navigation .pfe-navigation__fallback-links a>pfe-icon,.pfe-navigation--collapse-secondary-links #pfe-navigation .pfe-navigation__log-in-link .secondary-link__icon-wrapper,.pfe-navigation--collapse-secondary-links #pfe-navigation .pfe-navigation__log-in-link>pfe-icon,.pfe-navigation--collapse-secondary-links #pfe-navigation .pfe-navigation__menu-link .secondary-link__icon-wrapper,.pfe-navigation--collapse-secondary-links #pfe-navigation .pfe-navigation__menu-link>pfe-icon,.pfe-navigation--collapse-secondary-links #pfe-navigation .pfe-navigation__secondary-link .secondary-link__icon-wrapper,.pfe-navigation--collapse-secondary-links #pfe-navigation .pfe-navigation__secondary-link>pfe-icon,.pfe-navigation--collapse-secondary-links pfe-navigation .pfe-navigation__fallback-links a .secondary-link__icon-wrapper,.pfe-navigation--collapse-secondary-links pfe-navigation .pfe-navigation__fallback-links a>pfe-icon,.pfe-navigation--collapse-secondary-links pfe-navigation .pfe-navigation__log-in-link .secondary-link__icon-wrapper,.pfe-navigation--collapse-secondary-links pfe-navigation .pfe-navigation__log-in-link>pfe-icon,.pfe-navigation--collapse-secondary-links pfe-navigation .pfe-navigation__menu-link .secondary-link__icon-wrapper,.pfe-navigation--collapse-secondary-links pfe-navigation .pfe-navigation__menu-link>pfe-icon,.pfe-navigation--collapse-secondary-links pfe-navigation .pfe-navigation__secondary-link .secondary-link__icon-wrapper,.pfe-navigation--collapse-secondary-links pfe-navigation .pfe-navigation__secondary-link>pfe-icon{padding:0 16px 0 0}#pfe-navigation .pfe-navigation__fallback-links a pfe-icon,#pfe-navigation .pfe-navigation__log-in-link pfe-icon,#pfe-navigation .pfe-navigation__menu-link pfe-icon,#pfe-navigation .pfe-navigation__secondary-link pfe-icon,pfe-navigation .pfe-navigation__fallback-links a pfe-icon,pfe-navigation .pfe-navigation__log-in-link pfe-icon,pfe-navigation .pfe-navigation__menu-link pfe-icon,pfe-navigation .pfe-navigation__secondary-link pfe-icon{display:block;height:18px}#pfe-navigation .pfe-navigation__fallback-links a[class],#pfe-navigation .pfe-navigation__fallback-links a[href],#pfe-navigation .pfe-navigation__log-in-link[class],#pfe-navigation .pfe-navigation__log-in-link[href],#pfe-navigation .pfe-navigation__menu-link[class],#pfe-navigation .pfe-navigation__menu-link[href],#pfe-navigation .pfe-navigation__secondary-link[class],#pfe-navigation .pfe-navigation__secondary-link[href],pfe-navigation .pfe-navigation__fallback-links a[class],pfe-navigation .pfe-navigation__fallback-links a[href],pfe-navigation .pfe-navigation__log-in-link[class],pfe-navigation .pfe-navigation__log-in-link[href],pfe-navigation .pfe-navigation__menu-link[class],pfe-navigation .pfe-navigation__menu-link[href],pfe-navigation .pfe-navigation__secondary-link[class],pfe-navigation .pfe-navigation__secondary-link[href]{align-items:center;justify-content:center}#pfe-navigation .pfe-navigation__account-toggle,#pfe-navigation [slot=account]>a[href],pfe-navigation .pfe-navigation__account-toggle,pfe-navigation [slot=account]>a[href]{--pfe-icon--color:var(--pfe-navigation__dropdown--link--Color,var(--pfe-theme--color--link,#06c));align-items:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;background:0 0;border:0;color:#06c;color:var(--pfe-navigation__dropdown--link--Color,var(--pfe-theme--color--link,#06c));cursor:pointer;font-family:inherit;font-size:1rem;font-size:var(--pf-global--FontSize--md,1rem);justify-content:flex-start;margin:0;outline:0;position:relative;text-align:center;text-decoration:none;white-space:nowrap;width:100%;--pfe-icon--color:var(--pfe-navigation__nav-bar--Color--default,var(--pfe-theme--color--ui-base--text,#fff));color:#fff;color:var(--pfe-navigation__nav-bar--Color--default,var(--pfe-theme--color--ui-base--text,#fff));display:flex;flex-direction:column;font-size:12px;font-size:var(--pfe-navigation--FontSize--xs,12px);height:72px;height:var(--pfe-navigation__nav-bar--Height,72px);justify-content:flex-end;padding:14px 8px;width:auto}@media print{#pfe-navigation .pfe-navigation__account-toggle,#pfe-navigation [slot=account]>a[href],pfe-navigation .pfe-navigation__account-toggle,pfe-navigation [slot=account]>a[href]{display:none!important}}#pfe-navigation .pfe-navigation__account-toggle:focus,#pfe-navigation .pfe-navigation__account-toggle:hover,#pfe-navigation [slot=account]>a[href]:focus,#pfe-navigation [slot=account]>a[href]:hover,pfe-navigation .pfe-navigation__account-toggle:focus,pfe-navigation .pfe-navigation__account-toggle:hover,pfe-navigation [slot=account]>a[href]:focus,pfe-navigation [slot=account]>a[href]:hover{box-shadow:inset 4px 0 0 0 #06c;box-shadow:inset 4px 0 0 0 var(--pfe-navigation__nav-bar--highlight-color,var(--pfe-theme--color--ui-accent,#06c))}#pfe-navigation .pfe-navigation__account-toggle:focus,#pfe-navigation [slot=account]>a[href]:focus,pfe-navigation .pfe-navigation__account-toggle:focus,pfe-navigation [slot=account]>a[href]:focus{outline:0}#pfe-navigation .pfe-navigation__account-toggle:focus:after,#pfe-navigation [slot=account]>a[href]:focus:after,pfe-navigation .pfe-navigation__account-toggle:focus:after,pfe-navigation [slot=account]>a[href]:focus:after{border:1px dashed;bottom:0;content:"";display:block;left:0;position:absolute;right:0;top:0}#pfe-navigation .pfe-navigation__account-toggle pfe-icon,#pfe-navigation [slot=account]>a[href] pfe-icon,pfe-navigation .pfe-navigation__account-toggle pfe-icon,pfe-navigation [slot=account]>a[href] pfe-icon{pointer-events:none}@supports (display:grid){#pfe-navigation .pfe-navigation__account-toggle,#pfe-navigation [slot=account]>a[href],pfe-navigation .pfe-navigation__account-toggle,pfe-navigation [slot=account]>a[href]{align-items:center;display:grid;grid-template-rows:26px 18px;justify-items:center}}#pfe-navigation .pfe-navigation__account-toggle[class]:focus,#pfe-navigation .pfe-navigation__account-toggle[class]:hover,#pfe-navigation [slot=account]>a[href][class]:focus,#pfe-navigation [slot=account]>a[href][class]:hover,pfe-navigation .pfe-navigation__account-toggle[class]:focus,pfe-navigation .pfe-navigation__account-toggle[class]:hover,pfe-navigation [slot=account]>a[href][class]:focus,pfe-navigation [slot=account]>a[href][class]:hover{box-shadow:inset 0 4px 0 0 #06c;box-shadow:inset 0 4px 0 0 var(--pfe-navigation__nav-bar--highlight-color,var(--pfe-theme--color--ui-accent,#06c))}@media print{#pfe-navigation .pfe-navigation__account-toggle,#pfe-navigation [slot=account]>a[href],pfe-navigation .pfe-navigation__account-toggle,pfe-navigation [slot=account]>a[href]{display:none}}#pfe-navigation .pfe-navigation__account-toggle pfe-icon,#pfe-navigation [slot=account]>a[href] pfe-icon,pfe-navigation .pfe-navigation__account-toggle pfe-icon,pfe-navigation [slot=account]>a[href] pfe-icon{--pfe-icon--size:18px;padding:2px 0 4px}@media (min-width:768px){#pfe-navigation .pfe-navigation__account-toggle pfe-icon,#pfe-navigation [slot=account]>a[href] pfe-icon,pfe-navigation .pfe-navigation__account-toggle pfe-icon,pfe-navigation [slot=account]>a[href] pfe-icon{padding-right:0}}#pfe-navigation .pfe-navigation__account-toggle:focus,#pfe-navigation .pfe-navigation__account-toggle:hover,#pfe-navigation .pfe-navigation__account-toggle[aria-expanded=true],#pfe-navigation [slot=account]>a[href][href]:focus,#pfe-navigation [slot=account]>a[href][href]:hover,pfe-navigation .pfe-navigation__account-toggle:focus,pfe-navigation .pfe-navigation__account-toggle:hover,pfe-navigation .pfe-navigation__account-toggle[aria-expanded=true],pfe-navigation [slot=account]>a[href][href]:focus,pfe-navigation [slot=account]>a[href][href]:hover{box-shadow:inset 0 4px 0 0 #06c;box-shadow:inset 0 4px 0 0 var(--pfe-navigation__nav-bar--highlight-color,var(--pfe-theme--color--ui-accent,#06c))}#pfe-navigation .pfe-navigation__account-toggle[aria-expanded=true],pfe-navigation .pfe-navigation__account-toggle[aria-expanded=true]{--pfe-icon--color:var(--pfe-navigation__nav-bar--Color--active,var(--pfe-theme--color--text,#151515));background:#fff;background:var(--pfe-navigation__nav-bar--toggle--BackgroundColor--active,var(--pfe-theme--color--surface--lightest,#fff));color:#151515;color:var(--pfe-navigation__nav-bar--Color--active,var(--pfe-theme--color--text,#151515))}#pfe-navigation .pfe-navigation__account-toggle[aria-expanded=true]:focus,pfe-navigation .pfe-navigation__account-toggle[aria-expanded=true]:focus{outline:0}#pfe-navigation .pfe-navigation__account-toggle[aria-expanded=true]:focus:after,pfe-navigation .pfe-navigation__account-toggle[aria-expanded=true]:focus:after{border:1px dashed #151515;border:1px dashed var(--pfe-navigation__nav-bar--Color--active,var(--pfe-theme--color--text,#151515));bottom:0;content:"";display:block;left:0;position:absolute;right:0;top:0}#pfe-navigation .pfe-navigation__fallback-links,#pfe-navigation .pfe-navigation__menu,pfe-navigation .pfe-navigation__fallback-links,pfe-navigation .pfe-navigation__menu{font-size:inherit;list-style:none;margin:0;padding:0}@media (min-width:768px){#pfe-navigation .pfe-navigation__fallback-links,#pfe-navigation .pfe-navigation__menu,pfe-navigation .pfe-navigation__fallback-links,pfe-navigation .pfe-navigation__menu{align-items:stretch;display:flex}}#pfe-navigation .pfe-navigation__fallback-links li,#pfe-navigation .pfe-navigation__menu li,pfe-navigation .pfe-navigation__fallback-links li,pfe-navigation .pfe-navigation__menu li{font-size:inherit;margin:0;padding:0}#pfe-navigation .pfe-navigation__fallback-links li:before,#pfe-navigation .pfe-navigation__menu li:before,pfe-navigation .pfe-navigation__fallback-links li:before,pfe-navigation .pfe-navigation__menu li:before{content:none}#pfe-navigation .pfe-navigation__fallback-links,pfe-navigation .pfe-navigation__fallback-links{margin-left:auto}#pfe-navigation .pfe-navigation__menu-link,pfe-navigation .pfe-navigation__menu-link{display:flex;font-size:1rem;font-size:var(--pf-global--FontSize--md,1rem);white-space:nowrap}#pfe-navigation.pfe-navigation--processed,pfe-navigation.pfe-navigation--processed{display:block;padding:0}#pfe-navigation.pfe-navigation--processed:before,pfe-navigation.pfe-navigation--processed:before{content:none}#pfe-navigation.pfe-navigation--processed>[slot=account],#pfe-navigation.pfe-navigation--processed>[slot=search],#pfe-navigation.pfe-navigation--processed>[slot=secondary-links],pfe-navigation.pfe-navigation--processed>[slot=account],pfe-navigation.pfe-navigation--processed>[slot=search],pfe-navigation.pfe-navigation--processed>[slot=secondary-links]{height:auto;overflow:visible;visibility:visible;width:auto}#pfe-navigation.pfe-navigation--processed pfe-navigation-dropdown,pfe-navigation.pfe-navigation--processed pfe-navigation-dropdown{display:block}#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown,#pfe-navigation.pfe-navigation--processed pfe-navigation-dropdown,#pfe-navigation.pfe-navigation--processed>[slot],pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown,pfe-navigation.pfe-navigation--processed pfe-navigation-dropdown,pfe-navigation.pfe-navigation--processed>[slot]{animation:none;opacity:1}#pfe-navigation.pfe-navigation--processed [slot=secondary-links],pfe-navigation.pfe-navigation--processed [slot=secondary-links]{display:block;height:auto;list-style:none;margin:0 0 8px;padding:0;width:auto}@media (min-width:768px){#pfe-navigation.pfe-navigation--processed [slot=secondary-links],pfe-navigation.pfe-navigation--processed [slot=secondary-links]{margin:0}}.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed [slot=secondary-links],.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed [slot=secondary-links]{margin:0 0 8px}#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button{--pfe-icon--color:var(--pfe-navigation__dropdown--link--Color,var(--pfe-theme--color--link,#06c));align-items:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;background:0 0;border:0;color:#06c;color:var(--pfe-navigation__dropdown--link--Color,var(--pfe-theme--color--link,#06c));cursor:pointer;display:flex;font-family:inherit;font-size:1rem;font-size:var(--pf-global--FontSize--md,1rem);justify-content:flex-start;margin:0;outline:0;padding:8px 24px;position:relative;text-align:center;text-decoration:none;white-space:nowrap;width:100%}@media print{#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button{display:none!important}}@media (min-width:768px){#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button{--pfe-icon--color:var(--pfe-navigation__nav-bar--Color--default,var(--pfe-theme--color--ui-base--text,#fff));color:#fff;color:var(--pfe-navigation__nav-bar--Color--default,var(--pfe-theme--color--ui-base--text,#fff));display:flex;flex-direction:column;font-size:12px;font-size:var(--pfe-navigation--FontSize--xs,12px);height:72px;height:var(--pfe-navigation__nav-bar--Height,72px);justify-content:flex-end;padding:14px 8px;width:auto}@supports (display:grid){#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button{align-items:center;display:grid;grid-template-rows:26px 18px;justify-items:center}}#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a[class]:focus,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a[class]:hover,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button[class]:focus,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button[class]:hover,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a[class]:focus,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a[class]:hover,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button[class]:focus,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button[class]:hover{box-shadow:inset 0 4px 0 0 #06c;box-shadow:inset 0 4px 0 0 var(--pfe-navigation__nav-bar--highlight-color,var(--pfe-theme--color--ui-accent,#06c))}}#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:focus,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:hover,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:focus,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:hover,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:focus,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:hover,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:focus,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:hover{box-shadow:inset 4px 0 0 0 #06c;box-shadow:inset 4px 0 0 0 var(--pfe-navigation__nav-bar--highlight-color,var(--pfe-theme--color--ui-accent,#06c))}@media (min-width:768px){#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:focus,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:hover,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:focus,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:hover,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:focus,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:hover,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:focus,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:hover{box-shadow:inset 0 4px 0 0 #06c;box-shadow:inset 0 4px 0 0 var(--pfe-navigation__nav-bar--highlight-color,var(--pfe-theme--color--ui-accent,#06c))}}.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:focus,.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:hover,.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:focus,.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:hover,.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:focus,.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:hover,.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:focus,.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:hover{box-shadow:inset 4px 0 0 0 #06c;box-shadow:inset 4px 0 0 0 var(--pfe-navigation__nav-bar--highlight-color,var(--pfe-theme--color--ui-accent,#06c))}#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:focus,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:focus,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:focus,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:focus{outline:0}#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:focus:after,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:focus:after,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:focus:after,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:focus:after{border:1px dashed;bottom:0;content:"";display:block;left:0;position:absolute;right:0;top:0}#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a pfe-icon,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button pfe-icon,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a pfe-icon,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button pfe-icon{pointer-events:none}#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a .secondary-link__icon-wrapper,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a>pfe-icon,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button .secondary-link__icon-wrapper,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button>pfe-icon,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a .secondary-link__icon-wrapper,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a>pfe-icon,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button .secondary-link__icon-wrapper,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button>pfe-icon{--pfe-icon--size:18px;padding-right:5px}@media (min-width:768px){#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a .secondary-link__icon-wrapper,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a>pfe-icon,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button .secondary-link__icon-wrapper,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button>pfe-icon,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a .secondary-link__icon-wrapper,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a>pfe-icon,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button .secondary-link__icon-wrapper,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button>pfe-icon{padding-right:0;padding:2px 0 4px}}.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a .secondary-link__icon-wrapper,.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a>pfe-icon,.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button .secondary-link__icon-wrapper,.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button>pfe-icon,.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a .secondary-link__icon-wrapper,.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a>pfe-icon,.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button .secondary-link__icon-wrapper,.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button>pfe-icon{padding:0 16px 0 0}#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a pfe-icon,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button pfe-icon,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a pfe-icon,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button pfe-icon{display:block;height:18px}@media (min-width:768px){#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:focus,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:focus,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:focus,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:focus{outline:0}#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:focus:after,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:focus:after,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:focus:after,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:focus:after{border:1px dashed #fff;border:1px dashed var(--pfe-navigation__nav-bar--Color--default,var(--pfe-theme--color--ui-base--text,#fff));bottom:0;content:"";display:block;left:0;position:absolute;right:0;top:0}}.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:focus,.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:focus,.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:focus,.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:focus{box-shadow:none}@media (min-width:768px){#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a[aria-expanded=true],#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button[aria-expanded=true],pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a[aria-expanded=true],pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button[aria-expanded=true]{--pfe-icon--color:var(--pfe-navigation__nav-bar--Color--active,var(--pfe-theme--color--text,#151515));background:#fff;background:var(--pfe-navigation__nav-bar--toggle--BackgroundColor--active,var(--pfe-theme--color--surface--lightest,#fff));color:#151515;color:var(--pfe-navigation__nav-bar--Color--active,var(--pfe-theme--color--text,#151515))}}.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a[aria-expanded=true],.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button[aria-expanded=true],.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a[aria-expanded=true],.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button[aria-expanded=true]{background:0 0;box-shadow:none}#pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown__wrapper--single-column,pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown__wrapper--single-column{position:relative}#pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown__wrapper,pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown__wrapper{display:block}#pfe-navigation.pfe-navigation--processed [slot=secondary-links] .pfe-navigation__dropdown-wrapper[class],pfe-navigation.pfe-navigation--processed [slot=secondary-links] .pfe-navigation__dropdown-wrapper[class]{height:0;transition:height .25s ease-in-out;transition:var(--pfe-navigation--accordion-transition,height .25s ease-in-out)}@media (prefers-reduced-motion){#pfe-navigation.pfe-navigation--processed [slot=secondary-links] .pfe-navigation__dropdown-wrapper[class],pfe-navigation.pfe-navigation--processed [slot=secondary-links] .pfe-navigation__dropdown-wrapper[class]{transition:none}}@media (min-width:768px){#pfe-navigation.pfe-navigation--processed [slot=secondary-links] .pfe-navigation__dropdown-wrapper[class],pfe-navigation.pfe-navigation--processed [slot=secondary-links] .pfe-navigation__dropdown-wrapper[class]{position:absolute;right:0;top:72px;top:var(--pfe-navigation__nav-bar--Height,72px)}}.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed [slot=secondary-links] .pfe-navigation__dropdown-wrapper[class],.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed [slot=secondary-links] .pfe-navigation__dropdown-wrapper[class]{position:static}@media (min-width:768px){#pfe-navigation.pfe-navigation--processed [slot=secondary-links] .pfe-navigation__dropdown-wrapper[class][aria-hidden=false],pfe-navigation.pfe-navigation--processed [slot=secondary-links] .pfe-navigation__dropdown-wrapper[class][aria-hidden=false]{height:auto}}.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed [slot=secondary-links] .pfe-navigation__dropdown-wrapper[class][aria-hidden=false],.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed [slot=secondary-links] .pfe-navigation__dropdown-wrapper[class][aria-hidden=false]{height:0}#pfe-navigation.pfe-navigation--processed[breakpoint=mobile] [slot=secondary-links][mobile-slider] .pfe-navigation__dropdown-wrapper,pfe-navigation.pfe-navigation--processed[breakpoint=mobile] [slot=secondary-links][mobile-slider] .pfe-navigation__dropdown-wrapper{left:100vw;left:calc(100vw - 32px);left:calc(100vw - var(--pfe-navigation__mobile-dropdown--PaddingHorizontal,32px));position:absolute;top:0;width:100vw}#pfe-navigation.pfe-navigation--processed[breakpoint=mobile] [slot=secondary-links][mobile-slider] .pfe-navigation__dropdown-wrapper[aria-hidden=false],pfe-navigation.pfe-navigation--processed[breakpoint=mobile] [slot=secondary-links][mobile-slider] .pfe-navigation__dropdown-wrapper[aria-hidden=false]{height:100vh;height:calc(100vh - 72px);height:calc(100vh - var(--pfe-navigation__nav-bar--Height,72px));overflow-y:scroll}#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles,#pfe-navigation.pfe-navigation--processed .pfe-navigation__site-switcher .pfe-navigation__dropdown-wrapper,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles,pfe-navigation.pfe-navigation--processed .pfe-navigation__site-switcher .pfe-navigation__dropdown-wrapper{background:#fff;background:var(--pfe-navigation__dropdown--Background,var(--pfe-theme--color--surface--lightest,#fff));padding:0 24px;padding:0 var(--pfe-navigation__dropdown--full-width--spacing--mobile,24px)}@media (min-width:768px){#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles,#pfe-navigation.pfe-navigation--processed .pfe-navigation__site-switcher .pfe-navigation__dropdown-wrapper,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles,pfe-navigation.pfe-navigation--processed .pfe-navigation__site-switcher .pfe-navigation__dropdown-wrapper{padding:0 64px24px;padding:0 var(--pfe-navigation__dropdown--full-width--spacing--desktop,64px) var(--pfe-navigation__dropdown--full-width--spacing--mobile,24px)}}.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container,.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles,.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed .pfe-navigation__site-switcher .pfe-navigation__dropdown-wrapper,.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container,.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles,.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed .pfe-navigation__site-switcher .pfe-navigation__dropdown-wrapper{padding:0 24px;padding:0 var(--pfe-navigation__dropdown--full-width--spacing--mobile,24px)}#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container a,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles a,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container a,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles a{border:1px solid transparent;color:#06c;color:var(--pfe-navigation__dropdown--link--Color,var(--pfe-theme--color--link,#06c));display:inline-block}#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container a:hover,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles a:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container a:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles a:hover{color:#036;color:var(--pfe-navigation__dropdown--link--Color--hover,#036);text-decoration:underline}#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles a:focus{border:1px dashed;outline:0}#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container .pfe-link-list--header,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container [role=heading][aria-heading-level],#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h2,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h3,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h4,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h5,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h6,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles .pfe-link-list--header,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles [role=heading][aria-heading-level],#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h2,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h3,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h4,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h5,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h6,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container .pfe-link-list--header,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container [role=heading][aria-heading-level],pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h2,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h3,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h4,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h5,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h6,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles .pfe-link-list--header,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles [role=heading][aria-heading-level],pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h2,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h3,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h4,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h5,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h6{margin:32px 0 .75em;margin:var(--pfe-navigation--gutter,32px) 0 .75em;padding:0;-moz-column-break-inside:avoid;break-inside:avoid;color:#464646;color:var(--pfe-navigation__dropdown--headings--Color,#464646);font-family:Red Hat Display,RedHatDisplay,Arial,Helvetica,sans-serif;font-family:var(--pfe-navigation--FontFamilyHeadline,Red Hat Display,RedHatDisplay,Arial,Helvetica,sans-serif);font-size:1.125rem;font-size:var(--pf-global--FontSize--lg,1.125rem);font-weight:500}#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container .pfe-link-list--header:first-child,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container [role=heading][aria-heading-level]:first-child,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h2:first-child,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h3:first-child,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h4:first-child,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h5:first-child,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h6:first-child,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles .pfe-link-list--header:first-child,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles [role=heading][aria-heading-level]:first-child,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h2:first-child,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h3:first-child,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h4:first-child,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h5:first-child,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h6:first-child,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container .pfe-link-list--header:first-child,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container [role=heading][aria-heading-level]:first-child,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h2:first-child,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h3:first-child,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h4:first-child,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h5:first-child,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h6:first-child,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles .pfe-link-list--header:first-child,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles [role=heading][aria-heading-level]:first-child,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h2:first-child,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h3:first-child,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h4:first-child,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h5:first-child,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h6:first-child{margin-top:0}#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container .pfe-link-list--header a,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container [role=heading][aria-heading-level] a,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h2 a,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h3 a,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h4 a,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h5 a,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h6 a,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles .pfe-link-list--header a,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles [role=heading][aria-heading-level] a,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h2 a,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h3 a,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h4 a,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h5 a,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h6 a,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container .pfe-link-list--header a,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container [role=heading][aria-heading-level] a,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h2 a,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h3 a,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h4 a,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h5 a,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h6 a,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles .pfe-link-list--header a,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles [role=heading][aria-heading-level] a,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h2 a,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h3 a,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h4 a,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h5 a,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h6 a{border:1px solid transparent;color:#464646;color:var(--pfe-navigation__dropdown--headings--Color,#464646);text-decoration:underline}#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container .pfe-link-list--header a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container .pfe-link-list--header a:hover,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container [role=heading][aria-heading-level] a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container [role=heading][aria-heading-level] a:hover,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h2 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h2 a:hover,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h3 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h3 a:hover,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h4 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h4 a:hover,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h5 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h5 a:hover,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h6 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h6 a:hover,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles .pfe-link-list--header a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles .pfe-link-list--header a:hover,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles [role=heading][aria-heading-level] a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles [role=heading][aria-heading-level] a:hover,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h2 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h2 a:hover,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h3 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h3 a:hover,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h4 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h4 a:hover,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h5 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h5 a:hover,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h6 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h6 a:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container .pfe-link-list--header a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container .pfe-link-list--header a:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container [role=heading][aria-heading-level] a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container [role=heading][aria-heading-level] a:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h2 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h2 a:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h3 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h3 a:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h4 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h4 a:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h5 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h5 a:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h6 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h6 a:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles .pfe-link-list--header a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles .pfe-link-list--header a:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles [role=heading][aria-heading-level] a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles [role=heading][aria-heading-level] a:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h2 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h2 a:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h3 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h3 a:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h4 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h4 a:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h5 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h5 a:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h6 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h6 a:hover{color:#036;color:var(--pfe-navigation__dropdown--link--Color--hover,#036);text-decoration:none}#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container .pfe-link-list--header a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container [role=heading][aria-heading-level] a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h2 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h3 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h4 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h5 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h6 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles .pfe-link-list--header a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles [role=heading][aria-heading-level] a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h2 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h3 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h4 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h5 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h6 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container .pfe-link-list--header a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container [role=heading][aria-heading-level] a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h2 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h3 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h4 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h5 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h6 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles .pfe-link-list--header a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles [role=heading][aria-heading-level] a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h2 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h3 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h4 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h5 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h6 a:focus{border:1px dashed;outline:0}#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container li,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles li,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container li,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles li{margin:0 0 16px;-moz-column-break-inside:avoid;break-inside:avoid}#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container a,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-card,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-cta,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles a,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-card,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-cta,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container a,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-card,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-cta,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles a,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-card,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-cta{-moz-column-break-inside:avoid;break-inside:avoid}#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-cta[pfe-priority=primary],#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-cta[priority=primary],#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-cta[pfe-priority=primary],#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-cta[priority=primary],pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-cta[pfe-priority=primary],pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-cta[priority=primary],pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-cta[pfe-priority=primary],pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-cta[priority=primary]{--pfe-cta--BackgroundColor:var(--pfe-navigation__dropdown--pfe-cta--BackgroundColor,#e00);--pfe-cta--BackgroundColor--hover:var(--pfe-navigation__dropdown--pfe-cta--hover--BackgroundColor,#c00);--pfe-theme--ui--border-width:0}#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-cta[pfe-priority=primary]:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-cta[pfe-priority=primary]:hover,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-cta[priority=primary]:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-cta[priority=primary]:hover,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-cta[pfe-priority=primary]:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-cta[pfe-priority=primary]:hover,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-cta[priority=primary]:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-cta[priority=primary]:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-cta[pfe-priority=primary]:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-cta[pfe-priority=primary]:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-cta[priority=primary]:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-cta[priority=primary]:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-cta[pfe-priority=primary]:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-cta[pfe-priority=primary]:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-cta[priority=primary]:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-cta[priority=primary]:hover{--pfe-cta--BackgroundColor:var(--pfe-navigation__dropdown--pfe-cta--hover--BackgroundColor,#c00)}pfe-card #pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-cta,pfe-card #pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-cta,pfe-card pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-cta,pfe-card pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-cta{margin-top:0}#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container li,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container ul,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles li,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles ul,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container li,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container ul,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles li,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles ul{list-style:none;margin:0;padding:0}#pfe-navigation.pfe-navigation--processed .pfe-navigation-grid,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles,pfe-navigation.pfe-navigation--processed .pfe-navigation-grid,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles{color:#151515;color:var(--pfe-navigation__dropdown--Color,#151515);-moz-column-count:auto;column-count:auto;display:block;font-size:1rem;font-size:var(--pf-global--FontSize--md,1rem);gap:0;margin-left:auto;margin-right:auto;max-width:1136px;max-width:var(--pfe-navigation--content-max-width,1136px);padding-bottom:12px;padding-top:12px;width:calc(100% + 32px)}@media (min-width:768px){#pfe-navigation.pfe-navigation--processed .pfe-navigation-grid,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles,pfe-navigation.pfe-navigation--processed .pfe-navigation-grid,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles{-moz-column-count:3;column-count:3;display:block;gap:32px;gap:var(--pfe-navigation--gutter,32px);padding-bottom:12px;padding-top:12px}}@media (min-width:1200px){#pfe-navigation.pfe-navigation--processed .pfe-navigation-grid,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles,pfe-navigation.pfe-navigation--processed .pfe-navigation-grid,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles{-moz-column-count:auto;column-count:auto;display:flex;flex-wrap:wrap;padding-bottom:32px;padding-top:32px}@supports (display:grid){#pfe-navigation.pfe-navigation--processed .pfe-navigation-grid,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles,pfe-navigation.pfe-navigation--processed .pfe-navigation-grid,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles{display:grid;gap:32px;gap:var(--pfe-navigation--gutter,32px);grid-auto-flow:row;grid-template-columns:repeat(4,minmax(0,1fr))}}}.pfe-navigation--collapse-main-menu #pfe-navigation.pfe-navigation--processed .pfe-navigation-grid,.pfe-navigation--collapse-main-menu #pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles,.pfe-navigation--collapse-main-menu pfe-navigation.pfe-navigation--processed .pfe-navigation-grid,.pfe-navigation--collapse-main-menu pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles{-moz-column-count:3;column-count:3;display:block;gap:32px;gap:var(--pfe-navigation--gutter,32px);padding-bottom:12px;padding-top:12px}.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed .pfe-navigation-grid,.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles,.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed .pfe-navigation-grid,.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles{-moz-column-count:auto;column-count:auto;display:block;gap:0;margin-left:-16px;margin-right:-16px;max-width:1136px;max-width:var(--pfe-navigation--content-max-width,1136px);padding-bottom:12px;padding-top:12px;width:calc(100% + 32px)}.pfe-navigation__menu-item--open #pfe-navigation.pfe-navigation--processed .pfe-navigation-grid,.pfe-navigation__menu-item--open #pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles,.pfe-navigation__menu-item--open pfe-navigation.pfe-navigation--processed .pfe-navigation-grid,.pfe-navigation__menu-item--open pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles{transition-delay:0s;visibility:visible}#pfe-navigation.pfe-navigation--processed .pfe-navigation-grid>*,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles>*,pfe-navigation.pfe-navigation--processed .pfe-navigation-grid>*,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles>*{margin:0 0 18px;-moz-column-break-inside:avoid;break-inside:avoid}@media (min-width:1200px){#pfe-navigation.pfe-navigation--processed .pfe-navigation-grid>*,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles>*,pfe-navigation.pfe-navigation--processed .pfe-navigation-grid>*,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles>*{margin:0}}.pfe-navigation--collapse-main-menu #pfe-navigation.pfe-navigation--processed .pfe-navigation-grid>*,.pfe-navigation--collapse-main-menu #pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles>*,.pfe-navigation--collapse-main-menu pfe-navigation.pfe-navigation--processed .pfe-navigation-grid>*,.pfe-navigation--collapse-main-menu pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles>*{margin:0 0 18px}#pfe-navigation.pfe-navigation--processed .pfe-navigation-grid,pfe-navigation.pfe-navigation--processed .pfe-navigation-grid{max-width:100%}#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--1-x,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--1-x{display:block}#pfe-navigation.pfe-navigation--processed .pfe-navigation__site-switcher .pfe-navigation__dropdown,pfe-navigation.pfe-navigation--processed .pfe-navigation__site-switcher .pfe-navigation__dropdown{background:#fff}#pfe-navigation.pfe-navigation--processed .pfe-navigation__site-switcher .pfe-navigation__dropdown site-switcher,pfe-navigation.pfe-navigation--processed .pfe-navigation__site-switcher .pfe-navigation__dropdown site-switcher{margin-left:auto;margin-right:auto;max-width:1136px;max-width:var(--pfe-navigation--content-max-width,1136px);padding:12px 24px;padding:12px var(--pfe-navigation__dropdown--full-width--spacing--mobile,24px)}@media (min-width:1200px){#pfe-navigation.pfe-navigation--processed .pfe-navigation__site-switcher .pfe-navigation__dropdown site-switcher,pfe-navigation.pfe-navigation--processed .pfe-navigation__site-switcher .pfe-navigation__dropdown site-switcher{padding:32px 64px;padding:32px var(--pfe-navigation__dropdown--full-width--spacing--desktop,64px)}}.pfe-navigation--collapse-main-menu #pfe-navigation.pfe-navigation--processed .pfe-navigation__site-switcher .pfe-navigation__dropdown site-switcher,.pfe-navigation--collapse-main-menu pfe-navigation.pfe-navigation--processed .pfe-navigation__site-switcher .pfe-navigation__dropdown site-switcher{padding:12px 24px;padding:12px var(--pfe-navigation__dropdown--full-width--spacing--mobile,24px)}#pfe-navigation.pfe-navigation--processed .pfe-navigation__site-switcher .pfe-navigation__dropdown site-switcher .container,pfe-navigation.pfe-navigation--processed .pfe-navigation__site-switcher .pfe-navigation__dropdown site-switcher .container{margin:0;padding:0;width:auto}#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--invisible[class],pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--invisible[class]{padding:0}#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--invisible pfe-navigation-dropdown,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--invisible pfe-navigation-dropdown{visibility:hidden}#pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown--single-column[class],pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown--single-column[class]{padding:0}@media (min-width:768px){#pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown--single-column[class],pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown--single-column[class]{box-shadow:0 1px 2px rgba(0,0,0,.12);box-shadow:var(--pfe-navigation__dropdown--BoxShadow,0 1px 2px rgba(0,0,0,.12));max-width:100%;min-width:13em;padding:0 32px;position:absolute;top:100%}}.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown--single-column[class],.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown--single-column[class]{box-shadow:none;max-width:100%;position:static}@media (min-width:768px){#pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown--single-column[class],pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown--single-column[class]{right:0}}#pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown--full[class],pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown--full[class]{width:100%}@media (min-width:768px){#pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown--full[class],pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown--full[class]{left:0;position:absolute;right:0}}.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown--full[class],.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown--full[class]{position:static}#pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown--full[class] .pfe-navigation__dropdown,pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown--full[class] .pfe-navigation__dropdown{width:100%}#pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles,pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles{padding-left:16px;padding-right:16px}#pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles form,pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles form{align-items:center;display:flex}#pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles button,#pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles input,pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles button,pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles input{padding:10px;transition:box-shadow .2s}#pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles input,pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles input{border:1px solid #f0f0f0;border-bottom-color:#8b8e91;color:#717579;flex-basis:0%;flex-grow:1;flex-shrink:1;font-size:1rem;font-size:var(--pf-global--FontSize--md,1rem);margin-right:8px}#pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles input::-moz-placeholder,pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles input::-moz-placeholder{color:#717579}#pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles input::placeholder,pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles input::placeholder{color:#717579}#pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles button,pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles button{background-color:#e00;border:1px solid #e00;border-radius:2px;color:#fff;flex-basis:auto;flex-grow:0;flex-shrink:1;font-size:1rem;font-size:var(--pf-global--FontSize--md,1rem)}#pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles input:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles input:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles input:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles input:hover{outline:0}#pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles input:focus:after,#pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles input:hover:after,pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles input:focus:after,pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles input:hover:after{border:1px dashed #000;bottom:0;content:"";display:block;left:0;position:absolute;right:0;top:0}#pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles button:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles button:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles button:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles button:hover{outline:0}#pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles button:focus:after,#pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles button:hover:after,pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles button:focus:after,pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles button:hover:after{border:1px dashed #fff;bottom:0;content:"";display:block;left:0;position:absolute;right:0;top:0}#pfe-navigation .pfe-navigation__site-switcher__back-wrapper,pfe-navigation .pfe-navigation__site-switcher__back-wrapper{border-bottom:1px solid #d2d2d2;border-bottom:var(--pfe-navigation__dropdown--separator--Border,1px solid var(--pfe-theme--color--ui--border--lighter,#d2d2d2));display:block}@media (min-width:768px){#pfe-navigation .pfe-navigation__site-switcher__back-wrapper,pfe-navigation .pfe-navigation__site-switcher__back-wrapper{display:none}}.pfe-navigation--collapse-secondary-links #pfe-navigation .pfe-navigation__site-switcher__back-wrapper,.pfe-navigation--collapse-secondary-links pfe-navigation .pfe-navigation__site-switcher__back-wrapper{display:block}#pfe-navigation .pfe-navigation__site-switcher__back-button,pfe-navigation .pfe-navigation__site-switcher__back-button{background-color:transparent;border:1px solid transparent;color:#06c;color:var(--pfe-navigation__dropdown--link--Color,var(--pfe-theme--color--link,#06c));cursor:pointer;font-size:1rem;font-size:var(--pf-global--FontSize--md,1rem);padding:21px 21px 21px 45px;position:relative;text-align:left;width:100%}#pfe-navigation .pfe-navigation__site-switcher__back-button:before,pfe-navigation .pfe-navigation__site-switcher__back-button:before{border:2px solid #06c;border:2px solid var(--pfe-navigation__dropdown--link--Color,var(--pfe-theme--color--link,#06c));border-right:0;border-top:0;content:"";display:block;height:8px;left:35px;position:absolute;right:auto;top:27px;transform:rotate(45deg);transform-origin:left top;width:8px}#pfe-navigation .pfe-navigation__site-switcher__back-button:focus,#pfe-navigation .pfe-navigation__site-switcher__back-button:hover,pfe-navigation .pfe-navigation__site-switcher__back-button:focus,pfe-navigation .pfe-navigation__site-switcher__back-button:hover{border:1px dashed #151515;border-top:1px dashed #151515;border:1px dashed var(--pfe-navigation__dropdown--Color,#151515);color:#036;color:var(--pfe-navigation__dropdown--link--Color--hover,#036);outline:0}#pfe-navigation.pfe-navigation--processed site-switcher,pfe-navigation.pfe-navigation--processed site-switcher{-moz-columns:auto;columns:auto;display:block}#pfe-navigation.pfe-navigation--stuck,pfe-navigation.pfe-navigation--stuck{left:0;position:fixed;top:0;width:100%;z-index:95;z-index:var(--pfe-theme--zindex--navigation,95)}#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__outer-menu-wrapper__inner,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__outer-menu-wrapper__inner{opacity:1!important}#pfe-navigation.pfe-navigation--in-crusty-browser pfe-navigation-account,#pfe-navigation.pfe-navigation--in-crusty-browser rh-account-dropdown,pfe-navigation.pfe-navigation--in-crusty-browser pfe-navigation-account,pfe-navigation.pfe-navigation--in-crusty-browser rh-account-dropdown{display:none!important}#pfe-navigation.pfe-navigation--in-crusty-browser[open-toggle=pfe-navigation__account-toggle] pfe-navigation-account,#pfe-navigation.pfe-navigation--in-crusty-browser[open-toggle=pfe-navigation__account-toggle] rh-account-dropdown,pfe-navigation.pfe-navigation--in-crusty-browser[open-toggle=pfe-navigation__account-toggle] pfe-navigation-account,pfe-navigation.pfe-navigation--in-crusty-browser[open-toggle=pfe-navigation__account-toggle] rh-account-dropdown{display:block!important}#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__menu-item,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__menu-item{display:block}#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__menu-link[aria-expanded=true],pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__menu-link[aria-expanded=true]{--pfe-icon--color:var(--pfe-navigation__nav-bar--Color--active,var(--pfe-theme--color--text,#151515));background:#fff;background:var(--pfe-navigation__nav-bar--toggle--BackgroundColor--active,var(--pfe-theme--color--surface--lightest,#fff));color:#151515;color:var(--pfe-navigation__nav-bar--Color--active,var(--pfe-theme--color--text,#151515))}#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__menu-link[aria-expanded=true]:focus,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__menu-link[aria-expanded=true]:focus{outline:0}#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__menu-link[aria-expanded=true]:focus:after,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__menu-link[aria-expanded=true]:focus:after{border:1px dashed;bottom:0;content:"";display:block;left:0;position:absolute;right:0;top:0}#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__dropdown,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__dropdown{display:flex;flex-wrap:wrap}#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__dropdown>.style-scope,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__dropdown>.style-scope{flex-basis:25%}#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__dropdown .pfe-navigation__footer.style-scope,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__dropdown .pfe-navigation__footer.style-scope{flex-basis:100%}#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__dropdown .pfe-navigation__footer.style-scope>.style-scope,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__dropdown .pfe-navigation__footer.style-scope>.style-scope{margin-right:16px}#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__dropdown--single-column,#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__dropdown--single-column ul,#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__dropdown--single-column>.style-scope,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__dropdown--single-column,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__dropdown--single-column ul,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__dropdown--single-column>.style-scope{display:flex;flex-direction:column;flex-wrap:nowrap}#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__dropdown--single-column>.style-scope,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__dropdown--single-column>.style-scope{flex-basis:auto}#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__search-toggle,#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__secondary-link,#pfe-navigation.pfe-navigation--in-crusty-browser [slot=secondary-links]>a,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__search-toggle,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__secondary-link,pfe-navigation.pfe-navigation--in-crusty-browser [slot=secondary-links]>a{color:#fff!important;justify-content:center!important}#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__search-toggle[aria-expanded=true],#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__secondary-link[aria-expanded=true],#pfe-navigation.pfe-navigation--in-crusty-browser [slot=secondary-links]>a[aria-expanded=true],pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__search-toggle[aria-expanded=true],pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__secondary-link[aria-expanded=true],pfe-navigation.pfe-navigation--in-crusty-browser [slot=secondary-links]>a[aria-expanded=true]{color:#151515!important}#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__account-wrapper--logged-in .pfe-navigation__log-in-link,#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__search-toggle .secondary-link__icon-wrapper,#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__search-toggle pfe-icon,#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__secondary-link .secondary-link__icon-wrapper,#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__secondary-link pfe-icon,#pfe-navigation.pfe-navigation--in-crusty-browser [slot=secondary-links]>a .secondary-link__icon-wrapper,#pfe-navigation.pfe-navigation--in-crusty-browser [slot=secondary-links]>a pfe-icon,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__account-wrapper--logged-in .pfe-navigation__log-in-link,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__search-toggle .secondary-link__icon-wrapper,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__search-toggle pfe-icon,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__secondary-link .secondary-link__icon-wrapper,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__secondary-link pfe-icon,pfe-navigation.pfe-navigation--in-crusty-browser [slot=secondary-links]>a .secondary-link__icon-wrapper,pfe-navigation.pfe-navigation--in-crusty-browser [slot=secondary-links]>a pfe-icon{display:none!important}[id=pfe-navigation__account-dropdown][class][class]{display:block;height:auto;left:0;padding:0;position:absolute;top:72px;top:var(--pfe-navigation__nav-bar--Height,72px);width:100%}[id=pfe-navigation__account-dropdown].pfe-navigation__dropdown-wrapper--invisible[class]{display:none}.pfe-navigation__dropdown-wrapper{overflow:hidden}@media (min-width:768px){.pfe-navigation__custom-dropdown--single-column{min-width:25em}}.pfe-navigation--collapse-secondary-links .pfe-navigation__custom-dropdown--single-column{min-width:0}.secondary-link__icon-wrapper{align-items:center;display:flex;justify-content:center}.secondary-link__alert-count{background:#06c;background:var(--pfe-navigation__nav-bar--alert-color,var(--pfe-theme--color--link,#06c));border-radius:20px;color:#fff;color:var(--pfe-navigation__nav-bar--Color--on-highlight,var(--pfe-theme--color--text--on-saturated,#fff));display:block;font-size:12px;font-size:var(--pfe-navigation--FontSize--xs,12px);line-height:20px;margin:0 4px 0 2px;min-width:23px;overflow:hidden;padding:0 8px}.secondary-link__alert-count:empty{display:none}#pfe-navigation__1x-skip-links{left:0;position:absolute;top:0}#pfe-navigation__1x-skip-links,#pfe-navigation__1x-skip-links li{height:0;list-style:none;margin:0;padding:0;width:0}.skip-link[class][class]{font-size:.875rem;font-size:var(--pf-global--FontSize--sm,.875rem);line-height:18px}.skip-link[class][class]:focus{border-radius:.21429em;height:auto;left:50%;padding:.42857em .57143em;position:fixed;top:8px;transform:translateX(-50%);width:auto;z-index:99999;clip:auto;background:#fff;background:var(--pfe-navigation__skip-link--BackgroundColor,var(--pfe-theme--color--surface--lightest,#fff));color:#06c;color:var(--pfe-navigation__skip-link--Color,var(--pfe-theme--color--link,#06c));text-decoration:none}pfe-navigation pfe-navigation-account[slot=account]{background:#fff;background:var(--pfe-navigation__dropdown--Background,var(--pfe-theme--color--surface--lightest,#fff));width:100%}</style>
<style>:host([size=sm]) #container[data-v-8589d091]{--_size:var(--pf-global--icon--FontSize--sm,12px)}.content-wrapper[data-v-8589d091]{height:auto;margin:0 auto;min-height:46vh}.content[data-v-8589d091]{max-width:1000px}#left-content[data-v-8589d091]{max-width:330px;z-index:1}.line-below-chp[data-v-8589d091]{margin:var(--rh-space-xl,24px) 0 var(--rh-space-3xl,48px)}.toc-container[data-v-8589d091]{border-right:1px solid var(--rh-color-gray-30,#c7c7c7);min-height:100vh;position:sticky;top:0;transition:transform .3s ease-in-out}nav#toc[data-v-8589d091]{height:auto;overflow-y:auto;padding-bottom:var(--rh-space-2xl,32px)}.max-height-85[data-v-8589d091]{max-height:85vh}.max-height-75[data-v-8589d091]{max-height:75vh}.toc-filter[data-v-8589d091]{background-color:#fff;padding:var(--rh-space-lg,16px) var(--rh-space-2xl,32px);position:sticky;top:-1px;width:100%;z-index:1}#text[data-v-8589d091],.toc-filter[data-v-8589d091]{align-items:center;display:flex}#text[data-v-8589d091]{flex:1;flex-direction:row}#search-icon[data-v-8589d091]{color:#151515;left:2.5rem;position:absolute;top:55%;transform:translateY(-50%)}pf-icon[data-v-8589d091]{--pf-icon--size:16px}#text:focus-within #icon[data-v-8589d091],#text:hover #icon[data-v-8589d091]{color:#151515}#text[data-v-8589d091]:after,#text[data-v-8589d091]:before{content:"";inset:0;pointer-events:none;position:absolute}#text-input[data-v-8589d091]:focus,#text-input:focus+#utilities[data-v-8589d091]{border-bottom:2px solid #06c;outline:none}#text-input[data-v-8589d091]{background-color:transparent;border:1px solid #f0f0f0;border-bottom-color:#8a8d90;color:#151515;font-family:inherit;font-size:100%;grid-area:text-input;line-height:1.5;overflow:hidden;padding:.375rem .25rem .375rem 2rem;position:relative;text-overflow:ellipsis;white-space:nowrap;width:100%}#utilities[data-v-8589d091]{align-items:center;border:1px solid #f0f0f0;border-bottom:1px solid #8a8d90;border-left:0;display:flex}#utilities rh-badge[data-v-8589d091]{border-radius:80px;font-weight:var(--rh-font-weight-heading-medium,500);--_background-color:#e0e0e0;margin-right:8px}#clear-button[data-v-8589d091]{--pf-c-button--PaddingTop:0.625rem;--pf-c-button--PaddingRight:.25rem;--pf-c-button--PaddingBottom:0.625rem;--pf-c-button--PaddingLeft:.25rem;margin-right:8px}#text-input.no-right-border[data-v-8589d091]{border-right:0}.btn-container[data-v-8589d091]{bottom:0;display:flex;justify-content:flex-end;padding:1rem;pointer-events:none;position:fixed;right:0;z-index:2}.top-scroll-btn[data-v-8589d091]{--pf-c-button--BorderRadius:64px;pointer-events:all}.focusable[data-v-8589d091]:focus-visible{border:2px solid var(--rh-color-interactive-blue,#06c)}.mobile-nav-wrapper[data-v-8589d091]{align-items:center;border-bottom:1px solid #c7c7c7;display:flex;height:auto;justify-content:space-between;padding:var(--rh-space-sm,.5rem)}.mobile-nav[data-v-8589d091]{align-items:center;background-color:var(--rh-color-bg-page,#fff);min-height:51px;position:sticky;top:0;z-index:5}.active-mobile-menu[data-v-8589d091]{color:#151515;padding-left:.5rem}.hidden[data-v-8589d091]{display:none}.mobile-nav-btn[data-v-8589d091]{background-color:transparent;border:none;font-family:inherit;font-size:.875rem;font-weight:500;margin:0;min-height:40px;min-width:40px}.border-right[data-v-8589d091]{border-right:1px solid #c7c7c7}.toc-focus-container[data-v-8589d091]{position:sticky;top:0;z-index:2}.toc-focus-btn[data-v-8589d091]{align-items:center;background-color:var(--rh-color-white,#fff);border:1px solid var(--rh-color-blue-50,#06c);border-radius:50%;cursor:pointer;display:flex;height:40px;justify-content:center;position:absolute;right:-20px;top:15px;width:40px}.toc-focus-btn[data-v-8589d091]:focus-visible,.toc-focus-btn[data-v-8589d091]:hover{background-color:var(--rh-color-blue-10,#e0f0ff);box-shadow:var(--rh-box-shadow-sm,0 2px 4px 0 hsla(0,0%,8%,.2))}.toc-focus-btn[data-v-8589d091]:focus-visible{border:2px solid var(--rh-color-blue-50,#06c)}.toc-focus-btn-icon[data-v-8589d091]{color:var(--rh-color-blue-50,#06c)}.toc-wrapper[data-v-8589d091]{padding:0}.product-container[data-v-8589d091]{border-bottom:1px solid var(--rh-color-gray-30,#c7c7c7);padding:var(--rh-space-xl,24px) var(--rh-space-2xl,32px)}.product-container h1.product-title[data-v-8589d091]{font-size:var(--rh-font-size-code-xl,1.25rem);line-height:30px;margin-bottom:0;margin-top:0}.product-container .product-version[data-v-8589d091]{align-items:center;display:flex;flex-wrap:wrap;margin-top:var(--rh-space-lg,16px)}.product-version .version-label[data-v-8589d091]{color:var(--rh-color-canvas-black,#151515);font-family:Red Hat Text;font-size:var(--rh-font-size-body-text-sm,.875rem);font-weight:500}.product-version .version-select-dropdown[data-v-8589d091]{margin:var(--rh-space-md,8px) var(--rh-space-sm,6px);max-width:9.75rem;min-height:2rem;min-width:3rem;overflow:hidden;width:-moz-min-content;width:min-content;word-wrap:nowrap;-webkit-appearance:none;-moz-appearance:none;background:var(--rh-color-white,#fff);background-image:url("data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http://www.w3.org/2000/svg' width='10' height='6' fill='none' viewBox='0 0 10 6'%3E%3Cpath fill='%23151515' d='M.678 0h8.644c.596 0 .895.797.497 1.195l-4.372 4.58c-.298.3-.695.3-.993 0L.18 1.196C-.216.797.081 0 .678 0'/%3E%3C/svg%3E");background-position-x:85%;background-position-y:50%;background-repeat:no-repeat;border:1px solid var(--rh-color-gray-30,#c7c7c7);border-bottom:0;box-shadow:0 -1px 0 0 var(--rh-color-gray-60,#4d4d4d) inset;cursor:pointer;font-size:var(--rh-font-size-body-text-md,1rem);padding:var(--rh-space-md,8px);padding-right:24px;text-overflow:ellipsis}pf-popover[data-v-8589d091]{margin-top:var(--rh-space-md,8px);--pf-c-popover__arrow--BackgroundColor:var(--rh-color-canvas-black,#151515);--pf-c-popover__content--BackgroundColor:var(--rh-color-canvas-black,#151515);--pf-c-popover--BoxShadow:0px 4px 8px 0px #15151540;--pf-c-popover__title-text--Color:var(--rh-color-white,#fff);--pf-c-popover--MaxWidth:300px;--pf-c-popover--MinWidth:300px;--pf-c-popover--c-button--Top:20px;--pf-c-popover--c-button--Right:4px;--pf-c-button--m-plain--hover--Color:var(--rh-color-white,#fff)}pf-popover[data-v-8589d091]::part(content){padding:var(--rh-space-2xl,32px)}pf-popover[data-v-8589d091]::part(body){margin-top:var(--rh-space-lg,16px)}pf-popover[data-v-8589d091]::part(close-button){--pf-c-button--m-plain--focus--Color:var(--rh-color-gray-30,#c7c7c7);--pf-c-button--m-plain--Color:var(--rh-color-gray-30,#c7c7c7)}.popover-header-text[data-v-8589d091]{color:var(--rh-color-white,#fff);font-size:var(--rh-font-size-code-md,1rem);margin:0;max-width:80%;padding:0}.popover-body-link[data-v-8589d091]{color:var(--rh-color-blue-30,#92c5f9);text-decoration:none}.popover-trigger-btn[data-v-8589d091]{align-items:center;background:none;border:none;cursor:pointer;display:flex;justify-content:center}#first-button[data-v-8589d091]{width:80%}#second-button[data-v-8589d091]{text-align:right;width:20%}#toc-btn[data-v-8589d091]{text-align:left;width:100%}.toc-error[data-v-8589d091]{margin:0;max-width:100%}#layout label[data-v-8589d091]{font-weight:500}.page-layout-options[data-v-8589d091]{background-color:#fff;display:flex;flex-direction:column;padding-bottom:var(--rh-space-lg,16px)}.sticky-top[data-v-8589d091]{position:sticky;top:0}summary[data-v-8589d091]{cursor:pointer;list-style:none;position:relative}summary[data-v-8589d091]::-webkit-details-marker{display:none}details#jump-links-details .jump-links-heading[data-v-8589d091]{background-color:var(--rh-color-white,#fff);display:block;margin-top:var(--rh-space-lg,16px);padding:var(--rh-space-lg,16px) 0 0 var(--rh-space-xl,24px);position:sticky;top:0}details#jump-links-details .jump-links-heading[data-v-8589d091]:before{border-right:3px solid #151515;border-top:3px solid #151515;color:#151515;content:"";display:flex;height:9px;left:2px;position:absolute;top:26px;transform:rotate(-135deg);width:9px}details#jump-links-details[open] .jump-links-heading[data-v-8589d091]:before{transform:rotate(135deg)}.table-of-contents>ol[data-v-8589d091]{list-style:none;margin:0;padding:0}nav.table-of-contents[data-v-8589d091]{z-index:1}nav.table-of-contents ol[data-v-8589d091]{list-style:none;margin:0;padding:0}#mobile-browse-docs[data-v-8589d091]{font-weight:var(--rh-font-weight-body-text-medium,500);padding-left:var(--rh-space-2xl,32px)}.docs-content-container[data-v-8589d091]{font-size:var(--rh-font-size-body-text-lg,1.125rem);font-weight:var(--rh-font-weight-body-text-regular,400);line-height:1.6667;padding-left:6rem;padding-right:6rem;padding-top:var(--rh-space-3xl,4rem)}.chapter-title[data-v-8589d091]{font-family:Red Hat Display}h1.chapter-title[data-v-8589d091]{font-size:var(--rh-fontsize-heading-xl,2.25rem);line-height:46.8px;margin:0;padding:0}.chapter .section h4[data-v-8589d091]{font-size:24px;font-weight:400}.banner-wrapper[data-v-8589d091]{padding:3rem 6rem 0}.page-format-dropdown[data-v-8589d091]{-webkit-appearance:none;-moz-appearance:none;appearance:none;background:#fff;background-image:url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAGCAYAAAD68A/GAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAABtSURBVHgBhc4xCoAwDAXQxE6li0K76w0cPZqjHsEb6AlcHb2BR9ADdG7GmIKTWv0QSOAFPjrndgAo4TtHxszTD4JoVAhh1VoXiNgkUO+971Q8iGgxxlSy1jc3CGof39baWTrzNSOkkksEbG/oBGEJIn6gD3jAAAAAAElFTkSuQmCC");background-position:8.5rem;background-repeat:no-repeat;background-size:auto;border:1px solid #c7c7c7;box-shadow:inset 0 -1px 0 0 #4d4d4d;font-family:Red Hat Text;font-size:var(--rh-font-size-body-text-md,1rem);margin-top:var(--rh-space-xs,4px);max-width:168px;min-height:36px;min-width:168px;overflow:hidden;padding:0 var(--rh-space-xl,24px) 0 var(--rh-space-md,8px);text-overflow:ellipsis;white-space:nowrap}.content-format-selectors[data-v-8589d091]{color:#151515;font-family:Red Hat Text;font-size:var(--rh-font-size-body-text-sm,.875rem);font-weight:var(--rh-font-weight-body-text-medium,500);margin-right:var(--rh-space-2xl,32px);max-width:250px;min-width:250px;padding-top:var(--rh-space-2xl,32px)}.chapter .section .simpara[data-v-8589d091],.chapter .section p[data-v-8589d091]{font-family:Red Hat Text;font-size:var(--rh-font-size-body-text-lg,1.125rem);font-weight:var(--rh-font-weight-body-text-regular,400);line-height:30px}#toggle-focus-mode[data-v-8589d091]{padding-right:var(--rh-space-lg,1rem)}@keyframes slideaway-left-8589d091{0%{display:block}to{opacity:0;transform:translateX(-40px)}}@keyframes slideaway-right-8589d091{0%{display:block}to{opacity:0;transform:translateX(40px)}}@keyframes enter-left-8589d091{0%{display:none;transform:translateX(-40px)}to{opacity:1}}@keyframes enter-right-8589d091{0%{display:none;transform:translateX(40px)}to{opacity:1}}.hide-left[data-v-8589d091]{animation:slideaway-left-8589d091 .2s;display:none}.enter-left[data-v-8589d091]{animation:enter-left-8589d091 .3s;border-right:none;display:block}.enter-right[data-v-8589d091]{animation:enter-right-8589d091 .3s;display:block}.hide-right[data-v-8589d091]{animation:slideaway-right-8589d091 .2s;display:none}.toc-container.enter-toc-container-left[data-v-8589d091]{transform:translateX(-85%)}.alert-section[data-v-8589d091]{padding-bottom:3rem}rh-alert[data-v-8589d091]{width:auto}@media (min-width:992px){#mobile-nav[data-v-8589d091],#toc-list-mobile[data-v-8589d091]{display:none}}@media (min-width:992px) and (max-width:1400px){.docs-ocp-content-container[data-v-8589d091]{padding:var(--rh-space-4xl,64px) var(--rh-space-lg,16px) 0}}@media (width < 992px){#breadcrumbs[data-v-8589d091],.content-format-selectors[data-v-8589d091],.toc-container[data-v-8589d091]{display:none}#mobile-nav-content-wrapper[data-v-8589d091]{border-bottom:1px solid #c7c7c7;border-top:1px solid #c7c7c7}#toc-wrapper-mobile[data-v-8589d091]{padding:var(--rh-space-md,1.5rem)}.product-container[data-v-8589d091]{padding:var(--rh-space-2xl,32px) var(--rh-space-lg,16px)}.product-container.shrink-product-padding[data-v-8589d091]{padding:var(--rh-space-lg,16px)}.product-version .version-select-dropdown[data-v-8589d091]{margin:0 var(--rh-space-lg,16px)}#page-content-options-mobile[data-v-8589d091]{padding:var(--rh-space-lg,2rem)}label[for=page-format][data-v-8589d091],label[for=toggle-focus-mode][data-v-8589d091]{display:block}.page-format-dropdown[data-v-8589d091]{background-position:97%;max-width:100%}nav#mobile-toc-menu[data-v-8589d091]{max-height:50vh;overflow-y:scroll}.mobile-jump-links #first-button[data-v-8589d091]{width:100%}#jump-links-btn[data-v-8589d091]{text-align:left;width:100%}#mobile-jump-links-content-wrapper[data-v-8589d091]{border-bottom:1px solid #c7c7c7;border-top:1px solid #c7c7c7;padding:0 var(--rh-space-lg,16px) var(--rh-space-2xl,32px)}.table-of-contents #browse-docs[data-v-8589d091]{margin-top:1rem;padding-top:var(--rh-space-md,1.5rem)}.mobile-nav[data-v-8589d091]{display:block}.hide-mobile-nav[data-v-8589d091],.mobile-nav[data-v-8589d091]{transition:transform .3s ease-in-out}.hide-mobile-nav[data-v-8589d091]{transform:translateY(-100%)}.docs-content-container[data-v-8589d091]{padding-left:1.25rem;padding-right:1.25rem;padding-top:var(--rh-space-xl,24px)}.banner-wrapper[data-v-8589d091]{padding:0 1rem}.toc-filter-mobile[data-v-8589d091]{align-items:center;display:flex;padding:var(--rh-space-lg,16px);width:100%}#text-input[data-v-8589d091]{padding-left:.5rem}.toc-filter[data-v-8589d091]{display:none}}@media (width <=576px){.content-format-selectors[data-v-8589d091]{display:none}}.informaltable[data-v-8589d091],.rhdocs .informaltable[data-v-8589d091],.rhdocs .table-contents[data-v-8589d091],.rhdocs .table-wrapper[data-v-8589d091],.table-contents[data-v-8589d091],.table-wrapper[data-v-8589d091]{max-height:var(--rh-table--maxHeight);overflow:auto}rh-table[data-v-8589d091]{display:block;margin:2rem 0;max-width:100%}.pvof-doc__wrapper[data-v-8589d091],.rhdocs[data-v-8589d091]{--rh-table--maxHeight:calc(100vh - 12.5rem)}</style>
<style>:is(rh-footer-block) a[data-v-97dd2752]{text-decoration:underline}</style>
<style>:is(rh-footer,:is(rh-footer-universal,rh-global-footer)) a{color:var(--rh-color-link-inline-on-dark,var(--rh-color-interactive-blue-lighter,#92c5f9));text-decoration:none}:is(rh-footer,:is(rh-footer-universal,rh-global-footer)) a:hover{color:var(--rh-color-link-inline-hover-on-dark,var(--rh-color-interactive-blue-lightest,#b9dafc));text-decoration:underline}:is(rh-footer,:is(rh-footer-universal,rh-global-footer)) a:is(:focus,:focus-within){color:var(--rh-color-link-inline-focus-on-dark,var(--rh-color-interactive-blue-lightest,#b9dafc));text-decoration:underline}:is(rh-footer,:is(rh-footer-universal,rh-global-footer)) a:visited{color:var(--rh-color-link-inline-visited-on-dark,var(--rh-color-interactive-blue-lightest,#b9dafc));text-decoration:none}:is(rh-footer,:is(rh-footer-universal,rh-global-footer)) a[slot^=logo]{display:block}:is(rh-footer) a[slot^=logo]>img{display:block;height:100%;height:var(--rh-size-icon-04,40px);width:auto}:is(rh-footer,rh-footer-universal,rh-global-footer) :is(h1,h2,h3,h4,h5,h6){font-family:var(--rh-font-family-heading,RedHatDisplay,"Red Hat Display","Noto Sans Arabic","Noto Sans Hebrew","Noto Sans JP","Noto Sans KR","Noto Sans Malayalam","Noto Sans SC","Noto Sans TC","Noto Sans Thai",Helvetica,Arial,sans-serif);line-height:var(--rh-line-height-heading,1.3)}rh-footer [slot=links]:is(h1,h2,h3,h4,h5):nth-of-type(n+5){--_link-header-margin:calc(var(--rh-space-2xl, 32px) - var(--rh-space-lg, 16px))}rh-footer [slot^=links] a{gap:var(--rh-footer-links-gap,var(--rh-space-md,8px))}:is(rh-footer,:is(rh-footer-universal,rh-global-footer)) [slot^=links] li{display:contents;margin:0;padding:0}:is(rh-footer,:is(rh-footer-universal,rh-global-footer)) [slot^=links] a{color:var(--rh-color-text-primary-on-dark,#fff)!important;display:block;font-size:var(--rh-footer-link-font-size,var(--rh-font-size-body-text-sm,.875rem));width:-moz-fit-content;width:fit-content}:is(rh-footer-universal,rh-global-footer) [slot^=links] a{font-size:inherit}:is(rh-footer,rh-footer-universal,rh-global-footer){--rh-footer-section-side-gap:var(--rh-space-lg,16px)}@media screen and (min-width:768px){:is(rh-footer,rh-footer-universal,rh-global-footer){--rh-footer-section-side-gap:var(--rh-space-2xl,32px)}}@media screen and (min-width:1440px){:is(rh-footer,rh-footer-universal,rh-global-footer){--rh-footer-section-side-gap:var(--rh-space-4xl,64px)}}rh-footer:not(:defined){background-color:var(--rh-color-surface-darker,#1f1f1f);display:grid;grid-template-areas:"footer" "global";grid-template-rows:1fr auto;min-height:var(--rh-footer-nojs-min-height,750px);width:100%}:is(rh-footer-universal,rh-global-footer):not(:defined):before{grid-area:global}rh-footer:not(:defined)>[slot=logo]{padding:var(--rh-space-2xl,32px) var(--_section-side-gap)}:is(rh-footer-universal,rh-global-footer):not(:defined)>*,rh-footer:not(:defined)>:not([slot=logo],:is(rh-footer-universal,rh-global-footer)){border:0;clip:rect(1px,1px,1px,1px);height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px}:is(rh-footer-universal,rh-global-footer):not(:defined){background-color:var(--rh-color-surface-darkest,#151515);display:block;min-height:176px;width:100%}rh-footer-universal rh-footer-copyright{grid-column:-1/1}</style>
<style>.status-legal .status-page-widget[data-v-5f538988]{display:block;margin:.5rem 0;width:11.3125rem;width:-moz-max-content;width:max-content}.status-page-widget[data-v-5f538988]{align-items:center;display:flex;flex-direction:row}.status-legal .status-page-widget .status-description[data-v-5f538988]{color:#ccc;font-weight:600;letter-spacing:.0125rem;line-height:1.5;margin-right:.5rem}.status-good[data-v-5f538988]{background-color:#3e8536}.status-critical[data-v-5f538988]{background-color:#a30100}.status-partial[data-v-5f538988]{background-color:#f5c12d}.status-maintentance[data-v-5f538988]{background-color:#316dc1}.status-minor[data-v-5f538988]{background-color:#b85c00}.status-description[data-v-5f538988]{color:#ccc;font-weight:500;letter-spacing:.2px;line-height:1.5}.current-status-indicator[data-v-5f538988]{border-radius:6px;display:inline-block;height:12px;margin:0 0 0 5px;width:12px}.current-status-indicator.small[data-v-5f538988]{border-radius:4px;display:inline-block;height:8px;margin:0 0 0 5px;width:8px}</style>
<style>.breadcrumbs[data-v-798f280c]{align-items:center;background-color:#f6f6f6;display:flex;gap:var(--rh-space-xl,24px);padding:var(--rh-space-lg,16px) var(--rh-space-2xl,32px)}nav[data-v-798f280c]{flex:1}ol[data-v-798f280c]{background-color:#f6f6f6;font-size:.875rem;list-style:none;margin:0;padding:0}li[data-v-798f280c]{color:#151515;display:inline}a[data-v-798f280c]:after{border-bottom-color:transparent;border-left-color:transparent;box-shadow:inset .25rem .25rem 0 .0625rem #8a8d8d;content:"";display:inline-block;height:1.07143em;margin:0 .5em;position:relative;right:0;top:.75em;transform:translateY(-.5em) rotate(135deg) scale(.5);width:1.07143em}</style>
<style>ol[data-v-fa0dae77]{margin:0;padding:0}li[data-v-fa0dae77],ol[data-v-fa0dae77],ul[data-v-fa0dae77]{list-style:none;margin:0}.chapter-title[data-v-fa0dae77]{font-size:1em}.sub-chapter-title[data-v-fa0dae77],.sub-chapter-title a[data-v-fa0dae77]{font-size:.875rem}#toc .link[data-v-fa0dae77],#toc-mobile .link[data-v-fa0dae77],.heading[data-v-fa0dae77],.sub-nav .link[data-v-fa0dae77],.sub-nav .link .link[data-v-fa0dae77]{display:block;padding:var(--rh-space-md,8px) var(--rh-space-2xl,32px);padding-right:2.5em;text-decoration:none;transition:background-color .25s}.heading[data-v-fa0dae77]:hover,.link[data-v-fa0dae77]:hover,.sub-nav .link[data-v-fa0dae77]:hover{background:var(--rh-color-surface-lighter,#f2f2f2);box-shadow:inset 3px 0 0 0 #d2d2d2;color:#151515}details[open]:first-of-type>.heading[data-v-fa0dae77]:after{transform:rotate(135deg)}.item[data-v-fa0dae77]{line-height:22px}#toc .link[data-v-fa0dae77],#toc-mobile .link[data-v-fa0dae77]{color:var(--rh-color-text-primary-on-light,#151515)}.sub-nav[data-v-fa0dae77],.toc-wrapper[data-v-fa0dae77]{list-style:none;margin:0}.toc-wrapper[data-v-fa0dae77]{min-width:100%;padding:0}.sub-nav[data-v-fa0dae77]{font-size:1em;line-height:24px;padding-left:1rem;padding-left:16px}.sub-nav .link[data-v-fa0dae77]:hover{color:#151515}.active[data-v-fa0dae77]{background:var(--rh-color-surface-lighter,#f2f2f2);box-shadow:inset 3px 0 0 0 var(--rh-color-icon-primary-on-light,#e00)}.chapter-landing-page[data-v-fa0dae77]{font-weight:500}summary[data-v-fa0dae77]{cursor:pointer;list-style:none;position:relative}summary[data-v-fa0dae77]::-webkit-details-marker{display:none}@keyframes slideDown-fa0dae77{0%{height:0;opacity:0}to{height:var(--details-height-open,"100%");opacity:1}}html[data-v-fa0dae77]{--details-transition-time:400ms}details[data-v-fa0dae77]{max-height:var(--details-height-closed,auto);transition:all ease-out var(--details-transition-time,0)}details[open][data-v-fa0dae77]{max-height:var(--details-height-open,auto)}details .heading.sub-chapter-title[data-v-fa0dae77]:after,details .heading[data-v-fa0dae77]:after{border-right:3px solid #151515;border-top:3px solid #151515;color:#151515;content:"";display:flex;float:right;height:9px;margin-left:16px;position:absolute;right:var(--rh-space-xl,24px);top:14px;transform:rotate(45deg);width:9px}details .heading.sub-chapter-title[data-v-fa0dae77]:after{height:8px;width:8px}</style>
<style>.item[data-v-b883c74f]{line-height:22px}#toc .link[data-v-b883c74f],#toc-mobile .link[data-v-b883c74f]{color:var(--rh-color-text-primary-on-light,#151515)}#toc .link[data-v-b883c74f],#toc-mobile .link[data-v-b883c74f],.heading[data-v-b883c74f],.sub-nav .link[data-v-b883c74f],.sub-nav .link .link[data-v-b883c74f]{display:block;padding:var(--rh-space-md,8px) var(--rh-space-2xl,32px);padding-right:2.5em;text-decoration:none;transition:background-color .25s}.heading[data-v-b883c74f]:hover,.link[data-v-b883c74f]:hover,.sub-nav .link[data-v-b883c74f]:hover{background:var(--rh-color-surface-lighter,#f2f2f2);box-shadow:inset 3px 0 0 0 #d2d2d2;color:#151515}ol[data-v-b883c74f]{margin:0;padding:0}li[data-v-b883c74f],ol[data-v-b883c74f],ul[data-v-b883c74f]{list-style:none;margin:0}.chapter-title[data-v-b883c74f]{font-size:1em}.sub-nav[data-v-b883c74f]{font-size:1em;line-height:24px;list-style:none;margin:0;padding-left:1rem;padding-left:16px}.sub-nav .link[data-v-b883c74f]:hover{color:#151515}.active[data-v-b883c74f]{background:var(--rh-color-surface-lighter,#f2f2f2);box-shadow:inset 3px 0 0 0 var(--rh-color-icon-primary-on-light,#e00)}.sub-chapter-title[data-v-b883c74f],.sub-chapter-title a[data-v-b883c74f]{font-size:.875rem}summary[data-v-b883c74f]{cursor:pointer;list-style:none;position:relative}summary[data-v-b883c74f]::-webkit-details-marker{display:none}html[data-v-b883c74f]{--details-transition-time:400ms}.chapter-landing-page[data-v-b883c74f]{font-weight:500}details[open]:first-of-type>.heading[data-v-b883c74f]:after{transform:rotate(135deg)}details[data-v-b883c74f]{max-height:var(--details-height-closed,auto);transition:all ease-out var(--details-transition-time,0)}details[open][data-v-b883c74f]{max-height:var(--details-height-open,auto)}details .heading.sub-chapter-title[data-v-b883c74f]:after,details .heading[data-v-b883c74f]:after{border-right:3px solid #151515;border-top:3px solid #151515;color:#151515;content:"";display:flex;float:right;height:9px;margin-left:16px;position:absolute;right:var(--rh-space-xl,24px);top:14px;transform:rotate(45deg);width:9px}details .heading.sub-chapter-title[data-v-b883c74f]:after{height:8px;width:8px}</style>
<style>.html-container[data-v-9c2a9ddb]{padding:2rem 1.5rem 0}rh-alert[data-v-9c2a9ddb]{color:#151515}@media (max-width:772px){.html-container[data-v-9c2a9ddb]{padding:3rem 1rem 0}}</style>
<style>.search-container[data-v-69710f44]{height:100%}.form-box[data-v-69710f44],.search-container[data-v-69710f44]{justify-content:center}.form-box[data-v-69710f44],.search-box[data-v-69710f44],.search-container[data-v-69710f44]{align-items:center;display:flex;width:100%}.search-box[data-v-69710f44]{justify-content:space-between;position:relative}ul[data-v-69710f44]{list-style-type:none}#search-list[data-v-69710f44]{background:#fff;border:1px solid #f0f0f0;box-shadow:0 4px 4px 0 #00000040;color:#151515;display:block;left:0;margin:0;padding:0;position:absolute;top:37px;width:100%;z-index:200}#search-list li[data-v-69710f44]{align-items:center;display:flex;justify-content:space-between;padding:.75rem}#search-list .active[data-v-69710f44],#search-list li[data-v-69710f44]:hover{background:#f0f0f0}.group-title[data-v-69710f44]{border-top:1px solid #4d4d4d;color:#4d4d4d;cursor:default;font-size:12px;font-weight:400;pointer-events:none}.group-title[data-v-69710f44],.group-title[data-v-69710f44]:hover{background:#fff}.search-item-text-elipsis[data-v-69710f44]{display:inline-block;max-width:48%;overflow:hidden;text-overflow:ellipsis;white-space:nowrap}.search-item-text[data-v-69710f44]{padding-left:1.75rem}.search-item-chip[data-v-69710f44]{float:right}.search-product-version[data-v-69710f44]{background:#fff;border:1px solid #f0f0f0;border-radius:3px;font-size:1rem;font-weight:400;line-height:24px}.search-icon-form[data-v-69710f44]{color:var(--rh-color-gray-50,#707070);left:12px;position:absolute}.input-search-box[data-v-69710f44]{-webkit-appearance:none;-moz-appearance:none;appearance:none;border:0;font-family:var(--rh-font-family-body-text,"Red Hat Text","RedHatText",Arial,sans-serif);font-size:var(--rh-font-size-body-text-md,1rem);height:36px;padding:0 40px;width:100%}.input-clear-btn[data-v-69710f44]{align-items:center;background-color:transparent;border:none;display:flex;height:36px;justify-content:center;margin-right:-30px;outline:none;transform:translateX(-30px)}.input-clear-btn[data-v-69710f44]:focus{border:1px solid var(--rh-color-accent-base-on-light,#06c)}.input-clear-btn:focus .input-clear-icon[data-v-69710f44]{color:var(--rh-color-canvas-black,#151515)}.input-clear-icon[data-v-69710f44]{color:#6b6e72;cursor:pointer}.input-clear-icon[data-v-69710f44]:hover{color:var(--rh-color-canvas-black,#151515)}.form-submit-btn[data-v-69710f44]::part(button){align-items:center;background-color:var(--rh-color-gray-20,#e0e0e0);border-radius:0;display:flex;height:36px;justify-content:center;--_default-border-color:var(--rh-color-gray-20,#e0e0e0)}.input-close-btn[data-v-69710f44]{background:none;border:none;cursor:pointer;margin:0 var(--rh-space-lg,16px)}.input-close-icon[data-v-69710f44]{color:var(--rh-color-white,#fff)}@media (max-width:992px){.form-box[data-v-69710f44]{gap:var(--rh-space-md,8px);margin:auto;width:100%}.input-search-box[data-v-69710f44]{border:1px solid var(--rh-color-gray-30,#c7c7c7)}.input-search-box[data-v-69710f44]::-moz-placeholder{color:#6a6e73;font-family:var(--rh-font-family-body-text,"Red Hat Text","RedHatText",Arial,sans-serif);font-size:var(--rh-font-size-body-text-md,1rem);font-weight:var(--rh-font-weight-code-regular,400);line-height:24px}.input-search-box[data-v-69710f44]::placeholder{color:#6a6e73;font-family:var(--rh-font-family-body-text,"Red Hat Text","RedHatText",Arial,sans-serif);font-size:var(--rh-font-size-body-text-md,1rem);font-weight:var(--rh-font-weight-code-regular,400);line-height:24px}.search-item-text-elipsis[data-v-69710f44]{max-width:60%}}@media (max-width:767px){.input-close-btn[data-v-69710f44]{display:none}.search-container[data-v-69710f44]{border:1px solid #f0f0f0}}</style>
<link rel="stylesheet" href="/_nuxt/entry.DNAluCmw.css" integrity="sha384-FnrZajt9k3u4tri3ClqikI96k+jP7kyrvgKKgdzBr5Y8CQEi3gusKE0+eMSLvGxm">
<link rel="stylesheet" href="/_nuxt/SearchAutocomplete.DkrJaF8R.css" integrity="sha384-Zw8gf6w7SrpWDmknvrab5QanIN+DSJRS/bPB9/lgDkhR7JhDmG/VF++MTMKU8mKB">
<link rel="stylesheet" href="/_nuxt/Breadcrumbs.BLkLxUMB.css" integrity="sha384-f6iEfCywVoZB0/hIKTRaxywtS21KzhBx2JOI/uVjjU9aqFcP7X9cqLH29w2HQvLe">
<link rel="stylesheet" href="/_nuxt/Alert.fTkXFs3h.css" integrity="sha384-yFMpT5E64LAQi3qJ10AJJ1oOH3DrI68OvLSjSivjNCQXZ25pmFxlPavPQ0TEyEpq">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/C3PvZR0C.js" integrity="sha384-H9Can2ny34kmIBk2SNFJRaBH6FotFjI6LVF8tQ4HqJnqY0a1tGDF/4RHxK2LFs7c">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/Ds9UYxCD.js" integrity="sha384-PFyBx6Pvk48yXM+prD4CDErW/3HFtPEqORVyAch5qDvJSyubA93+vR4jsWGRQKZs">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/BUXK7nH-.js" integrity="sha384-Kqf3r1QrD7+NOn9EuK/ba9sTBZjn7vLAjnCoRtq7IKz+QV0JUUBFf1Snf1yVkkgr">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/BxBriHwM.js" integrity="sha384-bejD6BN5N1iVRo5Ymn+LdVN0jvrnJTzgqgFD9xQ5+Yi46U6ff+s5W2AISzRWvJaM">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/DB5Lt3x5.js" integrity="sha384-Ae/gV/4Dt4jnJApC0CWbckKJ7omq+W9Hb4jjdMyhxGJpwk6FlO7pGYMD3bPO/h1y">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/D8BFaW0S.js" integrity="sha384-/m09v/yYk14L9Hra6/9jYtMTn2IdkKQvzpFPRQ5P/baRKwdZQN98873hqvwuYXFS">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/_58Q44fW.js" integrity="sha384-EdSd8jpnetO/BWDAc8C4SpQExZ7pYjMygNPvbLmiA1TaYsNUdVOqIIyOIzaErEeU">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/DOCUiUcq.js" integrity="sha384-9H868K5q7MLzC8TSRXT3pVqDzsOVxZLYvUQ8cLGpHPZCFEyEJjnwSHE+/7FWrJPV">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/CiTVMRA7.js" integrity="sha384-xBIJ2xO0t62/oREKqSxPtW1tRxKY+5YYXbGcJ0QR9IRM28JhL+53NOiAvVFn3rmF">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/CR3F0y4K.js">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/Bn-QuJwp.js">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/T_zvNmZe.js">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/Ciddaed-.js">
<link rel="prefetch" as="image" type="image/svg+xml" href="/_nuxt/Footer_Cloud.DpSdW8MR.svg">
<script type="module">
      import "@rhds/elements/rh-cta/rh-cta.js";
      </script>
<script type="module">
      import '@rhds/elements/rh-alert/rh-alert.js';
      </script>
<script type="module">
        import "/scripts/v1/@cpelements/pfe-navigation/dist/pfe-navigation.min.js";
        import "/scripts/v1/@rhds/elements/elements/rh-button/rh-button.js";
      </script>
<script type="module">import "@rhds/elements/rh-footer/rh-footer.js"</script>
<link rel="canonical" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html-single/managing_file_systems/index">
<script type="module">
      import "@rhds/elements/rh-alert/rh-alert.js";
      import "@rhds/elements/rh-code-block/rh-code-block.js";
      import '@rhds/elements/rh-cta/rh-cta.js';
      import '@patternfly/elements/pf-switch/pf-switch.js';
      import '@cpelements/rh-table/dist/rh-table.js';
      import '@patternfly/pfe-clipboard/dist/pfe-clipboard.min.js';
      import '@patternfly/elements/pf-button/pf-button.js';
      import '@patternfly/elements/pf-modal/pf-modal.js';
      import '@patternfly/elements/pf-icon/pf-icon.js';
      import '@patternfly/elements/pf-popover/pf-popover.js';
      import '@patternfly/elements/pf-tooltip/pf-tooltip.js';
      import '@rhds/elements/rh-badge/rh-badge.js';
      </script>
<meta name="description" content="Managing file systems | Red Hat Documentation">
<meta name="app-version" content="v0.0.1">
<script type="module">
        import "/scripts/v1/@rhds/elements/elements/rh-button/rh-button.js";
      </script>
<script type="module">
      import '@rhds/elements/rh-alert/rh-alert.js';
      </script>
<script type="module">
        import "/scripts/v1/@rhds/elements/elements/rh-button/rh-button.js";
        import "@patternfly/elements/pf-badge/pf-badge.js";
      </script>
<script type="module" src="/_nuxt/C3PvZR0C.js" crossorigin integrity="sha384-H9Can2ny34kmIBk2SNFJRaBH6FotFjI6LVF8tQ4HqJnqY0a1tGDF/4RHxK2LFs7c"></script></head><body><div id="__nuxt"><!--[--><!--[--><!----><header data-v-edc0d12c><a href="#pfe-navigation" id="global-skip-to-nav" class="skip-link visually-hidden" data-v-edc0d12c>Skip to navigation</a><a href="#main-content" class="skip-link visually-hidden" data-v-edc0d12c>Skip to content</a><nav id="upper-navigation" class="upper-navigation" aria-labelledby="upper-navigation-label" data-analytics-region="upper-navigation" data-v-edc0d12c><p id="upper-navigation-label" class="upper-nav-hidden" data-v-edc0d12c>Featured links</p><div class="upper-nav-container" data-v-edc0d12c><ul class="upper-nav-menu" data-v-edc0d12c><li data-v-edc0d12c><a href="https://access.redhat.com/" class="upper-nav-links" data-analytics-text="Support" data-analytics-category="Featured Links" data-v-edc0d12c>Support</a></li><li data-v-edc0d12c><a href="https://console.redhat.com/" class="upper-nav-links" data-analytics-text="Console" data-analytics-category="Featured Links" data-v-edc0d12c>Console</a></li><li data-v-edc0d12c><a href="https://developers.redhat.com/" class="upper-nav-links" data-analytics-text="Developers" data-analytics-category="Featured Links" data-v-edc0d12c>Developers</a></li><li data-v-edc0d12c><a href="https://www.redhat.com/en/products/trials" class="upper-nav-links" data-analytics-text="Start a trial" data-analytics-category="Featured Links" data-v-edc0d12c>Start a trial</a></li><li data-v-edc0d12c><button id="all-red-hat" class="upper-nav-links" data-analytics-text="All Red Hat" data-analytics-category="Featured Links" aria-expanded="false" data-analytics-linktype="tab" data-v-edc0d12c>All Red Hat<svg class="upper-nav-arrow" xmlns="http://www.w3.org/2000/svg" width="1024" height="1024" viewBox="0 0 1024 1024" aria-hidden="true" data-v-edc0d12c=""><path d="M810.642 511.557c0 8.905-3.447 16.776-10.284 23.613L322.31 1013.216c-6.835 6.837-14.706 10.284-23.61 10.284s-16.776-3.447-23.613-10.284l-51.303-51.303c-6.837-6.837-10.284-14.707-10.284-23.612s3.447-16.775 10.284-23.61L626.972 511.5 223.784 108.31c-6.837-6.835-10.284-14.706-10.284-23.61s3.447-16.776 10.284-23.613l51.303-51.303C281.924 2.947 289.794-.5 298.7-.5s16.775 3.447 23.61 10.284L800.36 487.83c6.837 6.837 10.284 14.708 10.284 23.613v.114" data-v-edc0d12c=""/></svg></button><div class="upper-nav-dropdown-container" data-v-edc0d12c><ul data-v-edc0d12c><li data-v-edc0d12c><span data-v-edc0d12c>For customers</span><ul data-v-edc0d12c><li data-v-edc0d12c><a href="https://access.redhat.com/support" data-pzn-audience="customers" data-analytics-category="All Red Hat|For customers" data-analytics-text="Customer support" data-v-edc0d12c>Customer support</a></li><li data-v-edc0d12c><a href="/products" data-pzn-audience="customers" data-analytics-category="All Red Hat|For customers" data-analytics-text="Documentation" data-v-edc0d12c>Documentation</a></li><li data-v-edc0d12c><a href="https://access.redhat.com/support/cases" data-pzn-audience="customers" data-analytics-category="All Red Hat|For customers" data-analytics-text="Support cases" data-v-edc0d12c>Support Cases</a></li><li data-v-edc0d12c><a href="https://access.redhat.com/management" data-pzn-audience="customers" data-analytics-category="All Red Hat|For customers" data-analytics-text="Subscription management" data-v-edc0d12c>Subscription management</a></li><li data-v-edc0d12c><a href="https://catalog.redhat.com/" data-analytics-category="All Red Hat|For customers" data-analytics-text="Red Hat Ecosystem Catalog" data-v-edc0d12c>Red Hat Ecosystem Catalog</a></li><li data-v-edc0d12c><a href="https://catalog.redhat.com/partners" data-analytics-category="All Red Hat|For customers" data-analytics-text="Find a partner" data-v-edc0d12c>Find a partner</a></li></ul></li><li data-v-edc0d12c><span data-v-edc0d12c>For partners</span><ul data-v-edc0d12c><li data-v-edc0d12c><a href="https://connect.redhat.com/login" data-pzn-audience="partners" data-analytics-category="All Red Hat|For partners" data-analytics-text="Partner login" data-v-edc0d12c>Partner login</a></li><li data-v-edc0d12c><a href="https://connect.redhat.com/en/support" data-pzn-audience="partners" data-analytics-category="All Red Hat|For partners" data-analytics-text="Partner support" data-v-edc0d12c>Partner support</a></li><li data-v-edc0d12c><a href="https://connect.redhat.com/" data-pzn-audience="partners" data-analytics-category="All Red Hat|For partners" data-analytics-text="Become a partner " data-v-edc0d12c>Become a partner</a></li></ul></li><li data-v-edc0d12c><span data-v-edc0d12c>Try, buy, &amp; sell</span><ul data-v-edc0d12c><li data-v-edc0d12c><a href="https://marketplace.redhat.com/en-us" data-analytics-category="All Red Hat|Try, buy, &amp; sell" data-analytics-text="Red Hat Marketplace" data-v-edc0d12c>Red Hat Marketplace</a></li><li data-v-edc0d12c><a href="https://www.redhat.com/en/store" data-analytics-category="All Red Hat|Try, buy, &amp; sell" data-analytics-text="Red Hat Store" data-v-edc0d12c>Red Hat Store</a></li><li data-v-edc0d12c><a href="https://www.redhat.com/en/contact" data-analytics-category="All Red Hat|Try, buy, &amp; sell" data-analytics-text="Contact sales" data-v-edc0d12c>Contact Sales</a></li><li data-v-edc0d12c><a href="https://www.redhat.com/en/products/trials" data-analytics-category="All Red Hat|Try, buy, &amp; sell" data-analytics-text="Start a trial" data-v-edc0d12c>Start a trial</a></li></ul></li><li data-v-edc0d12c><span data-v-edc0d12c>Learning resources</span><ul data-v-edc0d12c><li data-v-edc0d12c><a href="https://www.redhat.com/en/services/training-and-certification" data-analytics-category="All Red Hat|Learning resources" data-analytics-text="Training and certification " data-v-edc0d12c>Training and certification</a></li><li data-v-edc0d12c><a href="https://developers.redhat.com/" data-pzn-audience="developers|community" data-analytics-category="All Red Hat|Learning resources" data-analytics-text="For developers" data-v-edc0d12c>For developers</a></li><li data-v-edc0d12c><a href="https://cloud.redhat.com/learn" data-analytics-category="All Red Hat|Learning resources" data-analytics-text="Hybrid cloud learning hub" data-v-edc0d12c>Hybrid cloud learning hub</a></li><li data-v-edc0d12c><a href="https://www.redhat.com/en/interactive-labs" data-analytics-category="All Red Hat|Learning resources" data-analytics-text="Interactive labs" data-v-edc0d12c>Interactive labs</a></li><li data-v-edc0d12c><a href="https://learn.redhat.com/" data-analytics-category="All Red Hat|Learning resources" data-analytics-text="Learning community" data-v-edc0d12c>Learning community</a></li><li data-v-edc0d12c><a href="https://www.redhat.com/en/tv" data-analytics-category="All Red Hat|Learning resources" data-analytics-text="Red Hat TV" data-v-edc0d12c>Red Hat TV</a></li></ul></li><li data-v-edc0d12c><span data-v-edc0d12c>Open source communities</span><ul data-v-edc0d12c><li data-v-edc0d12c><a href="https://www.ansible.com/community" data-analytics-category="All Red Hat|Open source communities" data-analytics-text="Ansible" data-v-edc0d12c>Ansible</a></li><li data-v-edc0d12c><a href="https://www.redhat.com/sysadmin/" id="community" data-analytics-category="All Red Hat|Open source communities" data-analytics-text="For system administrators" data-v-edc0d12c>For system administrators</a></li><li data-v-edc0d12c><a href="https://www.redhat.com/architect/" data-pzn-audience="community" data-analytics-category="All Red Hat|Open source communities" data-analytics-text="For architects" data-v-edc0d12c>For architects</a></li></ul></li></ul></div></li></ul></div></nav><pfe-navigation full-width id="pfe-navigation" pf-sticky="true" lang="en" data-v-edc0d12c><nav class="pfe-navigation" aria-label="Main Navigation" data-v-edc0d12c><div class="pfe-navigation__logo-wrapper" id="pfe-navigation__logo-wrapper" data-v-edc0d12c><a href="/en" class="pfe-navigation__logo-link" data-v-edc0d12c><img class="pfe-navigation__logo-image pfe-navigation__logo-image--screen pfe-navigation__logo-image--small" src="/Logo-Red_Hat-Documentation-A-Reverse-RGB.svg" width="240" height="40" alt="Red Hat Documentation" data-v-edc0d12c></a></div></nav><span data-v-edc0d12c></span><div slot="secondary-links" data-v-edc0d12c><div class="hidden-at-desktop hidden-at-tablet search-mobile" data-v-edc0d12c><div id="search-form" class="search-container" opensearchbox="true" data-v-edc0d12c data-v-69710f44><form role="search" class="form-box" autocomplete="off" data-v-69710f44><div class="search-box" data-v-69710f44><pf-icon icon="search" size="md" class="search-icon-form" data-v-69710f44></pf-icon><input type="text" id="input-search" class="input-search-box" placeholder="Search documentation" value aria-autocomplete="list" data-v-69710f44><!----><!----><!----><rh-button disabled variant="tertiary" class="form-submit-btn" data-v-69710f44><img src="data:image/svg+xml,%3csvg%20width=&#39;14&#39;%20height=&#39;14&#39;%20viewBox=&#39;0%200%2014%2014&#39;%20fill=&#39;none&#39;%20xmlns=&#39;http://www.w3.org/2000/svg&#39;%3e%3cpath%20d=&#39;M7%200L5.6%201.4L10.3%206H0V8H10.3L5.6%2012.6L7%2014L14%207L7%200Z&#39;%20fill=&#39;%23707070&#39;/%3e%3c/svg%3e" alt="Submit button" data-v-69710f44></rh-button></div></form><!----></div></div><div class="hidden-at-desktop hidden-at-tablet buttons" data-v-edc0d12c><a href="https://access.redhat.com/" data-analytics-category="More Red Hat" data-analytics-text="Support" data-v-edc0d12c>Support</a><a href="https://console.redhat.com/" data-analytics-category="More Red Hat" data-analytics-text="Console" data-v-edc0d12c>Console</a><a href="https://developers.redhat.com/" data-analytics-category="More Red Hat" data-analytics-text="Developers" data-v-edc0d12c>Developers</a><a href="https://www.redhat.com/en/products/trials" data-analytics-category="More Red Hat" data-analytics-text="Start a trial" data-v-edc0d12c>Start a trial</a><a href="https://www.redhat.com/en/contact" data-analytics-category="More Red Hat" data-analytics-text="Contact" data-v-edc0d12c>Contact</a></div><div class="hidden-at-desktop hidden-at-tablet mobile-lang-select" data-v-edc0d12c><label for="lang_selection" data-v-edc0d12c>Select your language</label><select id="lang_selection" data-v-edc0d12c><!--[--><option value="en" xml:lang="en" hreflang="en" data-v-edc0d12c>English</option><option value="fr" xml:lang="fr" hreflang="fr" data-v-edc0d12c>Français</option><option value="ko" xml:lang="ko" hreflang="ko" data-v-edc0d12c>한국어</option><option value="ja" xml:lang="ja" hreflang="ja" data-v-edc0d12c>日本語</option><option value="zh-cn" xml:lang="zh-cn" hreflang="zh-cn" data-v-edc0d12c>中文 (中国)</option><option value="de" xml:lang="de" hreflang="de" data-v-edc0d12c>Deutsch</option><option value="it" xml:lang="it" hreflang="it" data-v-edc0d12c>Italiano</option><option value="pt-br" xml:lang="pt-br" hreflang="pt-br" data-v-edc0d12c>Português</option><option value="es" xml:lang="es" hreflang="es" data-v-edc0d12c>Español</option><!--]--></select></div></div></pfe-navigation></header><main id="main-content"><!--[--><!--[--><!--[--><!----><!----><!--]--><div class="breadcrumbs" id="breadcrumbs" data-v-8589d091 data-v-798f280c><nav aria-label="Breadcrumb" class="breadcrumb" data-v-798f280c><ol data-v-798f280c><li data-v-798f280c><a href="/" data-v-798f280c>Home</a></li><li data-v-798f280c><a href="/en/products" data-v-798f280c>Products</a></li><!--[--><li data-v-798f280c><a href="/en/documentation/red_hat_enterprise_linux/" data-v-798f280c>Red Hat Enterprise Linux</a></li><li data-v-798f280c><a href="/en/documentation/red_hat_enterprise_linux/9/" data-v-798f280c>9</a></li><li data-v-798f280c><!--[-->Managing file systems<!--]--></li><!--]--></ol></nav><span data-v-798f280c></span></div><!----><nav id="mobile-nav" class="mobile-nav" aria-label="mobile menu" data-v-8589d091><div class="mobile-nav-wrapper" data-v-8589d091><div id="first-button" data-v-8589d091><button id="toc-btn" aria-expanded="false" aria-controls="mobile-nav-content-wrapper" class="mobile-nav-btn" data-v-8589d091><span class="sr-only" data-v-8589d091>Open </span>Table of contents</button></div><div id="second-button" data-v-8589d091><button id="settings-btn" aria-expanded="false" aria-controls="mobile-nav-content-wrapper" class="mobile-nav-btn" data-v-8589d091><pf-icon icon="cog" size="md" data-v-8589d091></pf-icon><span class="sr-only" data-v-8589d091>Open page settings</span></button></div></div><div id="mobile-nav-content-wrapper" class="hidden" role="navigation" tabindex="0" data-v-8589d091><div id="toc-mobile" class="hidden" aria-labelledby="toc-btn" data-v-8589d091><div class="shrink-product-padding product-container" id="product-container-mobile" data-v-8589d091><h1 class="product-title" data-v-8589d091>Red Hat Enterprise Linux</h1><!----></div><div class="toc-filter-mobile" data-v-8589d091><span id="text" part="text" data-v-8589d091><input id="text-input" aria-label="Search input" part="text-input" placeholder="Filter table of contents" type="text" class value data-v-8589d091><!----></span></div><div id="toc-wrapper-mobile" class="span-xs-12 span-sm-4 span-md-3" lang="en" data-v-8589d091><nav id="mobile-toc-menu" class="table-of-contents" aria-label="table of content - mobile" data-v-8589d091><!----></nav></div><!----></div><div id="page-content-options-mobile" class="hidden" aria-labelledby="settings-btn" data-v-8589d091><div class="page-layout-options" data-v-8589d091><label for="page-format-mobile" data-v-8589d091>Format</label><select id="page-format-mobile" class="page-format-dropdown" data-v-8589d091><option class="page-type" value="html" data-v-8589d091>Multi-page</option><option selected class="page-type" value="html-single" data-v-8589d091>Single-page</option><option class="page-type" value="pdf" data-v-8589d091>View full doc as PDF</option></select></div></div></div><!----><!----></nav><div class="grid grid-col-12 content-wrapper" data-v-8589d091><aside id="left-content" class="span-xs-12 span-sm-4 span-md-3" lang="en-us" aria-label="left navigation" xml:lang="en-us" data-v-8589d091><div class="toc-container" id="toc-container" visible="true" data-v-8589d091><div class="toc-focus-container" id="toc-focus-container" data-v-8589d091><button class="toc-focus-btn" aria-label="toggle left menu" aria-controls="toc-container" aria-expanded="true" data-v-8589d091><pf-icon size="md" icon="angle-left" class="toc-focus-btn-icon" data-v-8589d091></pf-icon></button></div><div class="product-container" id="product-container-desktop" data-v-8589d091><h1 class="product-title" data-v-8589d091>Red Hat Enterprise Linux</h1><!----></div><div class="toc-filter" id="toc-filter" data-v-8589d091><span id="text" part="text" data-v-8589d091><span id="search-icon" part="search-icon" data-v-8589d091><pf-icon icon="filter" size="md" data-v-8589d091></pf-icon></span><input id="text-input" aria-label="Search input" part="text-input" placeholder="Filter table of contents" type="text" class value data-v-8589d091><!----></span></div><div id="toc-wrapper" class="toc-wrapper" data-v-8589d091><nav id="toc" class="max-height-85 table-of-contents" aria-label="Table of contents" data-v-8589d091><ol id="toc-list" data-v-8589d091><!--[--><li class="item chapter" data-v-fa0dae77><a class="link active" href id="chapter-index" data-v-fa0dae77>Managing file systems</a></li><li class="item chapter" data-v-fa0dae77><a class="link" href="#proc_providing-feedback-on-red-hat-documentation_managing-file-systems" id="chapter-landing--managing_file_systems-proc_providing-feedback-on-red-hat-documentation_managing-file-systems" data-v-fa0dae77>Providing feedback on Red Hat documentation</a></li><li class="item chapter" data-v-fa0dae77><details id="toc--overview-of-available-file-systems_managing-file-systems" data-v-fa0dae77><summary class="heading chapter-title" id="overview-of-available-file-systems_managing-file-systems--summary" data-v-fa0dae77>1. Overview of available file systems</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#overview-of-available-file-systems_managing-file-systems" id="chapter-landing--managing_file_systems-overview-of-available-file-systems_managing-file-systems" data-v-fa0dae77>Overview of available file systems</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#types-of-file-systems_overview-of-available-file-systems" id="sub-link-to-managing_file_systems-types-of-file-systems_overview-of-available-file-systems" data-v-b883c74f>1.1. Types of file systems</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#local-file-systems_overview-of-available-file-systems" id="sub-link-to-managing_file_systems-local-file-systems_overview-of-available-file-systems" data-v-b883c74f>1.2. Local file systems</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#the-xfs-file-system_overview-of-available-file-systems" id="sub-link-to-managing_file_systems-the-xfs-file-system_overview-of-available-file-systems" data-v-b883c74f>1.3. The XFS file system</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#the-ext4-file-system_overview-of-available-file-systems" id="sub-link-to-managing_file_systems-the-ext4-file-system_overview-of-available-file-systems" data-v-b883c74f>1.4. The ext4 file system</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#comparison-of-xfs-and-ext4_overview-of-available-file-systems" id="sub-link-to-managing_file_systems-comparison-of-xfs-and-ext4_overview-of-available-file-systems" data-v-b883c74f>1.5. Comparison of XFS and ext4</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#choosing-a-local-file-system_overview-of-available-file-systems" id="sub-link-to-managing_file_systems-choosing-a-local-file-system_overview-of-available-file-systems" data-v-b883c74f>1.6. Choosing a local file system</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#network-file-systems_overview-of-available-file-systems" id="sub-link-to-managing_file_systems-network-file-systems_overview-of-available-file-systems" data-v-b883c74f>1.7. Network file systems</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#shared-storage-file-systems_overview-of-available-file-systems" id="sub-link-to-managing_file_systems-shared-storage-file-systems_overview-of-available-file-systems" data-v-b883c74f>1.8. Shared storage file systems</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#choosing-between-network-and-shared-storage-file-systems_overview-of-available-file-systems" id="sub-link-to-managing_file_systems-choosing-between-network-and-shared-storage-file-systems_overview-of-available-file-systems" data-v-b883c74f>1.9. Choosing between network and shared storage file systems</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#volume-managing-file-systems_overview-of-available-file-systems" id="sub-link-to-managing_file_systems-volume-managing-file-systems_overview-of-available-file-systems" data-v-b883c74f>1.10. Volume-managing file systems</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--managing-local-storage-using-rhel-system-roles_managing-file-systems" data-v-fa0dae77><summary class="heading chapter-title" id="managing-local-storage-using-rhel-system-roles_managing-file-systems--summary" data-v-fa0dae77>2. Managing local storage by using the RHEL system role</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#managing-local-storage-using-rhel-system-roles_managing-file-systems" id="chapter-landing--managing_file_systems-managing-local-storage-using-rhel-system-roles_managing-file-systems" data-v-fa0dae77>Managing local storage by using the RHEL system role</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#storage-role-intro_managing-local-storage-using-rhel-system-roles" id="sub-link-to-managing_file_systems-storage-role-intro_managing-local-storage-using-rhel-system-roles" data-v-b883c74f>2.1. Introduction to the storage RHEL system role</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#an-example-ansible-playbook-to-create-an-xfs-file-system_managing-local-storage-using-rhel-system-roles" id="sub-link-to-managing_file_systems-an-example-ansible-playbook-to-create-an-xfs-file-system_managing-local-storage-using-rhel-system-roles" data-v-b883c74f>2.2. Creating an XFS file system on a block device by using the storage RHEL system role</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#an-example-ansible-playbook-to-persistently-mount-a-file-system_managing-local-storage-using-rhel-system-roles" id="sub-link-to-managing_file_systems-an-example-ansible-playbook-to-persistently-mount-a-file-system_managing-local-storage-using-rhel-system-roles" data-v-b883c74f>2.3. Persistently mounting a file system by using the storage RHEL system role</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#an-example-playbook-to-manage-logical-volumes_managing-local-storage-using-rhel-system-roles" id="sub-link-to-managing_file_systems-an-example-playbook-to-manage-logical-volumes_managing-local-storage-using-rhel-system-roles" data-v-b883c74f>2.4. Managing logical volumes by using the storage RHEL system role</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#an-example-ansible-playbook-to-enable-online-block-discard_managing-local-storage-using-rhel-system-roles" id="sub-link-to-managing_file_systems-an-example-ansible-playbook-to-enable-online-block-discard_managing-local-storage-using-rhel-system-roles" data-v-b883c74f>2.5. Enabling online block discard by using the storage RHEL system role</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#an-example-playbook-to-create-mount-an-ext4-file-system_managing-local-storage-using-rhel-system-roles" id="sub-link-to-managing_file_systems-an-example-playbook-to-create-mount-an-ext4-file-system_managing-local-storage-using-rhel-system-roles" data-v-b883c74f>2.6. Creating and mounting an Ext4 file system by using the storage RHEL system role</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#an-example-ansible-playbook-to-create-mount-ext3-file-system_managing-local-storage-using-rhel-system-roles" id="sub-link-to-managing_file_systems-an-example-ansible-playbook-to-create-mount-ext3-file-system_managing-local-storage-using-rhel-system-roles" data-v-b883c74f>2.7. Creating and mounting an Ext3 file system by using the storage RHEL system role</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#example-ansible-playbook-to-resize-an-existing-lvm-file-system-using-the-storage-rhel-system-role_managing-local-storage-using-rhel-system-roles" id="sub-link-to-managing_file_systems-example-ansible-playbook-to-resize-an-existing-lvm-file-system-using-the-storage-rhel-system-role_managing-local-storage-using-rhel-system-roles" data-v-b883c74f>2.8. Resizing an existing file system on LVM by using the storage RHEL system role</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#example-ansible-playbook-to-create-a-swap-partition-using-the-storage-rhel-system-role_managing-local-storage-using-rhel-system-roles" id="sub-link-to-managing_file_systems-example-ansible-playbook-to-create-a-swap-partition-using-the-storage-rhel-system-role_managing-local-storage-using-rhel-system-roles" data-v-b883c74f>2.9. Creating a swap volume by using the storage RHEL system role</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#configuring-a-raid-volume-using-the-storage-system-role_managing-local-storage-using-rhel-system-roles" id="sub-link-to-managing_file_systems-configuring-a-raid-volume-using-the-storage-system-role_managing-local-storage-using-rhel-system-roles" data-v-b883c74f>2.10. Configuring a RAID volume by using the storage RHEL system role</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#configuring-lvm-pool-with-raid-using-storage-system-role_managing-local-storage-using-rhel-system-roles" id="sub-link-to-managing_file_systems-configuring-lvm-pool-with-raid-using-storage-system-role_managing-local-storage-using-rhel-system-roles" data-v-b883c74f>2.11. Configuring an LVM pool with RAID by using the storage RHEL system role</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#configuring-a-stripe-size-for-raid-lvm-system-role_managing-local-storage-using-rhel-system-roles" id="sub-link-to-managing_file_systems-configuring-a-stripe-size-for-raid-lvm-system-role_managing-local-storage-using-rhel-system-roles" data-v-b883c74f>2.12. Configuring a stripe size for RAID LVM volumes by using the storage RHEL system role</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#example-ansible-playbook-to-compress-and-deduplicate-a-vdo-volume-on-lvm-using-the-storage-rhel-system-role_managing-local-storage-using-rhel-system-roles" id="sub-link-to-managing_file_systems-example-ansible-playbook-to-compress-and-deduplicate-a-vdo-volume-on-lvm-using-the-storage-rhel-system-role_managing-local-storage-using-rhel-system-roles" data-v-b883c74f>2.13. Compressing and deduplicating a VDO volume on LVM by using the storage RHEL system role</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#creating-a-luks2-encrypted-volume-using-the-storage-role_managing-local-storage-using-rhel-system-roles" id="sub-link-to-managing_file_systems-creating-a-luks2-encrypted-volume-using-the-storage-role_managing-local-storage-using-rhel-system-roles" data-v-b883c74f>2.14. Creating a LUKS2 encrypted volume by using the storage RHEL system role</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#example-ansible-playbook-to-express-pool-volume-sizes-as-percentage-using-the-storage-rhel-system-role_managing-local-storage-using-rhel-system-roles" id="sub-link-to-managing_file_systems-example-ansible-playbook-to-express-pool-volume-sizes-as-percentage-using-the-storage-rhel-system-role_managing-local-storage-using-rhel-system-roles" data-v-b883c74f>2.15. Expressing pool volume sizes as percentage by using the storage RHEL system role</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--managing-partitions-using-the-web-console_managing-file-systems" data-v-fa0dae77><summary class="heading chapter-title" id="managing-partitions-using-the-web-console_managing-file-systems--summary" data-v-fa0dae77>3. Managing partitions using the web console</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#managing-partitions-using-the-web-console_managing-file-systems" id="chapter-landing--managing_file_systems-managing-partitions-using-the-web-console_managing-file-systems" data-v-fa0dae77>Managing partitions using the web console</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#displaying-partitions-in-the-web-console_managing-partitions-using-the-web-console" id="sub-link-to-managing_file_systems-displaying-partitions-in-the-web-console_managing-partitions-using-the-web-console" data-v-b883c74f>3.1. Displaying partitions formatted with file systems in the web console</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#creating-partitions-in-the-web-console_managing-partitions-using-the-web-console" id="sub-link-to-managing_file_systems-creating-partitions-in-the-web-console_managing-partitions-using-the-web-console" data-v-b883c74f>3.2. Creating partitions in the web console</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#deleting-partitions-in-the-web-console_managing-partitions-using-the-web-console" id="sub-link-to-managing_file_systems-deleting-partitions-in-the-web-console_managing-partitions-using-the-web-console" data-v-b883c74f>3.3. Deleting partitions in the web console</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--mounting-nfs-shares_managing-file-systems" data-v-fa0dae77><summary class="heading chapter-title" id="mounting-nfs-shares_managing-file-systems--summary" data-v-fa0dae77>4. Mounting NFS shares</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#mounting-nfs-shares_managing-file-systems" id="chapter-landing--managing_file_systems-mounting-nfs-shares_managing-file-systems" data-v-fa0dae77>Mounting NFS shares</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#services-required-on-an-nfs-client_mounting-nfs-shares" id="sub-link-to-managing_file_systems-services-required-on-an-nfs-client_mounting-nfs-shares" data-v-b883c74f>4.1. Services required on an NFS client</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#preparing-an-nfsv3-client-to-run-behind-a-firewall_mounting-nfs-shares" id="sub-link-to-managing_file_systems-preparing-an-nfsv3-client-to-run-behind-a-firewall_mounting-nfs-shares" data-v-b883c74f>4.2. Preparing an NFSv3 client to run behind a firewall</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#preparing-an-nfsv4-0-client-to-run-behind-a-firewall_mounting-nfs-shares" id="sub-link-to-managing_file_systems-preparing-an-nfsv4-0-client-to-run-behind-a-firewall_mounting-nfs-shares" data-v-b883c74f>4.3. Preparing an NFSv4.0 client to run behind a firewall</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#manually-mounting-an-nfs-share_mounting-nfs-shares" id="sub-link-to-managing_file_systems-manually-mounting-an-nfs-share_mounting-nfs-shares" data-v-b883c74f>4.4. Manually mounting an NFS share</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#mounting-an-nfs-share-automatically-when-the-system-boots_mounting-nfs-shares" id="sub-link-to-managing_file_systems-mounting-an-nfs-share-automatically-when-the-system-boots_mounting-nfs-shares" data-v-b883c74f>4.5. Mounting an NFS share automatically when the system boots</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#connecting-nfs-mounts-in-the-web-console_mounting-nfs-shares" id="sub-link-to-managing_file_systems-connecting-nfs-mounts-in-the-web-console_mounting-nfs-shares" data-v-b883c74f>4.6. Connecting NFS mounts in the web console</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#customizing-nfs-mount-options-in-the-web-console_mounting-nfs-shares" id="sub-link-to-managing_file_systems-customizing-nfs-mount-options-in-the-web-console_mounting-nfs-shares" data-v-b883c74f>4.7. Customizing NFS mount options in the web console</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#setting-up-an-nfs-client-with-kerberos-in-a-red-hat-identity-management-domain_mounting-nfs-shares" id="sub-link-to-managing_file_systems-setting-up-an-nfs-client-with-kerberos-in-a-red-hat-identity-management-domain_mounting-nfs-shares" data-v-b883c74f>4.8. Setting up an NFS client with Kerberos in a Red Hat Identity Management domain</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#configuring-gnome-to-store-user-settings-on-home-directories-hosted-on-an-nfs-share_mounting-nfs-shares" id="sub-link-to-managing_file_systems-configuring-gnome-to-store-user-settings-on-home-directories-hosted-on-an-nfs-share_mounting-nfs-shares" data-v-b883c74f>4.9. Configuring GNOME to store user settings on home directories hosted on an NFS share</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#frequently-used-nfs-mount-options_mounting-nfs-shares" id="sub-link-to-managing_file_systems-frequently-used-nfs-mount-options_mounting-nfs-shares" data-v-b883c74f>4.10. Frequently used NFS mount options</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><details id="nested-toc--enabling-client-side-caching-of-nfs-content_mounting-nfs-shares" data-v-b883c74f><summary class="heading sub-chapter-title" id="enabling-client-side-caching-of-nfs-content_mounting-nfs-shares--summary" data-v-b883c74f>4.11. Enabling client-side caching of NFS content</summary><ol id="sub-nav--enabling-client-side-caching-of-nfs-content_mounting-nfs-shares" class="sub-nav" data-v-b883c74f><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title chapter-landing-page" href="#enabling-client-side-caching-of-nfs-content_mounting-nfs-shares" id="chapter-landing--managing_file_systems-enabling-client-side-caching-of-nfs-content_mounting-nfs-shares" data-v-b883c74f>Enabling client-side caching of NFS content</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#how-nfs-caching-works_enabling-client-side-caching-of-nfs-content" id="sub-link-to-managing_file_systems-how-nfs-caching-works_enabling-client-side-caching-of-nfs-content" data-v-b883c74f>4.11.1. How NFS caching works</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#installing-and-configuring-the-cachefilesd-service_enabling-client-side-caching-of-nfs-content" id="sub-link-to-managing_file_systems-installing-and-configuring-the-cachefilesd-service_enabling-client-side-caching-of-nfs-content" data-v-b883c74f>4.11.2. Installing and configuring the cachefilesd service</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#sharing-nfs-cache_enabling-client-side-caching-of-nfs-content" id="sub-link-to-managing_file_systems-sharing-nfs-cache_enabling-client-side-caching-of-nfs-content" data-v-b883c74f>4.11.3. Sharing NFS cache</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#nfs-cache-limitations_enabling-client-side-caching-of-nfs-content" id="sub-link-to-managing_file_systems-nfs-cache-limitations_enabling-client-side-caching-of-nfs-content" data-v-b883c74f>4.11.4. NFS cache limitations</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#how-cache-culling-works_enabling-client-side-caching-of-nfs-content" id="sub-link-to-managing_file_systems-how-cache-culling-works_enabling-client-side-caching-of-nfs-content" data-v-b883c74f>4.11.5. How cache culling works</a></li><!--]--><!--]--></ol></details></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--mounting-an-smb-share-on-red-hat-enterprise-linux_managing-file-systems" data-v-fa0dae77><summary class="heading chapter-title" id="mounting-an-smb-share-on-red-hat-enterprise-linux_managing-file-systems--summary" data-v-fa0dae77>5. Mounting an SMB Share</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#mounting-an-smb-share-on-red-hat-enterprise-linux_managing-file-systems" id="chapter-landing--managing_file_systems-mounting-an-smb-share-on-red-hat-enterprise-linux_managing-file-systems" data-v-fa0dae77>Mounting an SMB Share</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#con_supported-smb-protocol-versions_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux" id="sub-link-to-managing_file_systems-con_supported-smb-protocol-versions_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux" data-v-b883c74f>5.1. Supported SMB protocol versions</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#con_unix-extensions-support_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux" id="sub-link-to-managing_file_systems-con_unix-extensions-support_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux" data-v-b883c74f>5.2. UNIX extensions support</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_manually-mounting-an-smb-share_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux" id="sub-link-to-managing_file_systems-proc_manually-mounting-an-smb-share_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux" data-v-b883c74f>5.3. Manually mounting an SMB share</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_mounting-an-smb-share-automatically-when-the-system-boots_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux" id="sub-link-to-managing_file_systems-proc_mounting-an-smb-share-automatically-when-the-system-boots_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux" data-v-b883c74f>5.4. Mounting an SMB share automatically when the system boots</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_authenticating-to-an-smb-share-using-a-credentials-file_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux" id="sub-link-to-managing_file_systems-proc_authenticating-to-an-smb-share-using-a-credentials-file_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux" data-v-b883c74f>5.5. Creating a credentials file to authenticate to an SMB share</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><details id="nested-toc--performing-a-multi-user-smb-mount_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux" data-v-b883c74f><summary class="heading sub-chapter-title" id="performing-a-multi-user-smb-mount_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux--summary" data-v-b883c74f>5.6. Performing a multi-user SMB mount</summary><ol id="sub-nav--performing-a-multi-user-smb-mount_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux" class="sub-nav" data-v-b883c74f><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title chapter-landing-page" href="#performing-a-multi-user-smb-mount_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux" id="chapter-landing--managing_file_systems-performing-a-multi-user-smb-mount_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux" data-v-b883c74f>Performing a multi-user SMB mount</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_mounting-a-share-with-the-multiuser-option_assembly_performing-a-multi-user-smb-mount" id="sub-link-to-managing_file_systems-proc_mounting-a-share-with-the-multiuser-option_assembly_performing-a-multi-user-smb-mount" data-v-b883c74f>5.6.1. Mounting a share with the multiuser option</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_verifying-if-an-smb-share-is-mounted-with-the-multiuser-option_assembly_performing-a-multi-user-smb-mount" id="sub-link-to-managing_file_systems-proc_verifying-if-an-smb-share-is-mounted-with-the-multiuser-option_assembly_performing-a-multi-user-smb-mount" data-v-b883c74f>5.6.2. Verifying if an SMB share is mounted with the multiuser option</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_accessing-a-share-as-a-user_assembly_performing-a-multi-user-smb-mount" id="sub-link-to-managing_file_systems-proc_accessing-a-share-as-a-user_assembly_performing-a-multi-user-smb-mount" data-v-b883c74f>5.6.3. Accessing a share as a user</a></li><!--]--><!--]--></ol></details></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#con_frequently-used-mount-options_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux" id="sub-link-to-managing_file_systems-con_frequently-used-mount-options_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux" data-v-b883c74f>5.7. Frequently used SMB mount options</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--assembly_overview-of-persistent-naming-attributes_managing-file-systems" data-v-fa0dae77><summary class="heading chapter-title" id="assembly_overview-of-persistent-naming-attributes_managing-file-systems--summary" data-v-fa0dae77>6. Overview of persistent naming attributes</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#assembly_overview-of-persistent-naming-attributes_managing-file-systems" id="chapter-landing--managing_file_systems-assembly_overview-of-persistent-naming-attributes_managing-file-systems" data-v-fa0dae77>Overview of persistent naming attributes</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#con_disadvantages-of-non-persistent-naming-attributes_assembly_overview-of-persistent-naming-attributes" id="sub-link-to-managing_file_systems-con_disadvantages-of-non-persistent-naming-attributes_assembly_overview-of-persistent-naming-attributes" data-v-b883c74f>6.1. Disadvantages of non-persistent naming attributes</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#file-system-and-device-identifiers_assembly_overview-of-persistent-naming-attributes" id="sub-link-to-managing_file_systems-file-system-and-device-identifiers_assembly_overview-of-persistent-naming-attributes" data-v-b883c74f>6.2. File system and device identifiers</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><details id="nested-toc--con_device-names-managed-by-the-udev-mechanism-in-dev-disk-_assembly_overview-of-persistent-naming-attributes" data-v-b883c74f><summary class="heading sub-chapter-title" id="con_device-names-managed-by-the-udev-mechanism-in-dev-disk-_assembly_overview-of-persistent-naming-attributes--summary" data-v-b883c74f>6.3. Device names managed by the udev mechanism in /dev/disk/</summary><ol id="sub-nav--con_device-names-managed-by-the-udev-mechanism-in-dev-disk-_assembly_overview-of-persistent-naming-attributes" class="sub-nav" data-v-b883c74f><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title chapter-landing-page" href="#con_device-names-managed-by-the-udev-mechanism-in-dev-disk-_assembly_overview-of-persistent-naming-attributes" id="chapter-landing--managing_file_systems-con_device-names-managed-by-the-udev-mechanism-in-dev-disk-_assembly_overview-of-persistent-naming-attributes" data-v-b883c74f>Device names managed by the udev mechanism in /dev/disk/</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#file-system-identifiers_assembly_overview-of-persistent-naming-attributes" id="sub-link-to-managing_file_systems-file-system-identifiers_assembly_overview-of-persistent-naming-attributes" data-v-b883c74f>6.3.1. File system identifiers</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#device-identifiers_assembly_overview-of-persistent-naming-attributes" id="sub-link-to-managing_file_systems-device-identifiers_assembly_overview-of-persistent-naming-attributes" data-v-b883c74f>6.3.2. Device identifiers</a></li><!--]--><!--]--></ol></details></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#con_the-world-wide-identifier-with-dm-multipath_assembly_overview-of-persistent-naming-attributes" id="sub-link-to-managing_file_systems-con_the-world-wide-identifier-with-dm-multipath_assembly_overview-of-persistent-naming-attributes" data-v-b883c74f>6.4. The World Wide Identifier with DM Multipath</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#con_limitations-of-the-udev-device-naming-convention_assembly_overview-of-persistent-naming-attributes" id="sub-link-to-managing_file_systems-con_limitations-of-the-udev-device-naming-convention_assembly_overview-of-persistent-naming-attributes" data-v-b883c74f>6.5. Limitations of the udev device naming convention</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_listing-persistent-naming-attributes_assembly_overview-of-persistent-naming-attributes" id="sub-link-to-managing_file_systems-proc_listing-persistent-naming-attributes_assembly_overview-of-persistent-naming-attributes" data-v-b883c74f>6.6. Listing persistent naming attributes</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_modifying-persistent-naming-attributes_assembly_overview-of-persistent-naming-attributes" id="sub-link-to-managing_file_systems-proc_modifying-persistent-naming-attributes_assembly_overview-of-persistent-naming-attributes" data-v-b883c74f>6.7. Modifying persistent naming attributes</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--partition-operations-with-parted_managing-file-systems" data-v-fa0dae77><summary class="heading chapter-title" id="partition-operations-with-parted_managing-file-systems--summary" data-v-fa0dae77>7. Partition operations with parted</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#partition-operations-with-parted_managing-file-systems" id="chapter-landing--managing_file_systems-partition-operations-with-parted_managing-file-systems" data-v-fa0dae77>Partition operations with parted</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#viewing-the-partition-table-with-parted_partition-operations-with-parted" id="sub-link-to-managing_file_systems-viewing-the-partition-table-with-parted_partition-operations-with-parted" data-v-b883c74f>7.1. Viewing the partition table with parted</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_creating-a-partition-table-on-a-disk-with-parted_partition-operations-with-parted" id="sub-link-to-managing_file_systems-proc_creating-a-partition-table-on-a-disk-with-parted_partition-operations-with-parted" data-v-b883c74f>7.2. Creating a partition table on a disk with parted</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_creating-a-partition-with-parted_partition-operations-with-parted" id="sub-link-to-managing_file_systems-proc_creating-a-partition-with-parted_partition-operations-with-parted" data-v-b883c74f>7.3. Creating a partition with parted</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_removing-a-partition-with-parted_partition-operations-with-parted" id="sub-link-to-managing_file_systems-proc_removing-a-partition-with-parted_partition-operations-with-parted" data-v-b883c74f>7.4. Removing a partition with parted</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_resizing-a-partition-with-parted_partition-operations-with-parted" id="sub-link-to-managing_file_systems-proc_resizing-a-partition-with-parted_partition-operations-with-parted" data-v-b883c74f>7.5. Resizing a partition with parted</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--strategies-for-repartitioning-a-disk_managing-file-systems" data-v-fa0dae77><summary class="heading chapter-title" id="strategies-for-repartitioning-a-disk_managing-file-systems--summary" data-v-fa0dae77>8. Strategies for repartitioning a disk</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#strategies-for-repartitioning-a-disk_managing-file-systems" id="chapter-landing--managing_file_systems-strategies-for-repartitioning-a-disk_managing-file-systems" data-v-fa0dae77>Strategies for repartitioning a disk</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#using-unpartitioned-free-space_strategies-for-repartitioning-a-disk" id="sub-link-to-managing_file_systems-using-unpartitioned-free-space_strategies-for-repartitioning-a-disk" data-v-b883c74f>8.1. Using unpartitioned free space</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#using-space-from-an-unused-partition_strategies-for-repartitioning-a-disk" id="sub-link-to-managing_file_systems-using-space-from-an-unused-partition_strategies-for-repartitioning-a-disk" data-v-b883c74f>8.2. Using space from an unused partition</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><details id="nested-toc--using-free-space-from-an-active-partition_strategies-for-repartitioning-a-disk" data-v-b883c74f><summary class="heading sub-chapter-title" id="using-free-space-from-an-active-partition_strategies-for-repartitioning-a-disk--summary" data-v-b883c74f>8.3. Using free space from an active partition</summary><ol id="sub-nav--using-free-space-from-an-active-partition_strategies-for-repartitioning-a-disk" class="sub-nav" data-v-b883c74f><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title chapter-landing-page" href="#using-free-space-from-an-active-partition_strategies-for-repartitioning-a-disk" id="chapter-landing--managing_file_systems-using-free-space-from-an-active-partition_strategies-for-repartitioning-a-disk" data-v-b883c74f>Using free space from an active partition</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#destructive-repartitioning_using-free-space-from-an-active-partition" id="sub-link-to-managing_file_systems-destructive-repartitioning_using-free-space-from-an-active-partition" data-v-b883c74f>8.3.1. Destructive repartitioning</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#non-destructive-repartitioning_using-free-space-from-an-active-partition" id="sub-link-to-managing_file_systems-non-destructive-repartitioning_using-free-space-from-an-active-partition" data-v-b883c74f>8.3.2. Non-destructive repartitioning</a></li><!--]--><!--]--></ol></details></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--getting-started-with-xfs_managing-file-systems" data-v-fa0dae77><summary class="heading chapter-title" id="getting-started-with-xfs_managing-file-systems--summary" data-v-fa0dae77>9. Getting started with XFS</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#getting-started-with-xfs_managing-file-systems" id="chapter-landing--managing_file_systems-getting-started-with-xfs_managing-file-systems" data-v-fa0dae77>Getting started with XFS</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#the-xfs-file-system_getting-started-with-xfs" id="sub-link-to-managing_file_systems-the-xfs-file-system_getting-started-with-xfs" data-v-b883c74f>9.1. The XFS file system</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#comparison-of-tools-used-with-ext4-and-xfs_getting-started-with-xfs" id="sub-link-to-managing_file_systems-comparison-of-tools-used-with-ext4-and-xfs_getting-started-with-xfs" data-v-b883c74f>9.2. Comparison of tools used with ext4 and XFS</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--assembly_creating-an-xfs-file-system_managing-file-systems" data-v-fa0dae77><summary class="heading chapter-title" id="assembly_creating-an-xfs-file-system_managing-file-systems--summary" data-v-fa0dae77>10. Creating an XFS file system</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#assembly_creating-an-xfs-file-system_managing-file-systems" id="chapter-landing--managing_file_systems-assembly_creating-an-xfs-file-system_managing-file-systems" data-v-fa0dae77>Creating an XFS file system</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_creating-an-xfs-file-system-with-mkfs-xfs-creating-an-xfs-file-system" id="sub-link-to-managing_file_systems-proc_creating-an-xfs-file-system-with-mkfs-xfs-creating-an-xfs-file-system" data-v-b883c74f>10.1. Creating an XFS file system with mkfs.xfs</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--backing-up-an-xfs-file-system_managing-file-systems" data-v-fa0dae77><summary class="heading chapter-title" id="backing-up-an-xfs-file-system_managing-file-systems--summary" data-v-fa0dae77>11. Backing up an XFS file system</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#backing-up-an-xfs-file-system_managing-file-systems" id="chapter-landing--managing_file_systems-backing-up-an-xfs-file-system_managing-file-systems" data-v-fa0dae77>Backing up an XFS file system</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#con_features-of-xfs-backup-backing-up-an-xfs-file-system" id="sub-link-to-managing_file_systems-con_features-of-xfs-backup-backing-up-an-xfs-file-system" data-v-b883c74f>11.1. Features of XFS backup</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_backing-up-an-xfs-file-system-with-xfsdump-backing-up-an-xfs-file-system" id="sub-link-to-managing_file_systems-proc_backing-up-an-xfs-file-system-with-xfsdump-backing-up-an-xfs-file-system" data-v-b883c74f>11.2. Backing up an XFS file system with xfsdump</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--restoring-an-xfs-file-system-from-backup_managing-file-systems" data-v-fa0dae77><summary class="heading chapter-title" id="restoring-an-xfs-file-system-from-backup_managing-file-systems--summary" data-v-fa0dae77>12. Restoring an XFS file system from backup</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#restoring-an-xfs-file-system-from-backup_managing-file-systems" id="chapter-landing--managing_file_systems-restoring-an-xfs-file-system-from-backup_managing-file-systems" data-v-fa0dae77>Restoring an XFS file system from backup</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#con_features-of-restoring-xfs-from-backup-restoring-an-xfs-file-system-from-backup" id="sub-link-to-managing_file_systems-con_features-of-restoring-xfs-from-backup-restoring-an-xfs-file-system-from-backup" data-v-b883c74f>12.1. Features of restoring XFS from backup</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_restoring-an-xfs-file-system-from-backup-with-xfsrestore-restoring-an-xfs-file-system-from-backup" id="sub-link-to-managing_file_systems-proc_restoring-an-xfs-file-system-from-backup-with-xfsrestore-restoring-an-xfs-file-system-from-backup" data-v-b883c74f>12.2. Restoring an XFS file system from backup with xfsrestore</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#con_informational-messages-when-restoring-an-xfs-backup-from-a-tape-restoring-an-xfs-file-system-from-backup" id="sub-link-to-managing_file_systems-con_informational-messages-when-restoring-an-xfs-backup-from-a-tape-restoring-an-xfs-file-system-from-backup" data-v-b883c74f>12.3. Informational messages when restoring an XFS backup from a tape</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--increasing-the-size-of-an-xfs-file-system_managing-file-systems" data-v-fa0dae77><summary class="heading chapter-title" id="increasing-the-size-of-an-xfs-file-system_managing-file-systems--summary" data-v-fa0dae77>13. Increasing the size of an XFS file system</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#increasing-the-size-of-an-xfs-file-system_managing-file-systems" id="chapter-landing--managing_file_systems-increasing-the-size-of-an-xfs-file-system_managing-file-systems" data-v-fa0dae77>Increasing the size of an XFS file system</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_increasing-the-size-of-an-xfs-file-system-with-xfs_growfs_increasing-the-size-of-an-xfs-file-system" id="sub-link-to-managing_file_systems-proc_increasing-the-size-of-an-xfs-file-system-with-xfs_growfs_increasing-the-size-of-an-xfs-file-system" data-v-b883c74f>13.1. Increasing the size of an XFS file system with xfs_growfs</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--configuring-xfs-error-behavior_managing-file-systems" data-v-fa0dae77><summary class="heading chapter-title" id="configuring-xfs-error-behavior_managing-file-systems--summary" data-v-fa0dae77>14. Configuring XFS error behavior</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#configuring-xfs-error-behavior_managing-file-systems" id="chapter-landing--managing_file_systems-configuring-xfs-error-behavior_managing-file-systems" data-v-fa0dae77>Configuring XFS error behavior</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#configurable-error-handling-in-xfs_configuring-xfs-error-behavior" id="sub-link-to-managing_file_systems-configurable-error-handling-in-xfs_configuring-xfs-error-behavior" data-v-b883c74f>14.1. Configurable error handling in XFS</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#configuration-files-for-specific-and-undefined-xfs-error-conditions_configuring-xfs-error-behavior" id="sub-link-to-managing_file_systems-configuration-files-for-specific-and-undefined-xfs-error-conditions_configuring-xfs-error-behavior" data-v-b883c74f>14.2. Configuration files for specific and undefined XFS error conditions</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#setting-specific-and-undefined-xfs-error-conditions_configuring-xfs-error-behavior" id="sub-link-to-managing_file_systems-setting-specific-and-undefined-xfs-error-conditions_configuring-xfs-error-behavior" data-v-b883c74f>14.3. Setting XFS behavior for specific conditions</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#setting-undefined-xfs-error-conditions_configuring-xfs-error-behavior" id="sub-link-to-managing_file_systems-setting-undefined-xfs-error-conditions_configuring-xfs-error-behavior" data-v-b883c74f>14.4. Setting XFS behavior for undefined conditions</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#setting-the-unmount-behavior_configuring-xfs-error-behavior" id="sub-link-to-managing_file_systems-setting-the-unmount-behavior_configuring-xfs-error-behavior" data-v-b883c74f>14.5. Setting the XFS unmount behavior</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--checking-and-repairing-a-file-system__managing-file-systems" data-v-fa0dae77><summary class="heading chapter-title" id="checking-and-repairing-a-file-system__managing-file-systems--summary" data-v-fa0dae77>15. Checking and repairing a file system</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#checking-and-repairing-a-file-system__managing-file-systems" id="chapter-landing--managing_file_systems-checking-and-repairing-a-file-system__managing-file-systems" data-v-fa0dae77>Checking and repairing a file system</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#file-system-checking-and-repair_checking-and-repairing-a-file-system" id="sub-link-to-managing_file_systems-file-system-checking-and-repair_checking-and-repairing-a-file-system" data-v-b883c74f>15.1. Scenarios that require a file system check</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#potential-side-effects-of-running-fsck_checking-and-repairing-a-file-system" id="sub-link-to-managing_file_systems-potential-side-effects-of-running-fsck_checking-and-repairing-a-file-system" data-v-b883c74f>15.2. Potential side effects of running fsck</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#error-handling-mechanisms-in-xfs_checking-and-repairing-a-file-system" id="sub-link-to-managing_file_systems-error-handling-mechanisms-in-xfs_checking-and-repairing-a-file-system" data-v-b883c74f>15.3. Error-handling mechanisms in XFS</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#checking-an-xfs-file-system-with-xfs-repair_checking-and-repairing-a-file-system" id="sub-link-to-managing_file_systems-checking-an-xfs-file-system-with-xfs-repair_checking-and-repairing-a-file-system" data-v-b883c74f>15.4. Checking an XFS file system with xfs_repair</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_repairing-an-xfs-file-system-with-xfs_repair_checking-and-repairing-a-file-system" id="sub-link-to-managing_file_systems-proc_repairing-an-xfs-file-system-with-xfs_repair_checking-and-repairing-a-file-system" data-v-b883c74f>15.5. Repairing an XFS file system with xfs_repair</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#error-handling-mechanisms-in-ext2-ext3-and-ext4_checking-and-repairing-a-file-system" id="sub-link-to-managing_file_systems-error-handling-mechanisms-in-ext2-ext3-and-ext4_checking-and-repairing-a-file-system" data-v-b883c74f>15.6. Error handling mechanisms in ext2, ext3, and ext4</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#checking-an-ext2-ext3-or-ext4-file-system-with-e2fsck_checking-and-repairing-a-file-system" id="sub-link-to-managing_file_systems-checking-an-ext2-ext3-or-ext4-file-system-with-e2fsck_checking-and-repairing-a-file-system" data-v-b883c74f>15.7. Checking an ext2, ext3, or ext4 file system with e2fsck</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#repairing-an-ext2-ext3-or-ext4-file-system-with-e2fsck_checking-and-repairing-a-file-system" id="sub-link-to-managing_file_systems-repairing-an-ext2-ext3-or-ext4-file-system-with-e2fsck_checking-and-repairing-a-file-system" data-v-b883c74f>15.8. Repairing an ext2, ext3, or ext4 file system with e2fsck</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--mounting-file-systems_managing-file-systems" data-v-fa0dae77><summary class="heading chapter-title" id="mounting-file-systems_managing-file-systems--summary" data-v-fa0dae77>16. Mounting file systems</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#mounting-file-systems_managing-file-systems" id="chapter-landing--managing_file_systems-mounting-file-systems_managing-file-systems" data-v-fa0dae77>Mounting file systems</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#the-linux-mount-mechanism_mounting-file-systems" id="sub-link-to-managing_file_systems-the-linux-mount-mechanism_mounting-file-systems" data-v-b883c74f>16.1. The Linux mount mechanism</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#listing-currently-mounted-file-systems_mounting-file-systems" id="sub-link-to-managing_file_systems-listing-currently-mounted-file-systems_mounting-file-systems" data-v-b883c74f>16.2. Listing currently mounted file systems</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#mounting-a-file-system-with-mount_mounting-file-systems" id="sub-link-to-managing_file_systems-mounting-a-file-system-with-mount_mounting-file-systems" data-v-b883c74f>16.3. Mounting a file system with mount</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#moving-a-mount-point_mounting-file-systems" id="sub-link-to-managing_file_systems-moving-a-mount-point_mounting-file-systems" data-v-b883c74f>16.4. Moving a mount point</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#unmounting-a-file-system-with-umount_mounting-file-systems" id="sub-link-to-managing_file_systems-unmounting-a-file-system-with-umount_mounting-file-systems" data-v-b883c74f>16.5. Unmounting a file system with umount</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#mounting-and-unmounting-file-systems-in-the-web-console_mounting-file-systems" id="sub-link-to-managing_file_systems-mounting-and-unmounting-file-systems-in-the-web-console_mounting-file-systems" data-v-b883c74f>16.6. Mounting and unmounting file systems in the web console</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#common-mount-options_mounting-file-systems" id="sub-link-to-managing_file_systems-common-mount-options_mounting-file-systems" data-v-b883c74f>16.7. Common mount options</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--sharing-a-mount-on-multiple-mount-points_managing-file-systems" data-v-fa0dae77><summary class="heading chapter-title" id="sharing-a-mount-on-multiple-mount-points_managing-file-systems--summary" data-v-fa0dae77>17. Sharing a mount on multiple mount points</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#sharing-a-mount-on-multiple-mount-points_managing-file-systems" id="chapter-landing--managing_file_systems-sharing-a-mount-on-multiple-mount-points_managing-file-systems" data-v-fa0dae77>Sharing a mount on multiple mount points</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#types-of-shared-mounts_sharing-a-mount-on-multiple-mount-points" id="sub-link-to-managing_file_systems-types-of-shared-mounts_sharing-a-mount-on-multiple-mount-points" data-v-b883c74f>17.1. Types of shared mounts</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#creating-a-private-mount-point-duplicate_sharing-a-mount-on-multiple-mount-points" id="sub-link-to-managing_file_systems-creating-a-private-mount-point-duplicate_sharing-a-mount-on-multiple-mount-points" data-v-b883c74f>17.2. Creating a private mount point duplicate</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#creating-a-shared-mount-point-duplicate_sharing-a-mount-on-multiple-mount-points" id="sub-link-to-managing_file_systems-creating-a-shared-mount-point-duplicate_sharing-a-mount-on-multiple-mount-points" data-v-b883c74f>17.3. Creating a shared mount point duplicate</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#creating-a-slave-mount-point-duplicate_sharing-a-mount-on-multiple-mount-points" id="sub-link-to-managing_file_systems-creating-a-slave-mount-point-duplicate_sharing-a-mount-on-multiple-mount-points" data-v-b883c74f>17.4. Creating a slave mount point duplicate</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#preventing-a-mount-point-from-being-duplicated_sharing-a-mount-on-multiple-mount-points" id="sub-link-to-managing_file_systems-preventing-a-mount-point-from-being-duplicated_sharing-a-mount-on-multiple-mount-points" data-v-b883c74f>17.5. Preventing a mount point from being duplicated</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--assembly_persistently-mounting-file-systems_managing-file-systems" data-v-fa0dae77><summary class="heading chapter-title" id="assembly_persistently-mounting-file-systems_managing-file-systems--summary" data-v-fa0dae77>18. Persistently mounting file systems</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#assembly_persistently-mounting-file-systems_managing-file-systems" id="chapter-landing--managing_file_systems-assembly_persistently-mounting-file-systems_managing-file-systems" data-v-fa0dae77>Persistently mounting file systems</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#con_the-etc-fstab-file_assembly_persistently-mounting-file-systems" id="sub-link-to-managing_file_systems-con_the-etc-fstab-file_assembly_persistently-mounting-file-systems" data-v-b883c74f>18.1. The /etc/fstab file</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#adding-a-file-system-to-etc-fstab_assembly_persistently-mounting-file-systems" id="sub-link-to-managing_file_systems-adding-a-file-system-to-etc-fstab_assembly_persistently-mounting-file-systems" data-v-b883c74f>18.2. Adding a file system to /etc/fstab</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--mounting-file-systems-on-demand_managing-file-systems" data-v-fa0dae77><summary class="heading chapter-title" id="mounting-file-systems-on-demand_managing-file-systems--summary" data-v-fa0dae77>19. Mounting file systems on demand</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#mounting-file-systems-on-demand_managing-file-systems" id="chapter-landing--managing_file_systems-mounting-file-systems-on-demand_managing-file-systems" data-v-fa0dae77>Mounting file systems on demand</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#the-autofs-service_mounting-file-systems-on-demand" id="sub-link-to-managing_file_systems-the-autofs-service_mounting-file-systems-on-demand" data-v-b883c74f>19.1. The autofs service</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#the-autofs-configuration-files_mounting-file-systems-on-demand" id="sub-link-to-managing_file_systems-the-autofs-configuration-files_mounting-file-systems-on-demand" data-v-b883c74f>19.2. The autofs configuration files</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#configuring-autofs-mount-points_mounting-file-systems-on-demand" id="sub-link-to-managing_file_systems-configuring-autofs-mount-points_mounting-file-systems-on-demand" data-v-b883c74f>19.3. Configuring autofs mount points</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#automounting-user-home-directories-with-autofs-service_mounting-file-systems-on-demand" id="sub-link-to-managing_file_systems-automounting-user-home-directories-with-autofs-service_mounting-file-systems-on-demand" data-v-b883c74f>19.4. Automounting NFS server user home directories with autofs service</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#overriding-or-augmenting-autofs-site-configuration-files_mounting-file-systems-on-demand" id="sub-link-to-managing_file_systems-overriding-or-augmenting-autofs-site-configuration-files_mounting-file-systems-on-demand" data-v-b883c74f>19.5. Overriding or augmenting autofs site configuration files</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#using-ldap-to-store-automounter-maps_mounting-file-systems-on-demand" id="sub-link-to-managing_file_systems-using-ldap-to-store-automounter-maps_mounting-file-systems-on-demand" data-v-b883c74f>19.6. Using LDAP to store automounter maps</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_using-systemd-automount-to-mount-a-file-system-on-demand-with-etc-fstab_mounting-file-systems-on-demand" id="sub-link-to-managing_file_systems-proc_using-systemd-automount-to-mount-a-file-system-on-demand-with-etc-fstab_mounting-file-systems-on-demand" data-v-b883c74f>19.7. Using systemd.automount to mount a file system on demand with /etc/fstab</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_using-systemd-automount-to-mount-a-file-system-on-demand-with-a-mount-unit_mounting-file-systems-on-demand" id="sub-link-to-managing_file_systems-proc_using-systemd-automount-to-mount-a-file-system-on-demand-with-a-mount-unit_mounting-file-systems-on-demand" data-v-b883c74f>19.8. Using systemd.automount to mount a file system on-demand with a mount unit</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--using-sssd-component-from-idm-to-cache-the-autofs-map_managing-file-systems" data-v-fa0dae77><summary class="heading chapter-title" id="using-sssd-component-from-idm-to-cache-the-autofs-map_managing-file-systems--summary" data-v-fa0dae77>20. Using SSSD component from IdM to cache the autofs maps</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#using-sssd-component-from-idm-to-cache-the-autofs-map_managing-file-systems" id="chapter-landing--managing_file_systems-using-sssd-component-from-idm-to-cache-the-autofs-map_managing-file-systems" data-v-fa0dae77>Using SSSD component from IdM to cache the autofs maps</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#configuring-autofs-manually-to-use-sssd-and-idm_using-sssd-component-from-idm-to-cache-the-autofs-map" id="sub-link-to-managing_file_systems-configuring-autofs-manually-to-use-sssd-and-idm_using-sssd-component-from-idm-to-cache-the-autofs-map" data-v-b883c74f>20.1. Configuring autofs manually to use IdM server as an LDAP server</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#configuring-sssd-to-cache-autofs-map_using-sssd-component-from-idm-to-cache-the-autofs-map" id="sub-link-to-managing_file_systems-configuring-sssd-to-cache-autofs-map_using-sssd-component-from-idm-to-cache-the-autofs-map" data-v-b883c74f>20.2. Configuring SSSD to cache autofs maps</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--setting-read-only-permissions-for-the-root-file-system_managing-file-systems" data-v-fa0dae77><summary class="heading chapter-title" id="setting-read-only-permissions-for-the-root-file-system_managing-file-systems--summary" data-v-fa0dae77>21. Setting read-only permissions for the root file system</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#setting-read-only-permissions-for-the-root-file-system_managing-file-systems" id="chapter-landing--managing_file_systems-setting-read-only-permissions-for-the-root-file-system_managing-file-systems" data-v-fa0dae77>Setting read-only permissions for the root file system</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#files-and-directories-that-always-retain-write-permissions_setting-read-only-permissions-for-the-root-file-system" id="sub-link-to-managing_file_systems-files-and-directories-that-always-retain-write-permissions_setting-read-only-permissions-for-the-root-file-system" data-v-b883c74f>21.1. Files and directories that always retain write permissions</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#configuring-the-root-file-system-to-mount-with-read-only-permissions-on-boot_setting-read-only-permissions-for-the-root-file-system" id="sub-link-to-managing_file_systems-configuring-the-root-file-system-to-mount-with-read-only-permissions-on-boot_setting-read-only-permissions-for-the-root-file-system" data-v-b883c74f>21.2. Configuring the root file system to mount with read-only permissions on boot</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--assembly_limiting-storage-space-usage-on-xfs-with-quotas_managing-file-systems" data-v-fa0dae77><summary class="heading chapter-title" id="assembly_limiting-storage-space-usage-on-xfs-with-quotas_managing-file-systems--summary" data-v-fa0dae77>22. Limiting storage space usage on XFS with quotas</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#assembly_limiting-storage-space-usage-on-xfs-with-quotas_managing-file-systems" id="chapter-landing--managing_file_systems-assembly_limiting-storage-space-usage-on-xfs-with-quotas_managing-file-systems" data-v-fa0dae77>Limiting storage space usage on XFS with quotas</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#con_disk-quotas_assembly_limiting-storage-space-usage-on-xfs-with-quotas" id="sub-link-to-managing_file_systems-con_disk-quotas_assembly_limiting-storage-space-usage-on-xfs-with-quotas" data-v-b883c74f>22.1. Disk quotas</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#the-xfs_quota-tool_assembly_limiting-storage-space-usage-on-xfs-with-quotas" id="sub-link-to-managing_file_systems-the-xfs_quota-tool_assembly_limiting-storage-space-usage-on-xfs-with-quotas" data-v-b883c74f>22.2. The xfs_quota tool</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#file-system-quota-management-in-xfs_assembly_limiting-storage-space-usage-on-xfs-with-quotas" id="sub-link-to-managing_file_systems-file-system-quota-management-in-xfs_assembly_limiting-storage-space-usage-on-xfs-with-quotas" data-v-b883c74f>22.3. File system quota management in XFS</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#enabling-disk-quotas-for-xfs_assembly_limiting-storage-space-usage-on-xfs-with-quotas" id="sub-link-to-managing_file_systems-enabling-disk-quotas-for-xfs_assembly_limiting-storage-space-usage-on-xfs-with-quotas" data-v-b883c74f>22.4. Enabling disk quotas for XFS</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#running-the-xfs_quota-tool_assembly_limiting-storage-space-usage-on-xfs-with-quotas" id="sub-link-to-managing_file_systems-running-the-xfs_quota-tool_assembly_limiting-storage-space-usage-on-xfs-with-quotas" data-v-b883c74f>22.5. Reporting XFS usage</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#running-the-xfs_quota-tool-in-expert-mode_assembly_limiting-storage-space-usage-on-xfs-with-quotas" id="sub-link-to-managing_file_systems-running-the-xfs_quota-tool-in-expert-mode_assembly_limiting-storage-space-usage-on-xfs-with-quotas" data-v-b883c74f>22.6. Modifying XFS quota limits</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#setting-project-limits-for-xfs_assembly_limiting-storage-space-usage-on-xfs-with-quotas" id="sub-link-to-managing_file_systems-setting-project-limits-for-xfs_assembly_limiting-storage-space-usage-on-xfs-with-quotas" data-v-b883c74f>22.7. Setting project limits for XFS</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--limiting-storage-space-usage-on-ext4-with-quotas_managing-file-systems" data-v-fa0dae77><summary class="heading chapter-title" id="limiting-storage-space-usage-on-ext4-with-quotas_managing-file-systems--summary" data-v-fa0dae77>23. Limiting storage space usage on ext4 with quotas</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#limiting-storage-space-usage-on-ext4-with-quotas_managing-file-systems" id="chapter-landing--managing_file_systems-limiting-storage-space-usage-on-ext4-with-quotas_managing-file-systems" data-v-fa0dae77>Limiting storage space usage on ext4 with quotas</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#installing-quota-rpm_limiting-storage-space-usage-on-ext4-with-quotas" id="sub-link-to-managing_file_systems-installing-quota-rpm_limiting-storage-space-usage-on-ext4-with-quotas" data-v-b883c74f>23.1. Installing the quota tool</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#enabling-quota-feature-in-file-system-creation_limiting-storage-space-usage-on-ext4-with-quotas" id="sub-link-to-managing_file_systems-enabling-quota-feature-in-file-system-creation_limiting-storage-space-usage-on-ext4-with-quotas" data-v-b883c74f>23.2. Enabling quota feature on file system creation</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#enabling-quota-feature-on-existing-file-system_limiting-storage-space-usage-on-ext4-with-quotas" id="sub-link-to-managing_file_systems-enabling-quota-feature-on-existing-file-system_limiting-storage-space-usage-on-ext4-with-quotas" data-v-b883c74f>23.3. Enabling quota feature on existing file systems</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#enabling-quota-enforcement_limiting-storage-space-usage-on-ext4-with-quotas" id="sub-link-to-managing_file_systems-enabling-quota-enforcement_limiting-storage-space-usage-on-ext4-with-quotas" data-v-b883c74f>23.4. Enabling quota enforcement</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#assigning-quotas-per-user_limiting-storage-space-usage-on-ext4-with-quotas" id="sub-link-to-managing_file_systems-assigning-quotas-per-user_limiting-storage-space-usage-on-ext4-with-quotas" data-v-b883c74f>23.5. Assigning quotas per user</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#assigning-quotas-per-group_limiting-storage-space-usage-on-ext4-with-quotas" id="sub-link-to-managing_file_systems-assigning-quotas-per-group_limiting-storage-space-usage-on-ext4-with-quotas" data-v-b883c74f>23.6. Assigning quotas per group</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#assigning-quotas-per-project_limiting-storage-space-usage-on-ext4-with-quotas" id="sub-link-to-managing_file_systems-assigning-quotas-per-project_limiting-storage-space-usage-on-ext4-with-quotas" data-v-b883c74f>23.7. Assigning quotas per project</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#setting-the-grace-period-for-soft-limits_limiting-storage-space-usage-on-ext4-with-quotas" id="sub-link-to-managing_file_systems-setting-the-grace-period-for-soft-limits_limiting-storage-space-usage-on-ext4-with-quotas" data-v-b883c74f>23.8. Setting the grace period for soft limits</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#turning-file-system-quotas-off_limiting-storage-space-usage-on-ext4-with-quotas" id="sub-link-to-managing_file_systems-turning-file-system-quotas-off_limiting-storage-space-usage-on-ext4-with-quotas" data-v-b883c74f>23.9. Turning file system quotas off</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#reporting-on-disk-quotas_limiting-storage-space-usage-on-ext4-with-quotas" id="sub-link-to-managing_file_systems-reporting-on-disk-quotas_limiting-storage-space-usage-on-ext4-with-quotas" data-v-b883c74f>23.10. Reporting on disk quotas</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--discarding-unused-blocks_managing-file-systems" data-v-fa0dae77><summary class="heading chapter-title" id="discarding-unused-blocks_managing-file-systems--summary" data-v-fa0dae77>24. Discarding unused blocks</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#discarding-unused-blocks_managing-file-systems" id="chapter-landing--managing_file_systems-discarding-unused-blocks_managing-file-systems" data-v-fa0dae77>Discarding unused blocks</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#types-of-block-discard-operations_discarding-unused-blocks" id="sub-link-to-managing_file_systems-types-of-block-discard-operations_discarding-unused-blocks" data-v-b883c74f>24.1. Types of block discard operations</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#performing-batch-block-discard_discarding-unused-blocks" id="sub-link-to-managing_file_systems-performing-batch-block-discard_discarding-unused-blocks" data-v-b883c74f>24.2. Performing batch block discard</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#enabling-online-block-discard_discarding-unused-blocks" id="sub-link-to-managing_file_systems-enabling-online-block-discard_discarding-unused-blocks" data-v-b883c74f>24.3. Enabling online block discard</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#enabling-periodic-block-discard_discarding-unused-blocks" id="sub-link-to-managing_file_systems-enabling-periodic-block-discard_discarding-unused-blocks" data-v-b883c74f>24.4. Enabling periodic block discard</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--setting-up-stratis-file-systems_managing-file-systems" data-v-fa0dae77><summary class="heading chapter-title" id="setting-up-stratis-file-systems_managing-file-systems--summary" data-v-fa0dae77>25. Setting up Stratis file systems</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#setting-up-stratis-file-systems_managing-file-systems" id="chapter-landing--managing_file_systems-setting-up-stratis-file-systems_managing-file-systems" data-v-fa0dae77>Setting up Stratis file systems</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#the-purpose-and-features-of-stratis_setting-up-stratis-file-systems" id="sub-link-to-managing_file_systems-the-purpose-and-features-of-stratis_setting-up-stratis-file-systems" data-v-b883c74f>25.1. What is Stratis</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#components-of-a-stratis-volume_setting-up-stratis-file-systems" id="sub-link-to-managing_file_systems-components-of-a-stratis-volume_setting-up-stratis-file-systems" data-v-b883c74f>25.2. Components of a Stratis volume</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#block-devices-usable-with-stratis_setting-up-stratis-file-systems" id="sub-link-to-managing_file_systems-block-devices-usable-with-stratis_setting-up-stratis-file-systems" data-v-b883c74f>25.3. Block devices usable with Stratis</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#installing-stratis_setting-up-stratis-file-systems" id="sub-link-to-managing_file_systems-installing-stratis_setting-up-stratis-file-systems" data-v-b883c74f>25.4. Installing Stratis</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#create-unencrypted-stratis-pool_setting-up-stratis-file-systems" id="sub-link-to-managing_file_systems-create-unencrypted-stratis-pool_setting-up-stratis-file-systems" data-v-b883c74f>25.5. Creating an unencrypted Stratis pool</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#creating-an-unencrypted-stratis-pool-using-the-web-console_setting-up-stratis-file-systems" id="sub-link-to-managing_file_systems-creating-an-unencrypted-stratis-pool-using-the-web-console_setting-up-stratis-file-systems" data-v-b883c74f>25.6. Creating an unencrypted Stratis pool by using the web console</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#create-encrypted-stratis-pool_setting-up-stratis-file-systems" id="sub-link-to-managing_file_systems-create-encrypted-stratis-pool_setting-up-stratis-file-systems" data-v-b883c74f>25.7. Creating an encrypted Stratis pool</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#creating-an-encrypted-stratis-pool-using-the-web-console_setting-up-stratis-file-systems" id="sub-link-to-managing_file_systems-creating-an-encrypted-stratis-pool-using-the-web-console_setting-up-stratis-file-systems" data-v-b883c74f>25.8. Creating an encrypted Stratis pool by using the web console</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#renaming-a-stratis-pool-using-the-web-console_setting-up-stratis-file-systems" id="sub-link-to-managing_file_systems-renaming-a-stratis-pool-using-the-web-console_setting-up-stratis-file-systems" data-v-b883c74f>25.9. Renaming a Stratis pool by using the web console</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_setting-overprovisioning-mode-in-stratis-fs_setting-up-stratis-file-systems" id="sub-link-to-managing_file_systems-proc_setting-overprovisioning-mode-in-stratis-fs_setting-up-stratis-file-systems" data-v-b883c74f>25.10. Setting overprovisioning mode in Stratis filesystem</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#bind-stratis-pool-nbde_setting-up-stratis-file-systems" id="sub-link-to-managing_file_systems-bind-stratis-pool-nbde_setting-up-stratis-file-systems" data-v-b883c74f>25.11. Binding a Stratis pool to NBDE</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#bind-stratis-pool-tpm_setting-up-stratis-file-systems" id="sub-link-to-managing_file_systems-bind-stratis-pool-tpm_setting-up-stratis-file-systems" data-v-b883c74f>25.12. Binding a Stratis pool to TPM</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#unlock-encrypted-stratis-pool-keyring_setting-up-stratis-file-systems" id="sub-link-to-managing_file_systems-unlock-encrypted-stratis-pool-keyring_setting-up-stratis-file-systems" data-v-b883c74f>25.13. Unlocking an encrypted Stratis pool with kernel keyring</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#unbind-encrypted-stratis-pool-from-supplementary-encryption_setting-up-stratis-file-systems" id="sub-link-to-managing_file_systems-unbind-encrypted-stratis-pool-from-supplementary-encryption_setting-up-stratis-file-systems" data-v-b883c74f>25.14. Unbinding a Stratis pool from supplementary encryption</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_starting-and-stopping-stratis-pool_setting-up-stratis-file-systems" id="sub-link-to-managing_file_systems-proc_starting-and-stopping-stratis-pool_setting-up-stratis-file-systems" data-v-b883c74f>25.15. Starting and stopping Stratis pool</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#creating-a-stratis-file-system_setting-up-stratis-file-systems" id="sub-link-to-managing_file_systems-creating-a-stratis-file-system_setting-up-stratis-file-systems" data-v-b883c74f>25.16. Creating a Stratis file system</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#creating-a-file-system-on-a-stratis-pool-using-the-web-console_setting-up-stratis-file-systems" id="sub-link-to-managing_file_systems-creating-a-file-system-on-a-stratis-pool-using-the-web-console_setting-up-stratis-file-systems" data-v-b883c74f>25.17. Creating a file system on a Stratis pool by using the web console</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#mounting-a-stratis-file-system_setting-up-stratis-file-systems" id="sub-link-to-managing_file_systems-mounting-a-stratis-file-system_setting-up-stratis-file-systems" data-v-b883c74f>25.18. Mounting a Stratis file system</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#persistently-mounting-a-stratis-file-system_setting-up-stratis-file-systems" id="sub-link-to-managing_file_systems-persistently-mounting-a-stratis-file-system_setting-up-stratis-file-systems" data-v-b883c74f>25.19. Persistently mounting a Stratis file system</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_setting-up-non-root-stratis-fs-fstab-systemd_setting-up-stratis-file-systems" id="sub-link-to-managing_file_systems-proc_setting-up-non-root-stratis-fs-fstab-systemd_setting-up-stratis-file-systems" data-v-b883c74f>25.20. Setting up non-root Stratis filesystems in /etc/fstab using a systemd service</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--extending-a-stratis-volume-with-additional-block-devices_managing-file-systems" data-v-fa0dae77><summary class="heading chapter-title" id="extending-a-stratis-volume-with-additional-block-devices_managing-file-systems--summary" data-v-fa0dae77>26. Extending a Stratis volume with additional block devices</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#extending-a-stratis-volume-with-additional-block-devices_managing-file-systems" id="chapter-landing--managing_file_systems-extending-a-stratis-volume-with-additional-block-devices_managing-file-systems" data-v-fa0dae77>Extending a Stratis volume with additional block devices</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#components-of-a-stratis-volume_extending-a-stratis-volume-with-additional-block-devices" id="sub-link-to-managing_file_systems-components-of-a-stratis-volume_extending-a-stratis-volume-with-additional-block-devices" data-v-b883c74f>26.1. Components of a Stratis volume</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#adding-block-devices-to-a-stratis-pool_extending-a-stratis-volume-with-additional-block-devices" id="sub-link-to-managing_file_systems-adding-block-devices-to-a-stratis-pool_extending-a-stratis-volume-with-additional-block-devices" data-v-b883c74f>26.2. Adding block devices to a Stratis pool</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#adding-a-block-device-to-a-stratis-pool-using-the-web-console_extending-a-stratis-volume-with-additional-block-devices" id="sub-link-to-managing_file_systems-adding-a-block-device-to-a-stratis-pool-using-the-web-console_extending-a-stratis-volume-with-additional-block-devices" data-v-b883c74f>26.3. Adding a block device to a Stratis pool by using the web console</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#additional_resources" id="sub-link-to-managing_file_systems-additional_resources" data-v-b883c74f>26.4. Additional resources</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--monitoring-stratis-file-systems_managing-file-systems" data-v-fa0dae77><summary class="heading chapter-title" id="monitoring-stratis-file-systems_managing-file-systems--summary" data-v-fa0dae77>27. Monitoring Stratis file systems</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#monitoring-stratis-file-systems_managing-file-systems" id="chapter-landing--managing_file_systems-monitoring-stratis-file-systems_managing-file-systems" data-v-fa0dae77>Monitoring Stratis file systems</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#stratis-sizes-reported-by-different-utilities_monitoring-stratis-file-systems" id="sub-link-to-managing_file_systems-stratis-sizes-reported-by-different-utilities_monitoring-stratis-file-systems" data-v-b883c74f>27.1. Stratis sizes reported by different utilities</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#displaying-information-about-stratis-volumes_monitoring-stratis-file-systems" id="sub-link-to-managing_file_systems-displaying-information-about-stratis-volumes_monitoring-stratis-file-systems" data-v-b883c74f>27.2. Displaying information about Stratis volumes</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#viewing-a-stratis-pool-using-the-web-console_monitoring-stratis-file-systems" id="sub-link-to-managing_file_systems-viewing-a-stratis-pool-using-the-web-console_monitoring-stratis-file-systems" data-v-b883c74f>27.3. Viewing a Stratis pool by using the web console</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#additional_resources_2" id="sub-link-to-managing_file_systems-additional_resources_2" data-v-b883c74f>27.4. Additional resources</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--using-snapshots-on-stratis-file-systems_managing-file-systems" data-v-fa0dae77><summary class="heading chapter-title" id="using-snapshots-on-stratis-file-systems_managing-file-systems--summary" data-v-fa0dae77>28. Using snapshots on Stratis file systems</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#using-snapshots-on-stratis-file-systems_managing-file-systems" id="chapter-landing--managing_file_systems-using-snapshots-on-stratis-file-systems_managing-file-systems" data-v-fa0dae77>Using snapshots on Stratis file systems</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#characteristics-of-stratis-snapshots_using-snapshots-on-stratis-file-systems" id="sub-link-to-managing_file_systems-characteristics-of-stratis-snapshots_using-snapshots-on-stratis-file-systems" data-v-b883c74f>28.1. Characteristics of Stratis snapshots</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#creating-a-stratis-snapshot_using-snapshots-on-stratis-file-systems" id="sub-link-to-managing_file_systems-creating-a-stratis-snapshot_using-snapshots-on-stratis-file-systems" data-v-b883c74f>28.2. Creating a Stratis snapshot</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#accessing-the-content-of-a-stratis-snapshot_using-snapshots-on-stratis-file-systems" id="sub-link-to-managing_file_systems-accessing-the-content-of-a-stratis-snapshot_using-snapshots-on-stratis-file-systems" data-v-b883c74f>28.3. Accessing the content of a Stratis snapshot</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#reverting-a-stratis-file-system-to-a-previous-snapshot_using-snapshots-on-stratis-file-systems" id="sub-link-to-managing_file_systems-reverting-a-stratis-file-system-to-a-previous-snapshot_using-snapshots-on-stratis-file-systems" data-v-b883c74f>28.4. Reverting a Stratis file system to a previous snapshot</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#removing-a-stratis-snapshot_using-snapshots-on-stratis-file-systems" id="sub-link-to-managing_file_systems-removing-a-stratis-snapshot_using-snapshots-on-stratis-file-systems" data-v-b883c74f>28.5. Removing a Stratis snapshot</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#additional_resources_3" id="sub-link-to-managing_file_systems-additional_resources_3" data-v-b883c74f>28.6. Additional resources</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--removing-stratis-file-systems_managing-file-systems" data-v-fa0dae77><summary class="heading chapter-title" id="removing-stratis-file-systems_managing-file-systems--summary" data-v-fa0dae77>29. Removing Stratis file systems</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#removing-stratis-file-systems_managing-file-systems" id="chapter-landing--managing_file_systems-removing-stratis-file-systems_managing-file-systems" data-v-fa0dae77>Removing Stratis file systems</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#components-of-a-stratis-volume_removing-stratis-file-systems" id="sub-link-to-managing_file_systems-components-of-a-stratis-volume_removing-stratis-file-systems" data-v-b883c74f>29.1. Components of a Stratis volume</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#removing-a-stratis-file-system_removing-stratis-file-systems" id="sub-link-to-managing_file_systems-removing-a-stratis-file-system_removing-stratis-file-systems" data-v-b883c74f>29.2. Removing a Stratis file system</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#deleting-a-file-system-from-a-stratis-pool-using-the-web-console_removing-stratis-file-systems" id="sub-link-to-managing_file_systems-deleting-a-file-system-from-a-stratis-pool-using-the-web-console_removing-stratis-file-systems" data-v-b883c74f>29.3. Deleting a file system from a Stratis pool by using the web console</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#removing-a-stratis-pool_removing-stratis-file-systems" id="sub-link-to-managing_file_systems-removing-a-stratis-pool_removing-stratis-file-systems" data-v-b883c74f>29.4. Removing a Stratis pool</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#deleting-a-stratis-pool-using-the-web-console_removing-stratis-file-systems" id="sub-link-to-managing_file_systems-deleting-a-stratis-pool-using-the-web-console_removing-stratis-file-systems" data-v-b883c74f>29.5. Deleting a Stratis pool by using the web console</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#additional_resources_4" id="sub-link-to-managing_file_systems-additional_resources_4" data-v-b883c74f>29.6. Additional resources</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--getting-started-with-an-ext4-file-system_managing-file-systems" data-v-fa0dae77><summary class="heading chapter-title" id="getting-started-with-an-ext4-file-system_managing-file-systems--summary" data-v-fa0dae77>30. Getting started with an ext4 file system</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#getting-started-with-an-ext4-file-system_managing-file-systems" id="chapter-landing--managing_file_systems-getting-started-with-an-ext4-file-system_managing-file-systems" data-v-fa0dae77>Getting started with an ext4 file system</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#features-of-an-ext4-file-system_getting-started-with-an-ext4-file-system" id="sub-link-to-managing_file_systems-features-of-an-ext4-file-system_getting-started-with-an-ext4-file-system" data-v-b883c74f>30.1. Features of an ext4 file system</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#creating-an-ext4-file-system_getting-started-with-an-ext4-file-system" id="sub-link-to-managing_file_systems-creating-an-ext4-file-system_getting-started-with-an-ext4-file-system" data-v-b883c74f>30.2. Creating an ext4 file system</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#mounting-an-ext4-file-system_getting-started-with-an-ext4-file-system" id="sub-link-to-managing_file_systems-mounting-an-ext4-file-system_getting-started-with-an-ext4-file-system" data-v-b883c74f>30.3. Mounting an ext4 file system</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#resizing-an-ext4-file-system_getting-started-with-an-ext4-file-system" id="sub-link-to-managing_file_systems-resizing-an-ext4-file-system_getting-started-with-an-ext4-file-system" data-v-b883c74f>30.4. Resizing an ext4 file system</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#comparison-of-tools-used-with-ext4-and-xfs_getting-started-with-an-ext4-file-system" id="sub-link-to-managing_file_systems-comparison-of-tools-used-with-ext4-and-xfs_getting-started-with-an-ext4-file-system" data-v-b883c74f>30.5. Comparison of tools used with ext4 and XFS</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><a class="link" href="#idm139822467588976" id="chapter-landing--managing_file_systems-idm139822467588976" data-v-fa0dae77>Legal Notice</a></li><!--]--></ol></nav><!----></div></div></aside><article class="content span-xs-12 span-sm-6 span-md-12 span-lg-7" aria-live="polite" data-v-8589d091><!----><div lang="en-us" xml:lang="en-us" class="docs-content-container" data-v-8589d091><!----><!----><h1 data-id="content_chapter" class="chapter-title" data-v-8589d091>Managing file systems</h1><hr class="line-below-chp" data-v-8589d091><section class="rhdocs" data-v-8589d091><body><div xml:lang="en-US" class="book" id="idm139822467671200"><div class="titlepage"><div><div class="producttitle"><span class="productname">Red Hat Enterprise Linux</span> <span class="productnumber">9</span></div><div><h3 class="subtitle">Creating, modifying, and administering file systems in Red Hat Enterprise Linux 9</h3></div><div><div xml:lang="en-US" class="authorgroup"><span class="orgname">Red Hat</span> <span class="orgdiv">Customer Content Services</span></div></div><div><a href="#idm139822467588976">Legal Notice</a></div><div><div class="abstract"><p class="title"><strong>Abstract</strong></p><div class="para">
				Red Hat Enterprise Linux supports a variety of file systems. Each type of file system solves different problems and their usage is application specific. Use the information about the key differences and considerations to select and deploy the appropriate file system based on your specific application requirements.
			</div><div class="para">
				The supported file systems include local on-disk file systems XFS and ext4, network and client-and-server file systems NFS and SMB, as well as a combined local storage and file system management solution, Stratis. You can perform several operations with a file system such as creating, mounting, backing up, restoring, checking and repairing, as well as limiting the storage space by using quotas.
			</div></div></div></div><hr></div><section class="preface" id="proc_providing-feedback-on-red-hat-documentation_managing-file-systems"><div class="titlepage"><div><div><h2 class="title">Providing feedback on Red Hat documentation</h2></div></div></div><p class="_abstract _abstract">
			We appreciate your feedback on our documentation. Let us know how we can improve it.
		</p><div class="orderedlist"><p class="title"><strong>Submitting feedback through Jira (account required)</strong></p><ol class="orderedlist" type="1"><li class="listitem">
					Log in to the <a class="link" href="https://issues.redhat.com/projects/RHELDOCS/issues">Jira</a> website.
				</li><li class="listitem">
					Click <span class="strong strong"><strong>Create</strong></span> in the top navigation bar
				</li><li class="listitem">
					Enter a descriptive title in the <span class="strong strong"><strong>Summary</strong></span> field.
				</li><li class="listitem">
					Enter your suggestion for improvement in the <span class="strong strong"><strong>Description</strong></span> field. Include links to the relevant parts of the documentation.
				</li><li class="listitem">
					Click <span class="strong strong"><strong>Create</strong></span> at the bottom of the dialogue.
				</li></ol></div></section><section class="chapter" id="overview-of-available-file-systems_managing-file-systems"><div class="titlepage"><div><div><h2 class="title">Chapter 1. Overview of available file systems</h2></div></div></div><p>
			Choosing the file system that is appropriate for your application is an important decision due to the large number of options available and the trade-offs involved.
		</p><p>
			The following sections describe the file systems that Red Hat Enterprise Linux 9 includes by default, and recommendations on the most suitable file system for your application.
		</p><section class="section" id="types-of-file-systems_overview-of-available-file-systems"><div class="titlepage"><div><div><h3 class="title">1.1. Types of file systems</h3></div></div></div><p class="_abstract _abstract">
				Red Hat Enterprise Linux 9 supports a variety of file systems (FS). Different types of file systems solve different kinds of problems, and their usage is application specific. At the most general level, available file systems can be grouped into the following major types:
			</p><rh-table id="idm139822465608160"><table class="lt-4-cols lt-7-rows"><caption>Table 1.1. Types of file systems and their use cases</caption><colgroup><col style="width: 25%; " class="col_1"><!--Empty--><col style="width: 25%; " class="col_2"><!--Empty--><col style="width: 50%; " class="col_3"><!--Empty--></colgroup><thead><tr><th align="left" valign="top" id="idm139822456768464" scope="col">Type</th><th align="left" valign="top" id="idm139822456767376" scope="col">File system</th><th align="left" valign="top" id="idm139822456766288" scope="col">Attributes and use cases</th></tr></thead><tbody><tr><td rowspan="2" align="left" valign="top" headers="idm139822456768464"> <p>
								Disk or local FS
							</p>
							 </td><td align="left" valign="top" headers="idm139822456767376"> <p>
								XFS
							</p>
							 </td><td align="left" valign="top" headers="idm139822456766288"> <p>
								XFS is the default file system in RHEL. Red Hat recommends deploying XFS as your local file system unless there are specific reasons to do otherwise: for example, compatibility or corner cases around performance.
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822456767376"> <p>
								ext4
							</p>
							 </td><td align="left" valign="top" headers="idm139822456766288"> <p>
								ext4 has the benefit of familiarity in Linux, having evolved from the older ext2 and ext3 file systems. In many cases, it rivals XFS on performance. Support limits for ext4 filesystem and file sizes are lower than those on XFS.
							</p>
							 </td></tr><tr><td rowspan="2" align="left" valign="top" headers="idm139822456768464"> <p>
								Network or client-and-server FS
							</p>
							 </td><td align="left" valign="top" headers="idm139822456767376"> <p>
								NFS
							</p>
							 </td><td align="left" valign="top" headers="idm139822456766288"> <p>
								Use NFS to share files between multiple systems on the same network.
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822456767376"> <p>
								SMB
							</p>
							 </td><td align="left" valign="top" headers="idm139822456766288"> <p>
								Use SMB for file sharing with Microsoft Windows systems.
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822456768464"> <p>
								Shared storage or shared disk FS
							</p>
							 </td><td align="left" valign="top" headers="idm139822456767376"> <p>
								GFS2
							</p>
							 </td><td align="left" valign="top" headers="idm139822456766288"> <p>
								GFS2 provides shared write access to members of a compute cluster. The emphasis is on stability and reliability, with the functional experience of a local file system as possible. SAS Grid, Tibco MQ, IBM Websphere MQ, and Red Hat Active MQ have been deployed successfully on GFS2.
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822456768464"> <p>
								Volume-managing FS
							</p>
							 </td><td align="left" valign="top" headers="idm139822456767376"> <p>
								Stratis
							</p>
							 </td><td align="left" valign="top" headers="idm139822456766288"> <p>
								Stratis is a volume manager built on a combination of XFS and LVM. The purpose of Stratis is to emulate capabilities offered by volume-managing file systems like Btrfs and ZFS. It is possible to build this stack manually, but Stratis reduces configuration complexity, implements best practices, and consolidates error information.
							</p>
							 </td></tr></tbody></table></rh-table></section><section class="section" id="local-file-systems_overview-of-available-file-systems"><div class="titlepage"><div><div><h3 class="title">1.2. Local file systems</h3></div></div></div><p class="_abstract _abstract">
				Local file systems are file systems that run on a single, local server and are directly attached to storage.
			</p><p>
				For example, a local file system is the only choice for internal SATA or SAS disks, and is used when your server has internal hardware RAID controllers with local drives. Local file systems are also the most common file systems used on SAN attached storage when the device exported on the SAN is not shared.
			</p><p>
				All local file systems are POSIX-compliant and are fully compatible with all supported Red Hat Enterprise Linux releases. POSIX-compliant file systems provide support for a well-defined set of system calls, such as <code class="literal">read()</code>, <code class="literal">write()</code>, and <code class="literal">seek()</code>.
			</p><p>
				When considering a file system choice, choose a file system based on how large the file system needs to be, what unique features it must have, and how it performs under your workload.
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">Available local file systems</span></dt><dd><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									XFS
								</li><li class="listitem">
									ext4
								</li></ul></div></dd></dl></div></section><section class="section" id="the-xfs-file-system_overview-of-available-file-systems"><div class="titlepage"><div><div><h3 class="title">1.3. The XFS file system</h3></div></div></div><p class="_abstract _abstract">
				XFS is a highly scalable, high-performance, robust, and mature 64-bit journaling file system that supports very large files and file systems on a single host. It is the default file system in Red Hat Enterprise Linux 9. XFS was originally developed in the early 1990s by SGI and has a long history of running on extremely large servers and storage arrays.
			</p><p>
				The features of XFS include:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">Reliability</span></dt><dd><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									Metadata journaling, which ensures file system integrity after a system crash by keeping a record of file system operations that can be replayed when the system is restarted and the file system remounted
								</li><li class="listitem">
									Extensive run-time metadata consistency checking
								</li><li class="listitem">
									Scalable and fast repair utilities
								</li><li class="listitem">
									Quota journaling. This avoids the need for lengthy quota consistency checks after a crash.
								</li></ul></div></dd><dt><span class="term">Scalability and performance</span></dt><dd><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									Supported file system size up to 1024 TiB
								</li><li class="listitem">
									Ability to support a large number of concurrent operations
								</li><li class="listitem">
									B-tree indexing for scalability of free space management
								</li><li class="listitem">
									Sophisticated metadata read-ahead algorithms
								</li><li class="listitem">
									Optimizations for streaming video workloads
								</li></ul></div></dd><dt><span class="term">Allocation schemes</span></dt><dd><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									Extent-based allocation
								</li><li class="listitem">
									Stripe-aware allocation policies
								</li><li class="listitem">
									Delayed allocation
								</li><li class="listitem">
									Space pre-allocation
								</li><li class="listitem">
									Dynamically allocated inodes
								</li></ul></div></dd><dt><span class="term">Other features</span></dt><dd><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									Reflink-based file copies
								</li><li class="listitem">
									Tightly integrated backup and restore utilities
								</li><li class="listitem">
									Online defragmentation
								</li><li class="listitem">
									Online file system growing
								</li><li class="listitem">
									Comprehensive diagnostics capabilities
								</li><li class="listitem">
									Extended attributes (<code class="literal">xattr</code>). This allows the system to associate several additional name/value pairs per file.
								</li><li class="listitem">
									Project or directory quotas. This allows quota restrictions over a directory tree.
								</li><li class="listitem">
									Subsecond timestamps
								</li></ul></div></dd></dl></div><div class="formalpara"><p class="title"><strong>Performance characteristics</strong></p><p>
					XFS has a high performance on large systems with enterprise workloads. A large system is one with a relatively high number of CPUs, multiple HBAs, and connections to external disk arrays. XFS also performs well on smaller systems that have a multi-threaded, parallel I/O workload.
				</p></div><p>
				XFS has a relatively low performance for single threaded, metadata-intensive workloads: for example, a workload that creates or deletes large numbers of small files in a single thread.
			</p></section><section class="section" id="the-ext4-file-system_overview-of-available-file-systems"><div class="titlepage"><div><div><h3 class="title">1.4. The ext4 file system</h3></div></div></div><p class="_abstract _abstract">
				The ext4 file system is the fourth generation of the ext file system family. It was the default file system in Red Hat Enterprise Linux 6.
			</p><p>
				The ext4 driver can read and write to ext2 and ext3 file systems, but the ext4 file system format is not compatible with ext2 and ext3 drivers.
			</p><p>
				ext4 adds several new and improved features, such as:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Supported file system size up to 50 TiB
					</li><li class="listitem">
						Extent-based metadata
					</li><li class="listitem">
						Delayed allocation
					</li><li class="listitem">
						Journal checksumming
					</li><li class="listitem">
						Large storage support
					</li></ul></div><p>
				The extent-based metadata and the delayed allocation features provide a more compact and efficient way to track utilized space in a file system. These features improve file system performance and reduce the space consumed by metadata. Delayed allocation allows the file system to postpone selection of the permanent location for newly written user data until the data is flushed to disk. This enables higher performance since it can allow for larger, more contiguous allocations, allowing the file system to make decisions with much better information.
			</p><p>
				File system repair time using the <code class="literal">fsck</code> utility in ext4 is much faster than in ext2 and ext3. Some file system repairs have demonstrated up to a six-fold increase in performance.
			</p></section><section class="section" id="comparison-of-xfs-and-ext4_overview-of-available-file-systems"><div class="titlepage"><div><div><h3 class="title">1.5. Comparison of XFS and ext4</h3></div></div></div><p class="_abstract _abstract">
				XFS is the default file system in RHEL. This section compares the usage and features of XFS and ext4.
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">Metadata error behavior</span></dt><dd>
							In ext4, you can configure the behavior when the file system encounters metadata errors. The default behavior is to simply continue the operation. When XFS encounters an unrecoverable metadata error, it shuts down the file system and returns the <code class="literal">EFSCORRUPTED</code> error.
						</dd><dt><span class="term">Quotas</span></dt><dd><p class="simpara">
							In ext4, you can enable quotas when creating the file system or later on an existing file system. You can then configure the quota enforcement using a mount option.
						</p><p class="simpara">
							XFS quotas are not a remountable option. You must activate quotas on the initial mount.
						</p><p class="simpara">
							Running the <code class="literal">quotacheck</code> command on an XFS file system has no effect. The first time you turn on quota accounting, XFS checks quotas automatically.
						</p></dd><dt><span class="term">File system resize</span></dt><dd>
							XFS has no utility to reduce the size of a file system. You can only increase the size of an XFS file system. In comparison, ext4 supports both extending and reducing the size of a file system.
						</dd><dt><span class="term">Inode numbers</span></dt><dd><p class="simpara">
							The ext4 file system does not support more than 2<sup>32</sup> inodes.
						</p><p class="simpara">
							XFS supports dynamic inode allocation. The amount of space inodes can consume on an XFS filesystem is calculated as a percentage of the total filesystem space. To prevent the system from running out of inodes, an administrator can tune this percentage after the filesystem has been created, given there is free space left on the file system.
						</p><p class="simpara">
							Certain applications cannot properly handle inode numbers larger than 2<sup>32</sup> on an XFS file system. These applications might cause the failure of 32-bit stat calls with the <code class="literal">EOVERFLOW</code> return value. Inode number exceed 2<sup>32</sup> under the following conditions:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									The file system is larger than 1 TiB with 256-byte inodes.
								</li><li class="listitem">
									The file system is larger than 2 TiB with 512-byte inodes.
								</li></ul></div><p class="simpara">
							If your application fails with large inode numbers, mount the XFS file system with the <code class="literal">-o inode32</code> option to enforce inode numbers below 2<sup>32</sup>. Note that using <code class="literal">inode32</code> does not affect inodes that are already allocated with 64-bit numbers.
						</p><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
								Do <span class="emphasis"><em>not</em></span> use the <code class="literal">inode32</code> option unless a specific environment requires it. The <code class="literal">inode32</code> option changes allocation behavior. As a consequence, the <code class="literal">ENOSPC</code> error might occur if no space is available to allocate inodes in the lower disk blocks.
							</p></div></rh-alert></dd></dl></div></section><section class="section" id="choosing-a-local-file-system_overview-of-available-file-systems"><div class="titlepage"><div><div><h3 class="title">1.6. Choosing a local file system</h3></div></div></div><p class="_abstract _abstract">
				To choose a file system that meets your application requirements, you must understand the target system on which you will deploy the file system. In general, use XFS unless you have a specific use case for ext4.
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">XFS</span></dt><dd>
							For large-scale deployments, use XFS, particularly when handling large files (hundreds of megabytes) and high I/O concurrency. XFS performs optimally in environments with high bandwidth (greater than 200MB/s) and more than 1000 IOPS. However, it consumes more CPU resources for metadata operations compared to ext4 and does not support file system shrinking.
						</dd><dt><span class="term">ext4</span></dt><dd>
							For smaller systems or environments with limited I/O bandwidth, ext4 might be a better fit. It performs better in single-threaded, lower I/O workloads and environments with lower throughput requirements. ext4 also supports offline shrinking, which can be beneficial if resizing the file system is a requirement.
						</dd></dl></div><p>
				Benchmark your application’s performance on your target server and storage system to ensure the selected file system meets your performance and scalability requirements.
			</p><rh-table id="idm139822460888464"><table class="lt-4-cols lt-7-rows"><caption>Table 1.2. Summary of local file system recommendations</caption><colgroup><col style="width: 60%; " class="col_1"><!--Empty--><col style="width: 40%; " class="col_2"><!--Empty--></colgroup><thead><tr><th align="left" valign="top" id="idm139822456927488" scope="col">Scenario</th><th align="left" valign="top" id="idm139822456926400" scope="col">Recommended file system</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm139822456927488"> <p>
								No special use case
							</p>
							 </td><td align="left" valign="top" headers="idm139822456926400"> <p>
								XFS
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822456927488"> <p>
								Large server
							</p>
							 </td><td align="left" valign="top" headers="idm139822456926400"> <p>
								XFS
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822456927488"> <p>
								Large storage devices
							</p>
							 </td><td align="left" valign="top" headers="idm139822456926400"> <p>
								XFS
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822456927488"> <p>
								Large files
							</p>
							 </td><td align="left" valign="top" headers="idm139822456926400"> <p>
								XFS
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822456927488"> <p>
								Multi-threaded I/O
							</p>
							 </td><td align="left" valign="top" headers="idm139822456926400"> <p>
								XFS
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822456927488"> <p>
								Single-threaded I/O
							</p>
							 </td><td align="left" valign="top" headers="idm139822456926400"> <p>
								ext4
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822456927488"> <p>
								Limited I/O capability (under 1000 IOPS)
							</p>
							 </td><td align="left" valign="top" headers="idm139822456926400"> <p>
								ext4
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822456927488"> <p>
								Limited bandwidth (under 200MB/s)
							</p>
							 </td><td align="left" valign="top" headers="idm139822456926400"> <p>
								ext4
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822456927488"> <p>
								CPU-bound workload
							</p>
							 </td><td align="left" valign="top" headers="idm139822456926400"> <p>
								ext4
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822456927488"> <p>
								Support for offline shrinking
							</p>
							 </td><td align="left" valign="top" headers="idm139822456926400"> <p>
								ext4
							</p>
							 </td></tr></tbody></table></rh-table></section><section class="section" id="network-file-systems_overview-of-available-file-systems"><div class="titlepage"><div><div><h3 class="title">1.7. Network file systems</h3></div></div></div><p class="_abstract _abstract">
				Network file systems, also referred to as client/server file systems, enable client systems to access files that are stored on a shared server. This makes it possible for multiple users on multiple systems to share files and storage resources.
			</p><p>
				Such file systems are built from one or more servers that export a set of file systems to one or more clients. The client nodes do not have access to the underlying block storage, but rather interact with the storage using a protocol that allows for better access control.
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">Available network file systems</span></dt><dd><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									The most common client/server file system for RHEL customers is the NFS file system. RHEL provides both an NFS server component to export a local file system over the network and an NFS client to import these file systems.
								</li><li class="listitem">
									RHEL also includes a CIFS client that supports the popular Microsoft SMB file servers for Windows interoperability. The userspace Samba server provides Windows clients with a Microsoft SMB service from a RHEL server.
								</li></ul></div></dd></dl></div></section><section class="section" id="shared-storage-file-systems_overview-of-available-file-systems"><div class="titlepage"><div><div><h3 class="title">1.8. Shared storage file systems</h3></div></div></div><p class="_abstract _abstract">
				Shared storage file systems, sometimes referred to as cluster file systems, give each server in the cluster direct access to a shared block device over a local storage area network (SAN).
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">Comparison with network file systems</span></dt><dd>
							Like client/server file systems, shared storage file systems work on a set of servers that are all members of a cluster. Unlike NFS, however, no single server provides access to data or metadata to other members: each member of the cluster has direct access to the same storage device (the <span class="emphasis"><em>shared storage</em></span>), and all cluster member nodes access the same set of files.
						</dd><dt><span class="term">Concurrency</span></dt><dd><p class="simpara">
							Cache coherency is key in a clustered file system to ensure data consistency and integrity. There must be a single version of all files in a cluster visible to all nodes within a cluster. The file system must prevent members of the cluster from updating the same storage block at the same time and causing data corruption. In order to do that, shared storage file systems use a cluster wide-locking mechanism to arbitrate access to the storage as a concurrency control mechanism. For example, before creating a new file or writing to a file that is opened on multiple servers, the file system component on the server must obtain the correct lock.
						</p><p class="simpara">
							The requirement of cluster file systems is to provide a highly available service like an Apache web server. Any member of the cluster will see a fully coherent view of the data stored in their shared disk file system, and all updates will be arbitrated correctly by the locking mechanisms.
						</p></dd><dt><span class="term">Performance characteristics</span></dt><dd><p class="simpara">
							Shared disk file systems do not always perform as well as local file systems running on the same system due to the computational cost of the locking overhead. Shared disk file systems perform well with workloads where each node writes almost exclusively to a particular set of files that are not shared with other nodes or where a set of files is shared in an almost exclusively read-only manner across a set of nodes. This results in a minimum of cross-node cache invalidation and can maximize performance.
						</p><p class="simpara">
							Setting up a shared disk file system is complex, and tuning an application to perform well on a shared disk file system can be challenging.
						</p></dd><dt><span class="term">Available shared storage file systems</span></dt><dd><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									Red Hat Enterprise Linux provides the GFS2 file system. GFS2 comes tightly integrated with the Red Hat Enterprise Linux High Availability Add-On and the Resilient Storage Add-On.
								</li></ul></div><p class="simpara">
							Red Hat Enterprise Linux supports GFS2 on clusters that range in size from 2 to 16 nodes.
						</p></dd></dl></div></section><section class="section" id="choosing-between-network-and-shared-storage-file-systems_overview-of-available-file-systems"><div class="titlepage"><div><div><h3 class="title">1.9. Choosing between network and shared storage file systems</h3></div></div></div><p class="_abstract _abstract">
				When choosing between network and shared storage file systems, consider the following points:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						NFS-based network file systems are an extremely common and popular choice for environments that provide NFS servers.
					</li><li class="listitem">
						Network file systems can be deployed using very high-performance networking technologies like Infiniband or 10 Gigabit Ethernet. This means that you should not turn to shared storage file systems just to get raw bandwidth to your storage. If the speed of access is of prime importance, then use NFS to export a local file system like XFS.
					</li><li class="listitem">
						Shared storage file systems are not easy to set up or to maintain, so you should deploy them only when you cannot provide your required availability with either local or network file systems.
					</li><li class="listitem">
						A shared storage file system in a clustered environment helps reduce downtime by eliminating the steps needed for unmounting and mounting that need to be done during a typical fail-over scenario involving the relocation of a high-availability service.
					</li></ul></div><p>
				Red Hat recommends that you use network file systems unless you have a specific use case for shared storage file systems. Use shared storage file systems primarily for deployments that need to provide high-availability services with minimum downtime and have stringent service-level requirements.
			</p></section><section class="section" id="volume-managing-file-systems_overview-of-available-file-systems"><div class="titlepage"><div><div><h3 class="title">1.10. Volume-managing file systems</h3></div></div></div><p class="_abstract _abstract">
				Volume-managing file systems integrate the entire storage stack for the purposes of simplicity and in-stack optimization.
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">Available volume-managing file systems</span></dt><dd><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									Red Hat Enterprise Linux 9 provides the Stratis volume manager. Stratis uses XFS for the file system layer and integrates it with LVM, Device Mapper, and other components.
								</li></ul></div><p class="simpara">
							Stratis was first released in Red Hat Enterprise Linux 8.0. It is conceived to fill the gap created when Red Hat deprecated Btrfs. Stratis 1.0 is an intuitive, command line-based volume manager that can perform significant storage management operations while hiding the complexity from the user:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									Volume management
								</li><li class="listitem">
									Pool creation
								</li><li class="listitem">
									Thin storage pools
								</li><li class="listitem">
									Snapshots
								</li><li class="listitem">
									Automated read cache
								</li></ul></div><p class="simpara">
							Stratis offers powerful features, but currently lacks certain capabilities of other offerings that it might be compared to, such as Btrfs or ZFS. Most notably, it does not support CRCs with self healing.
						</p></dd></dl></div></section></section><section class="chapter" id="managing-local-storage-using-rhel-system-roles_managing-file-systems"><div class="titlepage"><div><div><h2 class="title">Chapter 2. Managing local storage by using the RHEL system role</h2></div></div></div><p class="_abstract _abstract">
			To manage LVM and local file systems (FS) by using Ansible, you can use the <code class="literal">storage</code> role, which is one of the RHEL system roles available in RHEL 9.
		</p><p>
			Using the <code class="literal">storage</code> role enables you to automate administration of file systems on disks and logical volumes on multiple machines and across all versions of RHEL starting with RHEL 7.7.
		</p><p>
			For more information about RHEL system roles and how to apply them, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/intro-to-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles">Introduction to RHEL system roles</a>.
		</p><section class="section" id="storage-role-intro_managing-local-storage-using-rhel-system-roles"><div class="titlepage"><div><div><h3 class="title">2.1. Introduction to the <code class="literal">storage</code> RHEL system role</h3></div></div></div><p class="_abstract _abstract">
				The <code class="literal">storage</code> role can manage:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						File systems on disks which have not been partitioned
					</li><li class="listitem">
						Complete LVM volume groups including their logical volumes and file systems
					</li><li class="listitem">
						MD RAID volumes and their file systems
					</li></ul></div><p>
				With the <code class="literal">storage</code> role, you can perform the following tasks:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Create a file system
					</li><li class="listitem">
						Remove a file system
					</li><li class="listitem">
						Mount a file system
					</li><li class="listitem">
						Unmount a file system
					</li><li class="listitem">
						Create LVM volume groups
					</li><li class="listitem">
						Remove LVM volume groups
					</li><li class="listitem">
						Create logical volumes
					</li><li class="listitem">
						Remove logical volumes
					</li><li class="listitem">
						Create RAID volumes
					</li><li class="listitem">
						Remove RAID volumes
					</li><li class="listitem">
						Create LVM volume groups with RAID
					</li><li class="listitem">
						Remove LVM volume groups with RAID
					</li><li class="listitem">
						Create encrypted LVM volume groups
					</li><li class="listitem">
						Create LVM logical volumes with RAID
					</li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">/usr/share/ansible/roles/rhel-system-roles.storage/README.md</code> file
					</li><li class="listitem">
						<code class="literal">/usr/share/doc/rhel-system-roles/storage/</code> directory
					</li></ul></div></section><section class="section" id="an-example-ansible-playbook-to-create-an-xfs-file-system_managing-local-storage-using-rhel-system-roles"><div class="titlepage"><div><div><h3 class="title">2.2. Creating an XFS file system on a block device by using the <code class="literal">storage</code> RHEL system role</h3></div></div></div><p>
				The example Ansible playbook applies the <code class="literal">storage</code> role to create an XFS file system on a block device using the default parameters.
			</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					The <code class="literal">storage</code> role can create a file system only on an unpartitioned, whole disk or a logical volume (LV). It cannot create the file system on a partition.
				</p></div></rh-alert><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles">You have prepared the control node and the managed nodes</a>
					</li><li class="listitem">
						You are logged in to the control node as a user who can run playbooks on the managed nodes.
					</li><li class="listitem">
						The account you use to connect to the managed nodes has <code class="literal">sudo</code> permissions on them.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Create a playbook file, for example <code class="literal">~/playbook.yml</code>, with the following content:
					</p><pre class="programlisting language-yaml">---
- hosts: managed-node-01.example.com
  roles:
    - rhel-system-roles.storage
  vars:
    storage_volumes:
      - name: barefs
        type: disk
        disks:
          - sdb
        fs_type: xfs</pre><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								The volume name (<code class="literal"><span class="emphasis"><em>barefs</em></span></code> in the example) is currently arbitrary. The <code class="literal">storage</code> role identifies the volume by the disk device listed under the <code class="literal">disks:</code> attribute.
							</li><li class="listitem">
								You can omit the <code class="literal">fs_type: xfs</code> line because XFS is the default file system in RHEL 9.
							</li><li class="listitem"><p class="simpara">
								To create the file system on an LV, provide the LVM setup under the <code class="literal">disks:</code> attribute, including the enclosing volume group. For details, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_logical_volumes/managing-lvm-logical-volumes_configuring-and-managing-logical-volumes#an-example-playbook-to-manage-logical-volumes_managing-lvm-logical-volumes-using-rhel-system-roles">Managing logical volumes by using the storage RHEL system role</a>.
							</p><p class="simpara">
								Do not provide the path to the LV device.
							</p></li></ul></div></li><li class="listitem"><p class="simpara">
						Validate the playbook syntax:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-playbook --syntax-check ~/playbook.yml</strong></span></pre><p class="simpara">
						Note that this command only validates the syntax and does not protect against a wrong but valid configuration.
					</p></li><li class="listitem"><p class="simpara">
						Run the playbook:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-playbook ~/playbook.yml</strong></span></pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">/usr/share/ansible/roles/rhel-system-roles.storage/README.md</code> file
					</li><li class="listitem">
						<code class="literal">/usr/share/doc/rhel-system-roles/storage/</code> directory
					</li></ul></div></section><section class="section" id="an-example-ansible-playbook-to-persistently-mount-a-file-system_managing-local-storage-using-rhel-system-roles"><div class="titlepage"><div><div><h3 class="title">2.3. Persistently mounting a file system by using the <code class="literal">storage</code> RHEL system role</h3></div></div></div><p>
				The example Ansible applies the <code class="literal">storage</code> role to immediately and persistently mount an XFS file system.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles">You have prepared the control node and the managed nodes</a>
					</li><li class="listitem">
						You are logged in to the control node as a user who can run playbooks on the managed nodes.
					</li><li class="listitem">
						The account you use to connect to the managed nodes has <code class="literal">sudo</code> permissions on them.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Create a playbook file, for example <code class="literal">~/playbook.yml</code>, with the following content:
					</p><pre class="programlisting language-yaml">---
- hosts: managed-node-01.example.com
  roles:
    - rhel-system-roles.storage
  vars:
    storage_volumes:
      - name: barefs
        type: disk
        disks:
          - sdb
        fs_type: xfs
        mount_point: /mnt/data
        mount_user: somebody
        mount_group: somegroup
        mount_mode: 0755</pre><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								This playbook adds the file system to the <code class="literal">/etc/fstab</code> file, and mounts the file system immediately.
							</li><li class="listitem">
								If the file system on the <code class="literal">/dev/sdb</code> device or the mount point directory do not exist, the playbook creates them.
							</li></ul></div></li><li class="listitem"><p class="simpara">
						Validate the playbook syntax:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-playbook --syntax-check ~/playbook.yml</strong></span></pre><p class="simpara">
						Note that this command only validates the syntax and does not protect against a wrong but valid configuration.
					</p></li><li class="listitem"><p class="simpara">
						Run the playbook:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-playbook ~/playbook.yml</strong></span></pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">/usr/share/ansible/roles/rhel-system-roles.storage/README.md</code> file
					</li><li class="listitem">
						<code class="literal">/usr/share/doc/rhel-system-roles/storage/</code> directory
					</li></ul></div></section><section class="section" id="an-example-playbook-to-manage-logical-volumes_managing-local-storage-using-rhel-system-roles"><div class="titlepage"><div><div><h3 class="title">2.4. Managing logical volumes by using the <code class="literal">storage</code> RHEL system role</h3></div></div></div><p>
				The example Ansible playbook applies the <code class="literal">storage</code> role to create an LVM logical volume in a volume group.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles">You have prepared the control node and the managed nodes</a>
					</li><li class="listitem">
						You are logged in to the control node as a user who can run playbooks on the managed nodes.
					</li><li class="listitem">
						The account you use to connect to the managed nodes has <code class="literal">sudo</code> permissions on them.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Create a playbook file, for example <code class="literal">~/playbook.yml</code>, with the following content:
					</p><pre class="programlisting language-yaml">- hosts: managed-node-01.example.com
  roles:
    - rhel-system-roles.storage
  vars:
    storage_pools:
      - name: myvg
        disks:
          - sda
          - sdb
          - sdc
        volumes:
          - name: mylv
            size: 2G
            fs_type: ext4
            mount_point: /mnt/dat</pre><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								The <code class="literal">myvg</code> volume group consists of the following disks: <code class="literal">/dev/sda</code>, <code class="literal">/dev/sdb</code>, and <code class="literal">/dev/sdc</code>.
							</li><li class="listitem">
								If the <code class="literal">myvg</code> volume group already exists, the playbook adds the logical volume to the volume group.
							</li><li class="listitem">
								If the <code class="literal">myvg</code> volume group does not exist, the playbook creates it.
							</li><li class="listitem">
								The playbook creates an Ext4 file system on the <code class="literal">mylv</code> logical volume, and persistently mounts the file system at <code class="literal">/mnt</code>.
							</li></ul></div></li><li class="listitem"><p class="simpara">
						Validate the playbook syntax:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-playbook --syntax-check ~/playbook.yml</strong></span></pre><p class="simpara">
						Note that this command only validates the syntax and does not protect against a wrong but valid configuration.
					</p></li><li class="listitem"><p class="simpara">
						Run the playbook:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-playbook ~/playbook.yml</strong></span></pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">/usr/share/ansible/roles/rhel-system-roles.storage/README.md</code> file
					</li><li class="listitem">
						<code class="literal">/usr/share/doc/rhel-system-roles/storage/</code> directory
					</li></ul></div></section><section class="section" id="an-example-ansible-playbook-to-enable-online-block-discard_managing-local-storage-using-rhel-system-roles"><div class="titlepage"><div><div><h3 class="title">2.5. Enabling online block discard by using the <code class="literal">storage</code> RHEL system role</h3></div></div></div><p>
				The example Ansible playbook applies the <code class="literal">storage</code> role to mount an XFS file system with online block discard enabled.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles">You have prepared the control node and the managed nodes</a>
					</li><li class="listitem">
						You are logged in to the control node as a user who can run playbooks on the managed nodes.
					</li><li class="listitem">
						The account you use to connect to the managed nodes has <code class="literal">sudo</code> permissions on them.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Create a playbook file, for example <code class="literal">~/playbook.yml</code>, with the following content:
					</p><pre class="programlisting language-yaml">---
- hosts: managed-node-01.example.com
  roles:
    - rhel-system-roles.storage
  vars:
    storage_volumes:
      - name: barefs
        type: disk
        disks:
          - sdb
        fs_type: xfs
        mount_point: /mnt/data
        mount_options: discard</pre></li><li class="listitem"><p class="simpara">
						Validate the playbook syntax:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-playbook --syntax-check ~/playbook.yml</strong></span></pre><p class="simpara">
						Note that this command only validates the syntax and does not protect against a wrong but valid configuration.
					</p></li><li class="listitem"><p class="simpara">
						Run the playbook:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-playbook ~/playbook.yml</strong></span></pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">/usr/share/ansible/roles/rhel-system-roles.storage/README.md</code> file
					</li><li class="listitem">
						<code class="literal">/usr/share/doc/rhel-system-roles/storage/</code> directory
					</li></ul></div></section><section class="section" id="an-example-playbook-to-create-mount-an-ext4-file-system_managing-local-storage-using-rhel-system-roles"><div class="titlepage"><div><div><h3 class="title">2.6. Creating and mounting an Ext4 file system by using the <code class="literal">storage</code> RHEL system role</h3></div></div></div><p>
				The example Ansible playbook applies the <code class="literal">storage</code> role to create and mount an Ext4 file system.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles">You have prepared the control node and the managed nodes</a>
					</li><li class="listitem">
						You are logged in to the control node as a user who can run playbooks on the managed nodes.
					</li><li class="listitem">
						The account you use to connect to the managed nodes has <code class="literal">sudo</code> permissions on them.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Create a playbook file, for example <code class="literal">~/playbook.yml</code>, with the following content:
					</p><pre class="programlisting language-yaml">---
- hosts: managed-node-01.example.com
  roles:
    - rhel-system-roles.storage
  vars:
    storage_volumes:
      - name: barefs
        type: disk
        disks:
          - sdb
        fs_type: ext4
        fs_label: label-name
        mount_point: /mnt/data</pre><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								The playbook creates the file system on the <code class="literal">/dev/sdb</code> disk.
							</li><li class="listitem">
								The playbook persistently mounts the file system at the <code class="literal">/mnt/data</code> directory.
							</li><li class="listitem">
								The label of the file system is <code class="literal">label-name</code>.
							</li></ul></div></li><li class="listitem"><p class="simpara">
						Validate the playbook syntax:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-playbook --syntax-check ~/playbook.yml</strong></span></pre><p class="simpara">
						Note that this command only validates the syntax and does not protect against a wrong but valid configuration.
					</p></li><li class="listitem"><p class="simpara">
						Run the playbook:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-playbook ~/playbook.yml</strong></span></pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">/usr/share/ansible/roles/rhel-system-roles.storage/README.md</code> file
					</li><li class="listitem">
						<code class="literal">/usr/share/doc/rhel-system-roles/storage/</code> directory
					</li></ul></div></section><section class="section" id="an-example-ansible-playbook-to-create-mount-ext3-file-system_managing-local-storage-using-rhel-system-roles"><div class="titlepage"><div><div><h3 class="title">2.7. Creating and mounting an Ext3 file system by using the <code class="literal">storage</code> RHEL system role</h3></div></div></div><p>
				The example Ansible playbook applies the <code class="literal">storage</code> role to create and mount an Ext3 file system.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles">You have prepared the control node and the managed nodes</a>
					</li><li class="listitem">
						You are logged in to the control node as a user who can run playbooks on the managed nodes.
					</li><li class="listitem">
						The account you use to connect to the managed nodes has <code class="literal">sudo</code> permissions on them.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Create a playbook file, for example <code class="literal">~/playbook.yml</code>, with the following content:
					</p><pre class="programlisting language-yaml">---
- hosts: all
  roles:
    - rhel-system-roles.storage
  vars:
    storage_volumes:
      - name: barefs
        type: disk
        disks:
          - sdb
        fs_type: ext3
        fs_label: label-name
        mount_point: /mnt/data
        mount_user: somebody
        mount_group: somegroup
        mount_mode: 0755</pre><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								The playbook creates the file system on the <code class="literal">/dev/sdb</code> disk.
							</li><li class="listitem">
								The playbook persistently mounts the file system at the <code class="literal">/mnt/data</code> directory.
							</li><li class="listitem">
								The label of the file system is <code class="literal">label-name</code>.
							</li></ul></div></li><li class="listitem"><p class="simpara">
						Validate the playbook syntax:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-playbook --syntax-check ~/playbook.yml</strong></span></pre><p class="simpara">
						Note that this command only validates the syntax and does not protect against a wrong but valid configuration.
					</p></li><li class="listitem"><p class="simpara">
						Run the playbook:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-playbook ~/playbook.yml</strong></span></pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">/usr/share/ansible/roles/rhel-system-roles.storage/README.md</code> file
					</li><li class="listitem">
						<code class="literal">/usr/share/doc/rhel-system-roles/storage/</code> directory
					</li></ul></div></section><section class="section" id="example-ansible-playbook-to-resize-an-existing-lvm-file-system-using-the-storage-rhel-system-role_managing-local-storage-using-rhel-system-roles"><div class="titlepage"><div><div><h3 class="title">2.8. Resizing an existing file system on LVM by using the <code class="literal">storage</code> RHEL system role</h3></div></div></div><p>
				The example Ansible playbook applies the <code class="literal">storage</code> RHEL system role to resize an LVM logical volume with a file system.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles">You have prepared the control node and the managed nodes</a>
					</li><li class="listitem">
						You are logged in to the control node as a user who can run playbooks on the managed nodes.
					</li><li class="listitem">
						The account you use to connect to the managed nodes has <code class="literal">sudo</code> permissions on them.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Create a playbook file, for example <code class="literal">~/playbook.yml</code>, with the following content:
					</p><pre class="programlisting language-yaml">---
- name: Create LVM pool over three disks
  hosts: managed-node-01.example.com
  tasks:
    - name: Resize LVM logical volume with file system
      ansible.builtin.include_role:
        name: rhel-system-roles.storage
      vars:
        storage_pools:
          - name: myvg
            disks:
              - /dev/sda
              - /dev/sdb
              - /dev/sdc
            volumes:
              - name: mylv1
                size: 10 GiB
                fs_type: ext4
                mount_point: /opt/mount1
              - name: mylv2
                size: 50 GiB
                fs_type: ext4
                mount_point: /opt/mount2</pre><p class="simpara">
						This playbook resizes the following existing file systems:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								The Ext4 file system on the <code class="literal">mylv1</code> volume, which is mounted at <code class="literal">/opt/mount1</code>, resizes to 10 GiB.
							</li><li class="listitem">
								The Ext4 file system on the <code class="literal">mylv2</code> volume, which is mounted at <code class="literal">/opt/mount2</code>, resizes to 50 GiB.
							</li></ul></div></li><li class="listitem"><p class="simpara">
						Validate the playbook syntax:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-playbook --syntax-check ~/playbook.yml</strong></span></pre><p class="simpara">
						Note that this command only validates the syntax and does not protect against a wrong but valid configuration.
					</p></li><li class="listitem"><p class="simpara">
						Run the playbook:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-playbook ~/playbook.yml</strong></span></pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">/usr/share/ansible/roles/rhel-system-roles.storage/README.md</code> file
					</li><li class="listitem">
						<code class="literal">/usr/share/doc/rhel-system-roles/storage/</code> directory
					</li></ul></div></section><section class="section" id="example-ansible-playbook-to-create-a-swap-partition-using-the-storage-rhel-system-role_managing-local-storage-using-rhel-system-roles"><div class="titlepage"><div><div><h3 class="title">2.9. Creating a swap volume by using the <code class="literal">storage</code> RHEL system role</h3></div></div></div><p>
				This section provides an example Ansible playbook. This playbook applies the <code class="literal">storage</code> role to create a swap volume, if it does not exist, or to modify the swap volume, if it already exist, on a block device by using the default parameters.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles">You have prepared the control node and the managed nodes</a>
					</li><li class="listitem">
						You are logged in to the control node as a user who can run playbooks on the managed nodes.
					</li><li class="listitem">
						The account you use to connect to the managed nodes has <code class="literal">sudo</code> permissions on them.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Create a playbook file, for example <code class="literal">~/playbook.yml</code>, with the following content:
					</p><pre class="programlisting language-yaml">---
- name: Create a disk device with swap
  hosts: managed-node-01.example.com
  roles:
    - rhel-system-roles.storage
  vars:
    storage_volumes:
      - name: swap_fs
        type: disk
        disks:
          - /dev/sdb
        size: 15 GiB
        fs_type: swap</pre><p class="simpara">
						The volume name (<code class="literal"><span class="emphasis"><em>swap_fs</em></span></code> in the example) is currently arbitrary. The <code class="literal">storage</code> role identifies the volume by the disk device listed under the <code class="literal">disks:</code> attribute.
					</p></li><li class="listitem"><p class="simpara">
						Validate the playbook syntax:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-playbook --syntax-check ~/playbook.yml</strong></span></pre><p class="simpara">
						Note that this command only validates the syntax and does not protect against a wrong but valid configuration.
					</p></li><li class="listitem"><p class="simpara">
						Run the playbook:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-playbook ~/playbook.yml</strong></span></pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">/usr/share/ansible/roles/rhel-system-roles.storage/README.md</code> file
					</li><li class="listitem">
						<code class="literal">/usr/share/doc/rhel-system-roles/storage/</code> directory
					</li></ul></div></section><section class="section" id="configuring-a-raid-volume-using-the-storage-system-role_managing-local-storage-using-rhel-system-roles"><div class="titlepage"><div><div><h3 class="title">2.10. Configuring a RAID volume by using the <code class="literal">storage</code> RHEL system role</h3></div></div></div><p>
				With the <code class="literal">storage</code> system role, you can configure a RAID volume on RHEL by using Red Hat Ansible Automation Platform and Ansible-Core. Create an Ansible playbook with the parameters to configure a RAID volume to suit your requirements.
			</p><rh-alert class="admonition warning" state="danger"><div class="admonition_header" slot="header">Warning</div><div><p>
					Device names might change in certain circumstances, for example, when you add a new disk to a system. Therefore, to prevent data loss, do not use specific disk names in the playbook.
				</p></div></rh-alert><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles">You have prepared the control node and the managed nodes</a>
					</li><li class="listitem">
						You are logged in to the control node as a user who can run playbooks on the managed nodes.
					</li><li class="listitem">
						The account you use to connect to the managed nodes has <code class="literal">sudo</code> permissions on them.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Create a playbook file, for example <code class="literal">~/playbook.yml</code>, with the following content:
					</p><pre class="programlisting language-yaml">---
- name: Configure the storage
  hosts: managed-node-01.example.com
  tasks:
    - name: Create a RAID on sdd, sde, sdf, and sdg
      ansible.builtin.include_role:
        name: rhel-system-roles.storage
      vars:
        storage_safe_mode: false
        storage_volumes:
          - name: data
            type: raid
            disks: [sdd, sde, sdf, sdg]
            raid_level: raid0
            raid_chunk_size: 32 KiB
            mount_point: /mnt/data
            state: present</pre></li><li class="listitem"><p class="simpara">
						Validate the playbook syntax:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-playbook --syntax-check ~/playbook.yml</strong></span></pre><p class="simpara">
						Note that this command only validates the syntax and does not protect against a wrong but valid configuration.
					</p></li><li class="listitem"><p class="simpara">
						Run the playbook:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-playbook ~/playbook.yml</strong></span></pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">/usr/share/ansible/roles/rhel-system-roles.storage/README.md</code> file
					</li><li class="listitem">
						<code class="literal">/usr/share/doc/rhel-system-roles/storage/</code> directory
					</li></ul></div></section><section class="section" id="configuring-lvm-pool-with-raid-using-storage-system-role_managing-local-storage-using-rhel-system-roles"><div class="titlepage"><div><div><h3 class="title">2.11. Configuring an LVM pool with RAID by using the <code class="literal">storage</code> RHEL system role</h3></div></div></div><p>
				With the <code class="literal">storage</code> system role, you can configure an LVM pool with RAID on RHEL by using Red Hat Ansible Automation Platform. You can set up an Ansible playbook with the available parameters to configure an LVM pool with RAID.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles">You have prepared the control node and the managed nodes</a>
					</li><li class="listitem">
						You are logged in to the control node as a user who can run playbooks on the managed nodes.
					</li><li class="listitem">
						The account you use to connect to the managed nodes has <code class="literal">sudo</code> permissions on them.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Create a playbook file, for example <code class="literal">~/playbook.yml</code>, with the following content:
					</p><pre class="programlisting language-yaml">---
- name: Configure LVM pool with RAID
  hosts: managed-node-01.example.com
  roles:
    - rhel-system-roles.storage
  vars:
    storage_safe_mode: false
    storage_pools:
      - name: my_pool
        type: lvm
        disks: [sdh, sdi]
        raid_level: raid1
        volumes:
          - name: my_volume
            size: "1 GiB"
            mount_point: "/mnt/app/shared"
            fs_type: xfs
            state: present</pre><p class="simpara">
						To create an LVM pool with RAID, you must specify the RAID type by using the <code class="literal">raid_level</code> parameter.
					</p></li><li class="listitem"><p class="simpara">
						Validate the playbook syntax:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-playbook --syntax-check ~/playbook.yml</strong></span></pre><p class="simpara">
						Note that this command only validates the syntax and does not protect against a wrong but valid configuration.
					</p></li><li class="listitem"><p class="simpara">
						Run the playbook:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-playbook ~/playbook.yml</strong></span></pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">/usr/share/ansible/roles/rhel-system-roles.storage/README.md</code> file
					</li><li class="listitem">
						<code class="literal">/usr/share/doc/rhel-system-roles/storage/</code> directory
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_storage_devices/index#managing-raid_managing-storage-devices">Managing RAID</a>
					</li></ul></div></section><section class="section" id="configuring-a-stripe-size-for-raid-lvm-system-role_managing-local-storage-using-rhel-system-roles"><div class="titlepage"><div><div><h3 class="title">2.12. Configuring a stripe size for RAID LVM volumes by using the <code class="literal">storage</code> RHEL system role</h3></div></div></div><p>
				With the <code class="literal">storage</code> system role, you can configure a stripe size for RAID LVM volumes on RHEL by using Red Hat Ansible Automation Platform. You can set up an Ansible playbook with the available parameters to configure an LVM pool with RAID.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles">You have prepared the control node and the managed nodes</a>
					</li><li class="listitem">
						You are logged in to the control node as a user who can run playbooks on the managed nodes.
					</li><li class="listitem">
						The account you use to connect to the managed nodes has <code class="literal">sudo</code> permissions on them.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Create a playbook file, for example <code class="literal">~/playbook.yml</code>, with the following content:
					</p><pre class="programlisting language-yaml">---
- name: Configure stripe size for RAID LVM volumes
  hosts: managed-node-01.example.com
  roles:
    - rhel-system-roles.storage
  vars:
    storage_safe_mode: false
    storage_pools:
      - name: my_pool
        type: lvm
        disks: [sdh, sdi]
        volumes:
          - name: my_volume
            size: "1 GiB"
            mount_point: "/mnt/app/shared"
            fs_type: xfs
            raid_level: raid1
            raid_stripe_size: "256 KiB"
            state: present</pre></li><li class="listitem"><p class="simpara">
						Validate the playbook syntax:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-playbook --syntax-check ~/playbook.yml</strong></span></pre><p class="simpara">
						Note that this command only validates the syntax and does not protect against a wrong but valid configuration.
					</p></li><li class="listitem"><p class="simpara">
						Run the playbook:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-playbook ~/playbook.yml</strong></span></pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">/usr/share/ansible/roles/rhel-system-roles.storage/README.md</code> file
					</li><li class="listitem">
						<code class="literal">/usr/share/doc/rhel-system-roles/storage/</code> directory
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux//9/html-single/managing_storage_devices/index#managing-raid_managing-storage-devices">Managing RAID</a>
					</li></ul></div></section><section class="section" id="example-ansible-playbook-to-compress-and-deduplicate-a-vdo-volume-on-lvm-using-the-storage-rhel-system-role_managing-local-storage-using-rhel-system-roles"><div class="titlepage"><div><div><h3 class="title">2.13. Compressing and deduplicating a VDO volume on LVM by using the <code class="literal">storage</code> RHEL system role</h3></div></div></div><p>
				The example Ansible playbook applies the <code class="literal">storage</code> RHEL system role to enable compression and deduplication of Logical Volumes (LVM) by using Virtual Data Optimizer (VDO).
			</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					Because of the <code class="literal">storage</code> system role use of LVM VDO, only one volume per pool can use the compression and deduplication.
				</p></div></rh-alert><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles">You have prepared the control node and the managed nodes</a>
					</li><li class="listitem">
						You are logged in to the control node as a user who can run playbooks on the managed nodes.
					</li><li class="listitem">
						The account you use to connect to the managed nodes has <code class="literal">sudo</code> permissions on them.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Create a playbook file, for example <code class="literal">~/playbook.yml</code>, with the following content:
					</p><pre class="programlisting language-yaml">- name: Create LVM VDO volume under volume group 'myvg'
  hosts: managed-node-01.example.com
  roles:
    - rhel-system-roles.storage
  vars:
    storage_pools:
      - name: myvg
        disks:
          - /dev/sdb
        volumes:
          - name: mylv1
            compression: true
            deduplication: true
            vdo_pool_size: 10 GiB
            size: 30 GiB
            mount_point: /mnt/app/shared</pre><p class="simpara">
						In this example, the <code class="literal">compression</code> and <code class="literal">deduplication</code> pools are set to true, which specifies that the VDO is used. The following describes the usage of these parameters:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								The <code class="literal">deduplication</code> is used to deduplicate the duplicated data stored on the storage volume.
							</li><li class="listitem">
								The compression is used to compress the data stored on the storage volume, which results in more storage capacity.
							</li><li class="listitem">
								The vdo_pool_size specifies the actual size the volume takes on the device. The virtual size of VDO volume is set by the <code class="literal">size</code> parameter.
							</li></ul></div></li><li class="listitem"><p class="simpara">
						Validate the playbook syntax:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-playbook --syntax-check ~/playbook.yml</strong></span></pre><p class="simpara">
						Note that this command only validates the syntax and does not protect against a wrong but valid configuration.
					</p></li><li class="listitem"><p class="simpara">
						Run the playbook:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-playbook ~/playbook.yml</strong></span></pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">/usr/share/ansible/roles/rhel-system-roles.storage/README.md</code> file
					</li><li class="listitem">
						<code class="literal">/usr/share/doc/rhel-system-roles/storage/</code> directory
					</li></ul></div></section><section class="section" id="creating-a-luks2-encrypted-volume-using-the-storage-role_managing-local-storage-using-rhel-system-roles"><div class="titlepage"><div><div><h3 class="title">2.14. Creating a LUKS2 encrypted volume by using the <code class="literal">storage</code> RHEL system role</h3></div></div></div><p>
				You can use the <code class="literal">storage</code> role to create and configure a volume encrypted with LUKS by running an Ansible playbook.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles">You have prepared the control node and the managed nodes</a>
					</li><li class="listitem">
						You are logged in to the control node as a user who can run playbooks on the managed nodes.
					</li><li class="listitem">
						The account you use to connect to the managed nodes has <code class="literal">sudo</code> permissions on them.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Create a playbook file, for example <code class="literal">~/playbook.yml</code>, with the following content:
					</p><pre class="programlisting language-yaml">---
- name: Create and configure a volume encrypted with LUKS
  hosts: managed-node-01.example.com
  roles:
    - rhel-system-roles.storage
  vars:
    storage_volumes:
      - name: barefs
        type: disk
        disks:
         <span class="emphasis"><em>- sdb</em></span>
        fs_type: xfs
        fs_label: label-name
        mount_point: /mnt/data
        encryption: true
        encryption_password: <span class="emphasis"><em>&lt;password&gt;</em></span></pre><p class="simpara">
						You can also add other encryption parameters, such as <code class="literal">encryption_key</code>, <code class="literal">encryption_cipher</code>, <code class="literal">encryption_key_size</code>, and <code class="literal">encryption_luks</code>, to the playbook file.
					</p></li><li class="listitem"><p class="simpara">
						Validate the playbook syntax:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-playbook --syntax-check ~/playbook.yml</strong></span></pre><p class="simpara">
						Note that this command only validates the syntax and does not protect against a wrong but valid configuration.
					</p></li><li class="listitem"><p class="simpara">
						Run the playbook:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-playbook ~/playbook.yml</strong></span></pre></li></ol></div><div class="orderedlist"><p class="title"><strong>Verification</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						View the encryption status:
					</p><pre class="literallayout"># <span class="strong strong"><strong>cryptsetup status sdb</strong></span>

/dev/mapper/sdb is active and is in use.
type: LUKS2
cipher: aes-xts-plain64
keysize: 512 bits
key location: keyring
device: /dev/sdb
...</pre></li><li class="listitem"><p class="simpara">
						Verify the created LUKS encrypted volume:
					</p><pre class="literallayout"># <span class="strong strong"><strong>cryptsetup luksDump /dev/sdb</strong></span>

Version:        2
Epoch:          6
Metadata area:  16384 [bytes]
Keyslots area:  33521664 [bytes]
UUID:           a4c6be82-7347-4a91-a8ad-9479b72c9426
Label:          (no label)
Subsystem:      (no subsystem)
Flags:          allow-discards

Data segments:
  0: crypt
        offset: 33554432 [bytes]
        length: (whole device)
        cipher: aes-xts-plain64
        sector: 4096 [bytes]
...</pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">/usr/share/ansible/roles/rhel-system-roles.storage/README.md</code> file
					</li><li class="listitem">
						<code class="literal">/usr/share/doc/rhel-system-roles/storage/</code> directory
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_storage_devices/encrypting-block-devices-using-luks_managing-storage-devices">Encrypting block devices by using LUKS</a>
					</li></ul></div></section><section class="section" id="example-ansible-playbook-to-express-pool-volume-sizes-as-percentage-using-the-storage-rhel-system-role_managing-local-storage-using-rhel-system-roles"><div class="titlepage"><div><div><h3 class="title">2.15. Expressing pool volume sizes as percentage by using the <code class="literal">storage</code> RHEL system role</h3></div></div></div><p>
				The example Ansible playbook applies the <code class="literal">storage</code> system role to enable you to express Logical Manager Volumes (LVM) volume sizes as a percentage of the pool’s total size.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles">You have prepared the control node and the managed nodes</a>
					</li><li class="listitem">
						You are logged in to the control node as a user who can run playbooks on the managed nodes.
					</li><li class="listitem">
						The account you use to connect to the managed nodes has <code class="literal">sudo</code> permissions on them.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Create a playbook file, for example <code class="literal">~/playbook.yml</code>, with the following content:
					</p><pre class="programlisting language-yaml">---
- name: Express volume sizes as a percentage of the pool's total size
  hosts: managed-node-01.example.com
  roles:
    - rhel-system-roles.storage
  vars:
    storage_pools:
      - name: myvg
        disks:
          - /dev/sdb
        volumes:
          - name: data
            size: 60%
            mount_point: /opt/mount/data
          - name: web
            size: 30%
            mount_point: /opt/mount/web
          - name: cache
            size: 10%
            mount_point: /opt/cache/mount</pre><p class="simpara">
						This example specifies the size of LVM volumes as a percentage of the pool size, for example: <code class="literal">60%</code>. Alternatively, you can also specify the size of LVM volumes as a percentage of the pool size in a human-readable size of the file system, for example, <code class="literal">10g</code> or <code class="literal">50 GiB</code>.
					</p></li><li class="listitem"><p class="simpara">
						Validate the playbook syntax:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-playbook --syntax-check ~/playbook.yml</strong></span></pre><p class="simpara">
						Note that this command only validates the syntax and does not protect against a wrong but valid configuration.
					</p></li><li class="listitem"><p class="simpara">
						Run the playbook:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-playbook ~/playbook.yml</strong></span></pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">/usr/share/ansible/roles/rhel-system-roles.storage/README.md</code> file
					</li><li class="listitem">
						<code class="literal">/usr/share/doc/rhel-system-roles/storage/</code> directory
					</li></ul></div></section></section><section class="chapter" id="managing-partitions-using-the-web-console_managing-file-systems"><div class="titlepage"><div><div><h2 class="title">Chapter 3. Managing partitions using the web console</h2></div></div></div><p>
			Learn how to manage file systems on RHEL 9 using the web console.
		</p><section class="section" id="displaying-partitions-in-the-web-console_managing-partitions-using-the-web-console"><div class="titlepage"><div><div><h3 class="title">3.1. Displaying partitions formatted with file systems in the web console</h3></div></div></div><p class="_abstract _abstract">
				The <span class="strong strong"><strong>Storage</strong></span> section in the web console displays all available file systems in the <span class="strong strong"><strong>Filesystems</strong></span> table.
			</p><p>
				Besides the list of partitions formatted with file systems, you can also use the page for creating new storage.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						The <code class="literal">cockpit-storaged</code> package is installed on your system.
					</li></ul></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						You have installed the RHEL 9 web console.
					</p><p class="simpara">
						For instructions, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console">Installing and enabling the web console</a>.
					</p></li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Log in to the RHEL 9 web console.
					</p><p class="simpara">
						For details, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#logging-in-to-the-web-console_getting-started-with-the-rhel-9-web-console">Logging in to the web console</a>.
					</p></li><li class="listitem"><p class="simpara">
						Click the <span class="strong strong"><strong>Storage</strong></span> tab.
					</p><p class="simpara">
						In the <span class="strong strong"><strong>Storage</strong></span> table, you can see all available partitions formatted with file systems, their ID, types, locations, sizes, and how much space is available on each partition.
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/6cce358f149ba8380d3757567290d6ad/cockpit-filesystems-partitions.png" alt="Image displaying the Storage table available in the cockpit Storage tab."></span>

					</p><p class="simpara">
						You can also use the drop-down menu in the top-right corner to create new local or networked storage.
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/7609a2256402ee69664a842137ff6964/cockpit-adding-volume-groups.png" alt="Image displaying the drop-down menu available in the Storage table."></span>

					</p></li></ol></div></section><section class="section" id="creating-partitions-in-the-web-console_managing-partitions-using-the-web-console"><div class="titlepage"><div><div><h3 class="title">3.2. Creating partitions in the web console</h3></div></div></div><p class="_abstract _abstract">
				To create a new partition:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Use an existing partition table
					</li><li class="listitem">
						Create a partition
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						The <code class="literal">cockpit-storaged</code> package is installed on your system.
					</li><li class="listitem">
						The web console must be installed and accessible. For details, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console">Installing the web console</a>.
					</li><li class="listitem">
						An unformatted volume connected to the system is visible in the <span class="strong strong"><strong>Storage</strong></span> table of the <span class="strong strong"><strong>Storage</strong></span> tab.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Log in to the RHEL 9 web console.
					</p><p class="simpara">
						For details, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#logging-in-to-the-web-console_getting-started-with-the-rhel-9-web-console">Logging in to the web console</a>.
					</p></li><li class="listitem">
						Click the <span class="strong strong"><strong>Storage</strong></span> tab.
					</li><li class="listitem">
						In the <span class="strong strong"><strong>Storage</strong></span> table, click the device which you want to partition to open the page and options for that device.
					</li><li class="listitem">
						On the device page, click the menu button, <span class="guibutton">⋮</span>, and select <span class="strong strong"><strong>Create partition table</strong></span>.
					</li><li class="listitem"><p class="simpara">
						In the <span class="strong strong"><strong>Initialize disk</strong></span> dialog box, select the following:
					</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
								<span class="strong strong"><strong>Partitioning</strong></span>:
							</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
										Compatible with all systems and devices (MBR)
									</li><li class="listitem">
										Compatible with modern system and hard disks &gt; 2TB (GPT)
									</li><li class="listitem">
										No partitioning
									</li></ul></div></li><li class="listitem"><p class="simpara">
								<span class="strong strong"><strong>Overwrite</strong></span>:
							</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
										Select the <span class="strong strong"><strong>Overwrite existing data with zeros</strong></span> checkbox if you want the RHEL web console to rewrite the whole disk with zeros. This option is slower because the program has to go through the whole disk, but it is more secure. Use this option if the disk includes any data and you need to overwrite it.
									</p><p class="simpara">
										If you do not select the <span class="strong strong"><strong>Overwrite existing data with zeros</strong></span> checkbox, the RHEL web console rewrites only the disk header. This increases the speed of formatting.
									</p></li></ul></div></li></ol></div></li><li class="listitem">
						Click <span class="guibutton">Initialize</span>.
					</li><li class="listitem">
						Click the menu button, <span class="guibutton">⋮</span>, next to the partition table you created. It is named <span class="strong strong"><strong>Free space</strong></span> by default.
					</li><li class="listitem">
						Click <span class="guibutton">Create partition</span>.
					</li><li class="listitem">
						In the <span class="strong strong"><strong>Create partition</strong></span> dialog box, enter a <span class="strong strong"><strong>Name</strong></span> for the file system.
					</li><li class="listitem">
						Add a <span class="strong strong"><strong>Mount point</strong></span>.
					</li><li class="listitem"><p class="simpara">
						In the <span class="strong strong"><strong>Type</strong></span> drop-down menu, select a file system:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								<span class="strong strong"><strong>XFS</strong></span> file system supports large logical volumes, switching physical drives online without outage, and growing an existing file system. Leave this file system selected if you do not have a different strong preference.
							</li><li class="listitem"><p class="simpara">
								<span class="strong strong"><strong>ext4</strong></span> file system supports:
							</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
										Logical volumes
									</li><li class="listitem">
										Switching physical drives online without outage
									</li><li class="listitem">
										Growing a file system
									</li><li class="listitem">
										Shrinking a file system
									</li></ul></div></li></ul></div><p class="simpara">
						Additional option is to enable encryption of partition done by LUKS (Linux Unified Key Setup), which allows you to encrypt the volume with a passphrase.
					</p></li><li class="listitem">
						Enter the <span class="strong strong"><strong>Size</strong></span> of the volume you want to create.
					</li><li class="listitem"><p class="simpara">
						Select the <span class="strong strong"><strong>Overwrite existing data with zeros</strong></span> checkbox if you want the RHEL web console to rewrite the whole disk with zeros. This option is slower because the program has to go through the whole disk, but it is more secure. Use this option if the disk includes any data and you need to overwrite it.
					</p><p class="simpara">
						If you do not select the <span class="strong strong"><strong>Overwrite existing data with zeros</strong></span> checkbox, the RHEL web console rewrites only the disk header. This increases the speed of formatting.
					</p></li><li class="listitem"><p class="simpara">
						If you want to encrypt the volume, select the type of encryption in the <span class="strong strong"><strong>Encryption</strong></span> drop-down menu.
					</p><p class="simpara">
						If you do not want to encrypt the volume, select <span class="strong strong"><strong>No encryption</strong></span>.
					</p></li><li class="listitem">
						In the <span class="strong strong"><strong>At boot</strong></span> drop-down menu, select when you want to mount the volume.
					</li><li class="listitem"><p class="simpara">
						In <span class="strong strong"><strong>Mount options</strong></span> section:
					</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem">
								Select the <span class="strong strong"><strong>Mount read only</strong></span> checkbox if you want the to mount the volume as a read-only logical volume.
							</li><li class="listitem">
								Select the <span class="strong strong"><strong>Custom mount options</strong></span> checkbox and add the mount options if you want to change the default mount option.
							</li></ol></div></li><li class="listitem"><p class="simpara">
						Create the partition:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								If you want to create and mount the partition, click the <span class="guibutton">Create and mount</span> button.
							</li><li class="listitem"><p class="simpara">
								If you want to only create the partition, click the <span class="guibutton">Create only</span> button.
							</p><p class="simpara">
								Formatting can take several minutes depending on the volume size and which formatting options are selected.
							</p></li></ul></div></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						To verify that the partition has been successfully added, switch to the <span class="strong strong"><strong>Storage</strong></span> tab and check the <span class="strong strong"><strong>Storage</strong></span> table and verify whether the new partition is listed.
					</li></ul></div></section><section class="section" id="deleting-partitions-in-the-web-console_managing-partitions-using-the-web-console"><div class="titlepage"><div><div><h3 class="title">3.3. Deleting partitions in the web console</h3></div></div></div><p class="_abstract _abstract">
				You can remove partitions in the web console interface.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						The <code class="literal">cockpit-storaged</code> package is installed on your system.
					</li></ul></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						You have installed the RHEL 9 web console.
					</p><p class="simpara">
						For instructions, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console">Installing and enabling the web console</a>.
					</p></li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Log in to the RHEL 9 web console.
					</p><p class="simpara">
						For details, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#logging-in-to-the-web-console_getting-started-with-the-rhel-9-web-console">Logging in to the web console</a>.
					</p></li><li class="listitem">
						Click the <span class="strong strong"><strong>Storage</strong></span> tab.
					</li><li class="listitem">
						Click the device from which you want to delete a partition.
					</li><li class="listitem">
						On the device page and in the <span class="strong strong"><strong>GPT partitions</strong></span> section, click the menu button, <span class="guibutton">⋮</span> next to the partition you want to delete.
					</li><li class="listitem"><p class="simpara">
						From the drop-down menu, select <span class="guibutton">Delete</span>.
					</p><p class="simpara">
						The RHEL web console terminates all processes that are currently using the partition and unmount the partition before deleting it.
					</p></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						To verify that the partition has been successfully removed, switch to the <span class="strong strong"><strong>Storage</strong></span> tab and check the <span class="strong strong"><strong>Storage</strong></span> table.
					</li></ul></div></section></section><section class="chapter" id="mounting-nfs-shares_managing-file-systems"><div class="titlepage"><div><div><h2 class="title">Chapter 4. Mounting NFS shares</h2></div></div></div><p class="_abstract _abstract">
			As a system administrator, you can mount remote NFS shares on your system to access shared data.
		</p><section class="section" id="services-required-on-an-nfs-client_mounting-nfs-shares"><div class="titlepage"><div><div><h3 class="title">4.1. Services required on an NFS client</h3></div></div></div><p class="_abstract _abstract">
				Red Hat Enterprise Linux uses a combination of a kernel module and user-space processes to provide NFS file shares:
			</p><rh-table id="idm139822460057408"><table class="lt-4-cols lt-7-rows"><caption>Table 4.1. Services required on an NFS client</caption><colgroup><col style="width: 17%; " class="col_1"><!--Empty--><col style="width: 17%; " class="col_2"><!--Empty--><col style="width: 66%; " class="col_3"><!--Empty--></colgroup><thead><tr><th align="left" valign="top" id="idm139822456686576" scope="col">Service name</th><th align="left" valign="top" id="idm139822456685488" scope="col">NFS version</th><th align="left" valign="top" id="idm139822459522000" scope="col">Description</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm139822456686576"> <p>
								<code class="literal">rpc.idmapd</code>
							</p>
							 </td><td align="left" valign="top" headers="idm139822456685488"> <p>
								4
							</p>
							 </td><td align="left" valign="top" headers="idm139822459522000"> <p>
								This process provides NFSv4 client and server upcalls, which map between NFSv4 names (strings in the form of <span class="emphasis"><em><code class="literal">user@domain</code></em></span>) and local user and group IDs.
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822456686576"> <p>
								<code class="literal">rpc.statd</code>
							</p>
							 </td><td align="left" valign="top" headers="idm139822456685488"> <p>
								3
							</p>
							 </td><td align="left" valign="top" headers="idm139822459522000"> <p>
								This service provides notification to other NFSv3 clients when the local host reboots, and to the kernel when a remote NFSv3 host reboots.
							</p>
							 </td></tr></tbody></table></rh-table><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">rpc.idmapd(8)</code>, <code class="literal">rpc.statd(8)</code> man pages on your system
					</li></ul></div></section><section class="section" id="preparing-an-nfsv3-client-to-run-behind-a-firewall_mounting-nfs-shares"><div class="titlepage"><div><div><h3 class="title">4.2. Preparing an NFSv3 client to run behind a firewall</h3></div></div></div><p>
				An NFS server notifies clients about file locks and the server status. To establish a connection back to the client, you must open the relevant ports in the firewall on the client.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						By default, NFSv3 RPC services use random ports. To enable a firewall configuration, configure fixed port numbers in the <code class="literal">/etc/nfs.conf</code> file:
					</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
								In the <code class="literal">[lockd]</code> section, set a fixed port number for the <code class="literal">nlockmgr</code> RPC service, for example:
							</p><pre class="screen">port=<span class="emphasis"><em>5555</em></span></pre><p class="simpara">
								With this setting, the service automatically uses this port number for both the UDP and TCP protocol.
							</p></li><li class="listitem"><p class="simpara">
								In the <code class="literal">[statd]</code> section, set a fixed port number for the <code class="literal">rpc.statd</code> service, for example:
							</p><pre class="screen">port=<span class="emphasis"><em>6666</em></span></pre><p class="simpara">
								With this setting, the service automatically uses this port number for both the UDP and TCP protocol.
							</p></li></ol></div></li><li class="listitem"><p class="simpara">
						Open the relevant ports in <code class="literal">firewalld</code>:
					</p><pre class="screen"># <span class="strong strong"><strong>firewall-cmd --permanent --add-service=rpc-bind</strong></span>
# <span class="strong strong"><strong>firewall-cmd --permanent --add-port={<span class="emphasis"><em>5555</em></span>/tcp,<span class="emphasis"><em>5555</em></span>/udp,<span class="emphasis"><em>6666</em></span>/tcp,<span class="emphasis"><em>6666</em></span>/udp}</strong></span>
# <span class="strong strong"><strong>firewall-cmd --reload</strong></span></pre></li><li class="listitem"><p class="simpara">
						Restart the <code class="literal">rpc-statd</code> service:
					</p><pre class="screen"># <span class="strong strong"><strong>systemctl restart rpc-statd nfs-server</strong></span></pre></li></ol></div></section><section class="section" id="preparing-an-nfsv4-0-client-to-run-behind-a-firewall_mounting-nfs-shares"><div class="titlepage"><div><div><h3 class="title">4.3. Preparing an NFSv4.0 client to run behind a firewall</h3></div></div></div><p>
				An NFS server notifies clients about file locks and the server status. To establish a connection back to the client, you must open the relevant ports in the firewall on the client.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						The server uses the NFS 4.0 protocol.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Open the relevant ports in <code class="literal">firewalld</code>:
					</p><pre class="screen"># <span class="strong strong"><strong>firewall-cmd --permanent --add-port=<span class="emphasis"><em>&lt;callback_port&gt;</em></span>/tcp</strong></span>
# <span class="strong strong"><strong>firewall-cmd --reload</strong></span></pre></li></ul></div></section><section class="section" id="manually-mounting-an-nfs-share_mounting-nfs-shares"><div class="titlepage"><div><div><h3 class="title">4.4. Manually mounting an NFS share</h3></div></div></div><p>
				If you do not require that a NFS share is automatically mounted at boot time, you can manually mount it.
			</p><rh-alert class="admonition warning" state="danger"><div class="admonition_header" slot="header">Warning</div><div><p>
					You can experience conflicts in your NFSv4 <code class="literal">clientid</code> and their sudden expiration if your NFS clients have the same short hostname. To avoid any possible sudden expiration of your NFSv4 <code class="literal">clientid</code>, you must use either unique hostnames for NFS clients or configure identifier on each container, depending on what system you are using. For more information, see the <a class="link" href="https://access.redhat.com/solutions/6395261">NFSv4 clientid was expired suddenly due to use same hostname on several NFS clients</a> Knowledgebase article.
				</p></div></rh-alert><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Use the following command to mount an NFS share on a client:
					</p><pre class="screen"># <span class="strong strong"><strong>mount <span class="emphasis"><em>&lt;nfs_server_ip_or_hostname&gt;</em></span>:/<span class="emphasis"><em>&lt;exported_share&gt;</em></span> <span class="emphasis"><em>&lt;mount point&gt;</em></span></strong></span></pre><p class="simpara">
						For example, to mount the <code class="literal">/nfs/projects</code> share from the <code class="literal">server.example.com</code> NFS server to <code class="literal">/mnt</code>, enter:
					</p><pre class="screen"># <span class="strong strong"><strong>mount <span class="emphasis"><em>server.example.com:/nfs/projects/</em></span> /mnt/</strong></span></pre></li></ul></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						As a user who has permissions to access the NFS share, display the content of the mounted share:
					</p><pre class="screen">$ <span class="strong strong"><strong>ls -l /mnt/</strong></span></pre></li></ul></div></section><section class="section" id="mounting-an-nfs-share-automatically-when-the-system-boots_mounting-nfs-shares"><div class="titlepage"><div><div><h3 class="title">4.5. Mounting an NFS share automatically when the system boots</h3></div></div></div><p>
				Automatic mounting of an NFS share during system boot ensures that critical services reliant on centralized data, such as <code class="literal">/home</code> directories hosted on the NFS server, have seamless and uninterrupted access from the moment the system starts up.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Edit the <code class="literal">/etc/fstab</code> file and add a line for the share that you want to mount:
					</p><pre class="screen"><span class="strong strong"><strong><span class="emphasis"><em>&lt;nfs_server_ip_or_hostname&gt;:/&lt;exported_share&gt;</em></span> <span class="emphasis"><em>&lt;mount point&gt;</em></span> nfs default 0 0</strong></span></pre><p class="simpara">
						For example, to mount the <code class="literal">/nfs/home</code> share from the <code class="literal">server.example.com</code> NFS server to <code class="literal">/home</code>, enter:
					</p><pre class="screen">server.example.com:/nfs/projects    	/home        nfs 	defaults    	0 0</pre></li><li class="listitem"><p class="simpara">
						Mount the share:
					</p><pre class="screen"># <span class="strong strong"><strong>mount <span class="emphasis"><em>/home</em></span></strong></span></pre></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						As a user who has permissions to access the NFS share, display the content of the mounted share:
					</p><pre class="screen">$ <span class="strong strong"><strong>ls -l /mnt/</strong></span></pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">fstab(5)</code> man page on your system
					</li></ul></div></section><section class="section" id="connecting-nfs-mounts-in-the-web-console_mounting-nfs-shares"><div class="titlepage"><div><div><h3 class="title">4.6. Connecting NFS mounts in the web console</h3></div></div></div><p class="_abstract _abstract">
				Connect a remote directory to your file system using NFS.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						You have installed the RHEL 9 web console.
					</p><p class="simpara">
						For instructions, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console">Installing and enabling the web console</a>.
					</p></li><li class="listitem">
						The <code class="literal">cockpit-storaged</code> package is installed on your system.
					</li><li class="listitem">
						NFS server name or the IP address.
					</li><li class="listitem">
						Path to the directory on the remote server.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Log in to the RHEL 9 web console.
					</p><p class="simpara">
						For details, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#logging-in-to-the-web-console_getting-started-with-the-rhel-9-web-console">Logging in to the web console</a>.
					</p></li><li class="listitem">
						Click <span class="strong strong"><strong>Storage</strong></span>.
					</li><li class="listitem">
						In the <span class="strong strong"><strong>Storage</strong></span> table, click the menu button.
					</li><li class="listitem"><p class="simpara">
						From the drop-down menu, select <span class="strong strong"><strong>New NFS mount</strong></span>.
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/32dad32f8647e486ba3a67b25a80dd20/cockpit-adding-volume-groups-new-nfs.png" alt="Image displaying the available options in the Storage table drop-down menu. The New NFS mount options is highlighted."></span>

					</p></li><li class="listitem">
						In the <span class="strong strong"><strong>New NFS Mount</strong></span> dialog box, enter the server or IP address of the remote server.
					</li><li class="listitem">
						In the <span class="strong strong"><strong>Path on Server</strong></span> field, enter the path to the directory that you want to mount.
					</li><li class="listitem">
						In the <span class="strong strong"><strong>Local Mount Point</strong></span> field, enter the path to the directory on your local system where you want to mount the NFS.
					</li><li class="listitem"><p class="simpara">
						In the <span class="strong strong"><strong>Mount options</strong></span> check box list, select how you want to mount the NFS. You can select multiple options depending on your requirements.
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								Check the <span class="strong strong"><strong>Mount at boot</strong></span> box if you want the directory to be reachable even after you restart the local system.
							</li><li class="listitem">
								Check the <span class="strong strong"><strong>Mount read only</strong></span> box if you do not want to change the content of the NFS.
							</li><li class="listitem"><p class="simpara">
								Check the <span class="strong strong"><strong>Custom mount options</strong></span> box and add the mount options if you want to change the default mount option.
							</p><p class="simpara">
								<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/0152ffc2922c8556e646f59bf2e25a2b/cockpit-NFS-mount-new.png" alt="New NFS mount dialog box"></span>

							</p></li></ul></div></li><li class="listitem">
						Click <span class="guibutton">Add</span>.
					</li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Open the mounted directory and verify that the content is accessible.
					</li></ul></div></section><section class="section" id="customizing-nfs-mount-options-in-the-web-console_mounting-nfs-shares"><div class="titlepage"><div><div><h3 class="title">4.7. Customizing NFS mount options in the web console</h3></div></div></div><p class="_abstract _abstract">
				Edit an existing NFS mount and add custom mount options.
			</p><p>
				Custom mount options can help you to troubleshoot the connection or change parameters of the NFS mount such as changing timeout limits or configuring authentication.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						You have installed the RHEL 9 web console.
					</p><p class="simpara">
						For instructions, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console">Installing and enabling the web console</a>.
					</p></li><li class="listitem">
						The <code class="literal">cockpit-storaged</code> package is installed on your system.
					</li><li class="listitem">
						An NFS mount is added to your system.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem">
						Log in to the RHEL 9 web console. For details, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#logging-in-to-the-web-console_getting-started-with-the-rhel-9-web-console">Logging in to the web console</a>.
					</li><li class="listitem">
						Click <span class="strong strong"><strong>Storage</strong></span>.
					</li><li class="listitem">
						In the <span class="strong strong"><strong>Storage</strong></span> table, click the NFS mount you want to adjust.
					</li><li class="listitem"><p class="simpara">
						If the remote directory is mounted, click <span class="strong strong"><strong>Unmount</strong></span>.
					</p><p class="simpara">
						You must unmount the directory during the custom mount options configuration. Otherwise, the web console does not save the configuration and this causes an error.
					</p></li><li class="listitem">
						Click <span class="strong strong"><strong>Edit</strong></span>.
					</li><li class="listitem">
						In the <span class="strong strong"><strong>NFS Mount</strong></span> dialog box, select <span class="strong strong"><strong>Custom mount option</strong></span>.
					</li><li class="listitem"><p class="simpara">
						Enter mount options separated by a comma. For example:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								<code class="literal"><span class="strong strong"><strong>nfsvers=4</strong></span></code>: The NFS protocol version number
							</li><li class="listitem">
								<code class="literal"><span class="strong strong"><strong>soft</strong></span></code>: The type of recovery after an NFS request times out
							</li><li class="listitem">
								<code class="literal"><span class="strong strong"><strong>sec=krb5</strong></span></code>: The files on the NFS server can be secured by Kerberos authentication. Both the NFS client and server have to support Kerberos authentication.
							</li></ul></div><p class="simpara">
						For a complete list of the NFS mount options, enter <code class="literal">man nfs</code> in the command line.
					</p></li><li class="listitem">
						Click <span class="strong strong"><strong>Apply</strong></span>.
					</li><li class="listitem">
						Click <span class="strong strong"><strong>Mount</strong></span>.
					</li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Open the mounted directory and verify that the content is accessible.
					</li></ul></div></section><section class="section" id="setting-up-an-nfs-client-with-kerberos-in-a-red-hat-identity-management-domain_mounting-nfs-shares"><div class="titlepage"><div><div><h3 class="title">4.8. Setting up an NFS client with Kerberos in a Red Hat Identity Management domain</h3></div></div></div><p>
				If the NFS server uses Kerberos and is enrolled in an Red Hat Identity Management (IdM) domain, your client must also be a member of the domain to be able to mount the shares. This enables you to centrally manage users and groups and to use Kerberos for authentication, integrity protection, and traffic encryption.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						The NFS client is <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/installing_identity_management/assembly_installing-an-idm-client_installing-identity-management">enrolled</a> in a Red Hat Identity Management (IdM) domain.
					</li><li class="listitem">
						The exported NFS share uses Kerberos.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Obtain a kerberos ticket as an IdM administrator:
					</p><pre class="screen"># <span class="strong strong"><strong>kinit admin</strong></span></pre></li><li class="listitem"><p class="simpara">
						Retrieve the host principal, and store it in the <code class="literal">/etc/krb5.keytab</code> file:
					</p><pre class="screen"># <span class="strong strong"><strong>ipa-getkeytab -s <span class="emphasis"><em>idm_server.idm.example.com</em></span> -p <span class="emphasis"><em>host/nfs_client.idm.example.com</em></span> -k /etc/krb5.keytab</strong></span></pre><p class="simpara">
						IdM automatically created the <code class="literal">host</code> principal when you joined the host to the IdM domain.
					</p></li><li class="listitem"><p class="simpara">
						Optional: Display the principals in the <code class="literal">/etc/krb5.keytab</code> file:
					</p><pre class="screen"># <span class="strong strong"><strong>klist -k /etc/krb5.keytab</strong></span>
Keytab name: FILE:/etc/krb5.keytab
KVNO Principal
---- --------------------------------------------------------------------------
   6 host/nfs_client.idm.example.com@IDM.EXAMPLE.COM
   6 host/nfs_client.idm.example.com@IDM.EXAMPLE.COM
   6 host/nfs_client.idm.example.com@IDM.EXAMPLE.COM
   6 host/nfs_client.idm.example.com@IDM.EXAMPLE.COM</pre></li><li class="listitem"><p class="simpara">
						Use the <code class="literal">ipa-client-automount</code> utility to configure mapping of IdM IDs:
					</p><pre class="screen"># <span class="strong strong"><strong>ipa-client-automount</strong></span>
Searching for IPA server...
IPA server: DNS discovery
Location: default
Continue to configure the system with these values? [no]: yes
Configured /etc/idmapd.conf
Restarting sssd, waiting for it to become available.
Started autofs</pre></li><li class="listitem"><p class="simpara">
						Mount an exported NFS share, for example:
					</p><pre class="screen"># <span class="strong strong"><strong>mount -o sec=krb5i <span class="emphasis"><em>server.idm.example.com:/nfs/projects/</em></span> <span class="emphasis"><em>/mnt/</em></span></strong></span></pre><p class="simpara">
						The <code class="literal">-o sec</code> option specifies the Kerberos security method.
					</p></li></ol></div><div class="orderedlist"><p class="title"><strong>Verification</strong></p><ol class="orderedlist" type="1"><li class="listitem">
						Log in as an IdM user who has permissions to write on the mounted share.
					</li><li class="listitem"><p class="simpara">
						Obtain a Kerberos ticket:
					</p><pre class="screen">$ <span class="strong strong"><strong>kinit</strong></span></pre></li><li class="listitem"><p class="simpara">
						Create a file on the share, for example:
					</p><pre class="screen">$ <span class="strong strong"><strong>touch <span class="emphasis"><em>/mnt/test.txt</em></span></strong></span></pre></li><li class="listitem"><p class="simpara">
						List the directory to verify that the file was created:
					</p><pre class="screen">$ <span class="strong strong"><strong>ls -l <span class="emphasis"><em>/mnt/test.txt</em></span></strong></span>
-rw-r--r--. 1 admin users 0 Feb 15 11:54 /mnt/test.txt</pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/configuring_and_using_network_file_services/deploying-an-nfs-server_configuring-and-using-network-file-services#the-auth-gss-authentication-method_deploying-an-nfs-server">The AUTH_GSS authentication method</a>
					</li></ul></div></section><section class="section" id="configuring-gnome-to-store-user-settings-on-home-directories-hosted-on-an-nfs-share_mounting-nfs-shares"><div class="titlepage"><div><div><h3 class="title">4.9. Configuring GNOME to store user settings on home directories hosted on an NFS share</h3></div></div></div><p>
				If you use GNOME on a system with home directories hosted on an NFS server, you must change the <code class="literal">keyfile</code> backend of the <code class="literal">dconf</code> database. Otherwise, <code class="literal">dconf</code> might not work correctly.
			</p><p>
				This change affects all users on the host, as it alters the way <code class="literal">dconf</code> manages user settings and configurations stored in the home directories.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Create the <code class="literal">/etc/dconf/profile/user</code> file and add the following to it:
					</p><pre class="screen"><span class="strong strong"><strong>service-db:keyfile/user</strong></span></pre><p class="simpara">
						With this setting, <code class="literal">dconf</code> polls the <code class="literal">keyfile</code> back end to determine whether updates have been made, so settings might not be updated immediately.
					</p></li><li class="listitem">
						The changes take effect when the users logs out and in.
					</li></ol></div></section><section class="section" id="frequently-used-nfs-mount-options_mounting-nfs-shares"><div class="titlepage"><div><div><h3 class="title">4.10. Frequently used NFS mount options</h3></div></div></div><p>
				The following are the commonly-used options when mounting NFS shares. You can use these options with <code class="literal">mount</code> commands, in <code class="literal">/etc/fstab</code> settings, and the <code class="literal">autofs</code> automapper.
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">lookupcache=<span class="emphasis"><em>mode</em></span></code></span></dt><dd>
							Specifies how the kernel should manage its cache of directory entries for a given mount point. Valid arguments for mode are <code class="literal">all</code>, <code class="literal">none</code>, or <code class="literal">positive</code>.
						</dd><dt><span class="term"><code class="literal">nfsvers=<span class="emphasis"><em>version</em></span></code></span></dt><dd><p class="simpara">
							Specifies which version of the NFS protocol to use, where version is <code class="literal">3</code>, <code class="literal">4</code>, <code class="literal">4.0</code>, <code class="literal">4.1</code>, or <code class="literal">4.2</code>. This is useful for hosts that run multiple NFS servers, or to disable retrying a mount with lower versions. If no version is specified, the client tries version <code class="literal">4.2</code> first, then negotiates down until it finds a version supported by the server.
						</p><p class="simpara">
							The option <code class="literal">vers</code> is identical to <code class="literal">nfsvers</code>, and is included in this release for compatibility reasons.
						</p></dd><dt><span class="term"><code class="literal">noacl</code></span></dt><dd>
							Turns off all ACL processing. This can be needed when interfacing with old Red Hat Enterprise Linux versions that are not compatible with the recent ACL technology.
						</dd><dt><span class="term"><code class="literal">nolock</code></span></dt><dd>
							Disables file locking. This setting can be required when you connect to very old NFS servers.
						</dd><dt><span class="term"><code class="literal">noexec</code></span></dt><dd>
							Prevents execution of binaries on mounted file systems. This is useful if the system is mounting a non-Linux file system containing incompatible binaries.
						</dd><dt><span class="term"><code class="literal">nosuid</code></span></dt><dd>
							Disables the <code class="literal">set-user-identifier</code> and <code class="literal">set-group-identifier</code> bits. This prevents remote users from gaining higher privileges by running a <code class="literal">setuid</code> program.
						</dd><dt><span class="term"><code class="literal">retrans=<span class="emphasis"><em>num</em></span></code></span></dt><dd>
							The number of times the NFS client retries a request before it attempts further recovery action. If the <code class="literal">retrans</code> option is not specified, the NFS client tries each UDP request three times and each TCP request twice.
						</dd><dt><span class="term"><code class="literal">timeo=<span class="emphasis"><em>num</em></span></code></span></dt><dd>
							The time in tenths of a second the NFS client waits for a response before it retries an NFS request. For NFS over TCP, the default <code class="literal">timeo</code> value is 600 (60 seconds). The NFS client performs linear backoff: After each retransmission the timeout is increased by <code class="literal">timeo</code> up to the maximum of 600 seconds.
						</dd><dt><span class="term"><code class="literal">port=<span class="emphasis"><em>num</em></span></code></span></dt><dd>
							Specifies the numeric value of the NFS server port. For NFSv3, if num is <code class="literal">0</code> (the default value), or not specified, then mount queries the <code class="literal">rpcbind</code> service on the remote host for the port number to use. For NFSv4, if num is <code class="literal">0</code>, then mount queries the <code class="literal">rpcbind</code> service, but if it is not specified, the standard NFS port number of TCP 2049 is used instead and the remote <code class="literal">rpcbind</code> is not checked anymore.
						</dd><dt><span class="term"><code class="literal">rsize=<span class="emphasis"><em>num</em></span></code> and <code class="literal">wsize=<span class="emphasis"><em>num</em></span></code></span></dt><dd><p class="simpara">
							These options set the maximum number of bytes to be transferred in a single NFS read or write operation.
						</p><p class="simpara">
							There is no fixed default value for <code class="literal">rsize</code> and <code class="literal">wsize</code>. By default, NFS uses the largest possible value that both the server and the client support. In Red Hat Enterprise Linux 9, the client and server maximum is 1,048,576 bytes. For more details, see the <a class="link" href="https://access.redhat.com/solutions/753853">What are the default and maximum values for rsize and wsize with NFS mounts?</a> KBase article.
						</p></dd><dt><span class="term"><code class="literal">sec=<span class="emphasis"><em>options</em></span></code></span></dt><dd><p class="simpara">
							Security options to use for accessing files on the mounted export. The options value is a colon-separated list of one or more security options.
						</p><p class="simpara">
							By default, the client attempts to find a security option that both the client and the server support. If the server does not support any of the selected options, the mount operation fails.
						</p><p class="simpara">
							Available options:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									<code class="literal">sec=sys</code> uses local UNIX UIDs and GIDs. These use <code class="literal">AUTH_SYS</code> to authenticate NFS operations.
								</li><li class="listitem">
									<code class="literal">sec=krb5</code> uses Kerberos V5 instead of local UNIX UIDs and GIDs to authenticate users.
								</li><li class="listitem">
									<code class="literal">sec=krb5i</code> uses Kerberos V5 for user authentication and performs integrity checking of NFS operations using secure checksums to prevent data tampering.
								</li><li class="listitem">
									<code class="literal">sec=krb5p</code> uses Kerberos V5 for user authentication, integrity checking, and encrypts NFS traffic to prevent traffic sniffing. This is the most secure setting, but it also involves the most performance overhead.
								</li></ul></div></dd></dl></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">mount(8)</code> and `nfs(5)`man pages on your system
					</li></ul></div></section><section class="section" id="enabling-client-side-caching-of-nfs-content_mounting-nfs-shares"><div class="titlepage"><div><div><h3 class="title">4.11. Enabling client-side caching of NFS content</h3></div></div></div><p>
				FS-Cache is a persistent local cache on the client that file systems can use to take data retrieved from over the network and cache it on the local disk. This helps to minimize network traffic.
			</p><section class="section" id="how-nfs-caching-works_enabling-client-side-caching-of-nfs-content"><div class="titlepage"><div><div><h4 class="title">4.11.1. How NFS caching works</h4></div></div></div><p>
					The following diagram is a high-level illustration of how FS-Cache works:
				</p><div class="informalfigure"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/315fe3b891f2a78cb30c1cebbf0373e0/fs-cache.png" alt="FS-Cache overview"></div></div><p>
					FS-Cache is designed to be as transparent as possible to the users and administrators of a system. FS-Cache allows a file system on a server to interact directly with a client’s local cache without creating an over-mounted file system. With NFS, a mount option instructs the client to mount the NFS share with FS-cache enabled. The mount point will cause automatic upload for two kernel modules: <code class="literal">fscache</code> and <code class="literal">cachefiles</code>. The <code class="literal">cachefilesd</code> daemon communicates with the kernel modules to implement the cache.
				</p><p>
					FS-Cache does not alter the basic operation of a file system that works over the network. It merely provides that file system with a persistent place in which it can cache data. For example, a client can still mount an NFS share whether or not FS-Cache is enabled. In addition, cached NFS can handle files that will not fit into the cache (whether individually or collectively) as files can be partially cached and do not have to be read completely up front. FS-Cache also hides all I/O errors that occur in the cache from the client file system driver.
				</p><p>
					To provide caching services, FS-Cache needs a cache back end, the <code class="literal">cachefiles</code> service. FS-Cache requires a mounted block-based file system, that supports block mapping (<code class="literal">bmap</code>) and extended attributes as its cache back end:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							XFS
						</li><li class="listitem">
							ext3
						</li><li class="listitem">
							ext4
						</li></ul></div><p>
					FS-Cache cannot arbitrarily cache any file system, whether through the network or otherwise: the shared file system’s driver must be altered to allow interaction with FS-Cache, data storage or retrieval, and metadata setup and validation. FS-Cache needs <span class="emphasis"><em>indexing keys</em></span> and <span class="emphasis"><em>coherency data</em></span> from the cached file system to support persistence: indexing keys to match file system objects to cache objects, and coherency data to determine whether the cache objects are still valid.
				</p><p>
					Using FS-Cache is a compromise between various factors. If FS-Cache is being used to cache NFS traffic, it may slow the client down, but can massively reduce the network and server loading by satisfying read requests locally without consuming network bandwidth.
				</p></section><section class="section" id="installing-and-configuring-the-cachefilesd-service_enabling-client-side-caching-of-nfs-content"><div class="titlepage"><div><div><h4 class="title">4.11.2. Installing and configuring the cachefilesd service</h4></div></div></div><p>
					Red Hat Enterprise Linux provides only the <code class="literal">cachefiles</code> caching back end. The <code class="literal">cachefilesd</code> service initiates and manages <code class="literal">cachefiles</code>. The <code class="literal">/etc/cachefilesd.conf</code> file controls how <code class="literal">cachefiles</code> provides caching services.
				</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							The file system mounted under the <code class="literal">/var/cache/fscache/</code> directory is <code class="literal">ext3</code>, <code class="literal">ext4</code>, or <code class="literal">xfs</code>.
						</li><li class="listitem">
							The file system mounted under <code class="literal">/var/cache/fscache/</code> uses extended attributes, which is the default if you created the file system on RHEL 8 or later.
						</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Install the <code class="literal">cachefilesd</code> package:
						</p><pre class="screen"># <span class="strong strong"><strong>dnf install cachefilesd</strong></span></pre></li><li class="listitem"><p class="simpara">
							Enable and start the <code class="literal">cachefilesd</code> service:
						</p><pre class="screen"># <span class="strong strong"><strong>systemctl enable --now cachefilesd</strong></span></pre></li></ol></div><div class="orderedlist"><p class="title"><strong>Verification</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Mount an NFS share with the <code class="literal">fsc</code> option to use the cache:
						</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
									To mount a share temporarily, enter:
								</p><pre class="screen"># <span class="strong strong"><strong>mount -o fsc <span class="emphasis"><em>server.example.com:/nfs/projects/</em></span> /mnt/</strong></span></pre></li><li class="listitem"><p class="simpara">
									To mount a share permanently, add the <code class="literal">fsc</code> option to the entry in the <code class="literal">/etc/fstab</code> file:
								</p><pre class="screen"><span class="emphasis"><em>&lt;nfs_server_ip_or_hostname&gt;:/&lt;exported_share&gt;</em></span>     <span class="emphasis"><em>&lt;mount point&gt;</em></span>    nfs <span class="strong strong"><strong>fsc</strong></span> 0 0</pre></li></ol></div></li><li class="listitem"><p class="simpara">
							Display the FS-cache statistics:
						</p><pre class="screen"># <span class="strong strong"><strong>cat /proc/fs/fscache/stats</strong></span></pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<code class="literal">/usr/share/doc/cachefilesd/README</code> file
						</li><li class="listitem">
							<code class="literal">/usr/share/doc/kernel-doc-&lt;kernel_version&gt;/Documentation/filesystems/caching/fscache.rst</code> provided by the <code class="literal">kernel-doc</code> package
						</li></ul></div></section><section class="section" id="sharing-nfs-cache_enabling-client-side-caching-of-nfs-content"><div class="titlepage"><div><div><h4 class="title">4.11.3. Sharing NFS cache</h4></div></div></div><p>
					Because the cache is persistent, blocks of data in the cache are indexed on a sequence of four keys:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Level 1: Server details
						</li><li class="listitem">
							Level 2: Some mount options; security type; FSID; a uniquifier string
						</li><li class="listitem">
							Level 3: File Handle
						</li><li class="listitem">
							Level 4: Page number in file
						</li></ul></div><p>
					To avoid coherency management problems between superblocks, all NFS superblocks that require to cache the data have unique level 2 keys. Normally, two NFS mounts with the same source volume and options share a superblock, and therefore share the caching, even if they mount different directories within that volume.
				</p><div class="example" id="idm139822460866304"><p class="title"><strong>Example 4.1. NFS cache sharing:</strong></p><div class="example-contents"><p>
						The following two mounts likely share the superblock as they have the same mount options, especially if because they come from the same partition on the NFS server:
					</p><pre class="screen"># mount -o fsc home0:/nfs/projects /projects
# mount -o fsc home0:/nfs/home /home/</pre><p>
						If the mount options are different, they do not share the superblock:
					</p><pre class="screen"># mount -o fsc,rsize=8192 home0:/nfs/projects /projects
# mount -o fsc,rsize=65536 home0:/nfs/home /home/</pre></div></div><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
						The user can not share caches between superblocks that have different communications or protocol parameters. For example, it is not possible to share caches between NFSv4.0 and NFSv3 or between NFSv4.1 and NFSv4.2 because they force different superblocks. Also setting parameters, such as the read size (<code class="literal">rsize</code>), prevents cache sharing because, again, it forces a different superblock.
					</p></div></rh-alert></section><section class="section" id="nfs-cache-limitations_enabling-client-side-caching-of-nfs-content"><div class="titlepage"><div><div><h4 class="title">4.11.4. NFS cache limitations</h4></div></div></div><p>
					There are some cache limitations with NFS:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Opening a file from a shared file system for direct I/O automatically bypasses the cache. This is because this type of access must be direct to the server.
						</li><li class="listitem">
							Opening a file from a shared file system for either direct I/O or writing flushes the cached copy of the file. FS-Cache will not cache the file again until it is no longer opened for direct I/O or writing.
						</li><li class="listitem">
							Furthermore, this release of FS-Cache only caches regular NFS files. FS-Cache will not cache directories, symlinks, device files, FIFOs, and sockets.
						</li></ul></div></section><section class="section" id="how-cache-culling-works_enabling-client-side-caching-of-nfs-content"><div class="titlepage"><div><div><h4 class="title">4.11.5. How cache culling works</h4></div></div></div><p>
					The <code class="literal">cachefilesd</code> service works by caching remote data from shared file systems to free space on the local disk. This could potentially consume all available free space, which could cause problems if the disk also contains the root partition. To control this, <code class="literal">cachefilesd</code> tries to maintain a certain amount of free space by discarding old objects, such as less-recently accessed objects, from the cache. This behavior is known as cache culling.
				</p><p>
					Cache culling is done on the basis of the percentage of blocks and the percentage of files available in the underlying file system. There are settings in <code class="literal">/etc/cachefilesd.conf</code> which control six limits:
				</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">brun <span class="emphasis"><em>N%</em></span> (percentage of blocks), frun <span class="emphasis"><em>N%</em></span> (percentage of files)</span></dt><dd>
								If the amount of free space and the number of available files in the cache rises above both these limits, then culling is turned off.
							</dd><dt><span class="term">bcull <span class="emphasis"><em>N%</em></span> (percentage of blocks), fcull <span class="emphasis"><em>N%</em></span> (percentage of files)</span></dt><dd>
								If the amount of available space or the number of files in the cache falls below either of these limits, then culling is started.
							</dd><dt><span class="term">bstop <span class="emphasis"><em>N%</em></span> (percentage of blocks), fstop <span class="emphasis"><em>N%</em></span> (percentage of files)</span></dt><dd>
								If the amount of available space or the number of available files in the cache falls below either of these limits, then no further allocation of disk space or files is permitted until culling has raised things above these limits again.
							</dd></dl></div><p>
					The default value of <code class="literal">N</code> for each setting is as follows:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							<code class="literal">brun/frun</code>: 10%
						</li><li class="listitem">
							<code class="literal">bcull/fcull</code>: 7%
						</li><li class="listitem">
							<code class="literal">bstop/fstop</code>: 3%
						</li></ul></div><p>
					When configuring these settings, the following must hold true:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							0 ≤ <code class="literal">bstop</code> &lt; <code class="literal">bcull</code> &lt; <code class="literal">brun</code> &lt; 100
						</li><li class="listitem">
							0 ≤ <code class="literal">fstop</code> &lt; <code class="literal">fcull</code> &lt; <code class="literal">frun</code> &lt; 100
						</li></ul></div><p>
					These are the percentages of available space and available files and do not appear as 100 minus the percentage displayed by the <code class="literal">df</code> program.
				</p><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
						Culling depends on both b<span class="emphasis"><em>xxx</em></span> and f<span class="emphasis"><em>xxx</em></span> pairs simultaneously; the user can not treat them separately.
					</p></div></rh-alert></section></section></section><section class="chapter" id="mounting-an-smb-share-on-red-hat-enterprise-linux_managing-file-systems"><div class="titlepage"><div><div><h2 class="title">Chapter 5. Mounting an SMB Share</h2></div></div></div><p class="_abstract _abstract">
			The Server Message Block (SMB) protocol implements an application-layer network protocol used to access resources on a server, such as file shares and shared printers.
		</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
				In the context of SMB, you can find mentions about the Common Internet File System (CIFS) protocol, which is a dialect of SMB. Both the SMB and CIFS protocol are supported, and the kernel module and utilities involved in mounting SMB and CIFS shares both use the name <code class="literal">cifs</code>.
			</p></div></rh-alert><p>
			The <code class="literal">cifs-utils</code> package provides utilities to:
		</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
					Mount SMB and CIFS shares
				</li><li class="listitem">
					Manage NT LAN Manager (NTLM) credentials in the kernel’s keyring
				</li><li class="listitem">
					Set and display Access Control Lists (ACL) in a security descriptor on SMB and CIFS shares
				</li></ul></div><section class="section" id="con_supported-smb-protocol-versions_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux"><div class="titlepage"><div><div><h3 class="title">5.1. Supported SMB protocol versions</h3></div></div></div><p class="_abstract _abstract">
				The <code class="literal">cifs.ko</code> kernel module supports the following SMB protocol versions:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						SMB 1
					</p><rh-alert class="admonition warning" state="danger"><div class="admonition_header" slot="header">Warning</div><div><p>
							The SMB1 protocol is deprecated due to known security issues, and is only <span class="strong strong"><strong>safe to use on a private network</strong></span>. The main reason that SMB1 is still provided as a supported option is that currently it is the only SMB protocol version that supports UNIX extensions. If you do not need to use UNIX extensions on SMB, Red Hat strongly recommends using SMB2 or later.
						</p></div></rh-alert></li><li class="listitem">
						SMB 2.0
					</li><li class="listitem">
						SMB 2.1
					</li><li class="listitem">
						SMB 3.0
					</li><li class="listitem">
						SMB 3.1.1
					</li></ul></div><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					Depending on the protocol version, not all SMB features are implemented.
				</p></div></rh-alert></section><section class="section" id="con_unix-extensions-support_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux"><div class="titlepage"><div><div><h3 class="title">5.2. UNIX extensions support</h3></div></div></div><p class="_abstract _abstract">
				Samba uses the <code class="literal">CAP_UNIX</code> capability bit in the SMB protocol to provide the UNIX extensions feature. These extensions are also supported by the <code class="literal">cifs.ko</code> kernel module. However, both Samba and the kernel module support UNIX extensions only in the SMB 1 protocol.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						The <code class="literal">cifs-utils</code> package is installed.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem">
						Set the <code class="literal">server min protocol</code> parameter in the <code class="literal">[global]</code> section in the <code class="literal">/etc/samba/smb.conf</code> file to <code class="literal">NT1</code>.
					</li><li class="listitem"><p class="simpara">
						Mount the share using the SMB 1 protocol by providing the <code class="literal">-o vers=1.0</code> option to the mount command. For example:
					</p><pre class="literallayout"># <span class="strong strong"><strong>mount -t cifs -o vers=1.0,username=<span class="emphasis"><em>&lt;user_name&gt;</em></span> //<span class="emphasis"><em>&lt;server_name&gt;</em></span>/<span class="emphasis"><em>&lt;share_name&gt;</em></span> <span class="emphasis"><em>/mnt/</em></span></strong></span></pre><p class="simpara">
						By default, the kernel module uses SMB 2 or the highest later protocol version supported by the server. Passing the <code class="literal">-o vers=1.0</code> option to the <code class="literal">mount</code> command forces that the kernel module uses the SMB 1 protocol that is required for using UNIX extensions.
					</p></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Display the options of the mounted share:
					</p><pre class="literallayout"># <span class="strong strong"><strong>mount</strong></span>
...
//<span class="emphasis"><em>&lt;server_name&gt;</em></span>/<span class="emphasis"><em>&lt;share_name&gt;</em></span> on <span class="emphasis"><em>/mnt</em></span> type cifs (...,<span class="strong strong"><strong>unix</strong></span>,...)</pre><p class="simpara">
						If the <code class="literal">unix</code> entry is displayed in the list of mount options, UNIX extensions are enabled.
					</p></li></ul></div></section><section class="section" id="proc_manually-mounting-an-smb-share_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux"><div class="titlepage"><div><div><h3 class="title">5.3. Manually mounting an SMB share</h3></div></div></div><p class="_abstract _abstract">
				If you only require an SMB share to be temporary mounted, you can mount it manually using the <code class="literal">mount</code> utility.
			</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					Manually mounted shares are not mounted automatically again when you reboot the system. To configure that Red Hat Enterprise Linux automatically mounts the share when the system boots, see <a class="link" href="#proc_mounting-an-smb-share-automatically-when-the-system-boots_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux" title="5.4. Mounting an SMB share automatically when the system boots">Mounting an SMB share automatically when the system boots</a>.
				</p></div></rh-alert><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						The <code class="literal">cifs-utils</code> package is installed.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Use the <code class="literal">mount</code> utility with the <code class="literal">-t cifs</code> parameter to mount an SMB share:
					</p><pre class="literallayout"># <span class="strong strong"><strong>mount -t cifs -o username=<span class="emphasis"><em>&lt;user_name&gt;</em></span> //<span class="emphasis"><em>&lt;server_name&gt;</em></span>/<span class="emphasis"><em>&lt;share_name&gt;</em></span> <span class="emphasis"><em>/mnt/</em></span></strong></span>
Password for <span class="emphasis"><em>&lt;user_name&gt;</em></span>@//<span class="emphasis"><em>&lt;server_name&gt;</em></span>/<span class="emphasis"><em>&lt;share_name&gt;</em></span>:  <span class="emphasis"><em>password</em></span></pre><p class="simpara">
						In the <code class="literal">-o</code> parameter, you can specify options that are used to mount the share. For details, see the <code class="literal">OPTIONS</code> section in the <code class="literal">mount.cifs(8)</code> man page and <a class="link" href="#con_frequently-used-mount-options_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux" title="5.7. Frequently used SMB mount options">Frequently used mount options</a>.
					</p><div class="example" id="example_mounting-a-share-using-an-encrypted-smb30-connection_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux"><p class="title"><strong>Example 5.1. Mounting a share using an encrypted SMB 3.0 connection</strong></p><div class="example-contents"><p>
							To mount the <code class="literal">\\server\example\</code> share as the <code class="literal"><span class="emphasis"><em>DOMAIN</em></span>\Administrator</code> user over an encrypted SMB 3.0 connection into the <code class="literal">/mnt/</code> directory:
						</p><pre class="literallayout"># <span class="strong strong"><strong>mount -t cifs -o username=<span class="emphasis"><em>DOMAIN</em></span>\Administrator,seal,vers=3.0 //server/example /mnt/</strong></span>
Password for <span class="emphasis"><em>DOMAIN</em></span>\Administrator@//server_name/share_name:  <span class="emphasis"><em>password</em></span></pre></div></div></li></ul></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						List the content of the mounted share:
					</p><pre class="literallayout"># <span class="strong strong"><strong>ls -l /mnt/</strong></span>
total 4
drwxr-xr-x.  2 root root 8748 Dec  4 16:27 test.txt
drwxr-xr-x. 17 root root 4096 Dec  4 07:43 Demo-Directory</pre></li></ul></div></section><section class="section" id="proc_mounting-an-smb-share-automatically-when-the-system-boots_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux"><div class="titlepage"><div><div><h3 class="title">5.4. Mounting an SMB share automatically when the system boots</h3></div></div></div><p class="_abstract _abstract">
				If access to a mounted SMB share is permanently required on a server, mount the share automatically at boot time.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						The <code class="literal">cifs-utils</code> package is installed.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Add an entry for the share to the <code class="literal">/etc/fstab</code> file. For example:
					</p><pre class="literallayout">//<span class="emphasis"><em>&lt;server_name&gt;</em></span>/<span class="emphasis"><em>&lt;share_name&gt;</em></span>  <span class="emphasis"><em>/mnt</em></span>  cifs  credentials=<span class="emphasis"><em>/root/smb.cred</em></span>  0 0</pre><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
							To enable the system to mount a share automatically, you must store the user name, password, and domain name in a credentials file. For details, see <a class="link" href="#proc_authenticating-to-an-smb-share-using-a-credentials-file_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux" title="5.5. Creating a credentials file to authenticate to an SMB share">Creating a credentials file to authenticate to an SMB share</a>
						</p></div></rh-alert><p class="simpara">
						In the fourth field of the row in the <code class="literal">/etc/fstab</code>, specify mount options, such as the path to the credentials file. For details, see the <code class="literal">OPTIONS</code> section in the <code class="literal">mount.cifs(8)</code> man page and <a class="link" href="#con_frequently-used-mount-options_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux" title="5.7. Frequently used SMB mount options">Frequently used mount options</a>.
					</p></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Mount the share by specifying the mount point:
					</p><pre class="literallayout"># <span class="strong strong"><strong>mount /mnt/</strong></span></pre></li></ul></div></section><section class="section" id="proc_authenticating-to-an-smb-share-using-a-credentials-file_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux"><div class="titlepage"><div><div><h3 class="title">5.5. Creating a credentials file to authenticate to an SMB share</h3></div></div></div><p class="_abstract _abstract">
				In certain situations, such as when mounting a share automatically at boot time, a share should be mounted without entering the user name and password. To implement this, create a credentials file.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						The <code class="literal package">cifs-utils</code> package is installed.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Create a file, such as <code class="literal">/root/smb.cred</code>, and specify the user name, password, and domain name that file:
					</p><pre class="literallayout">username=<span class="emphasis"><em>user_name</em></span>
password=<span class="emphasis"><em>password</em></span>
domain=<span class="emphasis"><em>domain_name</em></span></pre></li><li class="listitem"><p class="simpara">
						Set the permissions to only allow the owner to access the file:
					</p><pre class="literallayout"># chown user_name /root/smb.cred
# chmod 600 /root/smb.cred</pre></li></ol></div><p>
				You can now pass the <code class="literal">credentials=<span class="emphasis"><em>file_name</em></span></code> mount option to the <code class="literal">mount</code> utility or use it in the <code class="literal">/etc/fstab</code> file to mount the share without being prompted for the user name and password.
			</p></section><section class="section" id="performing-a-multi-user-smb-mount_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux"><div class="titlepage"><div><div><h3 class="title">5.6. Performing a multi-user SMB mount</h3></div></div></div><p class="_abstract _abstract">
				The credentials you provide to mount a share determine the access permissions on the mount point by default. For example, if you use the <code class="literal"><span class="emphasis"><em>DOMAIN</em></span>\example</code> user when you mount a share, all operations on the share will be executed as this user, regardless which local user performs the operation.
			</p><p>
				However, in certain situations, the administrator wants to mount a share automatically when the system boots, but users should perform actions on the share’s content using their own credentials. The <code class="literal">multiuser</code> mount options lets you configure this scenario.
			</p><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
					To use the <code class="literal">multiuser</code> mount option, you must additionally set the <code class="literal">sec</code> mount option to a security type that supports providing credentials in a non-interactive way, such as <code class="literal">krb5</code> or the <code class="literal">ntlmssp</code> option with a credentials file. For details, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/managing_file_systems/index#proc_accessing-a-share-as-a-user_assembly_performing-a-multi-user-smb-mount">Accessing a share as a user</a>.
				</p></div></rh-alert><p>
				The <code class="literal">root</code> user mounts the share using the <code class="literal">multiuser</code> option and an account that has minimal access to the contents of the share. Regular users can then provide their user name and password to the current session’s kernel keyring using the <code class="literal">cifscreds</code> utility. If the user accesses the content of the mounted share, the kernel uses the credentials from the kernel keyring instead of the one initially used to mount the share.
			</p><p>
				Using this feature consists of the following steps:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/managing_file_systems/index#proc_mounting-a-share-with-the-multiuser-option_assembly_performing-a-multi-user-smb-mount">Mount a share with the <code class="literal">multiuser</code> option</a>.
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/managing_file_systems/index#proc_verifying-if-an-smb-share-is-mounted-with-the-multiuser-option_assembly_performing-a-multi-user-smb-mount">Optionally, verify if the share was successfully mounted with the <code class="literal">multiuser</code> option</a>.
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/managing_file_systems/index#proc_accessing-a-share-as-a-user_assembly_performing-a-multi-user-smb-mount">Access the share as a user</a>.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						The <code class="literal package">cifs-utils</code> package is installed.
					</li></ul></div><section class="section" id="proc_mounting-a-share-with-the-multiuser-option_assembly_performing-a-multi-user-smb-mount"><div class="titlepage"><div><div><h4 class="title">5.6.1. Mounting a share with the multiuser option</h4></div></div></div><p class="_abstract _abstract">
					Before users can access the share with their own credentials, mount the share as the <code class="literal">root</code> user using an account with limited permissions.
				</p><div class="formalpara"><p class="title"><strong>Procedure</strong></p><p>
						To mount a share automatically with the <code class="literal">multiuser</code> option when the system boots:
					</p></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Create the entry for the share in the <code class="literal filename">/etc/fstab</code> file. For example:
						</p><pre class="literallayout"><span class="emphasis"><em>//server_name/share_name</em></span>  <span class="emphasis"><em>/mnt</em></span>  cifs  <code class="literal">multiuser,sec=ntlmssp</code>,credentials=<span class="emphasis"><em>/root/smb.cred</em></span>  0 0</pre></li><li class="listitem"><p class="simpara">
							Mount the share:
						</p><pre class="literallayout"># mount /mnt/</pre></li></ol></div><p>
					If you do not want to mount the share automatically when the system boots, mount it manually by passing <code class="literal">-o multiuser,sec=security_type</code> to the <code class="literal">mount</code> command. For details about mounting an SMB share manually, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/managing_file_systems/index#proc_manually-mounting-an-smb-share_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux">Manually mounting an SMB share</a>.
				</p></section><section class="section" id="proc_verifying-if-an-smb-share-is-mounted-with-the-multiuser-option_assembly_performing-a-multi-user-smb-mount"><div class="titlepage"><div><div><h4 class="title">5.6.2. Verifying if an SMB share is mounted with the multiuser option</h4></div></div></div><p class="_abstract _abstract">
					To verify if a share is mounted with the <code class="literal">multiuser</code> option, display the mount options.
				</p><div class="formalpara"><p class="title"><strong>Procedure</strong></p><p>

</p><pre class="literallayout"># mount
...
<span class="emphasis"><em>//server_name/share_name</em></span> on <span class="emphasis"><em>/mnt</em></span> type cifs (sec=ntlmssp,<code class="literal">multiuser</code>,...)</pre>

					<p></p></div><p>
					If the <code class="literal">multiuser</code> entry is displayed in the list of mount options, the feature is enabled.
				</p></section><section class="section" id="proc_accessing-a-share-as-a-user_assembly_performing-a-multi-user-smb-mount"><div class="titlepage"><div><div><h4 class="title">5.6.3. Accessing a share as a user</h4></div></div></div><p class="_abstract _abstract">
					If an SMB share is mounted with the <code class="literal">multiuser</code> option, users can provide their credentials for the server to the kernel’s keyring:
				</p><pre class="literallayout"># cifscreds add -u <span class="emphasis"><em>SMB_user_name</em></span> <span class="emphasis"><em>server_name</em></span>
Password: <span class="emphasis"><em>password</em></span></pre><p>
					When the user performs operations in the directory that contains the mounted SMB share, the server applies the file system permissions for this user, instead of the one initially used when the share was mounted.
				</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
						Multiple users can perform operations using their own credentials on the mounted share at the same time.
					</p></div></rh-alert></section></section><section class="section" id="con_frequently-used-mount-options_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux"><div class="titlepage"><div><div><h3 class="title">5.7. Frequently used SMB mount options</h3></div></div></div><p class="_abstract _abstract">
				When you mount an SMB share, the mount options determine:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						How the connection will be established with the server. For example, which SMB protocol version is used when connecting to the server.
					</li><li class="listitem">
						How the share will be mounted into the local file system. For example, if the system overrides the remote file and directory permissions to enable multiple local users to access the content on the server.
					</li></ul></div><p>
				To set multiple options in the fourth field of the <code class="literal filename">/etc/fstab</code> file or in the <code class="literal">-o</code> parameter of a mount command, separate them with commas. For example, see <a class="link" href="#proc_mounting-a-share-with-the-multiuser-option_assembly_performing-a-multi-user-smb-mount" title="5.6.1. Mounting a share with the multiuser option">Mounting a share with the multiuser option</a>.
			</p><p>
				The following list gives frequently used mount options:
			</p><rh-table><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 29%; " class="col_1"><!--Empty--><col style="width: 71%; " class="col_2"><!--Empty--></colgroup><thead><tr><th align="left" valign="top" id="idm139822456464240" scope="col">Option</th><th align="left" valign="top" id="idm139822456463152" scope="col">Description</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm139822456464240"> <p>
								credentials=<span class="emphasis"><em>file_name</em></span>
							</p>
							 </td><td align="left" valign="top" headers="idm139822456463152"> <p>
								Sets the path to the credentials file. See <a class="link" href="#proc_authenticating-to-an-smb-share-using-a-credentials-file_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux" title="5.5. Creating a credentials file to authenticate to an SMB share">Authenticating to an SMB share using a credentials file</a>.
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822456464240"> <p>
								dir_mode=<span class="emphasis"><em>mode</em></span>
							</p>
							 </td><td align="left" valign="top" headers="idm139822456463152"> <p>
								Sets the directory mode if the server does not support CIFS UNIX extensions.
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822456464240"> <p>
								file_mode=<span class="emphasis"><em>mode</em></span>
							</p>
							 </td><td align="left" valign="top" headers="idm139822456463152"> <p>
								Sets the file mode if the server does not support CIFS UNIX extensions.
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822456464240"> <p>
								password=<span class="emphasis"><em>password</em></span>
							</p>
							 </td><td align="left" valign="top" headers="idm139822456463152"> <p>
								Sets the password used to authenticate to the SMB server. Alternatively, specify a credentials file using the <code class="literal">credentials</code> option.
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822456464240"> <p>
								seal
							</p>
							 </td><td align="left" valign="top" headers="idm139822456463152"> <p>
								Enables encryption support for connections using SMB 3.0 or a later protocol version. Therefore, use <code class="literal">seal</code> together with the <code class="literal">vers</code> mount option set to <code class="literal">3.0</code> or later. See the example in <a class="link" href="#proc_manually-mounting-an-smb-share_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux" title="5.3. Manually mounting an SMB share">Manually mounting an SMB share</a>.
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822456464240"> <p>
								sec=<span class="emphasis"><em>security_mode</em></span>
							</p>
							 </td><td align="left" valign="top" headers="idm139822456463152"> <p>
								Sets the security mode, such as <code class="literal">ntlmsspi</code>, to enable NTLMv2 password hashing and enabled packet signing. For a list of supported values, see the option’s description in the <code class="literal">mount.cifs(8)</code> man page on your system.
							</p>
							 <p>
								If the server does not support the <code class="literal">ntlmv2</code> security mode, use <code class="literal">sec=ntlmssp</code>, which is the default.
							</p>
							 <p>
								For security reasons, do not use the insecure <code class="literal">ntlm</code> security mode.
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822456464240"> <p>
								username=<span class="emphasis"><em>user_name</em></span>
							</p>
							 </td><td align="left" valign="top" headers="idm139822456463152"> <p>
								Sets the user name used to authenticate to the SMB server. Alternatively, specify a credentials file using the <code class="literal">credentials</code> option.
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822456464240"> <p>
								vers=<span class="emphasis"><em>SMB_protocol_version</em></span>
							</p>
							 </td><td align="left" valign="top" headers="idm139822456463152"> <p>
								Sets the SMB protocol version used for the communication with the server.
							</p>
							 </td></tr></tbody></table></rh-table><p>
				For a complete list, see the <code class="literal">OPTIONS</code> section in the <code class="literal">mount.cifs(8)</code> man page on your system.
			</p></section></section><section class="chapter" id="assembly_overview-of-persistent-naming-attributes_managing-file-systems"><div class="titlepage"><div><div><h2 class="title">Chapter 6. Overview of persistent naming attributes</h2></div></div></div><p class="_abstract _abstract">
			As a system administrator, you need to refer to storage volumes using persistent naming attributes to build storage setups that are reliable over multiple system boots.
		</p><section class="section" id="con_disadvantages-of-non-persistent-naming-attributes_assembly_overview-of-persistent-naming-attributes"><div class="titlepage"><div><div><h3 class="title">6.1. Disadvantages of non-persistent naming attributes</h3></div></div></div><p class="_abstract _abstract">
				Red Hat Enterprise Linux provides a number of ways to identify storage devices. It is important to use the correct option to identify each device when used in order to avoid inadvertently accessing the wrong device, particularly when installing to or reformatting drives.
			</p><p>
				Traditionally, non-persistent names in the form of <code class="literal">/dev/sd<span class="emphasis"><em><span class="replaceable replaceable">(major number)</span></em></span><span class="emphasis"><em><span class="replaceable replaceable">(minor number)</span></em></span></code> are used on Linux to refer to storage devices. The major and minor number range and associated <code class="literal">sd</code> names are allocated for each device when it is detected. This means that the association between the major and minor number range and associated <code class="literal">sd</code> names can change if the order of device detection changes.
			</p><p>
				Such a change in the ordering might occur in the following situations:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						The parallelization of the system boot process detects storage devices in a different order with each system boot.
					</li><li class="listitem">
						A disk fails to power up or respond to the SCSI controller. This results in it not being detected by the normal device probe. The disk is not accessible to the system and subsequent devices will have their major and minor number range, including the associated <code class="literal">sd</code> names shifted down. For example, if a disk normally referred to as <code class="literal">sdb</code> is not detected, a disk that is normally referred to as <code class="literal">sdc</code> would instead appear as <code class="literal">sdb</code>.
					</li><li class="listitem">
						A SCSI controller (host bus adapter, or HBA) fails to initialize, causing all disks connected to that HBA to not be detected. Any disks connected to subsequently probed HBAs are assigned different major and minor number ranges, and different associated <code class="literal">sd</code> names.
					</li><li class="listitem">
						The order of driver initialization changes if different types of HBAs are present in the system. This causes the disks connected to those HBAs to be detected in a different order. This might also occur if HBAs are moved to different PCI slots on the system.
					</li><li class="listitem">
						Disks connected to the system with Fibre Channel, iSCSI, or FCoE adapters might be inaccessible at the time the storage devices are probed, due to a storage array or intervening switch being powered off, for example. This might occur when a system reboots after a power failure, if the storage array takes longer to come online than the system take to boot. Although some Fibre Channel drivers support a mechanism to specify a persistent SCSI target ID to WWPN mapping, this does not cause the major and minor number ranges, and the associated <code class="literal">sd</code> names to be reserved; it only provides consistent SCSI target ID numbers.
					</li></ul></div><p>
				These reasons make it undesirable to use the major and minor number range or the associated <code class="literal">sd</code> names when referring to devices, such as in the <code class="literal filename">/etc/fstab</code> file. There is the possibility that the wrong device will be mounted and data corruption might result.
			</p><p>
				Occasionally, however, it is still necessary to refer to the <code class="literal">sd</code> names even when another mechanism is used, such as when errors are reported by a device. This is because the Linux kernel uses <code class="literal">sd</code> names (and also SCSI host/channel/target/LUN tuples) in kernel messages regarding the device.
			</p></section><section class="section" id="file-system-and-device-identifiers_assembly_overview-of-persistent-naming-attributes"><div class="titlepage"><div><div><h3 class="title">6.2. File system and device identifiers</h3></div></div></div><p class="_abstract _abstract">
				File system identifiers are tied to the file system itself, while device identifiers are linked to the physical block device. Understanding the difference is important for proper storage management.
			</p><h5 id="file_system_identifiers">File system identifiers</h5><p>
				File system identifiers are tied to a particular file system created on a block device. The identifier is also stored as part of the file system. If you copy the file system to a different device, it still carries the same file system identifier. However, if you rewrite the device, such as by formatting it with the <code class="literal">mkfs</code> utility, the device loses the attribute.
			</p><p>
				File system identifiers include:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Unique identifier (UUID)
					</li><li class="listitem">
						Label
					</li></ul></div><h5 id="device_identifiers">Device identifiers</h5><p>
				Device identifiers are tied to a block device: for example, a disk or a partition. If you rewrite the device, such as by formatting it with the <code class="literal">mkfs</code> utility, the device keeps the attribute, because it is not stored in the file system.
			</p><p>
				Device identifiers include:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						World Wide Identifier (WWID)
					</li><li class="listitem">
						Partition UUID
					</li><li class="listitem">
						Serial number
					</li></ul></div><h5 id="recommendations">Recommendations</h5><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Some file systems, such as logical volumes, span multiple devices. Red Hat recommends accessing these file systems using file system identifiers rather than device identifiers.
					</li></ul></div></section><section class="section" id="con_device-names-managed-by-the-udev-mechanism-in-dev-disk-_assembly_overview-of-persistent-naming-attributes"><div class="titlepage"><div><div><h3 class="title">6.3. Device names managed by the udev mechanism in /dev/disk/</h3></div></div></div><p class="_abstract _abstract">
				The <code class="literal">udev</code> mechanism is used for all types of devices in Linux, and is not limited only for storage devices. It provides different kinds of persistent naming attributes in the <code class="literal">/dev/disk/</code> directory. In the case of storage devices, Red Hat Enterprise Linux contains <code class="literal">udev</code> rules that create symbolic links in the <code class="literal">/dev/disk/</code> directory. This enables you to refer to storage devices by:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Their content
					</li><li class="listitem">
						A unique identifier
					</li><li class="listitem">
						Their serial number.
					</li></ul></div><p>
				Although <code class="literal">udev</code> naming attributes are persistent, in that they do not change on their own across system reboots, some are also configurable.
			</p><section class="section" id="file-system-identifiers_assembly_overview-of-persistent-naming-attributes"><div class="titlepage"><div><div><h4 class="title">6.3.1. File system identifiers</h4></div></div></div><h5 id="the_uuid_attribute_in_dev_disk_by_uuid">The UUID attribute in /dev/disk/by-uuid/</h5><p>
					Entries in this directory provide a symbolic name that refers to the storage device by a <span class="strong strong"><strong>unique identifier</strong></span> (UUID) in the content (that is, the data) stored on the device. For example:
				</p><pre class="screen">/dev/disk/by-uuid/<span class="emphasis"><em>3e6be9de-8139-11d1-9106-a43f08d823a6</em></span></pre><p>
					You can use the UUID to refer to the device in the <code class="literal filename">/etc/fstab</code> file using the following syntax:
				</p><pre class="screen">UUID=<span class="emphasis"><em>3e6be9de-8139-11d1-9106-a43f08d823a6</em></span></pre><p>
					You can configure the UUID attribute when creating a file system, and you can also change it later on.
				</p><h5 id="the_label_attribute_in_dev_disk_by_label">The Label attribute in /dev/disk/by-label/</h5><p>
					Entries in this directory provide a symbolic name that refers to the storage device by a <span class="strong strong"><strong>label</strong></span> in the content (that is, the data) stored on the device.
				</p><p>
					For example:
				</p><pre class="screen">/dev/disk/by-label/<span class="emphasis"><em>Boot</em></span></pre><p>
					You can use the label to refer to the device in the <code class="literal filename">/etc/fstab</code> file using the following syntax:
				</p><pre class="screen">LABEL=<span class="emphasis"><em>Boot</em></span></pre><p>
					You can configure the Label attribute when creating a file system, and you can also change it later on.
				</p></section><section class="section" id="device-identifiers_assembly_overview-of-persistent-naming-attributes"><div class="titlepage"><div><div><h4 class="title">6.3.2. Device identifiers</h4></div></div></div><h5 id="the_wwid_attribute_in_dev_disk_by_id">The WWID attribute in /dev/disk/by-id/</h5><p>
					The World Wide Identifier (WWID) is a persistent, <span class="strong strong"><strong>system-independent identifier</strong></span> that the SCSI Standard requires from all SCSI devices. The WWID identifier is guaranteed to be unique for every storage device, and independent of the path that is used to access the device. The identifier is a property of the device but is not stored in the content (that is, the data) on the devices.
				</p><p>
					This identifier can be obtained by issuing a SCSI Inquiry to retrieve the Device Identification Vital Product Data (page <code class="literal">0x83</code>) or Unit Serial Number (page <code class="literal">0x80</code>).
				</p><p>
					Red Hat Enterprise Linux automatically maintains the proper mapping from the WWID-based device name to a current <code class="literal">/dev/sd</code> name on that system. Applications can use the <code class="literal">/dev/disk/by-id/</code> name to reference the data on the disk, even if the path to the device changes, and even when accessing the device from different systems.
				</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
						If your are using an NVMe device, you might run into a disk by-id naming change for some vendors, if the serial number of your device has leading whitespace.
					</p></div></rh-alert><div class="example" id="idm139822461318192"><p class="title"><strong>Example 6.1. WWID mappings</strong></p><div class="example-contents"><rh-table><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 50%; " class="col_1"><!--Empty--><col style="width: 25%; " class="col_2"><!--Empty--><col style="width: 25%; " class="col_3"><!--Empty--></colgroup><thead><tr><th align="left" valign="top" id="idm139822460306640" scope="col">WWID symlink</th><th align="left" valign="top" id="idm139822460305552" scope="col">Non-persistent device</th><th align="left" valign="top" id="idm139822460304464" scope="col">Note</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm139822460306640"> <p>
										<code class="literal filename">/dev/disk/by-id/scsi-3600508b400105e210000900000490000</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139822460305552"> <p>
										<code class="literal filename">/dev/sda</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139822460304464"> <p>
										A device with a page <code class="literal">0x83</code> identifier
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139822460306640"> <p>
										<code class="literal filename">/dev/disk/by-id/scsi-SSEAGATE_ST373453LW_3HW1RHM6</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139822460305552"> <p>
										<code class="literal filename">/dev/sdb</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139822460304464"> <p>
										A device with a page <code class="literal">0x80</code> identifier
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139822460306640"> <p>
										<code class="literal filename">/dev/disk/by-id/ata-SAMSUNG_MZNLN256HMHQ-000L7_S2WDNX0J336519-part3</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139822460305552"> <p>
										<code class="literal filename">/dev/sdc3</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139822460304464"> <p>
										A disk partition
									</p>
									 </td></tr></tbody></table></rh-table></div></div><p>
					In addition to these persistent names provided by the system, you can also use <code class="literal">udev</code> rules to implement persistent names of your own, mapped to the WWID of the storage.
				</p><h5 id="the_partition_uuid_attribute_in_dev_disk_by_partuuid">The Partition UUID attribute in /dev/disk/by-partuuid</h5><p>
					The Partition UUID (PARTUUID) attribute identifies partitions as defined by GPT partition table.
				</p><div class="example" id="idm139822467256560"><p class="title"><strong>Example 6.2. Partition UUID mappings</strong></p><div class="example-contents"><rh-table><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 60%; " class="col_1"><!--Empty--><col style="width: 40%; " class="col_2"><!--Empty--></colgroup><thead><tr><th align="left" valign="top" id="idm139822458643456" scope="col">PARTUUID symlink</th><th align="left" valign="top" id="idm139822458642368" scope="col">Non-persistent device</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm139822458643456"> <p>
										<code class="literal filename">/dev/disk/by-partuuid/4cd1448a-01</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139822458642368"> <p>
										<code class="literal filename">/dev/sda1</code>
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139822458643456"> <p>
										<code class="literal filename">/dev/disk/by-partuuid/4cd1448a-02</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139822458642368"> <p>
										<code class="literal filename">/dev/sda2</code>
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm139822458643456"> <p>
										<code class="literal filename">/dev/disk/by-partuuid/4cd1448a-03</code>
									</p>
									 </td><td align="left" valign="top" headers="idm139822458642368"> <p>
										<code class="literal filename">/dev/sda3</code>
									</p>
									 </td></tr></tbody></table></rh-table></div></div><h5 id="the_path_attribute_in_dev_disk_by_path">The Path attribute in /dev/disk/by-path/</h5><p>
					This attribute provides a symbolic name that refers to the storage device by the <span class="strong strong"><strong>hardware path</strong></span> used to access the device.
				</p><p>
					The Path attribute fails if any part of the hardware path (for example, the PCI ID, target port, or LUN number) changes. The Path attribute is therefore unreliable. However, the Path attribute may be useful in one of the following scenarios:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							You need to identify a disk that you are planning to replace later.
						</li><li class="listitem">
							You plan to install a storage service on a disk in a specific location.
						</li></ul></div></section></section><section class="section" id="con_the-world-wide-identifier-with-dm-multipath_assembly_overview-of-persistent-naming-attributes"><div class="titlepage"><div><div><h3 class="title">6.4. The World Wide Identifier with DM Multipath</h3></div></div></div><p>
				You can configure Device Mapper (DM) Multipath to map between the World Wide Identifier (WWID) and non-persistent device names.
			</p><p>
				If there are multiple paths from a system to a device, DM Multipath uses the WWID to detect this. DM Multipath then presents a single "pseudo-device" in the <code class="literal">/dev/mapper/wwid</code> directory, such as <code class="literal">/dev/mapper/3600508b400105df70000e00000ac0000</code>.
			</p><p>
				The command <code class="literal">multipath -l</code> shows the mapping to the non-persistent identifiers:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						<code class="literal"><span class="emphasis"><em>Host</em></span>:<span class="emphasis"><em>Channel</em></span>:<span class="emphasis"><em>Target</em></span>:<span class="emphasis"><em>LUN</em></span></code>
					</li><li class="listitem">
						<code class="literal">/dev/sd</code> name
					</li><li class="listitem">
						<code class="literal"><span class="emphasis"><em>major</em></span>:<span class="emphasis"><em>minor</em></span></code> number
					</li></ul></div><div class="example" id="idm139822458398160"><p class="title"><strong>Example 6.3. WWID mappings in a multipath configuration</strong></p><div class="example-contents"><p>
					An example output of the <code class="literal">multipath -l</code> command:
				</p><pre class="screen">3600508b400105df70000e00000ac0000 dm-2 vendor,product
[size=20G][features=1 queue_if_no_path][hwhandler=0][rw]
\_ round-robin 0 [prio=0][active]
 \_ 5:0:1:1 sdc 8:32  [active][undef]
 \_ 6:0:1:1 sdg 8:96  [active][undef]
\_ round-robin 0 [prio=0][enabled]
 \_ 5:0:0:1 sdb 8:16  [active][undef]
 \_ 6:0:0:1 sdf 8:80  [active][undef]</pre></div></div><p>
				DM Multipath automatically maintains the proper mapping of each WWID-based device name to its corresponding <code class="literal">/dev/sd</code> name on the system. These names are persistent across path changes, and they are consistent when accessing the device from different systems.
			</p><p>
				When the <code class="literal">user_friendly_names</code> feature of DM Multipath is used, the WWID is mapped to a name of the form <code class="literal">/dev/mapper/mpath<span class="emphasis"><em>N</em></span></code>. By default, this mapping is maintained in the file <code class="literal">/etc/multipath/bindings</code>. These <code class="literal">mpath<span class="emphasis"><em>N</em></span></code> names are persistent as long as that file is maintained.
			</p><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
					If you use <code class="literal">user_friendly_names</code>, then additional steps are required to obtain consistent names in a cluster.
				</p></div></rh-alert></section><section class="section" id="con_limitations-of-the-udev-device-naming-convention_assembly_overview-of-persistent-naming-attributes"><div class="titlepage"><div><div><h3 class="title">6.5. Limitations of the udev device naming convention</h3></div></div></div><p class="_abstract _abstract">
				The following are some limitations of the <code class="literal">udev</code> naming convention:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						It is possible that the device might not be accessible at the time the query is performed because the <code class="literal">udev</code> mechanism might rely on the ability to query the storage device when the <code class="literal">udev</code> rules are processed for a <code class="literal">udev</code> event. This is more likely to occur with Fibre Channel, iSCSI or FCoE storage devices when the device is not located in the server chassis.
					</li><li class="listitem">
						The kernel might send <code class="literal">udev</code> events at any time, causing the rules to be processed and possibly causing the <code class="literal filename">/dev/disk/by-*/</code> links to be removed if the device is not accessible.
					</li><li class="listitem">
						There might be a delay between when the <code class="literal">udev</code> event is generated and when it is processed, such as when a large number of devices are detected and the user-space <code class="literal">udevd</code> service takes some amount of time to process the rules for each one. This might cause a delay between when the kernel detects the device and when the <code class="literal filename">/dev/disk/by-*/</code> names are available.
					</li><li class="listitem">
						External programs such as <code class="literal">blkid</code> invoked by the rules might open the device for a brief period of time, making the device inaccessible for other uses.
					</li><li class="listitem">
						The device names managed by the <code class="literal">udev</code> mechanism in /dev/disk/ may change between major releases, requiring you to update the links.
					</li></ul></div></section><section class="section" id="proc_listing-persistent-naming-attributes_assembly_overview-of-persistent-naming-attributes"><div class="titlepage"><div><div><h3 class="title">6.6. Listing persistent naming attributes</h3></div></div></div><p class="_abstract _abstract">
				You can find out the persistent naming attributes of non-persistent storage devices.
			</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						To list the UUID and Label attributes, use the <code class="literal">lsblk</code> utility:
					</p><pre class="screen">$ lsblk --fs <span class="emphasis"><em><span class="replaceable replaceable">storage-device</span></em></span></pre><p class="simpara">
						For example:
					</p><div class="example" id="idm139822448907872"><p class="title"><strong>Example 6.4. Viewing the UUID and Label of a file system</strong></p><div class="example-contents"><pre class="screen">$ lsblk --fs /dev/sda1

NAME FSTYPE <span class="strong strong"><strong>LABEL</strong></span> <span class="strong strong"><strong>UUID</strong></span>                                 MOUNTPOINT
sda1 xfs    <span class="strong strong"><strong>Boot</strong></span>  <span class="strong strong"><strong>afa5d5e3-9050-48c3-acc1-bb30095f3dc4</strong></span> /boot</pre></div></div></li><li class="listitem"><p class="simpara">
						To list the PARTUUID attribute, use the <code class="literal">lsblk</code> utility with the <code class="literal option">--output +PARTUUID</code> option:
					</p><pre class="screen">$ lsblk --output +PARTUUID</pre><p class="simpara">
						For example:
					</p><div class="example" id="idm139822453035200"><p class="title"><strong>Example 6.5. Viewing the PARTUUID attribute of a partition</strong></p><div class="example-contents"><pre class="screen">$ lsblk --output +PARTUUID /dev/sda1

NAME MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT <span class="strong strong"><strong>PARTUUID</strong></span>
sda1   8:1    0  512M  0 part /boot      <span class="strong strong"><strong>4cd1448a-01</strong></span></pre></div></div></li><li class="listitem"><p class="simpara">
						To list the WWID attribute, examine the targets of symbolic links in the <code class="literal filename">/dev/disk/by-id/</code> directory. For example:
					</p><div class="example" id="idm139822448577520"><p class="title"><strong>Example 6.6. Viewing the WWID of all storage devices on the system</strong></p><div class="example-contents"><pre class="screen">$ file /dev/disk/by-id/*

/dev/disk/by-id/ata-QEMU_HARDDISK_QM00001
symbolic link to ../../sda
/dev/disk/by-id/ata-QEMU_HARDDISK_QM00001-part1
symbolic link to ../../sda1
/dev/disk/by-id/ata-QEMU_HARDDISK_QM00001-part2
symbolic link to ../../sda2
/dev/disk/by-id/dm-name-rhel_rhel8-root
symbolic link to ../../dm-0
/dev/disk/by-id/dm-name-rhel_rhel8-swap
symbolic link to ../../dm-1
/dev/disk/by-id/dm-uuid-LVM-QIWtEHtXGobe5bewlIUDivKOz5ofkgFhP0RMFsNyySVihqEl2cWWbR7MjXJolD6g
symbolic link to ../../dm-1
/dev/disk/by-id/dm-uuid-LVM-QIWtEHtXGobe5bewlIUDivKOz5ofkgFhXqH2M45hD2H9nAf2qfWSrlRLhzfMyOKd
symbolic link to ../../dm-0
/dev/disk/by-id/lvm-pv-uuid-atlr2Y-vuMo-ueoH-CpMG-4JuH-AhEF-wu4QQm
symbolic link to ../../sda2</pre></div></div></li></ul></div></section><section class="section" id="proc_modifying-persistent-naming-attributes_assembly_overview-of-persistent-naming-attributes"><div class="titlepage"><div><div><h3 class="title">6.7. Modifying persistent naming attributes</h3></div></div></div><p class="_abstract _abstract">
				You can change the UUID or Label persistent naming attribute of a file system.
			</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					Changing <code class="literal">udev</code> attributes happens in the background and might take a long time. The <code class="literal command">udevadm settle</code> command waits until the change is fully registered, which ensures that your next command will be able to use the new attribute correctly.
				</p></div></rh-alert><p>
				In the following commands:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Replace <span class="emphasis"><em><span class="replaceable replaceable">new-uuid</span></em></span> with the UUID you want to set; for example, <code class="literal">1cdfbc07-1c90-4984-b5ec-f61943f5ea50</code>. You can generate a UUID using the <code class="literal command">uuidgen</code> command.
					</li><li class="listitem">
						Replace <span class="emphasis"><em><span class="replaceable replaceable">new-label</span></em></span> with a label; for example, <code class="literal">backup_data</code>.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						If you are modifying the attributes of an XFS file system, unmount it first.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						To change the UUID or Label attributes of an <span class="strong strong"><strong>XFS</strong></span> file system, use the <code class="literal">xfs_admin</code> utility:
					</p><pre class="screen"># xfs_admin -U <span class="emphasis"><em><span class="replaceable replaceable">new-uuid</span></em></span> -L <span class="emphasis"><em><span class="replaceable replaceable">new-label</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">storage-device</span></em></span>
# udevadm settle</pre></li><li class="listitem"><p class="simpara">
						To change the UUID or Label attributes of an <span class="strong strong"><strong>ext4</strong></span>, <span class="strong strong"><strong>ext3</strong></span>, or <span class="strong strong"><strong>ext2</strong></span> file system, use the <code class="literal">tune2fs</code> utility:
					</p><pre class="screen"># tune2fs -U <span class="emphasis"><em><span class="replaceable replaceable">new-uuid</span></em></span> -L <span class="emphasis"><em><span class="replaceable replaceable">new-label</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">storage-device</span></em></span>
# udevadm settle</pre></li><li class="listitem"><p class="simpara">
						To change the UUID or Label attributes of a swap volume, use the <code class="literal">swaplabel</code> utility:
					</p><pre class="screen"># swaplabel --uuid <span class="emphasis"><em><span class="replaceable replaceable">new-uuid</span></em></span> --label <span class="emphasis"><em><span class="replaceable replaceable">new-label</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">swap-device</span></em></span>
# udevadm settle</pre></li></ul></div></section></section><section class="chapter" id="partition-operations-with-parted_managing-file-systems"><div class="titlepage"><div><div><h2 class="title">Chapter 7. Partition operations with parted</h2></div></div></div><p>
			<code class="literal">parted</code> is a program to manipulate disk partitions. It supports multiple partition table formats, including MS-DOS and GPT. It is useful for creating space for new operating systems, reorganizing disk usage, and copying data to new hard disks.
		</p><section class="section" id="viewing-the-partition-table-with-parted_partition-operations-with-parted"><div class="titlepage"><div><div><h3 class="title">7.1. Viewing the partition table with parted</h3></div></div></div><p>
				Display the partition table of a block device to see the partition layout and details about individual partitions. You can view the partition table on a block device using the <code class="literal">parted</code> utility.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Start the <code class="literal">parted</code> utility. For example, the following output lists the device <code class="literal">/dev/sda</code>:
					</p><pre class="screen"># parted /dev/sda</pre></li><li class="listitem"><p class="simpara">
						View the partition table:
					</p><pre class="screen"># (parted) print

Model: ATA SAMSUNG MZNLN256 (scsi)
Disk /dev/sda: 256GB
Sector size (logical/physical): 512B/512B
Partition Table: msdos
Disk Flags:

Number  Start   End     Size    Type      File system  Flags
 1      1049kB  269MB   268MB   primary   xfs          boot
 2      269MB   34.6GB  34.4GB  primary
 3      34.6GB  45.4GB  10.7GB  primary
 4      45.4GB  256GB   211GB   extended
 5      45.4GB  256GB   211GB   logical</pre></li><li class="listitem"><p class="simpara">
						Optional: Switch to the device you want to examine next:
					</p><pre class="screen"># (parted) select <span class="emphasis"><em>block-device</em></span></pre></li></ol></div><p>
				For a detailed description of the print command output, see the following:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">Model: ATA SAMSUNG MZNLN256 (scsi)</code></span></dt><dd>
							The disk type, manufacturer, model number, and interface.
						</dd><dt><span class="term"><code class="literal">Disk /dev/sda: 256GB</code></span></dt><dd>
							The file path to the block device and the storage capacity.
						</dd><dt><span class="term"><code class="literal">Partition Table: msdos</code></span></dt><dd>
							The disk label type.
						</dd><dt><span class="term"><code class="literal">Number</code></span></dt><dd>
							The partition number. For example, the partition with minor number 1 corresponds to <code class="literal filename">/dev/sda1</code>.
						</dd><dt><span class="term"><code class="literal">Start</code> and <code class="literal">End</code></span></dt><dd>
							The location on the device where the partition starts and ends.
						</dd><dt><span class="term"><code class="literal">Type</code></span></dt><dd>
							Valid types are metadata, free, primary, extended, or logical.
						</dd><dt><span class="term"><code class="literal">File system</code></span></dt><dd>
							The file system type. If the <code class="literal">File system</code> field of a device shows no value, this means that its file system type is unknown. The <code class="literal">parted</code> utility cannot recognize the file system on encrypted devices.
						</dd><dt><span class="term"><code class="literal">Flags</code></span></dt><dd>
							Lists the flags set for the partition. Available flags are <code class="literal">boot</code>, <code class="literal">root</code>, <code class="literal">swap</code>, <code class="literal">hidden</code>, <code class="literal">raid</code>, <code class="literal">lvm</code>, or <code class="literal">lba</code>.
						</dd></dl></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">parted(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="proc_creating-a-partition-table-on-a-disk-with-parted_partition-operations-with-parted"><div class="titlepage"><div><div><h3 class="title">7.2. Creating a partition table on a disk with parted</h3></div></div></div><p>
				Use the <code class="literal">parted</code> utility to format a block device with a partition table more easily.
			</p><rh-alert class="admonition warning" state="danger"><div class="admonition_header" slot="header">Warning</div><div><p>
					Formatting a block device with a partition table deletes all data stored on the device.
				</p></div></rh-alert><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Start the interactive <code class="literal">parted</code> shell:
					</p><pre class="screen"># parted <span class="emphasis"><em>block-device</em></span></pre></li><li class="listitem"><p class="simpara">
						Determine if there already is a partition table on the device:
					</p><pre class="screen"># (parted) print</pre><p class="simpara">
						If the device already contains partitions, they will be deleted in the following steps.
					</p></li><li class="listitem"><p class="simpara">
						Create the new partition table:
					</p><pre class="screen"># (parted) mklabel <span class="emphasis"><em>table-type</em></span></pre><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								Replace <span class="emphasis"><em>table-type</em></span> with with the intended partition table type:
							</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
										<code class="literal">msdos</code> for MBR
									</li><li class="listitem">
										<code class="literal">gpt</code> for GPT
									</li></ul></div></li></ul></div><div class="example" id="idm139822449441328"><p class="title"><strong>Example 7.1. Creating a GUID Partition Table (GPT) table</strong></p><div class="example-contents"><p>
							To create a GPT table on the disk, use:
						</p><pre class="screen"># (parted) mklabel gpt</pre></div></div><p class="simpara">
						The changes start applying after you enter this command.
					</p></li><li class="listitem"><p class="simpara">
						View the partition table to confirm that it is created:
					</p><pre class="screen"># (parted) print</pre></li><li class="listitem"><p class="simpara">
						Exit the <code class="literal">parted</code> shell:
					</p><pre class="screen"># (parted) quit</pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">parted(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="proc_creating-a-partition-with-parted_partition-operations-with-parted"><div class="titlepage"><div><div><h3 class="title">7.3. Creating a partition with parted</h3></div></div></div><p>
				As a system administrator, you can create new partitions on a disk by using the <code class="literal">parted</code> utility.
			</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					The required partitions are <code class="literal">swap</code>, <code class="literal">/boot/</code>, and <code class="literal">/ (root)</code>.
				</p></div></rh-alert><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						A partition table on the disk.
					</li><li class="listitem">
						If the partition you want to create is larger than 2TiB, format the disk with the <span class="strong strong"><strong>GUID Partition Table (GPT)</strong></span>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Start the <code class="literal">parted</code> utility:
					</p><pre class="screen"># parted <span class="emphasis"><em>block-device</em></span></pre></li><li class="listitem"><p class="simpara">
						View the current partition table to determine if there is enough free space:
					</p><pre class="screen"># (parted) print</pre><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								Resize the partition in case there is not enough free space.
							</li><li class="listitem"><p class="simpara">
								From the partition table, determine:
							</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
										The start and end points of the new partition.
									</li><li class="listitem">
										On MBR, what partition type it should be.
									</li></ul></div></li></ul></div></li><li class="listitem"><p class="simpara">
						Create the new partition:
					</p><pre class="screen"># (parted) mkpart <span class="emphasis"><em><span class="replaceable replaceable">part-type</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">name</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">fs-type</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">start</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">end</span></em></span></pre><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								Replace <span class="emphasis"><em>part-type</em></span> with with <code class="literal">primary</code>, <code class="literal">logical</code>, or <code class="literal">extended</code>. This applies only to the MBR partition table.
							</li><li class="listitem">
								Replace <span class="emphasis"><em>name</em></span> with an arbitrary partition name. This is required for GPT partition tables.
							</li><li class="listitem">
								Replace <span class="emphasis"><em>fs-type</em></span> with <code class="literal">xfs</code>, <code class="literal">ext2</code>, <code class="literal">ext3</code>, <code class="literal">ext4</code>, <code class="literal">fat16</code>, <code class="literal">fat32</code>, <code class="literal">hfs</code>, <code class="literal">hfs+</code>, <code class="literal">linux-swap</code>, <code class="literal">ntfs</code>, or <code class="literal">reiserfs</code>. The <span class="emphasis"><em>fs-type</em></span> parameter is optional. Note that the <code class="literal">parted</code> utility does not create the file system on the partition.
							</li><li class="listitem">
								Replace <span class="emphasis"><em>start</em></span> and <span class="emphasis"><em>end</em></span> with the sizes that determine the starting and ending points of the partition, counting from the beginning of the disk. You can use size suffixes, such as <code class="literal">512MiB</code>, <code class="literal">20GiB</code>, or <code class="literal">1.5TiB</code>. The default size is in megabytes.
							</li></ul></div><div class="example" id="idm139822467127696"><p class="title"><strong>Example 7.2. Creating a small primary partition</strong></p><div class="example-contents"><p>
							To create a primary partition from 1024MiB until 2048MiB on an MBR table, use:
						</p><pre class="screen"># (parted) mkpart primary 1024MiB 2048MiB</pre></div></div><p class="simpara">
						The changes start applying after you enter the command.
					</p></li><li class="listitem"><p class="simpara">
						View the partition table to confirm that the created partition is in the partition table with the correct partition type, file system type, and size:
					</p><pre class="screen"># (parted) print</pre></li><li class="listitem"><p class="simpara">
						Exit the <code class="literal">parted</code> shell:
					</p><pre class="screen"># (parted) quit</pre></li><li class="listitem"><p class="simpara">
						Register the new device node:
					</p><pre class="screen"># udevadm settle</pre></li><li class="listitem"><p class="simpara">
						Verify that the kernel recognizes the new partition:
					</p><pre class="screen"># cat /proc/partitions</pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">parted(8)</code> man page on your system
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_file_systems/partition-operations-with-parted_managing-file-systems#proc_creating-a-partition-table-on-a-disk-with-parted_partition-operations-with-parted">Creating a partition table on a disk with parted</a>.
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_file_systems/partition-operations-with-parted_managing-file-systems#proc_resizing-a-partition-with-parted_partition-operations-with-parted">Resizing a partition with parted</a>
					</li></ul></div></section><section class="section" id="proc_removing-a-partition-with-parted_partition-operations-with-parted"><div class="titlepage"><div><div><h3 class="title">7.4. Removing a partition with parted</h3></div></div></div><p>
				Using the <code class="literal">parted</code> utility, you can remove a disk partition to free up disk space.
			</p><rh-alert class="admonition warning" state="danger"><div class="admonition_header" slot="header">Warning</div><div><p>
					Removing a partition deletes all data stored on the partition.
				</p></div></rh-alert><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Start the interactive <code class="literal">parted</code> shell:
					</p><pre class="screen"># parted <span class="emphasis"><em><span class="replaceable replaceable">block-device</span></em></span></pre><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								Replace <span class="emphasis"><em><span class="replaceable replaceable">block-device</span></em></span> with the path to the device where you want to remove a partition: for example, <code class="literal filename">/dev/sda</code>.
							</li></ul></div></li><li class="listitem"><p class="simpara">
						View the current partition table to determine the minor number of the partition to remove:
					</p><pre class="screen">(parted) print</pre></li><li class="listitem"><p class="simpara">
						Remove the partition:
					</p><pre class="screen">(parted) rm <span class="emphasis"><em>minor-number</em></span></pre><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								Replace <span class="emphasis"><em>minor-number</em></span> with the minor number of the partition you want to remove.
							</li></ul></div><p class="simpara">
						The changes start applying as soon as you enter this command.
					</p></li><li class="listitem"><p class="simpara">
						Verify that you have removed the partition from the partition table:
					</p><pre class="screen">(parted) print</pre></li><li class="listitem"><p class="simpara">
						Exit the <code class="literal">parted</code> shell:
					</p><pre class="screen">(parted) quit</pre></li><li class="listitem"><p class="simpara">
						Verify that the kernel registers that the partition is removed:
					</p><pre class="screen"># cat /proc/partitions</pre></li><li class="listitem">
						Remove the partition from the <code class="literal">/etc/fstab</code> file, if it is present. Find the line that declares the removed partition, and remove it from the file.
					</li><li class="listitem"><p class="simpara">
						Regenerate mount units so that your system registers the new <code class="literal">/etc/fstab</code> configuration:
					</p><pre class="screen"># systemctl daemon-reload</pre></li><li class="listitem"><p class="simpara">
						If you have deleted a swap partition or removed pieces of LVM, remove all references to the partition from the kernel command line:
					</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
								List active kernel options and see if any option references the removed partition:
							</p><pre class="screen"># grubby --info=ALL</pre></li><li class="listitem"><p class="simpara">
								Remove the kernel options that reference the removed partition:
							</p><pre class="screen"># grubby --update-kernel=ALL --remove-args="<span class="emphasis"><em>option</em></span>"</pre></li></ol></div></li><li class="listitem"><p class="simpara">
						To register the changes in the early boot system, rebuild the <code class="literal">initramfs</code> file system:
					</p><pre class="screen"># dracut --force --verbose</pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">parted(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="proc_resizing-a-partition-with-parted_partition-operations-with-parted"><div class="titlepage"><div><div><h3 class="title">7.5. Resizing a partition with parted</h3></div></div></div><p>
				Using the <code class="literal">parted</code> utility, extend a partition to use unused disk space, or shrink a partition to use its capacity for different purposes.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Back up the data before shrinking a partition.
					</li><li class="listitem">
						If the partition you want to create is larger than 2TiB, format the disk with the <span class="strong strong"><strong>GUID Partition Table (GPT)</strong></span>.
					</li><li class="listitem">
						If you want to shrink the partition, first shrink the file system so that it is not larger than the resized partition.
					</li></ul></div><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					XFS does not support shrinking.
				</p></div></rh-alert><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Start the <code class="literal">parted</code> utility:
					</p><pre class="screen"># parted <span class="emphasis"><em>block-device</em></span></pre></li><li class="listitem"><p class="simpara">
						View the current partition table:
					</p><pre class="screen"># (parted) print</pre><p class="simpara">
						From the partition table, determine:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								The minor number of the partition.
							</li><li class="listitem">
								The location of the existing partition and its new ending point after resizing.
							</li></ul></div></li><li class="listitem"><p class="simpara">
						Resize the partition:
					</p><pre class="screen"># (parted) resizepart <span class="emphasis"><em>1</em></span> <span class="emphasis"><em>2GiB</em></span></pre><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								Replace <span class="emphasis"><em>1</em></span> with the minor number of the partition that you are resizing.
							</li><li class="listitem">
								Replace <span class="emphasis"><em>2</em></span> with the size that determines the new ending point of the resized partition, counting from the beginning of the disk. You can use size suffixes, such as <code class="literal">512MiB</code>, <code class="literal">20GiB</code>, or <code class="literal">1.5TiB</code>. The default size is in megabytes.
							</li></ul></div></li><li class="listitem"><p class="simpara">
						View the partition table to confirm that the resized partition is in the partition table with the correct size:
					</p><pre class="screen"># (parted) print</pre></li><li class="listitem"><p class="simpara">
						Exit the <code class="literal">parted</code> shell:
					</p><pre class="screen"># (parted) quit</pre></li><li class="listitem"><p class="simpara">
						Verify that the kernel registers the new partition:
					</p><pre class="screen"># cat /proc/partitions</pre></li><li class="listitem">
						Optional: If you extended the partition, extend the file system on it as well.
					</li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">parted(8)</code> man page.
					</li></ul></div></section></section><section class="chapter" id="strategies-for-repartitioning-a-disk_managing-file-systems"><div class="titlepage"><div><div><h2 class="title">Chapter 8. Strategies for repartitioning a disk</h2></div></div></div><p>
			There are different approaches to repartitioning a disk. These include:
		</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
					Unpartitioned free space is available.
				</li><li class="listitem">
					An unused partition is available.
				</li><li class="listitem">
					Free space in an actively used partition is available.
				</li></ul></div><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
				The following examples are simplified for clarity and do not reflect the exact partition layout when actually installing Red Hat Enterprise Linux.
			</p></div></rh-alert><section class="section" id="using-unpartitioned-free-space_strategies-for-repartitioning-a-disk"><div class="titlepage"><div><div><h3 class="title">8.1. Using unpartitioned free space</h3></div></div></div><p>
				Partitions that are already defined and do not span the entire hard disk, leave unallocated space that is not part of any defined partition. The following diagram shows what this might look like.
			</p><div class="figure" id="idm139822450142592"><p class="title"><strong>Figure 8.1. Disk with unpartitioned free space</strong></p><div class="figure-contents"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/9bf58e64ea156351d8517609bd24afbe/unpart-space.png" alt="unpart space"></div></div></div><p>
				The first diagram represents a disk with one primary partition and an undefined partition with unallocated space. The second diagram represents a disk with two defined partitions with allocated space.
			</p><p>
				An unused hard disk also falls into this category. The only difference is that <span class="emphasis"><em>all</em></span> the space is not part of any defined partition.
			</p><p>
				On a new disk, you can create the necessary partitions from the unused space. Most preinstalled operating systems are configured to take up all available space on a disk drive.
			</p></section><section class="section" id="using-space-from-an-unused-partition_strategies-for-repartitioning-a-disk"><div class="titlepage"><div><div><h3 class="title">8.2. Using space from an unused partition</h3></div></div></div><p>
				In the following example, the first diagram represents a disk with an unused partition. The second diagram represents reallocating an unused partition for Linux.
			</p><div class="figure" id="idm139822448596048"><p class="title"><strong>Figure 8.2. Disk with an unused partition</strong></p><div class="figure-contents"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/f617fa878e1ca30a354e912eb6a67596/unused-partition.png" alt="unused partition"></div></div></div><p>
				To use the space allocated to the unused partition, delete the partition and then create the appropriate Linux partition instead. Alternatively, during the installation process, delete the unused partition and manually create new partitions.
			</p></section><section class="section" id="using-free-space-from-an-active-partition_strategies-for-repartitioning-a-disk"><div class="titlepage"><div><div><h3 class="title">8.3. Using free space from an active partition</h3></div></div></div><p>
				This process can be difficult to manage because an active partition, that is already in use, contains the required free space. In most cases, hard disks of computers with preinstalled software contain one larger partition holding the operating system and data.
			</p><rh-alert class="admonition warning" state="danger"><div class="admonition_header" slot="header">Warning</div><div><p>
					If you want to use an operating system (OS) on an active partition, you must reinstall the OS. Be aware that some computers, which include pre-installed software, do not include installation media to reinstall the original OS. Check whether this applies to your OS before you destroy an original partition and the OS installation.
				</p></div></rh-alert><p>
				To optimise the use of available free space, you can use the methods of destructive or non-destructive repartitioning.
			</p><section class="section" id="destructive-repartitioning_using-free-space-from-an-active-partition"><div class="titlepage"><div><div><h4 class="title">8.3.1. Destructive repartitioning</h4></div></div></div><p>
					Destructive repartitioning destroys the partition on your hard drive and creates several smaller partitions instead. Backup any needed data from the original partition as this method deletes the complete contents.
				</p><p>
					After creating a smaller partition for your existing operating system, you can:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Reinstall software.
						</li><li class="listitem">
							Restore your data.
						</li><li class="listitem">
							Start your Red Hat Enterprise Linux installation.
						</li></ul></div><p>
					The following diagram is a simplified representation of using the destructive repartitioning method.
				</p><div class="figure" id="idm139822453369168"><p class="title"><strong>Figure 8.3. Destructive repartitioning action on disk</strong></p><div class="figure-contents"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/216af447e0b72d58cd1c3b8636e40ca1/dstrct-reprt.png" alt="dstrct reprt"></div></div></div><rh-alert class="admonition warning" state="danger"><div class="admonition_header" slot="header">Warning</div><div><p>
						This method deletes all data previously stored in the original partition.
					</p></div></rh-alert></section><section class="section" id="non-destructive-repartitioning_using-free-space-from-an-active-partition"><div class="titlepage"><div><div><h4 class="title">8.3.2. Non-destructive repartitioning</h4></div></div></div><p>
					Non-destructive repartitioning resizes partitions, without any data loss. This method is reliable, however it takes longer processing time on large drives.
				</p><p>
					The following is a list of methods, which can help initiate non-destructive repartitioning.
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Compress existing data
						</li></ul></div><p>
					The storage location of some data cannot be changed. This can prevent the resizing of a partition to the required size, and ultimately lead to a destructive repartition process. Compressing data in an already existing partition can help you resize your partitions as needed. It can also help to maximize the free space available.
				</p><p>
					The following diagram is a simplified representation of this process.
				</p><div class="figure" id="idm139822448611904"><p class="title"><strong>Figure 8.4. Data compression on a disk</strong></p><div class="figure-contents"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/43ebf43f99569475246687fdc405a96d/compression.png" alt="compression"></div></div></div><p>
					To avoid any possible data loss, create a backup before continuing with the compression process.
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Resize the existing partition
						</li></ul></div><p>
					By resizing an already existing partition, you can free up more space. Depending on your resizing software, the results may vary. In the majority of cases, you can create a new unformatted partition of the same type, as the original partition.
				</p><p>
					The steps you take after resizing can depend on the software you use. In the following example, the best practice is to delete the new DOS (Disk Operating System) partition, and create a Linux partition instead. Verify what is most suitable for your disk before initiating the resizing process.
				</p><div class="figure" id="idm139822448604544"><p class="title"><strong>Figure 8.5. Partition resizing on a disk</strong></p><div class="figure-contents"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/a025b166d95662700634e74f4bb8b5b6/part-resize.png" alt="part resize"></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Optional: Create new partitions
						</li></ul></div><p>
					Some pieces of resizing software support Linux based systems. In such cases, there is no need to delete the newly created partition after resizing. Creating a new partition afterwards depends on the software you use.
				</p><p>
					The following diagram represents the disk state, before and after creating a new partition.
				</p><div class="figure" id="idm139822461669088"><p class="title"><strong>Figure 8.6. Disk with final partition configuration</strong></p><div class="figure-contents"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/df31d5c5afb12bf44ab0e543ee20ab58/nondestruct-fin.png" alt="nondestruct fin"></div></div></div></section></section></section><section class="chapter" id="getting-started-with-xfs_managing-file-systems"><div class="titlepage"><div><div><h2 class="title">Chapter 9. Getting started with XFS</h2></div></div></div><p>
			This is an overview of how to create and maintain XFS file systems.
		</p><section class="section" id="the-xfs-file-system_getting-started-with-xfs"><div class="titlepage"><div><div><h3 class="title">9.1. The XFS file system</h3></div></div></div><p class="_abstract _abstract">
				XFS is a highly scalable, high-performance, robust, and mature 64-bit journaling file system that supports very large files and file systems on a single host. It is the default file system in Red Hat Enterprise Linux 9. XFS was originally developed in the early 1990s by SGI and has a long history of running on extremely large servers and storage arrays.
			</p><p>
				The features of XFS include:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">Reliability</span></dt><dd><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									Metadata journaling, which ensures file system integrity after a system crash by keeping a record of file system operations that can be replayed when the system is restarted and the file system remounted
								</li><li class="listitem">
									Extensive run-time metadata consistency checking
								</li><li class="listitem">
									Scalable and fast repair utilities
								</li><li class="listitem">
									Quota journaling. This avoids the need for lengthy quota consistency checks after a crash.
								</li></ul></div></dd><dt><span class="term">Scalability and performance</span></dt><dd><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									Supported file system size up to 1024 TiB
								</li><li class="listitem">
									Ability to support a large number of concurrent operations
								</li><li class="listitem">
									B-tree indexing for scalability of free space management
								</li><li class="listitem">
									Sophisticated metadata read-ahead algorithms
								</li><li class="listitem">
									Optimizations for streaming video workloads
								</li></ul></div></dd><dt><span class="term">Allocation schemes</span></dt><dd><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									Extent-based allocation
								</li><li class="listitem">
									Stripe-aware allocation policies
								</li><li class="listitem">
									Delayed allocation
								</li><li class="listitem">
									Space pre-allocation
								</li><li class="listitem">
									Dynamically allocated inodes
								</li></ul></div></dd><dt><span class="term">Other features</span></dt><dd><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									Reflink-based file copies
								</li><li class="listitem">
									Tightly integrated backup and restore utilities
								</li><li class="listitem">
									Online defragmentation
								</li><li class="listitem">
									Online file system growing
								</li><li class="listitem">
									Comprehensive diagnostics capabilities
								</li><li class="listitem">
									Extended attributes (<code class="literal">xattr</code>). This allows the system to associate several additional name/value pairs per file.
								</li><li class="listitem">
									Project or directory quotas. This allows quota restrictions over a directory tree.
								</li><li class="listitem">
									Subsecond timestamps
								</li></ul></div></dd></dl></div><div class="formalpara"><p class="title"><strong>Performance characteristics</strong></p><p>
					XFS has a high performance on large systems with enterprise workloads. A large system is one with a relatively high number of CPUs, multiple HBAs, and connections to external disk arrays. XFS also performs well on smaller systems that have a multi-threaded, parallel I/O workload.
				</p></div><p>
				XFS has a relatively low performance for single threaded, metadata-intensive workloads: for example, a workload that creates or deletes large numbers of small files in a single thread.
			</p></section><section class="section" id="comparison-of-tools-used-with-ext4-and-xfs_getting-started-with-xfs"><div class="titlepage"><div><div><h3 class="title">9.2. Comparison of tools used with ext4 and XFS</h3></div></div></div><p class="_abstract _abstract">
				This section compares which tools to use to accomplish common tasks on the ext4 and XFS file systems.
			</p><rh-table><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 33%; " class="col_1"><!--Empty--><col style="width: 33%; " class="col_2"><!--Empty--><col style="width: 33%; " class="col_3"><!--Empty--></colgroup><thead><tr><th align="left" valign="top" id="idm139822453607152" scope="col">Task</th><th align="left" valign="top" id="idm139822453606064" scope="col">ext4</th><th align="left" valign="top" id="idm139822453604976" scope="col">XFS</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm139822453607152"> <p>
								Create a file system
							</p>
							 </td><td align="left" valign="top" headers="idm139822453606064"> <p>
								<code class="literal">mkfs.ext4</code>
							</p>
							 </td><td align="left" valign="top" headers="idm139822453604976"> <p>
								<code class="literal">mkfs.xfs</code>
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822453607152"> <p>
								File system check
							</p>
							 </td><td align="left" valign="top" headers="idm139822453606064"> <p>
								<code class="literal">e2fsck</code>
							</p>
							 </td><td align="left" valign="top" headers="idm139822453604976"> <p>
								<code class="literal">xfs_repair</code>
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822453607152"> <p>
								Resize a file system
							</p>
							 </td><td align="left" valign="top" headers="idm139822453606064"> <p>
								<code class="literal">resize2fs</code>
							</p>
							 </td><td align="left" valign="top" headers="idm139822453604976"> <p>
								<code class="literal">xfs_growfs</code>
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822453607152"> <p>
								Save an image of a file system
							</p>
							 </td><td align="left" valign="top" headers="idm139822453606064"> <p>
								<code class="literal">e2image</code>
							</p>
							 </td><td align="left" valign="top" headers="idm139822453604976"> <p>
								<code class="literal">xfs_metadump</code> and <code class="literal">xfs_mdrestore</code>
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822453607152"> <p>
								Label or tune a file system
							</p>
							 </td><td align="left" valign="top" headers="idm139822453606064"> <p>
								<code class="literal">tune2fs</code>
							</p>
							 </td><td align="left" valign="top" headers="idm139822453604976"> <p>
								<code class="literal">xfs_admin</code>
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822453607152"> <p>
								Back up a file system
							</p>
							 </td><td align="left" valign="top" headers="idm139822453606064"> <p>
								<code class="literal">tar</code> and <code class="literal">rsync</code>
							</p>
							 </td><td align="left" valign="top" headers="idm139822453604976"> <p>
								<code class="literal">xfsdump</code> and <code class="literal">xfsrestore</code>
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822453607152"> <p>
								Quota management
							</p>
							 </td><td align="left" valign="top" headers="idm139822453606064"> <p>
								<code class="literal">quota</code>
							</p>
							 </td><td align="left" valign="top" headers="idm139822453604976"> <p>
								<code class="literal">xfs_quota</code>
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822453607152"> <p>
								File mapping
							</p>
							 </td><td align="left" valign="top" headers="idm139822453606064"> <p>
								<code class="literal">filefrag</code>
							</p>
							 </td><td align="left" valign="top" headers="idm139822453604976"> <p>
								<code class="literal">xfs_bmap</code>
							</p>
							 </td></tr></tbody></table></rh-table><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					If you want a complete client-server solution for backups over network, you can use <code class="literal">bacula</code> backup utility that is available in RHEL 9. For more information about Bacula, see <a class="link" href="https://www.bacula.org/documentation/documentation/">Bacula backup solution</a>.
				</p></div></rh-alert></section></section><section class="chapter" id="assembly_creating-an-xfs-file-system_managing-file-systems"><div class="titlepage"><div><div><h2 class="title">Chapter 10. Creating an XFS file system</h2></div></div></div><p class="_abstract _abstract">
			As a system administrator, you can create an XFS file system on a block device to enable it to store files and directories.
		</p><section class="section" id="proc_creating-an-xfs-file-system-with-mkfs-xfs-creating-an-xfs-file-system"><div class="titlepage"><div><div><h3 class="title">10.1. Creating an XFS file system with mkfs.xfs</h3></div></div></div><p class="_abstract _abstract">
				This procedure describes how to create an XFS file system on a block device.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						To create the file system:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								If the device is a regular partition, an LVM volume, an MD volume, a disk, or a similar device, use the following command:
							</p><pre class="screen"># mkfs.xfs <span class="emphasis"><em>block-device</em></span></pre><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
										Replace <span class="emphasis"><em><span class="replaceable replaceable">block-device</span></em></span> with the path to the block device. For example, <code class="literal filename">/dev/sdb1</code>, <code class="literal filename">/dev/disk/by-uuid/05e99ec8-def1-4a5e-8a9d-5945339ceb2a</code>, or <code class="literal filename">/dev/my-volgroup/my-lv</code>.
									</li><li class="listitem">
										In general, the default options are optimal for common use.
									</li><li class="listitem">
										When using <code class="literal">mkfs.xfs</code> on a block device containing an existing file system, add the <code class="literal option">-f</code> option to overwrite that file system.
									</li></ul></div></li><li class="listitem"><p class="simpara">
								To create the file system on a hardware RAID device, check if the system correctly detects the stripe geometry of the device:
							</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem"><p class="simpara">
										If the stripe geometry information is correct, no additional options are needed. Create the file system:
									</p><pre class="screen"># mkfs.xfs <span class="emphasis"><em>block-device</em></span></pre></li><li class="listitem"><p class="simpara">
										If the information is incorrect, specify stripe geometry manually with the <code class="literal option">su</code> and <code class="literal option">sw</code> parameters of the <code class="literal option">-d</code> option. The <code class="literal option">su</code> parameter specifies the RAID chunk size, and the <code class="literal option">sw</code> parameter specifies the number of data disks in the RAID device.
									</p><p class="simpara">
										For example:
									</p><pre class="screen"># mkfs.xfs -d su=<span class="emphasis"><em>64k</em></span>,sw=<span class="emphasis"><em>4</em></span> <span class="emphasis"><em>/dev/sda3</em></span></pre></li></ul></div></li></ul></div></li><li class="listitem"><p class="simpara">
						Use the following command to wait for the system to register the new device node:
					</p><pre class="screen"># udevadm settle</pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">mkfs.xfs(8)</code> man page on your system
					</li></ul></div></section></section><section class="chapter" id="backing-up-an-xfs-file-system_managing-file-systems"><div class="titlepage"><div><div><h2 class="title">Chapter 11. Backing up an XFS file system</h2></div></div></div><p>
			As a system administrator, you can use the <code class="literal">xfsdump</code> to back up an XFS file system into a file or on a tape. This provides a simple backup mechanism.
		</p><section class="section" id="con_features-of-xfs-backup-backing-up-an-xfs-file-system"><div class="titlepage"><div><div><h3 class="title">11.1. Features of XFS backup</h3></div></div></div><p class="_abstract _abstract">
				This section describes key concepts and features of backing up an XFS file system with the <code class="literal">xfsdump</code> utility.
			</p><p>
				You can use the <code class="literal">xfsdump</code> utility to:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Perform backups to regular file images.
					</p><p class="simpara">
						Only one backup can be written to a regular file.
					</p></li><li class="listitem"><p class="simpara">
						Perform backups to tape drives.
					</p><p class="simpara">
						The <code class="literal">xfsdump</code> utility also enables you to write multiple backups to the same tape. A backup can span multiple tapes.
					</p><p class="simpara">
						To back up multiple file systems to a single tape device, simply write the backup to a tape that already contains an XFS backup. This appends the new backup to the previous one. By default, <code class="literal">xfsdump</code> never overwrites existing backups.
					</p></li><li class="listitem"><p class="simpara">
						Create incremental backups.
					</p><p class="simpara">
						The <code class="literal">xfsdump</code> utility uses dump levels to determine a base backup to which other backups are relative. Numbers from 0 to 9 refer to increasing dump levels. An incremental backup only backs up files that have changed since the last dump of a lower level:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
								To perform a full backup, perform a level 0 dump on the file system.
							</li><li class="listitem">
								A level 1 dump is the first incremental backup after a full backup. The next incremental backup would be level 2, which only backs up files that have changed since the last level 1 dump; and so on, to a maximum of level 9.
							</li></ul></div></li><li class="listitem">
						Exclude files from a backup using size, subtree, or inode flags to filter them.
					</li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">xfsdump(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="proc_backing-up-an-xfs-file-system-with-xfsdump-backing-up-an-xfs-file-system"><div class="titlepage"><div><div><h3 class="title">11.2. Backing up an XFS file system with xfsdump</h3></div></div></div><p class="_abstract _abstract">
				This procedure describes how to back up the content of an XFS file system into a file or a tape.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						An XFS file system that you can back up.
					</li><li class="listitem">
						Another file system or a tape drive where you can store the backup.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Use the following command to back up an XFS file system:
					</p><pre class="screen"># xfsdump -l <span class="emphasis"><em>level</em></span> [-L <span class="emphasis"><em>label</em></span>] \
          -f <span class="emphasis"><em>backup-destination</em></span> <span class="emphasis"><em>path-to-xfs-filesystem</em></span></pre><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
								Replace <span class="emphasis"><em>level</em></span> with the dump level of your backup. Use <code class="literal">0</code> to perform a full backup or <code class="literal">1</code> to <code class="literal">9</code> to perform consequent incremental backups.
							</li><li class="listitem">
								Replace <span class="emphasis"><em>backup-destination</em></span> with the path where you want to store your backup. The destination can be a regular file, a tape drive, or a remote tape device. For example, <code class="literal filename">/backup-files/Data.xfsdump</code> for a file or <code class="literal filename">/dev/st0</code> for a tape drive.
							</li><li class="listitem">
								Replace <span class="emphasis"><em>path-to-xfs-filesystem</em></span> with the mount point of the XFS file system you want to back up. For example, <code class="literal filename">/mnt/data/</code>. The file system must be mounted.
							</li><li class="listitem">
								When backing up multiple file systems and saving them on a single tape device, add a session label to each backup using the <code class="literal">-L <span class="emphasis"><em>label</em></span></code> option so that it is easier to identify them when restoring. Replace <span class="emphasis"><em>label</em></span> with any name for your backup: for example, <code class="literal">backup_data</code>.
							</li></ul></div></li></ul></div><div class="example" id="idm139822451832144"><p class="title"><strong>Example 11.1. Backing up multiple XFS file systems</strong></p><div class="example-contents"><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							To back up the content of XFS file systems mounted on the <code class="literal filename">/boot/</code> and <code class="literal filename">/data/</code> directories and save them as files in the <code class="literal filename">/backup-files/</code> directory:
						</p><pre class="screen"># xfsdump -l 0 -f <span class="emphasis"><em>/backup-files/boot.xfsdump</em></span> <span class="emphasis"><em>/boot</em></span>
# xfsdump -l 0 -f <span class="emphasis"><em>/backup-files/data.xfsdump</em></span> <span class="emphasis"><em>/data</em></span></pre></li><li class="listitem"><p class="simpara">
							To back up multiple file systems on a single tape device, add a session label to each backup using the <code class="literal">-L <span class="emphasis"><em>label</em></span></code> option:
						</p><pre class="screen"># xfsdump -l 0 -L <span class="emphasis"><em>"backup_boot"</em></span> -f <span class="emphasis"><em>/dev/st0</em></span> <span class="emphasis"><em>/boot</em></span>
# xfsdump -l 0 -L <span class="emphasis"><em>"backup_data"</em></span> -f <span class="emphasis"><em>/dev/st0</em></span> <span class="emphasis"><em>/data</em></span></pre></li></ul></div></div></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">xfsdump(8)</code> man page on your system
					</li></ul></div></section></section><section class="chapter" id="restoring-an-xfs-file-system-from-backup_managing-file-systems"><div class="titlepage"><div><div><h2 class="title">Chapter 12. Restoring an XFS file system from backup</h2></div></div></div><p>
			As a system administrator, you can use the <code class="literal">xfsrestore</code> utility to restore XFS backup created with the <code class="literal">xfsdump</code> utility and stored in a file or on a tape.
		</p><section class="section" id="con_features-of-restoring-xfs-from-backup-restoring-an-xfs-file-system-from-backup"><div class="titlepage"><div><div><h3 class="title">12.1. Features of restoring XFS from backup</h3></div></div></div><p>
				The <code class="literal">xfsrestore</code> utility restores file systems from backups produced by <code class="literal">xfsdump</code>. The <code class="literal">xfsrestore</code> utility has two modes:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						The <span class="strong strong"><strong>simple</strong></span> mode enables users to restore an entire file system from a level 0 dump. This is the default mode.
					</li><li class="listitem">
						The <span class="strong strong"><strong>cumulative</strong></span> mode enables file system restoration from an incremental backup: that is, level 1 to level 9.
					</li></ul></div><p>
				A unique <span class="emphasis"><em>session ID</em></span> or <span class="emphasis"><em>session label</em></span> identifies each backup. Restoring a backup from a tape containing multiple backups requires its corresponding session ID or label.
			</p><p>
				To extract, add, or delete specific files from a backup, enter the <code class="literal">xfsrestore</code> interactive mode. The interactive mode provides a set of commands to manipulate the backup files.
			</p><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">xfsrestore(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="proc_restoring-an-xfs-file-system-from-backup-with-xfsrestore-restoring-an-xfs-file-system-from-backup"><div class="titlepage"><div><div><h3 class="title">12.2. Restoring an XFS file system from backup with xfsrestore</h3></div></div></div><p class="_abstract _abstract">
				This procedure describes how to restore the content of an XFS file system from a file or tape backup.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						A file or tape backup of XFS file systems, as described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_file_systems/backing-up-an-xfs-file-system_managing-file-systems">Backing up an XFS file system</a>.
					</li><li class="listitem">
						A storage device where you can restore the backup.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						The command to restore the backup varies depending on whether you are restoring from a full backup or an incremental one, or are restoring multiple backups from a single tape device:
					</p><pre class="screen"># xfsrestore [-r] [-S session-id] [-L session-label] [-i]
             -f backup-location restoration-path</pre><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
								Replace <span class="emphasis"><em><span class="replaceable replaceable">backup-location</span></em></span> with the location of the backup. This can be a regular file, a tape drive, or a remote tape device. For example, <code class="literal filename">/backup-files/Data.xfsdump</code> for a file or <code class="literal filename">/dev/st0</code> for a tape drive.
							</li><li class="listitem">
								Replace <span class="emphasis"><em><span class="replaceable replaceable">restoration-path</span></em></span> with the path to the directory where you want to restore the file system. For example, <code class="literal filename">/mnt/data/</code>.
							</li><li class="listitem">
								To restore a file system from an incremental (level 1 to level 9) backup, add the <code class="literal option">-r</code> option.
							</li><li class="listitem"><p class="simpara">
								To restore a backup from a tape device that contains multiple backups, specify the backup using the <code class="literal option">-S</code> or <code class="literal option">-L</code> options.
							</p><p class="simpara">
								The <code class="literal option">-S</code> option lets you choose a backup by its session ID, while the <code class="literal option">-L</code> option lets you choose by the session label. To obtain the session ID and session labels, use the <code class="literal command">xfsrestore -I</code> command.
							</p><p class="simpara">
								Replace <span class="emphasis"><em><span class="replaceable replaceable">session-id</span></em></span> with the session ID of the backup. For example, <code class="literal">b74a3586-e52e-4a4a-8775-c3334fa8ea2c</code>. Replace <span class="emphasis"><em><span class="replaceable replaceable">session-label</span></em></span> with the session label of the backup. For example, <code class="literal">my_backup_session_label</code>.
							</p></li><li class="listitem"><p class="simpara">
								To use <code class="literal">xfsrestore</code> interactively, use the <code class="literal option">-i</code> option.
							</p><p class="simpara">
								The interactive dialog begins after <code class="literal">xfsrestore</code> finishes reading the specified device. Available commands in the interactive <code class="literal">xfsrestore</code> shell include <code class="literal">cd</code>, <code class="literal">ls</code>, <code class="literal">add</code>, <code class="literal">delete</code>, and <code class="literal">extract</code>; for a complete list of commands, use the <code class="literal">help</code> command.
							</p></li></ul></div></li></ul></div><div class="example" id="idm139822453388448"><p class="title"><strong>Example 12.1. Restoring Multiple XFS File Systems</strong></p><div class="example-contents"><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							To restore the XFS backup files and save their content into directories under <code class="literal filename">/mnt/</code>:
						</p><pre class="screen"># xfsrestore -f <span class="emphasis"><em>/backup-files/boot.xfsdump</em></span> <span class="emphasis"><em>/mnt/boot/</em></span>
# xfsrestore -f <span class="emphasis"><em>/backup-files/data.xfsdump</em></span> <span class="emphasis"><em>/mnt/data/</em></span></pre></li><li class="listitem"><p class="simpara">
							To restore from a tape device containing multiple backups, specify each backup by its session label or session ID:
						</p><pre class="screen"># xfsrestore -L <span class="emphasis"><em>"backup_boot"</em></span> -f <span class="emphasis"><em>/dev/st0</em></span> <span class="emphasis"><em>/mnt/boot/</em></span>
# xfsrestore -S <span class="emphasis"><em>"45e9af35-efd2-4244-87bc-4762e476cbab"</em></span> \
             -f <span class="emphasis"><em>/dev/st0</em></span> <span class="emphasis"><em>/mnt/data/</em></span></pre></li></ul></div></div></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">xfsrestore(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="con_informational-messages-when-restoring-an-xfs-backup-from-a-tape-restoring-an-xfs-file-system-from-backup"><div class="titlepage"><div><div><h3 class="title">12.3. Informational messages when restoring an XFS backup from a tape</h3></div></div></div><p class="_abstract _abstract">
				When restoring a backup from a tape with backups from multiple file systems, the <code class="literal">xfsrestore</code> utility might issue messages. The messages inform you whether a match of the requested backup has been found when <code class="literal">xfsrestore</code> examines each backup on the tape in sequential order. For example:
			</p><pre class="screen">xfsrestore: preparing drive
xfsrestore: examining media file 0
xfsrestore: inventory session uuid (8590224e-3c93-469c-a311-fc8f23029b2a) does not match the media header's session uuid (7eda9f86-f1e9-4dfd-b1d4-c50467912408)
xfsrestore: examining media file 1
xfsrestore: inventory session uuid (8590224e-3c93-469c-a311-fc8f23029b2a) does not match the media header's session uuid (7eda9f86-f1e9-4dfd-b1d4-c50467912408)
[...]</pre><p>
				The informational messages keep appearing until the matching backup is found.
			</p></section></section><section class="chapter" id="increasing-the-size-of-an-xfs-file-system_managing-file-systems"><div class="titlepage"><div><div><h2 class="title">Chapter 13. Increasing the size of an XFS file system</h2></div></div></div><p>
			As a system administrator, you can increase the size of an XFS file system to make a complete use of a larger storage capacity.
		</p><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
				It is not currently possible to decrease the size of XFS file systems.
			</p></div></rh-alert><section class="section" id="proc_increasing-the-size-of-an-xfs-file-system-with-xfs_growfs_increasing-the-size-of-an-xfs-file-system"><div class="titlepage"><div><div><h3 class="title">13.1. Increasing the size of an XFS file system with xfs_growfs</h3></div></div></div><p class="_abstract _abstract">
				This procedure describes how to grow an XFS file system using the <code class="literal">xfs_growfs</code> utility.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Ensure that the underlying block device is of an appropriate size to hold the resized file system later. Use the appropriate resizing methods for the affected block device.
					</li><li class="listitem">
						Mount the XFS file system.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						While the XFS file system is mounted, use the <code class="literal">xfs_growfs</code> utility to increase its size:
					</p><pre class="screen"># xfs_growfs <span class="emphasis"><em><span class="replaceable replaceable">file-system</span></em></span> -D <span class="emphasis"><em><span class="replaceable replaceable">new-size</span></em></span></pre><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
								Replace <span class="emphasis"><em><span class="replaceable replaceable">file-system</span></em></span> with the mount point of the XFS file system.
							</li><li class="listitem"><p class="simpara">
								With the <code class="literal option">-D</code> option, replace <span class="emphasis"><em><span class="replaceable replaceable">new-size</span></em></span> with the desired new size of the file system specified in the number of file system blocks.
							</p><p class="simpara">
								To find out the block size in kB of a given XFS file system, use the <code class="literal">xfs_info</code> utility:
							</p><pre class="screen"># xfs_info <span class="emphasis"><em><span class="replaceable replaceable">block-device</span></em></span>

...
data     =              bsize=4096
...</pre></li><li class="listitem">
								Without the <code class="literal option">-D</code> option, <code class="literal">xfs_growfs</code> grows the file system to the maximum size supported by the underlying device.
							</li></ul></div></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">xfs_growfs(8)</code> man page on your system.
					</li></ul></div></section></section><section class="chapter" id="configuring-xfs-error-behavior_managing-file-systems"><div class="titlepage"><div><div><h2 class="title">Chapter 14. Configuring XFS error behavior</h2></div></div></div><p>
			You can configure how an XFS file system behaves when it encounters different I/O errors.
		</p><section class="section" id="configurable-error-handling-in-xfs_configuring-xfs-error-behavior"><div class="titlepage"><div><div><h3 class="title">14.1. Configurable error handling in XFS</h3></div></div></div><p class="_abstract _abstract">
				The XFS file system responds in one of the following ways when an error occurs during an I/O operation:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						XFS repeatedly retries the I/O operation until the operation succeeds or XFS reaches a set limit.
					</p><p class="simpara">
						The limit is based either on a maximum number of retries or a maximum time for retries.
					</p></li><li class="listitem">
						XFS considers the error permanent and stops the operation on the file system.
					</li></ul></div><p>
				You can configure how XFS reacts to the following error conditions:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">EIO</code></span></dt><dd>
							Error when reading or writing
						</dd><dt><span class="term"><code class="literal">ENOSPC</code></span></dt><dd>
							No space left on the device
						</dd><dt><span class="term"><code class="literal">ENODEV</code></span></dt><dd>
							Device cannot be found
						</dd></dl></div><p>
				You can set the maximum number of retries and the maximum time in seconds until XFS considers an error permanent. XFS stops retrying the operation when it reaches either of the limits.
			</p><p>
				You can also configure XFS so that when unmounting a file system, XFS immediately cancels the retries regardless of any other configuration. This configuration enables the unmount operation to succeed despite persistent errors.
			</p><div class="formalpara"><p class="title"><strong>Default behavior</strong></p><p>
					The default behavior for each XFS error condition depends on the error context. Some XFS errors such as <code class="literal">ENODEV</code> are considered to be fatal and unrecoverable, regardless of the retry count. Their default retry limit is 0.
				</p></div></section><section class="section" id="configuration-files-for-specific-and-undefined-xfs-error-conditions_configuring-xfs-error-behavior"><div class="titlepage"><div><div><h3 class="title">14.2. Configuration files for specific and undefined XFS error conditions</h3></div></div></div><p class="_abstract _abstract">
				The following directories store configuration files that control XFS error behavior for different error conditions:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">/sys/fs/xfs/<span class="emphasis"><em>device</em></span>/error/metadata/EIO/</code></span></dt><dd>
							For the <code class="literal">EIO</code> error condition
						</dd><dt><span class="term"><code class="literal">/sys/fs/xfs/<span class="emphasis"><em>device</em></span>/error/metadata/ENODEV/</code></span></dt><dd>
							For the <code class="literal">ENODEV</code> error condition
						</dd><dt><span class="term"><code class="literal">/sys/fs/xfs/<span class="emphasis"><em>device</em></span>/error/metadata/ENOSPC/</code></span></dt><dd>
							For the <code class="literal">ENOSPC</code> error condition
						</dd><dt><span class="term"><code class="literal">/sys/fs/xfs/<span class="emphasis"><em>device</em></span>/error/default/</code></span></dt><dd>
							Common configuration for all other, undefined error conditions
						</dd></dl></div><p>
				Each directory contains the following configuration files for configuring retry limits:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">max_retries</code></span></dt><dd>
							Controls the maximum number of times that XFS retries the operation.
						</dd><dt><span class="term"><code class="literal">retry_timeout_seconds</code></span></dt><dd>
							Specifies the time limit in seconds after which XFS stops retrying the operation.
						</dd></dl></div></section><section class="section" id="setting-specific-and-undefined-xfs-error-conditions_configuring-xfs-error-behavior"><div class="titlepage"><div><div><h3 class="title">14.3. Setting XFS behavior for specific conditions</h3></div></div></div><p class="_abstract _abstract">
				This procedure configures how XFS reacts to specific error conditions.
			</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Set the maximum number of retries, the retry time limit, or both:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem"><p class="simpara">
								To set the maximum number of retries, write the desired number to the <code class="literal">max_retries</code> file:
							</p><pre class="screen"># echo <span class="emphasis"><em>value</em></span> &gt; /sys/fs/xfs/<span class="emphasis"><em>device</em></span>/error/metadata/<span class="emphasis"><em>condition</em></span>/max_retries</pre></li><li class="listitem"><p class="simpara">
								To set the time limit, write the desired number of seconds to the <code class="literal">retry_timeout_seconds</code> file:
							</p><pre class="screen"># echo <span class="emphasis"><em>value</em></span> &gt; /sys/fs/xfs/<span class="emphasis"><em>device</em></span>/error/metadata/<span class="emphasis"><em>condition</em></span>/retry_timeout_second</pre></li></ul></div><p class="simpara">
						<span class="emphasis"><em>value</em></span> is a number between -1 and the maximum possible value of the C signed integer type. This is 2147483647 on 64-bit Linux.
					</p><p class="simpara">
						In both limits, the value <code class="literal">-1</code> is used for continuous retries and <code class="literal">0</code> to stop immediately.
					</p><p class="simpara">
						<span class="emphasis"><em>device</em></span> is the name of the device, as found in the <code class="literal">/dev/</code> directory; for example, <code class="literal">sda</code>.
					</p></li></ul></div></section><section class="section" id="setting-undefined-xfs-error-conditions_configuring-xfs-error-behavior"><div class="titlepage"><div><div><h3 class="title">14.4. Setting XFS behavior for undefined conditions</h3></div></div></div><p class="_abstract _abstract">
				This procedure configures how XFS reacts to all undefined error conditions, which share a common configuration.
			</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Set the maximum number of retries, the retry time limit, or both:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem"><p class="simpara">
								To set the maximum number of retries, write the desired number to the <code class="literal">max_retries</code> file:
							</p><pre class="screen"># echo <span class="emphasis"><em>value</em></span> &gt; /sys/fs/xfs/<span class="emphasis"><em>device</em></span>/error/metadata/default/max_retries</pre></li><li class="listitem"><p class="simpara">
								To set the time limit, write the desired number of seconds to the <code class="literal">retry_timeout_seconds</code> file:
							</p><pre class="screen"># echo <span class="emphasis"><em>value</em></span> &gt; /sys/fs/xfs/<span class="emphasis"><em>device</em></span>/error/metadata/default/retry_timeout_seconds</pre></li></ul></div><p class="simpara">
						<span class="emphasis"><em>value</em></span> is a number between -1 and the maximum possible value of the C signed integer type. This is 2147483647 on 64-bit Linux.
					</p><p class="simpara">
						In both limits, the value <code class="literal">-1</code> is used for continuous retries and <code class="literal">0</code> to stop immediately.
					</p><p class="simpara">
						<span class="emphasis"><em>device</em></span> is the name of the device, as found in the <code class="literal">/dev/</code> directory; for example, <code class="literal">sda</code>.
					</p></li></ul></div></section><section class="section" id="setting-the-unmount-behavior_configuring-xfs-error-behavior"><div class="titlepage"><div><div><h3 class="title">14.5. Setting the XFS unmount behavior</h3></div></div></div><p class="_abstract _abstract">
				This procedure configures how XFS reacts to error conditions when unmounting the file system.
			</p><p>
				If you set the <code class="literal">fail_at_unmount</code> option in the file system, it overrides all other error configurations during unmount, and immediately unmounts the file system without retrying the I/O operation. This allows the unmount operation to succeed even in case of persistent errors.
			</p><rh-alert class="admonition warning" state="danger"><div class="admonition_header" slot="header">Warning</div><div><p>
					You cannot change the <code class="literal">fail_at_unmount</code> value after the unmount process starts, because the unmount process removes the configuration files from the <code class="literal">sysfs</code> interface for the respective file system. You must configure the unmount behavior before the file system starts unmounting.
				</p></div></rh-alert><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Enable or disable the <code class="literal">fail_at_unmount</code> option:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem"><p class="simpara">
								To cancel retrying all operations when the file system unmounts, enable the option:
							</p><pre class="screen"># echo 1 &gt; /sys/fs/xfs/<span class="emphasis"><em>device</em></span>/error/fail_at_unmount</pre></li><li class="listitem"><p class="simpara">
								To respect the <code class="literal">max_retries</code> and <code class="literal">retry_timeout_seconds</code> retry limits when the file system unmounts, disable the option:
							</p><pre class="screen"># echo 0 &gt; /sys/fs/xfs/<span class="emphasis"><em>device</em></span>/error/fail_at_unmount</pre></li></ul></div><p class="simpara">
						<span class="emphasis"><em>device</em></span> is the name of the device, as found in the <code class="literal">/dev/</code> directory; for example, <code class="literal">sda</code>.
					</p></li></ul></div></section></section><section class="chapter" id="checking-and-repairing-a-file-system__managing-file-systems"><div class="titlepage"><div><div><h2 class="title">Chapter 15. Checking and repairing a file system</h2></div></div></div><p class="_abstract _abstract">
			RHEL provides file system administration utilities which are capable of checking and repairing file systems. These tools are often referred to as <code class="literal">fsck</code> tools, where <code class="literal">fsck</code> is a shortened version of <span class="emphasis"><em>file system check</em></span>. In most cases, these utilities are run automatically during system boot, if needed, but can also be manually invoked if required.
		</p><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
				File system checkers guarantee only metadata consistency across the file system. They have no awareness of the actual data contained within the file system and are not data recovery tools.
			</p></div></rh-alert><section class="section" id="file-system-checking-and-repair_checking-and-repairing-a-file-system"><div class="titlepage"><div><div><h3 class="title">15.1. Scenarios that require a file system check</h3></div></div></div><p class="_abstract _abstract">
				The relevant <code class="literal">fsck</code> tools can be used to check your system if any of the following occurs:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						System fails to boot
					</li><li class="listitem">
						Files on a specific disk become corrupt
					</li><li class="listitem">
						The file system shuts down or changes to read-only due to inconsistencies
					</li><li class="listitem">
						A file on the file system is inaccessible
					</li></ul></div><p>
				File system inconsistencies can occur for various reasons, including but not limited to hardware errors, storage administration errors, and software bugs.
			</p><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
					File system check tools cannot repair hardware problems. A file system must be fully readable and writable if repair is to operate successfully. If a file system was corrupted due to a hardware error, the file system must first be moved to a good disk, for example with the <code class="literal">dd(8)</code> utility.
				</p></div></rh-alert><p>
				For journaling file systems, all that is normally required at boot time is to replay the journal if required and this is usually a very short operation.
			</p><p>
				However, if a file system inconsistency or corruption occurs, even for journaling file systems, then the file system checker must be used to repair the file system.
			</p><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
					It is possible to disable file system check at boot by setting the sixth field in <code class="literal">/etc/fstab</code> to <code class="literal">0</code>. However, Red Hat does not recommend doing so unless you are having issues with <code class="literal">fsck</code> at boot time, for example with extremely large or remote file systems.
				</p></div></rh-alert><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">fstab(5)</code>, <code class="literal">fsck(8)</code>, and <code class="literal">dd(8)</code> man pages on your system
					</li></ul></div></section><section class="section" id="potential-side-effects-of-running-fsck_checking-and-repairing-a-file-system"><div class="titlepage"><div><div><h3 class="title">15.2. Potential side effects of running fsck</h3></div></div></div><p class="_abstract _abstract">
				Generally, running the file system check and repair tool can be expected to automatically repair at least some of the inconsistencies it finds. In some cases, the following issues can arise:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Severely damaged inodes or directories may be discarded if they cannot be repaired.
					</li><li class="listitem">
						Significant changes to the file system may occur.
					</li></ul></div><p>
				To ensure that unexpected or undesirable changes are not permanently made, ensure you follow any precautionary steps outlined in the procedure.
			</p></section><section class="section" id="error-handling-mechanisms-in-xfs_checking-and-repairing-a-file-system"><div class="titlepage"><div><div><h3 class="title">15.3. Error-handling mechanisms in XFS</h3></div></div></div><p class="_abstract _abstract">
				This section describes how XFS handles various kinds of errors in the file system.
			</p><h5 id="unclean_unmounts">Unclean unmounts</h5><p>
				Journalling maintains a transactional record of metadata changes that happen on the file system.
			</p><p>
				In the event of a system crash, power failure, or other unclean unmount, XFS uses the journal (also called log) to recover the file system. The kernel performs journal recovery when mounting the XFS file system.
			</p><h5 id="corruption">Corruption</h5><p>
				In this context, <span class="emphasis"><em>corruption</em></span> means errors on the file system caused by, for example:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Hardware faults
					</li><li class="listitem">
						Bugs in storage firmware, device drivers, the software stack, or the file system itself
					</li><li class="listitem">
						Problems that cause parts of the file system to be overwritten by something outside of the file system
					</li></ul></div><p>
				When XFS detects corruption in the file system or the file-system metadata, it may shut down the file system and report the incident in the system log. Note that if the corruption occurred on the file system hosting the <code class="literal filename">/var</code> directory, these logs will not be available after a reboot.
			</p><div class="example" id="idm139822448930272"><p class="title"><strong>Example 15.1. System log entry reporting an XFS corruption</strong></p><div class="example-contents"><pre class="screen"># dmesg --notime | tail -15

XFS (loop0): Mounting V5 Filesystem
XFS (loop0): Metadata CRC error detected at xfs_agi_read_verify+0xcb/0xf0 [xfs], xfs_agi block 0x2
XFS (loop0): Unmount and run xfs_repair
XFS (loop0): First 128 bytes of corrupted metadata buffer:
00000000027b3b56: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
000000005f9abc7a: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
000000005b0aef35: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
00000000da9d2ded: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
000000001e265b07: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
000000006a40df69: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
000000000b272907: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
00000000e484aac5: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................
XFS (loop0): metadata I/O error in "xfs_trans_read_buf_map" at daddr 0x2 len 1 error 74
XFS (loop0): xfs_imap_lookup: xfs_ialloc_read_agi() returned error -117, agno 0
XFS (loop0): Failed to read root inode 0x80, error 11</pre></div></div><p>
				User-space utilities usually report the <span class="emphasis"><em>Input/output error</em></span> message when trying to access a corrupted XFS file system. Mounting an XFS file system with a corrupted log results in a failed mount and the following error message:
			</p><pre class="screen">mount: <span class="emphasis"><em><span class="replaceable replaceable">/mount-point</span></em></span>: mount(2) system call failed: Structure needs cleaning.</pre><p>
				You must manually use the <code class="literal">xfs_repair</code> utility to repair the corruption.
			</p><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">xfs_repair(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="checking-an-xfs-file-system-with-xfs-repair_checking-and-repairing-a-file-system"><div class="titlepage"><div><div><h3 class="title">15.4. Checking an XFS file system with <code class="literal">xfs_repair</code></h3></div></div></div><p class="_abstract _abstract">
				Perform a read-only check of an XFS file system by using the xfs_repair utility. Unlike other file system repair utilities, <code class="literal">xfs_repair</code> does not run at boot time, even when an XFS file system was not cleanly unmounted. In case of an unclean unmount, XFS simply replays the log at mount time, ensuring a consistent file system; <code class="literal">xfs_repair</code> cannot repair an XFS file system with a dirty log without remounting it first.
			</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					Although an <code class="literal">fsck.xfs</code> binary is present in the <code class="literal">xfsprogs</code> package, this is present only to satisfy <code class="literal">initscripts</code> that look for an <code class="literal">fsck.file</code> system binary at boot time. <code class="literal">fsck.xfs</code> immediately exits with an exit code of 0.
				</p></div></rh-alert><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Replay the log by mounting and unmounting the file system:
					</p><pre class="screen"># mount <span class="emphasis"><em><span class="replaceable replaceable">file-system</span></em></span>
# umount <span class="emphasis"><em><span class="replaceable replaceable">file-system</span></em></span></pre><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
							If the mount fails with a structure needs cleaning error, the log is corrupted and cannot be replayed. The dry run should discover and report more on-disk corruption as a result.
						</p></div></rh-alert></li><li class="listitem"><p class="simpara">
						Use the <code class="literal">xfs_repair</code> utility to perform a dry run to check the file system. Any errors are printed and an indication of the actions that would be taken, without modifying the file system.
					</p><pre class="screen"># xfs_repair -n <span class="emphasis"><em><span class="replaceable replaceable">block-device</span></em></span></pre></li><li class="listitem"><p class="simpara">
						Mount the file system:
					</p><pre class="screen"># mount <span class="emphasis"><em><span class="replaceable replaceable">file-system</span></em></span></pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">xfs_repair(8)</code> and <code class="literal">xfs_metadump(8)</code> man pages on your system
					</li></ul></div></section><section class="section" id="proc_repairing-an-xfs-file-system-with-xfs_repair_checking-and-repairing-a-file-system"><div class="titlepage"><div><div><h3 class="title">15.5. Repairing an XFS file system with xfs_repair</h3></div></div></div><p class="_abstract _abstract">
				This procedure repairs a corrupted XFS file system using the <code class="literal">xfs_repair</code> utility.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Create a metadata image prior to repair for diagnostic or testing purposes using the <code class="literal">xfs_metadump</code> utility. A pre-repair file system metadata image can be useful for support investigations if the corruption is due to a software bug. Patterns of corruption present in the pre-repair image can aid in root-cause analysis.
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								Use the <code class="literal">xfs_metadump</code> debugging tool to copy the metadata from an XFS file system to a file. The resulting <code class="literal">metadump</code> file can be compressed using standard compression utilities to reduce the file size if large <code class="literal">metadump</code> files need to be sent to support.
							</p><pre class="screen"># xfs_metadump <span class="emphasis"><em><span class="replaceable replaceable">block-device</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">metadump-file</span></em></span></pre></li></ul></div></li><li class="listitem"><p class="simpara">
						Replay the log by remounting the file system:
					</p><pre class="screen"># mount <span class="emphasis"><em><span class="replaceable replaceable">file-system</span></em></span>
# umount <span class="emphasis"><em><span class="replaceable replaceable">file-system</span></em></span></pre></li><li class="listitem"><p class="simpara">
						Use the <code class="literal">xfs_repair</code> utility to repair the unmounted file system:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								If the mount succeeded, no additional options are required:
							</p><pre class="screen"># xfs_repair <span class="emphasis"><em><span class="replaceable replaceable">block-device</span></em></span></pre></li><li class="listitem"><p class="simpara">
								If the mount failed with the <span class="emphasis"><em>Structure needs cleaning</em></span> error, the log is corrupted and cannot be replayed. Use the <code class="literal option">-L</code> option (<span class="emphasis"><em>force log zeroing</em></span>) to clear the log:
							</p><rh-alert class="admonition warning" state="danger"><div class="admonition_header" slot="header">Warning</div><div><p>
									This command causes all metadata updates in progress at the time of the crash to be lost, which might cause significant file system damage and data loss. This should be used only as a last resort if the log cannot be replayed.
								</p></div></rh-alert><pre class="screen"># xfs_repair -L <span class="emphasis"><em><span class="replaceable replaceable">block-device</span></em></span></pre></li></ul></div></li><li class="listitem"><p class="simpara">
						Mount the file system:
					</p><pre class="screen"># mount <span class="emphasis"><em><span class="replaceable replaceable">file-system</span></em></span></pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">xfs_repair(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="error-handling-mechanisms-in-ext2-ext3-and-ext4_checking-and-repairing-a-file-system"><div class="titlepage"><div><div><h3 class="title">15.6. Error handling mechanisms in ext2, ext3, and ext4</h3></div></div></div><p class="_abstract _abstract">
				The ext2, ext3, and ext4 file systems use the <code class="literal">e2fsck</code> utility to perform file system checks and repairs. The file names <code class="literal">fsck.ext2</code>, <code class="literal">fsck.ext3</code>, and <code class="literal">fsck.ext4</code> are hardlinks to the <code class="literal">e2fsck</code> utility. These binaries are run automatically at boot time and their behavior differs based on the file system being checked and the state of the file system.
			</p><p>
				A full file system check and repair is invoked for ext2, which is not a metadata journaling file system, and for ext4 file systems without a journal.
			</p><p>
				For ext3 and ext4 file systems with metadata journaling, the journal is replayed in userspace and the utility exits. This is the default action because journal replay ensures a consistent file system after a crash.
			</p><p>
				If these file systems encounter metadata inconsistencies while mounted, they record this fact in the file system superblock. If <code class="literal">e2fsck</code> finds that a file system is marked with such an error, <code class="literal">e2fsck</code> performs a full check after replaying the journal (if present).
			</p><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">fsck(8)</code> and <code class="literal">e2fsck(8)</code> man pages on your system
					</li></ul></div></section><section class="section" id="checking-an-ext2-ext3-or-ext4-file-system-with-e2fsck_checking-and-repairing-a-file-system"><div class="titlepage"><div><div><h3 class="title">15.7. Checking an ext2, ext3, or ext4 file system with e2fsck</h3></div></div></div><p class="_abstract _abstract">
				This procedure checks an ext2, ext3, or ext4 file system using the <code class="literal">e2fsck</code> utility.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Replay the log by remounting the file system:
					</p><pre class="screen"># mount <span class="emphasis"><em><span class="replaceable replaceable">file-system</span></em></span>
# umount <span class="emphasis"><em><span class="replaceable replaceable">file-system</span></em></span></pre></li><li class="listitem"><p class="simpara">
						Perform a dry run to check the file system.
					</p><pre class="screen"># e2fsck -n <span class="emphasis"><em><span class="replaceable replaceable">block-device</span></em></span></pre><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
							Any errors are printed and an indication of the actions that would be taken, without modifying the file system. Later phases of consistency checking may print extra errors as it discovers inconsistencies which would have been fixed in early phases if it were running in repair mode.
						</p></div></rh-alert></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">e2image(8)</code> and <code class="literal">e2fsck(8)</code> man pages on your system
					</li></ul></div></section><section class="section" id="repairing-an-ext2-ext3-or-ext4-file-system-with-e2fsck_checking-and-repairing-a-file-system"><div class="titlepage"><div><div><h3 class="title">15.8. Repairing an ext2, ext3, or ext4 file system with e2fsck</h3></div></div></div><p class="_abstract _abstract">
				This procedure repairs a corrupted ext2, ext3, or ext4 file system using the <code class="literal">e2fsck</code> utility.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Save a file system image for support investigations. A pre-repair file system metadata image can be useful for support investigations if the corruption is due to a software bug. Patterns of corruption present in the pre-repair image can aid in root-cause analysis.
					</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
							Severely damaged file systems may cause problems with metadata image creation.
						</p></div></rh-alert><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								If you are creating the image for testing purposes, use the <code class="literal">-r</code> option to create a sparse file of the same size as the file system itself. <code class="literal">e2fsck</code> can then operate directly on the resulting file.
							</p><pre class="screen"># e2image -r <span class="emphasis"><em><span class="replaceable replaceable">block-device</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">image-file</span></em></span></pre></li><li class="listitem"><p class="simpara">
								If you are creating the image to be archived or provided for diagnostic, use the <code class="literal">-Q</code> option, which creates a more compact file format suitable for transfer.
							</p><pre class="screen"># e2image -Q <span class="emphasis"><em><span class="replaceable replaceable">block-device</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">image-file</span></em></span></pre></li></ul></div></li><li class="listitem"><p class="simpara">
						Replay the log by remounting the file system:
					</p><pre class="screen"># mount <span class="emphasis"><em><span class="replaceable replaceable">file-system</span></em></span>
# umount <span class="emphasis"><em><span class="replaceable replaceable">file-system</span></em></span></pre></li><li class="listitem"><p class="simpara">
						Automatically repair the file system. If user intervention is required, <code class="literal">e2fsck</code> indicates the unfixed problem in its output and reflects this status in the exit code.
					</p><pre class="screen"># e2fsck -p <span class="emphasis"><em><span class="replaceable replaceable">block-device</span></em></span></pre><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
								<code class="literal">e2image(8)</code> man page on your system
							</li><li class="listitem">
								<code class="literal">e2fsck(8)</code> man page on your system
							</li></ul></div></li></ol></div></section></section><section class="chapter" id="mounting-file-systems_managing-file-systems"><div class="titlepage"><div><div><h2 class="title">Chapter 16. Mounting file systems</h2></div></div></div><p>
			As a system administrator, you can mount file systems on your system to access data on them.
		</p><section class="section" id="the-linux-mount-mechanism_mounting-file-systems"><div class="titlepage"><div><div><h3 class="title">16.1. The Linux mount mechanism</h3></div></div></div><p class="_abstract _abstract">
				These are the basic concepts of mounting file systems on Linux.
			</p><p>
				On Linux, UNIX, and similar operating systems, file systems on different partitions and removable devices (CDs, DVDs, or USB flash drives for example) can be attached to a certain point (the mount point) in the directory tree, and then detached again. While a file system is mounted on a directory, the original content of the directory is not accessible.
			</p><p>
				Note that Linux does not prevent you from mounting a file system to a directory with a file system already attached to it.
			</p><p>
				When mounting, you can identify the device by:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						a universally unique identifier (UUID): for example, <code class="literal">UUID=34795a28-ca6d-4fd8-a347-73671d0c19cb</code>
					</li><li class="listitem">
						a volume label: for example, <code class="literal">LABEL=home</code>
					</li><li class="listitem">
						a full path to a non-persistent block device: for example, <code class="literal filename">/dev/sda3</code>
					</li></ul></div><p>
				When you mount a file system using the <code class="literal">mount</code> command without all required information, that is without the device name, the target directory, or the file system type, the <code class="literal">mount</code> utility reads the content of the <code class="literal filename">/etc/fstab</code> file to check if the given file system is listed there. The <code class="literal filename">/etc/fstab</code> file contains a list of device names and the directories in which the selected file systems are set to be mounted as well as the file system type and mount options. Therefore, when mounting a file system that is specified in <code class="literal filename">/etc/fstab</code>, the following command syntax is sufficient:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Mounting by the mount point:
					</p><pre class="screen"># mount <span class="emphasis"><em><span class="replaceable replaceable">directory</span></em></span></pre></li><li class="listitem"><p class="simpara">
						Mounting by the block device:
					</p><pre class="screen"># mount <span class="emphasis"><em><span class="replaceable replaceable">device</span></em></span></pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">mount(8)</code> man page on your system
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#proc_listing-persistent-naming-attributes_assembly_overview-of-persistent-naming-attributes">How to list persistent naming attributes such as the UUID</a>.
					</li></ul></div></section><section class="section" id="listing-currently-mounted-file-systems_mounting-file-systems"><div class="titlepage"><div><div><h3 class="title">16.2. Listing currently mounted file systems</h3></div></div></div><p class="_abstract _abstract">
				List all currently mounted file systems on the command line by using the <code class="literal">findmnt</code> utility.
			</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						To list all mounted file systems, use the <code class="literal">findmnt</code> utility:
					</p><pre class="screen">$ findmnt</pre></li><li class="listitem"><p class="simpara">
						To limit the listed file systems only to a certain file system type, add the <code class="literal option">--types</code> option:
					</p><pre class="screen">$ findmnt --types <span class="emphasis"><em><span class="replaceable replaceable">fs-type</span></em></span></pre><p class="simpara">
						For example:
					</p><div class="example" id="idm139822452693040"><p class="title"><strong>Example 16.1. Listing only XFS file systems</strong></p><div class="example-contents"><pre class="screen">$ findmnt --types xfs

TARGET  SOURCE                                                FSTYPE OPTIONS
/       /dev/mapper/luks-5564ed00-6aac-4406-bfb4-c59bf5de48b5 xfs    rw,relatime
├─/boot /dev/sda1                                             xfs    rw,relatime
└─/home /dev/mapper/luks-9d185660-7537-414d-b727-d92ea036051e xfs    rw,relatime</pre></div></div></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">findmnt(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="mounting-a-file-system-with-mount_mounting-file-systems"><div class="titlepage"><div><div><h3 class="title">16.3. Mounting a file system with mount</h3></div></div></div><p class="_abstract _abstract">
				Mount a file system by using the <code class="literal">mount</code> utility.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Verify that no file system is already mounted on your chosen mount point:
					</p><pre class="screen">$ findmnt <span class="emphasis"><em><span class="replaceable replaceable">mount-point</span></em></span></pre></li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						To attach a certain file system, use the <code class="literal">mount</code> utility:
					</p><pre class="screen"># mount <span class="emphasis"><em><span class="replaceable replaceable">device</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">mount-point</span></em></span></pre><div class="example" id="idm139822452486400"><p class="title"><strong>Example 16.2. Mounting an XFS file system</strong></p><div class="example-contents"><p>
							For example, to mount a local XFS file system identified by UUID:
						</p><pre class="screen"># mount UUID=ea74bbec-536d-490c-b8d9-5b40bbd7545b /mnt/data</pre></div></div></li><li class="listitem"><p class="simpara">
						If <code class="literal">mount</code> cannot recognize the file system type automatically, specify it using the <code class="literal option">--types</code> option:
					</p><pre class="screen"># mount --types <span class="emphasis"><em><span class="replaceable replaceable">type</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">device</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">mount-point</span></em></span></pre><div class="example" id="idm139822452478992"><p class="title"><strong>Example 16.3. Mounting an NFS file system</strong></p><div class="example-contents"><p>
							For example, to mount a remote NFS file system:
						</p><pre class="screen"># mount --types nfs4 host:/remote-export /mnt/nfs</pre></div></div></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">mount(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="moving-a-mount-point_mounting-file-systems"><div class="titlepage"><div><div><h3 class="title">16.4. Moving a mount point</h3></div></div></div><p class="_abstract _abstract">
				Change the mount point of a mounted file system to a different directory by using the <code class="literal">mount</code> utility.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						To change the directory in which a file system is mounted:
					</p><pre class="screen"># mount --move <span class="emphasis"><em><span class="replaceable replaceable">old-directory</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">new-directory</span></em></span></pre><div class="example" id="idm139822449909984"><p class="title"><strong>Example 16.4. Moving a home file system</strong></p><div class="example-contents"><p>
							For example, to move the file system mounted in the <code class="literal filename">/mnt/userdirs/</code> directory to the <code class="literal filename">/home/</code> mount point:
						</p><pre class="screen"># mount --move /mnt/userdirs /home</pre></div></div></li><li class="listitem"><p class="simpara">
						Verify that the file system has been moved as expected:
					</p><pre class="screen">$ findmnt
$ ls <span class="emphasis"><em><span class="replaceable replaceable">old-directory</span></em></span>
$ ls <span class="emphasis"><em><span class="replaceable replaceable">new-directory</span></em></span></pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">mount(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="unmounting-a-file-system-with-umount_mounting-file-systems"><div class="titlepage"><div><div><h3 class="title">16.5. Unmounting a file system with umount</h3></div></div></div><p class="_abstract _abstract">
				Unmount a file system by using the <code class="literal">umount</code> utility.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Try unmounting the file system using either of the following commands:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								By mount point:
							</p><pre class="screen"># umount <span class="emphasis"><em><span class="replaceable replaceable">mount-point</span></em></span></pre></li><li class="listitem"><p class="simpara">
								By device:
							</p><pre class="screen"># umount <span class="emphasis"><em><span class="replaceable replaceable">device</span></em></span></pre></li></ul></div><p class="simpara">
						If the command fails with an error similar to the following, it means that the file system is in use because of a process is using resources on it:
					</p><pre class="screen">umount: <span class="emphasis"><em><span class="replaceable replaceable">/run/media/user/FlashDrive</span></em></span>: target is busy.</pre></li><li class="listitem"><p class="simpara">
						If the file system is in use, use the <code class="literal">fuser</code> utility to determine which processes are accessing it. For example:
					</p><pre class="screen">$ fuser --mount <span class="emphasis"><em><span class="replaceable replaceable">/run/media/user/FlashDrive</span></em></span>

<span class="emphasis"><em><span class="replaceable replaceable">/run/media/user/FlashDrive</span></em></span>: <span class="emphasis"><em><span class="replaceable replaceable">18351</span></em></span></pre><p class="simpara">
						Afterwards, stop the processes using the file system and try unmounting it again.
					</p></li></ol></div></section><section class="section" id="mounting-and-unmounting-file-systems-in-the-web-console_mounting-file-systems"><div class="titlepage"><div><div><h3 class="title">16.6. Mounting and unmounting file systems in the web console</h3></div></div></div><p class="_abstract _abstract">
				To be able to use partitions on RHEL systems, you need to mount a file system on the partition as a device.
			</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					You also can unmount a file system and the RHEL system will stop using it. Unmounting the file system enables you to delete, remove, or re-format devices.
				</p></div></rh-alert><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						The <code class="literal">cockpit-storaged</code> package is installed on your system.
					</li></ul></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						You have installed the RHEL 9 web console.
					</p><p class="simpara">
						For instructions, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console">Installing and enabling the web console</a>.
					</p></li><li class="listitem">
						If you want to unmount a file system, ensure that the system does not use any file, service, or application stored in the partition.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Log in to the RHEL 9 web console.
					</p><p class="simpara">
						For details, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#logging-in-to-the-web-console_getting-started-with-the-rhel-9-web-console">Logging in to the web console</a>.
					</p></li><li class="listitem">
						Click the <span class="strong strong"><strong>Storage</strong></span> tab.
					</li><li class="listitem">
						In the <span class="strong strong"><strong>Storage</strong></span> table, select a volume from which you want to delete the partition.
					</li><li class="listitem">
						In the <span class="strong strong"><strong>GPT partitions</strong></span> section, click the menu button, <span class="guibutton">⋮</span> next to the partition whose file system you want to mount or unmount.
					</li><li class="listitem">
						Click <span class="guibutton">Mount</span> or <span class="guibutton">Unmount</span>.
					</li></ol></div></section><section class="section" id="common-mount-options_mounting-file-systems"><div class="titlepage"><div><div><h3 class="title">16.7. Common mount options</h3></div></div></div><p>
				The following table lists the most common options of the <code class="literal">mount</code> utility. You can apply these mount options using the following syntax:
			</p><pre class="screen"># mount --options <span class="emphasis"><em><span class="replaceable replaceable">option1,option2,option3</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">device</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">mount-point</span></em></span></pre><rh-table id="idm139822467758848"><table class="lt-4-cols lt-7-rows"><caption>Table 16.1. Common mount options</caption><colgroup><col style="width: 25%; " class="col_1"><!--Empty--><col style="width: 75%; " class="col_2"><!--Empty--></colgroup><thead><tr><th align="left" valign="top" id="idm139822467754016" scope="col">Option</th><th align="left" valign="top" id="idm139822467752928" scope="col">Description</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm139822467754016"> <p>
								<code class="literal">async</code>
							</p>
							 </td><td align="left" valign="top" headers="idm139822467752928"> <p>
								Enables asynchronous input and output operations on the file system.
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822467754016"> <p>
								<code class="literal">auto</code>
							</p>
							 </td><td align="left" valign="top" headers="idm139822467752928"> <p>
								Enables the file system to be mounted automatically using the <code class="literal command">mount -a</code> command.
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822467754016"> <p>
								<code class="literal">defaults</code>
							</p>
							 </td><td align="left" valign="top" headers="idm139822467752928"> <p>
								Provides an alias for the <code class="literal">async,auto,dev,exec,nouser,rw,suid</code> options.
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822467754016"> <p>
								<code class="literal">exec</code>
							</p>
							 </td><td align="left" valign="top" headers="idm139822467752928"> <p>
								Allows the execution of binary files on the particular file system.
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822467754016"> <p>
								<code class="literal">loop</code>
							</p>
							 </td><td align="left" valign="top" headers="idm139822467752928"> <p>
								Mounts an image as a loop device.
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822467754016"> <p>
								<code class="literal">noauto</code>
							</p>
							 </td><td align="left" valign="top" headers="idm139822467752928"> <p>
								Default behavior disables the automatic mount of the file system using the <code class="literal command">mount -a</code> command.
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822467754016"> <p>
								<code class="literal">noexec</code>
							</p>
							 </td><td align="left" valign="top" headers="idm139822467752928"> <p>
								Disallows the execution of binary files on the particular file system.
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822467754016"> <p>
								<code class="literal">nouser</code>
							</p>
							 </td><td align="left" valign="top" headers="idm139822467752928"> <p>
								Disallows an ordinary user (that is, other than root) to mount and unmount the file system.
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822467754016"> <p>
								<code class="literal">remount</code>
							</p>
							 </td><td align="left" valign="top" headers="idm139822467752928"> <p>
								Remounts the file system in case it is already mounted.
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822467754016"> <p>
								<code class="literal">ro</code>
							</p>
							 </td><td align="left" valign="top" headers="idm139822467752928"> <p>
								Mounts the file system for reading only.
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822467754016"> <p>
								<code class="literal">rw</code>
							</p>
							 </td><td align="left" valign="top" headers="idm139822467752928"> <p>
								Mounts the file system for both reading and writing.
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822467754016"> <p>
								<code class="literal">user</code>
							</p>
							 </td><td align="left" valign="top" headers="idm139822467752928"> <p>
								Allows an ordinary user (that is, other than root) to mount and unmount the file system.
							</p>
							 </td></tr></tbody></table></rh-table></section></section><section class="chapter" id="sharing-a-mount-on-multiple-mount-points_managing-file-systems"><div class="titlepage"><div><div><h2 class="title">Chapter 17. Sharing a mount on multiple mount points</h2></div></div></div><p class="_abstract _abstract">
			As a system administrator, you can duplicate mount points to make the file systems accessible from multiple directories.
		</p><section class="section" id="types-of-shared-mounts_sharing-a-mount-on-multiple-mount-points"><div class="titlepage"><div><div><h3 class="title">17.1. Types of shared mounts</h3></div></div></div><p class="_abstract _abstract">
				There are multiple types of shared mounts that you can use. The difference between them is what happens when you mount another file system under one of the shared mount points. The shared mounts are implemented using the <span class="emphasis"><em>shared subtrees</em></span> functionality.
			</p><p>
				The following mount types are available:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">private</code></span></dt><dd><p class="simpara">
							This type does not receive or forward any propagation events.
						</p><p class="simpara">
							When you mount another file system under either the duplicate or the original mount point, it is not reflected in the other.
						</p></dd><dt><span class="term"><code class="literal">shared</code></span></dt><dd><p class="simpara">
							This type creates an exact replica of a given mount point.
						</p><p class="simpara">
							When a mount point is marked as a <code class="literal">shared</code> mount, any mount within the original mount point is reflected in it, and vice versa.
						</p><p class="simpara">
							This is the default mount type of the root file system.
						</p></dd><dt><span class="term"><code class="literal">slave</code></span></dt><dd><p class="simpara">
							This type creates a limited duplicate of a given mount point.
						</p><p class="simpara">
							When a mount point is marked as a <code class="literal">slave</code> mount, any mount within the original mount point is reflected in it, but no mount within a <code class="literal">slave</code> mount is reflected in its original.
						</p></dd><dt><span class="term"><code class="literal">unbindable</code></span></dt><dd>
							This type prevents the given mount point from being duplicated whatsoever.
						</dd></dl></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="https://lwn.net/Articles/159077/">The <span class="emphasis"><em>Shared subtrees</em></span> article on Linux Weekly News</a>
					</li></ul></div></section><section class="section" id="creating-a-private-mount-point-duplicate_sharing-a-mount-on-multiple-mount-points"><div class="titlepage"><div><div><h3 class="title">17.2. Creating a private mount point duplicate</h3></div></div></div><p class="_abstract _abstract">
				Duplicate a mount point as a private mount. File systems that you later mount under the duplicate or the original mount point are not reflected in the other.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Create a virtual file system (VFS) node from the original mount point:
					</p><pre class="screen"># mount --bind <span class="emphasis"><em><span class="replaceable replaceable">original-dir</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">original-dir</span></em></span></pre></li><li class="listitem"><p class="simpara">
						Mark the original mount point as private:
					</p><pre class="screen"># mount --make-private <span class="emphasis"><em><span class="replaceable replaceable">original-dir</span></em></span></pre><p class="simpara">
						Alternatively, to change the mount type for the selected mount point and all mount points under it, use the <code class="literal option">--make-rprivate</code> option instead of <code class="literal option">--make-private</code>.
					</p></li><li class="listitem"><p class="simpara">
						Create the duplicate:
					</p><pre class="screen"># mount --bind <span class="emphasis"><em><span class="replaceable replaceable">original-dir</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">duplicate-dir</span></em></span></pre></li></ol></div><div class="example" id="idm139822450410752"><p class="title"><strong>Example 17.1. Duplicating /media into /mnt as a private mount point</strong></p><div class="example-contents"><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Create a VFS node from the <code class="literal filename">/media</code> directory:
						</p><pre class="screen"># mount --bind /media /media</pre></li><li class="listitem"><p class="simpara">
							Mark the <code class="literal filename">/media</code> directory as private:
						</p><pre class="screen"># mount --make-private /media</pre></li><li class="listitem"><p class="simpara">
							Create its duplicate in <code class="literal filename">/mnt</code>:
						</p><pre class="screen"># mount --bind /media /mnt</pre></li><li class="listitem"><p class="simpara">
							It is now possible to verify that <code class="literal filename">/media</code> and <code class="literal filename">/mnt</code> share content but none of the mounts within <code class="literal filename">/media</code> appear in <code class="literal filename">/mnt</code>. For example, if the CD-ROM drive contains non-empty media and the <code class="literal filename">/media/cdrom/</code> directory exists, use:
						</p><pre class="screen"># mount /dev/cdrom /media/cdrom
# ls /media/cdrom
EFI  GPL  isolinux  LiveOS
# ls /mnt/cdrom
#</pre></li><li class="listitem"><p class="simpara">
							It is also possible to verify that file systems mounted in the <code class="literal filename">/mnt</code> directory are not reflected in <code class="literal filename">/media</code>. For example, if a non-empty USB flash drive that uses the <code class="literal filename">/dev/sdc1</code> device is plugged in and the <code class="literal filename">/mnt/flashdisk/</code> directory is present, use:
						</p><pre class="screen"># mount /dev/sdc1 /mnt/flashdisk
# ls /media/flashdisk
# ls /mnt/flashdisk
en-US  publican.cfg</pre></li></ol></div></div></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">mount(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="creating-a-shared-mount-point-duplicate_sharing-a-mount-on-multiple-mount-points"><div class="titlepage"><div><div><h3 class="title">17.3. Creating a shared mount point duplicate</h3></div></div></div><p class="_abstract _abstract">
				Duplicate a mount point as a shared mount. File systems that you later mount under the original directory or the duplicate are always reflected in the other.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Create a virtual file system (VFS) node from the original mount point:
					</p><pre class="screen"># mount --bind <span class="emphasis"><em><span class="replaceable replaceable">original-dir</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">original-dir</span></em></span></pre></li><li class="listitem"><p class="simpara">
						Mark the original mount point as shared:
					</p><pre class="screen"># mount --make-shared <span class="emphasis"><em><span class="replaceable replaceable">original-dir</span></em></span></pre><p class="simpara">
						Alternatively, to change the mount type for the selected mount point and all mount points under it, use the <code class="literal option">--make-rshared</code> option instead of <code class="literal option">--make-shared</code>.
					</p></li><li class="listitem"><p class="simpara">
						Create the duplicate:
					</p><pre class="screen"># mount --bind <span class="emphasis"><em><span class="replaceable replaceable">original-dir</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">duplicate-dir</span></em></span></pre></li></ol></div><div class="example" id="idm139822449967264"><p class="title"><strong>Example 17.2. Duplicating /media into /mnt as a shared mount point</strong></p><div class="example-contents"><p>
					To make the <code class="literal filename">/media</code> and <code class="literal filename">/mnt</code> directories share the same content:
				</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Create a VFS node from the <code class="literal filename">/media</code> directory:
						</p><pre class="screen"># mount --bind /media /media</pre></li><li class="listitem"><p class="simpara">
							Mark the <code class="literal filename">/media</code> directory as shared:
						</p><pre class="screen"># mount --make-shared /media</pre></li><li class="listitem"><p class="simpara">
							Create its duplicate in <code class="literal filename">/mnt</code>:
						</p><pre class="screen"># mount --bind /media /mnt</pre></li><li class="listitem"><p class="simpara">
							It is now possible to verify that a mount within <code class="literal filename">/media</code> also appears in <code class="literal filename">/mnt</code>. For example, if the CD-ROM drive contains non-empty media and the <code class="literal filename">/media/cdrom/</code> directory exists, use:
						</p><pre class="screen"># mount /dev/cdrom /media/cdrom
# ls /media/cdrom
EFI  GPL  isolinux  LiveOS
# ls /mnt/cdrom
EFI  GPL  isolinux  LiveOS</pre></li><li class="listitem"><p class="simpara">
							Similarly, it is possible to verify that any file system mounted in the <code class="literal filename">/mnt</code> directory is reflected in <code class="literal filename">/media</code>. For example, if a non-empty USB flash drive that uses the <code class="literal filename">/dev/sdc1</code> device is plugged in and the <code class="literal filename">/mnt/flashdisk/</code> directory is present, use:
						</p><pre class="screen"># mount /dev/sdc1 /mnt/flashdisk
# ls /media/flashdisk
en-US  publican.cfg
# ls /mnt/flashdisk
en-US  publican.cfg</pre></li></ol></div></div></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">mount(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="creating-a-slave-mount-point-duplicate_sharing-a-mount-on-multiple-mount-points"><div class="titlepage"><div><div><h3 class="title">17.4. Creating a slave mount point duplicate</h3></div></div></div><p class="_abstract _abstract">
				Duplicate a mount point as a <code class="literal">slave</code> mount type. File systems that you later mount under the original mount point are reflected in the duplicate but not the other way around.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Create a virtual file system (VFS) node from the original mount point:
					</p><pre class="screen"># mount --bind <span class="emphasis"><em><span class="replaceable replaceable">original-dir</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">original-dir</span></em></span></pre></li><li class="listitem"><p class="simpara">
						Mark the original mount point as shared:
					</p><pre class="screen"># mount --make-shared <span class="emphasis"><em><span class="replaceable replaceable">original-dir</span></em></span></pre><p class="simpara">
						Alternatively, to change the mount type for the selected mount point and all mount points under it, use the <code class="literal option">--make-rshared</code> option instead of <code class="literal option">--make-shared</code>.
					</p></li><li class="listitem"><p class="simpara">
						Create the duplicate and mark it as the <code class="literal">slave</code> type:
					</p><pre class="screen"># mount --bind <span class="emphasis"><em><span class="replaceable replaceable">original-dir</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">duplicate-dir</span></em></span>
# mount --make-slave <span class="emphasis"><em><span class="replaceable replaceable">duplicate-dir</span></em></span></pre></li></ol></div><div class="example" id="idm139822450465584"><p class="title"><strong>Example 17.3. Duplicating /media into /mnt as a slave mount point</strong></p><div class="example-contents"><p>
					This example shows how to get the content of the <code class="literal filename">/media</code> directory to appear in <code class="literal filename">/mnt</code> as well, but without any mounts in the <code class="literal filename">/mnt</code> directory to be reflected in <code class="literal filename">/media</code>.
				</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Create a VFS node from the <code class="literal filename">/media</code> directory:
						</p><pre class="screen"># mount --bind /media /media</pre></li><li class="listitem"><p class="simpara">
							Mark the <code class="literal filename">/media</code> directory as shared:
						</p><pre class="screen"># mount --make-shared /media</pre></li><li class="listitem"><p class="simpara">
							Create its duplicate in <code class="literal filename">/mnt</code> and mark it as <code class="literal">slave</code>:
						</p><pre class="screen"># mount --bind /media /mnt
# mount --make-slave /mnt</pre></li><li class="listitem"><p class="simpara">
							Verify that a mount within <code class="literal filename">/media</code> also appears in <code class="literal filename">/mnt</code>. For example, if the CD-ROM drive contains non-empty media and the <code class="literal filename">/media/cdrom/</code> directory exists, use:
						</p><pre class="screen"># mount /dev/cdrom /media/cdrom
# ls /media/cdrom
EFI  GPL  isolinux  LiveOS
# ls /mnt/cdrom
EFI  GPL  isolinux  LiveOS</pre></li><li class="listitem"><p class="simpara">
							Also verify that file systems mounted in the <code class="literal filename">/mnt</code> directory are not reflected in <code class="literal filename">/media</code>. For example, if a non-empty USB flash drive that uses the <code class="literal filename">/dev/sdc1</code> device is plugged in and the <code class="literal filename">/mnt/flashdisk/</code> directory is present, use:
						</p><pre class="screen"># mount /dev/sdc1 /mnt/flashdisk
# ls /media/flashdisk
# ls /mnt/flashdisk
en-US  publican.cfg</pre></li></ol></div></div></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">mount(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="preventing-a-mount-point-from-being-duplicated_sharing-a-mount-on-multiple-mount-points"><div class="titlepage"><div><div><h3 class="title">17.5. Preventing a mount point from being duplicated</h3></div></div></div><p class="_abstract _abstract">
				Mark a mount point as unbindable so that it is not possible to duplicate it in another mount point.
			</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						To change the type of a mount point to an unbindable mount, use:
					</p><pre class="screen"># mount --bind <span class="emphasis"><em><span class="replaceable replaceable">mount-point</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">mount-point</span></em></span>
# mount --make-unbindable <span class="emphasis"><em><span class="replaceable replaceable">mount-point</span></em></span></pre><p class="simpara">
						Alternatively, to change the mount type for the selected mount point and all mount points under it, use the <code class="literal option">--make-runbindable</code> option instead of <code class="literal option">--make-unbindable</code>.
					</p><p class="simpara">
						Any subsequent attempt to make a duplicate of this mount fails with the following error:
					</p><pre class="screen"># mount --bind <span class="emphasis"><em><span class="replaceable replaceable">mount-point</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">duplicate-dir</span></em></span>

mount: wrong fs type, bad option, bad superblock on <span class="emphasis"><em><span class="replaceable replaceable">mount-point</span></em></span>,
missing codepage or helper program, or other error
In some cases useful info is found in syslog - try
dmesg | tail  or so</pre></li></ul></div><div class="example" id="idm139822467721632"><p class="title"><strong>Example 17.4. Preventing /media from being duplicated</strong></p><div class="example-contents"><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							To prevent the <code class="literal filename">/media</code> directory from being shared, use:
						</p><pre class="screen"># mount --bind /media /media
# mount --make-unbindable /media</pre></li></ul></div></div></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">mount(8)</code> man page on your system
					</li></ul></div></section></section><section class="chapter" id="assembly_persistently-mounting-file-systems_managing-file-systems"><div class="titlepage"><div><div><h2 class="title">Chapter 18. Persistently mounting file systems</h2></div></div></div><p class="_abstract _abstract">
			As a system administrator, you can persistently mount file systems to configure non-removable storage.
		</p><section class="section" id="con_the-etc-fstab-file_assembly_persistently-mounting-file-systems"><div class="titlepage"><div><div><h3 class="title">18.1. The /etc/fstab file</h3></div></div></div><p class="_abstract _abstract">
				Use the <code class="literal">/etc/fstab</code> configuration file to control persistent mount points of file systems. Each line in the <code class="literal">/etc/fstab</code> file defines a mount point of a file system.
			</p><p>
				It includes six fields separated by white space:
			</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
						The block device identified by a persistent attribute or a path in the <code class="literal">/dev</code> directory.
					</li><li class="listitem">
						The directory where the device will be mounted.
					</li><li class="listitem">
						The file system on the device.
					</li><li class="listitem">
						Mount options for the file system, which includes the <code class="literal">defaults</code> option to mount the partition at boot time with default options. The mount option field also recognizes the <code class="literal">systemd</code> mount unit options in the <code class="literal">x-systemd.<span class="emphasis"><em>option</em></span></code> format.
					</li><li class="listitem">
						Backup option for the <code class="literal">dump</code> utility.
					</li><li class="listitem">
						Check order for the <code class="literal">fsck</code> utility.
					</li></ol></div><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					The <code class="literal">systemd-fstab-generator</code> dynamically converts the entries from the <code class="literal">/etc/fstab</code> file to the <code class="literal">systemd-mount</code> units. The <code class="literal">systemd</code> auto mounts LVM volumes from <code class="literal">/etc/fstab</code> during manual activation unless the <code class="literal">systemd-mount</code> unit is masked.
				</p></div></rh-alert><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					The <code class="literal">dump</code> utility used for backup of file systems has been removed in RHEL 9, and is available in the EPEL 9 repository.
				</p></div></rh-alert><div class="example" id="idm139822450229440"><p class="title"><strong>Example 18.1. The <code class="literal filename">/boot</code> file system in <code class="literal filename">/etc/fstab</code></strong></p><div class="example-contents"><rh-table><table class="gt-4-cols lt-7-rows"><colgroup><col style="width: 29%; " class="col_1"><!--Empty--><col style="width: 14%; " class="col_2"><!--Empty--><col style="width: 14%; " class="col_3"><!--Empty--><col style="width: 14%; " class="col_4"><!--Empty--><col style="width: 14%; " class="col_5"><!--Empty--><col style="width: 14%; " class="col_6"><!--Empty--></colgroup><thead><tr><th align="left" valign="top" id="idm139822448903120" scope="col">Block device</th><th align="left" valign="top" id="idm139822448902032" scope="col">Mount point</th><th align="left" valign="top" id="idm139822448900944" scope="col">File system</th><th align="left" valign="top" id="idm139822448899856" scope="col">Options</th><th align="left" valign="top" id="idm139822448898768" scope="col">Backup</th><th align="left" valign="top" id="idm139822448897680" scope="col">Check</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm139822448903120"> <p>
									<code class="literal">UUID=ea74bbec-536d-490c-b8d9-5b40bbd7545b</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139822448902032"> <p>
									<code class="literal">/boot</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139822448900944"> <p>
									<code class="literal">xfs</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139822448899856"> <p>
									<code class="literal">defaults</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139822448898768"> <p>
									<code class="literal">0</code>
								</p>
								 </td><td align="left" valign="top" headers="idm139822448897680"> <p>
									<code class="literal">0</code>
								</p>
								 </td></tr></tbody></table></rh-table></div></div><p>
				The <code class="literal">systemd</code> service automatically generates mount units from entries in <code class="literal filename">/etc/fstab</code>.
			</p><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">fstab(5)</code> and <code class="literal">systemd.mount(5)</code> man pages on your system
					</li></ul></div></section><section class="section" id="adding-a-file-system-to-etc-fstab_assembly_persistently-mounting-file-systems"><div class="titlepage"><div><div><h3 class="title">18.2. Adding a file system to /etc/fstab</h3></div></div></div><p class="_abstract _abstract">
				Configure persistent mount point for a file system in the <code class="literal filename">/etc/fstab</code> configuration file.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Find out the UUID attribute of the file system:
					</p><pre class="screen">$ lsblk --fs <span class="emphasis"><em><span class="replaceable replaceable">storage-device</span></em></span></pre><p class="simpara">
						For example:
					</p><div class="example" id="idm139822451240784"><p class="title"><strong>Example 18.2. Viewing the UUID of a partition</strong></p><div class="example-contents"><pre class="screen">$ lsblk --fs <span class="emphasis"><em><span class="replaceable replaceable">/dev/sda1</span></em></span>

NAME FSTYPE LABEL <span class="strong strong"><strong>UUID</strong></span>                                 MOUNTPOINT
sda1 xfs    Boot  <span class="strong strong"><strong>ea74bbec-536d-490c-b8d9-5b40bbd7545b</strong></span> /boot</pre></div></div></li><li class="listitem"><p class="simpara">
						If the mount point directory does not exist, create it:
					</p><pre class="screen"># mkdir --parents <span class="emphasis"><em><span class="replaceable replaceable">mount-point</span></em></span></pre></li><li class="listitem"><p class="simpara">
						As root, edit the <code class="literal filename">/etc/fstab</code> file and add a line for the file system, identified by the UUID.
					</p><p class="simpara">
						For example:
					</p><div class="example" id="idm139822451232176"><p class="title"><strong>Example 18.3. The /boot mount point in /etc/fstab</strong></p><div class="example-contents"><pre class="screen">UUID=ea74bbec-536d-490c-b8d9-5b40bbd7545b /boot xfs defaults 0 0</pre></div></div></li><li class="listitem"><p class="simpara">
						Regenerate mount units so that your system registers the new configuration:
					</p><pre class="screen"># systemctl daemon-reload</pre></li><li class="listitem"><p class="simpara">
						Try mounting the file system to verify that the configuration works:
					</p><pre class="screen"># mount <span class="emphasis"><em><span class="replaceable replaceable">mount-point</span></em></span></pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#con_device-names-managed-by-the-udev-mechanism-in-dev-disk-_assembly_overview-of-persistent-naming-attributes">Overview of persistent naming attributes</a>
					</li></ul></div></section></section><section class="chapter" id="mounting-file-systems-on-demand_managing-file-systems"><div class="titlepage"><div><div><h2 class="title">Chapter 19. Mounting file systems on demand</h2></div></div></div><p>
			As a system administrator, you can configure file systems, such as NFS, to mount automatically on demand.
		</p><section class="section" id="the-autofs-service_mounting-file-systems-on-demand"><div class="titlepage"><div><div><h3 class="title">19.1. The autofs service</h3></div></div></div><p class="_abstract _abstract">
				The <code class="literal">autofs</code> service can mount and unmount file systems automatically (on-demand), therefore saving system resources. It can be used to mount file systems such as NFS, AFS, SMBFS, CIFS, and local file systems.
			</p><p>
				One drawback of permanent mounting using the <code class="literal filename">/etc/fstab</code> configuration is that, regardless of how infrequently a user accesses the mounted file system, the system must dedicate resources to keep the mounted file system in place. This might affect system performance when, for example, the system is maintaining NFS mounts to many systems at one time.
			</p><p>
				An alternative to <code class="literal filename">/etc/fstab</code> is to use the kernel-based <code class="literal">autofs</code> service. It consists of the following components:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						A kernel module that implements a file system, and
					</li><li class="listitem">
						A user-space service that performs all of the other functions.
					</li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">autofs(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="the-autofs-configuration-files_mounting-file-systems-on-demand"><div class="titlepage"><div><div><h3 class="title">19.2. The autofs configuration files</h3></div></div></div><p class="_abstract _abstract">
				This section describes the usage and syntax of configuration files used by the <code class="literal">autofs</code> service.
			</p><div class="formalpara"><p class="title"><strong>The master map file</strong></p><p>
					The <code class="literal">autofs</code> service uses <code class="literal filename">/etc/auto.master</code> (master map) as its default primary configuration file. This can be changed to use another supported network source and name using the <code class="literal">autofs</code> configuration in the <code class="literal filename">/etc/autofs.conf</code> configuration file in conjunction with the Name Service Switch (NSS) mechanism.
				</p></div><p>
				All on-demand mount points must be configured in the master map. Mount point, host name, exported directory, and options can all be specified in a set of files (or other supported network sources) rather than configuring them manually for each host.
			</p><p>
				The master map file lists mount points controlled by <code class="literal">autofs</code>, and their corresponding configuration files or network sources known as automount maps. The format of the master map is as follows:
			</p><pre class="screen"><span class="emphasis"><em><span class="replaceable replaceable">mount-point</span></em></span>  <span class="emphasis"><em><span class="replaceable replaceable">map-name</span></em></span>  <span class="emphasis"><em><span class="replaceable replaceable">options</span></em></span></pre><p>
				The variables used in this format are:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><span class="emphasis"><em><span class="replaceable replaceable">mount-point</span></em></span></span></dt><dd>
							The <code class="literal">autofs</code> mount point; for example, <code class="literal filename">/mnt/data</code>.
						</dd><dt><span class="term"><span class="emphasis"><em><span class="replaceable replaceable">map-file</span></em></span></span></dt><dd>
							The map source file, which contains a list of mount points and the file system location from which those mount points should be mounted.
						</dd><dt><span class="term"><span class="emphasis"><em><span class="replaceable replaceable">options</span></em></span></span></dt><dd>
							If supplied, these apply to all entries in the given map, if they do not themselves have options specified.
						</dd></dl></div><div class="example" id="idm139822453675952"><p class="title"><strong>Example 19.1. The /etc/auto.master file</strong></p><div class="example-contents"><p>
					The following is a sample line from <code class="literal filename">/etc/auto.master</code> file:
				</p><pre class="screen">/mnt/data  /etc/auto.data</pre></div></div><div class="formalpara"><p class="title"><strong>Map files</strong></p><p>
					Map files configure the properties of individual on-demand mount points.
				</p></div><p>
				The automounter creates the directories if they do not exist. If the directories exist before the automounter was started, the automounter will not remove them when it exits. If a timeout is specified, the directory is automatically unmounted if the directory is not accessed for the timeout period.
			</p><p>
				The general format of maps is similar to the master map. However, the options field appears between the mount point and the location instead of at the end of the entry as in the master map:
			</p><pre class="screen"><span class="emphasis"><em><span class="replaceable replaceable">mount-point</span></em></span>  <span class="emphasis"><em><span class="replaceable replaceable">options</span></em></span>  <span class="emphasis"><em><span class="replaceable replaceable">location</span></em></span></pre><p>
				The variables used in this format are:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><span class="emphasis"><em><span class="replaceable replaceable">mount-point</span></em></span></span></dt><dd>
							This refers to the <code class="literal">autofs</code> mount point. This can be a single directory name for an indirect mount or the full path of the mount point for direct mounts. Each direct and indirect map entry key (<span class="emphasis"><em><span class="replaceable replaceable">mount-point</span></em></span>) can be followed by a space separated list of offset directories (subdirectory names each beginning with <code class="literal">/</code>) making them what is known as a multi-mount entry.
						</dd><dt><span class="term"><span class="emphasis"><em><span class="replaceable replaceable">options</span></em></span></span></dt><dd>
							When supplied, these options are appended to the master map entry options, if any, or used instead of the master map options if the configuration entry <code class="literal">append_options</code> is set to <code class="literal">no</code>.
						</dd><dt><span class="term"><span class="emphasis"><em><span class="replaceable replaceable">location</span></em></span></span></dt><dd>
							This refers to the file system location such as a local file system path (preceded with the Sun map format escape character <code class="literal">:</code> for map names beginning with <code class="literal">/</code>), an NFS file system or other valid file system location.
						</dd></dl></div><div class="example" id="idm139822452846560"><p class="title"><strong>Example 19.2. A map file</strong></p><div class="example-contents"><p>
					The following is a sample from a map file; for example, <code class="literal filename">/etc/auto.misc</code>:
				</p><pre class="screen">payroll  -fstype=nfs4  personnel:/exports/payroll
sales    -fstype=xfs   :/dev/hda4</pre><p>
					The first column in the map file indicates the <code class="literal">autofs</code> mount point: <code class="literal">sales</code> and <code class="literal">payroll</code> from the server called <code class="literal">personnel</code>. The second column indicates the options for the <code class="literal">autofs</code> mount. The third column indicates the source of the mount.
				</p><p>
					Following the given configuration, the <code class="literal">autofs</code> mount points will be <code class="literal">/home/payroll</code> and <code class="literal">/home/sales</code>. The <code class="literal option">-fstype=</code> option is often omitted and is not needed if the file system is NFS, including mounts for NFSv4 if the system default is NFSv4 for NFS mounts.
				</p><p>
					Using the given configuration, if a process requires access to an <code class="literal">autofs</code> unmounted directory such as <code class="literal filename">/home/payroll/2006/July.sxc</code>, the <code class="literal">autofs</code> service automatically mounts the directory.
				</p></div></div><div class="formalpara"><p class="title"><strong>The amd map format</strong></p><p>
					The <code class="literal">autofs</code> service recognizes map configuration in the <code class="literal">amd</code> format as well. This is useful if you want to reuse existing automounter configuration written for the <code class="literal">am-utils</code> service, which has been removed from Red Hat Enterprise Linux.
				</p></div><p>
				However, Red Hat recommends using the simpler <code class="literal">autofs</code> format described in the previous sections.
			</p><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">autofs(5)</code>, <code class="literal">autofs.conf(5)</code>, and <code class="literal">auto.master(5)</code> man pages on your system
					</li><li class="listitem">
						<code class="literal filename">/usr/share/doc/autofs/README.amd-maps</code> file
					</li></ul></div></section><section class="section" id="configuring-autofs-mount-points_mounting-file-systems-on-demand"><div class="titlepage"><div><div><h3 class="title">19.3. Configuring autofs mount points</h3></div></div></div><p class="_abstract _abstract">
				Configure on-demand mount points by using the <code class="literal">autofs</code> service.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Install the <code class="literal package">autofs</code> package:
					</p><pre class="screen"># dnf install autofs</pre></li><li class="listitem"><p class="simpara">
						Start and enable the <code class="literal">autofs</code> service:
					</p><pre class="screen"># systemctl enable --now autofs</pre></li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem">
						Create a map file for the on-demand mount point, located at <code class="literal filename">/etc/auto.<span class="emphasis"><em><span class="replaceable replaceable">identifier</span></em></span></code>. Replace <span class="emphasis"><em><span class="replaceable replaceable">identifier</span></em></span> with a name that identifies the mount point.
					</li><li class="listitem">
						In the map file, enter the mount point, options, and location fields as described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_file_systems/mounting-file-systems-on-demand_managing-file-systems#the-autofs-configuration-files_mounting-file-systems-on-demand">The autofs configuration files</a> section.
					</li><li class="listitem">
						Register the map file in the master map file, as described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_file_systems/mounting-file-systems-on-demand_managing-file-systems#the-autofs-configuration-files_mounting-file-systems-on-demand">The autofs configuration files</a> section.
					</li><li class="listitem"><p class="simpara">
						Allow the service to re-read the configuration, so it can manage the newly configured <code class="literal">autofs</code> mount:
					</p><pre class="screen"># systemctl reload autofs.service</pre></li><li class="listitem"><p class="simpara">
						Try accessing content in the on-demand directory:
					</p><pre class="screen"># ls <span class="emphasis"><em><span class="replaceable replaceable">automounted-directory</span></em></span></pre></li></ol></div></section><section class="section" id="automounting-user-home-directories-with-autofs-service_mounting-file-systems-on-demand"><div class="titlepage"><div><div><h3 class="title">19.4. Automounting NFS server user home directories with autofs service</h3></div></div></div><p class="_abstract _abstract">
				Configure the <span class="strong strong"><strong>autofs</strong></span> service to mount user home directories automatically.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						The <span class="strong strong"><strong><span class="package package">autofs</span></strong></span> package is installed.
					</li><li class="listitem">
						The <span class="strong strong"><strong><span class="service service">autofs</span></strong></span> service is enabled and running.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Specify the mount point and location of the map file by editing the <code class="literal filename">/etc/auto.master</code> file on a server on which you need to mount user home directories. To do so, add the following line into the <code class="literal filename">/etc/auto.master</code> file:
					</p><pre class="screen">/home /etc/auto.home</pre></li><li class="listitem"><p class="simpara">
						Create a map file with the name of <code class="literal filename">/etc/auto.home</code> on a server on which you need to mount user home directories, and edit the file with the following parameters:
					</p><pre class="screen">* -fstype=nfs,rw,sync <span class="emphasis"><em>host.example.com</em></span>:/home/&amp;</pre><p class="simpara">
						You can skip <code class="literal"><span class="emphasis"><em>fstype</em></span></code> parameter, as it is <code class="literal"><span class="emphasis"><em>nfs</em></span></code> by default. For more information, see <code class="literal">autofs(5)</code> man page on your system.
					</p></li><li class="listitem"><p class="simpara">
						Reload the <code class="literal service">autofs</code> service:
					</p><pre class="screen"># systemctl reload autofs</pre></li></ol></div></section><section class="section" id="overriding-or-augmenting-autofs-site-configuration-files_mounting-file-systems-on-demand"><div class="titlepage"><div><div><h3 class="title">19.5. Overriding or augmenting autofs site configuration files</h3></div></div></div><p class="_abstract _abstract">
				It is sometimes useful to override site defaults for a specific mount point on a client system.
			</p><div class="example" id="idm139822451796928"><p class="title"><strong>Example 19.3. Initial conditions</strong></p><div class="example-contents"><p>
					For example, consider the following conditions:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							Automounter maps are stored in NIS and the <code class="literal filename">/etc/nsswitch.conf</code> file has the following directive:
						</p><pre class="screen">automount:    files nis</pre></li><li class="listitem"><p class="simpara">
							The <code class="literal">auto.master</code> file contains:
						</p><pre class="screen">+auto.master</pre></li><li class="listitem"><p class="simpara">
							The NIS <code class="literal">auto.master</code> map file contains:
						</p><pre class="screen">/home auto.home</pre></li><li class="listitem"><p class="simpara">
							The NIS <code class="literal">auto.home</code> map contains:
						</p><pre class="screen">beth    fileserver.example.com:/export/home/beth
joe     fileserver.example.com:/export/home/joe
*       fileserver.example.com:/export/home/&amp;</pre></li><li class="listitem"><p class="simpara">
							The <code class="literal">autofs</code> configuration option <code class="literal">BROWSE_MODE</code> is set to <code class="literal">yes</code>:
						</p><pre class="screen">BROWSE_MODE="yes"</pre></li><li class="listitem">
							The file map <code class="literal filename">/etc/auto.home</code> does not exist.
						</li></ul></div></div></div><div class="formalpara"><p class="title"><strong>Procedure</strong></p><p>
					This section describes the examples of mounting home directories from a different server and augmenting <code class="literal">auto.home</code> with only selected entries.
				</p></div><div class="example" id="idm139822451779968"><p class="title"><strong>Example 19.4. Mounting home directories from a different server</strong></p><div class="example-contents"><p>
					Given the preceding conditions, let’s assume that the client system needs to override the NIS map <code class="literal">auto.home</code> and mount home directories from a different server.
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							In this case, the client needs to use the following <code class="literal filename">/etc/auto.master</code> map:
						</p><pre class="screen">/home ­/etc/auto.home
+auto.master</pre></li><li class="listitem"><p class="simpara">
							The <code class="literal filename">/etc/auto.home</code> map contains the entry:
						</p><pre class="screen">*    host.example.com:/export/home/&amp;</pre></li></ul></div><p>
					Because the automounter only processes the first occurrence of a mount point, the <code class="literal filename">/home</code> directory contains the content of <code class="literal filename">/etc/auto.home</code> instead of the NIS <code class="literal">auto.home</code> map.
				</p></div></div><div class="example" id="idm139822449170544"><p class="title"><strong>Example 19.5. Augmenting auto.home with only selected entries</strong></p><div class="example-contents"><p>
					Alternatively, to augment the site-wide <code class="literal">auto.home</code> map with just a few entries:
				</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Create an <code class="literal filename">/etc/auto.home</code> file map, and in it put the new entries. At the end, include the NIS <code class="literal">auto.home</code> map. Then the <code class="literal filename">/etc/auto.home</code> file map looks similar to:
						</p><pre class="screen">mydir someserver:/export/mydir
+auto.home</pre></li><li class="listitem"><p class="simpara">
							With these NIS <code class="literal">auto.home</code> map conditions, listing the content of the <code class="literal filename">/home</code> directory outputs:
						</p><pre class="screen">$ ls /home

beth joe mydir</pre></li></ol></div><p>
					This last example works as expected because <code class="literal">autofs</code> does not include the contents of a file map of the same name as the one it is reading. As such, <code class="literal">autofs</code> moves on to the next map source in the <code class="literal">nsswitch</code> configuration.
				</p></div></div></section><section class="section" id="using-ldap-to-store-automounter-maps_mounting-file-systems-on-demand"><div class="titlepage"><div><div><h3 class="title">19.6. Using LDAP to store automounter maps</h3></div></div></div><p class="_abstract _abstract">
				Configure <code class="literal">autofs</code> to store automounter maps in LDAP configuration rather than in <code class="literal">autofs</code> map files.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						LDAP client libraries must be installed on all systems configured to retrieve automounter maps from LDAP. On Red Hat Enterprise Linux, the <code class="literal package">openldap</code> package should be installed automatically as a dependency of the <code class="literal package">autofs</code> package.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem">
						To configure LDAP access, modify the <code class="literal filename">/etc/openldap/ldap.conf</code> file. Ensure that the <code class="literal">BASE</code>, <code class="literal">URI</code>, and <code class="literal">schema</code> options are set appropriately for your site.
					</li><li class="listitem"><p class="simpara">
						The most recently established schema for storing automount maps in LDAP is described by the <code class="literal">rfc2307bis</code> draft. To use this schema, set it in the <code class="literal filename">/etc/autofs.conf</code> configuration file by removing the comment characters from the schema definition. For example:
					</p><div class="example" id="idm139822450727680"><p class="title"><strong>Example 19.6. Setting autofs configuration</strong></p><div class="example-contents"><pre class="screen">DEFAULT_MAP_OBJECT_CLASS="automountMap"
DEFAULT_ENTRY_OBJECT_CLASS="automount"
DEFAULT_MAP_ATTRIBUTE="automountMapName"
DEFAULT_ENTRY_ATTRIBUTE="automountKey"
DEFAULT_VALUE_ATTRIBUTE="automountInformation"</pre></div></div></li><li class="listitem"><p class="simpara">
						Ensure that all other schema entries are commented in the configuration. The <code class="literal">automountKey</code> attribute of the <code class="literal">rfc2307bis</code> schema replaces the <code class="literal">cn</code> attribute of the <code class="literal">rfc2307</code> schema. Following is an example of an LDAP Data Interchange Format (LDIF) configuration:
					</p><div class="example" id="idm139822450723008"><p class="title"><strong>Example 19.7. LDIF Configuration</strong></p><div class="example-contents"><pre class="screen"># auto.master, example.com
dn: automountMapName=auto.master,dc=example,dc=com
objectClass: top
objectClass: automountMap
automountMapName: auto.master

# /home, auto.master, example.com
dn: automountMapName=auto.master,dc=example,dc=com
objectClass: automount
automountKey: /home
automountInformation: auto.home

# auto.home, example.com
dn: automountMapName=auto.home,dc=example,dc=com
objectClass: automountMap
automountMapName: auto.home

# foo, auto.home, example.com
dn: automountKey=foo,automountMapName=auto.home,dc=example,dc=com
objectClass: automount
automountKey: foo
automountInformation: filer.example.com:/export/foo

# /, auto.home, example.com
dn: automountKey=/,automountMapName=auto.home,dc=example,dc=com
objectClass: automount
automountKey: /
automountInformation: filer.example.com:/export/&amp;</pre></div></div></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="https://tools.ietf.org/html/draft-howard-rfc2307bis">The <code class="literal">rfc2307bis</code> draft</a>
					</li></ul></div></section><section class="section" id="proc_using-systemd-automount-to-mount-a-file-system-on-demand-with-etc-fstab_mounting-file-systems-on-demand"><div class="titlepage"><div><div><h3 class="title">19.7. Using systemd.automount to mount a file system on demand with /etc/fstab</h3></div></div></div><p class="_abstract _abstract">
				Mount a file system on demand using the automount systemd units when mount point is defined in <code class="literal">/etc/fstab</code>. You have to add an automount unit for each mount and enable it.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Add desired fstab entry as documented in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#assembly_persistently-mounting-file-systems_managing-file-systems">Persistently mounting file systems</a>. For example:
					</p><pre class="screen">/dev/disk/by-id/da875760-edb9-4b82-99dc-5f4b1ff2e5f4  /mount/point  xfs  defaults  0 0</pre></li><li class="listitem">
						Add <code class="literal">x-systemd.automount</code> to the options field of entry created in the previous step.
					</li><li class="listitem"><p class="simpara">
						Load newly created units so that your system registers the new configuration:
					</p><pre class="screen"># systemctl daemon-reload</pre></li><li class="listitem"><p class="simpara">
						Start the automount unit:
					</p><pre class="screen"># systemctl start <span class="emphasis"><em>mount-point.automount</em></span></pre></li></ol></div><div class="orderedlist"><p class="title"><strong>Verification</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Check that <code class="literal"><span class="emphasis"><em>mount-point.automount</em></span></code> is running:
					</p><pre class="screen"># systemctl status <span class="emphasis"><em>mount-point.automount</em></span></pre></li><li class="listitem"><p class="simpara">
						Check that automounted directory has desired content:
					</p><pre class="screen"># ls <span class="emphasis"><em>/mount/point</em></span></pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">systemd.automount(5)</code> and <code class="literal">systemd.mount(5)</code> man pages on your system
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_basic_system_settings/managing-systemd_configuring-basic-system-settings#doc-wrapper">Managing systemd</a>
					</li></ul></div></section><section class="section" id="proc_using-systemd-automount-to-mount-a-file-system-on-demand-with-a-mount-unit_mounting-file-systems-on-demand"><div class="titlepage"><div><div><h3 class="title">19.8. Using systemd.automount to mount a file system on-demand with a mount unit</h3></div></div></div><p class="_abstract _abstract">
				Mount a file system on-demand using the automount systemd units when mount point is defined by a mount unit. You have to add an automount unit for each mount and enable it.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Create a mount unit. For example:
					</p><pre class="screen">mount-point.mount
[Mount]
What=<span class="emphasis"><em>/dev/disk/by-uuid/f5755511-a714-44c1-a123-cfde0e4ac688</em></span>
Where=<span class="emphasis"><em>/mount/point</em></span>
Type=<span class="emphasis"><em>xfs</em></span></pre></li><li class="listitem">
						Create a unit file with the same name as the mount unit, but with extension <code class="literal">.automount</code>.
					</li><li class="listitem"><p class="simpara">
						Open the file and create an <code class="literal">[Automount]</code> section. Set the <code class="literal">Where=</code> option to the mount path:
					</p><pre class="screen">[Automount]
Where=<span class="emphasis"><em>/mount/point</em></span>
[Install]
WantedBy=multi-user.target</pre></li><li class="listitem"><p class="simpara">
						Load newly created units so that your system registers the new configuration:
					</p><pre class="screen"># systemctl daemon-reload</pre></li><li class="listitem"><p class="simpara">
						Enable and start the automount unit instead:
					</p><pre class="screen"># systemctl enable --now <span class="emphasis"><em>mount-point.automount</em></span></pre></li></ol></div><div class="orderedlist"><p class="title"><strong>Verification</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Check that <code class="literal"><span class="emphasis"><em>mount-point.automount</em></span></code> is running:
					</p><pre class="screen"># systemctl status <span class="emphasis"><em>mount-point.automount</em></span></pre></li><li class="listitem"><p class="simpara">
						Check that automounted directory has desired content:
					</p><pre class="screen"># ls <span class="emphasis"><em>/mount/point</em></span></pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">systemd.automount(5)</code> and <code class="literal">systemd.mount(5)</code> man pages on your system
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_basic_system_settings/managing-systemd_configuring-basic-system-settings">Managing systemd</a>
					</li></ul></div></section></section><section class="chapter" id="using-sssd-component-from-idm-to-cache-the-autofs-map_managing-file-systems"><div class="titlepage"><div><div><h2 class="title">Chapter 20. Using SSSD component from IdM to cache the autofs maps</h2></div></div></div><p class="_abstract _abstract">
			The System Security Services Daemon (SSSD) is a system service to access remote service directories and authentication mechanisms. The data caching is useful in case of the slow network connection. To configure the SSSD service to cache the autofs map, follow the procedures below in this section.
		</p><section class="section" id="configuring-autofs-manually-to-use-sssd-and-idm_using-sssd-component-from-idm-to-cache-the-autofs-map"><div class="titlepage"><div><div><h3 class="title">20.1. Configuring autofs manually to use IdM server as an LDAP server</h3></div></div></div><p class="_abstract _abstract">
				Configure <code class="literal">autofs</code> to use IdM server as an LDAP server.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Edit the <code class="literal">/etc/autofs.conf</code> file to specify the schema attributes that <code class="literal">autofs</code> searches for:
					</p><pre class="literallayout">#
# Other common LDAP naming
#
map_object_class = "automountMap"
entry_object_class = "automount"
map_attribute = "automountMapName"
entry_attribute = "automountKey"
value_attribute = "automountInformation"</pre><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
							User can write the attributes in both lower and upper cases in the <code class="literal">/etc/autofs.conf</code> file.
						</p></div></rh-alert></li><li class="listitem"><p class="simpara">
						Optional: Specify the LDAP configuration. There are two ways to do this. The simplest is to let the automount service discover the LDAP server and locations on its own:
					</p><pre class="literallayout">ldap_uri = "ldap:///dc=example,dc=com"</pre><p class="simpara">
						<span class="emphasis"><em>This option requires DNS to contain SRV records for the discoverable servers.</em></span>
					</p><p class="simpara">
						Alternatively, explicitly set which LDAP server to use and the base DN for LDAP searches:
					</p><pre class="literallayout">ldap_uri = "ldap://ipa.example.com"
search_base = "cn=<span class="emphasis"><em>location</em></span>,cn=automount,dc=example,dc=com"</pre></li><li class="listitem"><p class="simpara">
						Edit the <code class="literal">/etc/autofs_ldap_auth.conf</code> file so that autofs allows client authentication with the IdM LDAP server.
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								Change <code class="literal">authrequired</code> to yes.
							</li><li class="listitem"><p class="simpara">
								Set the principal to the Kerberos host principal for the IdM LDAP server, <span class="emphasis"><em>host/FQDN@REALM</em></span>. The principal name is used to connect to the IdM directory as part of GSS client authentication.
							</p><pre class="literallayout">&lt;autofs_ldap_sasl_conf
     usetls="no"
     tlsrequired="no"
     authrequired="yes"
     authtype="GSSAPI"
     clientprinc="host/server.example.com@EXAMPLE.COM"
     /&gt;</pre><p class="simpara">
								For more information about host principal, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/working_with_dns_in_identity_management/using-canonicalized-dns-host-names-in-idm_working-with-dns-in-identity-management">Using canonicalized DNS host names in IdM</a>.
							</p><p class="simpara">
								If necessary, run <code class="literal command">klist -k</code> to get the exact host principal information.
							</p></li></ul></div></li></ol></div></section><section class="section" id="configuring-sssd-to-cache-autofs-map_using-sssd-component-from-idm-to-cache-the-autofs-map"><div class="titlepage"><div><div><h3 class="title">20.2. Configuring SSSD to cache autofs maps</h3></div></div></div><p class="_abstract _abstract">
				The SSSD service can be used to cache <code class="literal">autofs</code> maps stored on an IdM server without having to configure <code class="literal">autofs</code> to use the IdM server at all.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						The <code class="literal package">sssd</code> package is installed.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Open the SSSD configuration file:
					</p><pre class="literallayout"># vim /etc/sssd/sssd.conf</pre></li><li class="listitem"><p class="simpara">
						Add the <code class="literal">autofs</code> service to the list of services handled by SSSD.
					</p><pre class="literallayout">[sssd]
domains = ldap
services = nss,pam,<code class="literal">autofs</code></pre></li><li class="listitem"><p class="simpara">
						Create a new <code class="literal">[autofs]</code> section. You can leave this blank, because the default settings for an <code class="literal">autofs</code> service work with most infrastructures.
					</p><pre class="literallayout">[nss]

[pam]

[sudo]

<code class="literal">[autofs]</code>

[ssh]

[pac]</pre><p class="simpara">
						For more information, see the <code class="literal">sssd.conf</code> man page on your system.
					</p></li><li class="listitem"><p class="simpara">
						Optional: Set a search base for the <code class="literal">autofs</code> entries. By default, this is the LDAP search base, but a subtree can be specified in the <code class="literal">ldap_autofs_search_base</code> parameter.
					</p><pre class="literallayout">[domain/EXAMPLE]

ldap_search_base = "dc=example,dc=com"
ldap_autofs_search_base = "ou=automount,dc=example,dc=com"</pre></li><li class="listitem"><p class="simpara">
						Restart SSSD service:
					</p><pre class="literallayout"># systemctl restart sssd.service</pre></li><li class="listitem"><p class="simpara">
						Check the <code class="literal">/etc/nsswitch.conf</code> file, so that SSSD is listed as a source for automount configuration:
					</p><pre class="literallayout">automount: <code class="literal">sss</code> files</pre></li><li class="listitem"><p class="simpara">
						Restart <code class="literal">autofs</code> service:
					</p><pre class="literallayout"># systemctl restart autofs.service</pre></li><li class="listitem"><p class="simpara">
						Test the configuration by listing a user’s <code class="literal">/home</code> directory, assuming there is a master map entry for <code class="literal">/home</code>:
					</p><pre class="literallayout"># ls /home/<span class="emphasis"><em>userName</em></span></pre><p class="simpara">
						If this does not mount the remote file system, check the <code class="literal">/var/log/messages</code> file for errors. If necessary, increase the debug level in the <code class="literal">/etc/sysconfig/autofs</code> file by setting the <code class="literal">logging</code> parameter to <code class="literal">debug</code>.
					</p></li></ol></div></section></section><section class="chapter" id="setting-read-only-permissions-for-the-root-file-system_managing-file-systems"><div class="titlepage"><div><div><h2 class="title">Chapter 21. Setting read-only permissions for the root file system</h2></div></div></div><p class="_abstract _abstract">
			Sometimes, you need to mount the root file system (<code class="literal filename">/</code>) with read-only permissions. Example use cases include enhancing security or ensuring data integrity after an unexpected system power-off.
		</p><section class="section" id="files-and-directories-that-always-retain-write-permissions_setting-read-only-permissions-for-the-root-file-system"><div class="titlepage"><div><div><h3 class="title">21.1. Files and directories that always retain write permissions</h3></div></div></div><p class="_abstract _abstract">
				For the system to function properly, some files and directories need to retain write permissions. When the root file system is mounted in read-only mode, these files are mounted in RAM using the <code class="literal">tmpfs</code> temporary file system.
			</p><p>
				The default set of such files and directories is read from the <code class="literal filename">/etc/rwtab</code> file. Note that the <code class="literal">readonly-root</code> package is required to have this file present in your system.
			</p><pre class="screen">dirs	/var/cache/man
dirs	/var/gdm
<span class="emphasis"><em>&lt;content truncated&gt;</em></span>

empty	/tmp
empty	/var/cache/foomatic
<span class="emphasis"><em>&lt;content truncated&gt;</em></span>

files	/etc/adjtime
files	/etc/ntp.conf
<span class="emphasis"><em>&lt;content truncated&gt;</em></span></pre><p>
				Entries in the <code class="literal filename">/etc/rwtab</code> file follow this format:
			</p><pre class="screen"><span class="emphasis"><em><span class="replaceable replaceable">copy-method</span></em></span>    <span class="emphasis"><em><span class="replaceable replaceable">path</span></em></span></pre><p>
				In this syntax:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Replace <span class="emphasis"><em><span class="replaceable replaceable">copy-method</span></em></span> with one of the keywords specifying how the file or directory is copied to tmpfs.
					</li><li class="listitem">
						Replace <span class="emphasis"><em><span class="replaceable replaceable">path</span></em></span> with the path to the file or directory.
					</li></ul></div><p>
				The <code class="literal filename">/etc/rwtab</code> file recognizes the following ways in which a file or directory can be copied to <code class="literal">tmpfs</code>:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">empty</code></span></dt><dd><p class="simpara">
							An empty path is copied to <code class="literal">tmpfs</code>. For example:
						</p><pre class="screen">empty /tmp</pre></dd><dt><span class="term"><code class="literal">dirs</code></span></dt><dd><p class="simpara">
							A directory tree is copied to <code class="literal">tmpfs</code>, empty. For example:
						</p><pre class="screen">dirs /var/run</pre></dd><dt><span class="term"><code class="literal">files</code></span></dt><dd><p class="simpara">
							A file or a directory tree is copied to <code class="literal">tmpfs</code> intact. For example:
						</p><pre class="screen">files /etc/resolv.conf</pre></dd></dl></div><p>
				The same format applies when adding custom paths to <code class="literal filename">/etc/rwtab.d/</code>.
			</p></section><section class="section" id="configuring-the-root-file-system-to-mount-with-read-only-permissions-on-boot_setting-read-only-permissions-for-the-root-file-system"><div class="titlepage"><div><div><h3 class="title">21.2. Configuring the root file system to mount with read-only permissions on boot</h3></div></div></div><p class="_abstract _abstract">
				With this procedure, the root file system is mounted read-only on all following boots.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						In the <code class="literal filename">/etc/sysconfig/readonly-root</code> file, set the <code class="literal option">READONLY</code> option to <code class="literal">yes</code> to mount the file systems as read-only:
					</p><pre class="screen">READONLY=yes</pre></li><li class="listitem"><p class="simpara">
						Add the <code class="literal option">ro</code> option in the root entry (<code class="literal filename">/</code>) in the <code class="literal filename">/etc/fstab</code> file:
					</p><pre class="screen">/dev/mapper/luks-c376919e...  /  xfs  x-systemd.device-timeout=0,<span class="strong strong"><strong>ro</strong></span>  1  1</pre></li><li class="listitem"><p class="simpara">
						Enable the <code class="literal option">ro</code> kernel option:
					</p><pre class="screen"># grubby --update-kernel=ALL --args="ro"</pre></li><li class="listitem"><p class="simpara">
						Ensure that the <code class="literal option">rw</code> kernel option is disabled:
					</p><pre class="screen"># grubby --update-kernel=ALL --remove-args="rw"</pre></li><li class="listitem"><p class="simpara">
						If you need to add files and directories to be mounted with write permissions in the <code class="literal">tmpfs</code> file system, create a text file in the <code class="literal filename">/etc/rwtab.d/</code> directory and put the configuration there.
					</p><p class="simpara">
						For example, to mount the <code class="literal filename">/etc/example/file</code> file with write permissions, add this line to the <code class="literal filename">/etc/rwtab.d/example</code> file:
					</p><pre class="screen">files /etc/example/file</pre><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
							Changes made to files and directories in <code class="literal">tmpfs</code> do not persist across boots.
						</p></div></rh-alert></li><li class="listitem">
						Reboot the system to apply the changes.
					</li></ol></div><div class="itemizedlist"><p class="title"><strong>Troubleshooting</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						If you mount the root file system with read-only permissions by mistake, you can remount it with read-and-write permissions again using the following command:
					</p><pre class="screen"># mount -o remount,rw /</pre></li></ul></div></section></section><section class="chapter" id="assembly_limiting-storage-space-usage-on-xfs-with-quotas_managing-file-systems"><div class="titlepage"><div><div><h2 class="title">Chapter 22. Limiting storage space usage on XFS with quotas</h2></div></div></div><p class="_abstract _abstract">
			You can restrict the amount of disk space available to users or groups by implementing disk quotas. You can also define a warning level at which system administrators are informed before a user consumes too much disk space or a partition becomes full.
		</p><p>
			The XFS quota subsystem manages limits on disk space (blocks) and file (inode) usage. XFS quotas control or report on usage of these items on a user, group, or directory or project level. Group and project quotas are only mutually exclusive on older non-default XFS disk formats.
		</p><p>
			When managing on a per-directory or per-project basis, XFS manages the disk usage of directory hierarchies associated with a specific project.
		</p><section class="section" id="con_disk-quotas_assembly_limiting-storage-space-usage-on-xfs-with-quotas"><div class="titlepage"><div><div><h3 class="title">22.1. Disk quotas</h3></div></div></div><p class="_abstract _abstract">
				In most computing environments, disk space is not infinite. The quota subsystem provides a mechanism to control usage of disk space.
			</p><p>
				You can configure disk quotas for individual users as well as user groups on the local file systems. This makes it possible to manage the space allocated for user-specific files (such as email) separately from the space allocated to the projects that a user works on. The quota subsystem warns users when they exceed their allotted limit, but allows some extra space for current work (hard limit/soft limit).
			</p><p>
				If quotas are implemented, you need to check if the quotas are exceeded and make sure the quotas are accurate. If users repeatedly exceed their quotas or consistently reach their soft limits, a system administrator can either help the user determine how to use less disk space or increase the user’s disk quota.
			</p><p>
				You can set quotas to control:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						The number of consumed disk blocks.
					</li><li class="listitem">
						The number of inodes, which are data structures that contain information about files in UNIX file systems. Because inodes store file-related information, this allows control over the number of files that can be created.
					</li></ul></div></section><section class="section" id="the-xfs_quota-tool_assembly_limiting-storage-space-usage-on-xfs-with-quotas"><div class="titlepage"><div><div><h3 class="title">22.2. The <code class="literal">xfs_quota</code> tool</h3></div></div></div><p class="_abstract _abstract">
				You can use the <code class="literal">xfs_quota</code> tool to manage quotas on XFS file systems. In addition, you can use XFS file systems with limit enforcement turned off as an effective disk usage accounting system.
			</p><p>
				The XFS quota system differs from other file systems in a number of ways. Most importantly, XFS considers quota information as file system metadata and uses journaling to provide a higher level guarantee of consistency.
			</p><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">xfs_quota(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="file-system-quota-management-in-xfs_assembly_limiting-storage-space-usage-on-xfs-with-quotas"><div class="titlepage"><div><div><h3 class="title">22.3. File system quota management in XFS</h3></div></div></div><p class="_abstract _abstract">
				The XFS quota subsystem manages limits on disk space (blocks) and file (inode) usage. XFS quotas control or report on usage of these items on a user, group, or directory or project level. Group and project quotas are only mutually exclusive on older non-default XFS disk formats.
			</p><p>
				When managing on a per-directory or per-project basis, XFS manages the disk usage of directory hierarchies associated with a specific project.
			</p></section><section class="section" id="enabling-disk-quotas-for-xfs_assembly_limiting-storage-space-usage-on-xfs-with-quotas"><div class="titlepage"><div><div><h3 class="title">22.4. Enabling disk quotas for XFS</h3></div></div></div><p class="_abstract _abstract">
				Enable disk quotas for users, groups, and projects on an XFS file system. Once quotas are enabled, the <code class="literal">xfs_quota</code> tool can be used to set limits and report on disk usage.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Enable quotas for users:
					</p><pre class="screen"># mount -o uquota /dev/xvdb1 /xfs</pre><p class="simpara">
						Replace <code class="literal">uquota</code> with <code class="literal">uqnoenforce</code> to allow usage reporting without enforcing any limits.
					</p></li><li class="listitem"><p class="simpara">
						Enable quotas for groups:
					</p><pre class="screen"># mount -o gquota /dev/xvdb1 /xfs</pre><p class="simpara">
						Replace <code class="literal">gquota</code> with <code class="literal">gqnoenforce</code> to allow usage reporting without enforcing any limits.
					</p></li><li class="listitem"><p class="simpara">
						Enable quotas for projects:
					</p><pre class="screen"># mount -o pquota /dev/xvdb1 /xfs</pre><p class="simpara">
						Replace <code class="literal">pquota</code> with <code class="literal">pqnoenforce</code> to allow usage reporting without enforcing any limits.
					</p></li><li class="listitem"><p class="simpara">
						Alternatively, include the quota mount options in the <code class="literal">/etc/fstab</code> file. The following example shows entries in the <code class="literal">/etc/fstab</code> file to enable quotas for users, groups, and projects, respectively, on an XFS file system. These examples also mount the file system with read/write permissions:
					</p><pre class="screen"># vim /etc/fstab
/dev/xvdb1    /xfs    xfs    rw,quota       0  0
/dev/xvdb1    /xfs    xfs    rw,gquota      0  0
/dev/xvdb1    /xfs    xfs    rw,prjquota    0  0</pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">mount(8)</code> and <code class="literal">xfs_quota(8)</code> man pages on your system
					</li></ul></div></section><section class="section" id="running-the-xfs_quota-tool_assembly_limiting-storage-space-usage-on-xfs-with-quotas"><div class="titlepage"><div><div><h3 class="title">22.5. Reporting XFS usage</h3></div></div></div><p class="_abstract _abstract">
				Use the <code class="literal">xfs_quota</code> tool to set limits and report on disk usage. By default, <code class="literal">xfs_quota</code> is run interactively, and in basic mode. Basic mode subcommands simply report usage, and are available to all users.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Quotas have been enabled for the XFS file system. See <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#enabling-disk-quotas-for-xfs_assembly_limiting-storage-space-usage-on-xfs-with-quotas">Enabling disk quotas for XFS</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Start the <code class="literal">xfs_quota</code> shell:
					</p><pre class="screen"># xfs_quota</pre></li><li class="listitem"><p class="simpara">
						Show usage and limits for the given user:
					</p><pre class="screen"># xfs_quota&gt; quota <span class="emphasis"><em>username</em></span></pre></li><li class="listitem"><p class="simpara">
						Show free and used counts for blocks and inodes:
					</p><pre class="screen"># xfs_quota&gt; df</pre></li><li class="listitem"><p class="simpara">
						Run the help command to display the basic commands available with <code class="literal">xfs_quota</code>.
					</p><pre class="screen"># xfs_quota&gt; help</pre></li><li class="listitem"><p class="simpara">
						Specify <code class="literal">q</code> to exit <code class="literal">xfs_quota</code>.
					</p><pre class="screen"># xfs_quota&gt; q</pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">xfs_quota(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="running-the-xfs_quota-tool-in-expert-mode_assembly_limiting-storage-space-usage-on-xfs-with-quotas"><div class="titlepage"><div><div><h3 class="title">22.6. Modifying XFS quota limits</h3></div></div></div><p class="_abstract _abstract">
				Start the <code class="literal">xfs_quota</code> tool with the <code class="literal">-x</code> option to enable expert mode and run the administrator commands, which allow modifications to the quota system. The subcommands of this mode allow actual configuration of limits, and are available only to users with elevated privileges.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Quotas have been enabled for the XFS file system. See <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#enabling-disk-quotas-for-xfs_assembly_limiting-storage-space-usage-on-xfs-with-quotas">Enabling disk quotas for XFS</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Start the <code class="literal">xfs_quota</code> shell with the <code class="literal">-x</code> option to enable expert mode:
					</p><pre class="screen"># xfs_quota -x</pre></li><li class="listitem"><p class="simpara">
						Report quota information for a specific file system:
					</p><pre class="screen"># xfs_quota&gt; report /<span class="emphasis"><em>path</em></span></pre><p class="simpara">
						For example, to display a sample quota report for <code class="literal">/home</code> (on <code class="literal">/dev/blockdevice</code>), use the command <code class="literal">report -h /home</code>. This displays output similar to the following:
					</p><pre class="screen">User quota on /home (/dev/blockdevice)
Blocks
User ID      Used   Soft   Hard Warn/Grace
---------- ---------------------------------
root            0      0      0  00 [------]
testuser   103.4G      0      0  00 [------]</pre></li><li class="listitem"><p class="simpara">
						Modify quota limits:
					</p><pre class="screen"># xfs_quota&gt; limit isoft=<span class="emphasis"><em>500m</em></span> ihard=<span class="emphasis"><em>700m</em></span> <span class="emphasis"><em>user</em></span> /<span class="emphasis"><em>path</em></span></pre><p class="simpara">
						For example, to set a soft and hard inode count limit of 500 and 700 respectively for user <code class="literal">john</code>, whose home directory is <code class="literal">/home/john</code>, use the following command:
					</p><pre class="screen"># xfs_quota -x -c 'limit isoft=500 ihard=700 john' /home/</pre><p class="simpara">
						In this case, pass <code class="literal">mount_point</code> which is the mounted xfs file system.
					</p></li><li class="listitem"><p class="simpara">
						Run the help command to display the expert commands available with <code class="literal">xfs_quota -x</code>:
					</p><pre class="screen"># xfs_quota&gt; help</pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">xfs_quota(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="setting-project-limits-for-xfs_assembly_limiting-storage-space-usage-on-xfs-with-quotas"><div class="titlepage"><div><div><h3 class="title">22.7. Setting project limits for XFS</h3></div></div></div><p class="_abstract _abstract">
				Configure limits for project-controlled directories.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Add the project-controlled directories to <code class="literal">/etc/projects</code>. For example, the following adds the <code class="literal">/var/log</code> path with a unique ID of 11 to <code class="literal">/etc/projects</code>. Your project ID can be any numerical value mapped to your project.
					</p><pre class="screen"># echo 11:/var/log &gt;&gt; /etc/projects</pre></li><li class="listitem"><p class="simpara">
						Add project names to <code class="literal">/etc/projid</code> to map project IDs to project names. For example, the following associates a project called <code class="literal">logfiles</code> with the project ID of 11 as defined in the previous step.
					</p><pre class="screen"># echo logfiles:11 &gt;&gt; /etc/projid</pre></li><li class="listitem"><p class="simpara">
						Initialize the project directory. For example, the following initializes the project directory <code class="literal">/var</code>:
					</p><pre class="screen"># xfs_quota -x -c 'project -s logfiles' /var</pre></li><li class="listitem"><p class="simpara">
						Configure quotas for projects with initialized directories:
					</p><pre class="screen"># xfs_quota -x -c 'limit -p bhard=1g logfiles' /var</pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">xfs_quota(8)</code>, <code class="literal">projid(5)</code>, and <code class="literal">projects(5)</code> man pages on your system
					</li></ul></div></section></section><section class="chapter" id="limiting-storage-space-usage-on-ext4-with-quotas_managing-file-systems"><div class="titlepage"><div><div><h2 class="title">Chapter 23. Limiting storage space usage on ext4 with quotas</h2></div></div></div><p>
			You have to enable disk quotas on your system before you can assign them. You can assign disk quotas per user, per group or per project. However, if there is a soft limit set, you can exceed these quotas for a configurable period of time, known as the grace period.
		</p><section class="section" id="installing-quota-rpm_limiting-storage-space-usage-on-ext4-with-quotas"><div class="titlepage"><div><div><h3 class="title">23.1. Installing the quota tool</h3></div></div></div><p class="_abstract _abstract">
				You must install the <code class="literal">quota</code> RPM package to implement disk quotas.
			</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Install the <code class="literal">quota</code> package:
					</p><pre class="screen"># dnf install quota</pre></li></ul></div></section><section class="section" id="enabling-quota-feature-in-file-system-creation_limiting-storage-space-usage-on-ext4-with-quotas"><div class="titlepage"><div><div><h3 class="title">23.2. Enabling quota feature on file system creation</h3></div></div></div><p class="_abstract _abstract">
				Enable quotas on file system creation.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Enable quotas on file system creation:
					</p><pre class="screen"># mkfs.ext4 -O quota /dev/sda</pre><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
							Only user and group quotas are enabled and initialized by default.
						</p></div></rh-alert></li><li class="listitem"><p class="simpara">
						Change the defaults on file system creation:
					</p><pre class="screen"># mkfs.ext4 -O quota -E quotatype=usrquota:grpquota:prjquota /dev/sda</pre></li><li class="listitem"><p class="simpara">
						Mount the file system:
					</p><pre class="screen"># mount /dev/sda</pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">ext4(5)</code> man page on your system.
					</li></ul></div></section><section class="section" id="enabling-quota-feature-on-existing-file-system_limiting-storage-space-usage-on-ext4-with-quotas"><div class="titlepage"><div><div><h3 class="title">23.3. Enabling quota feature on existing file systems</h3></div></div></div><p class="_abstract _abstract">
				Enable the quota feature on existing file system by using the <code class="literal">tune2fs</code> command.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Unmount the file system:
					</p><pre class="screen"># umount /dev/sda</pre></li><li class="listitem"><p class="simpara">
						Enable quotas on existing file system:
					</p><pre class="screen"># tune2fs -O quota /dev/sda</pre><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
							Only user and group quotas are initialized by default.
						</p></div></rh-alert></li><li class="listitem"><p class="simpara">
						Change the defaults:
					</p><pre class="screen"># tune2fs -Q usrquota,grpquota,prjquota /dev/sda</pre></li><li class="listitem"><p class="simpara">
						Mount the file system:
					</p><pre class="screen"># mount /dev/sda</pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">ext4(5)</code> man page on your system.
					</li></ul></div></section><section class="section" id="enabling-quota-enforcement_limiting-storage-space-usage-on-ext4-with-quotas"><div class="titlepage"><div><div><h3 class="title">23.4. Enabling quota enforcement</h3></div></div></div><p class="_abstract _abstract">
				The quota accounting is enabled by default after mounting the file system without any additional options, but quota enforcement is not.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Quota feature is enabled and the default quotas are initialized.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Enable quota enforcement by <code class="literal">quotaon</code> for the user quota:
					</p><pre class="screen"># mount /dev/sda /mnt</pre><pre class="screen"># quotaon /mnt</pre><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
							The quota enforcement can be enabled at mount time using <code class="literal">usrquota</code>, <code class="literal">grpquota</code>, or <code class="literal">prjquota</code> mount options.
						</p><pre class="screen"># mount -o usrquota,grpquota,prjquota /dev/sda /mnt</pre></div></rh-alert></li><li class="listitem"><p class="simpara">
						Enable user, group, and project quotas for all file systems:
					</p><pre class="screen"># quotaon -vaugP</pre><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
								If neither of the <code class="literal">-u</code>, <code class="literal">-g</code>, or <code class="literal">-P</code> options are specified, only the user quotas are enabled.
							</li><li class="listitem">
								If only <code class="literal">-g</code> option is specified, only group quotas are enabled.
							</li><li class="listitem">
								If only <code class="literal">-P</code> option is specified, only project quotas are enabled.
							</li></ul></div></li><li class="listitem"><p class="simpara">
						Enable quotas for a specific file system, such as <code class="literal">/home</code>:
					</p><pre class="screen"># quotaon -vugP /home</pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">quotaon(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="assigning-quotas-per-user_limiting-storage-space-usage-on-ext4-with-quotas"><div class="titlepage"><div><div><h3 class="title">23.5. Assigning quotas per user</h3></div></div></div><p class="_abstract _abstract">
				The disk quotas are assigned to users with the <code class="literal">edquota</code> command.
			</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					The text editor defined by the <code class="literal">EDITOR</code> environment variable is used by <code class="literal">edquota</code>. To change the editor, set the <code class="literal">EDITOR</code> environment variable in your <code class="literal">~/.bash_profile</code> file to the full path of the editor of your choice.
				</p></div></rh-alert><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						User must exist prior to setting the user quota.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Assign the quota for a user:
					</p><pre class="screen"># edquota <span class="emphasis"><em>username</em></span></pre><p class="simpara">
						Replace <span class="emphasis"><em>username</em></span> with the user to which you want to assign the quotas.
					</p><p class="simpara">
						For example, if you enable a quota for the <code class="literal">/dev/sda</code> partition and execute the command <code class="literal">edquota testuser</code>, the following is displayed in the default editor configured on the system:
					</p><pre class="literallayout">Disk quotas for user testuser (uid 501):
Filesystem   blocks   soft   hard   inodes   soft   hard
/dev/sda      44043      0      0    37418      0      0</pre></li><li class="listitem"><p class="simpara">
						Change the desired limits.
					</p><p class="simpara">
						If any of the values are set to 0, limit is not set. Change them in the text editor.
					</p><p class="simpara">
						For example, the following shows the soft and hard block limits for the testuser have been set to 50000 and 55000 respectively.
					</p><pre class="screen">Disk quotas for user testuser (uid 501):
Filesystem   blocks   soft   hard   inodes   soft   hard
/dev/sda      44043  50000  55000    37418      0      0</pre><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								The first column is the name of the file system that has a quota enabled for it.
							</li><li class="listitem">
								The second column shows how many blocks the user is currently using.
							</li><li class="listitem">
								The next two columns are used to set soft and hard block limits for the user on the file system.
							</li><li class="listitem">
								The <code class="literal">inodes</code> column shows how many inodes the user is currently using.
							</li><li class="listitem"><p class="simpara">
								The last two columns are used to set the soft and hard inode limits for the user on the file system.
							</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
										The hard block limit is the absolute maximum amount of disk space that a user or group can use. Once this limit is reached, no further disk space can be used.
									</li><li class="listitem">
										The soft block limit defines the maximum amount of disk space that can be used. However, unlike the hard limit, the soft limit can be exceeded for a certain amount of time. That time is known as the <span class="emphasis"><em>grace period</em></span>. The grace period can be expressed in seconds, minutes, hours, days, weeks, or months.
									</li></ul></div></li></ul></div></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Verify that the quota for the user has been set:
					</p><pre class="literallayout"># quota -v testuser
Disk quotas for user testuser:
Filesystem  blocks  quota  limit  grace  files  quota  limit  grace
/dev/sda      1000*  1000   1000             0      0      0</pre></li></ul></div></section><section class="section" id="assigning-quotas-per-group_limiting-storage-space-usage-on-ext4-with-quotas"><div class="titlepage"><div><div><h3 class="title">23.6. Assigning quotas per group</h3></div></div></div><p class="_abstract _abstract">
				You can assign quotas on a per-group basis.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Group must exist prior to setting the group quota.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Set a group quota:
					</p><pre class="screen"># edquota -g <span class="emphasis"><em>groupname</em></span></pre><p class="simpara">
						For example, to set a group quota for the <code class="literal">devel</code> group:
					</p><pre class="screen"># edquota -g devel</pre><p class="simpara">
						This command displays the existing quota for the group in the text editor:
					</p><pre class="screen">Disk quotas for group devel (gid 505):
Filesystem   blocks  soft  hard  inodes  soft  hard
/dev/sda     440400     0     0   37418     0     0</pre></li><li class="listitem">
						Modify the limits and save the file.
					</li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Verify that the group quota is set:
					</p><pre class="screen"># quota -vg <span class="emphasis"><em>groupname</em></span></pre></li></ul></div></section><section class="section" id="assigning-quotas-per-project_limiting-storage-space-usage-on-ext4-with-quotas"><div class="titlepage"><div><div><h3 class="title">23.7. Assigning quotas per project</h3></div></div></div><p class="_abstract _abstract">
				You can assign quotas per project.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Project quota is enabled on your file system.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Add the project-controlled directories to <code class="literal">/etc/projects</code>. For example, the following adds the <code class="literal">/var/log</code> path with a unique ID of 11 to <code class="literal">/etc/projects</code>. Your project ID can be any numerical value mapped to your project.
					</p><pre class="screen"># echo 11:/var/log &gt;&gt; /etc/projects</pre></li><li class="listitem"><p class="simpara">
						Add project names to <code class="literal">/etc/projid</code> to map project IDs to project names. For example, the following associates a project called <code class="literal">Logs</code> with the project ID of 11 as defined in the previous step.
					</p><pre class="screen"># echo Logs:11 &gt;&gt; /etc/projid</pre></li><li class="listitem"><p class="simpara">
						Set the desired limits:
					</p><pre class="screen"># edquota -P 11</pre><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
							You can choose the project either by its project ID (<code class="literal">11</code> in this case), or by its name (<code class="literal">Logs</code> in this case).
						</p></div></rh-alert></li><li class="listitem"><p class="simpara">
						Using <code class="literal">quotaon</code>, enable quota enforcement:
					</p><p class="simpara">
						See <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_file_systems/limiting-storage-space-usage-on-ext4-with-quotas_managing-file-systems#enabling-quota-enforcement_limiting-storage-space-usage-on-ext4-with-quotas">Enabling quota enforcement</a>.
					</p></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Verify that the project quota is set:
					</p><pre class="screen"># quota -vP 11</pre><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
							You can verify either by the project ID, or by the project name.
						</p></div></rh-alert></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">edquota(8)</code>, <code class="literal">projid(5)</code>, and <code class="literal">projects(5)</code> man pages on your system
					</li></ul></div></section><section class="section" id="setting-the-grace-period-for-soft-limits_limiting-storage-space-usage-on-ext4-with-quotas"><div class="titlepage"><div><div><h3 class="title">23.8. Setting the grace period for soft limits</h3></div></div></div><p class="_abstract _abstract">
				If a given quota has soft limits, you can edit the grace period, which is the amount of time for which a soft limit can be exceeded. You can set the grace period for users, groups, or projects.
			</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Edit the grace period:
					</p><pre class="literallayout"># edquota -t</pre></li></ul></div><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
					While other <code class="literal">edquota</code> commands operate on quotas for a particular user, group, or project, the <code class="literal">-t</code> option operates on every file system with quotas enabled.
				</p></div></rh-alert><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">edquota(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="turning-file-system-quotas-off_limiting-storage-space-usage-on-ext4-with-quotas"><div class="titlepage"><div><div><h3 class="title">23.9. Turning file system quotas off</h3></div></div></div><p class="_abstract _abstract">
				Use <code class="literal">quotaoff</code> to turn disk quota enforcement off on the specified file systems. Quota accounting stays enabled after executing this command.
			</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						To turn all user and group quotas off:
					</p><pre class="screen"># quotaoff -vaugP</pre><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
								If neither of the <code class="literal">-u</code>, <code class="literal">-g</code>, or <code class="literal">-P</code> options are specified, only the user quotas are disabled.
							</li><li class="listitem">
								If only <code class="literal">-g</code> option is specified, only group quotas are disabled.
							</li><li class="listitem">
								If only <code class="literal">-P</code> option is specified, only project quotas are disabled.
							</li><li class="listitem">
								The <code class="literal">-v</code> switch causes verbose status information to display as the command executes.
							</li></ul></div></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">quotaoff(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="reporting-on-disk-quotas_limiting-storage-space-usage-on-ext4-with-quotas"><div class="titlepage"><div><div><h3 class="title">23.10. Reporting on disk quotas</h3></div></div></div><p>
				Create a disk quota report by using the <code class="literal">repquota</code> utility.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Run the <code class="literal">repquota</code> command:
					</p><pre class="screen"># repquota</pre><p class="simpara">
						For example, the command <code class="literal">repquota /dev/sda</code> produces this output:
					</p><pre class="literallayout">*** Report for user quotas on device /dev/sda
Block grace time: 7days; Inode grace time: 7days
			Block limits			File limits
User		used	soft	hard	grace	used	soft	hard	grace
----------------------------------------------------------------------
root      --      36       0       0              4     0     0
kristin   --     540       0       0            125     0     0
testuser  --  440400  500000  550000          37418     0     0</pre></li><li class="listitem"><p class="simpara">
						View the disk usage report for all quota-enabled file systems:
					</p><pre class="literallayout"># repquota -augP</pre></li></ol></div><p>
				The <code class="literal">--</code> symbol displayed after each user determines whether the block or inode limits have been exceeded. If either soft limit is exceeded, a <code class="literal">+</code> character appears in place of the corresponding <code class="literal">-</code> character. The first <code class="literal">-</code> character represents the block limit, and the second represents the inode limit.
			</p><p>
				The <code class="literal">grace</code> columns are normally blank. If a soft limit has been exceeded, the column contains a time specification equal to the amount of time remaining on the grace period. If the grace period has expired, <code class="literal">none</code> appears in its place.
			</p><div class="_additional-resources _additional-resources"><p class="title"><strong>Additional resources</strong></p><p>
					The <code class="literal">repquota(8)</code> man page for more information.
				</p></div></section></section><section class="chapter" id="discarding-unused-blocks_managing-file-systems"><div class="titlepage"><div><div><h2 class="title">Chapter 24. Discarding unused blocks</h2></div></div></div><p class="_abstract _abstract">
			You can perform or schedule discard operations on block devices that support them. The block discard operation communicates to the underlying storage which filesystem blocks are no longer in use by the mounted filesystem. Block discard operations allow SSDs to optimize garbage collection routines, and they can inform thinly-provisioned storage to repurpose unused physical blocks.
		</p><h4 id="requirements">Requirements</h4><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
					The block device underlying the file system must support physical discard operations.
				</p><p class="simpara">
					Physical discard operations are supported if the value in the <code class="literal filename">/sys/block/<span class="emphasis"><em><span class="replaceable replaceable">&lt;device&gt;</span></em></span>/queue/discard_max_bytes</code> file is not zero.
				</p></li></ul></div><section class="section" id="types-of-block-discard-operations_discarding-unused-blocks"><div class="titlepage"><div><div><h3 class="title">24.1. Types of block discard operations</h3></div></div></div><p class="_abstract _abstract">
				You can run discard operations using different methods:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">Batch discard</span></dt><dd>
							Is triggered explicitly by the user and discards all unused blocks in the selected file systems.
						</dd><dt><span class="term">Online discard</span></dt><dd>
							Is specified at mount time and triggers in real time without user intervention. Online discard operations discard only blocks that are transitioning from the <code class="literal">used</code> to the <code class="literal">free</code> state.
						</dd><dt><span class="term">Periodic discard</span></dt><dd>
							Are batch operations that are run regularly by a <code class="literal">systemd</code> service.
						</dd></dl></div><p>
				All types are supported by the XFS and ext4 file systems.
			</p><h5 id="recommendations_2">Recommendations</h5><p>
				Red Hat recommends that you use batch or periodic discard.
			</p><p>
				Use online discard only if:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						the system’s workload is such that batch discard is not feasible, or
					</li><li class="listitem">
						online discard operations are necessary to maintain performance.
					</li></ul></div></section><section class="section" id="performing-batch-block-discard_discarding-unused-blocks"><div class="titlepage"><div><div><h3 class="title">24.2. Performing batch block discard</h3></div></div></div><p class="_abstract _abstract">
				You can perform a batch block discard operation to discard unused blocks on a mounted file system.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						The file system is mounted.
					</li><li class="listitem">
						The block device underlying the file system supports physical discard operations.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Use the <code class="literal">fstrim</code> utility:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem"><p class="simpara">
								To perform discard only on a selected file system, use:
							</p><pre class="screen"># fstrim <span class="emphasis"><em><span class="replaceable replaceable">mount-point</span></em></span></pre></li><li class="listitem"><p class="simpara">
								To perform discard on all mounted file systems, use:
							</p><pre class="screen"># fstrim --all</pre></li></ul></div></li></ul></div><p>
				If you execute the <code class="literal">fstrim</code> command on:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						a device that does not support discard operations, or
					</li><li class="listitem">
						a logical device (LVM or MD) composed of multiple devices, where any one of the device does not support discard operations,
					</li></ul></div><p>
				the following message displays:
			</p><pre class="screen"># fstrim <span class="emphasis"><em><span class="replaceable replaceable">/mnt/non_discard</span></em></span>

fstrim: <span class="emphasis"><em><span class="replaceable replaceable">/mnt/non_discard</span></em></span>: the discard operation is not supported</pre><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">fstrim(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="enabling-online-block-discard_discarding-unused-blocks"><div class="titlepage"><div><div><h3 class="title">24.3. Enabling online block discard</h3></div></div></div><p class="_abstract _abstract">
				You can perform online block discard operations to automatically discard unused blocks on all supported file systems.
			</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Enable online discard at mount time:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem"><p class="simpara">
								When mounting a file system manually, add the <code class="literal option">-o discard</code> mount option:
							</p><pre class="screen"># mount -o discard <span class="emphasis"><em><span class="replaceable replaceable">device</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">mount-point</span></em></span></pre></li><li class="listitem">
								When mounting a file system persistently, add the <code class="literal option">discard</code> option to the mount entry in the <code class="literal filename">/etc/fstab</code> file.
							</li></ul></div></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">mount(8)</code> and <code class="literal">fstab(5)</code> man pages on your system
					</li></ul></div></section><section class="section" id="enabling-periodic-block-discard_discarding-unused-blocks"><div class="titlepage"><div><div><h3 class="title">24.4. Enabling periodic block discard</h3></div></div></div><p class="_abstract _abstract">
				You can enable a <code class="literal">systemd</code> timer to regularly discard unused blocks on all supported file systems.
			</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Enable and start the <code class="literal">systemd</code> timer:
					</p><pre class="screen"># <span class="strong strong"><strong>systemctl enable --now fstrim.timer</strong></span>
Created symlink /etc/systemd/system/timers.target.wants/fstrim.timer → /usr/lib/systemd/system/fstrim.timer.</pre></li></ul></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Verify the status of the timer:
					</p><pre class="screen"># <span class="strong strong"><strong>systemctl status fstrim.timer</strong></span>
fstrim.timer - Discard unused blocks once a week
   Loaded: loaded (/usr/lib/systemd/system/fstrim.timer; enabled; vendor preset: disabled)
   Active: active (waiting) since Wed 2023-05-17 13:24:41 CEST; 3min 15s ago
  Trigger: Mon 2023-05-22 01:20:46 CEST; 4 days left
     Docs: man:fstrim

May 17 13:24:41 localhost.localdomain systemd[1]: Started Discard unused blocks once a week.</pre></li></ul></div></section></section><section class="chapter" id="setting-up-stratis-file-systems_managing-file-systems"><div class="titlepage"><div><div><h2 class="title">Chapter 25. Setting up Stratis file systems</h2></div></div></div><p>
			Stratis runs as a service to manage pools of physical storage devices, simplifying local storage management with ease of use while helping you set up and manage complex storage configurations.
		</p><section class="section" id="the-purpose-and-features-of-stratis_setting-up-stratis-file-systems"><div class="titlepage"><div><div><h3 class="title">25.1. What is Stratis</h3></div></div></div><p class="_abstract _abstract">
				Stratis is a local storage-management solution for Linux. It is focused on simplicity and ease of use, and gives you access to advanced storage features.
			</p><p>
				Stratis makes the following activities easier:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Initial configuration of storage
					</li><li class="listitem">
						Making changes later
					</li><li class="listitem">
						Using advanced storage features
					</li></ul></div><p>
				Stratis is a local storage management system that supports advanced storage features. The central concept of Stratis is a storage <span class="emphasis"><em>pool</em></span>. This pool is created from one or more local disks or partitions, and file systems are created from the pool.
			</p><p>
				The pool enables many useful features, such as:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						File system snapshots
					</li><li class="listitem">
						Thin provisioning
					</li><li class="listitem">
						Tiering
					</li><li class="listitem">
						Encryption
					</li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="https://stratis-storage.github.io/">Stratis website</a>
					</li></ul></div></section><section class="section" id="components-of-a-stratis-volume_setting-up-stratis-file-systems"><div class="titlepage"><div><div><h3 class="title">25.2. Components of a Stratis volume</h3></div></div></div><p class="_abstract _abstract">
				Learn about the components that comprise a Stratis volume.
			</p><p>
				Externally, Stratis presents the following volume components in the command-line interface and the API:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">blockdev</code></span></dt><dd>
							Block devices, such as a disk or a disk partition.
						</dd><dt><span class="term"><code class="literal">pool</code></span></dt><dd><p class="simpara">
							Composed of one or more block devices.
						</p><p class="simpara">
							A pool has a fixed total size, equal to the size of the block devices.
						</p><p class="simpara">
							The pool contains most Stratis layers, such as the non-volatile data cache using the <code class="literal">dm-cache</code> target.
						</p><p class="simpara">
							Stratis creates a <code class="literal filename">/dev/stratis/<span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span>/</code> directory for each pool. This directory contains links to devices that represent Stratis file systems in the pool.
						</p></dd></dl></div><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">filesystem</code></span></dt><dd><p class="simpara">
							Each pool can contain one or more file systems, which store files.
						</p><p class="simpara">
							File systems are thinly provisioned and do not have a fixed total size. The actual size of a file system grows with the data stored on it. If the size of the data approaches the virtual size of the file system, Stratis grows the thin volume and the file system automatically.
						</p><p class="simpara">
							The file systems are formatted with XFS.
						</p><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
								Stratis tracks information about file systems created using Stratis that XFS is not aware of, and changes made using XFS do not automatically create updates in Stratis. Users must not reformat or reconfigure XFS file systems that are managed by Stratis.
							</p></div></rh-alert><p class="simpara">
							Stratis creates links to file systems at the <code class="literal filename">/dev/stratis/<span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span>/<span class="emphasis"><em><span class="replaceable replaceable">my-fs</span></em></span></code> path.
						</p></dd></dl></div><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					Stratis uses many Device Mapper devices, which show up in <code class="literal">dmsetup</code> listings and the <code class="literal filename">/proc/partitions</code> file. Similarly, the <code class="literal">lsblk</code> command output reflects the internal workings and layers of Stratis.
				</p></div></rh-alert></section><section class="section" id="block-devices-usable-with-stratis_setting-up-stratis-file-systems"><div class="titlepage"><div><div><h3 class="title">25.3. Block devices usable with Stratis</h3></div></div></div><p class="_abstract _abstract">
				Storage devices that can be used with Stratis.
			</p><h5 id="supported_devices">Supported devices</h5><p>
				Stratis pools have been tested to work on these types of block devices:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						LUKS
					</li><li class="listitem">
						LVM logical volumes
					</li><li class="listitem">
						MD RAID
					</li><li class="listitem">
						DM Multipath
					</li><li class="listitem">
						iSCSI
					</li><li class="listitem">
						HDDs and SSDs
					</li><li class="listitem">
						NVMe devices
					</li></ul></div><h5 id="unsupported_devices">Unsupported devices</h5><p>
				Because Stratis contains a thin-provisioning layer, Red Hat does not recommend placing a Stratis pool on block devices that are already thinly-provisioned.
			</p></section><section class="section" id="installing-stratis_setting-up-stratis-file-systems"><div class="titlepage"><div><div><h3 class="title">25.4. Installing Stratis</h3></div></div></div><p class="_abstract _abstract">
				Install the required packages for Stratis.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Install packages that provide the Stratis service and command-line utilities:
					</p><pre class="screen"># dnf install stratisd stratis-cli</pre></li><li class="listitem"><p class="simpara">
						Verify that the <code class="literal">stratisd</code> service is enabled:
					</p><pre class="screen"># systemctl enable --now stratisd</pre></li></ol></div></section><section class="section" id="create-unencrypted-stratis-pool_setting-up-stratis-file-systems"><div class="titlepage"><div><div><h3 class="title">25.5. Creating an unencrypted Stratis pool</h3></div></div></div><p class="_abstract _abstract">
				You can create an unencrypted Stratis pool from one or more block devices.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Stratis is installed. For more information, see <a class="link" href="#installing-stratis_setting-up-stratis-file-systems" title="25.4. Installing Stratis">Installing Stratis</a>.
					</li><li class="listitem">
						The <code class="literal">stratisd</code> service is running.
					</li><li class="listitem">
						The block devices on which you are creating a Stratis pool are not in use and are not mounted.
					</li><li class="listitem">
						Each block device on which you are creating a Stratis pool is at least 1 GB.
					</li><li class="listitem">
						On the IBM Z architecture, the <code class="literal">/dev/dasd*</code> block devices must be partitioned. Use the partition device for creating the Stratis pool.
					</li></ul></div><p>
				For information about partitioning DASD devices, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html-single/interactively_installing_rhel_over_the_network/index#configuring-a-linux-instance-on-ibm-z_preparing-a-rhel-installation-on-64-bit-ibm-z">Configuring a Linux instance on IBM Z</a>
			</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					You cannot encrypt an unencrypted Stratis pool.
				</p></div></rh-alert><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Erase any file system, partition table, or RAID signatures that exist on each block device that you want to use in the Stratis pool:
					</p><pre class="screen"># wipefs --all <span class="emphasis"><em><span class="replaceable replaceable">block-device</span></em></span></pre><p class="simpara">
						where <code class="literal replaceable"><span class="emphasis"><em>block-device</em></span></code> is the path to the block device; for example, <code class="literal">/dev/sdb</code>.
					</p></li><li class="listitem"><p class="simpara">
						Create the new unencrypted Stratis pool on the selected block device:
					</p><pre class="screen"># stratis pool create <span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">block-device</span></em></span></pre><p class="simpara">
						where <code class="literal replaceable"><span class="emphasis"><em>block-device</em></span></code> is the path to an empty or wiped block device.
					</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
							Specify multiple block devices on a single line:
						</p><pre class="screen"># stratis pool create <span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">block-device-1</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">block-device-2</span></em></span></pre></div></rh-alert></li><li class="listitem"><p class="simpara">
						Verify that the new Stratis pool was created:
					</p><pre class="screen"># stratis pool list</pre></li></ol></div></section><section class="section" id="creating-an-unencrypted-stratis-pool-using-the-web-console_setting-up-stratis-file-systems"><div class="titlepage"><div><div><h3 class="title">25.6. Creating an unencrypted Stratis pool by using the web console</h3></div></div></div><p class="_abstract _abstract">
				You can use the web console to create an unencrypted Stratis pool from one or more block devices.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						You have installed the RHEL 9 web console.
					</p><p class="simpara">
						For instructions, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console">Installing and enabling the web console</a>.
					</p></li><li class="listitem">
						The <code class="literal">stratisd</code> service is running.
					</li><li class="listitem">
						The block devices on which you are creating a Stratis pool are not in use and are not mounted.
					</li><li class="listitem">
						Each block device on which you are creating a Stratis pool is at least 1 GB.
					</li></ul></div><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					You cannot encrypt an unencrypted Stratis pool after it is created.
				</p></div></rh-alert><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Log in to the RHEL 9 web console.
					</p><p class="simpara">
						For details, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#logging-in-to-the-web-console_getting-started-with-the-rhel-9-web-console">Logging in to the web console</a>.
					</p></li><li class="listitem">
						Click <span class="guibutton">Storage</span>.
					</li><li class="listitem">
						In the <span class="strong strong"><strong>Storage</strong></span> table, click the menu button.
					</li><li class="listitem"><p class="simpara">
						From the drop-down menu, select <span class="strong strong"><strong>Create Stratis pool</strong></span>.
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/90ecf9cb494b94831c8f73565fe7be13/cockpit-adding-volume-groups-create-stratis.png" alt="Image displaying the available options in the Storage table drop-down menu. Selecting Create Stratis pool."></span>

					</p></li><li class="listitem"><p class="simpara">
						In the <span class="strong strong"><strong>Create Stratis pool</strong></span> dialog box, enter a name for the Stratis pool.
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/f436feb6682e0d109368415b13426e87/cockpit-create-stratis-pool.png" alt="Image displaying the Create Stratis pool dialog box."></span>

					</p></li><li class="listitem">
						Select the <span class="strong strong"><strong>Block devices</strong></span> from which you want to create the Stratis pool.
					</li><li class="listitem">
						Optional: If you want to specify the maximum size for each file system that is created in pool, select <span class="strong strong"><strong>Manage filesystem sizes</strong></span>.
					</li><li class="listitem">
						Click <span class="guibutton">Create</span>.
					</li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Go to the <span class="strong strong"><strong>Storage</strong></span> section and verify that you can see the new Stratis pool in the <span class="strong strong"><strong>Devices</strong></span> table.
					</li></ul></div></section><section class="section" id="create-encrypted-stratis-pool_setting-up-stratis-file-systems"><div class="titlepage"><div><div><h3 class="title">25.7. Creating an encrypted Stratis pool</h3></div></div></div><p class="_abstract _abstract">
				To secure your data, you can create an encrypted Stratis pool from one or more block devices.
			</p><p>
				When you create an encrypted Stratis pool, the kernel keyring is used as the primary encryption mechanism. After subsequent system reboots this kernel keyring is used to unlock the encrypted Stratis pool.
			</p><p>
				When creating an encrypted Stratis pool from one or more block devices, note the following:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Each block device is encrypted using the <code class="literal">cryptsetup</code> library and implements the <code class="literal">LUKS2</code> format.
					</li><li class="listitem">
						Each Stratis pool can either have a unique key or share the same key with other pools. These keys are stored in the kernel keyring.
					</li><li class="listitem">
						The block devices that comprise a Stratis pool must be either all encrypted or all unencrypted. It is not possible to have both encrypted and unencrypted block devices in the same Stratis pool.
					</li><li class="listitem">
						Block devices added to the data tier of an encrypted Stratis pool are automatically encrypted.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Stratis v2.1.0 or later is installed. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems">Installing Stratis</a>.
					</li><li class="listitem">
						The <code class="literal">stratisd</code> service is running.
					</li><li class="listitem">
						The block devices on which you are creating a Stratis pool are not in use and are not mounted.
					</li><li class="listitem">
						The block devices on which you are creating a Stratis pool are at least 1GB in size each.
					</li><li class="listitem">
						On the IBM Z architecture, the <code class="literal">/dev/dasd*</code> block devices must be partitioned. Use the partition in the Stratis pool.
					</li></ul></div><p>
				For information about partitioning DASD devices, see link:<a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html-single/interactively_installing_rhel_over_the_network/index#configuring-a-linux-instance-on-ibm-z_preparing-a-rhel-installation-on-64-bit-ibm-z">Configuring a Linux instance on IBM Z</a>.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Erase any file system, partition table, or RAID signatures that exist on each block device that you want to use in the Stratis pool:
					</p><pre class="screen"># wipefs --all <span class="emphasis"><em><span class="replaceable replaceable">block-device</span></em></span></pre><p class="simpara">
						where <code class="literal replaceable"><span class="emphasis"><em>block-device</em></span></code> is the path to the block device; for example, <code class="literal">/dev/sdb</code>.
					</p></li><li class="listitem"><p class="simpara">
						If you have not created a key set already, run the following command and follow the prompts to create a key set to use for the encryption.
					</p><pre class="screen"># stratis key set --capture-key <span class="emphasis"><em><span class="replaceable replaceable">key-description</span></em></span></pre><p class="simpara">
						where <code class="literal replaceable"><span class="emphasis"><em>key-description</em></span></code> is a reference to the key that gets created in the kernel keyring.
					</p></li><li class="listitem"><p class="simpara">
						Create the encrypted Stratis pool and specify the key description to use for the encryption. You can also specify the key path using the <code class="literal">--keyfile-path</code> option instead of using the <code class="literal replaceable"><span class="emphasis"><em>key-description</em></span></code> option.
					</p><pre class="screen"># stratis pool create --key-desc <span class="emphasis"><em><span class="replaceable replaceable">key-description</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">block-device</span></em></span></pre><p class="simpara">
						where
					</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal"><span class="emphasis"><em>key-description</em></span></code></span></dt><dd>
									References the key that exists in the kernel keyring, which you created in the previous step.
								</dd><dt><span class="term"><code class="literal"><span class="emphasis"><em>my-pool</em></span></code></span></dt><dd>
									Specifies the name of the new Stratis pool.
								</dd><dt><span class="term"><code class="literal"><span class="emphasis"><em>block-device</em></span></code></span></dt><dd><p class="simpara">
									Specifies the path to an empty or wiped block device.
								</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
										Specify multiple block devices on a single line:
									</p><pre class="screen"># stratis pool create --key-desc <span class="emphasis"><em><span class="replaceable replaceable">key-description</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">block-device-1</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">block-device-2</span></em></span></pre></div></rh-alert></dd></dl></div></li><li class="listitem"><p class="simpara">
						Verify that the new Stratis pool was created:
					</p><pre class="screen"># stratis pool list</pre></li></ol></div></section><section class="section" id="creating-an-encrypted-stratis-pool-using-the-web-console_setting-up-stratis-file-systems"><div class="titlepage"><div><div><h3 class="title">25.8. Creating an encrypted Stratis pool by using the web console</h3></div></div></div><p class="_abstract _abstract">
				To secure your data, you can use the web console to create an encrypted Stratis pool from one or more block devices.
			</p><p>
				When creating an encrypted Stratis pool from one or more block devices, note the following:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Each block device is encrypted using the cryptsetup library and implements the LUKS2 format.
					</li><li class="listitem">
						Each Stratis pool can either have a unique key or share the same key with other pools. These keys are stored in the kernel keyring.
					</li><li class="listitem">
						The block devices that comprise a Stratis pool must be either all encrypted or all unencrypted. It is not possible to have both encrypted and unencrypted block devices in the same Stratis pool.
					</li><li class="listitem">
						Block devices added to the data tier of an encrypted Stratis pool are automatically encrypted.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						You have installed the RHEL 9 web console.
					</p><p class="simpara">
						For instructions, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console">Installing and enabling the web console</a>.
					</p></li><li class="listitem">
						Stratis v2.1.0 or later is installed.
					</li><li class="listitem">
						The <code class="literal">stratisd</code> service is running.
					</li><li class="listitem">
						The block devices on which you are creating a Stratis pool are not in use and are not mounted.
					</li><li class="listitem">
						Each block device on which you are creating a Stratis pool is at least 1 GB.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Log in to the RHEL 9 web console.
					</p><p class="simpara">
						For details, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#logging-in-to-the-web-console_getting-started-with-the-rhel-9-web-console">Logging in to the web console</a>.
					</p></li><li class="listitem">
						Click <span class="guibutton">Storage</span>.
					</li><li class="listitem">
						In the <span class="strong strong"><strong>Storage</strong></span> table, click the menu button.
					</li><li class="listitem">
						From the drop-down menu, select <span class="strong strong"><strong>Create Stratis pool</strong></span>.
						<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/90ecf9cb494b94831c8f73565fe7be13/cockpit-adding-volume-groups-create-stratis.png" alt="Image displaying the available options in the Storage table drop-down menu. Selecting Create Stratis pool."></span>

					</li><li class="listitem"><p class="simpara">
						In the <span class="strong strong"><strong>Create Stratis pool</strong></span> dialog box, enter a name for the Stratis pool.
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/f436feb6682e0d109368415b13426e87/cockpit-create-stratis-pool.png" alt="Image displaying the Create Stratis pool dialog box."></span>

					</p></li><li class="listitem">
						Select the <span class="strong strong"><strong>Block devices</strong></span> from which you want to create the Stratis pool.
					</li><li class="listitem"><p class="simpara">
						Select the type of encryption, you can use a passphrase, a Tang keyserver, or both:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								Passphrase:
							</p><div class="orderedlist"><ol class="orderedlist" type="i"><li class="listitem">
										Enter a passphrase.
									</li><li class="listitem">
										Confirm the passphrase
									</li></ol></div></li><li class="listitem"><p class="simpara">
								Tang keyserver:
							</p><div class="orderedlist"><ol class="orderedlist" type="i"><li class="listitem">
										Enter the keyserver address. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/security_hardening/configuring-automated-unlocking-of-encrypted-volumes-using-policy-based-decryption_security-hardening#deploying-a-tang-server-with-selinux-in-enforcing-mode_configuring-automated-unlocking-of-encrypted-volumes-using-policy-based-decryption">Deploying a Tang server with SELinux in enforcing mode</a>.
									</li></ol></div></li></ul></div></li><li class="listitem">
						Optional: If you want to specify the maximum size for each file system that is created in pool, select <span class="strong strong"><strong>Manage filesystem sizes</strong></span>.
					</li><li class="listitem">
						Click <span class="guibutton">Create</span>.
					</li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Go to the <span class="strong strong"><strong>Storage</strong></span> section and verify that you can see the new Stratis pool in the <span class="strong strong"><strong>Devices</strong></span> table.
					</li></ul></div></section><section class="section" id="renaming-a-stratis-pool-using-the-web-console_setting-up-stratis-file-systems"><div class="titlepage"><div><div><h3 class="title">25.9. Renaming a Stratis pool by using the web console</h3></div></div></div><p class="_abstract _abstract">
				You can use the web console to rename an existing Stratis pool.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						You have installed the RHEL 9 web console.
					</p><p class="simpara">
						For instructions, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console">Installing and enabling the web console</a>.
					</p></li><li class="listitem"><p class="simpara">
						Stratis is installed.
					</p><p class="simpara">
						The web console detects and installs Stratis by default. However, for manually installing Stratis, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems">Installing Stratis</a>.
					</p></li><li class="listitem">
						The <code class="literal">stratisd</code> service is running.
					</li><li class="listitem">
						A Stratis pool is created.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem">
						Log in to the RHEL 9 web console.
					</li><li class="listitem">
						Click <span class="guibutton">Storage</span>.
					</li><li class="listitem">
						In the <span class="strong strong"><strong>Storage</strong></span> table, click the Stratis pool you want to rename.
					</li><li class="listitem"><p class="simpara">
						On the <span class="strong strong"><strong>Stratis pool</strong></span> page, click <span class="guibutton">edit</span> next to the <span class="strong strong"><strong>Name</strong></span> field.
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/7cbbd0667e9e4dad03191e3a1bd46614/cockpit-view-stratis-pool.png" alt="Image displaying the Stratis pool page."></span>

					</p></li><li class="listitem">
						In the <span class="strong strong"><strong>Rename Stratis pool</strong></span> dialog box, enter a new name.
					</li><li class="listitem">
						Click <span class="guibutton">Rename</span>.
					</li></ol></div></section><section class="section" id="proc_setting-overprovisioning-mode-in-stratis-fs_setting-up-stratis-file-systems"><div class="titlepage"><div><div><h3 class="title">25.10. Setting overprovisioning mode in Stratis filesystem</h3></div></div></div><p>
				A storage stack can reach a state of overprovision. If the file system size becomes bigger than the pool backing it, the pool becomes full. To prevent this, disable overprovisioning, which ensures that the size of all filesystems on the pool does not exceed the available physical storage provided by the pool. If you use Stratis for critical applications or the root filesystem, this mode prevents certain failure cases.
			</p><p>
				If you enable overprovisioning, an API signal notifies you when your storage has been fully allocated. The notification serves as a warning to the user to inform them that when all the remaining pool space fills up, Stratis has no space left to extend to.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Stratis is installed. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems">Installing Stratis</a>.
					</li></ul></div><div class="formalpara"><p class="title"><strong>Procedure</strong></p><p>
					To set up the pool correctly, you have two possibilities:
				</p></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Create a pool from one or more block devices:
					</p><pre class="screen"># stratis pool create --no-overprovision <span class="emphasis"><em>pool-name</em></span> <span class="emphasis"><em>/dev/sdb</em></span></pre><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								By using the <code class="literal">--no-overprovision</code> option, the pool cannot allocate more logical space than actual available physical space.
							</li></ul></div></li><li class="listitem"><p class="simpara">
						Set overprovisioning mode in the existing pool:
					</p><pre class="screen"># stratis pool overprovision <span class="emphasis"><em>pool-name</em></span> &lt;yes|no&gt;</pre><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								If set to "yes", you enable overprovisioning to the pool. This means that the sum of the logical sizes of the Stratis filesystems, supported by the pool, can exceed the amount of available data space.
							</li></ul></div></li></ol></div><div class="orderedlist"><p class="title"><strong>Verification</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Run the following to view the full list of Stratis pools:
					</p><pre class="screen"># stratis pool list

Name          Total Physical                    Properties     UUID                                   Alerts
<span class="emphasis"><em>pool-name</em></span>     1.42 TiB / 23.96 MiB / 1.42 TiB   ~Ca,~Cr,~Op    cb7cb4d8-9322-4ac4-a6fd-eb7ae9e1e540</pre></li><li class="listitem">
						Check if there is an indication of the pool overprovisioning mode flag in the <code class="literal">stratis pool list</code> output. The " ~ " is a math symbol for "NOT", so <code class="literal">~Op</code> means no-overprovisioning.
					</li><li class="listitem"><p class="simpara">
						Optional: Run the following to check overprovisioning on a specific pool:
					</p><pre class="screen"># stratis pool overprovision <span class="emphasis"><em>pool-name</em></span> <span class="emphasis"><em>yes</em></span>

# stratis pool list

Name          Total Physical                    Properties     UUID                                   Alerts
<span class="emphasis"><em>pool-name</em></span>     1.42 TiB / 23.96 MiB / 1.42 TiB   ~Ca,~Cr,~Op    cb7cb4d8-9322-4ac4-a6fd-eb7ae9e1e540</pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="https://stratis-storage.github.io/">The <span class="emphasis"><em>Stratis Storage</em></span> webpage</a>.
					</li></ul></div></section><section class="section" id="bind-stratis-pool-nbde_setting-up-stratis-file-systems"><div class="titlepage"><div><div><h3 class="title">25.11. Binding a Stratis pool to NBDE</h3></div></div></div><p class="_abstract _abstract">
				Binding an encrypted Stratis pool to Network Bound Disk Encryption (NBDE) requires a Tang server. When a system containing the Stratis pool reboots, it connects with the Tang server to automatically unlock the encrypted pool without you having to provide the kernel keyring description.
			</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					Binding a Stratis pool to a supplementary Clevis encryption mechanism does not remove the primary kernel keyring encryption.
				</p></div></rh-alert><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Stratis v2.3.0 or later is installed. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems">Installing Stratis</a>.
					</li><li class="listitem">
						The <code class="literal">stratisd</code> service is running.
					</li><li class="listitem">
						You have created an encrypted Stratis pool, and you have the key description of the key that was used for the encryption. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#create-encrypted-stratis-pool_setting-up-stratis-file-systems">Creating an encrypted Stratis pool</a>.
					</li><li class="listitem">
						You can connect to the Tang server. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/security_hardening/configuring-automated-unlocking-of-encrypted-volumes-using-policy-based-decryption_security-hardening#deploying-a-tang-server-with-selinux-in-enforcing-mode_configuring-automated-unlocking-of-encrypted-volumes-using-policy-based-decryption">Deploying a Tang server with SELinux in enforcing mode</a>
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Bind an encrypted Stratis pool to NBDE:
					</p><pre class="screen"># stratis pool bind nbde --trust-url <span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">tang-server</span></em></span></pre><p class="simpara">
						where
					</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal"><span class="emphasis"><em>my-pool</em></span></code></span></dt><dd>
									Specifies the name of the encrypted Stratis pool.
								</dd><dt><span class="term"><code class="literal"><span class="emphasis"><em>tang-server</em></span></code></span></dt><dd>
									Specifies the IP address or URL of the Tang server.
								</dd></dl></div></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/security_hardening/configuring-automated-unlocking-of-encrypted-volumes-using-policy-based-decryption_security-hardening">Configuring automated unlocking of encrypted volumes using policy-based decryption</a>
					</li></ul></div></section><section class="section" id="bind-stratis-pool-tpm_setting-up-stratis-file-systems"><div class="titlepage"><div><div><h3 class="title">25.12. Binding a Stratis pool to TPM</h3></div></div></div><p class="_abstract _abstract">
				When you bind an encrypted Stratis pool to the Trusted Platform Module (TPM) 2.0, the system containing the pool reboots, and the pool is automatically unlocked without you having to provide the kernel keyring description.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Stratis v2.3.0 or later is installed. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems">Installing Stratis</a>.
					</li><li class="listitem">
						The <code class="literal">stratisd</code> service is running.
					</li><li class="listitem">
						You have created an encrypted Stratis pool. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#create-encrypted-stratis-pool_setting-up-stratis-file-systems">Creating an encrypted Stratis pool</a>.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Bind an encrypted Stratis pool to TPM:
					</p><pre class="screen"># stratis pool bind tpm <span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">key-description</span></em></span></pre><p class="simpara">
						where
					</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal"><span class="emphasis"><em>my-pool</em></span></code></span></dt><dd>
									Specifies the name of the encrypted Stratis pool.
								</dd><dt><span class="term"><code class="literal"><span class="emphasis"><em>key-description</em></span></code></span></dt><dd>
									References the key that exists in the kernel keyring, which was generated when you created the encrypted Stratis pool.
								</dd></dl></div></li></ul></div></section><section class="section" id="unlock-encrypted-stratis-pool-keyring_setting-up-stratis-file-systems"><div class="titlepage"><div><div><h3 class="title">25.13. Unlocking an encrypted Stratis pool with kernel keyring</h3></div></div></div><p class="_abstract _abstract">
				After a system reboot, your encrypted Stratis pool or the block devices that comprise it might not be visible. You can unlock the pool using the kernel keyring that was used to encrypt the pool.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Stratis v2.1.0 is installed. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems">Installing Stratis</a>.
					</li><li class="listitem">
						The <code class="literal">stratisd</code> service is running.
					</li><li class="listitem">
						You have created an encrypted Stratis pool. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#create-encrypted-stratis-pool_setting-up-stratis-file-systems">Creating an encrypted Stratis pool</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Re-create the key set using the same key description that was used previously:
					</p><pre class="screen"># stratis key set --capture-key <span class="emphasis"><em><span class="replaceable replaceable">key-description</span></em></span></pre><p class="simpara">
						where <span class="emphasis"><em><span class="replaceable replaceable">key-description</span></em></span> references the key that exists in the kernel keyring, which was generated when you created the encrypted Stratis pool.
					</p></li><li class="listitem"><p class="simpara">
						Verify that the Stratis pool is visible:
					</p><pre class="screen"># stratis pool list</pre></li></ol></div></section><section class="section" id="unbind-encrypted-stratis-pool-from-supplementary-encryption_setting-up-stratis-file-systems"><div class="titlepage"><div><div><h3 class="title">25.14. Unbinding a Stratis pool from supplementary encryption</h3></div></div></div><p class="_abstract _abstract">
				When you unbind an encrypted Stratis pool from a supported supplementary encryption mechanism, the primary kernel keyring encryption remains in place. This is not true for pools that are created with Clevis encryption from the start.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Stratis v2.3.0 or later is installed on your system. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems">Installing Stratis</a>.
					</li><li class="listitem">
						You have created an encrypted Stratis pool. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#create-encrypted-stratis-pool_setting-up-stratis-file-systems">Creating an encrypted Stratis pool</a>.
					</li><li class="listitem">
						The encrypted Stratis pool is bound to a supported supplementary encryption mechanism.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Unbind an encrypted Stratis pool from a supplementary encryption mechanism:
					</p><pre class="screen"># stratis pool unbind clevis <span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span></pre><p class="simpara">
						where
					</p><p class="simpara">
						<code class="literal"><span class="emphasis"><em>my-pool</em></span></code> specifies the name of the Stratis pool you want to unbind.
					</p></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#bind-stratis-pool-nbde_setting-up-stratis-file-systems">Binding an encrypted Stratis pool to NBDE</a>
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#bind-stratis-pool-tpm_setting-up-stratis-file-systems">Binding an encrypted Stratis pool to TPM</a>
					</li></ul></div></section><section class="section" id="proc_starting-and-stopping-stratis-pool_setting-up-stratis-file-systems"><div class="titlepage"><div><div><h3 class="title">25.15. Starting and stopping Stratis pool</h3></div></div></div><p>
				You can start and stop Stratis pools. This gives you the option to dissasemble or bring down all the objects that were used to construct the pool, such as filesystems, cache devices, thin pool, and encrypted devices. Note that if the pool actively uses any device or filesystem, it might issue a warning and not be able to stop.
			</p><p>
				The stopped state is recorded in the pool’s metadata. These pools do not start on the following boot, until the pool receives a start command.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Stratis is installed. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems">Installing Stratis</a>.
					</li><li class="listitem">
						The <code class="literal">stratisd</code> service is running.
					</li><li class="listitem">
						You have created either an unencrypted or an encrypted Stratis pool. See <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#create-unencrypted-stratis-pool_setting-up-stratis-file-systems">Creating an unencrypted Stratis pool</a>
					</li></ul></div><p>
				or <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#create-encrypted-stratis-pool_setting-up-stratis-file-systems">Creating an encrypted Stratis pool</a>.
			</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Use the following command to start the Stratis pool. The <code class="literal">--unlock-method</code> option specifies the method of unlocking the pool if it is encrypted:
					</p><pre class="screen"># stratis pool start <span class="emphasis"><em>pool-uuid</em></span> --unlock-method &lt;keyring|clevis&gt;</pre></li><li class="listitem"><p class="simpara">
						Alternatively, use the following command to stop the Stratis pool. This tears down the storage stack but leaves all metadata intact:
					</p><pre class="screen"># stratis pool stop <span class="emphasis"><em>pool-name</em></span></pre></li></ul></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Use the following command to list all pools on the system:
					</p><pre class="screen"># stratis pool list</pre></li><li class="listitem"><p class="simpara">
						Use the following command to list all not previously started pools. If the UUID is specified, the command prints detailed information about the pool corresponding to the UUID:
					</p><pre class="screen"># stratis pool list --stopped --uuid <span class="emphasis"><em>UUID</em></span></pre></li></ul></div></section><section class="section" id="creating-a-stratis-file-system_setting-up-stratis-file-systems"><div class="titlepage"><div><div><h3 class="title">25.16. Creating a Stratis file system</h3></div></div></div><p class="_abstract _abstract">
				Create a Stratis file system on an existing Stratis pool.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Stratis is installed. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems">Installing Stratis</a>.
					</li><li class="listitem">
						The <code class="literal">stratisd</code> service is running.
					</li><li class="listitem">
						You have created a Stratis pool. See <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#create-unencrypted-stratis-pool_setting-up-stratis-file-systems">Creating an unencrypted Stratis pool</a>
					</li></ul></div><p>
				or <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#create-encrypted-stratis-pool_setting-up-stratis-file-systems">Creating an encrypted Stratis pool</a>.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						To create a Stratis file system on a pool, use:
					</p><pre class="screen"># stratis filesystem create --size <span class="emphasis"><em><span class="replaceable replaceable">number-and-unit</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">my-fs</span></em></span></pre><p class="simpara">
						where
					</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal"><span class="emphasis"><em>number-and-unit</em></span></code></span></dt><dd>
									Specifies the size of a file system. The specification format must follow the standard size specification format for input, that is B, KiB, MiB, GiB, TiB or PiB.
								</dd><dt><span class="term"><code class="literal"><span class="emphasis"><em>my-pool</em></span></code></span></dt><dd>
									Specifies the name of the Stratis pool.
								</dd><dt><span class="term"><code class="literal"><span class="emphasis"><em>my-fs</em></span></code></span></dt><dd><p class="simpara">
									Specifies an arbitrary name for the file system.
								</p><p class="simpara">
									For example:
								</p><div class="example" id="idm139822450275632"><p class="title"><strong>Example 25.1. Creating a Stratis file system</strong></p><div class="example-contents"><pre class="screen"># stratis filesystem create --size 10GiB pool1 filesystem1</pre></div></div></dd></dl></div></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						List file systems within the pool to check if the Stratis filesystem is created:
					</p><pre class="screen"># stratis fs list <span class="emphasis"><em>my-pool</em></span></pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/managing_file_systems/index#mounting-a-stratis-file-system_setting-up-stratis-file-systems">Mounting a Stratis file system</a>
					</li></ul></div></section><section class="section" id="creating-a-file-system-on-a-stratis-pool-using-the-web-console_setting-up-stratis-file-systems"><div class="titlepage"><div><div><h3 class="title">25.17. Creating a file system on a Stratis pool by using the web console</h3></div></div></div><p class="_abstract _abstract">
				You can use the web console to create a file system on an existing Stratis pool.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						You have installed the RHEL 9 web console.
					</p><p class="simpara">
						For instructions, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console">Installing and enabling the web console</a>.
					</p></li><li class="listitem">
						The <code class="literal">stratisd</code> service is running.
					</li><li class="listitem">
						A Stratis pool is created.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Log in to the RHEL 9 web console.
					</p><p class="simpara">
						For details, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#logging-in-to-the-web-console_getting-started-with-the-rhel-9-web-console">Logging in to the web console</a>.
					</p></li><li class="listitem">
						Click <span class="guibutton">Storage</span>.
					</li><li class="listitem">
						Click the Stratis pool on which you want to create a file system.
					</li><li class="listitem"><p class="simpara">
						On the <span class="strong strong"><strong>Stratis pool</strong></span> page, scroll to the <span class="strong strong"><strong>Stratis filesystems</strong></span> section and click <span class="guibutton">Create new filesystem</span>.
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/7cbbd0667e9e4dad03191e3a1bd46614/cockpit-view-stratis-pool.png" alt="Image displaying the Stratis pool page."></span>

					</p></li><li class="listitem"><p class="simpara">
						In the <span class="strong strong"><strong>Create filesystem</strong></span> dialog box, enter a <span class="strong strong"><strong>Name</strong></span> for the file system.
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/07fbccdba02bded4adc1d642baab4f53/cockpit-create-stratis-fs.png" alt="Image displaying the create Stratis file system dialog box."></span>

					</p></li><li class="listitem">
						Enter the <span class="strong strong"><strong>Mount point</strong></span> for the file system.
					</li><li class="listitem">
						Select the <span class="strong strong"><strong>Mount option</strong></span>.
					</li><li class="listitem">
						In the <span class="strong strong"><strong>At boot</strong></span> drop-down menu, select when you want to mount your file system.
					</li><li class="listitem"><p class="simpara">
						Create the file system:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								If you want to create and mount the file system, click <span class="guibutton">Create and mount</span>.
							</li><li class="listitem">
								If you want to only create the file system, click <span class="guibutton">Create only</span>.
							</li></ul></div></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						The new file system is visible on the <span class="strong strong"><strong>Stratis pool</strong></span> page under the <span class="strong strong"><strong>Stratis filesystems</strong></span> tab.
					</li></ul></div></section><section class="section" id="mounting-a-stratis-file-system_setting-up-stratis-file-systems"><div class="titlepage"><div><div><h3 class="title">25.18. Mounting a Stratis file system</h3></div></div></div><p class="_abstract _abstract">
				Mount an existing Stratis file system to access the content.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Stratis is installed. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems">Installing Stratis</a>.
					</li><li class="listitem">
						The <code class="literal">stratisd</code> service is running.
					</li><li class="listitem">
						You have created a Stratis file system. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#creating-a-stratis-file-system_setting-up-stratis-file-systems">Creating a Stratis filesystem</a>.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						To mount the file system, use the entries that Stratis maintains in the <code class="literal filename">/dev/stratis/</code> directory:
					</p><pre class="screen"># mount /dev/stratis/<span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span>/<span class="emphasis"><em><span class="replaceable replaceable">my-fs</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">mount-point</span></em></span></pre></li></ul></div><p>
				The file system is now mounted on the <span class="emphasis"><em><span class="replaceable replaceable">mount-point</span></em></span> directory and ready to use.
			</p><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#creating-a-stratis-file-system_setting-up-stratis-file-systems">Creating a Stratis file system</a>
					</li></ul></div></section><section class="section" id="persistently-mounting-a-stratis-file-system_setting-up-stratis-file-systems"><div class="titlepage"><div><div><h3 class="title">25.19. Persistently mounting a Stratis file system</h3></div></div></div><p class="_abstract _abstract">
				This procedure persistently mounts a Stratis file system so that it is available automatically after booting the system.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Stratis is installed. See <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems">Installing Stratis</a>.
					</li><li class="listitem">
						The <code class="literal">stratisd</code> service is running.
					</li><li class="listitem">
						You have created a Stratis file system. See <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#creating-a-stratis-file-system_setting-up-stratis-file-systems">Creating a Stratis filesystem</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Determine the UUID attribute of the file system:
					</p><pre class="screen">$ lsblk --output=UUID /dev/stratis/<span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span>/<span class="emphasis"><em><span class="replaceable replaceable">my-fs</span></em></span></pre><p class="simpara">
						For example:
					</p><div class="example" id="idm139822453439552"><p class="title"><strong>Example 25.2. Viewing the UUID of Stratis file system</strong></p><div class="example-contents"><pre class="screen">$ lsblk --output=UUID /dev/stratis/my-pool/fs1

UUID
a1f0b64a-4ebb-4d4e-9543-b1d79f600283</pre></div></div></li><li class="listitem"><p class="simpara">
						If the mount point directory does not exist, create it:
					</p><pre class="screen"># mkdir --parents <span class="emphasis"><em><span class="replaceable replaceable">mount-point</span></em></span></pre></li><li class="listitem"><p class="simpara">
						As root, edit the <code class="literal filename">/etc/fstab</code> file and add a line for the file system, identified by the UUID. Use <code class="literal">xfs</code> as the file system type and add the <code class="literal">x-systemd.requires=stratisd.service</code> option.
					</p><p class="simpara">
						For example:
					</p><div class="example" id="idm139822453432448"><p class="title"><strong>Example 25.3. The /fs1 mount point in /etc/fstab</strong></p><div class="example-contents"><pre class="screen">UUID=a1f0b64a-4ebb-4d4e-9543-b1d79f600283 /fs1 xfs defaults,x-systemd.requires=stratisd.service 0 0</pre></div></div></li><li class="listitem"><p class="simpara">
						Regenerate mount units so that your system registers the new configuration:
					</p><pre class="screen"># systemctl daemon-reload</pre></li><li class="listitem"><p class="simpara">
						Try mounting the file system to verify that the configuration works:
					</p><pre class="screen"># mount <span class="emphasis"><em><span class="replaceable replaceable">mount-point</span></em></span></pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_file_systems/assembly_persistently-mounting-file-systems_managing-file-systems">Persistently mounting file systems</a>
					</li></ul></div></section><section class="section" id="proc_setting-up-non-root-stratis-fs-fstab-systemd_setting-up-stratis-file-systems"><div class="titlepage"><div><div><h3 class="title">25.20. Setting up non-root Stratis filesystems in /etc/fstab using a systemd service</h3></div></div></div><p>
				You can manage setting up non-root filesystems in /etc/fstab using a systemd service.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Stratis is installed. See <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_file_systems/setting-up-stratis-file-systems_managing-file-systems#installing-stratis_setting-up-stratis-file-systems">Installing Stratis</a>.
					</li><li class="listitem">
						The <code class="literal">stratisd</code> service is running.
					</li><li class="listitem">
						You have created a Stratis file system. See <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_file_systems/setting-up-stratis-file-systems_managing-file-systems#creating-a-stratis-file-system_setting-up-stratis-file-systems">Creating a Stratis filesystem</a>.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						For all non-root Stratis filesystems, use:
					</p><pre class="screen"># /dev/stratis/<span class="emphasis"><em>[STRATIS_SYMLINK]</em></span> <span class="emphasis"><em>[MOUNT_POINT]</em></span> xfs defaults, x-systemd.requires=stratis-fstab-setup@<span class="emphasis"><em>[POOL_UUID]</em></span>.service,x-systemd.after=stratis-stab-setup@<span class="emphasis"><em>[POOL_UUID]</em></span>.service &lt;dump_value&gt; &lt;fsck_value&gt;</pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#assembly_persistently-mounting-file-systems_managing-file-systems">Persistently mounting file systems</a>
					</li></ul></div></section></section><section class="chapter" id="extending-a-stratis-volume-with-additional-block-devices_managing-file-systems"><div class="titlepage"><div><div><h2 class="title">Chapter 26. Extending a Stratis volume with additional block devices</h2></div></div></div><p>
			You can attach additional block devices to a Stratis pool to provide more storage capacity for Stratis file systems.
		</p><section class="section" id="components-of-a-stratis-volume_extending-a-stratis-volume-with-additional-block-devices"><div class="titlepage"><div><div><h3 class="title">26.1. Components of a Stratis volume</h3></div></div></div><p class="_abstract _abstract">
				Learn about the components that comprise a Stratis volume.
			</p><p>
				Externally, Stratis presents the following volume components in the command-line interface and the API:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">blockdev</code></span></dt><dd>
							Block devices, such as a disk or a disk partition.
						</dd><dt><span class="term"><code class="literal">pool</code></span></dt><dd><p class="simpara">
							Composed of one or more block devices.
						</p><p class="simpara">
							A pool has a fixed total size, equal to the size of the block devices.
						</p><p class="simpara">
							The pool contains most Stratis layers, such as the non-volatile data cache using the <code class="literal">dm-cache</code> target.
						</p><p class="simpara">
							Stratis creates a <code class="literal filename">/dev/stratis/<span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span>/</code> directory for each pool. This directory contains links to devices that represent Stratis file systems in the pool.
						</p></dd></dl></div><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">filesystem</code></span></dt><dd><p class="simpara">
							Each pool can contain one or more file systems, which store files.
						</p><p class="simpara">
							File systems are thinly provisioned and do not have a fixed total size. The actual size of a file system grows with the data stored on it. If the size of the data approaches the virtual size of the file system, Stratis grows the thin volume and the file system automatically.
						</p><p class="simpara">
							The file systems are formatted with XFS.
						</p><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
								Stratis tracks information about file systems created using Stratis that XFS is not aware of, and changes made using XFS do not automatically create updates in Stratis. Users must not reformat or reconfigure XFS file systems that are managed by Stratis.
							</p></div></rh-alert><p class="simpara">
							Stratis creates links to file systems at the <code class="literal filename">/dev/stratis/<span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span>/<span class="emphasis"><em><span class="replaceable replaceable">my-fs</span></em></span></code> path.
						</p></dd></dl></div><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					Stratis uses many Device Mapper devices, which show up in <code class="literal">dmsetup</code> listings and the <code class="literal filename">/proc/partitions</code> file. Similarly, the <code class="literal">lsblk</code> command output reflects the internal workings and layers of Stratis.
				</p></div></rh-alert></section><section class="section" id="adding-block-devices-to-a-stratis-pool_extending-a-stratis-volume-with-additional-block-devices"><div class="titlepage"><div><div><h3 class="title">26.2. Adding block devices to a Stratis pool</h3></div></div></div><p class="_abstract _abstract">
				This procedure adds one or more block devices to a Stratis pool to be usable by Stratis file systems.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Stratis is installed. See <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems">Installing Stratis</a>.
					</li><li class="listitem">
						The <code class="literal">stratisd</code> service is running.
					</li><li class="listitem">
						The block devices that you are adding to the Stratis pool are not in use and not mounted.
					</li><li class="listitem">
						The block devices that you are adding to the Stratis pool are at least 1 GiB in size each.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						To add one or more block devices to the pool, use:
					</p><pre class="screen"># stratis pool add-data <span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">device-1</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">device-2</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">device-n</span></em></span></pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">stratis(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="adding-a-block-device-to-a-stratis-pool-using-the-web-console_extending-a-stratis-volume-with-additional-block-devices"><div class="titlepage"><div><div><h3 class="title">26.3. Adding a block device to a Stratis pool by using the web console</h3></div></div></div><p class="_abstract _abstract">
				You can use the web console to add a block device to an existing Stratis pool. You can also add caches as a block device.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						You have installed the RHEL 9 web console.
					</p><p class="simpara">
						For instructions, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console">Installing and enabling the web console</a>.
					</p></li><li class="listitem">
						The <code class="literal">stratisd</code> service is running.
					</li><li class="listitem">
						A Stratis pool is created.
					</li><li class="listitem">
						The block devices on which you are creating a Stratis pool are not in use and are not mounted.
					</li><li class="listitem">
						Each block device on which you are creating a Stratis pool is at least 1 GB.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Log in to the RHEL 9 web console.
					</p><p class="simpara">
						For details, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#logging-in-to-the-web-console_getting-started-with-the-rhel-9-web-console">Logging in to the web console</a>.
					</p></li><li class="listitem">
						Click <span class="guibutton">Storage</span>.
					</li><li class="listitem">
						In the <span class="strong strong"><strong>Storage</strong></span> table, click the Stratis pool to which you want to add a block device.
					</li><li class="listitem"><p class="simpara">
						On the <span class="strong strong"><strong>Stratis pool</strong></span> page, click <span class="guibutton">Add block devices</span>.
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/7cbbd0667e9e4dad03191e3a1bd46614/cockpit-view-stratis-pool.png" alt="Image displaying the Stratis pool page."></span>

					</p></li><li class="listitem"><p class="simpara">
						In the <span class="strong strong"><strong>Add block devices</strong></span> dialog box, select the <span class="strong strong"><strong>Tier</strong></span>, whether you want to add a block device as data or cache.
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/4fe8c35276d6b3ff0b005558df3edcbe/cockpit-stratis-add-block-device.png" alt="Image displaying the Add block devices dialog box."></span>

					</p></li><li class="listitem">
						Optional: If you are adding the block device to a Stratis pool that is encrypted with a passphrase, then you must enter the passphrase.
					</li><li class="listitem">
						Under <span class="strong strong"><strong>Block devices</strong></span>, select the devices you want to add to the pool.
					</li><li class="listitem">
						Click <span class="guibutton">Add</span>.
					</li></ol></div></section><section class="section _additional-resources" id="additional_resources"><div class="titlepage"><div><div><h3 class="title">26.4. Additional resources</h3></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						<a class="link" href="https://stratis-storage.github.io/">The <span class="emphasis"><em>Stratis Storage</em></span> website</a>
					</li></ul></div></section></section><section class="chapter" id="monitoring-stratis-file-systems_managing-file-systems"><div class="titlepage"><div><div><h2 class="title">Chapter 27. Monitoring Stratis file systems</h2></div></div></div><p>
			As a Stratis user, you can view information about Stratis volumes on your system to monitor their state and free space.
		</p><section class="section" id="stratis-sizes-reported-by-different-utilities_monitoring-stratis-file-systems"><div class="titlepage"><div><div><h3 class="title">27.1. Stratis sizes reported by different utilities</h3></div></div></div><p class="_abstract _abstract">
				This section explains the difference between Stratis sizes reported by standard utilities such as <code class="literal">df</code> and the <code class="literal">stratis</code> utility.
			</p><p>
				Standard Linux utilities such as <code class="literal">df</code> report the size of the XFS file system layer on Stratis, which is 1 TiB. This is not useful information, because the actual storage usage of Stratis is less due to thin provisioning, and also because Stratis automatically grows the file system when the XFS layer is close to full.
			</p><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
					Regularly monitor the amount of data written to your Stratis file systems, which is reported as the <span class="emphasis"><em>Total Physical Used</em></span> value. Make sure it does not exceed the <span class="emphasis"><em>Total Physical Size</em></span> value.
				</p></div></rh-alert><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">stratis(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="displaying-information-about-stratis-volumes_monitoring-stratis-file-systems"><div class="titlepage"><div><div><h3 class="title">27.2. Displaying information about Stratis volumes</h3></div></div></div><p class="_abstract _abstract">
				This procedure lists statistics about your Stratis volumes, such as the total, used, and free size or file systems and block devices belonging to a pool.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Stratis is installed. See <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems">Installing Stratis</a>.
					</li><li class="listitem">
						The <code class="literal">stratisd</code> service is running.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						To display information about all <span class="strong strong"><strong>block devices</strong></span> used for Stratis on your system:
					</p><pre class="screen"># stratis blockdev

Pool Name  Device Node    Physical Size   State  Tier
<span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span>    <span class="emphasis"><em><span class="replaceable replaceable">/dev/sdb</span></em></span>            <span class="emphasis"><em><span class="replaceable replaceable">9.10 TiB</span></em></span>  <span class="emphasis"><em><span class="replaceable replaceable">In-use</span></em></span>  <span class="emphasis"><em><span class="replaceable replaceable">Data</span></em></span></pre></li><li class="listitem"><p class="simpara">
						To display information about all Stratis <span class="strong strong"><strong>pools</strong></span> on your system:
					</p><pre class="screen"># stratis pool

Name    Total Physical Size  Total Physical Used
<span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span>            <span class="emphasis"><em><span class="replaceable replaceable">9.10 TiB</span></em></span>              <span class="emphasis"><em><span class="replaceable replaceable">598 MiB</span></em></span></pre></li><li class="listitem"><p class="simpara">
						To display information about all Stratis <span class="strong strong"><strong>file systems</strong></span> on your system:
					</p><pre class="screen"># stratis filesystem

Pool Name  Name  Used     Created            Device
<span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span>    <span class="emphasis"><em><span class="replaceable replaceable">my-fs</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">546 MiB</span></em></span>  <span class="emphasis"><em><span class="replaceable replaceable">Nov 08 2018 08:03</span></em></span>  /dev/stratis/<span class="emphasis"><em><span class="replaceable replaceable">my-pool/my-fs</span></em></span></pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">stratis(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="viewing-a-stratis-pool-using-the-web-console_monitoring-stratis-file-systems"><div class="titlepage"><div><div><h3 class="title">27.3. Viewing a Stratis pool by using the web console</h3></div></div></div><p class="_abstract _abstract">
				You can use the web console to view an existing Stratis pool and the file systems it contains.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						You have installed the RHEL 9 web console.
					</p><p class="simpara">
						For instructions, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console">Installing and enabling the web console</a>.
					</p></li><li class="listitem">
						The <code class="literal">stratisd</code> service is running.
					</li><li class="listitem">
						You have an existing Stratis pool.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem">
						Log in to the RHEL 9 web console.
					</li><li class="listitem">
						Click <span class="guibutton">Storage</span>.
					</li><li class="listitem"><p class="simpara">
						In the <span class="strong strong"><strong>Storage</strong></span> table, click the Stratis pool you want to view.
					</p><p class="simpara">
						The Stratis pool page displays all the information about the pool and the file systems that you created in the pool.
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/7cbbd0667e9e4dad03191e3a1bd46614/cockpit-view-stratis-pool.png" alt="Image displaying the Stratis pool page."></span>

					</p></li></ol></div></section><section class="section _additional-resources" id="additional_resources_2"><div class="titlepage"><div><div><h3 class="title">27.4. Additional resources</h3></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						<a class="link" href="https://stratis-storage.github.io/">The <span class="emphasis"><em>Stratis Storage</em></span> website</a>
					</li></ul></div></section></section><section class="chapter" id="using-snapshots-on-stratis-file-systems_managing-file-systems"><div class="titlepage"><div><div><h2 class="title">Chapter 28. Using snapshots on Stratis file systems</h2></div></div></div><p>
			You can use snapshots on Stratis file systems to capture file system state at arbitrary times and restore it in the future.
		</p><section class="section" id="characteristics-of-stratis-snapshots_using-snapshots-on-stratis-file-systems"><div class="titlepage"><div><div><h3 class="title">28.1. Characteristics of Stratis snapshots</h3></div></div></div><p>
				In Stratis, a snapshot is a regular Stratis file system created as a copy of another Stratis file system. The snapshot initially contains the same file content as the original file system, but can change as the snapshot is modified. Whatever changes you make to the snapshot will not be reflected in the original file system.
			</p><p>
				The current snapshot implementation in Stratis is characterized by the following:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						A snapshot of a file system is another file system.
					</li><li class="listitem">
						A snapshot and its origin are not linked in lifetime. A snapshotted file system can live longer than the file system it was created from.
					</li><li class="listitem">
						A file system does not have to be mounted to create a snapshot from it.
					</li><li class="listitem">
						Each snapshot uses around half a gigabyte of actual backing storage, which is needed for the XFS log.
					</li></ul></div></section><section class="section" id="creating-a-stratis-snapshot_using-snapshots-on-stratis-file-systems"><div class="titlepage"><div><div><h3 class="title">28.2. Creating a Stratis snapshot</h3></div></div></div><p class="_abstract _abstract">
				This procedure creates a Stratis file system as a snapshot of an existing Stratis file system.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Stratis is installed. See <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems">Installing Stratis</a>.
					</li><li class="listitem">
						The <code class="literal">stratisd</code> service is running.
					</li><li class="listitem">
						You have created a Stratis file system. See <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/managing_file_systems/index#creating-a-stratis-file-system_setting-up-stratis-file-systems">Creating a Stratis filesystem</a>.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						To create a Stratis snapshot, use:
					</p><pre class="screen"># stratis fs snapshot <span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">my-fs</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">my-fs-snapshot</span></em></span></pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">stratis(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="accessing-the-content-of-a-stratis-snapshot_using-snapshots-on-stratis-file-systems"><div class="titlepage"><div><div><h3 class="title">28.3. Accessing the content of a Stratis snapshot</h3></div></div></div><p class="_abstract _abstract">
				This procedure mounts a snapshot of a Stratis file system to make it accessible for read and write operations.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Stratis is installed. See <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems">Installing Stratis</a>.
					</li><li class="listitem">
						The <code class="literal">stratisd</code> service is running.
					</li><li class="listitem">
						You have created a Stratis snapshot. See <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/managing_file_systems/index#creating-a-stratis-file-system_setting-up-stratis-file-systems">Creating a Stratis filesystem</a>.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						To access the snapshot, mount it as a regular file system from the <code class="literal filename">/dev/stratis/<span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span>/</code> directory:
					</p><pre class="screen"># mount /dev/stratis/<span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span>/<span class="emphasis"><em><span class="replaceable replaceable">my-fs-snapshot</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">mount-point</span></em></span></pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#mounting-a-stratis-file-system_setting-up-stratis-file-systems">Mounting a Stratis file system</a>
					</li><li class="listitem">
						<code class="literal">mount(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="reverting-a-stratis-file-system-to-a-previous-snapshot_using-snapshots-on-stratis-file-systems"><div class="titlepage"><div><div><h3 class="title">28.4. Reverting a Stratis file system to a previous snapshot</h3></div></div></div><p class="_abstract _abstract">
				This procedure reverts the content of a Stratis file system to the state captured in a Stratis snapshot.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Stratis is installed. See <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems">Installing Stratis</a>.
					</li><li class="listitem">
						The <code class="literal">stratisd</code> service is running.
					</li><li class="listitem">
						You have created a Stratis snapshot. See <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#creating-a-stratis-snapshot_using-snapshots-on-stratis-file-systems">Creating a Stratis snapshot</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Optional: Back up the current state of the file system to be able to access it later:
					</p><pre class="screen"># stratis filesystem snapshot <span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">my-fs</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">my-fs-backup</span></em></span></pre></li><li class="listitem"><p class="simpara">
						Unmount and remove the original file system:
					</p><pre class="screen"># umount /dev/stratis/<span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span>/<span class="emphasis"><em><span class="replaceable replaceable">my-fs</span></em></span>
# stratis filesystem destroy <span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">my-fs</span></em></span></pre></li><li class="listitem"><p class="simpara">
						Create a copy of the snapshot under the name of the original file system:
					</p><pre class="screen"># stratis filesystem snapshot <span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">my-fs-snapshot</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">my-fs</span></em></span></pre></li><li class="listitem"><p class="simpara">
						Mount the snapshot, which is now accessible with the same name as the original file system:
					</p><pre class="screen"># mount /dev/stratis/<span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span>/<span class="emphasis"><em><span class="replaceable replaceable">my-fs</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">mount-point</span></em></span></pre></li></ol></div><p>
				The content of the file system named <span class="emphasis"><em><span class="replaceable replaceable">my-fs</span></em></span> is now identical to the snapshot <span class="emphasis"><em><span class="replaceable replaceable">my-fs-snapshot</span></em></span>.
			</p><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">stratis(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="removing-a-stratis-snapshot_using-snapshots-on-stratis-file-systems"><div class="titlepage"><div><div><h3 class="title">28.5. Removing a Stratis snapshot</h3></div></div></div><p class="_abstract _abstract">
				This procedure removes a Stratis snapshot from a pool. Data on the snapshot are lost.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Stratis is installed. See <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems">Installing Stratis</a>.
					</li><li class="listitem">
						The <code class="literal">stratisd</code> service is running.
					</li><li class="listitem">
						You have created a Stratis snapshot. See <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_file_systems/using-snapshots-on-stratis-file-systems_managing-file-systems#creating-a-stratis-snapshot_using-snapshots-on-stratis-file-systems">Creating a Stratis snapshot</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Unmount the snapshot:
					</p><pre class="screen"># umount /dev/stratis/<span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span>/<span class="emphasis"><em><span class="replaceable replaceable">my-fs-snapshot</span></em></span></pre></li><li class="listitem"><p class="simpara">
						Destroy the snapshot:
					</p><pre class="screen"># stratis filesystem destroy <span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">my-fs-snapshot</span></em></span></pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">stratis(8)</code> man page on your system
					</li></ul></div></section><section class="section _additional-resources" id="additional_resources_3"><div class="titlepage"><div><div><h3 class="title">28.6. Additional resources</h3></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						<a class="link" href="https://stratis-storage.github.io/">The <span class="emphasis"><em>Stratis Storage</em></span> website</a>
					</li></ul></div></section></section><section class="chapter" id="removing-stratis-file-systems_managing-file-systems"><div class="titlepage"><div><div><h2 class="title">Chapter 29. Removing Stratis file systems</h2></div></div></div><p>
			You can remove an existing Stratis file system, or a Stratis pool, by destroying data on them.
		</p><section class="section" id="components-of-a-stratis-volume_removing-stratis-file-systems"><div class="titlepage"><div><div><h3 class="title">29.1. Components of a Stratis volume</h3></div></div></div><p class="_abstract _abstract">
				Learn about the components that comprise a Stratis volume.
			</p><p>
				Externally, Stratis presents the following volume components in the command-line interface and the API:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">blockdev</code></span></dt><dd>
							Block devices, such as a disk or a disk partition.
						</dd><dt><span class="term"><code class="literal">pool</code></span></dt><dd><p class="simpara">
							Composed of one or more block devices.
						</p><p class="simpara">
							A pool has a fixed total size, equal to the size of the block devices.
						</p><p class="simpara">
							The pool contains most Stratis layers, such as the non-volatile data cache using the <code class="literal">dm-cache</code> target.
						</p><p class="simpara">
							Stratis creates a <code class="literal filename">/dev/stratis/<span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span>/</code> directory for each pool. This directory contains links to devices that represent Stratis file systems in the pool.
						</p></dd></dl></div><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">filesystem</code></span></dt><dd><p class="simpara">
							Each pool can contain one or more file systems, which store files.
						</p><p class="simpara">
							File systems are thinly provisioned and do not have a fixed total size. The actual size of a file system grows with the data stored on it. If the size of the data approaches the virtual size of the file system, Stratis grows the thin volume and the file system automatically.
						</p><p class="simpara">
							The file systems are formatted with XFS.
						</p><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
								Stratis tracks information about file systems created using Stratis that XFS is not aware of, and changes made using XFS do not automatically create updates in Stratis. Users must not reformat or reconfigure XFS file systems that are managed by Stratis.
							</p></div></rh-alert><p class="simpara">
							Stratis creates links to file systems at the <code class="literal filename">/dev/stratis/<span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span>/<span class="emphasis"><em><span class="replaceable replaceable">my-fs</span></em></span></code> path.
						</p></dd></dl></div><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					Stratis uses many Device Mapper devices, which show up in <code class="literal">dmsetup</code> listings and the <code class="literal filename">/proc/partitions</code> file. Similarly, the <code class="literal">lsblk</code> command output reflects the internal workings and layers of Stratis.
				</p></div></rh-alert></section><section class="section" id="removing-a-stratis-file-system_removing-stratis-file-systems"><div class="titlepage"><div><div><h3 class="title">29.2. Removing a Stratis file system</h3></div></div></div><p class="_abstract _abstract">
				This procedure removes an existing Stratis file system. Data stored on it are lost.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Stratis is installed. See <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems">Installing Stratis</a>.
					</li><li class="listitem">
						The <code class="literal">stratisd</code> service is running.
					</li><li class="listitem">
						You have created a Stratis file system. See <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/managing_file_systems/index#creating-a-stratis-file-system_setting-up-stratis-file-systems">Creating a Stratis filesystem</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Unmount the file system:
					</p><pre class="screen"># umount /dev/stratis/<span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span>/<span class="emphasis"><em><span class="replaceable replaceable">my-fs</span></em></span></pre></li><li class="listitem"><p class="simpara">
						Destroy the file system:
					</p><pre class="screen"># stratis filesystem destroy <span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">my-fs</span></em></span></pre></li><li class="listitem"><p class="simpara">
						Verify that the file system no longer exists:
					</p><pre class="screen"># stratis filesystem list <span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span></pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">stratis(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="deleting-a-file-system-from-a-stratis-pool-using-the-web-console_removing-stratis-file-systems"><div class="titlepage"><div><div><h3 class="title">29.3. Deleting a file system from a Stratis pool by using the web console</h3></div></div></div><p class="_abstract _abstract">
				You can use the web console to delete a file system from an existing Stratis pool.
			</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					Deleting a Stratis pool file system erases all the data it contains.
				</p></div></rh-alert><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						You have installed the RHEL 9 web console.
					</p><p class="simpara">
						For instructions, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console">Installing and enabling the web console</a>.
					</p></li><li class="listitem"><p class="simpara">
						Stratis is installed.
					</p><p class="simpara">
						The web console detects and installs Stratis by default. However, for manually installing Stratis, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems">Installing Stratis</a>.
					</p></li><li class="listitem">
						The <code class="literal">stratisd</code> service is running.
					</li><li class="listitem">
						You have an existing Stratis pool.
					</li><li class="listitem">
						You have created a file system on the Stratis pool.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Log in to the RHEL 9 web console.
					</p><p class="simpara">
						For details, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#logging-in-to-the-web-console_getting-started-with-the-rhel-9-web-console">Logging in to the web console</a>.
					</p></li><li class="listitem">
						Click <span class="guibutton">Storage</span>.
					</li><li class="listitem">
						In the <span class="strong strong"><strong>Storage</strong></span> table, click the Stratis pool from which you want to delete a file system.
					</li><li class="listitem"><p class="simpara">
						On the <span class="strong strong"><strong>Stratis pool</strong></span> page, scroll to the <span class="strong strong"><strong>Stratis filesystems</strong></span> section and click the menu button <span class="guibutton">⋮</span> next to the file system you want to delete.
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/7cbbd0667e9e4dad03191e3a1bd46614/cockpit-view-stratis-pool.png" alt="Image displaying the Stratis pool page."></span>

					</p></li><li class="listitem"><p class="simpara">
						From the drop-down menu, select <span class="guibutton">delete</span>.
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/38f85c8e779f4a9eee61311e2daf656e/cockpit-stratis-fs-delete.png" alt="Image displaying the drop-down menu of a stratis file system."></span>

					</p></li><li class="listitem">
						In the <span class="strong strong"><strong>Confirm deletion</strong></span> dialog box, click <span class="guibutton">Delete</span>.
					</li></ol></div></section><section class="section" id="removing-a-stratis-pool_removing-stratis-file-systems"><div class="titlepage"><div><div><h3 class="title">29.4. Removing a Stratis pool</h3></div></div></div><p class="_abstract _abstract">
				This procedure removes an existing Stratis pool. Data stored on it are lost.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Stratis is installed. See <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems">Installing Stratis</a>.
					</li><li class="listitem">
						The <code class="literal">stratisd</code> service is running.
					</li><li class="listitem"><p class="simpara">
						You have created a Stratis pool:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
								To create an unencrypted pool, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#create-unencrypted-stratis-pool_setting-up-stratis-file-systems">Creating an unencrypted Stratis pool</a>
							</li><li class="listitem">
								To create an encrypted pool, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#create-encrypted-stratis-pool_setting-up-stratis-file-systems">Creating an encrypted Stratis pool</a>.
							</li></ul></div></li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						List file systems on the pool:
					</p><pre class="screen"># stratis filesystem list <span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span></pre></li><li class="listitem"><p class="simpara">
						Unmount all file systems on the pool:
					</p><pre class="screen"># umount /dev/stratis/<span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span>/<span class="emphasis"><em><span class="replaceable replaceable">my-fs-1</span></em></span> \
         /dev/stratis/<span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span>/<span class="emphasis"><em><span class="replaceable replaceable">my-fs-2</span></em></span> \
         /dev/stratis/<span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span>/<span class="emphasis"><em><span class="replaceable replaceable">my-fs-n</span></em></span></pre></li><li class="listitem"><p class="simpara">
						Destroy the file systems:
					</p><pre class="screen"># stratis filesystem destroy <span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">my-fs-1</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">my-fs-2</span></em></span></pre></li><li class="listitem"><p class="simpara">
						Destroy the pool:
					</p><pre class="screen"># stratis pool destroy <span class="emphasis"><em><span class="replaceable replaceable">my-pool</span></em></span></pre></li><li class="listitem"><p class="simpara">
						Verify that the pool no longer exists:
					</p><pre class="screen"># stratis pool list</pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">stratis(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="deleting-a-stratis-pool-using-the-web-console_removing-stratis-file-systems"><div class="titlepage"><div><div><h3 class="title">29.5. Deleting a Stratis pool by using the web console</h3></div></div></div><p class="_abstract _abstract">
				You can use the web console to delete an existing Stratis pool.
			</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					Deleting a Stratis pool erases all the data it contains.
				</p></div></rh-alert><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						You have installed the RHEL 9 web console.
					</p><p class="simpara">
						For instructions, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console">Installing and enabling the web console</a>.
					</p></li><li class="listitem">
						The <code class="literal">stratisd</code> service is running.
					</li><li class="listitem">
						You have an existing Stratis pool.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Log in to the RHEL 9 web console.
					</p><p class="simpara">
						For details, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#logging-in-to-the-web-console_getting-started-with-the-rhel-9-web-console">Logging in to the web console</a>.
					</p></li><li class="listitem">
						Click <span class="guibutton">Storage</span>.
					</li><li class="listitem">
						In the <span class="strong strong"><strong>Storage</strong></span> table, click the menu button, <span class="guibutton">⋮</span>, next to the Stratis pool you want to delete.
					</li><li class="listitem">
						From the drop-down menu, select <span class="guibutton">Delete pool</span>.
					</li><li class="listitem">
						In the <span class="strong strong"><strong>Permanently delete pool</strong></span> dialog box, click <span class="guibutton">Delete</span>.
					</li></ol></div></section><section class="section _additional-resources" id="additional_resources_4"><div class="titlepage"><div><div><h3 class="title">29.6. Additional resources</h3></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						<a class="link" href="https://stratis-storage.github.io/">The <span class="emphasis"><em>Stratis Storage</em></span> website</a>
					</li></ul></div></section></section><section class="chapter" id="getting-started-with-an-ext4-file-system_managing-file-systems"><div class="titlepage"><div><div><h2 class="title">Chapter 30. Getting started with an ext4 file system</h2></div></div></div><p>
			As a system administrator, you can create, mount, resize, backup, and restore an ext4 file system. The ext4 file system is a scalable extension of the ext3 file system. With Red Hat Enterprise Linux 9, it can support a maximum individual file size of <code class="literal">16</code> terabytes, and file system to a maximum of <code class="literal">50</code> terabytes.
		</p><section class="section" id="features-of-an-ext4-file-system_getting-started-with-an-ext4-file-system"><div class="titlepage"><div><div><h3 class="title">30.1. Features of an ext4 file system</h3></div></div></div><p class="_abstract _abstract">
				Following are the features of an ext4 file system:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Using extents: The ext4 file system uses extents, which improves performance when using large files and reduces metadata overhead for large files.
					</li><li class="listitem">
						Ext4 labels unallocated block groups and inode table sections accordingly, which allows the block groups and table sections to be skipped during a file system check. It leads to a quick file system check, which becomes more beneficial as the file system grows in size.
					</li><li class="listitem">
						Metadata checksum: By default, this feature is enabled in Red Hat Enterprise Linux 9.
					</li><li class="listitem"><p class="simpara">
						Allocation features of an ext4 file system:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
								Persistent pre-allocation
							</li><li class="listitem">
								Delayed allocation
							</li><li class="listitem">
								Multi-block allocation
							</li><li class="listitem">
								Stripe-aware allocation
							</li></ul></div></li><li class="listitem">
						Extended attributes (<code class="literal">xattr</code>): This allows the system to associate several additional name and value pairs per file.
					</li><li class="listitem"><p class="simpara">
						Quota journaling: This avoids the need for lengthy quota consistency checks after a crash.
					</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
							The only supported journaling mode in ext4 is <code class="literal">data=ordered</code> (default). For more information, see <a class="link" href="https://access.redhat.com/solutions/424073">Is the EXT journaling option "data=writeback" supported in RHEL?</a> Knowledgebase article.
						</p></div></rh-alert></li><li class="listitem">
						Subsecond timestamps — This gives timestamps to the subsecond.
					</li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">ext4</code> man page on your system
					</li></ul></div></section><section class="section" id="creating-an-ext4-file-system_getting-started-with-an-ext4-file-system"><div class="titlepage"><div><div><h3 class="title">30.2. Creating an ext4 file system</h3></div></div></div><p class="_abstract _abstract">
				As a system administrator, you can create an ext4 file system on a block device using <code class="literal">mkfs.ext4</code> command.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						A partition on your disk. For information about creating MBR or GPT partitions, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_file_systems/partition-operations-with-parted_managing-file-systems#proc_creating-a-partition-table-on-a-disk-with-parted_partition-operations-with-parted">Creating a partition table on a disk with parted</a>.
					</li><li class="listitem">
						Alternatively, use an LVM or MD volume.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						To create an ext4 file system:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								For a regular-partition device, an LVM volume, an MD volume, or a similar device, use the following command:
							</p><pre class="screen"># mkfs.ext4 /dev/<span class="emphasis"><em>block_device</em></span></pre><p class="simpara">
								Replace /dev/<span class="emphasis"><em>block_device</em></span> with the path to a block device.
							</p><p class="simpara">
								For example, <code class="literal">/dev/sdb1</code>, <code class="literal">/dev/disk/by-uuid/05e99ec8-def1-4a5e-8a9d-5945339ceb2a</code>, or <code class="literal">/dev/my-volgroup/my-lv</code>. In general, the default options are optimal for most usage scenarios.
							</p></li><li class="listitem"><p class="simpara">
								For striped block devices (for example, RAID5 arrays), the stripe geometry can be specified at the time of file system creation. Using proper stripe geometry enhances the performance of an ext4 file system. For example, to create a file system with a 64k stride (that is, 16 x 4096) on a 4k-block file system, use the following command:
							</p><pre class="screen"># mkfs.ext4 -E stride=16,stripe-width=64 /dev/<span class="emphasis"><em>block_device</em></span></pre><p class="simpara">
								In the given example:
							</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
										stride=value: Specifies the RAID chunk size
									</li><li class="listitem">
										stripe-width=value: Specifies the number of data disks in a RAID device, or the number of stripe units in the stripe.
									</li></ul></div></li></ul></div><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									To specify a UUID when creating a file system:
								</p><pre class="screen"># mkfs.ext4 -U <span class="emphasis"><em>UUID</em></span> /dev/<span class="emphasis"><em>block_device</em></span></pre><p class="simpara">
									Replace <span class="emphasis"><em>UUID</em></span> with the UUID you want to set: for example, <code class="literal">7cd65de3-e0be-41d9-b66d-96d749c02da7</code>.
								</p><p class="simpara">
									Replace /dev/<span class="emphasis"><em>block_device</em></span> with the path to an ext4 file system to have the UUID added to it: for example, <code class="literal">/dev/sda8</code>.
								</p></li><li class="listitem"><p class="simpara">
									To specify a label when creating a file system:
								</p><pre class="screen"># mkfs.ext4 -L <span class="emphasis"><em>label-name</em></span> /dev/<span class="emphasis"><em>block_device</em></span></pre></li></ul></div></div></rh-alert></li><li class="listitem"><p class="simpara">
						To view the created ext4 file system:
					</p><pre class="screen"># blkid</pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">ext4</code> and <code class="literal">mkfs.ext4</code> man pages on your system
					</li></ul></div></section><section class="section" id="mounting-an-ext4-file-system_getting-started-with-an-ext4-file-system"><div class="titlepage"><div><div><h3 class="title">30.3. Mounting an ext4 file system</h3></div></div></div><p class="_abstract _abstract">
				As a system administrator, you can mount an ext4 file system using the <code class="literal">mount</code> utility.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						An ext4 file system. For information about creating an ext4 file system, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#creating-an-ext4-file-system_getting-started-with-an-ext4-file-system">Creating an ext4 file system</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						To create a mount point to mount the file system:
					</p><pre class="screen"># mkdir <span class="emphasis"><em>/mount/point</em></span></pre><p class="simpara">
						Replace <span class="emphasis"><em>/mount/point</em></span> with the directory name where mount point of the partition must be created.
					</p></li><li class="listitem"><p class="simpara">
						To mount an ext4 file system:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								To mount an ext4 file system with no extra options:
							</p><pre class="screen"># mount /dev/<span class="emphasis"><em>block_device /mount/point</em></span></pre></li><li class="listitem">
								To mount the file system persistently, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_file_systems/assembly_persistently-mounting-file-systems_managing-file-systems">Persistently mounting file systems</a>.
							</li></ul></div></li><li class="listitem"><p class="simpara">
						To view the mounted file system:
					</p><pre class="screen"># df -h</pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">mount</code>, <code class="literal">ext4</code>, and <code class="literal">fstab</code> man pages on your system
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_file_systems/mounting-file-systems_managing-file-systems">Mounting file systems</a>
					</li></ul></div></section><section class="section" id="resizing-an-ext4-file-system_getting-started-with-an-ext4-file-system"><div class="titlepage"><div><div><h3 class="title">30.4. Resizing an ext4 file system</h3></div></div></div><p class="_abstract _abstract">
				As a system administrator, you can resize an ext4 file system using the <code class="literal">resize2fs</code> utility. The <code class="literal">resize2fs</code> utility reads the size in units of file system block size, unless a suffix indicating a specific unit is used. The following suffixes indicate specific units:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						s (sectors) - <code class="literal">512</code> byte sectors
					</li><li class="listitem">
						K (kilobytes) - <code class="literal">1,024</code> bytes
					</li><li class="listitem">
						M (megabytes) - <code class="literal">1,048,576</code> bytes
					</li><li class="listitem">
						G (gigabytes) - <code class="literal">1,073,741,824</code> bytes
					</li><li class="listitem">
						T (terabytes) - <code class="literal">1,099,511,627,776</code> bytes
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						An ext4 file system. For information about creating an ext4 file system, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/managing_file_systems/index#creating-an-ext4-file-system_getting-started-with-an-ext4-file-system">Creating an ext4 file system</a>.
					</li><li class="listitem">
						An underlying block device of an appropriate size to hold the file system after resizing.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						To resize an ext4 file system, take the following steps:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								To shrink and grow the size of an unmounted ext4 file system:
							</p><pre class="screen"># umount /dev/<span class="emphasis"><em>block_device</em></span>
# e2fsck -f /dev/<span class="emphasis"><em>block_device</em></span>
# resize2fs /dev/<span class="emphasis"><em>block_device</em></span> <span class="emphasis"><em>size</em></span></pre><p class="simpara">
								Replace <span class="emphasis"><em>/dev/block_device</em></span> with the path to the block device, for example <code class="literal">/dev/sdb1</code>.
							</p><p class="simpara">
								Replace <span class="emphasis"><em>size</em></span> with the required resize value using <code class="literal">s</code>, <code class="literal">K</code>, <code class="literal">M</code>, <code class="literal">G</code>, and <code class="literal">T</code> suffixes.
							</p></li><li class="listitem"><p class="simpara">
								An ext4 file system may be grown while mounted using the <code class="literal">resize2fs</code> command:
							</p><pre class="screen"># resize2fs <span class="emphasis"><em>/mount/device size</em></span></pre><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
									The size parameter is optional (and often redundant) when expanding. The <code class="literal">resize2fs</code> automatically expands to fill the available space of the container, usually a logical volume or partition.
								</p></div></rh-alert></li></ul></div></li><li class="listitem"><p class="simpara">
						To view the resized file system:
					</p><pre class="screen"># df -h</pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">resize2fs</code>, <code class="literal">e2fsck</code>, and <code class="literal">ext4</code> man pages on your system
					</li></ul></div></section><section class="section" id="comparison-of-tools-used-with-ext4-and-xfs_getting-started-with-an-ext4-file-system"><div class="titlepage"><div><div><h3 class="title">30.5. Comparison of tools used with ext4 and XFS</h3></div></div></div><p class="_abstract _abstract">
				This section compares which tools to use to accomplish common tasks on the ext4 and XFS file systems.
			</p><rh-table><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 33%; " class="col_1"><!--Empty--><col style="width: 33%; " class="col_2"><!--Empty--><col style="width: 33%; " class="col_3"><!--Empty--></colgroup><thead><tr><th align="left" valign="top" id="idm139822449094432" scope="col">Task</th><th align="left" valign="top" id="idm139822449093344" scope="col">ext4</th><th align="left" valign="top" id="idm139822450526032" scope="col">XFS</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm139822449094432"> <p>
								Create a file system
							</p>
							 </td><td align="left" valign="top" headers="idm139822449093344"> <p>
								<code class="literal">mkfs.ext4</code>
							</p>
							 </td><td align="left" valign="top" headers="idm139822450526032"> <p>
								<code class="literal">mkfs.xfs</code>
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822449094432"> <p>
								File system check
							</p>
							 </td><td align="left" valign="top" headers="idm139822449093344"> <p>
								<code class="literal">e2fsck</code>
							</p>
							 </td><td align="left" valign="top" headers="idm139822450526032"> <p>
								<code class="literal">xfs_repair</code>
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822449094432"> <p>
								Resize a file system
							</p>
							 </td><td align="left" valign="top" headers="idm139822449093344"> <p>
								<code class="literal">resize2fs</code>
							</p>
							 </td><td align="left" valign="top" headers="idm139822450526032"> <p>
								<code class="literal">xfs_growfs</code>
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822449094432"> <p>
								Save an image of a file system
							</p>
							 </td><td align="left" valign="top" headers="idm139822449093344"> <p>
								<code class="literal">e2image</code>
							</p>
							 </td><td align="left" valign="top" headers="idm139822450526032"> <p>
								<code class="literal">xfs_metadump</code> and <code class="literal">xfs_mdrestore</code>
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822449094432"> <p>
								Label or tune a file system
							</p>
							 </td><td align="left" valign="top" headers="idm139822449093344"> <p>
								<code class="literal">tune2fs</code>
							</p>
							 </td><td align="left" valign="top" headers="idm139822450526032"> <p>
								<code class="literal">xfs_admin</code>
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822449094432"> <p>
								Back up a file system
							</p>
							 </td><td align="left" valign="top" headers="idm139822449093344"> <p>
								<code class="literal">tar</code> and <code class="literal">rsync</code>
							</p>
							 </td><td align="left" valign="top" headers="idm139822450526032"> <p>
								<code class="literal">xfsdump</code> and <code class="literal">xfsrestore</code>
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822449094432"> <p>
								Quota management
							</p>
							 </td><td align="left" valign="top" headers="idm139822449093344"> <p>
								<code class="literal">quota</code>
							</p>
							 </td><td align="left" valign="top" headers="idm139822450526032"> <p>
								<code class="literal">xfs_quota</code>
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm139822449094432"> <p>
								File mapping
							</p>
							 </td><td align="left" valign="top" headers="idm139822449093344"> <p>
								<code class="literal">filefrag</code>
							</p>
							 </td><td align="left" valign="top" headers="idm139822450526032"> <p>
								<code class="literal">xfs_bmap</code>
							</p>
							 </td></tr></tbody></table></rh-table><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					If you want a complete client-server solution for backups over network, you can use <code class="literal">bacula</code> backup utility that is available in RHEL 9. For more information about Bacula, see <a class="link" href="https://www.bacula.org/documentation/documentation/">Bacula backup solution</a>.
				</p></div></rh-alert></section></section><div><div xml:lang="en-US" class="legalnotice" id="idm139822467588976"><h2 class="legalnotice">Legal Notice</h2><div class="para">
		Copyright <span class="trademark"><!--Empty--></span>© 2024 Red Hat, Inc.
	</div><div class="para">
		The text of and illustrations in this document are licensed by Red Hat under a Creative Commons Attribution–Share Alike 3.0 Unported license ("CC-BY-SA"). An explanation of CC-BY-SA is available at <a class="uri" href="http://creativecommons.org/licenses/by-sa/3.0/">http://creativecommons.org/licenses/by-sa/3.0/</a>. In accordance with CC-BY-SA, if you distribute this document or an adaptation of it, you must provide the URL for the original version.
	</div><div class="para">
		Red Hat, as the licensor of this document, waives the right to enforce, and agrees not to assert, Section 4d of CC-BY-SA to the fullest extent permitted by applicable law.
	</div><div class="para">
		Red Hat, Red Hat Enterprise Linux, the Shadowman logo, the Red Hat logo, JBoss, OpenShift, Fedora, the Infinity logo, and RHCE are trademarks of Red Hat, Inc., registered in the United States and other countries.
	</div><div class="para">
		<span class="trademark">Linux</span>® is the registered trademark of Linus Torvalds in the United States and other countries.
	</div><div class="para">
		<span class="trademark">Java</span>® is a registered trademark of Oracle and/or its affiliates.
	</div><div class="para">
		<span class="trademark">XFS</span>® is a trademark of Silicon Graphics International Corp. or its subsidiaries in the United States and/or other countries.
	</div><div class="para">
		<span class="trademark">MySQL</span>® is a registered trademark of MySQL AB in the United States, the European Union and other countries.
	</div><div class="para">
		<span class="trademark">Node.js</span>® is an official trademark of Joyent. Red Hat is not formally related to or endorsed by the official Joyent Node.js open source or commercial project.
	</div><div class="para">
		The <span class="trademark">OpenStack</span>® Word Mark and OpenStack logo are either registered trademarks/service marks or trademarks/service marks of the OpenStack Foundation, in the United States and other countries and are used with the OpenStack Foundation's permission. We are not affiliated with, endorsed or sponsored by the OpenStack Foundation, or the OpenStack community.
	</div><div class="para">
		All other trademarks are the property of their respective owners.
	</div></div></div></div></body></section><!----></div></article><aside id="layout" class="span-xs-12 span-sm-2 span-md-2 content-format-selectors" aria-label="Select page format" data-v-8589d091><div class="sticky-top page-layout-options" data-v-8589d091><label for="page-format" data-v-8589d091>Format</label><select id="page-format" class="page-format-dropdown" data-v-8589d091><option class="page-type" value="html" data-v-8589d091>Multi-page</option><option selected class="page-type" value="html-single" data-v-8589d091>Single-page</option><option class="page-type" value="pdf" data-v-8589d091>View full doc as PDF</option></select></div><!----></aside></div><div class="btn-container hidden" data-v-8589d091><pf-button class="top-scroll-btn" icon="angle-up" icon-set="fas" icon-position="right" data-v-8589d091>Back to top</pf-button></div><!--]--><!--]--></main><rh-footer data-analytics-region="page-footer" data-v-97dd2752><a slot="logo" href="/en" data-analytics-category="Footer" data-analytics-text="Logo" data-v-97dd2752><img alt="Red Hat logo" src="/Logo-Red_Hat-Documentation-A-Reverse-RGB.svg" loading="lazy" width="222" height="40" data-v-97dd2752></a><rh-footer-social-link slot="social-links" icon="github" data-v-97dd2752><a href="https://github.com/redhat-documentation" data-analytics-region="social-links-exit" data-analytics-category="Footer|social-links" data-analytics-text="LinkedIn" data-v-97dd2752>Github</a></rh-footer-social-link><rh-footer-social-link slot="social-links" icon="reddit" data-v-97dd2752><a href="https://www.reddit.com/r/redhat/" data-analytics-region="social-links-exit" data-analytics-category="Footer|social-links" data-analytics-text="YouTube" data-v-97dd2752>Reddit</a></rh-footer-social-link><rh-footer-social-link slot="social-links" icon="youtube" data-v-97dd2752><a href="https://www.youtube.com/@redhat" data-analytics-region="social-links-exit" data-analytics-category="Footer|social-links" data-analytics-text="Facebook" data-v-97dd2752>Youtube</a></rh-footer-social-link><rh-footer-social-link slot="social-links" icon="twitter" data-v-97dd2752><a href="https://twitter.com/RedHat" data-analytics-region="social-links-exit" data-analytics-category="Footer|social-links" data-analytics-text="Twitter" data-v-97dd2752>Twitter</a></rh-footer-social-link><h3 slot="links" data-analytics-text="Learn" data-v-97dd2752>Learn</h3><ul slot="links" data-v-97dd2752><li data-v-97dd2752><a href="https://developers.redhat.com/learn" data-analytics-category="Footer|Learn" data-analytics-text="Developer resources" data-v-97dd2752>Developer resources</a></li><li data-v-97dd2752><a href="https://cloud.redhat.com/learn" data-analytics-category="Footer|Learn" data-analytics-text="Cloud learning hub" data-v-97dd2752>Cloud learning hub</a></li><li data-v-97dd2752><a href="https://www.redhat.com/en/interactive-labs" data-analytics-category="Footer|Learn" data-analytics-text="Interactive labs" data-v-97dd2752>Interactive labs</a></li><li data-v-97dd2752><a href="https://www.redhat.com/services/training-and-certification" data-analytics-category="Footer|Learn" data-analytics-text="Training and certification" data-v-97dd2752>Training and certification</a></li><li data-v-97dd2752><a href="https://access.redhat.com/support" data-analytics-category="Footer|Learn" data-analytics-text="Customer support" data-v-97dd2752>Customer support</a></li><li data-v-97dd2752><a href="/products" data-analytics-category="Footer|Learn" data-analytics-text="See all documentation" data-v-97dd2752>See all documentation</a></li></ul><h3 slot="links" data-analytics-text="Try buy sell" data-v-97dd2752>Try, buy, &amp; sell</h3><ul slot="links" data-v-97dd2752><li data-v-97dd2752><a href="https://redhat.com/en/products/trials" data-analytics-category="Footer|Try buy sell" data-analytics-text="Product trial center" data-v-97dd2752>Product trial center</a></li><li data-v-97dd2752><a href="https://marketplace.redhat.com" data-analytics-category="Footer|Try buy sell" data-analytics-text="Red Hat Marketplace" data-v-97dd2752>Red Hat Marketplace</a></li><li data-v-97dd2752><a href="https://catalog.redhat.com/" data-analytics-category="Footer|Try buy sell" data-analytics-text="Red Hat Ecosystem Catalog" data-v-97dd2752>Red Hat Ecosystem Catalog</a></li><li data-v-97dd2752><a href="https://www.redhat.com/en/store" data-analytics-category="Footer|Try buy sell" data-analytics-text="Red Hat Store" data-v-97dd2752>Red Hat Store</a></li><li data-v-97dd2752><a href="https://www.redhat.com/about/japan-buy" data-analytics-category="Footer|Try buy sell" data-analytics-text="Buy online (Japan)" data-v-97dd2752>Buy online (Japan)</a></li></ul><h3 slot="links" data-analytics-text="Communities" data-v-97dd2752>Communities</h3><ul slot="links" data-v-97dd2752><li data-v-97dd2752><a href="https://access.redhat.com/community" data-analytics-category="Footer|Communities" data-analytics-text="Customer Portal Community" data-v-97dd2752>Customer Portal Community</a></li><li data-v-97dd2752><a href="https://www.redhat.com/events" data-analytics-category="Footer|Communities" data-analytics-text="Events" data-v-97dd2752>Events</a></li><li data-v-97dd2752><a href="https://www.redhat.com/about/our-community-contributions" data-analytics-category="Footer|Communities" data-analytics-text="How we contribute" data-v-97dd2752>How we contribute</a></li></ul><rh-footer-block slot="main-secondary" data-v-97dd2752><h3 slot="header" data-analytics-text="About Red Hat Documentation" data-v-97dd2752>About Red Hat Documentation</h3><p data-v-97dd2752>We help Red Hat users innovate and achieve their goals with our products and services with content they can trust.</p></rh-footer-block><rh-footer-block slot="main-secondary" data-v-97dd2752><h3 slot="header" data-analytics-text="Making open source more inclusive" data-v-97dd2752>Making open source more inclusive</h3><p data-v-97dd2752>Red Hat is committed to replacing problematic language in our code, documentation, and web properties. For more details, see the <a href=" https://www.redhat.com/en/blog/making-open-source-more-inclusive-eradicating-problematic-language" data-analytics-category="Footer|Making open source more inclusive" data-analytics-text="Red Hat Blog" data-v-97dd2752>Red Hat Blog</a>.</p></rh-footer-block><rh-footer-block slot="main-secondary" data-v-97dd2752><h3 slot="header" data-analytics-text="About Red Hat" data-v-97dd2752>About Red Hat</h3><p data-v-97dd2752>We deliver hardened solutions that make it easier for enterprises to work across platforms and environments, from the core datacenter to the network edge.</p></rh-footer-block><rh-footer-universal slot="universal" data-v-97dd2752><h3 slot="links-primary" data-analytics-text="Red Hat legal and privacy links" hidden data-v-97dd2752>Red Hat legal and privacy links</h3><ul slot="links-primary" data-analytics-region="page-footer-bottom-primary" data-v-97dd2752><li data-v-97dd2752><a href="https://redhat.com/en/about/company" data-analytics-category="Footer|Corporate" data-analytics-text="About Red Hat" data-v-97dd2752>About Red Hat</a></li><li data-v-97dd2752><a href="https://redhat.com/en/jobs" data-analytics-category="Footer|Corporate" data-analytics-text="Jobs" data-v-97dd2752>Jobs</a></li><li data-v-97dd2752><a href="https://redhat.com/en/events" data-analytics-category="Footer|Corporate" data-analytics-text="Events" data-v-97dd2752>Events</a></li><li data-v-97dd2752><a href="https://redhat.com/en/about/office-locations" data-analytics-category="Footer|Corporate" data-analytics-text="Locations" data-v-97dd2752>Locations</a></li><li data-v-97dd2752><a href="https://redhat.com/en/contact" data-analytics-category="Footer|Corporate" data-analytics-text="Contact Red Hat" data-v-97dd2752>Contact Red Hat</a></li><li data-v-97dd2752><a href="https://redhat.com/en/blog" data-analytics-category="Footer|Corporate" data-analytics-text="Red Hat Blog" data-v-97dd2752>Red Hat Blog</a></li><li data-v-97dd2752><a href="https://redhat.com/en/about/our-culture/diversity-equity-inclusion" data-analytics-category="Footer|Corporate" data-analytics-text="Diversity equity and inclusion" data-v-97dd2752>Diversity, equity, and inclusion</a></li><li data-v-97dd2752><a href="https://coolstuff.redhat.com/" data-analytics-category="Footer|Corporate" data-analytics-text="Cool Stuff Store" data-v-97dd2752>Cool Stuff Store</a></li><li data-v-97dd2752><a href="https://www.redhat.com/en/summit" data-analytics-category="Footer|Corporate" data-analytics-text="Red Hat Summit" data-v-97dd2752>Red Hat Summit</a></li></ul><span data-v-97dd2752 data-v-5f538988></span><rh-footer-copyright slot="links-secondary" data-v-97dd2752>© 2024 Red Hat, Inc.</rh-footer-copyright><h3 slot="links-secondary" data-analytics-text="Red Hat legal and privacy links" hidden data-v-97dd2752>Red Hat legal and privacy links</h3><ul slot="links-secondary" data-analytics-region="page-footer-bottom-secondary" data-v-97dd2752><li data-v-97dd2752><a href="https://redhat.com/en/about/privacy-policy" data-analytics-category="Footer|Red Hat legal and privacy links" data-analytics-text="Privacy statement" data-v-97dd2752>Privacy statement</a></li><li data-v-97dd2752><a href="https://redhat.com/en/about/terms-use" data-analytics-category="Footer|Red Hat legal and privacy links" data-analytics-text="Terms of use" data-v-97dd2752>Terms of use</a></li><li data-v-97dd2752><a href="https://redhat.com/en/about/all-policies-guidelines" data-analytics-category="Footer|Red Hat legal and privacy links" data-analytics-text="All policies and guidelines" data-v-97dd2752>All policies and guidelines</a></li><li data-v-97dd2752><a href="https://redhat.com/en/about/digital-accessibility" data-analytics-category="Footer|Red Hat legal and privacy links" data-analytics-text="Digital accessibility" class="active" data-v-97dd2752>Digital accessibility</a></li><li data-v-97dd2752><span id="teconsent" data-v-97dd2752></span></li></ul></rh-footer-universal></rh-footer><div id="consent_blackbar" style="position:fixed;bottom:0;width:100%;z-index:5;padding:10px;"></div><!--]--><!--]--></div><div id="teleports"></div><script type="application/json" id="__NUXT_DATA__" data-ssr="true">[["ShallowReactive",1],{"data":2,"state":1135,"once":1139,"_errors":1140,"serverRendered":15,"path":1142},["ShallowReactive",3],{"s8LoCEfG4A":4,"uUstF4AIyn":10,"Pn02PlJOas":1063,"rFVLKcOK8e":1134},[5,6,7,8,9],"fr-fr","en-us","zh-cn","ja-jp","ko-kr",{"name":11,"html":12,"type":-1,"toc":13,"breadcrumbs":964,"error":18,"title":972,"productName":966,"productVersions":981,"pagination":1010,"redirect":1044,"canonicalLinks":1045,"openShiftProducts":1047,"tocFromVolume":-1,"jumpLinks":1062},"Managing file systems","\u003Cbody>\u003Cdiv xml:lang=\"en-US\" class=\"book\" id=\"idm139822467671200\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv class=\"producttitle\">\u003Cspan class=\"productname\">Red Hat Enterprise Linux\u003C/span> \u003Cspan class=\"productnumber\">9\u003C/span>\u003C/div>\u003Cdiv>\u003Ch3 class=\"subtitle\">Creating, modifying, and administering file systems in Red Hat Enterprise Linux 9\u003C/h3>\u003C/div>\u003Cdiv>\u003Cdiv xml:lang=\"en-US\" class=\"authorgroup\">\u003Cspan class=\"orgname\">Red Hat\u003C/span> \u003Cspan class=\"orgdiv\">Customer Content Services\u003C/span>\u003C/div>\u003C/div>\u003Cdiv>\u003Ca href=\"#idm139822467588976\">Legal Notice\u003C/a>\u003C/div>\u003Cdiv>\u003Cdiv class=\"abstract\">\u003Cp class=\"title\">\u003Cstrong>Abstract\u003C/strong>\u003C/p>\u003Cdiv class=\"para\">\n\t\t\t\tRed Hat Enterprise Linux supports a variety of file systems. Each type of file system solves different problems and their usage is application specific. Use the information about the key differences and considerations to select and deploy the appropriate file system based on your specific application requirements.\n\t\t\t\u003C/div>\u003Cdiv class=\"para\">\n\t\t\t\tThe supported file systems include local on-disk file systems XFS and ext4, network and client-and-server file systems NFS and SMB, as well as a combined local storage and file system management solution, Stratis. You can perform several operations with a file system such as creating, mounting, backing up, restoring, checking and repairing, as well as limiting the storage space by using quotas.\n\t\t\t\u003C/div>\u003C/div>\u003C/div>\u003C/div>\u003Chr/>\u003C/div>\u003Csection class=\"preface\" id=\"proc_providing-feedback-on-red-hat-documentation_managing-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Providing feedback on Red Hat documentation\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tWe appreciate your feedback on our documentation. Let us know how we can improve it.\n\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Submitting feedback through Jira (account required)\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\n\t\t\t\t\tLog in to the \u003Ca class=\"link\" href=\"https://issues.redhat.com/projects/RHELDOCS/issues\">Jira\u003C/a> website.\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tClick \u003Cspan class=\"strong strong\">\u003Cstrong>Create\u003C/strong>\u003C/span> in the top navigation bar\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tEnter a descriptive title in the \u003Cspan class=\"strong strong\">\u003Cstrong>Summary\u003C/strong>\u003C/span> field.\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tEnter your suggestion for improvement in the \u003Cspan class=\"strong strong\">\u003Cstrong>Description\u003C/strong>\u003C/span> field. Include links to the relevant parts of the documentation.\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tClick \u003Cspan class=\"strong strong\">\u003Cstrong>Create\u003C/strong>\u003C/span> at the bottom of the dialogue.\n\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"chapter\" id=\"overview-of-available-file-systems_managing-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 1. Overview of available file systems\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\tChoosing the file system that is appropriate for your application is an important decision due to the large number of options available and the trade-offs involved.\n\t\t\u003C/p>\u003Cp>\n\t\t\tThe following sections describe the file systems that Red Hat Enterprise Linux 9 includes by default, and recommendations on the most suitable file system for your application.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"types-of-file-systems_overview-of-available-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">1.1. Types of file systems\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tRed Hat Enterprise Linux 9 supports a variety of file systems (FS). Different types of file systems solve different kinds of problems, and their usage is application specific. At the most general level, available file systems can be grouped into the following major types:\n\t\t\t\u003C/p>\u003Crh-table id=\"idm139822465608160\">\u003Ctable class=\"lt-4-cols lt-7-rows\">\u003Ccaption>Table 1.1. Types of file systems and their use cases\u003C/caption>\u003Ccolgroup>\u003Ccol style=\"width: 25%; \" class=\"col_1\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 25%; \" class=\"col_2\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 50%; \" class=\"col_3\">\u003C!--Empty-->\u003C/col>\u003C/colgroup>\u003Cthead>\u003Ctr>\u003Cth align=\"left\" valign=\"top\" id=\"idm139822456768464\" scope=\"col\">Type\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm139822456767376\" scope=\"col\">File system\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm139822456766288\" scope=\"col\">Attributes and use cases\u003C/th>\u003C/tr>\u003C/thead>\u003Ctbody>\u003Ctr>\u003Ctd rowspan=\"2\" align=\"left\" valign=\"top\" headers=\"idm139822456768464\"> \u003Cp>\n\t\t\t\t\t\t\t\tDisk or local FS\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456767376\"> \u003Cp>\n\t\t\t\t\t\t\t\tXFS\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456766288\"> \u003Cp>\n\t\t\t\t\t\t\t\tXFS is the default file system in RHEL. Red Hat recommends deploying XFS as your local file system unless there are specific reasons to do otherwise: for example, compatibility or corner cases around performance.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456767376\"> \u003Cp>\n\t\t\t\t\t\t\t\text4\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456766288\"> \u003Cp>\n\t\t\t\t\t\t\t\text4 has the benefit of familiarity in Linux, having evolved from the older ext2 and ext3 file systems. In many cases, it rivals XFS on performance. Support limits for ext4 filesystem and file sizes are lower than those on XFS.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd rowspan=\"2\" align=\"left\" valign=\"top\" headers=\"idm139822456768464\"> \u003Cp>\n\t\t\t\t\t\t\t\tNetwork or client-and-server FS\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456767376\"> \u003Cp>\n\t\t\t\t\t\t\t\tNFS\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456766288\"> \u003Cp>\n\t\t\t\t\t\t\t\tUse NFS to share files between multiple systems on the same network.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456767376\"> \u003Cp>\n\t\t\t\t\t\t\t\tSMB\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456766288\"> \u003Cp>\n\t\t\t\t\t\t\t\tUse SMB for file sharing with Microsoft Windows systems.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456768464\"> \u003Cp>\n\t\t\t\t\t\t\t\tShared storage or shared disk FS\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456767376\"> \u003Cp>\n\t\t\t\t\t\t\t\tGFS2\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456766288\"> \u003Cp>\n\t\t\t\t\t\t\t\tGFS2 provides shared write access to members of a compute cluster. The emphasis is on stability and reliability, with the functional experience of a local file system as possible. SAS Grid, Tibco MQ, IBM Websphere MQ, and Red Hat Active MQ have been deployed successfully on GFS2.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456768464\"> \u003Cp>\n\t\t\t\t\t\t\t\tVolume-managing FS\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456767376\"> \u003Cp>\n\t\t\t\t\t\t\t\tStratis\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456766288\"> \u003Cp>\n\t\t\t\t\t\t\t\tStratis is a volume manager built on a combination of XFS and LVM. The purpose of Stratis is to emulate capabilities offered by volume-managing file systems like Btrfs and ZFS. It is possible to build this stack manually, but Stratis reduces configuration complexity, implements best practices, and consolidates error information.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\u003C/rh-table>\u003C/section>\u003Csection class=\"section\" id=\"local-file-systems_overview-of-available-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">1.2. Local file systems\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tLocal file systems are file systems that run on a single, local server and are directly attached to storage.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tFor example, a local file system is the only choice for internal SATA or SAS disks, and is used when your server has internal hardware RAID controllers with local drives. Local file systems are also the most common file systems used on SAN attached storage when the device exported on the SAN is not shared.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tAll local file systems are POSIX-compliant and are fully compatible with all supported Red Hat Enterprise Linux releases. POSIX-compliant file systems provide support for a well-defined set of system calls, such as \u003Ccode class=\"literal\">read()\u003C/code>, \u003Ccode class=\"literal\">write()\u003C/code>, and \u003Ccode class=\"literal\">seek()\u003C/code>.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tWhen considering a file system choice, choose a file system based on how large the file system needs to be, what unique features it must have, and how it performs under your workload.\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">Available local file systems\u003C/span>\u003C/dt>\u003Cdd>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tXFS\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\text4\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/dd>\u003C/dl>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"the-xfs-file-system_overview-of-available-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">1.3. The XFS file system\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tXFS is a highly scalable, high-performance, robust, and mature 64-bit journaling file system that supports very large files and file systems on a single host. It is the default file system in Red Hat Enterprise Linux 9. XFS was originally developed in the early 1990s by SGI and has a long history of running on extremely large servers and storage arrays.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe features of XFS include:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">Reliability\u003C/span>\u003C/dt>\u003Cdd>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tMetadata journaling, which ensures file system integrity after a system crash by keeping a record of file system operations that can be replayed when the system is restarted and the file system remounted\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tExtensive run-time metadata consistency checking\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tScalable and fast repair utilities\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tQuota journaling. This avoids the need for lengthy quota consistency checks after a crash.\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Scalability and performance\u003C/span>\u003C/dt>\u003Cdd>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tSupported file system size up to 1024 TiB\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tAbility to support a large number of concurrent operations\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tB-tree indexing for scalability of free space management\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tSophisticated metadata read-ahead algorithms\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tOptimizations for streaming video workloads\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Allocation schemes\u003C/span>\u003C/dt>\u003Cdd>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tExtent-based allocation\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tStripe-aware allocation policies\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tDelayed allocation\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tSpace pre-allocation\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tDynamically allocated inodes\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Other features\u003C/span>\u003C/dt>\u003Cdd>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tReflink-based file copies\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tTightly integrated backup and restore utilities\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tOnline defragmentation\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tOnline file system growing\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tComprehensive diagnostics capabilities\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tExtended attributes (\u003Ccode class=\"literal\">xattr\u003C/code>). This allows the system to associate several additional name/value pairs per file.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tProject or directory quotas. This allows quota restrictions over a directory tree.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tSubsecond timestamps\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"formalpara\">\u003Cp class=\"title\">\u003Cstrong>Performance characteristics\u003C/strong>\u003C/p>\u003Cp>\n\t\t\t\t\tXFS has a high performance on large systems with enterprise workloads. A large system is one with a relatively high number of CPUs, multiple HBAs, and connections to external disk arrays. XFS also performs well on smaller systems that have a multi-threaded, parallel I/O workload.\n\t\t\t\t\u003C/p>\u003C/div>\u003Cp>\n\t\t\t\tXFS has a relatively low performance for single threaded, metadata-intensive workloads: for example, a workload that creates or deletes large numbers of small files in a single thread.\n\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"the-ext4-file-system_overview-of-available-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">1.4. The ext4 file system\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe ext4 file system is the fourth generation of the ext file system family. It was the default file system in Red Hat Enterprise Linux 6.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe ext4 driver can read and write to ext2 and ext3 file systems, but the ext4 file system format is not compatible with ext2 and ext3 drivers.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\text4 adds several new and improved features, such as:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tSupported file system size up to 50 TiB\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tExtent-based metadata\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tDelayed allocation\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tJournal checksumming\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tLarge storage support\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tThe extent-based metadata and the delayed allocation features provide a more compact and efficient way to track utilized space in a file system. These features improve file system performance and reduce the space consumed by metadata. Delayed allocation allows the file system to postpone selection of the permanent location for newly written user data until the data is flushed to disk. This enables higher performance since it can allow for larger, more contiguous allocations, allowing the file system to make decisions with much better information.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tFile system repair time using the \u003Ccode class=\"literal\">fsck\u003C/code> utility in ext4 is much faster than in ext2 and ext3. Some file system repairs have demonstrated up to a six-fold increase in performance.\n\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"comparison-of-xfs-and-ext4_overview-of-available-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">1.5. Comparison of XFS and ext4\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tXFS is the default file system in RHEL. This section compares the usage and features of XFS and ext4.\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">Metadata error behavior\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tIn ext4, you can configure the behavior when the file system encounters metadata errors. The default behavior is to simply continue the operation. When XFS encounters an unrecoverable metadata error, it shuts down the file system and returns the \u003Ccode class=\"literal\">EFSCORRUPTED\u003C/code> error.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Quotas\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIn ext4, you can enable quotas when creating the file system or later on an existing file system. You can then configure the quota enforcement using a mount option.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tXFS quotas are not a remountable option. You must activate quotas on the initial mount.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tRunning the \u003Ccode class=\"literal\">quotacheck\u003C/code> command on an XFS file system has no effect. The first time you turn on quota accounting, XFS checks quotas automatically.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">File system resize\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tXFS has no utility to reduce the size of a file system. You can only increase the size of an XFS file system. In comparison, ext4 supports both extending and reducing the size of a file system.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Inode numbers\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe ext4 file system does not support more than 2\u003Csup>32\u003C/sup> inodes.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tXFS supports dynamic inode allocation. The amount of space inodes can consume on an XFS filesystem is calculated as a percentage of the total filesystem space. To prevent the system from running out of inodes, an administrator can tune this percentage after the filesystem has been created, given there is free space left on the file system.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tCertain applications cannot properly handle inode numbers larger than 2\u003Csup>32\u003C/sup> on an XFS file system. These applications might cause the failure of 32-bit stat calls with the \u003Ccode class=\"literal\">EOVERFLOW\u003C/code> return value. Inode number exceed 2\u003Csup>32\u003C/sup> under the following conditions:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tThe file system is larger than 1 TiB with 256-byte inodes.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tThe file system is larger than 2 TiB with 512-byte inodes.\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIf your application fails with large inode numbers, mount the XFS file system with the \u003Ccode class=\"literal\">-o inode32\u003C/code> option to enforce inode numbers below 2\u003Csup>32\u003C/sup>. Note that using \u003Ccode class=\"literal\">inode32\u003C/code> does not affect inodes that are already allocated with 64-bit numbers.\n\t\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\t\tDo \u003Cspan class=\"emphasis\">\u003Cem>not\u003C/em>\u003C/span> use the \u003Ccode class=\"literal\">inode32\u003C/code> option unless a specific environment requires it. The \u003Ccode class=\"literal\">inode32\u003C/code> option changes allocation behavior. As a consequence, the \u003Ccode class=\"literal\">ENOSPC\u003C/code> error might occur if no space is available to allocate inodes in the lower disk blocks.\n\t\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/dd>\u003C/dl>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"choosing-a-local-file-system_overview-of-available-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">1.6. Choosing a local file system\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tTo choose a file system that meets your application requirements, you must understand the target system on which you will deploy the file system. In general, use XFS unless you have a specific use case for ext4.\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">XFS\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tFor large-scale deployments, use XFS, particularly when handling large files (hundreds of megabytes) and high I/O concurrency. XFS performs optimally in environments with high bandwidth (greater than 200MB/s) and more than 1000 IOPS. However, it consumes more CPU resources for metadata operations compared to ext4 and does not support file system shrinking.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">ext4\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tFor smaller systems or environments with limited I/O bandwidth, ext4 might be a better fit. It performs better in single-threaded, lower I/O workloads and environments with lower throughput requirements. ext4 also supports offline shrinking, which can be beneficial if resizing the file system is a requirement.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cp>\n\t\t\t\tBenchmark your application’s performance on your target server and storage system to ensure the selected file system meets your performance and scalability requirements.\n\t\t\t\u003C/p>\u003Crh-table id=\"idm139822460888464\">\u003Ctable class=\"lt-4-cols lt-7-rows\">\u003Ccaption>Table 1.2. Summary of local file system recommendations\u003C/caption>\u003Ccolgroup>\u003Ccol style=\"width: 60%; \" class=\"col_1\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 40%; \" class=\"col_2\">\u003C!--Empty-->\u003C/col>\u003C/colgroup>\u003Cthead>\u003Ctr>\u003Cth align=\"left\" valign=\"top\" id=\"idm139822456927488\" scope=\"col\">Scenario\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm139822456926400\" scope=\"col\">Recommended file system\u003C/th>\u003C/tr>\u003C/thead>\u003Ctbody>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456927488\"> \u003Cp>\n\t\t\t\t\t\t\t\tNo special use case\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456926400\"> \u003Cp>\n\t\t\t\t\t\t\t\tXFS\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456927488\"> \u003Cp>\n\t\t\t\t\t\t\t\tLarge server\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456926400\"> \u003Cp>\n\t\t\t\t\t\t\t\tXFS\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456927488\"> \u003Cp>\n\t\t\t\t\t\t\t\tLarge storage devices\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456926400\"> \u003Cp>\n\t\t\t\t\t\t\t\tXFS\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456927488\"> \u003Cp>\n\t\t\t\t\t\t\t\tLarge files\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456926400\"> \u003Cp>\n\t\t\t\t\t\t\t\tXFS\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456927488\"> \u003Cp>\n\t\t\t\t\t\t\t\tMulti-threaded I/O\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456926400\"> \u003Cp>\n\t\t\t\t\t\t\t\tXFS\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456927488\"> \u003Cp>\n\t\t\t\t\t\t\t\tSingle-threaded I/O\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456926400\"> \u003Cp>\n\t\t\t\t\t\t\t\text4\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456927488\"> \u003Cp>\n\t\t\t\t\t\t\t\tLimited I/O capability (under 1000 IOPS)\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456926400\"> \u003Cp>\n\t\t\t\t\t\t\t\text4\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456927488\"> \u003Cp>\n\t\t\t\t\t\t\t\tLimited bandwidth (under 200MB/s)\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456926400\"> \u003Cp>\n\t\t\t\t\t\t\t\text4\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456927488\"> \u003Cp>\n\t\t\t\t\t\t\t\tCPU-bound workload\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456926400\"> \u003Cp>\n\t\t\t\t\t\t\t\text4\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456927488\"> \u003Cp>\n\t\t\t\t\t\t\t\tSupport for offline shrinking\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456926400\"> \u003Cp>\n\t\t\t\t\t\t\t\text4\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\u003C/rh-table>\u003C/section>\u003Csection class=\"section\" id=\"network-file-systems_overview-of-available-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">1.7. Network file systems\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tNetwork file systems, also referred to as client/server file systems, enable client systems to access files that are stored on a shared server. This makes it possible for multiple users on multiple systems to share files and storage resources.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tSuch file systems are built from one or more servers that export a set of file systems to one or more clients. The client nodes do not have access to the underlying block storage, but rather interact with the storage using a protocol that allows for better access control.\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">Available network file systems\u003C/span>\u003C/dt>\u003Cdd>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tThe most common client/server file system for RHEL customers is the NFS file system. RHEL provides both an NFS server component to export a local file system over the network and an NFS client to import these file systems.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tRHEL also includes a CIFS client that supports the popular Microsoft SMB file servers for Windows interoperability. The userspace Samba server provides Windows clients with a Microsoft SMB service from a RHEL server.\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/dd>\u003C/dl>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"shared-storage-file-systems_overview-of-available-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">1.8. Shared storage file systems\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tShared storage file systems, sometimes referred to as cluster file systems, give each server in the cluster direct access to a shared block device over a local storage area network (SAN).\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">Comparison with network file systems\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tLike client/server file systems, shared storage file systems work on a set of servers that are all members of a cluster. Unlike NFS, however, no single server provides access to data or metadata to other members: each member of the cluster has direct access to the same storage device (the \u003Cspan class=\"emphasis\">\u003Cem>shared storage\u003C/em>\u003C/span>), and all cluster member nodes access the same set of files.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Concurrency\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tCache coherency is key in a clustered file system to ensure data consistency and integrity. There must be a single version of all files in a cluster visible to all nodes within a cluster. The file system must prevent members of the cluster from updating the same storage block at the same time and causing data corruption. In order to do that, shared storage file systems use a cluster wide-locking mechanism to arbitrate access to the storage as a concurrency control mechanism. For example, before creating a new file or writing to a file that is opened on multiple servers, the file system component on the server must obtain the correct lock.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe requirement of cluster file systems is to provide a highly available service like an Apache web server. Any member of the cluster will see a fully coherent view of the data stored in their shared disk file system, and all updates will be arbitrated correctly by the locking mechanisms.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Performance characteristics\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tShared disk file systems do not always perform as well as local file systems running on the same system due to the computational cost of the locking overhead. Shared disk file systems perform well with workloads where each node writes almost exclusively to a particular set of files that are not shared with other nodes or where a set of files is shared in an almost exclusively read-only manner across a set of nodes. This results in a minimum of cross-node cache invalidation and can maximize performance.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tSetting up a shared disk file system is complex, and tuning an application to perform well on a shared disk file system can be challenging.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Available shared storage file systems\u003C/span>\u003C/dt>\u003Cdd>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tRed Hat Enterprise Linux provides the GFS2 file system. GFS2 comes tightly integrated with the Red Hat Enterprise Linux High Availability Add-On and the Resilient Storage Add-On.\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tRed Hat Enterprise Linux supports GFS2 on clusters that range in size from 2 to 16 nodes.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003C/dl>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"choosing-between-network-and-shared-storage-file-systems_overview-of-available-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">1.9. Choosing between network and shared storage file systems\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tWhen choosing between network and shared storage file systems, consider the following points:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tNFS-based network file systems are an extremely common and popular choice for environments that provide NFS servers.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tNetwork file systems can be deployed using very high-performance networking technologies like Infiniband or 10 Gigabit Ethernet. This means that you should not turn to shared storage file systems just to get raw bandwidth to your storage. If the speed of access is of prime importance, then use NFS to export a local file system like XFS.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tShared storage file systems are not easy to set up or to maintain, so you should deploy them only when you cannot provide your required availability with either local or network file systems.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tA shared storage file system in a clustered environment helps reduce downtime by eliminating the steps needed for unmounting and mounting that need to be done during a typical fail-over scenario involving the relocation of a high-availability service.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tRed Hat recommends that you use network file systems unless you have a specific use case for shared storage file systems. Use shared storage file systems primarily for deployments that need to provide high-availability services with minimum downtime and have stringent service-level requirements.\n\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"volume-managing-file-systems_overview-of-available-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">1.10. Volume-managing file systems\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tVolume-managing file systems integrate the entire storage stack for the purposes of simplicity and in-stack optimization.\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">Available volume-managing file systems\u003C/span>\u003C/dt>\u003Cdd>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tRed Hat Enterprise Linux 9 provides the Stratis volume manager. Stratis uses XFS for the file system layer and integrates it with LVM, Device Mapper, and other components.\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tStratis was first released in Red Hat Enterprise Linux 8.0. It is conceived to fill the gap created when Red Hat deprecated Btrfs. Stratis 1.0 is an intuitive, command line-based volume manager that can perform significant storage management operations while hiding the complexity from the user:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tVolume management\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tPool creation\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tThin storage pools\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tSnapshots\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tAutomated read cache\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tStratis offers powerful features, but currently lacks certain capabilities of other offerings that it might be compared to, such as Btrfs or ZFS. Most notably, it does not support CRCs with self healing.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003C/dl>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"managing-local-storage-using-rhel-system-roles_managing-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 2. Managing local storage by using the RHEL system role\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tTo manage LVM and local file systems (FS) by using Ansible, you can use the \u003Ccode class=\"literal\">storage\u003C/code> role, which is one of the RHEL system roles available in RHEL 9.\n\t\t\u003C/p>\u003Cp>\n\t\t\tUsing the \u003Ccode class=\"literal\">storage\u003C/code> role enables you to automate administration of file systems on disks and logical volumes on multiple machines and across all versions of RHEL starting with RHEL 7.7.\n\t\t\u003C/p>\u003Cp>\n\t\t\tFor more information about RHEL system roles and how to apply them, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/intro-to-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles\">Introduction to RHEL system roles\u003C/a>.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"storage-role-intro_managing-local-storage-using-rhel-system-roles\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">2.1. Introduction to the \u003Ccode class=\"literal\">storage\u003C/code> RHEL system role\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe \u003Ccode class=\"literal\">storage\u003C/code> role can manage:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tFile systems on disks which have not been partitioned\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tComplete LVM volume groups including their logical volumes and file systems\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tMD RAID volumes and their file systems\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tWith the \u003Ccode class=\"literal\">storage\u003C/code> role, you can perform the following tasks:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tCreate a file system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tRemove a file system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tMount a file system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tUnmount a file system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tCreate LVM volume groups\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tRemove LVM volume groups\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tCreate logical volumes\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tRemove logical volumes\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tCreate RAID volumes\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tRemove RAID volumes\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tCreate LVM volume groups with RAID\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tRemove LVM volume groups with RAID\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tCreate encrypted LVM volume groups\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tCreate LVM logical volumes with RAID\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/ansible/roles/rhel-system-roles.storage/README.md\u003C/code> file\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/doc/rhel-system-roles/storage/\u003C/code> directory\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"an-example-ansible-playbook-to-create-an-xfs-file-system_managing-local-storage-using-rhel-system-roles\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">2.2. Creating an XFS file system on a block device by using the \u003Ccode class=\"literal\">storage\u003C/code> RHEL system role\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tThe example Ansible playbook applies the \u003Ccode class=\"literal\">storage\u003C/code> role to create an XFS file system on a block device using the default parameters.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tThe \u003Ccode class=\"literal\">storage\u003C/code> role can create a file system only on an unpartitioned, whole disk or a logical volume (LV). It cannot create the file system on a partition.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles\">You have prepared the control node and the managed nodes\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou are logged in to the control node as a user who can run playbooks on the managed nodes.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe account you use to connect to the managed nodes has \u003Ccode class=\"literal\">sudo\u003C/code> permissions on them.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a playbook file, for example \u003Ccode class=\"literal\">~/playbook.yml\u003C/code>, with the following content:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"programlisting language-yaml\">---\n- hosts: managed-node-01.example.com\n  roles:\n    - rhel-system-roles.storage\n  vars:\n    storage_volumes:\n      - name: barefs\n        type: disk\n        disks:\n          - sdb\n        fs_type: xfs\u003C/pre>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe volume name (\u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>barefs\u003C/em>\u003C/span>\u003C/code> in the example) is currently arbitrary. The \u003Ccode class=\"literal\">storage\u003C/code> role identifies the volume by the disk device listed under the \u003Ccode class=\"literal\">disks:\u003C/code> attribute.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tYou can omit the \u003Ccode class=\"literal\">fs_type: xfs\u003C/code> line because XFS is the default file system in RHEL 9.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tTo create the file system on an LV, provide the LVM setup under the \u003Ccode class=\"literal\">disks:\u003C/code> attribute, including the enclosing volume group. For details, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_logical_volumes/managing-lvm-logical-volumes_configuring-and-managing-logical-volumes#an-example-playbook-to-manage-logical-volumes_managing-lvm-logical-volumes-using-rhel-system-roles\">Managing logical volumes by using the storage RHEL system role\u003C/a>.\n\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tDo not provide the path to the LV device.\n\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tValidate the playbook syntax:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-playbook --syntax-check ~/playbook.yml\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tNote that this command only validates the syntax and does not protect against a wrong but valid configuration.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRun the playbook:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-playbook ~/playbook.yml\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/ansible/roles/rhel-system-roles.storage/README.md\u003C/code> file\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/doc/rhel-system-roles/storage/\u003C/code> directory\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"an-example-ansible-playbook-to-persistently-mount-a-file-system_managing-local-storage-using-rhel-system-roles\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">2.3. Persistently mounting a file system by using the \u003Ccode class=\"literal\">storage\u003C/code> RHEL system role\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tThe example Ansible applies the \u003Ccode class=\"literal\">storage\u003C/code> role to immediately and persistently mount an XFS file system.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles\">You have prepared the control node and the managed nodes\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou are logged in to the control node as a user who can run playbooks on the managed nodes.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe account you use to connect to the managed nodes has \u003Ccode class=\"literal\">sudo\u003C/code> permissions on them.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a playbook file, for example \u003Ccode class=\"literal\">~/playbook.yml\u003C/code>, with the following content:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"programlisting language-yaml\">---\n- hosts: managed-node-01.example.com\n  roles:\n    - rhel-system-roles.storage\n  vars:\n    storage_volumes:\n      - name: barefs\n        type: disk\n        disks:\n          - sdb\n        fs_type: xfs\n        mount_point: /mnt/data\n        mount_user: somebody\n        mount_group: somegroup\n        mount_mode: 0755\u003C/pre>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThis playbook adds the file system to the \u003Ccode class=\"literal\">/etc/fstab\u003C/code> file, and mounts the file system immediately.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tIf the file system on the \u003Ccode class=\"literal\">/dev/sdb\u003C/code> device or the mount point directory do not exist, the playbook creates them.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tValidate the playbook syntax:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-playbook --syntax-check ~/playbook.yml\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tNote that this command only validates the syntax and does not protect against a wrong but valid configuration.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRun the playbook:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-playbook ~/playbook.yml\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/ansible/roles/rhel-system-roles.storage/README.md\u003C/code> file\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/doc/rhel-system-roles/storage/\u003C/code> directory\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"an-example-playbook-to-manage-logical-volumes_managing-local-storage-using-rhel-system-roles\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">2.4. Managing logical volumes by using the \u003Ccode class=\"literal\">storage\u003C/code> RHEL system role\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tThe example Ansible playbook applies the \u003Ccode class=\"literal\">storage\u003C/code> role to create an LVM logical volume in a volume group.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles\">You have prepared the control node and the managed nodes\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou are logged in to the control node as a user who can run playbooks on the managed nodes.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe account you use to connect to the managed nodes has \u003Ccode class=\"literal\">sudo\u003C/code> permissions on them.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a playbook file, for example \u003Ccode class=\"literal\">~/playbook.yml\u003C/code>, with the following content:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"programlisting language-yaml\">- hosts: managed-node-01.example.com\n  roles:\n    - rhel-system-roles.storage\n  vars:\n    storage_pools:\n      - name: myvg\n        disks:\n          - sda\n          - sdb\n          - sdc\n        volumes:\n          - name: mylv\n            size: 2G\n            fs_type: ext4\n            mount_point: /mnt/dat\u003C/pre>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">myvg\u003C/code> volume group consists of the following disks: \u003Ccode class=\"literal\">/dev/sda\u003C/code>, \u003Ccode class=\"literal\">/dev/sdb\u003C/code>, and \u003Ccode class=\"literal\">/dev/sdc\u003C/code>.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tIf the \u003Ccode class=\"literal\">myvg\u003C/code> volume group already exists, the playbook adds the logical volume to the volume group.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tIf the \u003Ccode class=\"literal\">myvg\u003C/code> volume group does not exist, the playbook creates it.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe playbook creates an Ext4 file system on the \u003Ccode class=\"literal\">mylv\u003C/code> logical volume, and persistently mounts the file system at \u003Ccode class=\"literal\">/mnt\u003C/code>.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tValidate the playbook syntax:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-playbook --syntax-check ~/playbook.yml\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tNote that this command only validates the syntax and does not protect against a wrong but valid configuration.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRun the playbook:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-playbook ~/playbook.yml\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/ansible/roles/rhel-system-roles.storage/README.md\u003C/code> file\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/doc/rhel-system-roles/storage/\u003C/code> directory\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"an-example-ansible-playbook-to-enable-online-block-discard_managing-local-storage-using-rhel-system-roles\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">2.5. Enabling online block discard by using the \u003Ccode class=\"literal\">storage\u003C/code> RHEL system role\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tThe example Ansible playbook applies the \u003Ccode class=\"literal\">storage\u003C/code> role to mount an XFS file system with online block discard enabled.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles\">You have prepared the control node and the managed nodes\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou are logged in to the control node as a user who can run playbooks on the managed nodes.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe account you use to connect to the managed nodes has \u003Ccode class=\"literal\">sudo\u003C/code> permissions on them.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a playbook file, for example \u003Ccode class=\"literal\">~/playbook.yml\u003C/code>, with the following content:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"programlisting language-yaml\">---\n- hosts: managed-node-01.example.com\n  roles:\n    - rhel-system-roles.storage\n  vars:\n    storage_volumes:\n      - name: barefs\n        type: disk\n        disks:\n          - sdb\n        fs_type: xfs\n        mount_point: /mnt/data\n        mount_options: discard\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tValidate the playbook syntax:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-playbook --syntax-check ~/playbook.yml\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tNote that this command only validates the syntax and does not protect against a wrong but valid configuration.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRun the playbook:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-playbook ~/playbook.yml\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/ansible/roles/rhel-system-roles.storage/README.md\u003C/code> file\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/doc/rhel-system-roles/storage/\u003C/code> directory\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"an-example-playbook-to-create-mount-an-ext4-file-system_managing-local-storage-using-rhel-system-roles\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">2.6. Creating and mounting an Ext4 file system by using the \u003Ccode class=\"literal\">storage\u003C/code> RHEL system role\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tThe example Ansible playbook applies the \u003Ccode class=\"literal\">storage\u003C/code> role to create and mount an Ext4 file system.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles\">You have prepared the control node and the managed nodes\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou are logged in to the control node as a user who can run playbooks on the managed nodes.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe account you use to connect to the managed nodes has \u003Ccode class=\"literal\">sudo\u003C/code> permissions on them.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a playbook file, for example \u003Ccode class=\"literal\">~/playbook.yml\u003C/code>, with the following content:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"programlisting language-yaml\">---\n- hosts: managed-node-01.example.com\n  roles:\n    - rhel-system-roles.storage\n  vars:\n    storage_volumes:\n      - name: barefs\n        type: disk\n        disks:\n          - sdb\n        fs_type: ext4\n        fs_label: label-name\n        mount_point: /mnt/data\u003C/pre>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe playbook creates the file system on the \u003Ccode class=\"literal\">/dev/sdb\u003C/code> disk.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe playbook persistently mounts the file system at the \u003Ccode class=\"literal\">/mnt/data\u003C/code> directory.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe label of the file system is \u003Ccode class=\"literal\">label-name\u003C/code>.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tValidate the playbook syntax:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-playbook --syntax-check ~/playbook.yml\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tNote that this command only validates the syntax and does not protect against a wrong but valid configuration.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRun the playbook:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-playbook ~/playbook.yml\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/ansible/roles/rhel-system-roles.storage/README.md\u003C/code> file\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/doc/rhel-system-roles/storage/\u003C/code> directory\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"an-example-ansible-playbook-to-create-mount-ext3-file-system_managing-local-storage-using-rhel-system-roles\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">2.7. Creating and mounting an Ext3 file system by using the \u003Ccode class=\"literal\">storage\u003C/code> RHEL system role\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tThe example Ansible playbook applies the \u003Ccode class=\"literal\">storage\u003C/code> role to create and mount an Ext3 file system.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles\">You have prepared the control node and the managed nodes\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou are logged in to the control node as a user who can run playbooks on the managed nodes.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe account you use to connect to the managed nodes has \u003Ccode class=\"literal\">sudo\u003C/code> permissions on them.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a playbook file, for example \u003Ccode class=\"literal\">~/playbook.yml\u003C/code>, with the following content:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"programlisting language-yaml\">---\n- hosts: all\n  roles:\n    - rhel-system-roles.storage\n  vars:\n    storage_volumes:\n      - name: barefs\n        type: disk\n        disks:\n          - sdb\n        fs_type: ext3\n        fs_label: label-name\n        mount_point: /mnt/data\n        mount_user: somebody\n        mount_group: somegroup\n        mount_mode: 0755\u003C/pre>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe playbook creates the file system on the \u003Ccode class=\"literal\">/dev/sdb\u003C/code> disk.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe playbook persistently mounts the file system at the \u003Ccode class=\"literal\">/mnt/data\u003C/code> directory.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe label of the file system is \u003Ccode class=\"literal\">label-name\u003C/code>.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tValidate the playbook syntax:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-playbook --syntax-check ~/playbook.yml\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tNote that this command only validates the syntax and does not protect against a wrong but valid configuration.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRun the playbook:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-playbook ~/playbook.yml\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/ansible/roles/rhel-system-roles.storage/README.md\u003C/code> file\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/doc/rhel-system-roles/storage/\u003C/code> directory\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"example-ansible-playbook-to-resize-an-existing-lvm-file-system-using-the-storage-rhel-system-role_managing-local-storage-using-rhel-system-roles\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">2.8. Resizing an existing file system on LVM by using the \u003Ccode class=\"literal\">storage\u003C/code> RHEL system role\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tThe example Ansible playbook applies the \u003Ccode class=\"literal\">storage\u003C/code> RHEL system role to resize an LVM logical volume with a file system.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles\">You have prepared the control node and the managed nodes\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou are logged in to the control node as a user who can run playbooks on the managed nodes.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe account you use to connect to the managed nodes has \u003Ccode class=\"literal\">sudo\u003C/code> permissions on them.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a playbook file, for example \u003Ccode class=\"literal\">~/playbook.yml\u003C/code>, with the following content:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"programlisting language-yaml\">---\n- name: Create LVM pool over three disks\n  hosts: managed-node-01.example.com\n  tasks:\n    - name: Resize LVM logical volume with file system\n      ansible.builtin.include_role:\n        name: rhel-system-roles.storage\n      vars:\n        storage_pools:\n          - name: myvg\n            disks:\n              - /dev/sda\n              - /dev/sdb\n              - /dev/sdc\n            volumes:\n              - name: mylv1\n                size: 10 GiB\n                fs_type: ext4\n                mount_point: /opt/mount1\n              - name: mylv2\n                size: 50 GiB\n                fs_type: ext4\n                mount_point: /opt/mount2\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThis playbook resizes the following existing file systems:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe Ext4 file system on the \u003Ccode class=\"literal\">mylv1\u003C/code> volume, which is mounted at \u003Ccode class=\"literal\">/opt/mount1\u003C/code>, resizes to 10 GiB.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe Ext4 file system on the \u003Ccode class=\"literal\">mylv2\u003C/code> volume, which is mounted at \u003Ccode class=\"literal\">/opt/mount2\u003C/code>, resizes to 50 GiB.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tValidate the playbook syntax:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-playbook --syntax-check ~/playbook.yml\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tNote that this command only validates the syntax and does not protect against a wrong but valid configuration.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRun the playbook:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-playbook ~/playbook.yml\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/ansible/roles/rhel-system-roles.storage/README.md\u003C/code> file\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/doc/rhel-system-roles/storage/\u003C/code> directory\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"example-ansible-playbook-to-create-a-swap-partition-using-the-storage-rhel-system-role_managing-local-storage-using-rhel-system-roles\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">2.9. Creating a swap volume by using the \u003Ccode class=\"literal\">storage\u003C/code> RHEL system role\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tThis section provides an example Ansible playbook. This playbook applies the \u003Ccode class=\"literal\">storage\u003C/code> role to create a swap volume, if it does not exist, or to modify the swap volume, if it already exist, on a block device by using the default parameters.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles\">You have prepared the control node and the managed nodes\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou are logged in to the control node as a user who can run playbooks on the managed nodes.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe account you use to connect to the managed nodes has \u003Ccode class=\"literal\">sudo\u003C/code> permissions on them.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a playbook file, for example \u003Ccode class=\"literal\">~/playbook.yml\u003C/code>, with the following content:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"programlisting language-yaml\">---\n- name: Create a disk device with swap\n  hosts: managed-node-01.example.com\n  roles:\n    - rhel-system-roles.storage\n  vars:\n    storage_volumes:\n      - name: swap_fs\n        type: disk\n        disks:\n          - /dev/sdb\n        size: 15 GiB\n        fs_type: swap\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe volume name (\u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>swap_fs\u003C/em>\u003C/span>\u003C/code> in the example) is currently arbitrary. The \u003Ccode class=\"literal\">storage\u003C/code> role identifies the volume by the disk device listed under the \u003Ccode class=\"literal\">disks:\u003C/code> attribute.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tValidate the playbook syntax:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-playbook --syntax-check ~/playbook.yml\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tNote that this command only validates the syntax and does not protect against a wrong but valid configuration.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRun the playbook:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-playbook ~/playbook.yml\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/ansible/roles/rhel-system-roles.storage/README.md\u003C/code> file\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/doc/rhel-system-roles/storage/\u003C/code> directory\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"configuring-a-raid-volume-using-the-storage-system-role_managing-local-storage-using-rhel-system-roles\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">2.10. Configuring a RAID volume by using the \u003Ccode class=\"literal\">storage\u003C/code> RHEL system role\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tWith the \u003Ccode class=\"literal\">storage\u003C/code> system role, you can configure a RAID volume on RHEL by using Red Hat Ansible Automation Platform and Ansible-Core. Create an Ansible playbook with the parameters to configure a RAID volume to suit your requirements.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition warning\" state=\"danger\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Warning\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tDevice names might change in certain circumstances, for example, when you add a new disk to a system. Therefore, to prevent data loss, do not use specific disk names in the playbook.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles\">You have prepared the control node and the managed nodes\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou are logged in to the control node as a user who can run playbooks on the managed nodes.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe account you use to connect to the managed nodes has \u003Ccode class=\"literal\">sudo\u003C/code> permissions on them.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a playbook file, for example \u003Ccode class=\"literal\">~/playbook.yml\u003C/code>, with the following content:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"programlisting language-yaml\">---\n- name: Configure the storage\n  hosts: managed-node-01.example.com\n  tasks:\n    - name: Create a RAID on sdd, sde, sdf, and sdg\n      ansible.builtin.include_role:\n        name: rhel-system-roles.storage\n      vars:\n        storage_safe_mode: false\n        storage_volumes:\n          - name: data\n            type: raid\n            disks: [sdd, sde, sdf, sdg]\n            raid_level: raid0\n            raid_chunk_size: 32 KiB\n            mount_point: /mnt/data\n            state: present\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tValidate the playbook syntax:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-playbook --syntax-check ~/playbook.yml\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tNote that this command only validates the syntax and does not protect against a wrong but valid configuration.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRun the playbook:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-playbook ~/playbook.yml\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/ansible/roles/rhel-system-roles.storage/README.md\u003C/code> file\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/doc/rhel-system-roles/storage/\u003C/code> directory\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"configuring-lvm-pool-with-raid-using-storage-system-role_managing-local-storage-using-rhel-system-roles\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">2.11. Configuring an LVM pool with RAID by using the \u003Ccode class=\"literal\">storage\u003C/code> RHEL system role\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tWith the \u003Ccode class=\"literal\">storage\u003C/code> system role, you can configure an LVM pool with RAID on RHEL by using Red Hat Ansible Automation Platform. You can set up an Ansible playbook with the available parameters to configure an LVM pool with RAID.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles\">You have prepared the control node and the managed nodes\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou are logged in to the control node as a user who can run playbooks on the managed nodes.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe account you use to connect to the managed nodes has \u003Ccode class=\"literal\">sudo\u003C/code> permissions on them.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a playbook file, for example \u003Ccode class=\"literal\">~/playbook.yml\u003C/code>, with the following content:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"programlisting language-yaml\">---\n- name: Configure LVM pool with RAID\n  hosts: managed-node-01.example.com\n  roles:\n    - rhel-system-roles.storage\n  vars:\n    storage_safe_mode: false\n    storage_pools:\n      - name: my_pool\n        type: lvm\n        disks: [sdh, sdi]\n        raid_level: raid1\n        volumes:\n          - name: my_volume\n            size: \"1 GiB\"\n            mount_point: \"/mnt/app/shared\"\n            fs_type: xfs\n            state: present\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo create an LVM pool with RAID, you must specify the RAID type by using the \u003Ccode class=\"literal\">raid_level\u003C/code> parameter.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tValidate the playbook syntax:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-playbook --syntax-check ~/playbook.yml\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tNote that this command only validates the syntax and does not protect against a wrong but valid configuration.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRun the playbook:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-playbook ~/playbook.yml\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/ansible/roles/rhel-system-roles.storage/README.md\u003C/code> file\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/doc/rhel-system-roles/storage/\u003C/code> directory\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_storage_devices/index#managing-raid_managing-storage-devices\">Managing RAID\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"configuring-a-stripe-size-for-raid-lvm-system-role_managing-local-storage-using-rhel-system-roles\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">2.12. Configuring a stripe size for RAID LVM volumes by using the \u003Ccode class=\"literal\">storage\u003C/code> RHEL system role\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tWith the \u003Ccode class=\"literal\">storage\u003C/code> system role, you can configure a stripe size for RAID LVM volumes on RHEL by using Red Hat Ansible Automation Platform. You can set up an Ansible playbook with the available parameters to configure an LVM pool with RAID.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles\">You have prepared the control node and the managed nodes\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou are logged in to the control node as a user who can run playbooks on the managed nodes.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe account you use to connect to the managed nodes has \u003Ccode class=\"literal\">sudo\u003C/code> permissions on them.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a playbook file, for example \u003Ccode class=\"literal\">~/playbook.yml\u003C/code>, with the following content:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"programlisting language-yaml\">---\n- name: Configure stripe size for RAID LVM volumes\n  hosts: managed-node-01.example.com\n  roles:\n    - rhel-system-roles.storage\n  vars:\n    storage_safe_mode: false\n    storage_pools:\n      - name: my_pool\n        type: lvm\n        disks: [sdh, sdi]\n        volumes:\n          - name: my_volume\n            size: \"1 GiB\"\n            mount_point: \"/mnt/app/shared\"\n            fs_type: xfs\n            raid_level: raid1\n            raid_stripe_size: \"256 KiB\"\n            state: present\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tValidate the playbook syntax:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-playbook --syntax-check ~/playbook.yml\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tNote that this command only validates the syntax and does not protect against a wrong but valid configuration.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRun the playbook:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-playbook ~/playbook.yml\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/ansible/roles/rhel-system-roles.storage/README.md\u003C/code> file\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/doc/rhel-system-roles/storage/\u003C/code> directory\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux//9/html-single/managing_storage_devices/index#managing-raid_managing-storage-devices\">Managing RAID\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"example-ansible-playbook-to-compress-and-deduplicate-a-vdo-volume-on-lvm-using-the-storage-rhel-system-role_managing-local-storage-using-rhel-system-roles\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">2.13. Compressing and deduplicating a VDO volume on LVM by using the \u003Ccode class=\"literal\">storage\u003C/code> RHEL system role\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tThe example Ansible playbook applies the \u003Ccode class=\"literal\">storage\u003C/code> RHEL system role to enable compression and deduplication of Logical Volumes (LVM) by using Virtual Data Optimizer (VDO).\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tBecause of the \u003Ccode class=\"literal\">storage\u003C/code> system role use of LVM VDO, only one volume per pool can use the compression and deduplication.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles\">You have prepared the control node and the managed nodes\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou are logged in to the control node as a user who can run playbooks on the managed nodes.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe account you use to connect to the managed nodes has \u003Ccode class=\"literal\">sudo\u003C/code> permissions on them.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a playbook file, for example \u003Ccode class=\"literal\">~/playbook.yml\u003C/code>, with the following content:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"programlisting language-yaml\">- name: Create LVM VDO volume under volume group 'myvg'\n  hosts: managed-node-01.example.com\n  roles:\n    - rhel-system-roles.storage\n  vars:\n    storage_pools:\n      - name: myvg\n        disks:\n          - /dev/sdb\n        volumes:\n          - name: mylv1\n            compression: true\n            deduplication: true\n            vdo_pool_size: 10 GiB\n            size: 30 GiB\n            mount_point: /mnt/app/shared\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn this example, the \u003Ccode class=\"literal\">compression\u003C/code> and \u003Ccode class=\"literal\">deduplication\u003C/code> pools are set to true, which specifies that the VDO is used. The following describes the usage of these parameters:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">deduplication\u003C/code> is used to deduplicate the duplicated data stored on the storage volume.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe compression is used to compress the data stored on the storage volume, which results in more storage capacity.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe vdo_pool_size specifies the actual size the volume takes on the device. The virtual size of VDO volume is set by the \u003Ccode class=\"literal\">size\u003C/code> parameter.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tValidate the playbook syntax:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-playbook --syntax-check ~/playbook.yml\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tNote that this command only validates the syntax and does not protect against a wrong but valid configuration.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRun the playbook:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-playbook ~/playbook.yml\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/ansible/roles/rhel-system-roles.storage/README.md\u003C/code> file\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/doc/rhel-system-roles/storage/\u003C/code> directory\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"creating-a-luks2-encrypted-volume-using-the-storage-role_managing-local-storage-using-rhel-system-roles\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">2.14. Creating a LUKS2 encrypted volume by using the \u003Ccode class=\"literal\">storage\u003C/code> RHEL system role\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tYou can use the \u003Ccode class=\"literal\">storage\u003C/code> role to create and configure a volume encrypted with LUKS by running an Ansible playbook.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles\">You have prepared the control node and the managed nodes\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou are logged in to the control node as a user who can run playbooks on the managed nodes.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe account you use to connect to the managed nodes has \u003Ccode class=\"literal\">sudo\u003C/code> permissions on them.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a playbook file, for example \u003Ccode class=\"literal\">~/playbook.yml\u003C/code>, with the following content:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"programlisting language-yaml\">---\n- name: Create and configure a volume encrypted with LUKS\n  hosts: managed-node-01.example.com\n  roles:\n    - rhel-system-roles.storage\n  vars:\n    storage_volumes:\n      - name: barefs\n        type: disk\n        disks:\n         \u003Cspan class=\"emphasis\">\u003Cem>- sdb\u003C/em>\u003C/span>\n        fs_type: xfs\n        fs_label: label-name\n        mount_point: /mnt/data\n        encryption: true\n        encryption_password: \u003Cspan class=\"emphasis\">\u003Cem>&lt;password&gt;\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tYou can also add other encryption parameters, such as \u003Ccode class=\"literal\">encryption_key\u003C/code>, \u003Ccode class=\"literal\">encryption_cipher\u003C/code>, \u003Ccode class=\"literal\">encryption_key_size\u003C/code>, and \u003Ccode class=\"literal\">encryption_luks\u003C/code>, to the playbook file.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tValidate the playbook syntax:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-playbook --syntax-check ~/playbook.yml\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tNote that this command only validates the syntax and does not protect against a wrong but valid configuration.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRun the playbook:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-playbook ~/playbook.yml\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tView the encryption status:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>cryptsetup status sdb\u003C/strong>\u003C/span>\n\n/dev/mapper/sdb is active and is in use.\ntype: LUKS2\ncipher: aes-xts-plain64\nkeysize: 512 bits\nkey location: keyring\ndevice: /dev/sdb\n...\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify the created LUKS encrypted volume:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>cryptsetup luksDump /dev/sdb\u003C/strong>\u003C/span>\n\nVersion:        2\nEpoch:          6\nMetadata area:  16384 [bytes]\nKeyslots area:  33521664 [bytes]\nUUID:           a4c6be82-7347-4a91-a8ad-9479b72c9426\nLabel:          (no label)\nSubsystem:      (no subsystem)\nFlags:          allow-discards\n\nData segments:\n  0: crypt\n        offset: 33554432 [bytes]\n        length: (whole device)\n        cipher: aes-xts-plain64\n        sector: 4096 [bytes]\n...\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/ansible/roles/rhel-system-roles.storage/README.md\u003C/code> file\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/doc/rhel-system-roles/storage/\u003C/code> directory\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_storage_devices/encrypting-block-devices-using-luks_managing-storage-devices\">Encrypting block devices by using LUKS\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"example-ansible-playbook-to-express-pool-volume-sizes-as-percentage-using-the-storage-rhel-system-role_managing-local-storage-using-rhel-system-roles\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">2.15. Expressing pool volume sizes as percentage by using the \u003Ccode class=\"literal\">storage\u003C/code> RHEL system role\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tThe example Ansible playbook applies the \u003Ccode class=\"literal\">storage\u003C/code> system role to enable you to express Logical Manager Volumes (LVM) volume sizes as a percentage of the pool’s total size.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles\">You have prepared the control node and the managed nodes\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou are logged in to the control node as a user who can run playbooks on the managed nodes.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe account you use to connect to the managed nodes has \u003Ccode class=\"literal\">sudo\u003C/code> permissions on them.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a playbook file, for example \u003Ccode class=\"literal\">~/playbook.yml\u003C/code>, with the following content:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"programlisting language-yaml\">---\n- name: Express volume sizes as a percentage of the pool's total size\n  hosts: managed-node-01.example.com\n  roles:\n    - rhel-system-roles.storage\n  vars:\n    storage_pools:\n      - name: myvg\n        disks:\n          - /dev/sdb\n        volumes:\n          - name: data\n            size: 60%\n            mount_point: /opt/mount/data\n          - name: web\n            size: 30%\n            mount_point: /opt/mount/web\n          - name: cache\n            size: 10%\n            mount_point: /opt/cache/mount\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThis example specifies the size of LVM volumes as a percentage of the pool size, for example: \u003Ccode class=\"literal\">60%\u003C/code>. Alternatively, you can also specify the size of LVM volumes as a percentage of the pool size in a human-readable size of the file system, for example, \u003Ccode class=\"literal\">10g\u003C/code> or \u003Ccode class=\"literal\">50 GiB\u003C/code>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tValidate the playbook syntax:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-playbook --syntax-check ~/playbook.yml\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tNote that this command only validates the syntax and does not protect against a wrong but valid configuration.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRun the playbook:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-playbook ~/playbook.yml\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/ansible/roles/rhel-system-roles.storage/README.md\u003C/code> file\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/doc/rhel-system-roles/storage/\u003C/code> directory\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"managing-partitions-using-the-web-console_managing-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 3. Managing partitions using the web console\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\tLearn how to manage file systems on RHEL 9 using the web console.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"displaying-partitions-in-the-web-console_managing-partitions-using-the-web-console\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">3.1. Displaying partitions formatted with file systems in the web console\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe \u003Cspan class=\"strong strong\">\u003Cstrong>Storage\u003C/strong>\u003C/span> section in the web console displays all available file systems in the \u003Cspan class=\"strong strong\">\u003Cstrong>Filesystems\u003C/strong>\u003C/span> table.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tBesides the list of partitions formatted with file systems, you can also use the page for creating new storage.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">cockpit-storaged\u003C/code> package is installed on your system.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tYou have installed the RHEL 9 web console.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor instructions, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console\">Installing and enabling the web console\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tLog in to the RHEL 9 web console.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor details, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#logging-in-to-the-web-console_getting-started-with-the-rhel-9-web-console\">Logging in to the web console\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tClick the \u003Cspan class=\"strong strong\">\u003Cstrong>Storage\u003C/strong>\u003C/span> tab.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Storage\u003C/strong>\u003C/span> table, you can see all available partitions formatted with file systems, their ID, types, locations, sizes, and how much space is available on each partition.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/6cce358f149ba8380d3757567290d6ad/cockpit-filesystems-partitions.png\" alt=\"Image displaying the Storage table available in the cockpit Storage tab.\"/>\u003C/span>\n\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tYou can also use the drop-down menu in the top-right corner to create new local or networked storage.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/7609a2256402ee69664a842137ff6964/cockpit-adding-volume-groups.png\" alt=\"Image displaying the drop-down menu available in the Storage table.\"/>\u003C/span>\n\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"creating-partitions-in-the-web-console_managing-partitions-using-the-web-console\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">3.2. Creating partitions in the web console\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tTo create a new partition:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tUse an existing partition table\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tCreate a partition\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">cockpit-storaged\u003C/code> package is installed on your system.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe web console must be installed and accessible. For details, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console\">Installing the web console\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tAn unformatted volume connected to the system is visible in the \u003Cspan class=\"strong strong\">\u003Cstrong>Storage\u003C/strong>\u003C/span> table of the \u003Cspan class=\"strong strong\">\u003Cstrong>Storage\u003C/strong>\u003C/span> tab.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tLog in to the RHEL 9 web console.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor details, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#logging-in-to-the-web-console_getting-started-with-the-rhel-9-web-console\">Logging in to the web console\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick the \u003Cspan class=\"strong strong\">\u003Cstrong>Storage\u003C/strong>\u003C/span> tab.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Storage\u003C/strong>\u003C/span> table, click the device which you want to partition to open the page and options for that device.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tOn the device page, click the menu button, \u003Cspan class=\"guibutton\">⋮\u003C/span>, and select \u003Cspan class=\"strong strong\">\u003Cstrong>Create partition table\u003C/strong>\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Initialize disk\u003C/strong>\u003C/span> dialog box, select the following:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>Partitioning\u003C/strong>\u003C/span>:\n\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\tCompatible with all systems and devices (MBR)\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\tCompatible with modern system and hard disks &gt; 2TB (GPT)\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\tNo partitioning\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>Overwrite\u003C/strong>\u003C/span>:\n\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\tSelect the \u003Cspan class=\"strong strong\">\u003Cstrong>Overwrite existing data with zeros\u003C/strong>\u003C/span> checkbox if you want the RHEL web console to rewrite the whole disk with zeros. This option is slower because the program has to go through the whole disk, but it is more secure. Use this option if the disk includes any data and you need to overwrite it.\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\tIf you do not select the \u003Cspan class=\"strong strong\">\u003Cstrong>Overwrite existing data with zeros\u003C/strong>\u003C/span> checkbox, the RHEL web console rewrites only the disk header. This increases the speed of formatting.\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick \u003Cspan class=\"guibutton\">Initialize\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick the menu button, \u003Cspan class=\"guibutton\">⋮\u003C/span>, next to the partition table you created. It is named \u003Cspan class=\"strong strong\">\u003Cstrong>Free space\u003C/strong>\u003C/span> by default.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick \u003Cspan class=\"guibutton\">Create partition\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Create partition\u003C/strong>\u003C/span> dialog box, enter a \u003Cspan class=\"strong strong\">\u003Cstrong>Name\u003C/strong>\u003C/span> for the file system.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tAdd a \u003Cspan class=\"strong strong\">\u003Cstrong>Mount point\u003C/strong>\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Type\u003C/strong>\u003C/span> drop-down menu, select a file system:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>XFS\u003C/strong>\u003C/span> file system supports large logical volumes, switching physical drives online without outage, and growing an existing file system. Leave this file system selected if you do not have a different strong preference.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>ext4\u003C/strong>\u003C/span> file system supports:\n\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\tLogical volumes\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\tSwitching physical drives online without outage\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\tGrowing a file system\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\tShrinking a file system\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAdditional option is to enable encryption of partition done by LUKS (Linux Unified Key Setup), which allows you to encrypt the volume with a passphrase.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tEnter the \u003Cspan class=\"strong strong\">\u003Cstrong>Size\u003C/strong>\u003C/span> of the volume you want to create.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tSelect the \u003Cspan class=\"strong strong\">\u003Cstrong>Overwrite existing data with zeros\u003C/strong>\u003C/span> checkbox if you want the RHEL web console to rewrite the whole disk with zeros. This option is slower because the program has to go through the whole disk, but it is more secure. Use this option if the disk includes any data and you need to overwrite it.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIf you do not select the \u003Cspan class=\"strong strong\">\u003Cstrong>Overwrite existing data with zeros\u003C/strong>\u003C/span> checkbox, the RHEL web console rewrites only the disk header. This increases the speed of formatting.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIf you want to encrypt the volume, select the type of encryption in the \u003Cspan class=\"strong strong\">\u003Cstrong>Encryption\u003C/strong>\u003C/span> drop-down menu.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIf you do not want to encrypt the volume, select \u003Cspan class=\"strong strong\">\u003Cstrong>No encryption\u003C/strong>\u003C/span>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>At boot\u003C/strong>\u003C/span> drop-down menu, select when you want to mount the volume.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn \u003Cspan class=\"strong strong\">\u003Cstrong>Mount options\u003C/strong>\u003C/span> section:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tSelect the \u003Cspan class=\"strong strong\">\u003Cstrong>Mount read only\u003C/strong>\u003C/span> checkbox if you want the to mount the volume as a read-only logical volume.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tSelect the \u003Cspan class=\"strong strong\">\u003Cstrong>Custom mount options\u003C/strong>\u003C/span> checkbox and add the mount options if you want to change the default mount option.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate the partition:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tIf you want to create and mount the partition, click the \u003Cspan class=\"guibutton\">Create and mount\u003C/span> button.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tIf you want to only create the partition, click the \u003Cspan class=\"guibutton\">Create only\u003C/span> button.\n\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tFormatting can take several minutes depending on the volume size and which formatting options are selected.\n\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tTo verify that the partition has been successfully added, switch to the \u003Cspan class=\"strong strong\">\u003Cstrong>Storage\u003C/strong>\u003C/span> tab and check the \u003Cspan class=\"strong strong\">\u003Cstrong>Storage\u003C/strong>\u003C/span> table and verify whether the new partition is listed.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"deleting-partitions-in-the-web-console_managing-partitions-using-the-web-console\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">3.3. Deleting partitions in the web console\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can remove partitions in the web console interface.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">cockpit-storaged\u003C/code> package is installed on your system.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tYou have installed the RHEL 9 web console.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor instructions, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console\">Installing and enabling the web console\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tLog in to the RHEL 9 web console.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor details, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#logging-in-to-the-web-console_getting-started-with-the-rhel-9-web-console\">Logging in to the web console\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick the \u003Cspan class=\"strong strong\">\u003Cstrong>Storage\u003C/strong>\u003C/span> tab.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick the device from which you want to delete a partition.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tOn the device page and in the \u003Cspan class=\"strong strong\">\u003Cstrong>GPT partitions\u003C/strong>\u003C/span> section, click the menu button, \u003Cspan class=\"guibutton\">⋮\u003C/span> next to the partition you want to delete.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFrom the drop-down menu, select \u003Cspan class=\"guibutton\">Delete\u003C/span>.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe RHEL web console terminates all processes that are currently using the partition and unmount the partition before deleting it.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tTo verify that the partition has been successfully removed, switch to the \u003Cspan class=\"strong strong\">\u003Cstrong>Storage\u003C/strong>\u003C/span> tab and check the \u003Cspan class=\"strong strong\">\u003Cstrong>Storage\u003C/strong>\u003C/span> table.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"mounting-nfs-shares_managing-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 4. Mounting NFS shares\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tAs a system administrator, you can mount remote NFS shares on your system to access shared data.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"services-required-on-an-nfs-client_mounting-nfs-shares\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">4.1. Services required on an NFS client\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tRed Hat Enterprise Linux uses a combination of a kernel module and user-space processes to provide NFS file shares:\n\t\t\t\u003C/p>\u003Crh-table id=\"idm139822460057408\">\u003Ctable class=\"lt-4-cols lt-7-rows\">\u003Ccaption>Table 4.1. Services required on an NFS client\u003C/caption>\u003Ccolgroup>\u003Ccol style=\"width: 17%; \" class=\"col_1\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 17%; \" class=\"col_2\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 66%; \" class=\"col_3\">\u003C!--Empty-->\u003C/col>\u003C/colgroup>\u003Cthead>\u003Ctr>\u003Cth align=\"left\" valign=\"top\" id=\"idm139822456686576\" scope=\"col\">Service name\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm139822456685488\" scope=\"col\">NFS version\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm139822459522000\" scope=\"col\">Description\u003C/th>\u003C/tr>\u003C/thead>\u003Ctbody>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456686576\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">rpc.idmapd\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456685488\"> \u003Cp>\n\t\t\t\t\t\t\t\t4\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822459522000\"> \u003Cp>\n\t\t\t\t\t\t\t\tThis process provides NFSv4 client and server upcalls, which map between NFSv4 names (strings in the form of \u003Cspan class=\"emphasis\">\u003Cem>\u003Ccode class=\"literal\">user@domain\u003C/code>\u003C/em>\u003C/span>) and local user and group IDs.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456686576\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">rpc.statd\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456685488\"> \u003Cp>\n\t\t\t\t\t\t\t\t3\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822459522000\"> \u003Cp>\n\t\t\t\t\t\t\t\tThis service provides notification to other NFSv3 clients when the local host reboots, and to the kernel when a remote NFSv3 host reboots.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\u003C/rh-table>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">rpc.idmapd(8)\u003C/code>, \u003Ccode class=\"literal\">rpc.statd(8)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"preparing-an-nfsv3-client-to-run-behind-a-firewall_mounting-nfs-shares\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">4.2. Preparing an NFSv3 client to run behind a firewall\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tAn NFS server notifies clients about file locks and the server status. To establish a connection back to the client, you must open the relevant ports in the firewall on the client.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tBy default, NFSv3 RPC services use random ports. To enable a firewall configuration, configure fixed port numbers in the \u003Ccode class=\"literal\">/etc/nfs.conf\u003C/code> file:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tIn the \u003Ccode class=\"literal\">[lockd]\u003C/code> section, set a fixed port number for the \u003Ccode class=\"literal\">nlockmgr\u003C/code> RPC service, for example:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">port=\u003Cspan class=\"emphasis\">\u003Cem>5555\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tWith this setting, the service automatically uses this port number for both the UDP and TCP protocol.\n\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tIn the \u003Ccode class=\"literal\">[statd]\u003C/code> section, set a fixed port number for the \u003Ccode class=\"literal\">rpc.statd\u003C/code> service, for example:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">port=\u003Cspan class=\"emphasis\">\u003Cem>6666\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tWith this setting, the service automatically uses this port number for both the UDP and TCP protocol.\n\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOpen the relevant ports in \u003Ccode class=\"literal\">firewalld\u003C/code>:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>firewall-cmd --permanent --add-service=rpc-bind\u003C/strong>\u003C/span>\n# \u003Cspan class=\"strong strong\">\u003Cstrong>firewall-cmd --permanent --add-port={\u003Cspan class=\"emphasis\">\u003Cem>5555\u003C/em>\u003C/span>/tcp,\u003Cspan class=\"emphasis\">\u003Cem>5555\u003C/em>\u003C/span>/udp,\u003Cspan class=\"emphasis\">\u003Cem>6666\u003C/em>\u003C/span>/tcp,\u003Cspan class=\"emphasis\">\u003Cem>6666\u003C/em>\u003C/span>/udp}\u003C/strong>\u003C/span>\n# \u003Cspan class=\"strong strong\">\u003Cstrong>firewall-cmd --reload\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRestart the \u003Ccode class=\"literal\">rpc-statd\u003C/code> service:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl restart rpc-statd nfs-server\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"preparing-an-nfsv4-0-client-to-run-behind-a-firewall_mounting-nfs-shares\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">4.3. Preparing an NFSv4.0 client to run behind a firewall\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tAn NFS server notifies clients about file locks and the server status. To establish a connection back to the client, you must open the relevant ports in the firewall on the client.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe server uses the NFS 4.0 protocol.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOpen the relevant ports in \u003Ccode class=\"literal\">firewalld\u003C/code>:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>firewall-cmd --permanent --add-port=\u003Cspan class=\"emphasis\">\u003Cem>&lt;callback_port&gt;\u003C/em>\u003C/span>/tcp\u003C/strong>\u003C/span>\n# \u003Cspan class=\"strong strong\">\u003Cstrong>firewall-cmd --reload\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"manually-mounting-an-nfs-share_mounting-nfs-shares\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">4.4. Manually mounting an NFS share\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tIf you do not require that a NFS share is automatically mounted at boot time, you can manually mount it.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition warning\" state=\"danger\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Warning\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tYou can experience conflicts in your NFSv4 \u003Ccode class=\"literal\">clientid\u003C/code> and their sudden expiration if your NFS clients have the same short hostname. To avoid any possible sudden expiration of your NFSv4 \u003Ccode class=\"literal\">clientid\u003C/code>, you must use either unique hostnames for NFS clients or configure identifier on each container, depending on what system you are using. For more information, see the \u003Ca class=\"link\" href=\"https://access.redhat.com/solutions/6395261\">NFSv4 clientid was expired suddenly due to use same hostname on several NFS clients\u003C/a> Knowledgebase article.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tUse the following command to mount an NFS share on a client:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>mount \u003Cspan class=\"emphasis\">\u003Cem>&lt;nfs_server_ip_or_hostname&gt;\u003C/em>\u003C/span>:/\u003Cspan class=\"emphasis\">\u003Cem>&lt;exported_share&gt;\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>&lt;mount point&gt;\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor example, to mount the \u003Ccode class=\"literal\">/nfs/projects\u003C/code> share from the \u003Ccode class=\"literal\">server.example.com\u003C/code> NFS server to \u003Ccode class=\"literal\">/mnt\u003C/code>, enter:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>mount \u003Cspan class=\"emphasis\">\u003Cem>server.example.com:/nfs/projects/\u003C/em>\u003C/span> /mnt/\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAs a user who has permissions to access the NFS share, display the content of the mounted share:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ls -l /mnt/\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"mounting-an-nfs-share-automatically-when-the-system-boots_mounting-nfs-shares\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">4.5. Mounting an NFS share automatically when the system boots\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tAutomatic mounting of an NFS share during system boot ensures that critical services reliant on centralized data, such as \u003Ccode class=\"literal\">/home\u003C/code> directories hosted on the NFS server, have seamless and uninterrupted access from the moment the system starts up.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEdit the \u003Ccode class=\"literal\">/etc/fstab\u003C/code> file and add a line for the share that you want to mount:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">\u003Cspan class=\"strong strong\">\u003Cstrong>\u003Cspan class=\"emphasis\">\u003Cem>&lt;nfs_server_ip_or_hostname&gt;:/&lt;exported_share&gt;\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>&lt;mount point&gt;\u003C/em>\u003C/span> nfs default 0 0\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor example, to mount the \u003Ccode class=\"literal\">/nfs/home\u003C/code> share from the \u003Ccode class=\"literal\">server.example.com\u003C/code> NFS server to \u003Ccode class=\"literal\">/home\u003C/code>, enter:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">server.example.com:/nfs/projects    \t/home        nfs \tdefaults    \t0 0\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tMount the share:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>mount \u003Cspan class=\"emphasis\">\u003Cem>/home\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAs a user who has permissions to access the NFS share, display the content of the mounted share:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ls -l /mnt/\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">fstab(5)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"connecting-nfs-mounts-in-the-web-console_mounting-nfs-shares\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">4.6. Connecting NFS mounts in the web console\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tConnect a remote directory to your file system using NFS.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tYou have installed the RHEL 9 web console.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor instructions, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console\">Installing and enabling the web console\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">cockpit-storaged\u003C/code> package is installed on your system.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tNFS server name or the IP address.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tPath to the directory on the remote server.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tLog in to the RHEL 9 web console.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor details, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#logging-in-to-the-web-console_getting-started-with-the-rhel-9-web-console\">Logging in to the web console\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick \u003Cspan class=\"strong strong\">\u003Cstrong>Storage\u003C/strong>\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Storage\u003C/strong>\u003C/span> table, click the menu button.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFrom the drop-down menu, select \u003Cspan class=\"strong strong\">\u003Cstrong>New NFS mount\u003C/strong>\u003C/span>.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/32dad32f8647e486ba3a67b25a80dd20/cockpit-adding-volume-groups-new-nfs.png\" alt=\"Image displaying the available options in the Storage table drop-down menu. The New NFS mount options is highlighted.\"/>\u003C/span>\n\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>New NFS Mount\u003C/strong>\u003C/span> dialog box, enter the server or IP address of the remote server.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Path on Server\u003C/strong>\u003C/span> field, enter the path to the directory that you want to mount.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Local Mount Point\u003C/strong>\u003C/span> field, enter the path to the directory on your local system where you want to mount the NFS.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Mount options\u003C/strong>\u003C/span> check box list, select how you want to mount the NFS. You can select multiple options depending on your requirements.\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tCheck the \u003Cspan class=\"strong strong\">\u003Cstrong>Mount at boot\u003C/strong>\u003C/span> box if you want the directory to be reachable even after you restart the local system.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tCheck the \u003Cspan class=\"strong strong\">\u003Cstrong>Mount read only\u003C/strong>\u003C/span> box if you do not want to change the content of the NFS.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tCheck the \u003Cspan class=\"strong strong\">\u003Cstrong>Custom mount options\u003C/strong>\u003C/span> box and add the mount options if you want to change the default mount option.\n\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/0152ffc2922c8556e646f59bf2e25a2b/cockpit-NFS-mount-new.png\" alt=\"New NFS mount dialog box\"/>\u003C/span>\n\n\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick \u003Cspan class=\"guibutton\">Add\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tOpen the mounted directory and verify that the content is accessible.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"customizing-nfs-mount-options-in-the-web-console_mounting-nfs-shares\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">4.7. Customizing NFS mount options in the web console\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tEdit an existing NFS mount and add custom mount options.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tCustom mount options can help you to troubleshoot the connection or change parameters of the NFS mount such as changing timeout limits or configuring authentication.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tYou have installed the RHEL 9 web console.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor instructions, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console\">Installing and enabling the web console\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">cockpit-storaged\u003C/code> package is installed on your system.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tAn NFS mount is added to your system.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tLog in to the RHEL 9 web console. For details, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#logging-in-to-the-web-console_getting-started-with-the-rhel-9-web-console\">Logging in to the web console\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick \u003Cspan class=\"strong strong\">\u003Cstrong>Storage\u003C/strong>\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Storage\u003C/strong>\u003C/span> table, click the NFS mount you want to adjust.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIf the remote directory is mounted, click \u003Cspan class=\"strong strong\">\u003Cstrong>Unmount\u003C/strong>\u003C/span>.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tYou must unmount the directory during the custom mount options configuration. Otherwise, the web console does not save the configuration and this causes an error.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick \u003Cspan class=\"strong strong\">\u003Cstrong>Edit\u003C/strong>\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>NFS Mount\u003C/strong>\u003C/span> dialog box, select \u003Cspan class=\"strong strong\">\u003Cstrong>Custom mount option\u003C/strong>\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnter mount options separated by a comma. For example:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">\u003Cspan class=\"strong strong\">\u003Cstrong>nfsvers=4\u003C/strong>\u003C/span>\u003C/code>: The NFS protocol version number\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">\u003Cspan class=\"strong strong\">\u003Cstrong>soft\u003C/strong>\u003C/span>\u003C/code>: The type of recovery after an NFS request times out\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">\u003Cspan class=\"strong strong\">\u003Cstrong>sec=krb5\u003C/strong>\u003C/span>\u003C/code>: The files on the NFS server can be secured by Kerberos authentication. Both the NFS client and server have to support Kerberos authentication.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor a complete list of the NFS mount options, enter \u003Ccode class=\"literal\">man nfs\u003C/code> in the command line.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick \u003Cspan class=\"strong strong\">\u003Cstrong>Apply\u003C/strong>\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick \u003Cspan class=\"strong strong\">\u003Cstrong>Mount\u003C/strong>\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tOpen the mounted directory and verify that the content is accessible.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"setting-up-an-nfs-client-with-kerberos-in-a-red-hat-identity-management-domain_mounting-nfs-shares\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">4.8. Setting up an NFS client with Kerberos in a Red Hat Identity Management domain\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tIf the NFS server uses Kerberos and is enrolled in an Red Hat Identity Management (IdM) domain, your client must also be a member of the domain to be able to mount the shares. This enables you to centrally manage users and groups and to use Kerberos for authentication, integrity protection, and traffic encryption.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe NFS client is \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/installing_identity_management/assembly_installing-an-idm-client_installing-identity-management\">enrolled\u003C/a> in a Red Hat Identity Management (IdM) domain.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe exported NFS share uses Kerberos.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tObtain a kerberos ticket as an IdM administrator:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>kinit admin\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRetrieve the host principal, and store it in the \u003Ccode class=\"literal\">/etc/krb5.keytab\u003C/code> file:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ipa-getkeytab -s \u003Cspan class=\"emphasis\">\u003Cem>idm_server.idm.example.com\u003C/em>\u003C/span> -p \u003Cspan class=\"emphasis\">\u003Cem>host/nfs_client.idm.example.com\u003C/em>\u003C/span> -k /etc/krb5.keytab\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIdM automatically created the \u003Ccode class=\"literal\">host\u003C/code> principal when you joined the host to the IdM domain.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOptional: Display the principals in the \u003Ccode class=\"literal\">/etc/krb5.keytab\u003C/code> file:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>klist -k /etc/krb5.keytab\u003C/strong>\u003C/span>\nKeytab name: FILE:/etc/krb5.keytab\nKVNO Principal\n---- --------------------------------------------------------------------------\n   6 host/nfs_client.idm.example.com@IDM.EXAMPLE.COM\n   6 host/nfs_client.idm.example.com@IDM.EXAMPLE.COM\n   6 host/nfs_client.idm.example.com@IDM.EXAMPLE.COM\n   6 host/nfs_client.idm.example.com@IDM.EXAMPLE.COM\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tUse the \u003Ccode class=\"literal\">ipa-client-automount\u003C/code> utility to configure mapping of IdM IDs:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ipa-client-automount\u003C/strong>\u003C/span>\nSearching for IPA server...\nIPA server: DNS discovery\nLocation: default\nContinue to configure the system with these values? [no]: yes\nConfigured /etc/idmapd.conf\nRestarting sssd, waiting for it to become available.\nStarted autofs\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tMount an exported NFS share, for example:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>mount -o sec=krb5i \u003Cspan class=\"emphasis\">\u003Cem>server.idm.example.com:/nfs/projects/\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>/mnt/\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">-o sec\u003C/code> option specifies the Kerberos security method.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tLog in as an IdM user who has permissions to write on the mounted share.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tObtain a Kerberos ticket:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>kinit\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a file on the share, for example:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>touch \u003Cspan class=\"emphasis\">\u003Cem>/mnt/test.txt\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tList the directory to verify that the file was created:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ls -l \u003Cspan class=\"emphasis\">\u003Cem>/mnt/test.txt\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\n-rw-r--r--. 1 admin users 0 Feb 15 11:54 /mnt/test.txt\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/configuring_and_using_network_file_services/deploying-an-nfs-server_configuring-and-using-network-file-services#the-auth-gss-authentication-method_deploying-an-nfs-server\">The AUTH_GSS authentication method\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"configuring-gnome-to-store-user-settings-on-home-directories-hosted-on-an-nfs-share_mounting-nfs-shares\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">4.9. Configuring GNOME to store user settings on home directories hosted on an NFS share\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tIf you use GNOME on a system with home directories hosted on an NFS server, you must change the \u003Ccode class=\"literal\">keyfile\u003C/code> backend of the \u003Ccode class=\"literal\">dconf\u003C/code> database. Otherwise, \u003Ccode class=\"literal\">dconf\u003C/code> might not work correctly.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThis change affects all users on the host, as it alters the way \u003Ccode class=\"literal\">dconf\u003C/code> manages user settings and configurations stored in the home directories.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate the \u003Ccode class=\"literal\">/etc/dconf/profile/user\u003C/code> file and add the following to it:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">\u003Cspan class=\"strong strong\">\u003Cstrong>service-db:keyfile/user\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tWith this setting, \u003Ccode class=\"literal\">dconf\u003C/code> polls the \u003Ccode class=\"literal\">keyfile\u003C/code> back end to determine whether updates have been made, so settings might not be updated immediately.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe changes take effect when the users logs out and in.\n\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"frequently-used-nfs-mount-options_mounting-nfs-shares\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">4.10. Frequently used NFS mount options\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tThe following are the commonly-used options when mounting NFS shares. You can use these options with \u003Ccode class=\"literal\">mount\u003C/code> commands, in \u003Ccode class=\"literal\">/etc/fstab\u003C/code> settings, and the \u003Ccode class=\"literal\">autofs\u003C/code> automapper.\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">lookupcache=\u003Cspan class=\"emphasis\">\u003Cem>mode\u003C/em>\u003C/span>\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tSpecifies how the kernel should manage its cache of directory entries for a given mount point. Valid arguments for mode are \u003Ccode class=\"literal\">all\u003C/code>, \u003Ccode class=\"literal\">none\u003C/code>, or \u003Ccode class=\"literal\">positive\u003C/code>.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">nfsvers=\u003Cspan class=\"emphasis\">\u003Cem>version\u003C/em>\u003C/span>\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tSpecifies which version of the NFS protocol to use, where version is \u003Ccode class=\"literal\">3\u003C/code>, \u003Ccode class=\"literal\">4\u003C/code>, \u003Ccode class=\"literal\">4.0\u003C/code>, \u003Ccode class=\"literal\">4.1\u003C/code>, or \u003Ccode class=\"literal\">4.2\u003C/code>. This is useful for hosts that run multiple NFS servers, or to disable retrying a mount with lower versions. If no version is specified, the client tries version \u003Ccode class=\"literal\">4.2\u003C/code> first, then negotiates down until it finds a version supported by the server.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe option \u003Ccode class=\"literal\">vers\u003C/code> is identical to \u003Ccode class=\"literal\">nfsvers\u003C/code>, and is included in this release for compatibility reasons.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">noacl\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tTurns off all ACL processing. This can be needed when interfacing with old Red Hat Enterprise Linux versions that are not compatible with the recent ACL technology.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">nolock\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDisables file locking. This setting can be required when you connect to very old NFS servers.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">noexec\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tPrevents execution of binaries on mounted file systems. This is useful if the system is mounting a non-Linux file system containing incompatible binaries.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">nosuid\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDisables the \u003Ccode class=\"literal\">set-user-identifier\u003C/code> and \u003Ccode class=\"literal\">set-group-identifier\u003C/code> bits. This prevents remote users from gaining higher privileges by running a \u003Ccode class=\"literal\">setuid\u003C/code> program.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">retrans=\u003Cspan class=\"emphasis\">\u003Cem>num\u003C/em>\u003C/span>\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe number of times the NFS client retries a request before it attempts further recovery action. If the \u003Ccode class=\"literal\">retrans\u003C/code> option is not specified, the NFS client tries each UDP request three times and each TCP request twice.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">timeo=\u003Cspan class=\"emphasis\">\u003Cem>num\u003C/em>\u003C/span>\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe time in tenths of a second the NFS client waits for a response before it retries an NFS request. For NFS over TCP, the default \u003Ccode class=\"literal\">timeo\u003C/code> value is 600 (60 seconds). The NFS client performs linear backoff: After each retransmission the timeout is increased by \u003Ccode class=\"literal\">timeo\u003C/code> up to the maximum of 600 seconds.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">port=\u003Cspan class=\"emphasis\">\u003Cem>num\u003C/em>\u003C/span>\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tSpecifies the numeric value of the NFS server port. For NFSv3, if num is \u003Ccode class=\"literal\">0\u003C/code> (the default value), or not specified, then mount queries the \u003Ccode class=\"literal\">rpcbind\u003C/code> service on the remote host for the port number to use. For NFSv4, if num is \u003Ccode class=\"literal\">0\u003C/code>, then mount queries the \u003Ccode class=\"literal\">rpcbind\u003C/code> service, but if it is not specified, the standard NFS port number of TCP 2049 is used instead and the remote \u003Ccode class=\"literal\">rpcbind\u003C/code> is not checked anymore.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">rsize=\u003Cspan class=\"emphasis\">\u003Cem>num\u003C/em>\u003C/span>\u003C/code> and \u003Ccode class=\"literal\">wsize=\u003Cspan class=\"emphasis\">\u003Cem>num\u003C/em>\u003C/span>\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThese options set the maximum number of bytes to be transferred in a single NFS read or write operation.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThere is no fixed default value for \u003Ccode class=\"literal\">rsize\u003C/code> and \u003Ccode class=\"literal\">wsize\u003C/code>. By default, NFS uses the largest possible value that both the server and the client support. In Red Hat Enterprise Linux 9, the client and server maximum is 1,048,576 bytes. For more details, see the \u003Ca class=\"link\" href=\"https://access.redhat.com/solutions/753853\">What are the default and maximum values for rsize and wsize with NFS mounts?\u003C/a> KBase article.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">sec=\u003Cspan class=\"emphasis\">\u003Cem>options\u003C/em>\u003C/span>\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tSecurity options to use for accessing files on the mounted export. The options value is a colon-separated list of one or more security options.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tBy default, the client attempts to find a security option that both the client and the server support. If the server does not support any of the selected options, the mount operation fails.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tAvailable options:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">sec=sys\u003C/code> uses local UNIX UIDs and GIDs. These use \u003Ccode class=\"literal\">AUTH_SYS\u003C/code> to authenticate NFS operations.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">sec=krb5\u003C/code> uses Kerberos V5 instead of local UNIX UIDs and GIDs to authenticate users.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">sec=krb5i\u003C/code> uses Kerberos V5 for user authentication and performs integrity checking of NFS operations using secure checksums to prevent data tampering.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">sec=krb5p\u003C/code> uses Kerberos V5 for user authentication, integrity checking, and encrypts NFS traffic to prevent traffic sniffing. This is the most secure setting, but it also involves the most performance overhead.\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">mount(8)\u003C/code> and `nfs(5)`man pages on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"enabling-client-side-caching-of-nfs-content_mounting-nfs-shares\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">4.11. Enabling client-side caching of NFS content\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tFS-Cache is a persistent local cache on the client that file systems can use to take data retrieved from over the network and cache it on the local disk. This helps to minimize network traffic.\n\t\t\t\u003C/p>\u003Csection class=\"section\" id=\"how-nfs-caching-works_enabling-client-side-caching-of-nfs-content\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">4.11.1. How NFS caching works\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tThe following diagram is a high-level illustration of how FS-Cache works:\n\t\t\t\t\u003C/p>\u003Cdiv class=\"informalfigure\">\u003Cdiv class=\"mediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/315fe3b891f2a78cb30c1cebbf0373e0/fs-cache.png\" alt=\"FS-Cache overview\"/>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tFS-Cache is designed to be as transparent as possible to the users and administrators of a system. FS-Cache allows a file system on a server to interact directly with a client’s local cache without creating an over-mounted file system. With NFS, a mount option instructs the client to mount the NFS share with FS-cache enabled. The mount point will cause automatic upload for two kernel modules: \u003Ccode class=\"literal\">fscache\u003C/code> and \u003Ccode class=\"literal\">cachefiles\u003C/code>. The \u003Ccode class=\"literal\">cachefilesd\u003C/code> daemon communicates with the kernel modules to implement the cache.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tFS-Cache does not alter the basic operation of a file system that works over the network. It merely provides that file system with a persistent place in which it can cache data. For example, a client can still mount an NFS share whether or not FS-Cache is enabled. In addition, cached NFS can handle files that will not fit into the cache (whether individually or collectively) as files can be partially cached and do not have to be read completely up front. FS-Cache also hides all I/O errors that occur in the cache from the client file system driver.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tTo provide caching services, FS-Cache needs a cache back end, the \u003Ccode class=\"literal\">cachefiles\u003C/code> service. FS-Cache requires a mounted block-based file system, that supports block mapping (\u003Ccode class=\"literal\">bmap\u003C/code>) and extended attributes as its cache back end:\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tXFS\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\text3\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\text4\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\t\tFS-Cache cannot arbitrarily cache any file system, whether through the network or otherwise: the shared file system’s driver must be altered to allow interaction with FS-Cache, data storage or retrieval, and metadata setup and validation. FS-Cache needs \u003Cspan class=\"emphasis\">\u003Cem>indexing keys\u003C/em>\u003C/span> and \u003Cspan class=\"emphasis\">\u003Cem>coherency data\u003C/em>\u003C/span> from the cached file system to support persistence: indexing keys to match file system objects to cache objects, and coherency data to determine whether the cache objects are still valid.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tUsing FS-Cache is a compromise between various factors. If FS-Cache is being used to cache NFS traffic, it may slow the client down, but can massively reduce the network and server loading by satisfying read requests locally without consuming network bandwidth.\n\t\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"installing-and-configuring-the-cachefilesd-service_enabling-client-side-caching-of-nfs-content\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">4.11.2. Installing and configuring the cachefilesd service\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tRed Hat Enterprise Linux provides only the \u003Ccode class=\"literal\">cachefiles\u003C/code> caching back end. The \u003Ccode class=\"literal\">cachefilesd\u003C/code> service initiates and manages \u003Ccode class=\"literal\">cachefiles\u003C/code>. The \u003Ccode class=\"literal\">/etc/cachefilesd.conf\u003C/code> file controls how \u003Ccode class=\"literal\">cachefiles\u003C/code> provides caching services.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe file system mounted under the \u003Ccode class=\"literal\">/var/cache/fscache/\u003C/code> directory is \u003Ccode class=\"literal\">ext3\u003C/code>, \u003Ccode class=\"literal\">ext4\u003C/code>, or \u003Ccode class=\"literal\">xfs\u003C/code>.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe file system mounted under \u003Ccode class=\"literal\">/var/cache/fscache/\u003C/code> uses extended attributes, which is the default if you created the file system on RHEL 8 or later.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tInstall the \u003Ccode class=\"literal\">cachefilesd\u003C/code> package:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>dnf install cachefilesd\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tEnable and start the \u003Ccode class=\"literal\">cachefilesd\u003C/code> service:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl enable --now cachefilesd\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tMount an NFS share with the \u003Ccode class=\"literal\">fsc\u003C/code> option to use the cache:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tTo mount a share temporarily, enter:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>mount -o fsc \u003Cspan class=\"emphasis\">\u003Cem>server.example.com:/nfs/projects/\u003C/em>\u003C/span> /mnt/\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tTo mount a share permanently, add the \u003Ccode class=\"literal\">fsc\u003C/code> option to the entry in the \u003Ccode class=\"literal\">/etc/fstab\u003C/code> file:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">\u003Cspan class=\"emphasis\">\u003Cem>&lt;nfs_server_ip_or_hostname&gt;:/&lt;exported_share&gt;\u003C/em>\u003C/span>     \u003Cspan class=\"emphasis\">\u003Cem>&lt;mount point&gt;\u003C/em>\u003C/span>    nfs \u003Cspan class=\"strong strong\">\u003Cstrong>fsc\u003C/strong>\u003C/span> 0 0\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tDisplay the FS-cache statistics:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>cat /proc/fs/fscache/stats\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/doc/cachefilesd/README\u003C/code> file\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/doc/kernel-doc-&lt;kernel_version&gt;/Documentation/filesystems/caching/fscache.rst\u003C/code> provided by the \u003Ccode class=\"literal\">kernel-doc\u003C/code> package\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"sharing-nfs-cache_enabling-client-side-caching-of-nfs-content\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">4.11.3. Sharing NFS cache\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tBecause the cache is persistent, blocks of data in the cache are indexed on a sequence of four keys:\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tLevel 1: Server details\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tLevel 2: Some mount options; security type; FSID; a uniquifier string\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tLevel 3: File Handle\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tLevel 4: Page number in file\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\t\tTo avoid coherency management problems between superblocks, all NFS superblocks that require to cache the data have unique level 2 keys. Normally, two NFS mounts with the same source volume and options share a superblock, and therefore share the caching, even if they mount different directories within that volume.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"example\" id=\"idm139822460866304\">\u003Cp class=\"title\">\u003Cstrong>Example 4.1. NFS cache sharing:\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\t\tThe following two mounts likely share the superblock as they have the same mount options, especially if because they come from the same partition on the NFS server:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount -o fsc home0:/nfs/projects /projects\n# mount -o fsc home0:/nfs/home /home/\u003C/pre>\u003Cp>\n\t\t\t\t\t\tIf the mount options are different, they do not share the superblock:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount -o fsc,rsize=8192 home0:/nfs/projects /projects\n# mount -o fsc,rsize=65536 home0:/nfs/home /home/\u003C/pre>\u003C/div>\u003C/div>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\tThe user can not share caches between superblocks that have different communications or protocol parameters. For example, it is not possible to share caches between NFSv4.0 and NFSv3 or between NFSv4.1 and NFSv4.2 because they force different superblocks. Also setting parameters, such as the read size (\u003Ccode class=\"literal\">rsize\u003C/code>), prevents cache sharing because, again, it forces a different superblock.\n\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/section>\u003Csection class=\"section\" id=\"nfs-cache-limitations_enabling-client-side-caching-of-nfs-content\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">4.11.4. NFS cache limitations\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tThere are some cache limitations with NFS:\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tOpening a file from a shared file system for direct I/O automatically bypasses the cache. This is because this type of access must be direct to the server.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tOpening a file from a shared file system for either direct I/O or writing flushes the cached copy of the file. FS-Cache will not cache the file again until it is no longer opened for direct I/O or writing.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tFurthermore, this release of FS-Cache only caches regular NFS files. FS-Cache will not cache directories, symlinks, device files, FIFOs, and sockets.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"how-cache-culling-works_enabling-client-side-caching-of-nfs-content\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">4.11.5. How cache culling works\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tThe \u003Ccode class=\"literal\">cachefilesd\u003C/code> service works by caching remote data from shared file systems to free space on the local disk. This could potentially consume all available free space, which could cause problems if the disk also contains the root partition. To control this, \u003Ccode class=\"literal\">cachefilesd\u003C/code> tries to maintain a certain amount of free space by discarding old objects, such as less-recently accessed objects, from the cache. This behavior is known as cache culling.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tCache culling is done on the basis of the percentage of blocks and the percentage of files available in the underlying file system. There are settings in \u003Ccode class=\"literal\">/etc/cachefilesd.conf\u003C/code> which control six limits:\n\t\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">brun \u003Cspan class=\"emphasis\">\u003Cem>N%\u003C/em>\u003C/span> (percentage of blocks), frun \u003Cspan class=\"emphasis\">\u003Cem>N%\u003C/em>\u003C/span> (percentage of files)\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\tIf the amount of free space and the number of available files in the cache rises above both these limits, then culling is turned off.\n\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">bcull \u003Cspan class=\"emphasis\">\u003Cem>N%\u003C/em>\u003C/span> (percentage of blocks), fcull \u003Cspan class=\"emphasis\">\u003Cem>N%\u003C/em>\u003C/span> (percentage of files)\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\tIf the amount of available space or the number of files in the cache falls below either of these limits, then culling is started.\n\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">bstop \u003Cspan class=\"emphasis\">\u003Cem>N%\u003C/em>\u003C/span> (percentage of blocks), fstop \u003Cspan class=\"emphasis\">\u003Cem>N%\u003C/em>\u003C/span> (percentage of files)\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\tIf the amount of available space or the number of available files in the cache falls below either of these limits, then no further allocation of disk space or files is permitted until culling has raised things above these limits again.\n\t\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cp>\n\t\t\t\t\tThe default value of \u003Ccode class=\"literal\">N\u003C/code> for each setting is as follows:\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ccode class=\"literal\">brun/frun\u003C/code>: 10%\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ccode class=\"literal\">bcull/fcull\u003C/code>: 7%\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ccode class=\"literal\">bstop/fstop\u003C/code>: 3%\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\t\tWhen configuring these settings, the following must hold true:\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t0 ≤ \u003Ccode class=\"literal\">bstop\u003C/code> &lt; \u003Ccode class=\"literal\">bcull\u003C/code> &lt; \u003Ccode class=\"literal\">brun\u003C/code> &lt; 100\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t0 ≤ \u003Ccode class=\"literal\">fstop\u003C/code> &lt; \u003Ccode class=\"literal\">fcull\u003C/code> &lt; \u003Ccode class=\"literal\">frun\u003C/code> &lt; 100\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\t\tThese are the percentages of available space and available files and do not appear as 100 minus the percentage displayed by the \u003Ccode class=\"literal\">df\u003C/code> program.\n\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\tCulling depends on both b\u003Cspan class=\"emphasis\">\u003Cem>xxx\u003C/em>\u003C/span> and f\u003Cspan class=\"emphasis\">\u003Cem>xxx\u003C/em>\u003C/span> pairs simultaneously; the user can not treat them separately.\n\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/section>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"mounting-an-smb-share-on-red-hat-enterprise-linux_managing-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 5. Mounting an SMB Share\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tThe Server Message Block (SMB) protocol implements an application-layer network protocol used to access resources on a server, such as file shares and shared printers.\n\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\tIn the context of SMB, you can find mentions about the Common Internet File System (CIFS) protocol, which is a dialect of SMB. Both the SMB and CIFS protocol are supported, and the kernel module and utilities involved in mounting SMB and CIFS shares both use the name \u003Ccode class=\"literal\">cifs\u003C/code>.\n\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cp>\n\t\t\tThe \u003Ccode class=\"literal\">cifs-utils\u003C/code> package provides utilities to:\n\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\tMount SMB and CIFS shares\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tManage NT LAN Manager (NTLM) credentials in the kernel’s keyring\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tSet and display Access Control Lists (ACL) in a security descriptor on SMB and CIFS shares\n\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Csection class=\"section\" id=\"con_supported-smb-protocol-versions_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">5.1. Supported SMB protocol versions\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe \u003Ccode class=\"literal\">cifs.ko\u003C/code> kernel module supports the following SMB protocol versions:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tSMB 1\n\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition warning\" state=\"danger\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Warning\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\tThe SMB1 protocol is deprecated due to known security issues, and is only \u003Cspan class=\"strong strong\">\u003Cstrong>safe to use on a private network\u003C/strong>\u003C/span>. The main reason that SMB1 is still provided as a supported option is that currently it is the only SMB protocol version that supports UNIX extensions. If you do not need to use UNIX extensions on SMB, Red Hat strongly recommends using SMB2 or later.\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tSMB 2.0\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tSMB 2.1\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tSMB 3.0\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tSMB 3.1.1\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tDepending on the protocol version, not all SMB features are implemented.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/section>\u003Csection class=\"section\" id=\"con_unix-extensions-support_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">5.2. UNIX extensions support\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tSamba uses the \u003Ccode class=\"literal\">CAP_UNIX\u003C/code> capability bit in the SMB protocol to provide the UNIX extensions feature. These extensions are also supported by the \u003Ccode class=\"literal\">cifs.ko\u003C/code> kernel module. However, both Samba and the kernel module support UNIX extensions only in the SMB 1 protocol.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">cifs-utils\u003C/code> package is installed.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tSet the \u003Ccode class=\"literal\">server min protocol\u003C/code> parameter in the \u003Ccode class=\"literal\">[global]\u003C/code> section in the \u003Ccode class=\"literal\">/etc/samba/smb.conf\u003C/code> file to \u003Ccode class=\"literal\">NT1\u003C/code>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tMount the share using the SMB 1 protocol by providing the \u003Ccode class=\"literal\">-o vers=1.0\u003C/code> option to the mount command. For example:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>mount -t cifs -o vers=1.0,username=\u003Cspan class=\"emphasis\">\u003Cem>&lt;user_name&gt;\u003C/em>\u003C/span> //\u003Cspan class=\"emphasis\">\u003Cem>&lt;server_name&gt;\u003C/em>\u003C/span>/\u003Cspan class=\"emphasis\">\u003Cem>&lt;share_name&gt;\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>/mnt/\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tBy default, the kernel module uses SMB 2 or the highest later protocol version supported by the server. Passing the \u003Ccode class=\"literal\">-o vers=1.0\u003C/code> option to the \u003Ccode class=\"literal\">mount\u003C/code> command forces that the kernel module uses the SMB 1 protocol that is required for using UNIX extensions.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tDisplay the options of the mounted share:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>mount\u003C/strong>\u003C/span>\n...\n//\u003Cspan class=\"emphasis\">\u003Cem>&lt;server_name&gt;\u003C/em>\u003C/span>/\u003Cspan class=\"emphasis\">\u003Cem>&lt;share_name&gt;\u003C/em>\u003C/span> on \u003Cspan class=\"emphasis\">\u003Cem>/mnt\u003C/em>\u003C/span> type cifs (...,\u003Cspan class=\"strong strong\">\u003Cstrong>unix\u003C/strong>\u003C/span>,...)\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIf the \u003Ccode class=\"literal\">unix\u003C/code> entry is displayed in the list of mount options, UNIX extensions are enabled.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"proc_manually-mounting-an-smb-share_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">5.3. Manually mounting an SMB share\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tIf you only require an SMB share to be temporary mounted, you can mount it manually using the \u003Ccode class=\"literal\">mount\u003C/code> utility.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tManually mounted shares are not mounted automatically again when you reboot the system. To configure that Red Hat Enterprise Linux automatically mounts the share when the system boots, see \u003Ca class=\"link\" href=\"#proc_mounting-an-smb-share-automatically-when-the-system-boots_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux\" title=\"5.4. Mounting an SMB share automatically when the system boots\">Mounting an SMB share automatically when the system boots\u003C/a>.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">cifs-utils\u003C/code> package is installed.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tUse the \u003Ccode class=\"literal\">mount\u003C/code> utility with the \u003Ccode class=\"literal\">-t cifs\u003C/code> parameter to mount an SMB share:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>mount -t cifs -o username=\u003Cspan class=\"emphasis\">\u003Cem>&lt;user_name&gt;\u003C/em>\u003C/span> //\u003Cspan class=\"emphasis\">\u003Cem>&lt;server_name&gt;\u003C/em>\u003C/span>/\u003Cspan class=\"emphasis\">\u003Cem>&lt;share_name&gt;\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>/mnt/\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\nPassword for \u003Cspan class=\"emphasis\">\u003Cem>&lt;user_name&gt;\u003C/em>\u003C/span>@//\u003Cspan class=\"emphasis\">\u003Cem>&lt;server_name&gt;\u003C/em>\u003C/span>/\u003Cspan class=\"emphasis\">\u003Cem>&lt;share_name&gt;\u003C/em>\u003C/span>:  \u003Cspan class=\"emphasis\">\u003Cem>password\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn the \u003Ccode class=\"literal\">-o\u003C/code> parameter, you can specify options that are used to mount the share. For details, see the \u003Ccode class=\"literal\">OPTIONS\u003C/code> section in the \u003Ccode class=\"literal\">mount.cifs(8)\u003C/code> man page and \u003Ca class=\"link\" href=\"#con_frequently-used-mount-options_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux\" title=\"5.7. Frequently used SMB mount options\">Frequently used mount options\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"example\" id=\"example_mounting-a-share-using-an-encrypted-smb30-connection_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux\">\u003Cp class=\"title\">\u003Cstrong>Example 5.1. Mounting a share using an encrypted SMB 3.0 connection\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\t\t\tTo mount the \u003Ccode class=\"literal\">\\\\server\\example\\\u003C/code> share as the \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>DOMAIN\u003C/em>\u003C/span>\\Administrator\u003C/code> user over an encrypted SMB 3.0 connection into the \u003Ccode class=\"literal\">/mnt/\u003C/code> directory:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>mount -t cifs -o username=\u003Cspan class=\"emphasis\">\u003Cem>DOMAIN\u003C/em>\u003C/span>\\Administrator,seal,vers=3.0 //server/example /mnt/\u003C/strong>\u003C/span>\nPassword for \u003Cspan class=\"emphasis\">\u003Cem>DOMAIN\u003C/em>\u003C/span>\\Administrator@//server_name/share_name:  \u003Cspan class=\"emphasis\">\u003Cem>password\u003C/em>\u003C/span>\u003C/pre>\u003C/div>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tList the content of the mounted share:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ls -l /mnt/\u003C/strong>\u003C/span>\ntotal 4\ndrwxr-xr-x.  2 root root 8748 Dec  4 16:27 test.txt\ndrwxr-xr-x. 17 root root 4096 Dec  4 07:43 Demo-Directory\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"proc_mounting-an-smb-share-automatically-when-the-system-boots_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">5.4. Mounting an SMB share automatically when the system boots\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tIf access to a mounted SMB share is permanently required on a server, mount the share automatically at boot time.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">cifs-utils\u003C/code> package is installed.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAdd an entry for the share to the \u003Ccode class=\"literal\">/etc/fstab\u003C/code> file. For example:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">//\u003Cspan class=\"emphasis\">\u003Cem>&lt;server_name&gt;\u003C/em>\u003C/span>/\u003Cspan class=\"emphasis\">\u003Cem>&lt;share_name&gt;\u003C/em>\u003C/span>  \u003Cspan class=\"emphasis\">\u003Cem>/mnt\u003C/em>\u003C/span>  cifs  credentials=\u003Cspan class=\"emphasis\">\u003Cem>/root/smb.cred\u003C/em>\u003C/span>  0 0\u003C/pre>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\tTo enable the system to mount a share automatically, you must store the user name, password, and domain name in a credentials file. For details, see \u003Ca class=\"link\" href=\"#proc_authenticating-to-an-smb-share-using-a-credentials-file_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux\" title=\"5.5. Creating a credentials file to authenticate to an SMB share\">Creating a credentials file to authenticate to an SMB share\u003C/a>\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn the fourth field of the row in the \u003Ccode class=\"literal\">/etc/fstab\u003C/code>, specify mount options, such as the path to the credentials file. For details, see the \u003Ccode class=\"literal\">OPTIONS\u003C/code> section in the \u003Ccode class=\"literal\">mount.cifs(8)\u003C/code> man page and \u003Ca class=\"link\" href=\"#con_frequently-used-mount-options_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux\" title=\"5.7. Frequently used SMB mount options\">Frequently used mount options\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tMount the share by specifying the mount point:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>mount /mnt/\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"proc_authenticating-to-an-smb-share-using-a-credentials-file_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">5.5. Creating a credentials file to authenticate to an SMB share\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tIn certain situations, such as when mounting a share automatically at boot time, a share should be mounted without entering the user name and password. To implement this, create a credentials file.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal package\">cifs-utils\u003C/code> package is installed.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a file, such as \u003Ccode class=\"literal\">/root/smb.cred\u003C/code>, and specify the user name, password, and domain name that file:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">username=\u003Cspan class=\"emphasis\">\u003Cem>user_name\u003C/em>\u003C/span>\npassword=\u003Cspan class=\"emphasis\">\u003Cem>password\u003C/em>\u003C/span>\ndomain=\u003Cspan class=\"emphasis\">\u003Cem>domain_name\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tSet the permissions to only allow the owner to access the file:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># chown user_name /root/smb.cred\n# chmod 600 /root/smb.cred\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cp>\n\t\t\t\tYou can now pass the \u003Ccode class=\"literal\">credentials=\u003Cspan class=\"emphasis\">\u003Cem>file_name\u003C/em>\u003C/span>\u003C/code> mount option to the \u003Ccode class=\"literal\">mount\u003C/code> utility or use it in the \u003Ccode class=\"literal\">/etc/fstab\u003C/code> file to mount the share without being prompted for the user name and password.\n\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"performing-a-multi-user-smb-mount_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">5.6. Performing a multi-user SMB mount\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe credentials you provide to mount a share determine the access permissions on the mount point by default. For example, if you use the \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>DOMAIN\u003C/em>\u003C/span>\\example\u003C/code> user when you mount a share, all operations on the share will be executed as this user, regardless which local user performs the operation.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tHowever, in certain situations, the administrator wants to mount a share automatically when the system boots, but users should perform actions on the share’s content using their own credentials. The \u003Ccode class=\"literal\">multiuser\u003C/code> mount options lets you configure this scenario.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tTo use the \u003Ccode class=\"literal\">multiuser\u003C/code> mount option, you must additionally set the \u003Ccode class=\"literal\">sec\u003C/code> mount option to a security type that supports providing credentials in a non-interactive way, such as \u003Ccode class=\"literal\">krb5\u003C/code> or the \u003Ccode class=\"literal\">ntlmssp\u003C/code> option with a credentials file. For details, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/managing_file_systems/index#proc_accessing-a-share-as-a-user_assembly_performing-a-multi-user-smb-mount\">Accessing a share as a user\u003C/a>.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cp>\n\t\t\t\tThe \u003Ccode class=\"literal\">root\u003C/code> user mounts the share using the \u003Ccode class=\"literal\">multiuser\u003C/code> option and an account that has minimal access to the contents of the share. Regular users can then provide their user name and password to the current session’s kernel keyring using the \u003Ccode class=\"literal\">cifscreds\u003C/code> utility. If the user accesses the content of the mounted share, the kernel uses the credentials from the kernel keyring instead of the one initially used to mount the share.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tUsing this feature consists of the following steps:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/managing_file_systems/index#proc_mounting-a-share-with-the-multiuser-option_assembly_performing-a-multi-user-smb-mount\">Mount a share with the \u003Ccode class=\"literal\">multiuser\u003C/code> option\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/managing_file_systems/index#proc_verifying-if-an-smb-share-is-mounted-with-the-multiuser-option_assembly_performing-a-multi-user-smb-mount\">Optionally, verify if the share was successfully mounted with the \u003Ccode class=\"literal\">multiuser\u003C/code> option\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/managing_file_systems/index#proc_accessing-a-share-as-a-user_assembly_performing-a-multi-user-smb-mount\">Access the share as a user\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal package\">cifs-utils\u003C/code> package is installed.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Csection class=\"section\" id=\"proc_mounting-a-share-with-the-multiuser-option_assembly_performing-a-multi-user-smb-mount\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">5.6.1. Mounting a share with the multiuser option\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\t\tBefore users can access the share with their own credentials, mount the share as the \u003Ccode class=\"literal\">root\u003C/code> user using an account with limited permissions.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"formalpara\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cp>\n\t\t\t\t\t\tTo mount a share automatically with the \u003Ccode class=\"literal\">multiuser\u003C/code> option when the system boots:\n\t\t\t\t\t\u003C/p>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tCreate the entry for the share in the \u003Ccode class=\"literal filename\">/etc/fstab\u003C/code> file. For example:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">\u003Cspan class=\"emphasis\">\u003Cem>//server_name/share_name\u003C/em>\u003C/span>  \u003Cspan class=\"emphasis\">\u003Cem>/mnt\u003C/em>\u003C/span>  cifs  \u003Ccode class=\"literal\">multiuser,sec=ntlmssp\u003C/code>,credentials=\u003Cspan class=\"emphasis\">\u003Cem>/root/smb.cred\u003C/em>\u003C/span>  0 0\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tMount the share:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># mount /mnt/\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cp>\n\t\t\t\t\tIf you do not want to mount the share automatically when the system boots, mount it manually by passing \u003Ccode class=\"literal\">-o multiuser,sec=security_type\u003C/code> to the \u003Ccode class=\"literal\">mount\u003C/code> command. For details about mounting an SMB share manually, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/managing_file_systems/index#proc_manually-mounting-an-smb-share_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux\">Manually mounting an SMB share\u003C/a>.\n\t\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"proc_verifying-if-an-smb-share-is-mounted-with-the-multiuser-option_assembly_performing-a-multi-user-smb-mount\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">5.6.2. Verifying if an SMB share is mounted with the multiuser option\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\t\tTo verify if a share is mounted with the \u003Ccode class=\"literal\">multiuser\u003C/code> option, display the mount options.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"formalpara\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cp>\n\t\t\t\t\t\t\n\u003Cpre class=\"literallayout\"># mount\n...\n\u003Cspan class=\"emphasis\">\u003Cem>//server_name/share_name\u003C/em>\u003C/span> on \u003Cspan class=\"emphasis\">\u003Cem>/mnt\u003C/em>\u003C/span> type cifs (sec=ntlmssp,\u003Ccode class=\"literal\">multiuser\u003C/code>,...)\u003C/pre>\n\n\t\t\t\t\t\u003C/p>\u003C/div>\u003Cp>\n\t\t\t\t\tIf the \u003Ccode class=\"literal\">multiuser\u003C/code> entry is displayed in the list of mount options, the feature is enabled.\n\t\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"proc_accessing-a-share-as-a-user_assembly_performing-a-multi-user-smb-mount\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">5.6.3. Accessing a share as a user\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\t\tIf an SMB share is mounted with the \u003Ccode class=\"literal\">multiuser\u003C/code> option, users can provide their credentials for the server to the kernel’s keyring:\n\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># cifscreds add -u \u003Cspan class=\"emphasis\">\u003Cem>SMB_user_name\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>server_name\u003C/em>\u003C/span>\nPassword: \u003Cspan class=\"emphasis\">\u003Cem>password\u003C/em>\u003C/span>\u003C/pre>\u003Cp>\n\t\t\t\t\tWhen the user performs operations in the directory that contains the mounted SMB share, the server applies the file system permissions for this user, instead of the one initially used when the share was mounted.\n\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\tMultiple users can perform operations using their own credentials on the mounted share at the same time.\n\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/section>\u003C/section>\u003Csection class=\"section\" id=\"con_frequently-used-mount-options_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">5.7. Frequently used SMB mount options\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tWhen you mount an SMB share, the mount options determine:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tHow the connection will be established with the server. For example, which SMB protocol version is used when connecting to the server.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tHow the share will be mounted into the local file system. For example, if the system overrides the remote file and directory permissions to enable multiple local users to access the content on the server.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tTo set multiple options in the fourth field of the \u003Ccode class=\"literal filename\">/etc/fstab\u003C/code> file or in the \u003Ccode class=\"literal\">-o\u003C/code> parameter of a mount command, separate them with commas. For example, see \u003Ca class=\"link\" href=\"#proc_mounting-a-share-with-the-multiuser-option_assembly_performing-a-multi-user-smb-mount\" title=\"5.6.1. Mounting a share with the multiuser option\">Mounting a share with the multiuser option\u003C/a>.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe following list gives frequently used mount options:\n\t\t\t\u003C/p>\u003Crh-table>\u003Ctable class=\"lt-4-cols lt-7-rows\">\u003Ccolgroup>\u003Ccol style=\"width: 29%; \" class=\"col_1\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 71%; \" class=\"col_2\">\u003C!--Empty-->\u003C/col>\u003C/colgroup>\u003Cthead>\u003Ctr>\u003Cth align=\"left\" valign=\"top\" id=\"idm139822456464240\" scope=\"col\">Option\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm139822456463152\" scope=\"col\">Description\u003C/th>\u003C/tr>\u003C/thead>\u003Ctbody>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456464240\"> \u003Cp>\n\t\t\t\t\t\t\t\tcredentials=\u003Cspan class=\"emphasis\">\u003Cem>file_name\u003C/em>\u003C/span>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456463152\"> \u003Cp>\n\t\t\t\t\t\t\t\tSets the path to the credentials file. See \u003Ca class=\"link\" href=\"#proc_authenticating-to-an-smb-share-using-a-credentials-file_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux\" title=\"5.5. Creating a credentials file to authenticate to an SMB share\">Authenticating to an SMB share using a credentials file\u003C/a>.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456464240\"> \u003Cp>\n\t\t\t\t\t\t\t\tdir_mode=\u003Cspan class=\"emphasis\">\u003Cem>mode\u003C/em>\u003C/span>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456463152\"> \u003Cp>\n\t\t\t\t\t\t\t\tSets the directory mode if the server does not support CIFS UNIX extensions.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456464240\"> \u003Cp>\n\t\t\t\t\t\t\t\tfile_mode=\u003Cspan class=\"emphasis\">\u003Cem>mode\u003C/em>\u003C/span>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456463152\"> \u003Cp>\n\t\t\t\t\t\t\t\tSets the file mode if the server does not support CIFS UNIX extensions.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456464240\"> \u003Cp>\n\t\t\t\t\t\t\t\tpassword=\u003Cspan class=\"emphasis\">\u003Cem>password\u003C/em>\u003C/span>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456463152\"> \u003Cp>\n\t\t\t\t\t\t\t\tSets the password used to authenticate to the SMB server. Alternatively, specify a credentials file using the \u003Ccode class=\"literal\">credentials\u003C/code> option.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456464240\"> \u003Cp>\n\t\t\t\t\t\t\t\tseal\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456463152\"> \u003Cp>\n\t\t\t\t\t\t\t\tEnables encryption support for connections using SMB 3.0 or a later protocol version. Therefore, use \u003Ccode class=\"literal\">seal\u003C/code> together with the \u003Ccode class=\"literal\">vers\u003C/code> mount option set to \u003Ccode class=\"literal\">3.0\u003C/code> or later. See the example in \u003Ca class=\"link\" href=\"#proc_manually-mounting-an-smb-share_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux\" title=\"5.3. Manually mounting an SMB share\">Manually mounting an SMB share\u003C/a>.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456464240\"> \u003Cp>\n\t\t\t\t\t\t\t\tsec=\u003Cspan class=\"emphasis\">\u003Cem>security_mode\u003C/em>\u003C/span>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456463152\"> \u003Cp>\n\t\t\t\t\t\t\t\tSets the security mode, such as \u003Ccode class=\"literal\">ntlmsspi\u003C/code>, to enable NTLMv2 password hashing and enabled packet signing. For a list of supported values, see the option’s description in the \u003Ccode class=\"literal\">mount.cifs(8)\u003C/code> man page on your system.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003Cp>\n\t\t\t\t\t\t\t\tIf the server does not support the \u003Ccode class=\"literal\">ntlmv2\u003C/code> security mode, use \u003Ccode class=\"literal\">sec=ntlmssp\u003C/code>, which is the default.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003Cp>\n\t\t\t\t\t\t\t\tFor security reasons, do not use the insecure \u003Ccode class=\"literal\">ntlm\u003C/code> security mode.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456464240\"> \u003Cp>\n\t\t\t\t\t\t\t\tusername=\u003Cspan class=\"emphasis\">\u003Cem>user_name\u003C/em>\u003C/span>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456463152\"> \u003Cp>\n\t\t\t\t\t\t\t\tSets the user name used to authenticate to the SMB server. Alternatively, specify a credentials file using the \u003Ccode class=\"literal\">credentials\u003C/code> option.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456464240\"> \u003Cp>\n\t\t\t\t\t\t\t\tvers=\u003Cspan class=\"emphasis\">\u003Cem>SMB_protocol_version\u003C/em>\u003C/span>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822456463152\"> \u003Cp>\n\t\t\t\t\t\t\t\tSets the SMB protocol version used for the communication with the server.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\u003C/rh-table>\u003Cp>\n\t\t\t\tFor a complete list, see the \u003Ccode class=\"literal\">OPTIONS\u003C/code> section in the \u003Ccode class=\"literal\">mount.cifs(8)\u003C/code> man page on your system.\n\t\t\t\u003C/p>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"assembly_overview-of-persistent-naming-attributes_managing-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 6. Overview of persistent naming attributes\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tAs a system administrator, you need to refer to storage volumes using persistent naming attributes to build storage setups that are reliable over multiple system boots.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"con_disadvantages-of-non-persistent-naming-attributes_assembly_overview-of-persistent-naming-attributes\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">6.1. Disadvantages of non-persistent naming attributes\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tRed Hat Enterprise Linux provides a number of ways to identify storage devices. It is important to use the correct option to identify each device when used in order to avoid inadvertently accessing the wrong device, particularly when installing to or reformatting drives.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tTraditionally, non-persistent names in the form of \u003Ccode class=\"literal\">/dev/sd\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">(major number)\u003C/span>\u003C/em>\u003C/span>\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">(minor number)\u003C/span>\u003C/em>\u003C/span>\u003C/code> are used on Linux to refer to storage devices. The major and minor number range and associated \u003Ccode class=\"literal\">sd\u003C/code> names are allocated for each device when it is detected. This means that the association between the major and minor number range and associated \u003Ccode class=\"literal\">sd\u003C/code> names can change if the order of device detection changes.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tSuch a change in the ordering might occur in the following situations:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe parallelization of the system boot process detects storage devices in a different order with each system boot.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tA disk fails to power up or respond to the SCSI controller. This results in it not being detected by the normal device probe. The disk is not accessible to the system and subsequent devices will have their major and minor number range, including the associated \u003Ccode class=\"literal\">sd\u003C/code> names shifted down. For example, if a disk normally referred to as \u003Ccode class=\"literal\">sdb\u003C/code> is not detected, a disk that is normally referred to as \u003Ccode class=\"literal\">sdc\u003C/code> would instead appear as \u003Ccode class=\"literal\">sdb\u003C/code>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tA SCSI controller (host bus adapter, or HBA) fails to initialize, causing all disks connected to that HBA to not be detected. Any disks connected to subsequently probed HBAs are assigned different major and minor number ranges, and different associated \u003Ccode class=\"literal\">sd\u003C/code> names.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe order of driver initialization changes if different types of HBAs are present in the system. This causes the disks connected to those HBAs to be detected in a different order. This might also occur if HBAs are moved to different PCI slots on the system.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tDisks connected to the system with Fibre Channel, iSCSI, or FCoE adapters might be inaccessible at the time the storage devices are probed, due to a storage array or intervening switch being powered off, for example. This might occur when a system reboots after a power failure, if the storage array takes longer to come online than the system take to boot. Although some Fibre Channel drivers support a mechanism to specify a persistent SCSI target ID to WWPN mapping, this does not cause the major and minor number ranges, and the associated \u003Ccode class=\"literal\">sd\u003C/code> names to be reserved; it only provides consistent SCSI target ID numbers.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tThese reasons make it undesirable to use the major and minor number range or the associated \u003Ccode class=\"literal\">sd\u003C/code> names when referring to devices, such as in the \u003Ccode class=\"literal filename\">/etc/fstab\u003C/code> file. There is the possibility that the wrong device will be mounted and data corruption might result.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tOccasionally, however, it is still necessary to refer to the \u003Ccode class=\"literal\">sd\u003C/code> names even when another mechanism is used, such as when errors are reported by a device. This is because the Linux kernel uses \u003Ccode class=\"literal\">sd\u003C/code> names (and also SCSI host/channel/target/LUN tuples) in kernel messages regarding the device.\n\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"file-system-and-device-identifiers_assembly_overview-of-persistent-naming-attributes\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">6.2. File system and device identifiers\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tFile system identifiers are tied to the file system itself, while device identifiers are linked to the physical block device. Understanding the difference is important for proper storage management.\n\t\t\t\u003C/p>\u003Ch5 id=\"file_system_identifiers\">File system identifiers\u003C/h5>\u003Cp>\n\t\t\t\tFile system identifiers are tied to a particular file system created on a block device. The identifier is also stored as part of the file system. If you copy the file system to a different device, it still carries the same file system identifier. However, if you rewrite the device, such as by formatting it with the \u003Ccode class=\"literal\">mkfs\u003C/code> utility, the device loses the attribute.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tFile system identifiers include:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tUnique identifier (UUID)\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tLabel\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Ch5 id=\"device_identifiers\">Device identifiers\u003C/h5>\u003Cp>\n\t\t\t\tDevice identifiers are tied to a block device: for example, a disk or a partition. If you rewrite the device, such as by formatting it with the \u003Ccode class=\"literal\">mkfs\u003C/code> utility, the device keeps the attribute, because it is not stored in the file system.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tDevice identifiers include:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tWorld Wide Identifier (WWID)\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tPartition UUID\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tSerial number\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Ch5 id=\"recommendations\">Recommendations\u003C/h5>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tSome file systems, such as logical volumes, span multiple devices. Red Hat recommends accessing these file systems using file system identifiers rather than device identifiers.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"con_device-names-managed-by-the-udev-mechanism-in-dev-disk-_assembly_overview-of-persistent-naming-attributes\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">6.3. Device names managed by the udev mechanism in /dev/disk/\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe \u003Ccode class=\"literal\">udev\u003C/code> mechanism is used for all types of devices in Linux, and is not limited only for storage devices. It provides different kinds of persistent naming attributes in the \u003Ccode class=\"literal\">/dev/disk/\u003C/code> directory. In the case of storage devices, Red Hat Enterprise Linux contains \u003Ccode class=\"literal\">udev\u003C/code> rules that create symbolic links in the \u003Ccode class=\"literal\">/dev/disk/\u003C/code> directory. This enables you to refer to storage devices by:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tTheir content\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tA unique identifier\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tTheir serial number.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tAlthough \u003Ccode class=\"literal\">udev\u003C/code> naming attributes are persistent, in that they do not change on their own across system reboots, some are also configurable.\n\t\t\t\u003C/p>\u003Csection class=\"section\" id=\"file-system-identifiers_assembly_overview-of-persistent-naming-attributes\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">6.3.1. File system identifiers\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Ch5 id=\"the_uuid_attribute_in_dev_disk_by_uuid\">The UUID attribute in /dev/disk/by-uuid/\u003C/h5>\u003Cp>\n\t\t\t\t\tEntries in this directory provide a symbolic name that refers to the storage device by a \u003Cspan class=\"strong strong\">\u003Cstrong>unique identifier\u003C/strong>\u003C/span> (UUID) in the content (that is, the data) stored on the device. For example:\n\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">/dev/disk/by-uuid/\u003Cspan class=\"emphasis\">\u003Cem>3e6be9de-8139-11d1-9106-a43f08d823a6\u003C/em>\u003C/span>\u003C/pre>\u003Cp>\n\t\t\t\t\tYou can use the UUID to refer to the device in the \u003Ccode class=\"literal filename\">/etc/fstab\u003C/code> file using the following syntax:\n\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">UUID=\u003Cspan class=\"emphasis\">\u003Cem>3e6be9de-8139-11d1-9106-a43f08d823a6\u003C/em>\u003C/span>\u003C/pre>\u003Cp>\n\t\t\t\t\tYou can configure the UUID attribute when creating a file system, and you can also change it later on.\n\t\t\t\t\u003C/p>\u003Ch5 id=\"the_label_attribute_in_dev_disk_by_label\">The Label attribute in /dev/disk/by-label/\u003C/h5>\u003Cp>\n\t\t\t\t\tEntries in this directory provide a symbolic name that refers to the storage device by a \u003Cspan class=\"strong strong\">\u003Cstrong>label\u003C/strong>\u003C/span> in the content (that is, the data) stored on the device.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tFor example:\n\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">/dev/disk/by-label/\u003Cspan class=\"emphasis\">\u003Cem>Boot\u003C/em>\u003C/span>\u003C/pre>\u003Cp>\n\t\t\t\t\tYou can use the label to refer to the device in the \u003Ccode class=\"literal filename\">/etc/fstab\u003C/code> file using the following syntax:\n\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">LABEL=\u003Cspan class=\"emphasis\">\u003Cem>Boot\u003C/em>\u003C/span>\u003C/pre>\u003Cp>\n\t\t\t\t\tYou can configure the Label attribute when creating a file system, and you can also change it later on.\n\t\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"device-identifiers_assembly_overview-of-persistent-naming-attributes\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">6.3.2. Device identifiers\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Ch5 id=\"the_wwid_attribute_in_dev_disk_by_id\">The WWID attribute in /dev/disk/by-id/\u003C/h5>\u003Cp>\n\t\t\t\t\tThe World Wide Identifier (WWID) is a persistent, \u003Cspan class=\"strong strong\">\u003Cstrong>system-independent identifier\u003C/strong>\u003C/span> that the SCSI Standard requires from all SCSI devices. The WWID identifier is guaranteed to be unique for every storage device, and independent of the path that is used to access the device. The identifier is a property of the device but is not stored in the content (that is, the data) on the devices.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tThis identifier can be obtained by issuing a SCSI Inquiry to retrieve the Device Identification Vital Product Data (page \u003Ccode class=\"literal\">0x83\u003C/code>) or Unit Serial Number (page \u003Ccode class=\"literal\">0x80\u003C/code>).\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tRed Hat Enterprise Linux automatically maintains the proper mapping from the WWID-based device name to a current \u003Ccode class=\"literal\">/dev/sd\u003C/code> name on that system. Applications can use the \u003Ccode class=\"literal\">/dev/disk/by-id/\u003C/code> name to reference the data on the disk, even if the path to the device changes, and even when accessing the device from different systems.\n\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\tIf your are using an NVMe device, you might run into a disk by-id naming change for some vendors, if the serial number of your device has leading whitespace.\n\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"example\" id=\"idm139822461318192\">\u003Cp class=\"title\">\u003Cstrong>Example 6.1. WWID mappings\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Crh-table>\u003Ctable class=\"lt-4-cols lt-7-rows\">\u003Ccolgroup>\u003Ccol style=\"width: 50%; \" class=\"col_1\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 25%; \" class=\"col_2\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 25%; \" class=\"col_3\">\u003C!--Empty-->\u003C/col>\u003C/colgroup>\u003Cthead>\u003Ctr>\u003Cth align=\"left\" valign=\"top\" id=\"idm139822460306640\" scope=\"col\">WWID symlink\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm139822460305552\" scope=\"col\">Non-persistent device\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm139822460304464\" scope=\"col\">Note\u003C/th>\u003C/tr>\u003C/thead>\u003Ctbody>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822460306640\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal filename\">/dev/disk/by-id/scsi-3600508b400105e210000900000490000\u003C/code>\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822460305552\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal filename\">/dev/sda\u003C/code>\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822460304464\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\tA device with a page \u003Ccode class=\"literal\">0x83\u003C/code> identifier\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822460306640\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal filename\">/dev/disk/by-id/scsi-SSEAGATE_ST373453LW_3HW1RHM6\u003C/code>\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822460305552\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal filename\">/dev/sdb\u003C/code>\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822460304464\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\tA device with a page \u003Ccode class=\"literal\">0x80\u003C/code> identifier\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822460306640\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal filename\">/dev/disk/by-id/ata-SAMSUNG_MZNLN256HMHQ-000L7_S2WDNX0J336519-part3\u003C/code>\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822460305552\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal filename\">/dev/sdc3\u003C/code>\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822460304464\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\tA disk partition\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\u003C/rh-table>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tIn addition to these persistent names provided by the system, you can also use \u003Ccode class=\"literal\">udev\u003C/code> rules to implement persistent names of your own, mapped to the WWID of the storage.\n\t\t\t\t\u003C/p>\u003Ch5 id=\"the_partition_uuid_attribute_in_dev_disk_by_partuuid\">The Partition UUID attribute in /dev/disk/by-partuuid\u003C/h5>\u003Cp>\n\t\t\t\t\tThe Partition UUID (PARTUUID) attribute identifies partitions as defined by GPT partition table.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"example\" id=\"idm139822467256560\">\u003Cp class=\"title\">\u003Cstrong>Example 6.2. Partition UUID mappings\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Crh-table>\u003Ctable class=\"lt-4-cols lt-7-rows\">\u003Ccolgroup>\u003Ccol style=\"width: 60%; \" class=\"col_1\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 40%; \" class=\"col_2\">\u003C!--Empty-->\u003C/col>\u003C/colgroup>\u003Cthead>\u003Ctr>\u003Cth align=\"left\" valign=\"top\" id=\"idm139822458643456\" scope=\"col\">PARTUUID symlink\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm139822458642368\" scope=\"col\">Non-persistent device\u003C/th>\u003C/tr>\u003C/thead>\u003Ctbody>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822458643456\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal filename\">/dev/disk/by-partuuid/4cd1448a-01\u003C/code>\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822458642368\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal filename\">/dev/sda1\u003C/code>\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822458643456\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal filename\">/dev/disk/by-partuuid/4cd1448a-02\u003C/code>\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822458642368\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal filename\">/dev/sda2\u003C/code>\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822458643456\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal filename\">/dev/disk/by-partuuid/4cd1448a-03\u003C/code>\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822458642368\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal filename\">/dev/sda3\u003C/code>\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\u003C/rh-table>\u003C/div>\u003C/div>\u003Ch5 id=\"the_path_attribute_in_dev_disk_by_path\">The Path attribute in /dev/disk/by-path/\u003C/h5>\u003Cp>\n\t\t\t\t\tThis attribute provides a symbolic name that refers to the storage device by the \u003Cspan class=\"strong strong\">\u003Cstrong>hardware path\u003C/strong>\u003C/span> used to access the device.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tThe Path attribute fails if any part of the hardware path (for example, the PCI ID, target port, or LUN number) changes. The Path attribute is therefore unreliable. However, the Path attribute may be useful in one of the following scenarios:\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tYou need to identify a disk that you are planning to replace later.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tYou plan to install a storage service on a disk in a specific location.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"section\" id=\"con_the-world-wide-identifier-with-dm-multipath_assembly_overview-of-persistent-naming-attributes\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">6.4. The World Wide Identifier with DM Multipath\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tYou can configure Device Mapper (DM) Multipath to map between the World Wide Identifier (WWID) and non-persistent device names.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tIf there are multiple paths from a system to a device, DM Multipath uses the WWID to detect this. DM Multipath then presents a single \"pseudo-device\" in the \u003Ccode class=\"literal\">/dev/mapper/wwid\u003C/code> directory, such as \u003Ccode class=\"literal\">/dev/mapper/3600508b400105df70000e00000ac0000\u003C/code>.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe command \u003Ccode class=\"literal\">multipath -l\u003C/code> shows the mapping to the non-persistent identifiers:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>Host\u003C/em>\u003C/span>:\u003Cspan class=\"emphasis\">\u003Cem>Channel\u003C/em>\u003C/span>:\u003Cspan class=\"emphasis\">\u003Cem>Target\u003C/em>\u003C/span>:\u003Cspan class=\"emphasis\">\u003Cem>LUN\u003C/em>\u003C/span>\u003C/code>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/dev/sd\u003C/code> name\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>major\u003C/em>\u003C/span>:\u003Cspan class=\"emphasis\">\u003Cem>minor\u003C/em>\u003C/span>\u003C/code> number\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"example\" id=\"idm139822458398160\">\u003Cp class=\"title\">\u003Cstrong>Example 6.3. WWID mappings in a multipath configuration\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\tAn example output of the \u003Ccode class=\"literal\">multipath -l\u003C/code> command:\n\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">3600508b400105df70000e00000ac0000 dm-2 vendor,product\n[size=20G][features=1 queue_if_no_path][hwhandler=0][rw]\n\\_ round-robin 0 [prio=0][active]\n \\_ 5:0:1:1 sdc 8:32  [active][undef]\n \\_ 6:0:1:1 sdg 8:96  [active][undef]\n\\_ round-robin 0 [prio=0][enabled]\n \\_ 5:0:0:1 sdb 8:16  [active][undef]\n \\_ 6:0:0:1 sdf 8:80  [active][undef]\u003C/pre>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tDM Multipath automatically maintains the proper mapping of each WWID-based device name to its corresponding \u003Ccode class=\"literal\">/dev/sd\u003C/code> name on the system. These names are persistent across path changes, and they are consistent when accessing the device from different systems.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tWhen the \u003Ccode class=\"literal\">user_friendly_names\u003C/code> feature of DM Multipath is used, the WWID is mapped to a name of the form \u003Ccode class=\"literal\">/dev/mapper/mpath\u003Cspan class=\"emphasis\">\u003Cem>N\u003C/em>\u003C/span>\u003C/code>. By default, this mapping is maintained in the file \u003Ccode class=\"literal\">/etc/multipath/bindings\u003C/code>. These \u003Ccode class=\"literal\">mpath\u003Cspan class=\"emphasis\">\u003Cem>N\u003C/em>\u003C/span>\u003C/code> names are persistent as long as that file is maintained.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tIf you use \u003Ccode class=\"literal\">user_friendly_names\u003C/code>, then additional steps are required to obtain consistent names in a cluster.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/section>\u003Csection class=\"section\" id=\"con_limitations-of-the-udev-device-naming-convention_assembly_overview-of-persistent-naming-attributes\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">6.5. Limitations of the udev device naming convention\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe following are some limitations of the \u003Ccode class=\"literal\">udev\u003C/code> naming convention:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIt is possible that the device might not be accessible at the time the query is performed because the \u003Ccode class=\"literal\">udev\u003C/code> mechanism might rely on the ability to query the storage device when the \u003Ccode class=\"literal\">udev\u003C/code> rules are processed for a \u003Ccode class=\"literal\">udev\u003C/code> event. This is more likely to occur with Fibre Channel, iSCSI or FCoE storage devices when the device is not located in the server chassis.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe kernel might send \u003Ccode class=\"literal\">udev\u003C/code> events at any time, causing the rules to be processed and possibly causing the \u003Ccode class=\"literal filename\">/dev/disk/by-*/\u003C/code> links to be removed if the device is not accessible.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThere might be a delay between when the \u003Ccode class=\"literal\">udev\u003C/code> event is generated and when it is processed, such as when a large number of devices are detected and the user-space \u003Ccode class=\"literal\">udevd\u003C/code> service takes some amount of time to process the rules for each one. This might cause a delay between when the kernel detects the device and when the \u003Ccode class=\"literal filename\">/dev/disk/by-*/\u003C/code> names are available.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tExternal programs such as \u003Ccode class=\"literal\">blkid\u003C/code> invoked by the rules might open the device for a brief period of time, making the device inaccessible for other uses.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe device names managed by the \u003Ccode class=\"literal\">udev\u003C/code> mechanism in /dev/disk/ may change between major releases, requiring you to update the links.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"proc_listing-persistent-naming-attributes_assembly_overview-of-persistent-naming-attributes\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">6.6. Listing persistent naming attributes\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can find out the persistent naming attributes of non-persistent storage devices.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo list the UUID and Label attributes, use the \u003Ccode class=\"literal\">lsblk\u003C/code> utility:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ lsblk --fs \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">storage-device\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor example:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"example\" id=\"idm139822448907872\">\u003Cp class=\"title\">\u003Cstrong>Example 6.4. Viewing the UUID and Label of a file system\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cpre class=\"screen\">$ lsblk --fs /dev/sda1\n\nNAME FSTYPE \u003Cspan class=\"strong strong\">\u003Cstrong>LABEL\u003C/strong>\u003C/span> \u003Cspan class=\"strong strong\">\u003Cstrong>UUID\u003C/strong>\u003C/span>                                 MOUNTPOINT\nsda1 xfs    \u003Cspan class=\"strong strong\">\u003Cstrong>Boot\u003C/strong>\u003C/span>  \u003Cspan class=\"strong strong\">\u003Cstrong>afa5d5e3-9050-48c3-acc1-bb30095f3dc4\u003C/strong>\u003C/span> /boot\u003C/pre>\u003C/div>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo list the PARTUUID attribute, use the \u003Ccode class=\"literal\">lsblk\u003C/code> utility with the \u003Ccode class=\"literal option\">--output +PARTUUID\u003C/code> option:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ lsblk --output +PARTUUID\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor example:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"example\" id=\"idm139822453035200\">\u003Cp class=\"title\">\u003Cstrong>Example 6.5. Viewing the PARTUUID attribute of a partition\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cpre class=\"screen\">$ lsblk --output +PARTUUID /dev/sda1\n\nNAME MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT \u003Cspan class=\"strong strong\">\u003Cstrong>PARTUUID\u003C/strong>\u003C/span>\nsda1   8:1    0  512M  0 part /boot      \u003Cspan class=\"strong strong\">\u003Cstrong>4cd1448a-01\u003C/strong>\u003C/span>\u003C/pre>\u003C/div>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo list the WWID attribute, examine the targets of symbolic links in the \u003Ccode class=\"literal filename\">/dev/disk/by-id/\u003C/code> directory. For example:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"example\" id=\"idm139822448577520\">\u003Cp class=\"title\">\u003Cstrong>Example 6.6. Viewing the WWID of all storage devices on the system\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cpre class=\"screen\">$ file /dev/disk/by-id/*\n\n/dev/disk/by-id/ata-QEMU_HARDDISK_QM00001\nsymbolic link to ../../sda\n/dev/disk/by-id/ata-QEMU_HARDDISK_QM00001-part1\nsymbolic link to ../../sda1\n/dev/disk/by-id/ata-QEMU_HARDDISK_QM00001-part2\nsymbolic link to ../../sda2\n/dev/disk/by-id/dm-name-rhel_rhel8-root\nsymbolic link to ../../dm-0\n/dev/disk/by-id/dm-name-rhel_rhel8-swap\nsymbolic link to ../../dm-1\n/dev/disk/by-id/dm-uuid-LVM-QIWtEHtXGobe5bewlIUDivKOz5ofkgFhP0RMFsNyySVihqEl2cWWbR7MjXJolD6g\nsymbolic link to ../../dm-1\n/dev/disk/by-id/dm-uuid-LVM-QIWtEHtXGobe5bewlIUDivKOz5ofkgFhXqH2M45hD2H9nAf2qfWSrlRLhzfMyOKd\nsymbolic link to ../../dm-0\n/dev/disk/by-id/lvm-pv-uuid-atlr2Y-vuMo-ueoH-CpMG-4JuH-AhEF-wu4QQm\nsymbolic link to ../../sda2\u003C/pre>\u003C/div>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"proc_modifying-persistent-naming-attributes_assembly_overview-of-persistent-naming-attributes\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">6.7. Modifying persistent naming attributes\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can change the UUID or Label persistent naming attribute of a file system.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tChanging \u003Ccode class=\"literal\">udev\u003C/code> attributes happens in the background and might take a long time. The \u003Ccode class=\"literal command\">udevadm settle\u003C/code> command waits until the change is fully registered, which ensures that your next command will be able to use the new attribute correctly.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cp>\n\t\t\t\tIn the following commands:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">new-uuid\u003C/span>\u003C/em>\u003C/span> with the UUID you want to set; for example, \u003Ccode class=\"literal\">1cdfbc07-1c90-4984-b5ec-f61943f5ea50\u003C/code>. You can generate a UUID using the \u003Ccode class=\"literal command\">uuidgen\u003C/code> command.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">new-label\u003C/span>\u003C/em>\u003C/span> with a label; for example, \u003Ccode class=\"literal\">backup_data\u003C/code>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIf you are modifying the attributes of an XFS file system, unmount it first.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo change the UUID or Label attributes of an \u003Cspan class=\"strong strong\">\u003Cstrong>XFS\u003C/strong>\u003C/span> file system, use the \u003Ccode class=\"literal\">xfs_admin\u003C/code> utility:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># xfs_admin -U \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">new-uuid\u003C/span>\u003C/em>\u003C/span> -L \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">new-label\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">storage-device\u003C/span>\u003C/em>\u003C/span>\n# udevadm settle\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo change the UUID or Label attributes of an \u003Cspan class=\"strong strong\">\u003Cstrong>ext4\u003C/strong>\u003C/span>, \u003Cspan class=\"strong strong\">\u003Cstrong>ext3\u003C/strong>\u003C/span>, or \u003Cspan class=\"strong strong\">\u003Cstrong>ext2\u003C/strong>\u003C/span> file system, use the \u003Ccode class=\"literal\">tune2fs\u003C/code> utility:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># tune2fs -U \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">new-uuid\u003C/span>\u003C/em>\u003C/span> -L \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">new-label\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">storage-device\u003C/span>\u003C/em>\u003C/span>\n# udevadm settle\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo change the UUID or Label attributes of a swap volume, use the \u003Ccode class=\"literal\">swaplabel\u003C/code> utility:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># swaplabel --uuid \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">new-uuid\u003C/span>\u003C/em>\u003C/span> --label \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">new-label\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">swap-device\u003C/span>\u003C/em>\u003C/span>\n# udevadm settle\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"partition-operations-with-parted_managing-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 7. Partition operations with parted\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\u003Ccode class=\"literal\">parted\u003C/code> is a program to manipulate disk partitions. It supports multiple partition table formats, including MS-DOS and GPT. It is useful for creating space for new operating systems, reorganizing disk usage, and copying data to new hard disks.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"viewing-the-partition-table-with-parted_partition-operations-with-parted\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">7.1. Viewing the partition table with parted\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tDisplay the partition table of a block device to see the partition layout and details about individual partitions. You can view the partition table on a block device using the \u003Ccode class=\"literal\">parted\u003C/code> utility.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tStart the \u003Ccode class=\"literal\">parted\u003C/code> utility. For example, the following output lists the device \u003Ccode class=\"literal\">/dev/sda\u003C/code>:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># parted /dev/sda\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tView the partition table:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># (parted) print\n\nModel: ATA SAMSUNG MZNLN256 (scsi)\nDisk /dev/sda: 256GB\nSector size (logical/physical): 512B/512B\nPartition Table: msdos\nDisk Flags:\n\nNumber  Start   End     Size    Type      File system  Flags\n 1      1049kB  269MB   268MB   primary   xfs          boot\n 2      269MB   34.6GB  34.4GB  primary\n 3      34.6GB  45.4GB  10.7GB  primary\n 4      45.4GB  256GB   211GB   extended\n 5      45.4GB  256GB   211GB   logical\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOptional: Switch to the device you want to examine next:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># (parted) select \u003Cspan class=\"emphasis\">\u003Cem>block-device\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cp>\n\t\t\t\tFor a detailed description of the print command output, see the following:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Model: ATA SAMSUNG MZNLN256 (scsi)\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe disk type, manufacturer, model number, and interface.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Disk /dev/sda: 256GB\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe file path to the block device and the storage capacity.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Partition Table: msdos\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe disk label type.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Number\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe partition number. For example, the partition with minor number 1 corresponds to \u003Ccode class=\"literal filename\">/dev/sda1\u003C/code>.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Start\u003C/code> and \u003Ccode class=\"literal\">End\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe location on the device where the partition starts and ends.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Type\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tValid types are metadata, free, primary, extended, or logical.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">File system\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe file system type. If the \u003Ccode class=\"literal\">File system\u003C/code> field of a device shows no value, this means that its file system type is unknown. The \u003Ccode class=\"literal\">parted\u003C/code> utility cannot recognize the file system on encrypted devices.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Flags\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tLists the flags set for the partition. Available flags are \u003Ccode class=\"literal\">boot\u003C/code>, \u003Ccode class=\"literal\">root\u003C/code>, \u003Ccode class=\"literal\">swap\u003C/code>, \u003Ccode class=\"literal\">hidden\u003C/code>, \u003Ccode class=\"literal\">raid\u003C/code>, \u003Ccode class=\"literal\">lvm\u003C/code>, or \u003Ccode class=\"literal\">lba\u003C/code>.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">parted(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"proc_creating-a-partition-table-on-a-disk-with-parted_partition-operations-with-parted\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">7.2. Creating a partition table on a disk with parted\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tUse the \u003Ccode class=\"literal\">parted\u003C/code> utility to format a block device with a partition table more easily.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition warning\" state=\"danger\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Warning\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tFormatting a block device with a partition table deletes all data stored on the device.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tStart the interactive \u003Ccode class=\"literal\">parted\u003C/code> shell:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># parted \u003Cspan class=\"emphasis\">\u003Cem>block-device\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tDetermine if there already is a partition table on the device:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># (parted) print\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIf the device already contains partitions, they will be deleted in the following steps.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate the new partition table:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># (parted) mklabel \u003Cspan class=\"emphasis\">\u003Cem>table-type\u003C/em>\u003C/span>\u003C/pre>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>table-type\u003C/em>\u003C/span> with with the intended partition table type:\n\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">msdos\u003C/code> for MBR\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">gpt\u003C/code> for GPT\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"example\" id=\"idm139822449441328\">\u003Cp class=\"title\">\u003Cstrong>Example 7.1. Creating a GUID Partition Table (GPT) table\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\t\t\tTo create a GPT table on the disk, use:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># (parted) mklabel gpt\u003C/pre>\u003C/div>\u003C/div>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe changes start applying after you enter this command.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tView the partition table to confirm that it is created:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># (parted) print\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tExit the \u003Ccode class=\"literal\">parted\u003C/code> shell:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># (parted) quit\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">parted(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"proc_creating-a-partition-with-parted_partition-operations-with-parted\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">7.3. Creating a partition with parted\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tAs a system administrator, you can create new partitions on a disk by using the \u003Ccode class=\"literal\">parted\u003C/code> utility.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tThe required partitions are \u003Ccode class=\"literal\">swap\u003C/code>, \u003Ccode class=\"literal\">/boot/\u003C/code>, and \u003Ccode class=\"literal\">/ (root)\u003C/code>.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tA partition table on the disk.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIf the partition you want to create is larger than 2TiB, format the disk with the \u003Cspan class=\"strong strong\">\u003Cstrong>GUID Partition Table (GPT)\u003C/strong>\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tStart the \u003Ccode class=\"literal\">parted\u003C/code> utility:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># parted \u003Cspan class=\"emphasis\">\u003Cem>block-device\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tView the current partition table to determine if there is enough free space:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># (parted) print\u003C/pre>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tResize the partition in case there is not enough free space.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tFrom the partition table, determine:\n\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\tThe start and end points of the new partition.\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\tOn MBR, what partition type it should be.\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate the new partition:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># (parted) mkpart \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">part-type\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">name\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">fs-type\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">start\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">end\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>part-type\u003C/em>\u003C/span> with with \u003Ccode class=\"literal\">primary\u003C/code>, \u003Ccode class=\"literal\">logical\u003C/code>, or \u003Ccode class=\"literal\">extended\u003C/code>. This applies only to the MBR partition table.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>name\u003C/em>\u003C/span> with an arbitrary partition name. This is required for GPT partition tables.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>fs-type\u003C/em>\u003C/span> with \u003Ccode class=\"literal\">xfs\u003C/code>, \u003Ccode class=\"literal\">ext2\u003C/code>, \u003Ccode class=\"literal\">ext3\u003C/code>, \u003Ccode class=\"literal\">ext4\u003C/code>, \u003Ccode class=\"literal\">fat16\u003C/code>, \u003Ccode class=\"literal\">fat32\u003C/code>, \u003Ccode class=\"literal\">hfs\u003C/code>, \u003Ccode class=\"literal\">hfs+\u003C/code>, \u003Ccode class=\"literal\">linux-swap\u003C/code>, \u003Ccode class=\"literal\">ntfs\u003C/code>, or \u003Ccode class=\"literal\">reiserfs\u003C/code>. The \u003Cspan class=\"emphasis\">\u003Cem>fs-type\u003C/em>\u003C/span> parameter is optional. Note that the \u003Ccode class=\"literal\">parted\u003C/code> utility does not create the file system on the partition.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>start\u003C/em>\u003C/span> and \u003Cspan class=\"emphasis\">\u003Cem>end\u003C/em>\u003C/span> with the sizes that determine the starting and ending points of the partition, counting from the beginning of the disk. You can use size suffixes, such as \u003Ccode class=\"literal\">512MiB\u003C/code>, \u003Ccode class=\"literal\">20GiB\u003C/code>, or \u003Ccode class=\"literal\">1.5TiB\u003C/code>. The default size is in megabytes.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"example\" id=\"idm139822467127696\">\u003Cp class=\"title\">\u003Cstrong>Example 7.2. Creating a small primary partition\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\t\t\tTo create a primary partition from 1024MiB until 2048MiB on an MBR table, use:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># (parted) mkpart primary 1024MiB 2048MiB\u003C/pre>\u003C/div>\u003C/div>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe changes start applying after you enter the command.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tView the partition table to confirm that the created partition is in the partition table with the correct partition type, file system type, and size:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># (parted) print\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tExit the \u003Ccode class=\"literal\">parted\u003C/code> shell:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># (parted) quit\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRegister the new device node:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># udevadm settle\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify that the kernel recognizes the new partition:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># cat /proc/partitions\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">parted(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_file_systems/partition-operations-with-parted_managing-file-systems#proc_creating-a-partition-table-on-a-disk-with-parted_partition-operations-with-parted\">Creating a partition table on a disk with parted\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_file_systems/partition-operations-with-parted_managing-file-systems#proc_resizing-a-partition-with-parted_partition-operations-with-parted\">Resizing a partition with parted\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"proc_removing-a-partition-with-parted_partition-operations-with-parted\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">7.4. Removing a partition with parted\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tUsing the \u003Ccode class=\"literal\">parted\u003C/code> utility, you can remove a disk partition to free up disk space.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition warning\" state=\"danger\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Warning\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tRemoving a partition deletes all data stored on the partition.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tStart the interactive \u003Ccode class=\"literal\">parted\u003C/code> shell:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># parted \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">block-device\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">block-device\u003C/span>\u003C/em>\u003C/span> with the path to the device where you want to remove a partition: for example, \u003Ccode class=\"literal filename\">/dev/sda\u003C/code>.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tView the current partition table to determine the minor number of the partition to remove:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">(parted) print\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRemove the partition:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">(parted) rm \u003Cspan class=\"emphasis\">\u003Cem>minor-number\u003C/em>\u003C/span>\u003C/pre>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>minor-number\u003C/em>\u003C/span> with the minor number of the partition you want to remove.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe changes start applying as soon as you enter this command.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify that you have removed the partition from the partition table:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">(parted) print\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tExit the \u003Ccode class=\"literal\">parted\u003C/code> shell:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">(parted) quit\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify that the kernel registers that the partition is removed:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># cat /proc/partitions\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tRemove the partition from the \u003Ccode class=\"literal\">/etc/fstab\u003C/code> file, if it is present. Find the line that declares the removed partition, and remove it from the file.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRegenerate mount units so that your system registers the new \u003Ccode class=\"literal\">/etc/fstab\u003C/code> configuration:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># systemctl daemon-reload\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIf you have deleted a swap partition or removed pieces of LVM, remove all references to the partition from the kernel command line:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tList active kernel options and see if any option references the removed partition:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># grubby --info=ALL\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tRemove the kernel options that reference the removed partition:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># grubby --update-kernel=ALL --remove-args=\"\u003Cspan class=\"emphasis\">\u003Cem>option\u003C/em>\u003C/span>\"\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo register the changes in the early boot system, rebuild the \u003Ccode class=\"literal\">initramfs\u003C/code> file system:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dracut --force --verbose\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">parted(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"proc_resizing-a-partition-with-parted_partition-operations-with-parted\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">7.5. Resizing a partition with parted\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tUsing the \u003Ccode class=\"literal\">parted\u003C/code> utility, extend a partition to use unused disk space, or shrink a partition to use its capacity for different purposes.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tBack up the data before shrinking a partition.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIf the partition you want to create is larger than 2TiB, format the disk with the \u003Cspan class=\"strong strong\">\u003Cstrong>GUID Partition Table (GPT)\u003C/strong>\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIf you want to shrink the partition, first shrink the file system so that it is not larger than the resized partition.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tXFS does not support shrinking.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tStart the \u003Ccode class=\"literal\">parted\u003C/code> utility:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># parted \u003Cspan class=\"emphasis\">\u003Cem>block-device\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tView the current partition table:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># (parted) print\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFrom the partition table, determine:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe minor number of the partition.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe location of the existing partition and its new ending point after resizing.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tResize the partition:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># (parted) resizepart \u003Cspan class=\"emphasis\">\u003Cem>1\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>2GiB\u003C/em>\u003C/span>\u003C/pre>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>1\u003C/em>\u003C/span> with the minor number of the partition that you are resizing.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>2\u003C/em>\u003C/span> with the size that determines the new ending point of the resized partition, counting from the beginning of the disk. You can use size suffixes, such as \u003Ccode class=\"literal\">512MiB\u003C/code>, \u003Ccode class=\"literal\">20GiB\u003C/code>, or \u003Ccode class=\"literal\">1.5TiB\u003C/code>. The default size is in megabytes.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tView the partition table to confirm that the resized partition is in the partition table with the correct size:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># (parted) print\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tExit the \u003Ccode class=\"literal\">parted\u003C/code> shell:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># (parted) quit\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify that the kernel registers the new partition:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># cat /proc/partitions\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tOptional: If you extended the partition, extend the file system on it as well.\n\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">parted(8)\u003C/code> man page.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"strategies-for-repartitioning-a-disk_managing-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 8. Strategies for repartitioning a disk\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\tThere are different approaches to repartitioning a disk. These include:\n\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\tUnpartitioned free space is available.\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tAn unused partition is available.\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tFree space in an actively used partition is available.\n\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\tThe following examples are simplified for clarity and do not reflect the exact partition layout when actually installing Red Hat Enterprise Linux.\n\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Csection class=\"section\" id=\"using-unpartitioned-free-space_strategies-for-repartitioning-a-disk\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">8.1. Using unpartitioned free space\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tPartitions that are already defined and do not span the entire hard disk, leave unallocated space that is not part of any defined partition. The following diagram shows what this might look like.\n\t\t\t\u003C/p>\u003Cdiv class=\"figure\" id=\"idm139822450142592\">\u003Cp class=\"title\">\u003Cstrong>Figure 8.1. Disk with unpartitioned free space\u003C/strong>\u003C/p>\u003Cdiv class=\"figure-contents\">\u003Cdiv class=\"mediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/9bf58e64ea156351d8517609bd24afbe/unpart-space.png\" alt=\"unpart space\"/>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tThe first diagram represents a disk with one primary partition and an undefined partition with unallocated space. The second diagram represents a disk with two defined partitions with allocated space.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tAn unused hard disk also falls into this category. The only difference is that \u003Cspan class=\"emphasis\">\u003Cem>all\u003C/em>\u003C/span> the space is not part of any defined partition.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tOn a new disk, you can create the necessary partitions from the unused space. Most preinstalled operating systems are configured to take up all available space on a disk drive.\n\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"using-space-from-an-unused-partition_strategies-for-repartitioning-a-disk\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">8.2. Using space from an unused partition\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tIn the following example, the first diagram represents a disk with an unused partition. The second diagram represents reallocating an unused partition for Linux.\n\t\t\t\u003C/p>\u003Cdiv class=\"figure\" id=\"idm139822448596048\">\u003Cp class=\"title\">\u003Cstrong>Figure 8.2. Disk with an unused partition\u003C/strong>\u003C/p>\u003Cdiv class=\"figure-contents\">\u003Cdiv class=\"mediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/f617fa878e1ca30a354e912eb6a67596/unused-partition.png\" alt=\"unused partition\"/>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tTo use the space allocated to the unused partition, delete the partition and then create the appropriate Linux partition instead. Alternatively, during the installation process, delete the unused partition and manually create new partitions.\n\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"using-free-space-from-an-active-partition_strategies-for-repartitioning-a-disk\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">8.3. Using free space from an active partition\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tThis process can be difficult to manage because an active partition, that is already in use, contains the required free space. In most cases, hard disks of computers with preinstalled software contain one larger partition holding the operating system and data.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition warning\" state=\"danger\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Warning\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tIf you want to use an operating system (OS) on an active partition, you must reinstall the OS. Be aware that some computers, which include pre-installed software, do not include installation media to reinstall the original OS. Check whether this applies to your OS before you destroy an original partition and the OS installation.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cp>\n\t\t\t\tTo optimise the use of available free space, you can use the methods of destructive or non-destructive repartitioning.\n\t\t\t\u003C/p>\u003Csection class=\"section\" id=\"destructive-repartitioning_using-free-space-from-an-active-partition\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">8.3.1. Destructive repartitioning\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tDestructive repartitioning destroys the partition on your hard drive and creates several smaller partitions instead. Backup any needed data from the original partition as this method deletes the complete contents.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tAfter creating a smaller partition for your existing operating system, you can:\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tReinstall software.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tRestore your data.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tStart your Red Hat Enterprise Linux installation.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\t\tThe following diagram is a simplified representation of using the destructive repartitioning method.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"figure\" id=\"idm139822453369168\">\u003Cp class=\"title\">\u003Cstrong>Figure 8.3. Destructive repartitioning action on disk\u003C/strong>\u003C/p>\u003Cdiv class=\"figure-contents\">\u003Cdiv class=\"mediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/216af447e0b72d58cd1c3b8636e40ca1/dstrct-reprt.png\" alt=\"dstrct reprt\"/>\u003C/div>\u003C/div>\u003C/div>\u003Crh-alert class=\"admonition warning\" state=\"danger\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Warning\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\tThis method deletes all data previously stored in the original partition.\n\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/section>\u003Csection class=\"section\" id=\"non-destructive-repartitioning_using-free-space-from-an-active-partition\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">8.3.2. Non-destructive repartitioning\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tNon-destructive repartitioning resizes partitions, without any data loss. This method is reliable, however it takes longer processing time on large drives.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tThe following is a list of methods, which can help initiate non-destructive repartitioning.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tCompress existing data\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\t\tThe storage location of some data cannot be changed. This can prevent the resizing of a partition to the required size, and ultimately lead to a destructive repartition process. Compressing data in an already existing partition can help you resize your partitions as needed. It can also help to maximize the free space available.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tThe following diagram is a simplified representation of this process.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"figure\" id=\"idm139822448611904\">\u003Cp class=\"title\">\u003Cstrong>Figure 8.4. Data compression on a disk\u003C/strong>\u003C/p>\u003Cdiv class=\"figure-contents\">\u003Cdiv class=\"mediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/43ebf43f99569475246687fdc405a96d/compression.png\" alt=\"compression\"/>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tTo avoid any possible data loss, create a backup before continuing with the compression process.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tResize the existing partition\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\t\tBy resizing an already existing partition, you can free up more space. Depending on your resizing software, the results may vary. In the majority of cases, you can create a new unformatted partition of the same type, as the original partition.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tThe steps you take after resizing can depend on the software you use. In the following example, the best practice is to delete the new DOS (Disk Operating System) partition, and create a Linux partition instead. Verify what is most suitable for your disk before initiating the resizing process.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"figure\" id=\"idm139822448604544\">\u003Cp class=\"title\">\u003Cstrong>Figure 8.5. Partition resizing on a disk\u003C/strong>\u003C/p>\u003Cdiv class=\"figure-contents\">\u003Cdiv class=\"mediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/a025b166d95662700634e74f4bb8b5b6/part-resize.png\" alt=\"part resize\"/>\u003C/div>\u003C/div>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tOptional: Create new partitions\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\t\tSome pieces of resizing software support Linux based systems. In such cases, there is no need to delete the newly created partition after resizing. Creating a new partition afterwards depends on the software you use.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tThe following diagram represents the disk state, before and after creating a new partition.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"figure\" id=\"idm139822461669088\">\u003Cp class=\"title\">\u003Cstrong>Figure 8.6. Disk with final partition configuration\u003C/strong>\u003C/p>\u003Cdiv class=\"figure-contents\">\u003Cdiv class=\"mediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/df31d5c5afb12bf44ab0e543ee20ab58/nondestruct-fin.png\" alt=\"nondestruct fin\"/>\u003C/div>\u003C/div>\u003C/div>\u003C/section>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"getting-started-with-xfs_managing-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 9. Getting started with XFS\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\tThis is an overview of how to create and maintain XFS file systems.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"the-xfs-file-system_getting-started-with-xfs\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">9.1. The XFS file system\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tXFS is a highly scalable, high-performance, robust, and mature 64-bit journaling file system that supports very large files and file systems on a single host. It is the default file system in Red Hat Enterprise Linux 9. XFS was originally developed in the early 1990s by SGI and has a long history of running on extremely large servers and storage arrays.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe features of XFS include:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">Reliability\u003C/span>\u003C/dt>\u003Cdd>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tMetadata journaling, which ensures file system integrity after a system crash by keeping a record of file system operations that can be replayed when the system is restarted and the file system remounted\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tExtensive run-time metadata consistency checking\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tScalable and fast repair utilities\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tQuota journaling. This avoids the need for lengthy quota consistency checks after a crash.\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Scalability and performance\u003C/span>\u003C/dt>\u003Cdd>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tSupported file system size up to 1024 TiB\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tAbility to support a large number of concurrent operations\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tB-tree indexing for scalability of free space management\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tSophisticated metadata read-ahead algorithms\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tOptimizations for streaming video workloads\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Allocation schemes\u003C/span>\u003C/dt>\u003Cdd>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tExtent-based allocation\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tStripe-aware allocation policies\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tDelayed allocation\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tSpace pre-allocation\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tDynamically allocated inodes\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Other features\u003C/span>\u003C/dt>\u003Cdd>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tReflink-based file copies\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tTightly integrated backup and restore utilities\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tOnline defragmentation\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tOnline file system growing\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tComprehensive diagnostics capabilities\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tExtended attributes (\u003Ccode class=\"literal\">xattr\u003C/code>). This allows the system to associate several additional name/value pairs per file.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tProject or directory quotas. This allows quota restrictions over a directory tree.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tSubsecond timestamps\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"formalpara\">\u003Cp class=\"title\">\u003Cstrong>Performance characteristics\u003C/strong>\u003C/p>\u003Cp>\n\t\t\t\t\tXFS has a high performance on large systems with enterprise workloads. A large system is one with a relatively high number of CPUs, multiple HBAs, and connections to external disk arrays. XFS also performs well on smaller systems that have a multi-threaded, parallel I/O workload.\n\t\t\t\t\u003C/p>\u003C/div>\u003Cp>\n\t\t\t\tXFS has a relatively low performance for single threaded, metadata-intensive workloads: for example, a workload that creates or deletes large numbers of small files in a single thread.\n\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"comparison-of-tools-used-with-ext4-and-xfs_getting-started-with-xfs\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">9.2. Comparison of tools used with ext4 and XFS\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis section compares which tools to use to accomplish common tasks on the ext4 and XFS file systems.\n\t\t\t\u003C/p>\u003Crh-table>\u003Ctable class=\"lt-4-cols lt-7-rows\">\u003Ccolgroup>\u003Ccol style=\"width: 33%; \" class=\"col_1\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 33%; \" class=\"col_2\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 33%; \" class=\"col_3\">\u003C!--Empty-->\u003C/col>\u003C/colgroup>\u003Cthead>\u003Ctr>\u003Cth align=\"left\" valign=\"top\" id=\"idm139822453607152\" scope=\"col\">Task\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm139822453606064\" scope=\"col\">ext4\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm139822453604976\" scope=\"col\">XFS\u003C/th>\u003C/tr>\u003C/thead>\u003Ctbody>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822453607152\"> \u003Cp>\n\t\t\t\t\t\t\t\tCreate a file system\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822453606064\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">mkfs.ext4\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822453604976\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">mkfs.xfs\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822453607152\"> \u003Cp>\n\t\t\t\t\t\t\t\tFile system check\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822453606064\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">e2fsck\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822453604976\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs_repair\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822453607152\"> \u003Cp>\n\t\t\t\t\t\t\t\tResize a file system\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822453606064\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">resize2fs\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822453604976\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs_growfs\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822453607152\"> \u003Cp>\n\t\t\t\t\t\t\t\tSave an image of a file system\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822453606064\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">e2image\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822453604976\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs_metadump\u003C/code> and \u003Ccode class=\"literal\">xfs_mdrestore\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822453607152\"> \u003Cp>\n\t\t\t\t\t\t\t\tLabel or tune a file system\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822453606064\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">tune2fs\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822453604976\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs_admin\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822453607152\"> \u003Cp>\n\t\t\t\t\t\t\t\tBack up a file system\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822453606064\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">tar\u003C/code> and \u003Ccode class=\"literal\">rsync\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822453604976\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfsdump\u003C/code> and \u003Ccode class=\"literal\">xfsrestore\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822453607152\"> \u003Cp>\n\t\t\t\t\t\t\t\tQuota management\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822453606064\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">quota\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822453604976\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs_quota\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822453607152\"> \u003Cp>\n\t\t\t\t\t\t\t\tFile mapping\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822453606064\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">filefrag\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822453604976\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs_bmap\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\u003C/rh-table>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tIf you want a complete client-server solution for backups over network, you can use \u003Ccode class=\"literal\">bacula\u003C/code> backup utility that is available in RHEL 9. For more information about Bacula, see \u003Ca class=\"link\" href=\"https://www.bacula.org/documentation/documentation/\">Bacula backup solution\u003C/a>.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"assembly_creating-an-xfs-file-system_managing-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 10. Creating an XFS file system\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tAs a system administrator, you can create an XFS file system on a block device to enable it to store files and directories.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"proc_creating-an-xfs-file-system-with-mkfs-xfs-creating-an-xfs-file-system\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">10.1. Creating an XFS file system with mkfs.xfs\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure describes how to create an XFS file system on a block device.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo create the file system:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tIf the device is a regular partition, an LVM volume, an MD volume, a disk, or a similar device, use the following command:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mkfs.xfs \u003Cspan class=\"emphasis\">\u003Cem>block-device\u003C/em>\u003C/span>\u003C/pre>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">block-device\u003C/span>\u003C/em>\u003C/span> with the path to the block device. For example, \u003Ccode class=\"literal filename\">/dev/sdb1\u003C/code>, \u003Ccode class=\"literal filename\">/dev/disk/by-uuid/05e99ec8-def1-4a5e-8a9d-5945339ceb2a\u003C/code>, or \u003Ccode class=\"literal filename\">/dev/my-volgroup/my-lv\u003C/code>.\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\tIn general, the default options are optimal for common use.\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\tWhen using \u003Ccode class=\"literal\">mkfs.xfs\u003C/code> on a block device containing an existing file system, add the \u003Ccode class=\"literal option\">-f\u003C/code> option to overwrite that file system.\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tTo create the file system on a hardware RAID device, check if the system correctly detects the stripe geometry of the device:\n\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\tIf the stripe geometry information is correct, no additional options are needed. Create the file system:\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mkfs.xfs \u003Cspan class=\"emphasis\">\u003Cem>block-device\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\tIf the information is incorrect, specify stripe geometry manually with the \u003Ccode class=\"literal option\">su\u003C/code> and \u003Ccode class=\"literal option\">sw\u003C/code> parameters of the \u003Ccode class=\"literal option\">-d\u003C/code> option. The \u003Ccode class=\"literal option\">su\u003C/code> parameter specifies the RAID chunk size, and the \u003Ccode class=\"literal option\">sw\u003C/code> parameter specifies the number of data disks in the RAID device.\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\tFor example:\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mkfs.xfs -d su=\u003Cspan class=\"emphasis\">\u003Cem>64k\u003C/em>\u003C/span>,sw=\u003Cspan class=\"emphasis\">\u003Cem>4\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>/dev/sda3\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tUse the following command to wait for the system to register the new device node:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># udevadm settle\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">mkfs.xfs(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"backing-up-an-xfs-file-system_managing-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 11. Backing up an XFS file system\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\tAs a system administrator, you can use the \u003Ccode class=\"literal\">xfsdump\u003C/code> to back up an XFS file system into a file or on a tape. This provides a simple backup mechanism.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"con_features-of-xfs-backup-backing-up-an-xfs-file-system\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">11.1. Features of XFS backup\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis section describes key concepts and features of backing up an XFS file system with the \u003Ccode class=\"literal\">xfsdump\u003C/code> utility.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tYou can use the \u003Ccode class=\"literal\">xfsdump\u003C/code> utility to:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tPerform backups to regular file images.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOnly one backup can be written to a regular file.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tPerform backups to tape drives.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">xfsdump\u003C/code> utility also enables you to write multiple backups to the same tape. A backup can span multiple tapes.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo back up multiple file systems to a single tape device, simply write the backup to a tape that already contains an XFS backup. This appends the new backup to the previous one. By default, \u003Ccode class=\"literal\">xfsdump\u003C/code> never overwrites existing backups.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate incremental backups.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">xfsdump\u003C/code> utility uses dump levels to determine a base backup to which other backups are relative. Numbers from 0 to 9 refer to increasing dump levels. An incremental backup only backs up files that have changed since the last dump of a lower level:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tTo perform a full backup, perform a level 0 dump on the file system.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tA level 1 dump is the first incremental backup after a full backup. The next incremental backup would be level 2, which only backs up files that have changed since the last level 1 dump; and so on, to a maximum of level 9.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tExclude files from a backup using size, subtree, or inode flags to filter them.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">xfsdump(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"proc_backing-up-an-xfs-file-system-with-xfsdump-backing-up-an-xfs-file-system\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">11.2. Backing up an XFS file system with xfsdump\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure describes how to back up the content of an XFS file system into a file or a tape.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tAn XFS file system that you can back up.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tAnother file system or a tape drive where you can store the backup.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tUse the following command to back up an XFS file system:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># xfsdump -l \u003Cspan class=\"emphasis\">\u003Cem>level\u003C/em>\u003C/span> [-L \u003Cspan class=\"emphasis\">\u003Cem>label\u003C/em>\u003C/span>] \\\n          -f \u003Cspan class=\"emphasis\">\u003Cem>backup-destination\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>path-to-xfs-filesystem\u003C/em>\u003C/span>\u003C/pre>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>level\u003C/em>\u003C/span> with the dump level of your backup. Use \u003Ccode class=\"literal\">0\u003C/code> to perform a full backup or \u003Ccode class=\"literal\">1\u003C/code> to \u003Ccode class=\"literal\">9\u003C/code> to perform consequent incremental backups.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>backup-destination\u003C/em>\u003C/span> with the path where you want to store your backup. The destination can be a regular file, a tape drive, or a remote tape device. For example, \u003Ccode class=\"literal filename\">/backup-files/Data.xfsdump\u003C/code> for a file or \u003Ccode class=\"literal filename\">/dev/st0\u003C/code> for a tape drive.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>path-to-xfs-filesystem\u003C/em>\u003C/span> with the mount point of the XFS file system you want to back up. For example, \u003Ccode class=\"literal filename\">/mnt/data/\u003C/code>. The file system must be mounted.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tWhen backing up multiple file systems and saving them on a single tape device, add a session label to each backup using the \u003Ccode class=\"literal\">-L \u003Cspan class=\"emphasis\">\u003Cem>label\u003C/em>\u003C/span>\u003C/code> option so that it is easier to identify them when restoring. Replace \u003Cspan class=\"emphasis\">\u003Cem>label\u003C/em>\u003C/span> with any name for your backup: for example, \u003Ccode class=\"literal\">backup_data\u003C/code>.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"example\" id=\"idm139822451832144\">\u003Cp class=\"title\">\u003Cstrong>Example 11.1. Backing up multiple XFS file systems\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tTo back up the content of XFS file systems mounted on the \u003Ccode class=\"literal filename\">/boot/\u003C/code> and \u003Ccode class=\"literal filename\">/data/\u003C/code> directories and save them as files in the \u003Ccode class=\"literal filename\">/backup-files/\u003C/code> directory:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># xfsdump -l 0 -f \u003Cspan class=\"emphasis\">\u003Cem>/backup-files/boot.xfsdump\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>/boot\u003C/em>\u003C/span>\n# xfsdump -l 0 -f \u003Cspan class=\"emphasis\">\u003Cem>/backup-files/data.xfsdump\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>/data\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tTo back up multiple file systems on a single tape device, add a session label to each backup using the \u003Ccode class=\"literal\">-L \u003Cspan class=\"emphasis\">\u003Cem>label\u003C/em>\u003C/span>\u003C/code> option:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># xfsdump -l 0 -L \u003Cspan class=\"emphasis\">\u003Cem>\"backup_boot\"\u003C/em>\u003C/span> -f \u003Cspan class=\"emphasis\">\u003Cem>/dev/st0\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>/boot\u003C/em>\u003C/span>\n# xfsdump -l 0 -L \u003Cspan class=\"emphasis\">\u003Cem>\"backup_data\"\u003C/em>\u003C/span> -f \u003Cspan class=\"emphasis\">\u003Cem>/dev/st0\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>/data\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/div>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">xfsdump(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"restoring-an-xfs-file-system-from-backup_managing-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 12. Restoring an XFS file system from backup\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\tAs a system administrator, you can use the \u003Ccode class=\"literal\">xfsrestore\u003C/code> utility to restore XFS backup created with the \u003Ccode class=\"literal\">xfsdump\u003C/code> utility and stored in a file or on a tape.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"con_features-of-restoring-xfs-from-backup-restoring-an-xfs-file-system-from-backup\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">12.1. Features of restoring XFS from backup\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tThe \u003Ccode class=\"literal\">xfsrestore\u003C/code> utility restores file systems from backups produced by \u003Ccode class=\"literal\">xfsdump\u003C/code>. The \u003Ccode class=\"literal\">xfsrestore\u003C/code> utility has two modes:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Cspan class=\"strong strong\">\u003Cstrong>simple\u003C/strong>\u003C/span> mode enables users to restore an entire file system from a level 0 dump. This is the default mode.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Cspan class=\"strong strong\">\u003Cstrong>cumulative\u003C/strong>\u003C/span> mode enables file system restoration from an incremental backup: that is, level 1 to level 9.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tA unique \u003Cspan class=\"emphasis\">\u003Cem>session ID\u003C/em>\u003C/span> or \u003Cspan class=\"emphasis\">\u003Cem>session label\u003C/em>\u003C/span> identifies each backup. Restoring a backup from a tape containing multiple backups requires its corresponding session ID or label.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tTo extract, add, or delete specific files from a backup, enter the \u003Ccode class=\"literal\">xfsrestore\u003C/code> interactive mode. The interactive mode provides a set of commands to manipulate the backup files.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">xfsrestore(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"proc_restoring-an-xfs-file-system-from-backup-with-xfsrestore-restoring-an-xfs-file-system-from-backup\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">12.2. Restoring an XFS file system from backup with xfsrestore\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure describes how to restore the content of an XFS file system from a file or tape backup.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tA file or tape backup of XFS file systems, as described in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_file_systems/backing-up-an-xfs-file-system_managing-file-systems\">Backing up an XFS file system\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tA storage device where you can restore the backup.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe command to restore the backup varies depending on whether you are restoring from a full backup or an incremental one, or are restoring multiple backups from a single tape device:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># xfsrestore [-r] [-S session-id] [-L session-label] [-i]\n             -f backup-location restoration-path\u003C/pre>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">backup-location\u003C/span>\u003C/em>\u003C/span> with the location of the backup. This can be a regular file, a tape drive, or a remote tape device. For example, \u003Ccode class=\"literal filename\">/backup-files/Data.xfsdump\u003C/code> for a file or \u003Ccode class=\"literal filename\">/dev/st0\u003C/code> for a tape drive.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">restoration-path\u003C/span>\u003C/em>\u003C/span> with the path to the directory where you want to restore the file system. For example, \u003Ccode class=\"literal filename\">/mnt/data/\u003C/code>.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tTo restore a file system from an incremental (level 1 to level 9) backup, add the \u003Ccode class=\"literal option\">-r\u003C/code> option.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tTo restore a backup from a tape device that contains multiple backups, specify the backup using the \u003Ccode class=\"literal option\">-S\u003C/code> or \u003Ccode class=\"literal option\">-L\u003C/code> options.\n\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tThe \u003Ccode class=\"literal option\">-S\u003C/code> option lets you choose a backup by its session ID, while the \u003Ccode class=\"literal option\">-L\u003C/code> option lets you choose by the session label. To obtain the session ID and session labels, use the \u003Ccode class=\"literal command\">xfsrestore -I\u003C/code> command.\n\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">session-id\u003C/span>\u003C/em>\u003C/span> with the session ID of the backup. For example, \u003Ccode class=\"literal\">b74a3586-e52e-4a4a-8775-c3334fa8ea2c\u003C/code>. Replace \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">session-label\u003C/span>\u003C/em>\u003C/span> with the session label of the backup. For example, \u003Ccode class=\"literal\">my_backup_session_label\u003C/code>.\n\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tTo use \u003Ccode class=\"literal\">xfsrestore\u003C/code> interactively, use the \u003Ccode class=\"literal option\">-i\u003C/code> option.\n\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tThe interactive dialog begins after \u003Ccode class=\"literal\">xfsrestore\u003C/code> finishes reading the specified device. Available commands in the interactive \u003Ccode class=\"literal\">xfsrestore\u003C/code> shell include \u003Ccode class=\"literal\">cd\u003C/code>, \u003Ccode class=\"literal\">ls\u003C/code>, \u003Ccode class=\"literal\">add\u003C/code>, \u003Ccode class=\"literal\">delete\u003C/code>, and \u003Ccode class=\"literal\">extract\u003C/code>; for a complete list of commands, use the \u003Ccode class=\"literal\">help\u003C/code> command.\n\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"example\" id=\"idm139822453388448\">\u003Cp class=\"title\">\u003Cstrong>Example 12.1. Restoring Multiple XFS File Systems\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tTo restore the XFS backup files and save their content into directories under \u003Ccode class=\"literal filename\">/mnt/\u003C/code>:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># xfsrestore -f \u003Cspan class=\"emphasis\">\u003Cem>/backup-files/boot.xfsdump\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>/mnt/boot/\u003C/em>\u003C/span>\n# xfsrestore -f \u003Cspan class=\"emphasis\">\u003Cem>/backup-files/data.xfsdump\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>/mnt/data/\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tTo restore from a tape device containing multiple backups, specify each backup by its session label or session ID:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># xfsrestore -L \u003Cspan class=\"emphasis\">\u003Cem>\"backup_boot\"\u003C/em>\u003C/span> -f \u003Cspan class=\"emphasis\">\u003Cem>/dev/st0\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>/mnt/boot/\u003C/em>\u003C/span>\n# xfsrestore -S \u003Cspan class=\"emphasis\">\u003Cem>\"45e9af35-efd2-4244-87bc-4762e476cbab\"\u003C/em>\u003C/span> \\\n             -f \u003Cspan class=\"emphasis\">\u003Cem>/dev/st0\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>/mnt/data/\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/div>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">xfsrestore(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"con_informational-messages-when-restoring-an-xfs-backup-from-a-tape-restoring-an-xfs-file-system-from-backup\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">12.3. Informational messages when restoring an XFS backup from a tape\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tWhen restoring a backup from a tape with backups from multiple file systems, the \u003Ccode class=\"literal\">xfsrestore\u003C/code> utility might issue messages. The messages inform you whether a match of the requested backup has been found when \u003Ccode class=\"literal\">xfsrestore\u003C/code> examines each backup on the tape in sequential order. For example:\n\t\t\t\u003C/p>\u003Cpre class=\"screen\">xfsrestore: preparing drive\nxfsrestore: examining media file 0\nxfsrestore: inventory session uuid (8590224e-3c93-469c-a311-fc8f23029b2a) does not match the media header's session uuid (7eda9f86-f1e9-4dfd-b1d4-c50467912408)\nxfsrestore: examining media file 1\nxfsrestore: inventory session uuid (8590224e-3c93-469c-a311-fc8f23029b2a) does not match the media header's session uuid (7eda9f86-f1e9-4dfd-b1d4-c50467912408)\n[...]\u003C/pre>\u003Cp>\n\t\t\t\tThe informational messages keep appearing until the matching backup is found.\n\t\t\t\u003C/p>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"increasing-the-size-of-an-xfs-file-system_managing-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 13. Increasing the size of an XFS file system\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\tAs a system administrator, you can increase the size of an XFS file system to make a complete use of a larger storage capacity.\n\t\t\u003C/p>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\tIt is not currently possible to decrease the size of XFS file systems.\n\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Csection class=\"section\" id=\"proc_increasing-the-size-of-an-xfs-file-system-with-xfs_growfs_increasing-the-size-of-an-xfs-file-system\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">13.1. Increasing the size of an XFS file system with xfs_growfs\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure describes how to grow an XFS file system using the \u003Ccode class=\"literal\">xfs_growfs\u003C/code> utility.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tEnsure that the underlying block device is of an appropriate size to hold the resized file system later. Use the appropriate resizing methods for the affected block device.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tMount the XFS file system.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tWhile the XFS file system is mounted, use the \u003Ccode class=\"literal\">xfs_growfs\u003C/code> utility to increase its size:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># xfs_growfs \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">file-system\u003C/span>\u003C/em>\u003C/span> -D \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">new-size\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">file-system\u003C/span>\u003C/em>\u003C/span> with the mount point of the XFS file system.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tWith the \u003Ccode class=\"literal option\">-D\u003C/code> option, replace \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">new-size\u003C/span>\u003C/em>\u003C/span> with the desired new size of the file system specified in the number of file system blocks.\n\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tTo find out the block size in kB of a given XFS file system, use the \u003Ccode class=\"literal\">xfs_info\u003C/code> utility:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># xfs_info \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">block-device\u003C/span>\u003C/em>\u003C/span>\n\n...\ndata     =              bsize=4096\n...\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tWithout the \u003Ccode class=\"literal option\">-D\u003C/code> option, \u003Ccode class=\"literal\">xfs_growfs\u003C/code> grows the file system to the maximum size supported by the underlying device.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs_growfs(8)\u003C/code> man page on your system.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"configuring-xfs-error-behavior_managing-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 14. Configuring XFS error behavior\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\tYou can configure how an XFS file system behaves when it encounters different I/O errors.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"configurable-error-handling-in-xfs_configuring-xfs-error-behavior\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">14.1. Configurable error handling in XFS\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe XFS file system responds in one of the following ways when an error occurs during an I/O operation:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tXFS repeatedly retries the I/O operation until the operation succeeds or XFS reaches a set limit.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe limit is based either on a maximum number of retries or a maximum time for retries.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tXFS considers the error permanent and stops the operation on the file system.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tYou can configure how XFS reacts to the following error conditions:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">EIO\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tError when reading or writing\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">ENOSPC\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tNo space left on the device\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">ENODEV\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDevice cannot be found\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cp>\n\t\t\t\tYou can set the maximum number of retries and the maximum time in seconds until XFS considers an error permanent. XFS stops retrying the operation when it reaches either of the limits.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tYou can also configure XFS so that when unmounting a file system, XFS immediately cancels the retries regardless of any other configuration. This configuration enables the unmount operation to succeed despite persistent errors.\n\t\t\t\u003C/p>\u003Cdiv class=\"formalpara\">\u003Cp class=\"title\">\u003Cstrong>Default behavior\u003C/strong>\u003C/p>\u003Cp>\n\t\t\t\t\tThe default behavior for each XFS error condition depends on the error context. Some XFS errors such as \u003Ccode class=\"literal\">ENODEV\u003C/code> are considered to be fatal and unrecoverable, regardless of the retry count. Their default retry limit is 0.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"configuration-files-for-specific-and-undefined-xfs-error-conditions_configuring-xfs-error-behavior\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">14.2. Configuration files for specific and undefined XFS error conditions\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe following directories store configuration files that control XFS error behavior for different error conditions:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">/sys/fs/xfs/\u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span>/error/metadata/EIO/\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tFor the \u003Ccode class=\"literal\">EIO\u003C/code> error condition\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">/sys/fs/xfs/\u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span>/error/metadata/ENODEV/\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tFor the \u003Ccode class=\"literal\">ENODEV\u003C/code> error condition\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">/sys/fs/xfs/\u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span>/error/metadata/ENOSPC/\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tFor the \u003Ccode class=\"literal\">ENOSPC\u003C/code> error condition\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">/sys/fs/xfs/\u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span>/error/default/\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tCommon configuration for all other, undefined error conditions\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cp>\n\t\t\t\tEach directory contains the following configuration files for configuring retry limits:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">max_retries\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tControls the maximum number of times that XFS retries the operation.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">retry_timeout_seconds\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tSpecifies the time limit in seconds after which XFS stops retrying the operation.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"setting-specific-and-undefined-xfs-error-conditions_configuring-xfs-error-behavior\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">14.3. Setting XFS behavior for specific conditions\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure configures how XFS reacts to specific error conditions.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tSet the maximum number of retries, the retry time limit, or both:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tTo set the maximum number of retries, write the desired number to the \u003Ccode class=\"literal\">max_retries\u003C/code> file:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># echo \u003Cspan class=\"emphasis\">\u003Cem>value\u003C/em>\u003C/span> &gt; /sys/fs/xfs/\u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span>/error/metadata/\u003Cspan class=\"emphasis\">\u003Cem>condition\u003C/em>\u003C/span>/max_retries\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tTo set the time limit, write the desired number of seconds to the \u003Ccode class=\"literal\">retry_timeout_seconds\u003C/code> file:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># echo \u003Cspan class=\"emphasis\">\u003Cem>value\u003C/em>\u003C/span> &gt; /sys/fs/xfs/\u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span>/error/metadata/\u003Cspan class=\"emphasis\">\u003Cem>condition\u003C/em>\u003C/span>/retry_timeout_second\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\u003Cspan class=\"emphasis\">\u003Cem>value\u003C/em>\u003C/span> is a number between -1 and the maximum possible value of the C signed integer type. This is 2147483647 on 64-bit Linux.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn both limits, the value \u003Ccode class=\"literal\">-1\u003C/code> is used for continuous retries and \u003Ccode class=\"literal\">0\u003C/code> to stop immediately.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span> is the name of the device, as found in the \u003Ccode class=\"literal\">/dev/\u003C/code> directory; for example, \u003Ccode class=\"literal\">sda\u003C/code>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"setting-undefined-xfs-error-conditions_configuring-xfs-error-behavior\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">14.4. Setting XFS behavior for undefined conditions\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure configures how XFS reacts to all undefined error conditions, which share a common configuration.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tSet the maximum number of retries, the retry time limit, or both:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tTo set the maximum number of retries, write the desired number to the \u003Ccode class=\"literal\">max_retries\u003C/code> file:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># echo \u003Cspan class=\"emphasis\">\u003Cem>value\u003C/em>\u003C/span> &gt; /sys/fs/xfs/\u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span>/error/metadata/default/max_retries\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tTo set the time limit, write the desired number of seconds to the \u003Ccode class=\"literal\">retry_timeout_seconds\u003C/code> file:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># echo \u003Cspan class=\"emphasis\">\u003Cem>value\u003C/em>\u003C/span> &gt; /sys/fs/xfs/\u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span>/error/metadata/default/retry_timeout_seconds\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\u003Cspan class=\"emphasis\">\u003Cem>value\u003C/em>\u003C/span> is a number between -1 and the maximum possible value of the C signed integer type. This is 2147483647 on 64-bit Linux.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn both limits, the value \u003Ccode class=\"literal\">-1\u003C/code> is used for continuous retries and \u003Ccode class=\"literal\">0\u003C/code> to stop immediately.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span> is the name of the device, as found in the \u003Ccode class=\"literal\">/dev/\u003C/code> directory; for example, \u003Ccode class=\"literal\">sda\u003C/code>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"setting-the-unmount-behavior_configuring-xfs-error-behavior\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">14.5. Setting the XFS unmount behavior\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure configures how XFS reacts to error conditions when unmounting the file system.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tIf you set the \u003Ccode class=\"literal\">fail_at_unmount\u003C/code> option in the file system, it overrides all other error configurations during unmount, and immediately unmounts the file system without retrying the I/O operation. This allows the unmount operation to succeed even in case of persistent errors.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition warning\" state=\"danger\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Warning\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tYou cannot change the \u003Ccode class=\"literal\">fail_at_unmount\u003C/code> value after the unmount process starts, because the unmount process removes the configuration files from the \u003Ccode class=\"literal\">sysfs\u003C/code> interface for the respective file system. You must configure the unmount behavior before the file system starts unmounting.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnable or disable the \u003Ccode class=\"literal\">fail_at_unmount\u003C/code> option:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tTo cancel retrying all operations when the file system unmounts, enable the option:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># echo 1 &gt; /sys/fs/xfs/\u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span>/error/fail_at_unmount\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tTo respect the \u003Ccode class=\"literal\">max_retries\u003C/code> and \u003Ccode class=\"literal\">retry_timeout_seconds\u003C/code> retry limits when the file system unmounts, disable the option:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># echo 0 &gt; /sys/fs/xfs/\u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span>/error/fail_at_unmount\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span> is the name of the device, as found in the \u003Ccode class=\"literal\">/dev/\u003C/code> directory; for example, \u003Ccode class=\"literal\">sda\u003C/code>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"checking-and-repairing-a-file-system__managing-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 15. Checking and repairing a file system\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tRHEL provides file system administration utilities which are capable of checking and repairing file systems. These tools are often referred to as \u003Ccode class=\"literal\">fsck\u003C/code> tools, where \u003Ccode class=\"literal\">fsck\u003C/code> is a shortened version of \u003Cspan class=\"emphasis\">\u003Cem>file system check\u003C/em>\u003C/span>. In most cases, these utilities are run automatically during system boot, if needed, but can also be manually invoked if required.\n\t\t\u003C/p>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\tFile system checkers guarantee only metadata consistency across the file system. They have no awareness of the actual data contained within the file system and are not data recovery tools.\n\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Csection class=\"section\" id=\"file-system-checking-and-repair_checking-and-repairing-a-file-system\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">15.1. Scenarios that require a file system check\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe relevant \u003Ccode class=\"literal\">fsck\u003C/code> tools can be used to check your system if any of the following occurs:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tSystem fails to boot\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tFiles on a specific disk become corrupt\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe file system shuts down or changes to read-only due to inconsistencies\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tA file on the file system is inaccessible\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tFile system inconsistencies can occur for various reasons, including but not limited to hardware errors, storage administration errors, and software bugs.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tFile system check tools cannot repair hardware problems. A file system must be fully readable and writable if repair is to operate successfully. If a file system was corrupted due to a hardware error, the file system must first be moved to a good disk, for example with the \u003Ccode class=\"literal\">dd(8)\u003C/code> utility.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cp>\n\t\t\t\tFor journaling file systems, all that is normally required at boot time is to replay the journal if required and this is usually a very short operation.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tHowever, if a file system inconsistency or corruption occurs, even for journaling file systems, then the file system checker must be used to repair the file system.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tIt is possible to disable file system check at boot by setting the sixth field in \u003Ccode class=\"literal\">/etc/fstab\u003C/code> to \u003Ccode class=\"literal\">0\u003C/code>. However, Red Hat does not recommend doing so unless you are having issues with \u003Ccode class=\"literal\">fsck\u003C/code> at boot time, for example with extremely large or remote file systems.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">fstab(5)\u003C/code>, \u003Ccode class=\"literal\">fsck(8)\u003C/code>, and \u003Ccode class=\"literal\">dd(8)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"potential-side-effects-of-running-fsck_checking-and-repairing-a-file-system\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">15.2. Potential side effects of running fsck\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tGenerally, running the file system check and repair tool can be expected to automatically repair at least some of the inconsistencies it finds. In some cases, the following issues can arise:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tSeverely damaged inodes or directories may be discarded if they cannot be repaired.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tSignificant changes to the file system may occur.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tTo ensure that unexpected or undesirable changes are not permanently made, ensure you follow any precautionary steps outlined in the procedure.\n\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"error-handling-mechanisms-in-xfs_checking-and-repairing-a-file-system\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">15.3. Error-handling mechanisms in XFS\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis section describes how XFS handles various kinds of errors in the file system.\n\t\t\t\u003C/p>\u003Ch5 id=\"unclean_unmounts\">Unclean unmounts\u003C/h5>\u003Cp>\n\t\t\t\tJournalling maintains a transactional record of metadata changes that happen on the file system.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tIn the event of a system crash, power failure, or other unclean unmount, XFS uses the journal (also called log) to recover the file system. The kernel performs journal recovery when mounting the XFS file system.\n\t\t\t\u003C/p>\u003Ch5 id=\"corruption\">Corruption\u003C/h5>\u003Cp>\n\t\t\t\tIn this context, \u003Cspan class=\"emphasis\">\u003Cem>corruption\u003C/em>\u003C/span> means errors on the file system caused by, for example:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tHardware faults\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tBugs in storage firmware, device drivers, the software stack, or the file system itself\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tProblems that cause parts of the file system to be overwritten by something outside of the file system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tWhen XFS detects corruption in the file system or the file-system metadata, it may shut down the file system and report the incident in the system log. Note that if the corruption occurred on the file system hosting the \u003Ccode class=\"literal filename\">/var\u003C/code> directory, these logs will not be available after a reboot.\n\t\t\t\u003C/p>\u003Cdiv class=\"example\" id=\"idm139822448930272\">\u003Cp class=\"title\">\u003Cstrong>Example 15.1. System log entry reporting an XFS corruption\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cpre class=\"screen\"># dmesg --notime | tail -15\n\nXFS (loop0): Mounting V5 Filesystem\nXFS (loop0): Metadata CRC error detected at xfs_agi_read_verify+0xcb/0xf0 [xfs], xfs_agi block 0x2\nXFS (loop0): Unmount and run xfs_repair\nXFS (loop0): First 128 bytes of corrupted metadata buffer:\n00000000027b3b56: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................\n000000005f9abc7a: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................\n000000005b0aef35: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................\n00000000da9d2ded: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................\n000000001e265b07: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................\n000000006a40df69: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................\n000000000b272907: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................\n00000000e484aac5: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00  ................\nXFS (loop0): metadata I/O error in \"xfs_trans_read_buf_map\" at daddr 0x2 len 1 error 74\nXFS (loop0): xfs_imap_lookup: xfs_ialloc_read_agi() returned error -117, agno 0\nXFS (loop0): Failed to read root inode 0x80, error 11\u003C/pre>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tUser-space utilities usually report the \u003Cspan class=\"emphasis\">\u003Cem>Input/output error\u003C/em>\u003C/span> message when trying to access a corrupted XFS file system. Mounting an XFS file system with a corrupted log results in a failed mount and the following error message:\n\t\t\t\u003C/p>\u003Cpre class=\"screen\">mount: \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">/mount-point\u003C/span>\u003C/em>\u003C/span>: mount(2) system call failed: Structure needs cleaning.\u003C/pre>\u003Cp>\n\t\t\t\tYou must manually use the \u003Ccode class=\"literal\">xfs_repair\u003C/code> utility to repair the corruption.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs_repair(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"checking-an-xfs-file-system-with-xfs-repair_checking-and-repairing-a-file-system\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">15.4. Checking an XFS file system with \u003Ccode class=\"literal\">xfs_repair\u003C/code>\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tPerform a read-only check of an XFS file system by using the xfs_repair utility. Unlike other file system repair utilities, \u003Ccode class=\"literal\">xfs_repair\u003C/code> does not run at boot time, even when an XFS file system was not cleanly unmounted. In case of an unclean unmount, XFS simply replays the log at mount time, ensuring a consistent file system; \u003Ccode class=\"literal\">xfs_repair\u003C/code> cannot repair an XFS file system with a dirty log without remounting it first.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tAlthough an \u003Ccode class=\"literal\">fsck.xfs\u003C/code> binary is present in the \u003Ccode class=\"literal\">xfsprogs\u003C/code> package, this is present only to satisfy \u003Ccode class=\"literal\">initscripts\u003C/code> that look for an \u003Ccode class=\"literal\">fsck.file\u003C/code> system binary at boot time. \u003Ccode class=\"literal\">fsck.xfs\u003C/code> immediately exits with an exit code of 0.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tReplay the log by mounting and unmounting the file system:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">file-system\u003C/span>\u003C/em>\u003C/span>\n# umount \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">file-system\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\tIf the mount fails with a structure needs cleaning error, the log is corrupted and cannot be replayed. The dry run should discover and report more on-disk corruption as a result.\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tUse the \u003Ccode class=\"literal\">xfs_repair\u003C/code> utility to perform a dry run to check the file system. Any errors are printed and an indication of the actions that would be taken, without modifying the file system.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># xfs_repair -n \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">block-device\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tMount the file system:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">file-system\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs_repair(8)\u003C/code> and \u003Ccode class=\"literal\">xfs_metadump(8)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"proc_repairing-an-xfs-file-system-with-xfs_repair_checking-and-repairing-a-file-system\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">15.5. Repairing an XFS file system with xfs_repair\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure repairs a corrupted XFS file system using the \u003Ccode class=\"literal\">xfs_repair\u003C/code> utility.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a metadata image prior to repair for diagnostic or testing purposes using the \u003Ccode class=\"literal\">xfs_metadump\u003C/code> utility. A pre-repair file system metadata image can be useful for support investigations if the corruption is due to a software bug. Patterns of corruption present in the pre-repair image can aid in root-cause analysis.\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tUse the \u003Ccode class=\"literal\">xfs_metadump\u003C/code> debugging tool to copy the metadata from an XFS file system to a file. The resulting \u003Ccode class=\"literal\">metadump\u003C/code> file can be compressed using standard compression utilities to reduce the file size if large \u003Ccode class=\"literal\">metadump\u003C/code> files need to be sent to support.\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># xfs_metadump \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">block-device\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">metadump-file\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tReplay the log by remounting the file system:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">file-system\u003C/span>\u003C/em>\u003C/span>\n# umount \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">file-system\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tUse the \u003Ccode class=\"literal\">xfs_repair\u003C/code> utility to repair the unmounted file system:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tIf the mount succeeded, no additional options are required:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># xfs_repair \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">block-device\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tIf the mount failed with the \u003Cspan class=\"emphasis\">\u003Cem>Structure needs cleaning\u003C/em>\u003C/span> error, the log is corrupted and cannot be replayed. Use the \u003Ccode class=\"literal option\">-L\u003C/code> option (\u003Cspan class=\"emphasis\">\u003Cem>force log zeroing\u003C/em>\u003C/span>) to clear the log:\n\t\t\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition warning\" state=\"danger\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Warning\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\t\t\tThis command causes all metadata updates in progress at the time of the crash to be lost, which might cause significant file system damage and data loss. This should be used only as a last resort if the log cannot be replayed.\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cpre class=\"screen\"># xfs_repair -L \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">block-device\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tMount the file system:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">file-system\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs_repair(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"error-handling-mechanisms-in-ext2-ext3-and-ext4_checking-and-repairing-a-file-system\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">15.6. Error handling mechanisms in ext2, ext3, and ext4\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe ext2, ext3, and ext4 file systems use the \u003Ccode class=\"literal\">e2fsck\u003C/code> utility to perform file system checks and repairs. The file names \u003Ccode class=\"literal\">fsck.ext2\u003C/code>, \u003Ccode class=\"literal\">fsck.ext3\u003C/code>, and \u003Ccode class=\"literal\">fsck.ext4\u003C/code> are hardlinks to the \u003Ccode class=\"literal\">e2fsck\u003C/code> utility. These binaries are run automatically at boot time and their behavior differs based on the file system being checked and the state of the file system.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tA full file system check and repair is invoked for ext2, which is not a metadata journaling file system, and for ext4 file systems without a journal.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tFor ext3 and ext4 file systems with metadata journaling, the journal is replayed in userspace and the utility exits. This is the default action because journal replay ensures a consistent file system after a crash.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tIf these file systems encounter metadata inconsistencies while mounted, they record this fact in the file system superblock. If \u003Ccode class=\"literal\">e2fsck\u003C/code> finds that a file system is marked with such an error, \u003Ccode class=\"literal\">e2fsck\u003C/code> performs a full check after replaying the journal (if present).\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">fsck(8)\u003C/code> and \u003Ccode class=\"literal\">e2fsck(8)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"checking-an-ext2-ext3-or-ext4-file-system-with-e2fsck_checking-and-repairing-a-file-system\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">15.7. Checking an ext2, ext3, or ext4 file system with e2fsck\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure checks an ext2, ext3, or ext4 file system using the \u003Ccode class=\"literal\">e2fsck\u003C/code> utility.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tReplay the log by remounting the file system:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">file-system\u003C/span>\u003C/em>\u003C/span>\n# umount \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">file-system\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tPerform a dry run to check the file system.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># e2fsck -n \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">block-device\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\tAny errors are printed and an indication of the actions that would be taken, without modifying the file system. Later phases of consistency checking may print extra errors as it discovers inconsistencies which would have been fixed in early phases if it were running in repair mode.\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">e2image(8)\u003C/code> and \u003Ccode class=\"literal\">e2fsck(8)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"repairing-an-ext2-ext3-or-ext4-file-system-with-e2fsck_checking-and-repairing-a-file-system\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">15.8. Repairing an ext2, ext3, or ext4 file system with e2fsck\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure repairs a corrupted ext2, ext3, or ext4 file system using the \u003Ccode class=\"literal\">e2fsck\u003C/code> utility.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tSave a file system image for support investigations. A pre-repair file system metadata image can be useful for support investigations if the corruption is due to a software bug. Patterns of corruption present in the pre-repair image can aid in root-cause analysis.\n\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\tSeverely damaged file systems may cause problems with metadata image creation.\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tIf you are creating the image for testing purposes, use the \u003Ccode class=\"literal\">-r\u003C/code> option to create a sparse file of the same size as the file system itself. \u003Ccode class=\"literal\">e2fsck\u003C/code> can then operate directly on the resulting file.\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># e2image -r \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">block-device\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">image-file\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tIf you are creating the image to be archived or provided for diagnostic, use the \u003Ccode class=\"literal\">-Q\u003C/code> option, which creates a more compact file format suitable for transfer.\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># e2image -Q \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">block-device\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">image-file\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tReplay the log by remounting the file system:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">file-system\u003C/span>\u003C/em>\u003C/span>\n# umount \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">file-system\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAutomatically repair the file system. If user intervention is required, \u003Ccode class=\"literal\">e2fsck\u003C/code> indicates the unfixed problem in its output and reflects this status in the exit code.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># e2fsck -p \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">block-device\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">e2image(8)\u003C/code> man page on your system\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">e2fsck(8)\u003C/code> man page on your system\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"mounting-file-systems_managing-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 16. Mounting file systems\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\tAs a system administrator, you can mount file systems on your system to access data on them.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"the-linux-mount-mechanism_mounting-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">16.1. The Linux mount mechanism\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThese are the basic concepts of mounting file systems on Linux.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tOn Linux, UNIX, and similar operating systems, file systems on different partitions and removable devices (CDs, DVDs, or USB flash drives for example) can be attached to a certain point (the mount point) in the directory tree, and then detached again. While a file system is mounted on a directory, the original content of the directory is not accessible.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tNote that Linux does not prevent you from mounting a file system to a directory with a file system already attached to it.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tWhen mounting, you can identify the device by:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\ta universally unique identifier (UUID): for example, \u003Ccode class=\"literal\">UUID=34795a28-ca6d-4fd8-a347-73671d0c19cb\u003C/code>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\ta volume label: for example, \u003Ccode class=\"literal\">LABEL=home\u003C/code>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\ta full path to a non-persistent block device: for example, \u003Ccode class=\"literal filename\">/dev/sda3\u003C/code>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tWhen you mount a file system using the \u003Ccode class=\"literal\">mount\u003C/code> command without all required information, that is without the device name, the target directory, or the file system type, the \u003Ccode class=\"literal\">mount\u003C/code> utility reads the content of the \u003Ccode class=\"literal filename\">/etc/fstab\u003C/code> file to check if the given file system is listed there. The \u003Ccode class=\"literal filename\">/etc/fstab\u003C/code> file contains a list of device names and the directories in which the selected file systems are set to be mounted as well as the file system type and mount options. Therefore, when mounting a file system that is specified in \u003Ccode class=\"literal filename\">/etc/fstab\u003C/code>, the following command syntax is sufficient:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tMounting by the mount point:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">directory\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tMounting by the block device:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">device\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">mount(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#proc_listing-persistent-naming-attributes_assembly_overview-of-persistent-naming-attributes\">How to list persistent naming attributes such as the UUID\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"listing-currently-mounted-file-systems_mounting-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">16.2. Listing currently mounted file systems\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tList all currently mounted file systems on the command line by using the \u003Ccode class=\"literal\">findmnt\u003C/code> utility.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo list all mounted file systems, use the \u003Ccode class=\"literal\">findmnt\u003C/code> utility:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ findmnt\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo limit the listed file systems only to a certain file system type, add the \u003Ccode class=\"literal option\">--types\u003C/code> option:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ findmnt --types \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">fs-type\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor example:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"example\" id=\"idm139822452693040\">\u003Cp class=\"title\">\u003Cstrong>Example 16.1. Listing only XFS file systems\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cpre class=\"screen\">$ findmnt --types xfs\n\nTARGET  SOURCE                                                FSTYPE OPTIONS\n/       /dev/mapper/luks-5564ed00-6aac-4406-bfb4-c59bf5de48b5 xfs    rw,relatime\n├─/boot /dev/sda1                                             xfs    rw,relatime\n└─/home /dev/mapper/luks-9d185660-7537-414d-b727-d92ea036051e xfs    rw,relatime\u003C/pre>\u003C/div>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">findmnt(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"mounting-a-file-system-with-mount_mounting-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">16.3. Mounting a file system with mount\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tMount a file system by using the \u003Ccode class=\"literal\">mount\u003C/code> utility.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify that no file system is already mounted on your chosen mount point:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ findmnt \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">mount-point\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo attach a certain file system, use the \u003Ccode class=\"literal\">mount\u003C/code> utility:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">device\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">mount-point\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cdiv class=\"example\" id=\"idm139822452486400\">\u003Cp class=\"title\">\u003Cstrong>Example 16.2. Mounting an XFS file system\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\t\t\tFor example, to mount a local XFS file system identified by UUID:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount UUID=ea74bbec-536d-490c-b8d9-5b40bbd7545b /mnt/data\u003C/pre>\u003C/div>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIf \u003Ccode class=\"literal\">mount\u003C/code> cannot recognize the file system type automatically, specify it using the \u003Ccode class=\"literal option\">--types\u003C/code> option:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount --types \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">type\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">device\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">mount-point\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cdiv class=\"example\" id=\"idm139822452478992\">\u003Cp class=\"title\">\u003Cstrong>Example 16.3. Mounting an NFS file system\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\t\t\tFor example, to mount a remote NFS file system:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount --types nfs4 host:/remote-export /mnt/nfs\u003C/pre>\u003C/div>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">mount(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"moving-a-mount-point_mounting-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">16.4. Moving a mount point\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tChange the mount point of a mounted file system to a different directory by using the \u003Ccode class=\"literal\">mount\u003C/code> utility.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo change the directory in which a file system is mounted:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount --move \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">old-directory\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">new-directory\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cdiv class=\"example\" id=\"idm139822449909984\">\u003Cp class=\"title\">\u003Cstrong>Example 16.4. Moving a home file system\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\t\t\tFor example, to move the file system mounted in the \u003Ccode class=\"literal filename\">/mnt/userdirs/\u003C/code> directory to the \u003Ccode class=\"literal filename\">/home/\u003C/code> mount point:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount --move /mnt/userdirs /home\u003C/pre>\u003C/div>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify that the file system has been moved as expected:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ findmnt\n$ ls \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">old-directory\u003C/span>\u003C/em>\u003C/span>\n$ ls \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">new-directory\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">mount(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"unmounting-a-file-system-with-umount_mounting-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">16.5. Unmounting a file system with umount\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tUnmount a file system by using the \u003Ccode class=\"literal\">umount\u003C/code> utility.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTry unmounting the file system using either of the following commands:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tBy mount point:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># umount \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">mount-point\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tBy device:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># umount \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">device\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIf the command fails with an error similar to the following, it means that the file system is in use because of a process is using resources on it:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">umount: \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">/run/media/user/FlashDrive\u003C/span>\u003C/em>\u003C/span>: target is busy.\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIf the file system is in use, use the \u003Ccode class=\"literal\">fuser\u003C/code> utility to determine which processes are accessing it. For example:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ fuser --mount \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">/run/media/user/FlashDrive\u003C/span>\u003C/em>\u003C/span>\n\n\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">/run/media/user/FlashDrive\u003C/span>\u003C/em>\u003C/span>: \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">18351\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAfterwards, stop the processes using the file system and try unmounting it again.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"mounting-and-unmounting-file-systems-in-the-web-console_mounting-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">16.6. Mounting and unmounting file systems in the web console\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tTo be able to use partitions on RHEL systems, you need to mount a file system on the partition as a device.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tYou also can unmount a file system and the RHEL system will stop using it. Unmounting the file system enables you to delete, remove, or re-format devices.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">cockpit-storaged\u003C/code> package is installed on your system.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tYou have installed the RHEL 9 web console.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor instructions, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console\">Installing and enabling the web console\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIf you want to unmount a file system, ensure that the system does not use any file, service, or application stored in the partition.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tLog in to the RHEL 9 web console.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor details, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#logging-in-to-the-web-console_getting-started-with-the-rhel-9-web-console\">Logging in to the web console\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick the \u003Cspan class=\"strong strong\">\u003Cstrong>Storage\u003C/strong>\u003C/span> tab.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Storage\u003C/strong>\u003C/span> table, select a volume from which you want to delete the partition.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>GPT partitions\u003C/strong>\u003C/span> section, click the menu button, \u003Cspan class=\"guibutton\">⋮\u003C/span> next to the partition whose file system you want to mount or unmount.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick \u003Cspan class=\"guibutton\">Mount\u003C/span> or \u003Cspan class=\"guibutton\">Unmount\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"common-mount-options_mounting-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">16.7. Common mount options\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tThe following table lists the most common options of the \u003Ccode class=\"literal\">mount\u003C/code> utility. You can apply these mount options using the following syntax:\n\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount --options \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">option1,option2,option3\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">device\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">mount-point\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Crh-table id=\"idm139822467758848\">\u003Ctable class=\"lt-4-cols lt-7-rows\">\u003Ccaption>Table 16.1. Common mount options\u003C/caption>\u003Ccolgroup>\u003Ccol style=\"width: 25%; \" class=\"col_1\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 75%; \" class=\"col_2\">\u003C!--Empty-->\u003C/col>\u003C/colgroup>\u003Cthead>\u003Ctr>\u003Cth align=\"left\" valign=\"top\" id=\"idm139822467754016\" scope=\"col\">Option\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm139822467752928\" scope=\"col\">Description\u003C/th>\u003C/tr>\u003C/thead>\u003Ctbody>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822467754016\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">async\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822467752928\"> \u003Cp>\n\t\t\t\t\t\t\t\tEnables asynchronous input and output operations on the file system.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822467754016\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">auto\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822467752928\"> \u003Cp>\n\t\t\t\t\t\t\t\tEnables the file system to be mounted automatically using the \u003Ccode class=\"literal command\">mount -a\u003C/code> command.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822467754016\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">defaults\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822467752928\"> \u003Cp>\n\t\t\t\t\t\t\t\tProvides an alias for the \u003Ccode class=\"literal\">async,auto,dev,exec,nouser,rw,suid\u003C/code> options.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822467754016\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">exec\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822467752928\"> \u003Cp>\n\t\t\t\t\t\t\t\tAllows the execution of binary files on the particular file system.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822467754016\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">loop\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822467752928\"> \u003Cp>\n\t\t\t\t\t\t\t\tMounts an image as a loop device.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822467754016\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">noauto\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822467752928\"> \u003Cp>\n\t\t\t\t\t\t\t\tDefault behavior disables the automatic mount of the file system using the \u003Ccode class=\"literal command\">mount -a\u003C/code> command.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822467754016\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">noexec\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822467752928\"> \u003Cp>\n\t\t\t\t\t\t\t\tDisallows the execution of binary files on the particular file system.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822467754016\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">nouser\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822467752928\"> \u003Cp>\n\t\t\t\t\t\t\t\tDisallows an ordinary user (that is, other than root) to mount and unmount the file system.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822467754016\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">remount\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822467752928\"> \u003Cp>\n\t\t\t\t\t\t\t\tRemounts the file system in case it is already mounted.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822467754016\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">ro\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822467752928\"> \u003Cp>\n\t\t\t\t\t\t\t\tMounts the file system for reading only.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822467754016\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">rw\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822467752928\"> \u003Cp>\n\t\t\t\t\t\t\t\tMounts the file system for both reading and writing.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822467754016\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">user\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822467752928\"> \u003Cp>\n\t\t\t\t\t\t\t\tAllows an ordinary user (that is, other than root) to mount and unmount the file system.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\u003C/rh-table>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"sharing-a-mount-on-multiple-mount-points_managing-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 17. Sharing a mount on multiple mount points\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tAs a system administrator, you can duplicate mount points to make the file systems accessible from multiple directories.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"types-of-shared-mounts_sharing-a-mount-on-multiple-mount-points\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">17.1. Types of shared mounts\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThere are multiple types of shared mounts that you can use. The difference between them is what happens when you mount another file system under one of the shared mount points. The shared mounts are implemented using the \u003Cspan class=\"emphasis\">\u003Cem>shared subtrees\u003C/em>\u003C/span> functionality.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe following mount types are available:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">private\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThis type does not receive or forward any propagation events.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tWhen you mount another file system under either the duplicate or the original mount point, it is not reflected in the other.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">shared\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThis type creates an exact replica of a given mount point.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tWhen a mount point is marked as a \u003Ccode class=\"literal\">shared\u003C/code> mount, any mount within the original mount point is reflected in it, and vice versa.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThis is the default mount type of the root file system.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">slave\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThis type creates a limited duplicate of a given mount point.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tWhen a mount point is marked as a \u003Ccode class=\"literal\">slave\u003C/code> mount, any mount within the original mount point is reflected in it, but no mount within a \u003Ccode class=\"literal\">slave\u003C/code> mount is reflected in its original.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">unbindable\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThis type prevents the given mount point from being duplicated whatsoever.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://lwn.net/Articles/159077/\">The \u003Cspan class=\"emphasis\">\u003Cem>Shared subtrees\u003C/em>\u003C/span> article on Linux Weekly News\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"creating-a-private-mount-point-duplicate_sharing-a-mount-on-multiple-mount-points\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">17.2. Creating a private mount point duplicate\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tDuplicate a mount point as a private mount. File systems that you later mount under the duplicate or the original mount point are not reflected in the other.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a virtual file system (VFS) node from the original mount point:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount --bind \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">original-dir\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">original-dir\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tMark the original mount point as private:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount --make-private \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">original-dir\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAlternatively, to change the mount type for the selected mount point and all mount points under it, use the \u003Ccode class=\"literal option\">--make-rprivate\u003C/code> option instead of \u003Ccode class=\"literal option\">--make-private\u003C/code>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate the duplicate:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount --bind \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">original-dir\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">duplicate-dir\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"example\" id=\"idm139822450410752\">\u003Cp class=\"title\">\u003Cstrong>Example 17.1. Duplicating /media into /mnt as a private mount point\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tCreate a VFS node from the \u003Ccode class=\"literal filename\">/media\u003C/code> directory:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount --bind /media /media\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tMark the \u003Ccode class=\"literal filename\">/media\u003C/code> directory as private:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount --make-private /media\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tCreate its duplicate in \u003Ccode class=\"literal filename\">/mnt\u003C/code>:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount --bind /media /mnt\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIt is now possible to verify that \u003Ccode class=\"literal filename\">/media\u003C/code> and \u003Ccode class=\"literal filename\">/mnt\u003C/code> share content but none of the mounts within \u003Ccode class=\"literal filename\">/media\u003C/code> appear in \u003Ccode class=\"literal filename\">/mnt\u003C/code>. For example, if the CD-ROM drive contains non-empty media and the \u003Ccode class=\"literal filename\">/media/cdrom/\u003C/code> directory exists, use:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount /dev/cdrom /media/cdrom\n# ls /media/cdrom\nEFI  GPL  isolinux  LiveOS\n# ls /mnt/cdrom\n#\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIt is also possible to verify that file systems mounted in the \u003Ccode class=\"literal filename\">/mnt\u003C/code> directory are not reflected in \u003Ccode class=\"literal filename\">/media\u003C/code>. For example, if a non-empty USB flash drive that uses the \u003Ccode class=\"literal filename\">/dev/sdc1\u003C/code> device is plugged in and the \u003Ccode class=\"literal filename\">/mnt/flashdisk/\u003C/code> directory is present, use:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount /dev/sdc1 /mnt/flashdisk\n# ls /media/flashdisk\n# ls /mnt/flashdisk\nen-US  publican.cfg\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003C/div>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">mount(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"creating-a-shared-mount-point-duplicate_sharing-a-mount-on-multiple-mount-points\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">17.3. Creating a shared mount point duplicate\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tDuplicate a mount point as a shared mount. File systems that you later mount under the original directory or the duplicate are always reflected in the other.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a virtual file system (VFS) node from the original mount point:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount --bind \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">original-dir\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">original-dir\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tMark the original mount point as shared:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount --make-shared \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">original-dir\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAlternatively, to change the mount type for the selected mount point and all mount points under it, use the \u003Ccode class=\"literal option\">--make-rshared\u003C/code> option instead of \u003Ccode class=\"literal option\">--make-shared\u003C/code>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate the duplicate:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount --bind \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">original-dir\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">duplicate-dir\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"example\" id=\"idm139822449967264\">\u003Cp class=\"title\">\u003Cstrong>Example 17.2. Duplicating /media into /mnt as a shared mount point\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\tTo make the \u003Ccode class=\"literal filename\">/media\u003C/code> and \u003Ccode class=\"literal filename\">/mnt\u003C/code> directories share the same content:\n\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tCreate a VFS node from the \u003Ccode class=\"literal filename\">/media\u003C/code> directory:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount --bind /media /media\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tMark the \u003Ccode class=\"literal filename\">/media\u003C/code> directory as shared:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount --make-shared /media\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tCreate its duplicate in \u003Ccode class=\"literal filename\">/mnt\u003C/code>:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount --bind /media /mnt\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIt is now possible to verify that a mount within \u003Ccode class=\"literal filename\">/media\u003C/code> also appears in \u003Ccode class=\"literal filename\">/mnt\u003C/code>. For example, if the CD-ROM drive contains non-empty media and the \u003Ccode class=\"literal filename\">/media/cdrom/\u003C/code> directory exists, use:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount /dev/cdrom /media/cdrom\n# ls /media/cdrom\nEFI  GPL  isolinux  LiveOS\n# ls /mnt/cdrom\nEFI  GPL  isolinux  LiveOS\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tSimilarly, it is possible to verify that any file system mounted in the \u003Ccode class=\"literal filename\">/mnt\u003C/code> directory is reflected in \u003Ccode class=\"literal filename\">/media\u003C/code>. For example, if a non-empty USB flash drive that uses the \u003Ccode class=\"literal filename\">/dev/sdc1\u003C/code> device is plugged in and the \u003Ccode class=\"literal filename\">/mnt/flashdisk/\u003C/code> directory is present, use:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount /dev/sdc1 /mnt/flashdisk\n# ls /media/flashdisk\nen-US  publican.cfg\n# ls /mnt/flashdisk\nen-US  publican.cfg\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003C/div>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">mount(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"creating-a-slave-mount-point-duplicate_sharing-a-mount-on-multiple-mount-points\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">17.4. Creating a slave mount point duplicate\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tDuplicate a mount point as a \u003Ccode class=\"literal\">slave\u003C/code> mount type. File systems that you later mount under the original mount point are reflected in the duplicate but not the other way around.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a virtual file system (VFS) node from the original mount point:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount --bind \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">original-dir\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">original-dir\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tMark the original mount point as shared:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount --make-shared \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">original-dir\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAlternatively, to change the mount type for the selected mount point and all mount points under it, use the \u003Ccode class=\"literal option\">--make-rshared\u003C/code> option instead of \u003Ccode class=\"literal option\">--make-shared\u003C/code>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate the duplicate and mark it as the \u003Ccode class=\"literal\">slave\u003C/code> type:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount --bind \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">original-dir\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">duplicate-dir\u003C/span>\u003C/em>\u003C/span>\n# mount --make-slave \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">duplicate-dir\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"example\" id=\"idm139822450465584\">\u003Cp class=\"title\">\u003Cstrong>Example 17.3. Duplicating /media into /mnt as a slave mount point\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\tThis example shows how to get the content of the \u003Ccode class=\"literal filename\">/media\u003C/code> directory to appear in \u003Ccode class=\"literal filename\">/mnt\u003C/code> as well, but without any mounts in the \u003Ccode class=\"literal filename\">/mnt\u003C/code> directory to be reflected in \u003Ccode class=\"literal filename\">/media\u003C/code>.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tCreate a VFS node from the \u003Ccode class=\"literal filename\">/media\u003C/code> directory:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount --bind /media /media\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tMark the \u003Ccode class=\"literal filename\">/media\u003C/code> directory as shared:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount --make-shared /media\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tCreate its duplicate in \u003Ccode class=\"literal filename\">/mnt\u003C/code> and mark it as \u003Ccode class=\"literal\">slave\u003C/code>:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount --bind /media /mnt\n# mount --make-slave /mnt\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tVerify that a mount within \u003Ccode class=\"literal filename\">/media\u003C/code> also appears in \u003Ccode class=\"literal filename\">/mnt\u003C/code>. For example, if the CD-ROM drive contains non-empty media and the \u003Ccode class=\"literal filename\">/media/cdrom/\u003C/code> directory exists, use:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount /dev/cdrom /media/cdrom\n# ls /media/cdrom\nEFI  GPL  isolinux  LiveOS\n# ls /mnt/cdrom\nEFI  GPL  isolinux  LiveOS\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tAlso verify that file systems mounted in the \u003Ccode class=\"literal filename\">/mnt\u003C/code> directory are not reflected in \u003Ccode class=\"literal filename\">/media\u003C/code>. For example, if a non-empty USB flash drive that uses the \u003Ccode class=\"literal filename\">/dev/sdc1\u003C/code> device is plugged in and the \u003Ccode class=\"literal filename\">/mnt/flashdisk/\u003C/code> directory is present, use:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount /dev/sdc1 /mnt/flashdisk\n# ls /media/flashdisk\n# ls /mnt/flashdisk\nen-US  publican.cfg\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003C/div>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">mount(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"preventing-a-mount-point-from-being-duplicated_sharing-a-mount-on-multiple-mount-points\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">17.5. Preventing a mount point from being duplicated\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tMark a mount point as unbindable so that it is not possible to duplicate it in another mount point.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo change the type of a mount point to an unbindable mount, use:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount --bind \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">mount-point\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">mount-point\u003C/span>\u003C/em>\u003C/span>\n# mount --make-unbindable \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">mount-point\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAlternatively, to change the mount type for the selected mount point and all mount points under it, use the \u003Ccode class=\"literal option\">--make-runbindable\u003C/code> option instead of \u003Ccode class=\"literal option\">--make-unbindable\u003C/code>.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAny subsequent attempt to make a duplicate of this mount fails with the following error:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount --bind \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">mount-point\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">duplicate-dir\u003C/span>\u003C/em>\u003C/span>\n\nmount: wrong fs type, bad option, bad superblock on \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">mount-point\u003C/span>\u003C/em>\u003C/span>,\nmissing codepage or helper program, or other error\nIn some cases useful info is found in syslog - try\ndmesg | tail  or so\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"example\" id=\"idm139822467721632\">\u003Cp class=\"title\">\u003Cstrong>Example 17.4. Preventing /media from being duplicated\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tTo prevent the \u003Ccode class=\"literal filename\">/media\u003C/code> directory from being shared, use:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount --bind /media /media\n# mount --make-unbindable /media\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/div>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">mount(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"assembly_persistently-mounting-file-systems_managing-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 18. Persistently mounting file systems\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tAs a system administrator, you can persistently mount file systems to configure non-removable storage.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"con_the-etc-fstab-file_assembly_persistently-mounting-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">18.1. The /etc/fstab file\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tUse the \u003Ccode class=\"literal\">/etc/fstab\u003C/code> configuration file to control persistent mount points of file systems. Each line in the \u003Ccode class=\"literal\">/etc/fstab\u003C/code> file defines a mount point of a file system.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tIt includes six fields separated by white space:\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe block device identified by a persistent attribute or a path in the \u003Ccode class=\"literal\">/dev\u003C/code> directory.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe directory where the device will be mounted.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe file system on the device.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tMount options for the file system, which includes the \u003Ccode class=\"literal\">defaults\u003C/code> option to mount the partition at boot time with default options. The mount option field also recognizes the \u003Ccode class=\"literal\">systemd\u003C/code> mount unit options in the \u003Ccode class=\"literal\">x-systemd.\u003Cspan class=\"emphasis\">\u003Cem>option\u003C/em>\u003C/span>\u003C/code> format.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tBackup option for the \u003Ccode class=\"literal\">dump\u003C/code> utility.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tCheck order for the \u003Ccode class=\"literal\">fsck\u003C/code> utility.\n\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tThe \u003Ccode class=\"literal\">systemd-fstab-generator\u003C/code> dynamically converts the entries from the \u003Ccode class=\"literal\">/etc/fstab\u003C/code> file to the \u003Ccode class=\"literal\">systemd-mount\u003C/code> units. The \u003Ccode class=\"literal\">systemd\u003C/code> auto mounts LVM volumes from \u003Ccode class=\"literal\">/etc/fstab\u003C/code> during manual activation unless the \u003Ccode class=\"literal\">systemd-mount\u003C/code> unit is masked.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tThe \u003Ccode class=\"literal\">dump\u003C/code> utility used for backup of file systems has been removed in RHEL 9, and is available in the EPEL 9 repository.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"example\" id=\"idm139822450229440\">\u003Cp class=\"title\">\u003Cstrong>Example 18.1. The \u003Ccode class=\"literal filename\">/boot\u003C/code> file system in \u003Ccode class=\"literal filename\">/etc/fstab\u003C/code>\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Crh-table>\u003Ctable class=\"gt-4-cols lt-7-rows\">\u003Ccolgroup>\u003Ccol style=\"width: 29%; \" class=\"col_1\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 14%; \" class=\"col_2\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 14%; \" class=\"col_3\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 14%; \" class=\"col_4\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 14%; \" class=\"col_5\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 14%; \" class=\"col_6\">\u003C!--Empty-->\u003C/col>\u003C/colgroup>\u003Cthead>\u003Ctr>\u003Cth align=\"left\" valign=\"top\" id=\"idm139822448903120\" scope=\"col\">Block device\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm139822448902032\" scope=\"col\">Mount point\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm139822448900944\" scope=\"col\">File system\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm139822448899856\" scope=\"col\">Options\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm139822448898768\" scope=\"col\">Backup\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm139822448897680\" scope=\"col\">Check\u003C/th>\u003C/tr>\u003C/thead>\u003Ctbody>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822448903120\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">UUID=ea74bbec-536d-490c-b8d9-5b40bbd7545b\u003C/code>\n\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822448902032\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">/boot\u003C/code>\n\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822448900944\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs\u003C/code>\n\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822448899856\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">defaults\u003C/code>\n\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822448898768\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">0\u003C/code>\n\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822448897680\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">0\u003C/code>\n\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\u003C/rh-table>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tThe \u003Ccode class=\"literal\">systemd\u003C/code> service automatically generates mount units from entries in \u003Ccode class=\"literal filename\">/etc/fstab\u003C/code>.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">fstab(5)\u003C/code> and \u003Ccode class=\"literal\">systemd.mount(5)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"adding-a-file-system-to-etc-fstab_assembly_persistently-mounting-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">18.2. Adding a file system to /etc/fstab\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tConfigure persistent mount point for a file system in the \u003Ccode class=\"literal filename\">/etc/fstab\u003C/code> configuration file.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFind out the UUID attribute of the file system:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ lsblk --fs \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">storage-device\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor example:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"example\" id=\"idm139822451240784\">\u003Cp class=\"title\">\u003Cstrong>Example 18.2. Viewing the UUID of a partition\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cpre class=\"screen\">$ lsblk --fs \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">/dev/sda1\u003C/span>\u003C/em>\u003C/span>\n\nNAME FSTYPE LABEL \u003Cspan class=\"strong strong\">\u003Cstrong>UUID\u003C/strong>\u003C/span>                                 MOUNTPOINT\nsda1 xfs    Boot  \u003Cspan class=\"strong strong\">\u003Cstrong>ea74bbec-536d-490c-b8d9-5b40bbd7545b\u003C/strong>\u003C/span> /boot\u003C/pre>\u003C/div>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIf the mount point directory does not exist, create it:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mkdir --parents \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">mount-point\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAs root, edit the \u003Ccode class=\"literal filename\">/etc/fstab\u003C/code> file and add a line for the file system, identified by the UUID.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor example:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"example\" id=\"idm139822451232176\">\u003Cp class=\"title\">\u003Cstrong>Example 18.3. The /boot mount point in /etc/fstab\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cpre class=\"screen\">UUID=ea74bbec-536d-490c-b8d9-5b40bbd7545b /boot xfs defaults 0 0\u003C/pre>\u003C/div>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRegenerate mount units so that your system registers the new configuration:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># systemctl daemon-reload\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTry mounting the file system to verify that the configuration works:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">mount-point\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#con_device-names-managed-by-the-udev-mechanism-in-dev-disk-_assembly_overview-of-persistent-naming-attributes\">Overview of persistent naming attributes\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"mounting-file-systems-on-demand_managing-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 19. Mounting file systems on demand\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\tAs a system administrator, you can configure file systems, such as NFS, to mount automatically on demand.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"the-autofs-service_mounting-file-systems-on-demand\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">19.1. The autofs service\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe \u003Ccode class=\"literal\">autofs\u003C/code> service can mount and unmount file systems automatically (on-demand), therefore saving system resources. It can be used to mount file systems such as NFS, AFS, SMBFS, CIFS, and local file systems.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tOne drawback of permanent mounting using the \u003Ccode class=\"literal filename\">/etc/fstab\u003C/code> configuration is that, regardless of how infrequently a user accesses the mounted file system, the system must dedicate resources to keep the mounted file system in place. This might affect system performance when, for example, the system is maintaining NFS mounts to many systems at one time.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tAn alternative to \u003Ccode class=\"literal filename\">/etc/fstab\u003C/code> is to use the kernel-based \u003Ccode class=\"literal\">autofs\u003C/code> service. It consists of the following components:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tA kernel module that implements a file system, and\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tA user-space service that performs all of the other functions.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">autofs(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"the-autofs-configuration-files_mounting-file-systems-on-demand\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">19.2. The autofs configuration files\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis section describes the usage and syntax of configuration files used by the \u003Ccode class=\"literal\">autofs\u003C/code> service.\n\t\t\t\u003C/p>\u003Cdiv class=\"formalpara\">\u003Cp class=\"title\">\u003Cstrong>The master map file\u003C/strong>\u003C/p>\u003Cp>\n\t\t\t\t\tThe \u003Ccode class=\"literal\">autofs\u003C/code> service uses \u003Ccode class=\"literal filename\">/etc/auto.master\u003C/code> (master map) as its default primary configuration file. This can be changed to use another supported network source and name using the \u003Ccode class=\"literal\">autofs\u003C/code> configuration in the \u003Ccode class=\"literal filename\">/etc/autofs.conf\u003C/code> configuration file in conjunction with the Name Service Switch (NSS) mechanism.\n\t\t\t\t\u003C/p>\u003C/div>\u003Cp>\n\t\t\t\tAll on-demand mount points must be configured in the master map. Mount point, host name, exported directory, and options can all be specified in a set of files (or other supported network sources) rather than configuring them manually for each host.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe master map file lists mount points controlled by \u003Ccode class=\"literal\">autofs\u003C/code>, and their corresponding configuration files or network sources known as automount maps. The format of the master map is as follows:\n\t\t\t\u003C/p>\u003Cpre class=\"screen\">\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">mount-point\u003C/span>\u003C/em>\u003C/span>  \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">map-name\u003C/span>\u003C/em>\u003C/span>  \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">options\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cp>\n\t\t\t\tThe variables used in this format are:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">mount-point\u003C/span>\u003C/em>\u003C/span>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">autofs\u003C/code> mount point; for example, \u003Ccode class=\"literal filename\">/mnt/data\u003C/code>.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">map-file\u003C/span>\u003C/em>\u003C/span>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe map source file, which contains a list of mount points and the file system location from which those mount points should be mounted.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">options\u003C/span>\u003C/em>\u003C/span>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tIf supplied, these apply to all entries in the given map, if they do not themselves have options specified.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"example\" id=\"idm139822453675952\">\u003Cp class=\"title\">\u003Cstrong>Example 19.1. The /etc/auto.master file\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\tThe following is a sample line from \u003Ccode class=\"literal filename\">/etc/auto.master\u003C/code> file:\n\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">/mnt/data  /etc/auto.data\u003C/pre>\u003C/div>\u003C/div>\u003Cdiv class=\"formalpara\">\u003Cp class=\"title\">\u003Cstrong>Map files\u003C/strong>\u003C/p>\u003Cp>\n\t\t\t\t\tMap files configure the properties of individual on-demand mount points.\n\t\t\t\t\u003C/p>\u003C/div>\u003Cp>\n\t\t\t\tThe automounter creates the directories if they do not exist. If the directories exist before the automounter was started, the automounter will not remove them when it exits. If a timeout is specified, the directory is automatically unmounted if the directory is not accessed for the timeout period.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe general format of maps is similar to the master map. However, the options field appears between the mount point and the location instead of at the end of the entry as in the master map:\n\t\t\t\u003C/p>\u003Cpre class=\"screen\">\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">mount-point\u003C/span>\u003C/em>\u003C/span>  \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">options\u003C/span>\u003C/em>\u003C/span>  \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">location\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cp>\n\t\t\t\tThe variables used in this format are:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">mount-point\u003C/span>\u003C/em>\u003C/span>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThis refers to the \u003Ccode class=\"literal\">autofs\u003C/code> mount point. This can be a single directory name for an indirect mount or the full path of the mount point for direct mounts. Each direct and indirect map entry key (\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">mount-point\u003C/span>\u003C/em>\u003C/span>) can be followed by a space separated list of offset directories (subdirectory names each beginning with \u003Ccode class=\"literal\">/\u003C/code>) making them what is known as a multi-mount entry.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">options\u003C/span>\u003C/em>\u003C/span>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tWhen supplied, these options are appended to the master map entry options, if any, or used instead of the master map options if the configuration entry \u003Ccode class=\"literal\">append_options\u003C/code> is set to \u003Ccode class=\"literal\">no\u003C/code>.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">location\u003C/span>\u003C/em>\u003C/span>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThis refers to the file system location such as a local file system path (preceded with the Sun map format escape character \u003Ccode class=\"literal\">:\u003C/code> for map names beginning with \u003Ccode class=\"literal\">/\u003C/code>), an NFS file system or other valid file system location.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"example\" id=\"idm139822452846560\">\u003Cp class=\"title\">\u003Cstrong>Example 19.2. A map file\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\tThe following is a sample from a map file; for example, \u003Ccode class=\"literal filename\">/etc/auto.misc\u003C/code>:\n\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">payroll  -fstype=nfs4  personnel:/exports/payroll\nsales    -fstype=xfs   :/dev/hda4\u003C/pre>\u003Cp>\n\t\t\t\t\tThe first column in the map file indicates the \u003Ccode class=\"literal\">autofs\u003C/code> mount point: \u003Ccode class=\"literal\">sales\u003C/code> and \u003Ccode class=\"literal\">payroll\u003C/code> from the server called \u003Ccode class=\"literal\">personnel\u003C/code>. The second column indicates the options for the \u003Ccode class=\"literal\">autofs\u003C/code> mount. The third column indicates the source of the mount.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tFollowing the given configuration, the \u003Ccode class=\"literal\">autofs\u003C/code> mount points will be \u003Ccode class=\"literal\">/home/payroll\u003C/code> and \u003Ccode class=\"literal\">/home/sales\u003C/code>. The \u003Ccode class=\"literal option\">-fstype=\u003C/code> option is often omitted and is not needed if the file system is NFS, including mounts for NFSv4 if the system default is NFSv4 for NFS mounts.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tUsing the given configuration, if a process requires access to an \u003Ccode class=\"literal\">autofs\u003C/code> unmounted directory such as \u003Ccode class=\"literal filename\">/home/payroll/2006/July.sxc\u003C/code>, the \u003Ccode class=\"literal\">autofs\u003C/code> service automatically mounts the directory.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/div>\u003Cdiv class=\"formalpara\">\u003Cp class=\"title\">\u003Cstrong>The amd map format\u003C/strong>\u003C/p>\u003Cp>\n\t\t\t\t\tThe \u003Ccode class=\"literal\">autofs\u003C/code> service recognizes map configuration in the \u003Ccode class=\"literal\">amd\u003C/code> format as well. This is useful if you want to reuse existing automounter configuration written for the \u003Ccode class=\"literal\">am-utils\u003C/code> service, which has been removed from Red Hat Enterprise Linux.\n\t\t\t\t\u003C/p>\u003C/div>\u003Cp>\n\t\t\t\tHowever, Red Hat recommends using the simpler \u003Ccode class=\"literal\">autofs\u003C/code> format described in the previous sections.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">autofs(5)\u003C/code>, \u003Ccode class=\"literal\">autofs.conf(5)\u003C/code>, and \u003Ccode class=\"literal\">auto.master(5)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal filename\">/usr/share/doc/autofs/README.amd-maps\u003C/code> file\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"configuring-autofs-mount-points_mounting-file-systems-on-demand\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">19.3. Configuring autofs mount points\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tConfigure on-demand mount points by using the \u003Ccode class=\"literal\">autofs\u003C/code> service.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInstall the \u003Ccode class=\"literal package\">autofs\u003C/code> package:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf install autofs\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tStart and enable the \u003Ccode class=\"literal\">autofs\u003C/code> service:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># systemctl enable --now autofs\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tCreate a map file for the on-demand mount point, located at \u003Ccode class=\"literal filename\">/etc/auto.\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">identifier\u003C/span>\u003C/em>\u003C/span>\u003C/code>. Replace \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">identifier\u003C/span>\u003C/em>\u003C/span> with a name that identifies the mount point.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the map file, enter the mount point, options, and location fields as described in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_file_systems/mounting-file-systems-on-demand_managing-file-systems#the-autofs-configuration-files_mounting-file-systems-on-demand\">The autofs configuration files\u003C/a> section.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tRegister the map file in the master map file, as described in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_file_systems/mounting-file-systems-on-demand_managing-file-systems#the-autofs-configuration-files_mounting-file-systems-on-demand\">The autofs configuration files\u003C/a> section.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAllow the service to re-read the configuration, so it can manage the newly configured \u003Ccode class=\"literal\">autofs\u003C/code> mount:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># systemctl reload autofs.service\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTry accessing content in the on-demand directory:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># ls \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">automounted-directory\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"automounting-user-home-directories-with-autofs-service_mounting-file-systems-on-demand\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">19.4. Automounting NFS server user home directories with autofs service\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tConfigure the \u003Cspan class=\"strong strong\">\u003Cstrong>autofs\u003C/strong>\u003C/span> service to mount user home directories automatically.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Cspan class=\"strong strong\">\u003Cstrong>\u003Cspan class=\"package package\">autofs\u003C/span>\u003C/strong>\u003C/span> package is installed.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Cspan class=\"strong strong\">\u003Cstrong>\u003Cspan class=\"service service\">autofs\u003C/span>\u003C/strong>\u003C/span> service is enabled and running.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tSpecify the mount point and location of the map file by editing the \u003Ccode class=\"literal filename\">/etc/auto.master\u003C/code> file on a server on which you need to mount user home directories. To do so, add the following line into the \u003Ccode class=\"literal filename\">/etc/auto.master\u003C/code> file:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">/home /etc/auto.home\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a map file with the name of \u003Ccode class=\"literal filename\">/etc/auto.home\u003C/code> on a server on which you need to mount user home directories, and edit the file with the following parameters:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">* -fstype=nfs,rw,sync \u003Cspan class=\"emphasis\">\u003Cem>host.example.com\u003C/em>\u003C/span>:/home/&amp;\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tYou can skip \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>fstype\u003C/em>\u003C/span>\u003C/code> parameter, as it is \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>nfs\u003C/em>\u003C/span>\u003C/code> by default. For more information, see \u003Ccode class=\"literal\">autofs(5)\u003C/code> man page on your system.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tReload the \u003Ccode class=\"literal service\">autofs\u003C/code> service:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># systemctl reload autofs\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"overriding-or-augmenting-autofs-site-configuration-files_mounting-file-systems-on-demand\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">19.5. Overriding or augmenting autofs site configuration files\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tIt is sometimes useful to override site defaults for a specific mount point on a client system.\n\t\t\t\u003C/p>\u003Cdiv class=\"example\" id=\"idm139822451796928\">\u003Cp class=\"title\">\u003Cstrong>Example 19.3. Initial conditions\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\tFor example, consider the following conditions:\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tAutomounter maps are stored in NIS and the \u003Ccode class=\"literal filename\">/etc/nsswitch.conf\u003C/code> file has the following directive:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">automount:    files nis\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">auto.master\u003C/code> file contains:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">+auto.master\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe NIS \u003Ccode class=\"literal\">auto.master\u003C/code> map file contains:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">/home auto.home\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe NIS \u003Ccode class=\"literal\">auto.home\u003C/code> map contains:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">beth    fileserver.example.com:/export/home/beth\njoe     fileserver.example.com:/export/home/joe\n*       fileserver.example.com:/export/home/&amp;\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">autofs\u003C/code> configuration option \u003Ccode class=\"literal\">BROWSE_MODE\u003C/code> is set to \u003Ccode class=\"literal\">yes\u003C/code>:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">BROWSE_MODE=\"yes\"\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe file map \u003Ccode class=\"literal filename\">/etc/auto.home\u003C/code> does not exist.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/div>\u003C/div>\u003Cdiv class=\"formalpara\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cp>\n\t\t\t\t\tThis section describes the examples of mounting home directories from a different server and augmenting \u003Ccode class=\"literal\">auto.home\u003C/code> with only selected entries.\n\t\t\t\t\u003C/p>\u003C/div>\u003Cdiv class=\"example\" id=\"idm139822451779968\">\u003Cp class=\"title\">\u003Cstrong>Example 19.4. Mounting home directories from a different server\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\tGiven the preceding conditions, let’s assume that the client system needs to override the NIS map \u003Ccode class=\"literal\">auto.home\u003C/code> and mount home directories from a different server.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIn this case, the client needs to use the following \u003Ccode class=\"literal filename\">/etc/auto.master\u003C/code> map:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">/home ­/etc/auto.home\n+auto.master\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe \u003Ccode class=\"literal filename\">/etc/auto.home\u003C/code> map contains the entry:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">*    host.example.com:/export/home/&amp;\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\t\tBecause the automounter only processes the first occurrence of a mount point, the \u003Ccode class=\"literal filename\">/home\u003C/code> directory contains the content of \u003Ccode class=\"literal filename\">/etc/auto.home\u003C/code> instead of the NIS \u003Ccode class=\"literal\">auto.home\u003C/code> map.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/div>\u003Cdiv class=\"example\" id=\"idm139822449170544\">\u003Cp class=\"title\">\u003Cstrong>Example 19.5. Augmenting auto.home with only selected entries\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\tAlternatively, to augment the site-wide \u003Ccode class=\"literal\">auto.home\u003C/code> map with just a few entries:\n\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tCreate an \u003Ccode class=\"literal filename\">/etc/auto.home\u003C/code> file map, and in it put the new entries. At the end, include the NIS \u003Ccode class=\"literal\">auto.home\u003C/code> map. Then the \u003Ccode class=\"literal filename\">/etc/auto.home\u003C/code> file map looks similar to:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">mydir someserver:/export/mydir\n+auto.home\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tWith these NIS \u003Ccode class=\"literal\">auto.home\u003C/code> map conditions, listing the content of the \u003Ccode class=\"literal filename\">/home\u003C/code> directory outputs:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ ls /home\n\nbeth joe mydir\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cp>\n\t\t\t\t\tThis last example works as expected because \u003Ccode class=\"literal\">autofs\u003C/code> does not include the contents of a file map of the same name as the one it is reading. As such, \u003Ccode class=\"literal\">autofs\u003C/code> moves on to the next map source in the \u003Ccode class=\"literal\">nsswitch\u003C/code> configuration.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"using-ldap-to-store-automounter-maps_mounting-file-systems-on-demand\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">19.6. Using LDAP to store automounter maps\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tConfigure \u003Ccode class=\"literal\">autofs\u003C/code> to store automounter maps in LDAP configuration rather than in \u003Ccode class=\"literal\">autofs\u003C/code> map files.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tLDAP client libraries must be installed on all systems configured to retrieve automounter maps from LDAP. On Red Hat Enterprise Linux, the \u003Ccode class=\"literal package\">openldap\u003C/code> package should be installed automatically as a dependency of the \u003Ccode class=\"literal package\">autofs\u003C/code> package.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tTo configure LDAP access, modify the \u003Ccode class=\"literal filename\">/etc/openldap/ldap.conf\u003C/code> file. Ensure that the \u003Ccode class=\"literal\">BASE\u003C/code>, \u003Ccode class=\"literal\">URI\u003C/code>, and \u003Ccode class=\"literal\">schema\u003C/code> options are set appropriately for your site.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe most recently established schema for storing automount maps in LDAP is described by the \u003Ccode class=\"literal\">rfc2307bis\u003C/code> draft. To use this schema, set it in the \u003Ccode class=\"literal filename\">/etc/autofs.conf\u003C/code> configuration file by removing the comment characters from the schema definition. For example:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"example\" id=\"idm139822450727680\">\u003Cp class=\"title\">\u003Cstrong>Example 19.6. Setting autofs configuration\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cpre class=\"screen\">DEFAULT_MAP_OBJECT_CLASS=\"automountMap\"\nDEFAULT_ENTRY_OBJECT_CLASS=\"automount\"\nDEFAULT_MAP_ATTRIBUTE=\"automountMapName\"\nDEFAULT_ENTRY_ATTRIBUTE=\"automountKey\"\nDEFAULT_VALUE_ATTRIBUTE=\"automountInformation\"\u003C/pre>\u003C/div>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnsure that all other schema entries are commented in the configuration. The \u003Ccode class=\"literal\">automountKey\u003C/code> attribute of the \u003Ccode class=\"literal\">rfc2307bis\u003C/code> schema replaces the \u003Ccode class=\"literal\">cn\u003C/code> attribute of the \u003Ccode class=\"literal\">rfc2307\u003C/code> schema. Following is an example of an LDAP Data Interchange Format (LDIF) configuration:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"example\" id=\"idm139822450723008\">\u003Cp class=\"title\">\u003Cstrong>Example 19.7. LDIF Configuration\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cpre class=\"screen\"># auto.master, example.com\ndn: automountMapName=auto.master,dc=example,dc=com\nobjectClass: top\nobjectClass: automountMap\nautomountMapName: auto.master\n\n# /home, auto.master, example.com\ndn: automountMapName=auto.master,dc=example,dc=com\nobjectClass: automount\nautomountKey: /home\nautomountInformation: auto.home\n\n# auto.home, example.com\ndn: automountMapName=auto.home,dc=example,dc=com\nobjectClass: automountMap\nautomountMapName: auto.home\n\n# foo, auto.home, example.com\ndn: automountKey=foo,automountMapName=auto.home,dc=example,dc=com\nobjectClass: automount\nautomountKey: foo\nautomountInformation: filer.example.com:/export/foo\n\n# /, auto.home, example.com\ndn: automountKey=/,automountMapName=auto.home,dc=example,dc=com\nobjectClass: automount\nautomountKey: /\nautomountInformation: filer.example.com:/export/&amp;\u003C/pre>\u003C/div>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://tools.ietf.org/html/draft-howard-rfc2307bis\">The \u003Ccode class=\"literal\">rfc2307bis\u003C/code> draft\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"proc_using-systemd-automount-to-mount-a-file-system-on-demand-with-etc-fstab_mounting-file-systems-on-demand\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">19.7. Using systemd.automount to mount a file system on demand with /etc/fstab\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tMount a file system on demand using the automount systemd units when mount point is defined in \u003Ccode class=\"literal\">/etc/fstab\u003C/code>. You have to add an automount unit for each mount and enable it.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAdd desired fstab entry as documented in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#assembly_persistently-mounting-file-systems_managing-file-systems\">Persistently mounting file systems\u003C/a>. For example:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">/dev/disk/by-id/da875760-edb9-4b82-99dc-5f4b1ff2e5f4  /mount/point  xfs  defaults  0 0\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tAdd \u003Ccode class=\"literal\">x-systemd.automount\u003C/code> to the options field of entry created in the previous step.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tLoad newly created units so that your system registers the new configuration:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># systemctl daemon-reload\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tStart the automount unit:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># systemctl start \u003Cspan class=\"emphasis\">\u003Cem>mount-point.automount\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCheck that \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>mount-point.automount\u003C/em>\u003C/span>\u003C/code> is running:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># systemctl status \u003Cspan class=\"emphasis\">\u003Cem>mount-point.automount\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCheck that automounted directory has desired content:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># ls \u003Cspan class=\"emphasis\">\u003Cem>/mount/point\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">systemd.automount(5)\u003C/code> and \u003Ccode class=\"literal\">systemd.mount(5)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_basic_system_settings/managing-systemd_configuring-basic-system-settings#doc-wrapper\">Managing systemd\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"proc_using-systemd-automount-to-mount-a-file-system-on-demand-with-a-mount-unit_mounting-file-systems-on-demand\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">19.8. Using systemd.automount to mount a file system on-demand with a mount unit\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tMount a file system on-demand using the automount systemd units when mount point is defined by a mount unit. You have to add an automount unit for each mount and enable it.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a mount unit. For example:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">mount-point.mount\n[Mount]\nWhat=\u003Cspan class=\"emphasis\">\u003Cem>/dev/disk/by-uuid/f5755511-a714-44c1-a123-cfde0e4ac688\u003C/em>\u003C/span>\nWhere=\u003Cspan class=\"emphasis\">\u003Cem>/mount/point\u003C/em>\u003C/span>\nType=\u003Cspan class=\"emphasis\">\u003Cem>xfs\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tCreate a unit file with the same name as the mount unit, but with extension \u003Ccode class=\"literal\">.automount\u003C/code>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOpen the file and create an \u003Ccode class=\"literal\">[Automount]\u003C/code> section. Set the \u003Ccode class=\"literal\">Where=\u003C/code> option to the mount path:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">[Automount]\nWhere=\u003Cspan class=\"emphasis\">\u003Cem>/mount/point\u003C/em>\u003C/span>\n[Install]\nWantedBy=multi-user.target\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tLoad newly created units so that your system registers the new configuration:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># systemctl daemon-reload\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnable and start the automount unit instead:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># systemctl enable --now \u003Cspan class=\"emphasis\">\u003Cem>mount-point.automount\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCheck that \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>mount-point.automount\u003C/em>\u003C/span>\u003C/code> is running:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># systemctl status \u003Cspan class=\"emphasis\">\u003Cem>mount-point.automount\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCheck that automounted directory has desired content:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># ls \u003Cspan class=\"emphasis\">\u003Cem>/mount/point\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">systemd.automount(5)\u003C/code> and \u003Ccode class=\"literal\">systemd.mount(5)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_basic_system_settings/managing-systemd_configuring-basic-system-settings\">Managing systemd\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"using-sssd-component-from-idm-to-cache-the-autofs-map_managing-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 20. Using SSSD component from IdM to cache the autofs maps\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tThe System Security Services Daemon (SSSD) is a system service to access remote service directories and authentication mechanisms. The data caching is useful in case of the slow network connection. To configure the SSSD service to cache the autofs map, follow the procedures below in this section.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"configuring-autofs-manually-to-use-sssd-and-idm_using-sssd-component-from-idm-to-cache-the-autofs-map\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">20.1. Configuring autofs manually to use IdM server as an LDAP server\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tConfigure \u003Ccode class=\"literal\">autofs\u003C/code> to use IdM server as an LDAP server.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEdit the \u003Ccode class=\"literal\">/etc/autofs.conf\u003C/code> file to specify the schema attributes that \u003Ccode class=\"literal\">autofs\u003C/code> searches for:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">#\n# Other common LDAP naming\n#\nmap_object_class = \"automountMap\"\nentry_object_class = \"automount\"\nmap_attribute = \"automountMapName\"\nentry_attribute = \"automountKey\"\nvalue_attribute = \"automountInformation\"\u003C/pre>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\tUser can write the attributes in both lower and upper cases in the \u003Ccode class=\"literal\">/etc/autofs.conf\u003C/code> file.\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOptional: Specify the LDAP configuration. There are two ways to do this. The simplest is to let the automount service discover the LDAP server and locations on its own:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">ldap_uri = \"ldap:///dc=example,dc=com\"\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\u003Cspan class=\"emphasis\">\u003Cem>This option requires DNS to contain SRV records for the discoverable servers.\u003C/em>\u003C/span>\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAlternatively, explicitly set which LDAP server to use and the base DN for LDAP searches:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">ldap_uri = \"ldap://ipa.example.com\"\nsearch_base = \"cn=\u003Cspan class=\"emphasis\">\u003Cem>location\u003C/em>\u003C/span>,cn=automount,dc=example,dc=com\"\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEdit the \u003Ccode class=\"literal\">/etc/autofs_ldap_auth.conf\u003C/code> file so that autofs allows client authentication with the IdM LDAP server.\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tChange \u003Ccode class=\"literal\">authrequired\u003C/code> to yes.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tSet the principal to the Kerberos host principal for the IdM LDAP server, \u003Cspan class=\"emphasis\">\u003Cem>host/FQDN@REALM\u003C/em>\u003C/span>. The principal name is used to connect to the IdM directory as part of GSS client authentication.\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">&lt;autofs_ldap_sasl_conf\n     usetls=\"no\"\n     tlsrequired=\"no\"\n     authrequired=\"yes\"\n     authtype=\"GSSAPI\"\n     clientprinc=\"host/server.example.com@EXAMPLE.COM\"\n     /&gt;\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tFor more information about host principal, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/working_with_dns_in_identity_management/using-canonicalized-dns-host-names-in-idm_working-with-dns-in-identity-management\">Using canonicalized DNS host names in IdM\u003C/a>.\n\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tIf necessary, run \u003Ccode class=\"literal command\">klist -k\u003C/code> to get the exact host principal information.\n\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"configuring-sssd-to-cache-autofs-map_using-sssd-component-from-idm-to-cache-the-autofs-map\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">20.2. Configuring SSSD to cache autofs maps\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe SSSD service can be used to cache \u003Ccode class=\"literal\">autofs\u003C/code> maps stored on an IdM server without having to configure \u003Ccode class=\"literal\">autofs\u003C/code> to use the IdM server at all.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal package\">sssd\u003C/code> package is installed.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOpen the SSSD configuration file:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># vim /etc/sssd/sssd.conf\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAdd the \u003Ccode class=\"literal\">autofs\u003C/code> service to the list of services handled by SSSD.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">[sssd]\ndomains = ldap\nservices = nss,pam,\u003Ccode class=\"literal\">autofs\u003C/code>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a new \u003Ccode class=\"literal\">[autofs]\u003C/code> section. You can leave this blank, because the default settings for an \u003Ccode class=\"literal\">autofs\u003C/code> service work with most infrastructures.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">[nss]\n\n[pam]\n\n[sudo]\n\n\u003Ccode class=\"literal\">[autofs]\u003C/code>\n\n[ssh]\n\n[pac]\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor more information, see the \u003Ccode class=\"literal\">sssd.conf\u003C/code> man page on your system.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOptional: Set a search base for the \u003Ccode class=\"literal\">autofs\u003C/code> entries. By default, this is the LDAP search base, but a subtree can be specified in the \u003Ccode class=\"literal\">ldap_autofs_search_base\u003C/code> parameter.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">[domain/EXAMPLE]\n\nldap_search_base = \"dc=example,dc=com\"\nldap_autofs_search_base = \"ou=automount,dc=example,dc=com\"\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRestart SSSD service:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># systemctl restart sssd.service\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCheck the \u003Ccode class=\"literal\">/etc/nsswitch.conf\u003C/code> file, so that SSSD is listed as a source for automount configuration:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">automount: \u003Ccode class=\"literal\">sss\u003C/code> files\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRestart \u003Ccode class=\"literal\">autofs\u003C/code> service:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># systemctl restart autofs.service\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTest the configuration by listing a user’s \u003Ccode class=\"literal\">/home\u003C/code> directory, assuming there is a master map entry for \u003Ccode class=\"literal\">/home\u003C/code>:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># ls /home/\u003Cspan class=\"emphasis\">\u003Cem>userName\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIf this does not mount the remote file system, check the \u003Ccode class=\"literal\">/var/log/messages\u003C/code> file for errors. If necessary, increase the debug level in the \u003Ccode class=\"literal\">/etc/sysconfig/autofs\u003C/code> file by setting the \u003Ccode class=\"literal\">logging\u003C/code> parameter to \u003Ccode class=\"literal\">debug\u003C/code>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"setting-read-only-permissions-for-the-root-file-system_managing-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 21. Setting read-only permissions for the root file system\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tSometimes, you need to mount the root file system (\u003Ccode class=\"literal filename\">/\u003C/code>) with read-only permissions. Example use cases include enhancing security or ensuring data integrity after an unexpected system power-off.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"files-and-directories-that-always-retain-write-permissions_setting-read-only-permissions-for-the-root-file-system\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">21.1. Files and directories that always retain write permissions\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tFor the system to function properly, some files and directories need to retain write permissions. When the root file system is mounted in read-only mode, these files are mounted in RAM using the \u003Ccode class=\"literal\">tmpfs\u003C/code> temporary file system.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe default set of such files and directories is read from the \u003Ccode class=\"literal filename\">/etc/rwtab\u003C/code> file. Note that the \u003Ccode class=\"literal\">readonly-root\u003C/code> package is required to have this file present in your system.\n\t\t\t\u003C/p>\u003Cpre class=\"screen\">dirs\t/var/cache/man\ndirs\t/var/gdm\n\u003Cspan class=\"emphasis\">\u003Cem>&lt;content truncated&gt;\u003C/em>\u003C/span>\n\nempty\t/tmp\nempty\t/var/cache/foomatic\n\u003Cspan class=\"emphasis\">\u003Cem>&lt;content truncated&gt;\u003C/em>\u003C/span>\n\nfiles\t/etc/adjtime\nfiles\t/etc/ntp.conf\n\u003Cspan class=\"emphasis\">\u003Cem>&lt;content truncated&gt;\u003C/em>\u003C/span>\u003C/pre>\u003Cp>\n\t\t\t\tEntries in the \u003Ccode class=\"literal filename\">/etc/rwtab\u003C/code> file follow this format:\n\t\t\t\u003C/p>\u003Cpre class=\"screen\">\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">copy-method\u003C/span>\u003C/em>\u003C/span>    \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">path\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cp>\n\t\t\t\tIn this syntax:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">copy-method\u003C/span>\u003C/em>\u003C/span> with one of the keywords specifying how the file or directory is copied to tmpfs.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">path\u003C/span>\u003C/em>\u003C/span> with the path to the file or directory.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tThe \u003Ccode class=\"literal filename\">/etc/rwtab\u003C/code> file recognizes the following ways in which a file or directory can be copied to \u003Ccode class=\"literal\">tmpfs\u003C/code>:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">empty\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tAn empty path is copied to \u003Ccode class=\"literal\">tmpfs\u003C/code>. For example:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">empty /tmp\u003C/pre>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">dirs\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tA directory tree is copied to \u003Ccode class=\"literal\">tmpfs\u003C/code>, empty. For example:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">dirs /var/run\u003C/pre>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">files\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tA file or a directory tree is copied to \u003Ccode class=\"literal\">tmpfs\u003C/code> intact. For example:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">files /etc/resolv.conf\u003C/pre>\u003C/dd>\u003C/dl>\u003C/div>\u003Cp>\n\t\t\t\tThe same format applies when adding custom paths to \u003Ccode class=\"literal filename\">/etc/rwtab.d/\u003C/code>.\n\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"configuring-the-root-file-system-to-mount-with-read-only-permissions-on-boot_setting-read-only-permissions-for-the-root-file-system\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">21.2. Configuring the root file system to mount with read-only permissions on boot\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tWith this procedure, the root file system is mounted read-only on all following boots.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn the \u003Ccode class=\"literal filename\">/etc/sysconfig/readonly-root\u003C/code> file, set the \u003Ccode class=\"literal option\">READONLY\u003C/code> option to \u003Ccode class=\"literal\">yes\u003C/code> to mount the file systems as read-only:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">READONLY=yes\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAdd the \u003Ccode class=\"literal option\">ro\u003C/code> option in the root entry (\u003Ccode class=\"literal filename\">/\u003C/code>) in the \u003Ccode class=\"literal filename\">/etc/fstab\u003C/code> file:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">/dev/mapper/luks-c376919e...  /  xfs  x-systemd.device-timeout=0,\u003Cspan class=\"strong strong\">\u003Cstrong>ro\u003C/strong>\u003C/span>  1  1\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnable the \u003Ccode class=\"literal option\">ro\u003C/code> kernel option:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># grubby --update-kernel=ALL --args=\"ro\"\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnsure that the \u003Ccode class=\"literal option\">rw\u003C/code> kernel option is disabled:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># grubby --update-kernel=ALL --remove-args=\"rw\"\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIf you need to add files and directories to be mounted with write permissions in the \u003Ccode class=\"literal\">tmpfs\u003C/code> file system, create a text file in the \u003Ccode class=\"literal filename\">/etc/rwtab.d/\u003C/code> directory and put the configuration there.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor example, to mount the \u003Ccode class=\"literal filename\">/etc/example/file\u003C/code> file with write permissions, add this line to the \u003Ccode class=\"literal filename\">/etc/rwtab.d/example\u003C/code> file:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">files /etc/example/file\u003C/pre>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\tChanges made to files and directories in \u003Ccode class=\"literal\">tmpfs\u003C/code> do not persist across boots.\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tReboot the system to apply the changes.\n\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Troubleshooting\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIf you mount the root file system with read-only permissions by mistake, you can remount it with read-and-write permissions again using the following command:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount -o remount,rw /\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"assembly_limiting-storage-space-usage-on-xfs-with-quotas_managing-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 22. Limiting storage space usage on XFS with quotas\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tYou can restrict the amount of disk space available to users or groups by implementing disk quotas. You can also define a warning level at which system administrators are informed before a user consumes too much disk space or a partition becomes full.\n\t\t\u003C/p>\u003Cp>\n\t\t\tThe XFS quota subsystem manages limits on disk space (blocks) and file (inode) usage. XFS quotas control or report on usage of these items on a user, group, or directory or project level. Group and project quotas are only mutually exclusive on older non-default XFS disk formats.\n\t\t\u003C/p>\u003Cp>\n\t\t\tWhen managing on a per-directory or per-project basis, XFS manages the disk usage of directory hierarchies associated with a specific project.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"con_disk-quotas_assembly_limiting-storage-space-usage-on-xfs-with-quotas\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">22.1. Disk quotas\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tIn most computing environments, disk space is not infinite. The quota subsystem provides a mechanism to control usage of disk space.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tYou can configure disk quotas for individual users as well as user groups on the local file systems. This makes it possible to manage the space allocated for user-specific files (such as email) separately from the space allocated to the projects that a user works on. The quota subsystem warns users when they exceed their allotted limit, but allows some extra space for current work (hard limit/soft limit).\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tIf quotas are implemented, you need to check if the quotas are exceeded and make sure the quotas are accurate. If users repeatedly exceed their quotas or consistently reach their soft limits, a system administrator can either help the user determine how to use less disk space or increase the user’s disk quota.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tYou can set quotas to control:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe number of consumed disk blocks.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe number of inodes, which are data structures that contain information about files in UNIX file systems. Because inodes store file-related information, this allows control over the number of files that can be created.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"the-xfs_quota-tool_assembly_limiting-storage-space-usage-on-xfs-with-quotas\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">22.2. The \u003Ccode class=\"literal\">xfs_quota\u003C/code> tool\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can use the \u003Ccode class=\"literal\">xfs_quota\u003C/code> tool to manage quotas on XFS file systems. In addition, you can use XFS file systems with limit enforcement turned off as an effective disk usage accounting system.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe XFS quota system differs from other file systems in a number of ways. Most importantly, XFS considers quota information as file system metadata and uses journaling to provide a higher level guarantee of consistency.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs_quota(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"file-system-quota-management-in-xfs_assembly_limiting-storage-space-usage-on-xfs-with-quotas\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">22.3. File system quota management in XFS\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe XFS quota subsystem manages limits on disk space (blocks) and file (inode) usage. XFS quotas control or report on usage of these items on a user, group, or directory or project level. Group and project quotas are only mutually exclusive on older non-default XFS disk formats.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tWhen managing on a per-directory or per-project basis, XFS manages the disk usage of directory hierarchies associated with a specific project.\n\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"enabling-disk-quotas-for-xfs_assembly_limiting-storage-space-usage-on-xfs-with-quotas\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">22.4. Enabling disk quotas for XFS\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tEnable disk quotas for users, groups, and projects on an XFS file system. Once quotas are enabled, the \u003Ccode class=\"literal\">xfs_quota\u003C/code> tool can be used to set limits and report on disk usage.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnable quotas for users:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount -o uquota /dev/xvdb1 /xfs\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tReplace \u003Ccode class=\"literal\">uquota\u003C/code> with \u003Ccode class=\"literal\">uqnoenforce\u003C/code> to allow usage reporting without enforcing any limits.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnable quotas for groups:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount -o gquota /dev/xvdb1 /xfs\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tReplace \u003Ccode class=\"literal\">gquota\u003C/code> with \u003Ccode class=\"literal\">gqnoenforce\u003C/code> to allow usage reporting without enforcing any limits.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnable quotas for projects:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount -o pquota /dev/xvdb1 /xfs\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tReplace \u003Ccode class=\"literal\">pquota\u003C/code> with \u003Ccode class=\"literal\">pqnoenforce\u003C/code> to allow usage reporting without enforcing any limits.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAlternatively, include the quota mount options in the \u003Ccode class=\"literal\">/etc/fstab\u003C/code> file. The following example shows entries in the \u003Ccode class=\"literal\">/etc/fstab\u003C/code> file to enable quotas for users, groups, and projects, respectively, on an XFS file system. These examples also mount the file system with read/write permissions:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># vim /etc/fstab\n/dev/xvdb1    /xfs    xfs    rw,quota       0  0\n/dev/xvdb1    /xfs    xfs    rw,gquota      0  0\n/dev/xvdb1    /xfs    xfs    rw,prjquota    0  0\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">mount(8)\u003C/code> and \u003Ccode class=\"literal\">xfs_quota(8)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"running-the-xfs_quota-tool_assembly_limiting-storage-space-usage-on-xfs-with-quotas\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">22.5. Reporting XFS usage\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tUse the \u003Ccode class=\"literal\">xfs_quota\u003C/code> tool to set limits and report on disk usage. By default, \u003Ccode class=\"literal\">xfs_quota\u003C/code> is run interactively, and in basic mode. Basic mode subcommands simply report usage, and are available to all users.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tQuotas have been enabled for the XFS file system. See \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#enabling-disk-quotas-for-xfs_assembly_limiting-storage-space-usage-on-xfs-with-quotas\">Enabling disk quotas for XFS\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tStart the \u003Ccode class=\"literal\">xfs_quota\u003C/code> shell:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># xfs_quota\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tShow usage and limits for the given user:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># xfs_quota&gt; quota \u003Cspan class=\"emphasis\">\u003Cem>username\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tShow free and used counts for blocks and inodes:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># xfs_quota&gt; df\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRun the help command to display the basic commands available with \u003Ccode class=\"literal\">xfs_quota\u003C/code>.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># xfs_quota&gt; help\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tSpecify \u003Ccode class=\"literal\">q\u003C/code> to exit \u003Ccode class=\"literal\">xfs_quota\u003C/code>.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># xfs_quota&gt; q\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs_quota(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"running-the-xfs_quota-tool-in-expert-mode_assembly_limiting-storage-space-usage-on-xfs-with-quotas\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">22.6. Modifying XFS quota limits\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tStart the \u003Ccode class=\"literal\">xfs_quota\u003C/code> tool with the \u003Ccode class=\"literal\">-x\u003C/code> option to enable expert mode and run the administrator commands, which allow modifications to the quota system. The subcommands of this mode allow actual configuration of limits, and are available only to users with elevated privileges.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tQuotas have been enabled for the XFS file system. See \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#enabling-disk-quotas-for-xfs_assembly_limiting-storage-space-usage-on-xfs-with-quotas\">Enabling disk quotas for XFS\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tStart the \u003Ccode class=\"literal\">xfs_quota\u003C/code> shell with the \u003Ccode class=\"literal\">-x\u003C/code> option to enable expert mode:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># xfs_quota -x\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tReport quota information for a specific file system:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># xfs_quota&gt; report /\u003Cspan class=\"emphasis\">\u003Cem>path\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor example, to display a sample quota report for \u003Ccode class=\"literal\">/home\u003C/code> (on \u003Ccode class=\"literal\">/dev/blockdevice\u003C/code>), use the command \u003Ccode class=\"literal\">report -h /home\u003C/code>. This displays output similar to the following:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">User quota on /home (/dev/blockdevice)\nBlocks\nUser ID      Used   Soft   Hard Warn/Grace\n---------- ---------------------------------\nroot            0      0      0  00 [------]\ntestuser   103.4G      0      0  00 [------]\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tModify quota limits:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># xfs_quota&gt; limit isoft=\u003Cspan class=\"emphasis\">\u003Cem>500m\u003C/em>\u003C/span> ihard=\u003Cspan class=\"emphasis\">\u003Cem>700m\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>user\u003C/em>\u003C/span> /\u003Cspan class=\"emphasis\">\u003Cem>path\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor example, to set a soft and hard inode count limit of 500 and 700 respectively for user \u003Ccode class=\"literal\">john\u003C/code>, whose home directory is \u003Ccode class=\"literal\">/home/john\u003C/code>, use the following command:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># xfs_quota -x -c 'limit isoft=500 ihard=700 john' /home/\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn this case, pass \u003Ccode class=\"literal\">mount_point\u003C/code> which is the mounted xfs file system.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRun the help command to display the expert commands available with \u003Ccode class=\"literal\">xfs_quota -x\u003C/code>:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># xfs_quota&gt; help\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs_quota(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"setting-project-limits-for-xfs_assembly_limiting-storage-space-usage-on-xfs-with-quotas\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">22.7. Setting project limits for XFS\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tConfigure limits for project-controlled directories.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAdd the project-controlled directories to \u003Ccode class=\"literal\">/etc/projects\u003C/code>. For example, the following adds the \u003Ccode class=\"literal\">/var/log\u003C/code> path with a unique ID of 11 to \u003Ccode class=\"literal\">/etc/projects\u003C/code>. Your project ID can be any numerical value mapped to your project.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># echo 11:/var/log &gt;&gt; /etc/projects\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAdd project names to \u003Ccode class=\"literal\">/etc/projid\u003C/code> to map project IDs to project names. For example, the following associates a project called \u003Ccode class=\"literal\">logfiles\u003C/code> with the project ID of 11 as defined in the previous step.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># echo logfiles:11 &gt;&gt; /etc/projid\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInitialize the project directory. For example, the following initializes the project directory \u003Ccode class=\"literal\">/var\u003C/code>:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># xfs_quota -x -c 'project -s logfiles' /var\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tConfigure quotas for projects with initialized directories:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># xfs_quota -x -c 'limit -p bhard=1g logfiles' /var\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs_quota(8)\u003C/code>, \u003Ccode class=\"literal\">projid(5)\u003C/code>, and \u003Ccode class=\"literal\">projects(5)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"limiting-storage-space-usage-on-ext4-with-quotas_managing-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 23. Limiting storage space usage on ext4 with quotas\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\tYou have to enable disk quotas on your system before you can assign them. You can assign disk quotas per user, per group or per project. However, if there is a soft limit set, you can exceed these quotas for a configurable period of time, known as the grace period.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"installing-quota-rpm_limiting-storage-space-usage-on-ext4-with-quotas\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">23.1. Installing the quota tool\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou must install the \u003Ccode class=\"literal\">quota\u003C/code> RPM package to implement disk quotas.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInstall the \u003Ccode class=\"literal\">quota\u003C/code> package:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf install quota\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"enabling-quota-feature-in-file-system-creation_limiting-storage-space-usage-on-ext4-with-quotas\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">23.2. Enabling quota feature on file system creation\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tEnable quotas on file system creation.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnable quotas on file system creation:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mkfs.ext4 -O quota /dev/sda\u003C/pre>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\tOnly user and group quotas are enabled and initialized by default.\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tChange the defaults on file system creation:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mkfs.ext4 -O quota -E quotatype=usrquota:grpquota:prjquota /dev/sda\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tMount the file system:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount /dev/sda\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">ext4(5)\u003C/code> man page on your system.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"enabling-quota-feature-on-existing-file-system_limiting-storage-space-usage-on-ext4-with-quotas\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">23.3. Enabling quota feature on existing file systems\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tEnable the quota feature on existing file system by using the \u003Ccode class=\"literal\">tune2fs\u003C/code> command.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tUnmount the file system:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># umount /dev/sda\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnable quotas on existing file system:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># tune2fs -O quota /dev/sda\u003C/pre>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\tOnly user and group quotas are initialized by default.\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tChange the defaults:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># tune2fs -Q usrquota,grpquota,prjquota /dev/sda\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tMount the file system:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount /dev/sda\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">ext4(5)\u003C/code> man page on your system.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"enabling-quota-enforcement_limiting-storage-space-usage-on-ext4-with-quotas\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">23.4. Enabling quota enforcement\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe quota accounting is enabled by default after mounting the file system without any additional options, but quota enforcement is not.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tQuota feature is enabled and the default quotas are initialized.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnable quota enforcement by \u003Ccode class=\"literal\">quotaon\u003C/code> for the user quota:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount /dev/sda /mnt\u003C/pre>\u003Cpre class=\"screen\"># quotaon /mnt\u003C/pre>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\tThe quota enforcement can be enabled at mount time using \u003Ccode class=\"literal\">usrquota\u003C/code>, \u003Ccode class=\"literal\">grpquota\u003C/code>, or \u003Ccode class=\"literal\">prjquota\u003C/code> mount options.\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount -o usrquota,grpquota,prjquota /dev/sda /mnt\u003C/pre>\u003C/div>\u003C/rh-alert>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnable user, group, and project quotas for all file systems:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># quotaon -vaugP\u003C/pre>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tIf neither of the \u003Ccode class=\"literal\">-u\u003C/code>, \u003Ccode class=\"literal\">-g\u003C/code>, or \u003Ccode class=\"literal\">-P\u003C/code> options are specified, only the user quotas are enabled.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tIf only \u003Ccode class=\"literal\">-g\u003C/code> option is specified, only group quotas are enabled.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tIf only \u003Ccode class=\"literal\">-P\u003C/code> option is specified, only project quotas are enabled.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnable quotas for a specific file system, such as \u003Ccode class=\"literal\">/home\u003C/code>:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># quotaon -vugP /home\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">quotaon(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"assigning-quotas-per-user_limiting-storage-space-usage-on-ext4-with-quotas\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">23.5. Assigning quotas per user\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe disk quotas are assigned to users with the \u003Ccode class=\"literal\">edquota\u003C/code> command.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tThe text editor defined by the \u003Ccode class=\"literal\">EDITOR\u003C/code> environment variable is used by \u003Ccode class=\"literal\">edquota\u003C/code>. To change the editor, set the \u003Ccode class=\"literal\">EDITOR\u003C/code> environment variable in your \u003Ccode class=\"literal\">~/.bash_profile\u003C/code> file to the full path of the editor of your choice.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tUser must exist prior to setting the user quota.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAssign the quota for a user:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># edquota \u003Cspan class=\"emphasis\">\u003Cem>username\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>username\u003C/em>\u003C/span> with the user to which you want to assign the quotas.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor example, if you enable a quota for the \u003Ccode class=\"literal\">/dev/sda\u003C/code> partition and execute the command \u003Ccode class=\"literal\">edquota testuser\u003C/code>, the following is displayed in the default editor configured on the system:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">Disk quotas for user testuser (uid 501):\nFilesystem   blocks   soft   hard   inodes   soft   hard\n/dev/sda      44043      0      0    37418      0      0\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tChange the desired limits.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIf any of the values are set to 0, limit is not set. Change them in the text editor.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor example, the following shows the soft and hard block limits for the testuser have been set to 50000 and 55000 respectively.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">Disk quotas for user testuser (uid 501):\nFilesystem   blocks   soft   hard   inodes   soft   hard\n/dev/sda      44043  50000  55000    37418      0      0\u003C/pre>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe first column is the name of the file system that has a quota enabled for it.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe second column shows how many blocks the user is currently using.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe next two columns are used to set soft and hard block limits for the user on the file system.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">inodes\u003C/code> column shows how many inodes the user is currently using.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tThe last two columns are used to set the soft and hard inode limits for the user on the file system.\n\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\tThe hard block limit is the absolute maximum amount of disk space that a user or group can use. Once this limit is reached, no further disk space can be used.\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\tThe soft block limit defines the maximum amount of disk space that can be used. However, unlike the hard limit, the soft limit can be exceeded for a certain amount of time. That time is known as the \u003Cspan class=\"emphasis\">\u003Cem>grace period\u003C/em>\u003C/span>. The grace period can be expressed in seconds, minutes, hours, days, weeks, or months.\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify that the quota for the user has been set:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># quota -v testuser\nDisk quotas for user testuser:\nFilesystem  blocks  quota  limit  grace  files  quota  limit  grace\n/dev/sda      1000*  1000   1000             0      0      0\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"assigning-quotas-per-group_limiting-storage-space-usage-on-ext4-with-quotas\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">23.6. Assigning quotas per group\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can assign quotas on a per-group basis.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tGroup must exist prior to setting the group quota.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tSet a group quota:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># edquota -g \u003Cspan class=\"emphasis\">\u003Cem>groupname\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor example, to set a group quota for the \u003Ccode class=\"literal\">devel\u003C/code> group:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># edquota -g devel\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThis command displays the existing quota for the group in the text editor:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">Disk quotas for group devel (gid 505):\nFilesystem   blocks  soft  hard  inodes  soft  hard\n/dev/sda     440400     0     0   37418     0     0\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tModify the limits and save the file.\n\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify that the group quota is set:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># quota -vg \u003Cspan class=\"emphasis\">\u003Cem>groupname\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"assigning-quotas-per-project_limiting-storage-space-usage-on-ext4-with-quotas\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">23.7. Assigning quotas per project\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can assign quotas per project.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tProject quota is enabled on your file system.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAdd the project-controlled directories to \u003Ccode class=\"literal\">/etc/projects\u003C/code>. For example, the following adds the \u003Ccode class=\"literal\">/var/log\u003C/code> path with a unique ID of 11 to \u003Ccode class=\"literal\">/etc/projects\u003C/code>. Your project ID can be any numerical value mapped to your project.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># echo 11:/var/log &gt;&gt; /etc/projects\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAdd project names to \u003Ccode class=\"literal\">/etc/projid\u003C/code> to map project IDs to project names. For example, the following associates a project called \u003Ccode class=\"literal\">Logs\u003C/code> with the project ID of 11 as defined in the previous step.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># echo Logs:11 &gt;&gt; /etc/projid\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tSet the desired limits:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># edquota -P 11\u003C/pre>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\tYou can choose the project either by its project ID (\u003Ccode class=\"literal\">11\u003C/code> in this case), or by its name (\u003Ccode class=\"literal\">Logs\u003C/code> in this case).\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tUsing \u003Ccode class=\"literal\">quotaon\u003C/code>, enable quota enforcement:\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tSee \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_file_systems/limiting-storage-space-usage-on-ext4-with-quotas_managing-file-systems#enabling-quota-enforcement_limiting-storage-space-usage-on-ext4-with-quotas\">Enabling quota enforcement\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify that the project quota is set:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># quota -vP 11\u003C/pre>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\tYou can verify either by the project ID, or by the project name.\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">edquota(8)\u003C/code>, \u003Ccode class=\"literal\">projid(5)\u003C/code>, and \u003Ccode class=\"literal\">projects(5)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"setting-the-grace-period-for-soft-limits_limiting-storage-space-usage-on-ext4-with-quotas\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">23.8. Setting the grace period for soft limits\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tIf a given quota has soft limits, you can edit the grace period, which is the amount of time for which a soft limit can be exceeded. You can set the grace period for users, groups, or projects.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEdit the grace period:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># edquota -t\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tWhile other \u003Ccode class=\"literal\">edquota\u003C/code> commands operate on quotas for a particular user, group, or project, the \u003Ccode class=\"literal\">-t\u003C/code> option operates on every file system with quotas enabled.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">edquota(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"turning-file-system-quotas-off_limiting-storage-space-usage-on-ext4-with-quotas\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">23.9. Turning file system quotas off\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tUse \u003Ccode class=\"literal\">quotaoff\u003C/code> to turn disk quota enforcement off on the specified file systems. Quota accounting stays enabled after executing this command.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo turn all user and group quotas off:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># quotaoff -vaugP\u003C/pre>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tIf neither of the \u003Ccode class=\"literal\">-u\u003C/code>, \u003Ccode class=\"literal\">-g\u003C/code>, or \u003Ccode class=\"literal\">-P\u003C/code> options are specified, only the user quotas are disabled.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tIf only \u003Ccode class=\"literal\">-g\u003C/code> option is specified, only group quotas are disabled.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tIf only \u003Ccode class=\"literal\">-P\u003C/code> option is specified, only project quotas are disabled.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">-v\u003C/code> switch causes verbose status information to display as the command executes.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">quotaoff(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"reporting-on-disk-quotas_limiting-storage-space-usage-on-ext4-with-quotas\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">23.10. Reporting on disk quotas\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tCreate a disk quota report by using the \u003Ccode class=\"literal\">repquota\u003C/code> utility.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRun the \u003Ccode class=\"literal\">repquota\u003C/code> command:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># repquota\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor example, the command \u003Ccode class=\"literal\">repquota /dev/sda\u003C/code> produces this output:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">*** Report for user quotas on device /dev/sda\nBlock grace time: 7days; Inode grace time: 7days\n\t\t\tBlock limits\t\t\tFile limits\nUser\t\tused\tsoft\thard\tgrace\tused\tsoft\thard\tgrace\n----------------------------------------------------------------------\nroot      --      36       0       0              4     0     0\nkristin   --     540       0       0            125     0     0\ntestuser  --  440400  500000  550000          37418     0     0\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tView the disk usage report for all quota-enabled file systems:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># repquota -augP\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cp>\n\t\t\t\tThe \u003Ccode class=\"literal\">--\u003C/code> symbol displayed after each user determines whether the block or inode limits have been exceeded. If either soft limit is exceeded, a \u003Ccode class=\"literal\">+\u003C/code> character appears in place of the corresponding \u003Ccode class=\"literal\">-\u003C/code> character. The first \u003Ccode class=\"literal\">-\u003C/code> character represents the block limit, and the second represents the inode limit.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe \u003Ccode class=\"literal\">grace\u003C/code> columns are normally blank. If a soft limit has been exceeded, the column contains a time specification equal to the amount of time remaining on the grace period. If the grace period has expired, \u003Ccode class=\"literal\">none\u003C/code> appears in its place.\n\t\t\t\u003C/p>\u003Cdiv class=\"_additional-resources _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cp>\n\t\t\t\t\tThe \u003Ccode class=\"literal\">repquota(8)\u003C/code> man page for more information.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"discarding-unused-blocks_managing-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 24. Discarding unused blocks\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tYou can perform or schedule discard operations on block devices that support them. The block discard operation communicates to the underlying storage which filesystem blocks are no longer in use by the mounted filesystem. Block discard operations allow SSDs to optimize garbage collection routines, and they can inform thinly-provisioned storage to repurpose unused physical blocks.\n\t\t\u003C/p>\u003Ch4 id=\"requirements\">Requirements\u003C/h4>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\tThe block device underlying the file system must support physical discard operations.\n\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\tPhysical discard operations are supported if the value in the \u003Ccode class=\"literal filename\">/sys/block/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">&lt;device&gt;\u003C/span>\u003C/em>\u003C/span>/queue/discard_max_bytes\u003C/code> file is not zero.\n\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003Csection class=\"section\" id=\"types-of-block-discard-operations_discarding-unused-blocks\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">24.1. Types of block discard operations\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can run discard operations using different methods:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">Batch discard\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tIs triggered explicitly by the user and discards all unused blocks in the selected file systems.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Online discard\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tIs specified at mount time and triggers in real time without user intervention. Online discard operations discard only blocks that are transitioning from the \u003Ccode class=\"literal\">used\u003C/code> to the \u003Ccode class=\"literal\">free\u003C/code> state.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Periodic discard\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tAre batch operations that are run regularly by a \u003Ccode class=\"literal\">systemd\u003C/code> service.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cp>\n\t\t\t\tAll types are supported by the XFS and ext4 file systems.\n\t\t\t\u003C/p>\u003Ch5 id=\"recommendations_2\">Recommendations\u003C/h5>\u003Cp>\n\t\t\t\tRed Hat recommends that you use batch or periodic discard.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tUse online discard only if:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tthe system’s workload is such that batch discard is not feasible, or\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tonline discard operations are necessary to maintain performance.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"performing-batch-block-discard_discarding-unused-blocks\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">24.2. Performing batch block discard\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can perform a batch block discard operation to discard unused blocks on a mounted file system.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe file system is mounted.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe block device underlying the file system supports physical discard operations.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tUse the \u003Ccode class=\"literal\">fstrim\u003C/code> utility:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tTo perform discard only on a selected file system, use:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># fstrim \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">mount-point\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tTo perform discard on all mounted file systems, use:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># fstrim --all\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tIf you execute the \u003Ccode class=\"literal\">fstrim\u003C/code> command on:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\ta device that does not support discard operations, or\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\ta logical device (LVM or MD) composed of multiple devices, where any one of the device does not support discard operations,\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tthe following message displays:\n\t\t\t\u003C/p>\u003Cpre class=\"screen\"># fstrim \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">/mnt/non_discard\u003C/span>\u003C/em>\u003C/span>\n\nfstrim: \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">/mnt/non_discard\u003C/span>\u003C/em>\u003C/span>: the discard operation is not supported\u003C/pre>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">fstrim(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"enabling-online-block-discard_discarding-unused-blocks\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">24.3. Enabling online block discard\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can perform online block discard operations to automatically discard unused blocks on all supported file systems.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnable online discard at mount time:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tWhen mounting a file system manually, add the \u003Ccode class=\"literal option\">-o discard\u003C/code> mount option:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount -o discard \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">device\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">mount-point\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tWhen mounting a file system persistently, add the \u003Ccode class=\"literal option\">discard\u003C/code> option to the mount entry in the \u003Ccode class=\"literal filename\">/etc/fstab\u003C/code> file.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">mount(8)\u003C/code> and \u003Ccode class=\"literal\">fstab(5)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"enabling-periodic-block-discard_discarding-unused-blocks\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">24.4. Enabling periodic block discard\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can enable a \u003Ccode class=\"literal\">systemd\u003C/code> timer to regularly discard unused blocks on all supported file systems.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnable and start the \u003Ccode class=\"literal\">systemd\u003C/code> timer:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl enable --now fstrim.timer\u003C/strong>\u003C/span>\nCreated symlink /etc/systemd/system/timers.target.wants/fstrim.timer → /usr/lib/systemd/system/fstrim.timer.\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify the status of the timer:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl status fstrim.timer\u003C/strong>\u003C/span>\nfstrim.timer - Discard unused blocks once a week\n   Loaded: loaded (/usr/lib/systemd/system/fstrim.timer; enabled; vendor preset: disabled)\n   Active: active (waiting) since Wed 2023-05-17 13:24:41 CEST; 3min 15s ago\n  Trigger: Mon 2023-05-22 01:20:46 CEST; 4 days left\n     Docs: man:fstrim\n\nMay 17 13:24:41 localhost.localdomain systemd[1]: Started Discard unused blocks once a week.\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"setting-up-stratis-file-systems_managing-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 25. Setting up Stratis file systems\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\tStratis runs as a service to manage pools of physical storage devices, simplifying local storage management with ease of use while helping you set up and manage complex storage configurations.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"the-purpose-and-features-of-stratis_setting-up-stratis-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">25.1. What is Stratis\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tStratis is a local storage-management solution for Linux. It is focused on simplicity and ease of use, and gives you access to advanced storage features.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tStratis makes the following activities easier:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tInitial configuration of storage\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tMaking changes later\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tUsing advanced storage features\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tStratis is a local storage management system that supports advanced storage features. The central concept of Stratis is a storage \u003Cspan class=\"emphasis\">\u003Cem>pool\u003C/em>\u003C/span>. This pool is created from one or more local disks or partitions, and file systems are created from the pool.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe pool enables many useful features, such as:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tFile system snapshots\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThin provisioning\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tTiering\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tEncryption\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://stratis-storage.github.io/\">Stratis website\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"components-of-a-stratis-volume_setting-up-stratis-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">25.2. Components of a Stratis volume\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tLearn about the components that comprise a Stratis volume.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tExternally, Stratis presents the following volume components in the command-line interface and the API:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">blockdev\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tBlock devices, such as a disk or a disk partition.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pool\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tComposed of one or more block devices.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tA pool has a fixed total size, equal to the size of the block devices.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe pool contains most Stratis layers, such as the non-volatile data cache using the \u003Ccode class=\"literal\">dm-cache\u003C/code> target.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tStratis creates a \u003Ccode class=\"literal filename\">/dev/stratis/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span>/\u003C/code> directory for each pool. This directory contains links to devices that represent Stratis file systems in the pool.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">filesystem\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tEach pool can contain one or more file systems, which store files.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFile systems are thinly provisioned and do not have a fixed total size. The actual size of a file system grows with the data stored on it. If the size of the data approaches the virtual size of the file system, Stratis grows the thin volume and the file system automatically.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe file systems are formatted with XFS.\n\t\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\t\tStratis tracks information about file systems created using Stratis that XFS is not aware of, and changes made using XFS do not automatically create updates in Stratis. Users must not reformat or reconfigure XFS file systems that are managed by Stratis.\n\t\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tStratis creates links to file systems at the \u003Ccode class=\"literal filename\">/dev/stratis/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span>/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-fs\u003C/span>\u003C/em>\u003C/span>\u003C/code> path.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003C/dl>\u003C/div>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tStratis uses many Device Mapper devices, which show up in \u003Ccode class=\"literal\">dmsetup\u003C/code> listings and the \u003Ccode class=\"literal filename\">/proc/partitions\u003C/code> file. Similarly, the \u003Ccode class=\"literal\">lsblk\u003C/code> command output reflects the internal workings and layers of Stratis.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/section>\u003Csection class=\"section\" id=\"block-devices-usable-with-stratis_setting-up-stratis-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">25.3. Block devices usable with Stratis\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tStorage devices that can be used with Stratis.\n\t\t\t\u003C/p>\u003Ch5 id=\"supported_devices\">Supported devices\u003C/h5>\u003Cp>\n\t\t\t\tStratis pools have been tested to work on these types of block devices:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tLUKS\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tLVM logical volumes\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tMD RAID\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tDM Multipath\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tiSCSI\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tHDDs and SSDs\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tNVMe devices\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Ch5 id=\"unsupported_devices\">Unsupported devices\u003C/h5>\u003Cp>\n\t\t\t\tBecause Stratis contains a thin-provisioning layer, Red Hat does not recommend placing a Stratis pool on block devices that are already thinly-provisioned.\n\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"installing-stratis_setting-up-stratis-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">25.4. Installing Stratis\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tInstall the required packages for Stratis.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInstall packages that provide the Stratis service and command-line utilities:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf install stratisd stratis-cli\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify that the \u003Ccode class=\"literal\">stratisd\u003C/code> service is enabled:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># systemctl enable --now stratisd\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"create-unencrypted-stratis-pool_setting-up-stratis-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">25.5. Creating an unencrypted Stratis pool\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can create an unencrypted Stratis pool from one or more block devices.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tStratis is installed. For more information, see \u003Ca class=\"link\" href=\"#installing-stratis_setting-up-stratis-file-systems\" title=\"25.4. Installing Stratis\">Installing Stratis\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">stratisd\u003C/code> service is running.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe block devices on which you are creating a Stratis pool are not in use and are not mounted.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tEach block device on which you are creating a Stratis pool is at least 1 GB.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tOn the IBM Z architecture, the \u003Ccode class=\"literal\">/dev/dasd*\u003C/code> block devices must be partitioned. Use the partition device for creating the Stratis pool.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tFor information about partitioning DASD devices, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html-single/interactively_installing_rhel_over_the_network/index#configuring-a-linux-instance-on-ibm-z_preparing-a-rhel-installation-on-64-bit-ibm-z\">Configuring a Linux instance on IBM Z\u003C/a>\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tYou cannot encrypt an unencrypted Stratis pool.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tErase any file system, partition table, or RAID signatures that exist on each block device that you want to use in the Stratis pool:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># wipefs --all \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">block-device\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\twhere \u003Ccode class=\"literal replaceable\">\u003Cspan class=\"emphasis\">\u003Cem>block-device\u003C/em>\u003C/span>\u003C/code> is the path to the block device; for example, \u003Ccode class=\"literal\">/dev/sdb\u003C/code>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate the new unencrypted Stratis pool on the selected block device:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis pool create \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">block-device\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\twhere \u003Ccode class=\"literal replaceable\">\u003Cspan class=\"emphasis\">\u003Cem>block-device\u003C/em>\u003C/span>\u003C/code> is the path to an empty or wiped block device.\n\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\tSpecify multiple block devices on a single line:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis pool create \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">block-device-1\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">block-device-2\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/div>\u003C/rh-alert>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify that the new Stratis pool was created:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis pool list\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"creating-an-unencrypted-stratis-pool-using-the-web-console_setting-up-stratis-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">25.6. Creating an unencrypted Stratis pool by using the web console\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can use the web console to create an unencrypted Stratis pool from one or more block devices.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tYou have installed the RHEL 9 web console.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor instructions, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console\">Installing and enabling the web console\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">stratisd\u003C/code> service is running.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe block devices on which you are creating a Stratis pool are not in use and are not mounted.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tEach block device on which you are creating a Stratis pool is at least 1 GB.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tYou cannot encrypt an unencrypted Stratis pool after it is created.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tLog in to the RHEL 9 web console.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor details, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#logging-in-to-the-web-console_getting-started-with-the-rhel-9-web-console\">Logging in to the web console\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick \u003Cspan class=\"guibutton\">Storage\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Storage\u003C/strong>\u003C/span> table, click the menu button.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFrom the drop-down menu, select \u003Cspan class=\"strong strong\">\u003Cstrong>Create Stratis pool\u003C/strong>\u003C/span>.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/90ecf9cb494b94831c8f73565fe7be13/cockpit-adding-volume-groups-create-stratis.png\" alt=\"Image displaying the available options in the Storage table drop-down menu. Selecting Create Stratis pool.\"/>\u003C/span>\n\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Create Stratis pool\u003C/strong>\u003C/span> dialog box, enter a name for the Stratis pool.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/f436feb6682e0d109368415b13426e87/cockpit-create-stratis-pool.png\" alt=\"Image displaying the Create Stratis pool dialog box.\"/>\u003C/span>\n\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tSelect the \u003Cspan class=\"strong strong\">\u003Cstrong>Block devices\u003C/strong>\u003C/span> from which you want to create the Stratis pool.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tOptional: If you want to specify the maximum size for each file system that is created in pool, select \u003Cspan class=\"strong strong\">\u003Cstrong>Manage filesystem sizes\u003C/strong>\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick \u003Cspan class=\"guibutton\">Create\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tGo to the \u003Cspan class=\"strong strong\">\u003Cstrong>Storage\u003C/strong>\u003C/span> section and verify that you can see the new Stratis pool in the \u003Cspan class=\"strong strong\">\u003Cstrong>Devices\u003C/strong>\u003C/span> table.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"create-encrypted-stratis-pool_setting-up-stratis-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">25.7. Creating an encrypted Stratis pool\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tTo secure your data, you can create an encrypted Stratis pool from one or more block devices.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tWhen you create an encrypted Stratis pool, the kernel keyring is used as the primary encryption mechanism. After subsequent system reboots this kernel keyring is used to unlock the encrypted Stratis pool.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tWhen creating an encrypted Stratis pool from one or more block devices, note the following:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tEach block device is encrypted using the \u003Ccode class=\"literal\">cryptsetup\u003C/code> library and implements the \u003Ccode class=\"literal\">LUKS2\u003C/code> format.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tEach Stratis pool can either have a unique key or share the same key with other pools. These keys are stored in the kernel keyring.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe block devices that comprise a Stratis pool must be either all encrypted or all unencrypted. It is not possible to have both encrypted and unencrypted block devices in the same Stratis pool.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tBlock devices added to the data tier of an encrypted Stratis pool are automatically encrypted.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tStratis v2.1.0 or later is installed. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems\">Installing Stratis\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">stratisd\u003C/code> service is running.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe block devices on which you are creating a Stratis pool are not in use and are not mounted.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe block devices on which you are creating a Stratis pool are at least 1GB in size each.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tOn the IBM Z architecture, the \u003Ccode class=\"literal\">/dev/dasd*\u003C/code> block devices must be partitioned. Use the partition in the Stratis pool.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tFor information about partitioning DASD devices, see link:\u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html-single/interactively_installing_rhel_over_the_network/index#configuring-a-linux-instance-on-ibm-z_preparing-a-rhel-installation-on-64-bit-ibm-z\">Configuring a Linux instance on IBM Z\u003C/a>.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tErase any file system, partition table, or RAID signatures that exist on each block device that you want to use in the Stratis pool:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># wipefs --all \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">block-device\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\twhere \u003Ccode class=\"literal replaceable\">\u003Cspan class=\"emphasis\">\u003Cem>block-device\u003C/em>\u003C/span>\u003C/code> is the path to the block device; for example, \u003Ccode class=\"literal\">/dev/sdb\u003C/code>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIf you have not created a key set already, run the following command and follow the prompts to create a key set to use for the encryption.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis key set --capture-key \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">key-description\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\twhere \u003Ccode class=\"literal replaceable\">\u003Cspan class=\"emphasis\">\u003Cem>key-description\u003C/em>\u003C/span>\u003C/code> is a reference to the key that gets created in the kernel keyring.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate the encrypted Stratis pool and specify the key description to use for the encryption. You can also specify the key path using the \u003Ccode class=\"literal\">--keyfile-path\u003C/code> option instead of using the \u003Ccode class=\"literal replaceable\">\u003Cspan class=\"emphasis\">\u003Cem>key-description\u003C/em>\u003C/span>\u003C/code> option.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis pool create --key-desc \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">key-description\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">block-device\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\twhere\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>key-description\u003C/em>\u003C/span>\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\tReferences the key that exists in the kernel keyring, which you created in the previous step.\n\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>my-pool\u003C/em>\u003C/span>\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\tSpecifies the name of the new Stratis pool.\n\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>block-device\u003C/em>\u003C/span>\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tSpecifies the path to an empty or wiped block device.\n\t\t\t\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\t\t\t\tSpecify multiple block devices on a single line:\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis pool create --key-desc \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">key-description\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">block-device-1\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">block-device-2\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/div>\u003C/rh-alert>\u003C/dd>\u003C/dl>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify that the new Stratis pool was created:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis pool list\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"creating-an-encrypted-stratis-pool-using-the-web-console_setting-up-stratis-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">25.8. Creating an encrypted Stratis pool by using the web console\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tTo secure your data, you can use the web console to create an encrypted Stratis pool from one or more block devices.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tWhen creating an encrypted Stratis pool from one or more block devices, note the following:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tEach block device is encrypted using the cryptsetup library and implements the LUKS2 format.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tEach Stratis pool can either have a unique key or share the same key with other pools. These keys are stored in the kernel keyring.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe block devices that comprise a Stratis pool must be either all encrypted or all unencrypted. It is not possible to have both encrypted and unencrypted block devices in the same Stratis pool.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tBlock devices added to the data tier of an encrypted Stratis pool are automatically encrypted.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tYou have installed the RHEL 9 web console.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor instructions, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console\">Installing and enabling the web console\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tStratis v2.1.0 or later is installed.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">stratisd\u003C/code> service is running.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe block devices on which you are creating a Stratis pool are not in use and are not mounted.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tEach block device on which you are creating a Stratis pool is at least 1 GB.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tLog in to the RHEL 9 web console.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor details, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#logging-in-to-the-web-console_getting-started-with-the-rhel-9-web-console\">Logging in to the web console\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick \u003Cspan class=\"guibutton\">Storage\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Storage\u003C/strong>\u003C/span> table, click the menu button.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tFrom the drop-down menu, select \u003Cspan class=\"strong strong\">\u003Cstrong>Create Stratis pool\u003C/strong>\u003C/span>. \n\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/90ecf9cb494b94831c8f73565fe7be13/cockpit-adding-volume-groups-create-stratis.png\" alt=\"Image displaying the available options in the Storage table drop-down menu. Selecting Create Stratis pool.\"/>\u003C/span>\n\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Create Stratis pool\u003C/strong>\u003C/span> dialog box, enter a name for the Stratis pool.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/f436feb6682e0d109368415b13426e87/cockpit-create-stratis-pool.png\" alt=\"Image displaying the Create Stratis pool dialog box.\"/>\u003C/span>\n\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tSelect the \u003Cspan class=\"strong strong\">\u003Cstrong>Block devices\u003C/strong>\u003C/span> from which you want to create the Stratis pool.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tSelect the type of encryption, you can use a passphrase, a Tang keyserver, or both:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tPassphrase:\n\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"i\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\tEnter a passphrase.\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\tConfirm the passphrase\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tTang keyserver:\n\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"i\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\tEnter the keyserver address. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/security_hardening/configuring-automated-unlocking-of-encrypted-volumes-using-policy-based-decryption_security-hardening#deploying-a-tang-server-with-selinux-in-enforcing-mode_configuring-automated-unlocking-of-encrypted-volumes-using-policy-based-decryption\">Deploying a Tang server with SELinux in enforcing mode\u003C/a>.\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tOptional: If you want to specify the maximum size for each file system that is created in pool, select \u003Cspan class=\"strong strong\">\u003Cstrong>Manage filesystem sizes\u003C/strong>\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick \u003Cspan class=\"guibutton\">Create\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tGo to the \u003Cspan class=\"strong strong\">\u003Cstrong>Storage\u003C/strong>\u003C/span> section and verify that you can see the new Stratis pool in the \u003Cspan class=\"strong strong\">\u003Cstrong>Devices\u003C/strong>\u003C/span> table.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"renaming-a-stratis-pool-using-the-web-console_setting-up-stratis-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">25.9. Renaming a Stratis pool by using the web console\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can use the web console to rename an existing Stratis pool.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tYou have installed the RHEL 9 web console.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor instructions, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console\">Installing and enabling the web console\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tStratis is installed.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe web console detects and installs Stratis by default. However, for manually installing Stratis, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems\">Installing Stratis\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">stratisd\u003C/code> service is running.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tA Stratis pool is created.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tLog in to the RHEL 9 web console.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick \u003Cspan class=\"guibutton\">Storage\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Storage\u003C/strong>\u003C/span> table, click the Stratis pool you want to rename.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOn the \u003Cspan class=\"strong strong\">\u003Cstrong>Stratis pool\u003C/strong>\u003C/span> page, click \u003Cspan class=\"guibutton\">edit\u003C/span> next to the \u003Cspan class=\"strong strong\">\u003Cstrong>Name\u003C/strong>\u003C/span> field.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/7cbbd0667e9e4dad03191e3a1bd46614/cockpit-view-stratis-pool.png\" alt=\"Image displaying the Stratis pool page.\"/>\u003C/span>\n\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Rename Stratis pool\u003C/strong>\u003C/span> dialog box, enter a new name.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick \u003Cspan class=\"guibutton\">Rename\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"proc_setting-overprovisioning-mode-in-stratis-fs_setting-up-stratis-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">25.10. Setting overprovisioning mode in Stratis filesystem\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tA storage stack can reach a state of overprovision. If the file system size becomes bigger than the pool backing it, the pool becomes full. To prevent this, disable overprovisioning, which ensures that the size of all filesystems on the pool does not exceed the available physical storage provided by the pool. If you use Stratis for critical applications or the root filesystem, this mode prevents certain failure cases.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tIf you enable overprovisioning, an API signal notifies you when your storage has been fully allocated. The notification serves as a warning to the user to inform them that when all the remaining pool space fills up, Stratis has no space left to extend to.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tStratis is installed. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems\">Installing Stratis\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"formalpara\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cp>\n\t\t\t\t\tTo set up the pool correctly, you have two possibilities:\n\t\t\t\t\u003C/p>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a pool from one or more block devices:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis pool create --no-overprovision \u003Cspan class=\"emphasis\">\u003Cem>pool-name\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>/dev/sdb\u003C/em>\u003C/span>\u003C/pre>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tBy using the \u003Ccode class=\"literal\">--no-overprovision\u003C/code> option, the pool cannot allocate more logical space than actual available physical space.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tSet overprovisioning mode in the existing pool:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis pool overprovision \u003Cspan class=\"emphasis\">\u003Cem>pool-name\u003C/em>\u003C/span> &lt;yes|no&gt;\u003C/pre>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tIf set to \"yes\", you enable overprovisioning to the pool. This means that the sum of the logical sizes of the Stratis filesystems, supported by the pool, can exceed the amount of available data space.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRun the following to view the full list of Stratis pools:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis pool list\n\nName          Total Physical                    Properties     UUID                                   Alerts\n\u003Cspan class=\"emphasis\">\u003Cem>pool-name\u003C/em>\u003C/span>     1.42 TiB / 23.96 MiB / 1.42 TiB   ~Ca,~Cr,~Op    cb7cb4d8-9322-4ac4-a6fd-eb7ae9e1e540\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tCheck if there is an indication of the pool overprovisioning mode flag in the \u003Ccode class=\"literal\">stratis pool list\u003C/code> output. The \" ~ \" is a math symbol for \"NOT\", so \u003Ccode class=\"literal\">~Op\u003C/code> means no-overprovisioning.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOptional: Run the following to check overprovisioning on a specific pool:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis pool overprovision \u003Cspan class=\"emphasis\">\u003Cem>pool-name\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>yes\u003C/em>\u003C/span>\n\n# stratis pool list\n\nName          Total Physical                    Properties     UUID                                   Alerts\n\u003Cspan class=\"emphasis\">\u003Cem>pool-name\u003C/em>\u003C/span>     1.42 TiB / 23.96 MiB / 1.42 TiB   ~Ca,~Cr,~Op    cb7cb4d8-9322-4ac4-a6fd-eb7ae9e1e540\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://stratis-storage.github.io/\">The \u003Cspan class=\"emphasis\">\u003Cem>Stratis Storage\u003C/em>\u003C/span> webpage\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"bind-stratis-pool-nbde_setting-up-stratis-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">25.11. Binding a Stratis pool to NBDE\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tBinding an encrypted Stratis pool to Network Bound Disk Encryption (NBDE) requires a Tang server. When a system containing the Stratis pool reboots, it connects with the Tang server to automatically unlock the encrypted pool without you having to provide the kernel keyring description.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tBinding a Stratis pool to a supplementary Clevis encryption mechanism does not remove the primary kernel keyring encryption.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tStratis v2.3.0 or later is installed. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems\">Installing Stratis\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">stratisd\u003C/code> service is running.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have created an encrypted Stratis pool, and you have the key description of the key that was used for the encryption. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#create-encrypted-stratis-pool_setting-up-stratis-file-systems\">Creating an encrypted Stratis pool\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou can connect to the Tang server. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/security_hardening/configuring-automated-unlocking-of-encrypted-volumes-using-policy-based-decryption_security-hardening#deploying-a-tang-server-with-selinux-in-enforcing-mode_configuring-automated-unlocking-of-encrypted-volumes-using-policy-based-decryption\">Deploying a Tang server with SELinux in enforcing mode\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tBind an encrypted Stratis pool to NBDE:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis pool bind nbde --trust-url \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">tang-server\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\twhere\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>my-pool\u003C/em>\u003C/span>\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\tSpecifies the name of the encrypted Stratis pool.\n\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>tang-server\u003C/em>\u003C/span>\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\tSpecifies the IP address or URL of the Tang server.\n\t\t\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/security_hardening/configuring-automated-unlocking-of-encrypted-volumes-using-policy-based-decryption_security-hardening\">Configuring automated unlocking of encrypted volumes using policy-based decryption\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"bind-stratis-pool-tpm_setting-up-stratis-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">25.12. Binding a Stratis pool to TPM\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tWhen you bind an encrypted Stratis pool to the Trusted Platform Module (TPM) 2.0, the system containing the pool reboots, and the pool is automatically unlocked without you having to provide the kernel keyring description.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tStratis v2.3.0 or later is installed. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems\">Installing Stratis\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">stratisd\u003C/code> service is running.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have created an encrypted Stratis pool. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#create-encrypted-stratis-pool_setting-up-stratis-file-systems\">Creating an encrypted Stratis pool\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tBind an encrypted Stratis pool to TPM:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis pool bind tpm \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">key-description\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\twhere\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>my-pool\u003C/em>\u003C/span>\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\tSpecifies the name of the encrypted Stratis pool.\n\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>key-description\u003C/em>\u003C/span>\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\tReferences the key that exists in the kernel keyring, which was generated when you created the encrypted Stratis pool.\n\t\t\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"unlock-encrypted-stratis-pool-keyring_setting-up-stratis-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">25.13. Unlocking an encrypted Stratis pool with kernel keyring\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tAfter a system reboot, your encrypted Stratis pool or the block devices that comprise it might not be visible. You can unlock the pool using the kernel keyring that was used to encrypt the pool.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tStratis v2.1.0 is installed. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems\">Installing Stratis\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">stratisd\u003C/code> service is running.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have created an encrypted Stratis pool. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#create-encrypted-stratis-pool_setting-up-stratis-file-systems\">Creating an encrypted Stratis pool\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRe-create the key set using the same key description that was used previously:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis key set --capture-key \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">key-description\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\twhere \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">key-description\u003C/span>\u003C/em>\u003C/span> references the key that exists in the kernel keyring, which was generated when you created the encrypted Stratis pool.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify that the Stratis pool is visible:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis pool list\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"unbind-encrypted-stratis-pool-from-supplementary-encryption_setting-up-stratis-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">25.14. Unbinding a Stratis pool from supplementary encryption\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tWhen you unbind an encrypted Stratis pool from a supported supplementary encryption mechanism, the primary kernel keyring encryption remains in place. This is not true for pools that are created with Clevis encryption from the start.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tStratis v2.3.0 or later is installed on your system. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems\">Installing Stratis\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have created an encrypted Stratis pool. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#create-encrypted-stratis-pool_setting-up-stratis-file-systems\">Creating an encrypted Stratis pool\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe encrypted Stratis pool is bound to a supported supplementary encryption mechanism.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tUnbind an encrypted Stratis pool from a supplementary encryption mechanism:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis pool unbind clevis \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\twhere\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>my-pool\u003C/em>\u003C/span>\u003C/code> specifies the name of the Stratis pool you want to unbind.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#bind-stratis-pool-nbde_setting-up-stratis-file-systems\">Binding an encrypted Stratis pool to NBDE\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#bind-stratis-pool-tpm_setting-up-stratis-file-systems\">Binding an encrypted Stratis pool to TPM\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"proc_starting-and-stopping-stratis-pool_setting-up-stratis-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">25.15. Starting and stopping Stratis pool\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tYou can start and stop Stratis pools. This gives you the option to dissasemble or bring down all the objects that were used to construct the pool, such as filesystems, cache devices, thin pool, and encrypted devices. Note that if the pool actively uses any device or filesystem, it might issue a warning and not be able to stop.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe stopped state is recorded in the pool’s metadata. These pools do not start on the following boot, until the pool receives a start command.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tStratis is installed. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems\">Installing Stratis\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">stratisd\u003C/code> service is running.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have created either an unencrypted or an encrypted Stratis pool. See \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#create-unencrypted-stratis-pool_setting-up-stratis-file-systems\">Creating an unencrypted Stratis pool\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tor \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#create-encrypted-stratis-pool_setting-up-stratis-file-systems\">Creating an encrypted Stratis pool\u003C/a>.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tUse the following command to start the Stratis pool. The \u003Ccode class=\"literal\">--unlock-method\u003C/code> option specifies the method of unlocking the pool if it is encrypted:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis pool start \u003Cspan class=\"emphasis\">\u003Cem>pool-uuid\u003C/em>\u003C/span> --unlock-method &lt;keyring|clevis&gt;\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAlternatively, use the following command to stop the Stratis pool. This tears down the storage stack but leaves all metadata intact:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis pool stop \u003Cspan class=\"emphasis\">\u003Cem>pool-name\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tUse the following command to list all pools on the system:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis pool list\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tUse the following command to list all not previously started pools. If the UUID is specified, the command prints detailed information about the pool corresponding to the UUID:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis pool list --stopped --uuid \u003Cspan class=\"emphasis\">\u003Cem>UUID\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"creating-a-stratis-file-system_setting-up-stratis-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">25.16. Creating a Stratis file system\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tCreate a Stratis file system on an existing Stratis pool.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tStratis is installed. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems\">Installing Stratis\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">stratisd\u003C/code> service is running.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have created a Stratis pool. See \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#create-unencrypted-stratis-pool_setting-up-stratis-file-systems\">Creating an unencrypted Stratis pool\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tor \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#create-encrypted-stratis-pool_setting-up-stratis-file-systems\">Creating an encrypted Stratis pool\u003C/a>.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo create a Stratis file system on a pool, use:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis filesystem create --size \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">number-and-unit\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-fs\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\twhere\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>number-and-unit\u003C/em>\u003C/span>\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\tSpecifies the size of a file system. The specification format must follow the standard size specification format for input, that is B, KiB, MiB, GiB, TiB or PiB.\n\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>my-pool\u003C/em>\u003C/span>\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\tSpecifies the name of the Stratis pool.\n\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>my-fs\u003C/em>\u003C/span>\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tSpecifies an arbitrary name for the file system.\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tFor example:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"example\" id=\"idm139822450275632\">\u003Cp class=\"title\">\u003Cstrong>Example 25.1. Creating a Stratis file system\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cpre class=\"screen\"># stratis filesystem create --size 10GiB pool1 filesystem1\u003C/pre>\u003C/div>\u003C/div>\u003C/dd>\u003C/dl>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tList file systems within the pool to check if the Stratis filesystem is created:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis fs list \u003Cspan class=\"emphasis\">\u003Cem>my-pool\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/managing_file_systems/index#mounting-a-stratis-file-system_setting-up-stratis-file-systems\">Mounting a Stratis file system\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"creating-a-file-system-on-a-stratis-pool-using-the-web-console_setting-up-stratis-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">25.17. Creating a file system on a Stratis pool by using the web console\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can use the web console to create a file system on an existing Stratis pool.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tYou have installed the RHEL 9 web console.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor instructions, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console\">Installing and enabling the web console\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">stratisd\u003C/code> service is running.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tA Stratis pool is created.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tLog in to the RHEL 9 web console.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor details, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#logging-in-to-the-web-console_getting-started-with-the-rhel-9-web-console\">Logging in to the web console\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick \u003Cspan class=\"guibutton\">Storage\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick the Stratis pool on which you want to create a file system.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOn the \u003Cspan class=\"strong strong\">\u003Cstrong>Stratis pool\u003C/strong>\u003C/span> page, scroll to the \u003Cspan class=\"strong strong\">\u003Cstrong>Stratis filesystems\u003C/strong>\u003C/span> section and click \u003Cspan class=\"guibutton\">Create new filesystem\u003C/span>.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/7cbbd0667e9e4dad03191e3a1bd46614/cockpit-view-stratis-pool.png\" alt=\"Image displaying the Stratis pool page.\"/>\u003C/span>\n\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Create filesystem\u003C/strong>\u003C/span> dialog box, enter a \u003Cspan class=\"strong strong\">\u003Cstrong>Name\u003C/strong>\u003C/span> for the file system.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/07fbccdba02bded4adc1d642baab4f53/cockpit-create-stratis-fs.png\" alt=\"Image displaying the create Stratis file system dialog box.\"/>\u003C/span>\n\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tEnter the \u003Cspan class=\"strong strong\">\u003Cstrong>Mount point\u003C/strong>\u003C/span> for the file system.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tSelect the \u003Cspan class=\"strong strong\">\u003Cstrong>Mount option\u003C/strong>\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>At boot\u003C/strong>\u003C/span> drop-down menu, select when you want to mount your file system.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate the file system:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tIf you want to create and mount the file system, click \u003Cspan class=\"guibutton\">Create and mount\u003C/span>.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tIf you want to only create the file system, click \u003Cspan class=\"guibutton\">Create only\u003C/span>.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe new file system is visible on the \u003Cspan class=\"strong strong\">\u003Cstrong>Stratis pool\u003C/strong>\u003C/span> page under the \u003Cspan class=\"strong strong\">\u003Cstrong>Stratis filesystems\u003C/strong>\u003C/span> tab.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"mounting-a-stratis-file-system_setting-up-stratis-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">25.18. Mounting a Stratis file system\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tMount an existing Stratis file system to access the content.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tStratis is installed. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems\">Installing Stratis\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">stratisd\u003C/code> service is running.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have created a Stratis file system. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#creating-a-stratis-file-system_setting-up-stratis-file-systems\">Creating a Stratis filesystem\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo mount the file system, use the entries that Stratis maintains in the \u003Ccode class=\"literal filename\">/dev/stratis/\u003C/code> directory:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount /dev/stratis/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span>/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-fs\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">mount-point\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tThe file system is now mounted on the \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">mount-point\u003C/span>\u003C/em>\u003C/span> directory and ready to use.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#creating-a-stratis-file-system_setting-up-stratis-file-systems\">Creating a Stratis file system\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"persistently-mounting-a-stratis-file-system_setting-up-stratis-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">25.19. Persistently mounting a Stratis file system\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure persistently mounts a Stratis file system so that it is available automatically after booting the system.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tStratis is installed. See \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems\">Installing Stratis\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">stratisd\u003C/code> service is running.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have created a Stratis file system. See \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#creating-a-stratis-file-system_setting-up-stratis-file-systems\">Creating a Stratis filesystem\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tDetermine the UUID attribute of the file system:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ lsblk --output=UUID /dev/stratis/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span>/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-fs\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor example:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"example\" id=\"idm139822453439552\">\u003Cp class=\"title\">\u003Cstrong>Example 25.2. Viewing the UUID of Stratis file system\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cpre class=\"screen\">$ lsblk --output=UUID /dev/stratis/my-pool/fs1\n\nUUID\na1f0b64a-4ebb-4d4e-9543-b1d79f600283\u003C/pre>\u003C/div>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIf the mount point directory does not exist, create it:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mkdir --parents \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">mount-point\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAs root, edit the \u003Ccode class=\"literal filename\">/etc/fstab\u003C/code> file and add a line for the file system, identified by the UUID. Use \u003Ccode class=\"literal\">xfs\u003C/code> as the file system type and add the \u003Ccode class=\"literal\">x-systemd.requires=stratisd.service\u003C/code> option.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor example:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"example\" id=\"idm139822453432448\">\u003Cp class=\"title\">\u003Cstrong>Example 25.3. The /fs1 mount point in /etc/fstab\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cpre class=\"screen\">UUID=a1f0b64a-4ebb-4d4e-9543-b1d79f600283 /fs1 xfs defaults,x-systemd.requires=stratisd.service 0 0\u003C/pre>\u003C/div>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRegenerate mount units so that your system registers the new configuration:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># systemctl daemon-reload\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTry mounting the file system to verify that the configuration works:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">mount-point\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_file_systems/assembly_persistently-mounting-file-systems_managing-file-systems\">Persistently mounting file systems\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"proc_setting-up-non-root-stratis-fs-fstab-systemd_setting-up-stratis-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">25.20. Setting up non-root Stratis filesystems in /etc/fstab using a systemd service\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tYou can manage setting up non-root filesystems in /etc/fstab using a systemd service.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tStratis is installed. See \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_file_systems/setting-up-stratis-file-systems_managing-file-systems#installing-stratis_setting-up-stratis-file-systems\">Installing Stratis\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">stratisd\u003C/code> service is running.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have created a Stratis file system. See \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_file_systems/setting-up-stratis-file-systems_managing-file-systems#creating-a-stratis-file-system_setting-up-stratis-file-systems\">Creating a Stratis filesystem\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor all non-root Stratis filesystems, use:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># /dev/stratis/\u003Cspan class=\"emphasis\">\u003Cem>[STRATIS_SYMLINK]\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>[MOUNT_POINT]\u003C/em>\u003C/span> xfs defaults, x-systemd.requires=stratis-fstab-setup@\u003Cspan class=\"emphasis\">\u003Cem>[POOL_UUID]\u003C/em>\u003C/span>.service,x-systemd.after=stratis-stab-setup@\u003Cspan class=\"emphasis\">\u003Cem>[POOL_UUID]\u003C/em>\u003C/span>.service &lt;dump_value&gt; &lt;fsck_value&gt;\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#assembly_persistently-mounting-file-systems_managing-file-systems\">Persistently mounting file systems\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"extending-a-stratis-volume-with-additional-block-devices_managing-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 26. Extending a Stratis volume with additional block devices\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\tYou can attach additional block devices to a Stratis pool to provide more storage capacity for Stratis file systems.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"components-of-a-stratis-volume_extending-a-stratis-volume-with-additional-block-devices\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">26.1. Components of a Stratis volume\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tLearn about the components that comprise a Stratis volume.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tExternally, Stratis presents the following volume components in the command-line interface and the API:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">blockdev\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tBlock devices, such as a disk or a disk partition.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pool\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tComposed of one or more block devices.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tA pool has a fixed total size, equal to the size of the block devices.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe pool contains most Stratis layers, such as the non-volatile data cache using the \u003Ccode class=\"literal\">dm-cache\u003C/code> target.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tStratis creates a \u003Ccode class=\"literal filename\">/dev/stratis/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span>/\u003C/code> directory for each pool. This directory contains links to devices that represent Stratis file systems in the pool.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">filesystem\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tEach pool can contain one or more file systems, which store files.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFile systems are thinly provisioned and do not have a fixed total size. The actual size of a file system grows with the data stored on it. If the size of the data approaches the virtual size of the file system, Stratis grows the thin volume and the file system automatically.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe file systems are formatted with XFS.\n\t\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\t\tStratis tracks information about file systems created using Stratis that XFS is not aware of, and changes made using XFS do not automatically create updates in Stratis. Users must not reformat or reconfigure XFS file systems that are managed by Stratis.\n\t\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tStratis creates links to file systems at the \u003Ccode class=\"literal filename\">/dev/stratis/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span>/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-fs\u003C/span>\u003C/em>\u003C/span>\u003C/code> path.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003C/dl>\u003C/div>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tStratis uses many Device Mapper devices, which show up in \u003Ccode class=\"literal\">dmsetup\u003C/code> listings and the \u003Ccode class=\"literal filename\">/proc/partitions\u003C/code> file. Similarly, the \u003Ccode class=\"literal\">lsblk\u003C/code> command output reflects the internal workings and layers of Stratis.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/section>\u003Csection class=\"section\" id=\"adding-block-devices-to-a-stratis-pool_extending-a-stratis-volume-with-additional-block-devices\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">26.2. Adding block devices to a Stratis pool\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure adds one or more block devices to a Stratis pool to be usable by Stratis file systems.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tStratis is installed. See \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems\">Installing Stratis\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">stratisd\u003C/code> service is running.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe block devices that you are adding to the Stratis pool are not in use and not mounted.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe block devices that you are adding to the Stratis pool are at least 1 GiB in size each.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo add one or more block devices to the pool, use:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis pool add-data \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">device-1\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">device-2\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">device-n\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">stratis(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"adding-a-block-device-to-a-stratis-pool-using-the-web-console_extending-a-stratis-volume-with-additional-block-devices\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">26.3. Adding a block device to a Stratis pool by using the web console\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can use the web console to add a block device to an existing Stratis pool. You can also add caches as a block device.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tYou have installed the RHEL 9 web console.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor instructions, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console\">Installing and enabling the web console\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">stratisd\u003C/code> service is running.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tA Stratis pool is created.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe block devices on which you are creating a Stratis pool are not in use and are not mounted.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tEach block device on which you are creating a Stratis pool is at least 1 GB.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tLog in to the RHEL 9 web console.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor details, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#logging-in-to-the-web-console_getting-started-with-the-rhel-9-web-console\">Logging in to the web console\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick \u003Cspan class=\"guibutton\">Storage\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Storage\u003C/strong>\u003C/span> table, click the Stratis pool to which you want to add a block device.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOn the \u003Cspan class=\"strong strong\">\u003Cstrong>Stratis pool\u003C/strong>\u003C/span> page, click \u003Cspan class=\"guibutton\">Add block devices\u003C/span>.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/7cbbd0667e9e4dad03191e3a1bd46614/cockpit-view-stratis-pool.png\" alt=\"Image displaying the Stratis pool page.\"/>\u003C/span>\n\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Add block devices\u003C/strong>\u003C/span> dialog box, select the \u003Cspan class=\"strong strong\">\u003Cstrong>Tier\u003C/strong>\u003C/span>, whether you want to add a block device as data or cache.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/4fe8c35276d6b3ff0b005558df3edcbe/cockpit-stratis-add-block-device.png\" alt=\"Image displaying the Add block devices dialog box.\"/>\u003C/span>\n\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tOptional: If you are adding the block device to a Stratis pool that is encrypted with a passphrase, then you must enter the passphrase.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tUnder \u003Cspan class=\"strong strong\">\u003Cstrong>Block devices\u003C/strong>\u003C/span>, select the devices you want to add to the pool.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick \u003Cspan class=\"guibutton\">Add\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"section _additional-resources\" id=\"additional_resources\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">26.4. Additional resources\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://stratis-storage.github.io/\">The \u003Cspan class=\"emphasis\">\u003Cem>Stratis Storage\u003C/em>\u003C/span> website\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"monitoring-stratis-file-systems_managing-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 27. Monitoring Stratis file systems\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\tAs a Stratis user, you can view information about Stratis volumes on your system to monitor their state and free space.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"stratis-sizes-reported-by-different-utilities_monitoring-stratis-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">27.1. Stratis sizes reported by different utilities\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis section explains the difference between Stratis sizes reported by standard utilities such as \u003Ccode class=\"literal\">df\u003C/code> and the \u003Ccode class=\"literal\">stratis\u003C/code> utility.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tStandard Linux utilities such as \u003Ccode class=\"literal\">df\u003C/code> report the size of the XFS file system layer on Stratis, which is 1 TiB. This is not useful information, because the actual storage usage of Stratis is less due to thin provisioning, and also because Stratis automatically grows the file system when the XFS layer is close to full.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tRegularly monitor the amount of data written to your Stratis file systems, which is reported as the \u003Cspan class=\"emphasis\">\u003Cem>Total Physical Used\u003C/em>\u003C/span> value. Make sure it does not exceed the \u003Cspan class=\"emphasis\">\u003Cem>Total Physical Size\u003C/em>\u003C/span> value.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">stratis(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"displaying-information-about-stratis-volumes_monitoring-stratis-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">27.2. Displaying information about Stratis volumes\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure lists statistics about your Stratis volumes, such as the total, used, and free size or file systems and block devices belonging to a pool.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tStratis is installed. See \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems\">Installing Stratis\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">stratisd\u003C/code> service is running.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo display information about all \u003Cspan class=\"strong strong\">\u003Cstrong>block devices\u003C/strong>\u003C/span> used for Stratis on your system:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis blockdev\n\nPool Name  Device Node    Physical Size   State  Tier\n\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span>    \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">/dev/sdb\u003C/span>\u003C/em>\u003C/span>            \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">9.10 TiB\u003C/span>\u003C/em>\u003C/span>  \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">In-use\u003C/span>\u003C/em>\u003C/span>  \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">Data\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo display information about all Stratis \u003Cspan class=\"strong strong\">\u003Cstrong>pools\u003C/strong>\u003C/span> on your system:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis pool\n\nName    Total Physical Size  Total Physical Used\n\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span>            \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">9.10 TiB\u003C/span>\u003C/em>\u003C/span>              \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">598 MiB\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo display information about all Stratis \u003Cspan class=\"strong strong\">\u003Cstrong>file systems\u003C/strong>\u003C/span> on your system:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis filesystem\n\nPool Name  Name  Used     Created            Device\n\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span>    \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-fs\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">546 MiB\u003C/span>\u003C/em>\u003C/span>  \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">Nov 08 2018 08:03\u003C/span>\u003C/em>\u003C/span>  /dev/stratis/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool/my-fs\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">stratis(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"viewing-a-stratis-pool-using-the-web-console_monitoring-stratis-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">27.3. Viewing a Stratis pool by using the web console\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can use the web console to view an existing Stratis pool and the file systems it contains.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tYou have installed the RHEL 9 web console.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor instructions, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console\">Installing and enabling the web console\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">stratisd\u003C/code> service is running.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have an existing Stratis pool.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tLog in to the RHEL 9 web console.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick \u003Cspan class=\"guibutton\">Storage\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Storage\u003C/strong>\u003C/span> table, click the Stratis pool you want to view.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe Stratis pool page displays all the information about the pool and the file systems that you created in the pool.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/7cbbd0667e9e4dad03191e3a1bd46614/cockpit-view-stratis-pool.png\" alt=\"Image displaying the Stratis pool page.\"/>\u003C/span>\n\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"section _additional-resources\" id=\"additional_resources_2\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">27.4. Additional resources\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://stratis-storage.github.io/\">The \u003Cspan class=\"emphasis\">\u003Cem>Stratis Storage\u003C/em>\u003C/span> website\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"using-snapshots-on-stratis-file-systems_managing-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 28. Using snapshots on Stratis file systems\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\tYou can use snapshots on Stratis file systems to capture file system state at arbitrary times and restore it in the future.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"characteristics-of-stratis-snapshots_using-snapshots-on-stratis-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">28.1. Characteristics of Stratis snapshots\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tIn Stratis, a snapshot is a regular Stratis file system created as a copy of another Stratis file system. The snapshot initially contains the same file content as the original file system, but can change as the snapshot is modified. Whatever changes you make to the snapshot will not be reflected in the original file system.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe current snapshot implementation in Stratis is characterized by the following:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tA snapshot of a file system is another file system.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tA snapshot and its origin are not linked in lifetime. A snapshotted file system can live longer than the file system it was created from.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tA file system does not have to be mounted to create a snapshot from it.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tEach snapshot uses around half a gigabyte of actual backing storage, which is needed for the XFS log.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"creating-a-stratis-snapshot_using-snapshots-on-stratis-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">28.2. Creating a Stratis snapshot\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure creates a Stratis file system as a snapshot of an existing Stratis file system.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tStratis is installed. See \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems\">Installing Stratis\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">stratisd\u003C/code> service is running.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have created a Stratis file system. See \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/managing_file_systems/index#creating-a-stratis-file-system_setting-up-stratis-file-systems\">Creating a Stratis filesystem\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo create a Stratis snapshot, use:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis fs snapshot \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-fs\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-fs-snapshot\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">stratis(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"accessing-the-content-of-a-stratis-snapshot_using-snapshots-on-stratis-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">28.3. Accessing the content of a Stratis snapshot\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure mounts a snapshot of a Stratis file system to make it accessible for read and write operations.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tStratis is installed. See \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems\">Installing Stratis\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">stratisd\u003C/code> service is running.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have created a Stratis snapshot. See \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/managing_file_systems/index#creating-a-stratis-file-system_setting-up-stratis-file-systems\">Creating a Stratis filesystem\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo access the snapshot, mount it as a regular file system from the \u003Ccode class=\"literal filename\">/dev/stratis/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span>/\u003C/code> directory:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount /dev/stratis/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span>/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-fs-snapshot\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">mount-point\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#mounting-a-stratis-file-system_setting-up-stratis-file-systems\">Mounting a Stratis file system\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">mount(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"reverting-a-stratis-file-system-to-a-previous-snapshot_using-snapshots-on-stratis-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">28.4. Reverting a Stratis file system to a previous snapshot\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure reverts the content of a Stratis file system to the state captured in a Stratis snapshot.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tStratis is installed. See \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems\">Installing Stratis\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">stratisd\u003C/code> service is running.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have created a Stratis snapshot. See \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#creating-a-stratis-snapshot_using-snapshots-on-stratis-file-systems\">Creating a Stratis snapshot\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOptional: Back up the current state of the file system to be able to access it later:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis filesystem snapshot \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-fs\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-fs-backup\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tUnmount and remove the original file system:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># umount /dev/stratis/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span>/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-fs\u003C/span>\u003C/em>\u003C/span>\n# stratis filesystem destroy \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-fs\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a copy of the snapshot under the name of the original file system:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis filesystem snapshot \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-fs-snapshot\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-fs\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tMount the snapshot, which is now accessible with the same name as the original file system:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount /dev/stratis/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span>/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-fs\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">mount-point\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cp>\n\t\t\t\tThe content of the file system named \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-fs\u003C/span>\u003C/em>\u003C/span> is now identical to the snapshot \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-fs-snapshot\u003C/span>\u003C/em>\u003C/span>.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">stratis(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"removing-a-stratis-snapshot_using-snapshots-on-stratis-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">28.5. Removing a Stratis snapshot\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure removes a Stratis snapshot from a pool. Data on the snapshot are lost.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tStratis is installed. See \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems\">Installing Stratis\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">stratisd\u003C/code> service is running.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have created a Stratis snapshot. See \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_file_systems/using-snapshots-on-stratis-file-systems_managing-file-systems#creating-a-stratis-snapshot_using-snapshots-on-stratis-file-systems\">Creating a Stratis snapshot\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tUnmount the snapshot:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># umount /dev/stratis/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span>/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-fs-snapshot\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tDestroy the snapshot:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis filesystem destroy \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-fs-snapshot\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">stratis(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section _additional-resources\" id=\"additional_resources_3\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">28.6. Additional resources\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://stratis-storage.github.io/\">The \u003Cspan class=\"emphasis\">\u003Cem>Stratis Storage\u003C/em>\u003C/span> website\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"removing-stratis-file-systems_managing-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 29. Removing Stratis file systems\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\tYou can remove an existing Stratis file system, or a Stratis pool, by destroying data on them.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"components-of-a-stratis-volume_removing-stratis-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">29.1. Components of a Stratis volume\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tLearn about the components that comprise a Stratis volume.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tExternally, Stratis presents the following volume components in the command-line interface and the API:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">blockdev\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tBlock devices, such as a disk or a disk partition.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pool\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tComposed of one or more block devices.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tA pool has a fixed total size, equal to the size of the block devices.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe pool contains most Stratis layers, such as the non-volatile data cache using the \u003Ccode class=\"literal\">dm-cache\u003C/code> target.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tStratis creates a \u003Ccode class=\"literal filename\">/dev/stratis/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span>/\u003C/code> directory for each pool. This directory contains links to devices that represent Stratis file systems in the pool.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">filesystem\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tEach pool can contain one or more file systems, which store files.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFile systems are thinly provisioned and do not have a fixed total size. The actual size of a file system grows with the data stored on it. If the size of the data approaches the virtual size of the file system, Stratis grows the thin volume and the file system automatically.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe file systems are formatted with XFS.\n\t\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\t\tStratis tracks information about file systems created using Stratis that XFS is not aware of, and changes made using XFS do not automatically create updates in Stratis. Users must not reformat or reconfigure XFS file systems that are managed by Stratis.\n\t\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tStratis creates links to file systems at the \u003Ccode class=\"literal filename\">/dev/stratis/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span>/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-fs\u003C/span>\u003C/em>\u003C/span>\u003C/code> path.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003C/dl>\u003C/div>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tStratis uses many Device Mapper devices, which show up in \u003Ccode class=\"literal\">dmsetup\u003C/code> listings and the \u003Ccode class=\"literal filename\">/proc/partitions\u003C/code> file. Similarly, the \u003Ccode class=\"literal\">lsblk\u003C/code> command output reflects the internal workings and layers of Stratis.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/section>\u003Csection class=\"section\" id=\"removing-a-stratis-file-system_removing-stratis-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">29.2. Removing a Stratis file system\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure removes an existing Stratis file system. Data stored on it are lost.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tStratis is installed. See \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems\">Installing Stratis\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">stratisd\u003C/code> service is running.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have created a Stratis file system. See \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/managing_file_systems/index#creating-a-stratis-file-system_setting-up-stratis-file-systems\">Creating a Stratis filesystem\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tUnmount the file system:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># umount /dev/stratis/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span>/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-fs\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tDestroy the file system:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis filesystem destroy \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-fs\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify that the file system no longer exists:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis filesystem list \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">stratis(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"deleting-a-file-system-from-a-stratis-pool-using-the-web-console_removing-stratis-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">29.3. Deleting a file system from a Stratis pool by using the web console\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can use the web console to delete a file system from an existing Stratis pool.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tDeleting a Stratis pool file system erases all the data it contains.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tYou have installed the RHEL 9 web console.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor instructions, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console\">Installing and enabling the web console\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tStratis is installed.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe web console detects and installs Stratis by default. However, for manually installing Stratis, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems\">Installing Stratis\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">stratisd\u003C/code> service is running.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have an existing Stratis pool.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have created a file system on the Stratis pool.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tLog in to the RHEL 9 web console.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor details, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#logging-in-to-the-web-console_getting-started-with-the-rhel-9-web-console\">Logging in to the web console\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick \u003Cspan class=\"guibutton\">Storage\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Storage\u003C/strong>\u003C/span> table, click the Stratis pool from which you want to delete a file system.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOn the \u003Cspan class=\"strong strong\">\u003Cstrong>Stratis pool\u003C/strong>\u003C/span> page, scroll to the \u003Cspan class=\"strong strong\">\u003Cstrong>Stratis filesystems\u003C/strong>\u003C/span> section and click the menu button \u003Cspan class=\"guibutton\">⋮\u003C/span> next to the file system you want to delete.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/7cbbd0667e9e4dad03191e3a1bd46614/cockpit-view-stratis-pool.png\" alt=\"Image displaying the Stratis pool page.\"/>\u003C/span>\n\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFrom the drop-down menu, select \u003Cspan class=\"guibutton\">delete\u003C/span>.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US/images/38f85c8e779f4a9eee61311e2daf656e/cockpit-stratis-fs-delete.png\" alt=\"Image displaying the drop-down menu of a stratis file system.\"/>\u003C/span>\n\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Confirm deletion\u003C/strong>\u003C/span> dialog box, click \u003Cspan class=\"guibutton\">Delete\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"removing-a-stratis-pool_removing-stratis-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">29.4. Removing a Stratis pool\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure removes an existing Stratis pool. Data stored on it are lost.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tStratis is installed. See \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#installing-stratis_setting-up-stratis-file-systems\">Installing Stratis\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">stratisd\u003C/code> service is running.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tYou have created a Stratis pool:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tTo create an unencrypted pool, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#create-unencrypted-stratis-pool_setting-up-stratis-file-systems\">Creating an unencrypted Stratis pool\u003C/a>\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tTo create an encrypted pool, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#create-encrypted-stratis-pool_setting-up-stratis-file-systems\">Creating an encrypted Stratis pool\u003C/a>.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tList file systems on the pool:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis filesystem list \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tUnmount all file systems on the pool:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># umount /dev/stratis/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span>/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-fs-1\u003C/span>\u003C/em>\u003C/span> \\\n         /dev/stratis/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span>/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-fs-2\u003C/span>\u003C/em>\u003C/span> \\\n         /dev/stratis/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span>/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-fs-n\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tDestroy the file systems:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis filesystem destroy \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-fs-1\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-fs-2\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tDestroy the pool:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis pool destroy \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-pool\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify that the pool no longer exists:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stratis pool list\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">stratis(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"deleting-a-stratis-pool-using-the-web-console_removing-stratis-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">29.5. Deleting a Stratis pool by using the web console\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can use the web console to delete an existing Stratis pool.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tDeleting a Stratis pool erases all the data it contains.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tYou have installed the RHEL 9 web console.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor instructions, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console\">Installing and enabling the web console\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">stratisd\u003C/code> service is running.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have an existing Stratis pool.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tLog in to the RHEL 9 web console.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor details, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#logging-in-to-the-web-console_getting-started-with-the-rhel-9-web-console\">Logging in to the web console\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick \u003Cspan class=\"guibutton\">Storage\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Storage\u003C/strong>\u003C/span> table, click the menu button, \u003Cspan class=\"guibutton\">⋮\u003C/span>, next to the Stratis pool you want to delete.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tFrom the drop-down menu, select \u003Cspan class=\"guibutton\">Delete pool\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Permanently delete pool\u003C/strong>\u003C/span> dialog box, click \u003Cspan class=\"guibutton\">Delete\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"section _additional-resources\" id=\"additional_resources_4\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">29.6. Additional resources\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://stratis-storage.github.io/\">The \u003Cspan class=\"emphasis\">\u003Cem>Stratis Storage\u003C/em>\u003C/span> website\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"getting-started-with-an-ext4-file-system_managing-file-systems\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 30. Getting started with an ext4 file system\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\tAs a system administrator, you can create, mount, resize, backup, and restore an ext4 file system. The ext4 file system is a scalable extension of the ext3 file system. With Red Hat Enterprise Linux 9, it can support a maximum individual file size of \u003Ccode class=\"literal\">16\u003C/code> terabytes, and file system to a maximum of \u003Ccode class=\"literal\">50\u003C/code> terabytes.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"features-of-an-ext4-file-system_getting-started-with-an-ext4-file-system\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">30.1. Features of an ext4 file system\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tFollowing are the features of an ext4 file system:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tUsing extents: The ext4 file system uses extents, which improves performance when using large files and reduces metadata overhead for large files.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tExt4 labels unallocated block groups and inode table sections accordingly, which allows the block groups and table sections to be skipped during a file system check. It leads to a quick file system check, which becomes more beneficial as the file system grows in size.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tMetadata checksum: By default, this feature is enabled in Red Hat Enterprise Linux 9.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAllocation features of an ext4 file system:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tPersistent pre-allocation\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tDelayed allocation\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tMulti-block allocation\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tStripe-aware allocation\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tExtended attributes (\u003Ccode class=\"literal\">xattr\u003C/code>): This allows the system to associate several additional name and value pairs per file.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tQuota journaling: This avoids the need for lengthy quota consistency checks after a crash.\n\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\tThe only supported journaling mode in ext4 is \u003Ccode class=\"literal\">data=ordered\u003C/code> (default). For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/solutions/424073\">Is the EXT journaling option \"data=writeback\" supported in RHEL?\u003C/a> Knowledgebase article.\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tSubsecond timestamps — This gives timestamps to the subsecond.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">ext4\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"creating-an-ext4-file-system_getting-started-with-an-ext4-file-system\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">30.2. Creating an ext4 file system\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tAs a system administrator, you can create an ext4 file system on a block device using \u003Ccode class=\"literal\">mkfs.ext4\u003C/code> command.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tA partition on your disk. For information about creating MBR or GPT partitions, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_file_systems/partition-operations-with-parted_managing-file-systems#proc_creating-a-partition-table-on-a-disk-with-parted_partition-operations-with-parted\">Creating a partition table on a disk with parted\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tAlternatively, use an LVM or MD volume.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo create an ext4 file system:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tFor a regular-partition device, an LVM volume, an MD volume, or a similar device, use the following command:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mkfs.ext4 /dev/\u003Cspan class=\"emphasis\">\u003Cem>block_device\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tReplace /dev/\u003Cspan class=\"emphasis\">\u003Cem>block_device\u003C/em>\u003C/span> with the path to a block device.\n\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tFor example, \u003Ccode class=\"literal\">/dev/sdb1\u003C/code>, \u003Ccode class=\"literal\">/dev/disk/by-uuid/05e99ec8-def1-4a5e-8a9d-5945339ceb2a\u003C/code>, or \u003Ccode class=\"literal\">/dev/my-volgroup/my-lv\u003C/code>. In general, the default options are optimal for most usage scenarios.\n\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tFor striped block devices (for example, RAID5 arrays), the stripe geometry can be specified at the time of file system creation. Using proper stripe geometry enhances the performance of an ext4 file system. For example, to create a file system with a 64k stride (that is, 16 x 4096) on a 4k-block file system, use the following command:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mkfs.ext4 -E stride=16,stripe-width=64 /dev/\u003Cspan class=\"emphasis\">\u003Cem>block_device\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tIn the given example:\n\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\tstride=value: Specifies the RAID chunk size\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\tstripe-width=value: Specifies the number of data disks in a RAID device, or the number of stripe units in the stripe.\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tTo specify a UUID when creating a file system:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mkfs.ext4 -U \u003Cspan class=\"emphasis\">\u003Cem>UUID\u003C/em>\u003C/span> /dev/\u003Cspan class=\"emphasis\">\u003Cem>block_device\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>UUID\u003C/em>\u003C/span> with the UUID you want to set: for example, \u003Ccode class=\"literal\">7cd65de3-e0be-41d9-b66d-96d749c02da7\u003C/code>.\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tReplace /dev/\u003Cspan class=\"emphasis\">\u003Cem>block_device\u003C/em>\u003C/span> with the path to an ext4 file system to have the UUID added to it: for example, \u003Ccode class=\"literal\">/dev/sda8\u003C/code>.\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tTo specify a label when creating a file system:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mkfs.ext4 -L \u003Cspan class=\"emphasis\">\u003Cem>label-name\u003C/em>\u003C/span> /dev/\u003Cspan class=\"emphasis\">\u003Cem>block_device\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/div>\u003C/rh-alert>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo view the created ext4 file system:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># blkid\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">ext4\u003C/code> and \u003Ccode class=\"literal\">mkfs.ext4\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"mounting-an-ext4-file-system_getting-started-with-an-ext4-file-system\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">30.3. Mounting an ext4 file system\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tAs a system administrator, you can mount an ext4 file system using the \u003Ccode class=\"literal\">mount\u003C/code> utility.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tAn ext4 file system. For information about creating an ext4 file system, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#creating-an-ext4-file-system_getting-started-with-an-ext4-file-system\">Creating an ext4 file system\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo create a mount point to mount the file system:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mkdir \u003Cspan class=\"emphasis\">\u003Cem>/mount/point\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>/mount/point\u003C/em>\u003C/span> with the directory name where mount point of the partition must be created.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo mount an ext4 file system:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tTo mount an ext4 file system with no extra options:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mount /dev/\u003Cspan class=\"emphasis\">\u003Cem>block_device /mount/point\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tTo mount the file system persistently, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_file_systems/assembly_persistently-mounting-file-systems_managing-file-systems\">Persistently mounting file systems\u003C/a>.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo view the mounted file system:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># df -h\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">mount\u003C/code>, \u003Ccode class=\"literal\">ext4\u003C/code>, and \u003Ccode class=\"literal\">fstab\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_file_systems/mounting-file-systems_managing-file-systems\">Mounting file systems\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"resizing-an-ext4-file-system_getting-started-with-an-ext4-file-system\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">30.4. Resizing an ext4 file system\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tAs a system administrator, you can resize an ext4 file system using the \u003Ccode class=\"literal\">resize2fs\u003C/code> utility. The \u003Ccode class=\"literal\">resize2fs\u003C/code> utility reads the size in units of file system block size, unless a suffix indicating a specific unit is used. The following suffixes indicate specific units:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\ts (sectors) - \u003Ccode class=\"literal\">512\u003C/code> byte sectors\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tK (kilobytes) - \u003Ccode class=\"literal\">1,024\u003C/code> bytes\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tM (megabytes) - \u003Ccode class=\"literal\">1,048,576\u003C/code> bytes\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tG (gigabytes) - \u003Ccode class=\"literal\">1,073,741,824\u003C/code> bytes\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tT (terabytes) - \u003Ccode class=\"literal\">1,099,511,627,776\u003C/code> bytes\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tAn ext4 file system. For information about creating an ext4 file system, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/managing_file_systems/index#creating-an-ext4-file-system_getting-started-with-an-ext4-file-system\">Creating an ext4 file system\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tAn underlying block device of an appropriate size to hold the file system after resizing.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo resize an ext4 file system, take the following steps:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tTo shrink and grow the size of an unmounted ext4 file system:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># umount /dev/\u003Cspan class=\"emphasis\">\u003Cem>block_device\u003C/em>\u003C/span>\n# e2fsck -f /dev/\u003Cspan class=\"emphasis\">\u003Cem>block_device\u003C/em>\u003C/span>\n# resize2fs /dev/\u003Cspan class=\"emphasis\">\u003Cem>block_device\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>size\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>/dev/block_device\u003C/em>\u003C/span> with the path to the block device, for example \u003Ccode class=\"literal\">/dev/sdb1\u003C/code>.\n\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>size\u003C/em>\u003C/span> with the required resize value using \u003Ccode class=\"literal\">s\u003C/code>, \u003Ccode class=\"literal\">K\u003C/code>, \u003Ccode class=\"literal\">M\u003C/code>, \u003Ccode class=\"literal\">G\u003C/code>, and \u003Ccode class=\"literal\">T\u003C/code> suffixes.\n\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tAn ext4 file system may be grown while mounted using the \u003Ccode class=\"literal\">resize2fs\u003C/code> command:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># resize2fs \u003Cspan class=\"emphasis\">\u003Cem>/mount/device size\u003C/em>\u003C/span>\u003C/pre>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\t\t\tThe size parameter is optional (and often redundant) when expanding. The \u003Ccode class=\"literal\">resize2fs\u003C/code> automatically expands to fill the available space of the container, usually a logical volume or partition.\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo view the resized file system:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># df -h\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">resize2fs\u003C/code>, \u003Ccode class=\"literal\">e2fsck\u003C/code>, and \u003Ccode class=\"literal\">ext4\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"comparison-of-tools-used-with-ext4-and-xfs_getting-started-with-an-ext4-file-system\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">30.5. Comparison of tools used with ext4 and XFS\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis section compares which tools to use to accomplish common tasks on the ext4 and XFS file systems.\n\t\t\t\u003C/p>\u003Crh-table>\u003Ctable class=\"lt-4-cols lt-7-rows\">\u003Ccolgroup>\u003Ccol style=\"width: 33%; \" class=\"col_1\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 33%; \" class=\"col_2\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 33%; \" class=\"col_3\">\u003C!--Empty-->\u003C/col>\u003C/colgroup>\u003Cthead>\u003Ctr>\u003Cth align=\"left\" valign=\"top\" id=\"idm139822449094432\" scope=\"col\">Task\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm139822449093344\" scope=\"col\">ext4\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm139822450526032\" scope=\"col\">XFS\u003C/th>\u003C/tr>\u003C/thead>\u003Ctbody>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822449094432\"> \u003Cp>\n\t\t\t\t\t\t\t\tCreate a file system\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822449093344\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">mkfs.ext4\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822450526032\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">mkfs.xfs\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822449094432\"> \u003Cp>\n\t\t\t\t\t\t\t\tFile system check\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822449093344\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">e2fsck\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822450526032\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs_repair\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822449094432\"> \u003Cp>\n\t\t\t\t\t\t\t\tResize a file system\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822449093344\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">resize2fs\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822450526032\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs_growfs\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822449094432\"> \u003Cp>\n\t\t\t\t\t\t\t\tSave an image of a file system\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822449093344\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">e2image\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822450526032\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs_metadump\u003C/code> and \u003Ccode class=\"literal\">xfs_mdrestore\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822449094432\"> \u003Cp>\n\t\t\t\t\t\t\t\tLabel or tune a file system\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822449093344\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">tune2fs\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822450526032\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs_admin\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822449094432\"> \u003Cp>\n\t\t\t\t\t\t\t\tBack up a file system\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822449093344\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">tar\u003C/code> and \u003Ccode class=\"literal\">rsync\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822450526032\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfsdump\u003C/code> and \u003Ccode class=\"literal\">xfsrestore\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822449094432\"> \u003Cp>\n\t\t\t\t\t\t\t\tQuota management\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822449093344\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">quota\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822450526032\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs_quota\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822449094432\"> \u003Cp>\n\t\t\t\t\t\t\t\tFile mapping\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822449093344\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">filefrag\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm139822450526032\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs_bmap\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\u003C/rh-table>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tIf you want a complete client-server solution for backups over network, you can use \u003Ccode class=\"literal\">bacula\u003C/code> backup utility that is available in RHEL 9. For more information about Bacula, see \u003Ca class=\"link\" href=\"https://www.bacula.org/documentation/documentation/\">Bacula backup solution\u003C/a>.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/section>\u003C/section>\u003Cdiv>\u003Cdiv xml:lang=\"en-US\" class=\"legalnotice\" id=\"idm139822467588976\">\u003Ch2 class=\"legalnotice\">Legal Notice\u003C/h2>\u003Cdiv class=\"para\">\n\t\tCopyright \u003Cspan class=\"trademark\">\u003C!--Empty-->\u003C/span>© 2024 Red Hat, Inc.\n\t\u003C/div>\u003Cdiv class=\"para\">\n\t\tThe text of and illustrations in this document are licensed by Red Hat under a Creative Commons Attribution–Share Alike 3.0 Unported license (\"CC-BY-SA\"). An explanation of CC-BY-SA is available at \u003Ca class=\"uri\" href=\"http://creativecommons.org/licenses/by-sa/3.0/\">http://creativecommons.org/licenses/by-sa/3.0/\u003C/a>. In accordance with CC-BY-SA, if you distribute this document or an adaptation of it, you must provide the URL for the original version.\n\t\u003C/div>\u003Cdiv class=\"para\">\n\t\tRed Hat, as the licensor of this document, waives the right to enforce, and agrees not to assert, Section 4d of CC-BY-SA to the fullest extent permitted by applicable law.\n\t\u003C/div>\u003Cdiv class=\"para\">\n\t\tRed Hat, Red Hat Enterprise Linux, the Shadowman logo, the Red Hat logo, JBoss, OpenShift, Fedora, the Infinity logo, and RHCE are trademarks of Red Hat, Inc., registered in the United States and other countries.\n\t\u003C/div>\u003Cdiv class=\"para\">\n\t\t\u003Cspan class=\"trademark\">Linux\u003C/span>® is the registered trademark of Linus Torvalds in the United States and other countries.\n\t\u003C/div>\u003Cdiv class=\"para\">\n\t\t\u003Cspan class=\"trademark\">Java\u003C/span>® is a registered trademark of Oracle and/or its affiliates.\n\t\u003C/div>\u003Cdiv class=\"para\">\n\t\t\u003Cspan class=\"trademark\">XFS\u003C/span>® is a trademark of Silicon Graphics International Corp. or its subsidiaries in the United States and/or other countries.\n\t\u003C/div>\u003Cdiv class=\"para\">\n\t\t\u003Cspan class=\"trademark\">MySQL\u003C/span>® is a registered trademark of MySQL AB in the United States, the European Union and other countries.\n\t\u003C/div>\u003Cdiv class=\"para\">\n\t\t\u003Cspan class=\"trademark\">Node.js\u003C/span>® is an official trademark of Joyent. Red Hat is not formally related to or endorsed by the official Joyent Node.js open source or commercial project.\n\t\u003C/div>\u003Cdiv class=\"para\">\n\t\tThe \u003Cspan class=\"trademark\">OpenStack\u003C/span>® Word Mark and OpenStack logo are either registered trademarks/service marks or trademarks/service marks of the OpenStack Foundation, in the United States and other countries and are used with the OpenStack Foundation's permission. We are not affiliated with, endorsed or sponsored by the OpenStack Foundation, or the OpenStack community.\n\t\u003C/div>\u003Cdiv class=\"para\">\n\t\tAll other trademarks are the property of their respective owners.\n\t\u003C/div>\u003C/div>\u003C/div>\u003C/div>\u003C/body>",[14,21,26,79,149,166,236,282,324,349,375,388,397,410,427,436,462,500,534,560,574,612,626,640,674,720,742,828,850,872,902,932,958],{"title":11,"visible":15,"weight":16,"urlFragment":17,"anchor":18,"singlePageAnchor":18,"docTitle":19,"url":20},true,1,"index",null,"managing_file_systems","#",{"title":22,"visible":15,"weight":23,"urlFragment":24,"anchor":18,"singlePageAnchor":24,"docTitle":19,"url":25},"Providing feedback on Red Hat documentation",2,"proc_providing-feedback-on-red-hat-documentation_managing-file-systems","#proc_providing-feedback-on-red-hat-documentation_managing-file-systems",{"title":27,"visible":15,"weight":28,"urlFragment":29,"anchor":18,"singlePageAnchor":29,"sections":30,"docTitle":19,"url":78},"1. Overview of available file systems",3,"overview-of-available-file-systems_managing-file-systems",[31,35,39,43,48,53,58,63,68,73],{"title":32,"visible":15,"weight":16,"urlFragment":29,"anchor":33,"singlePageAnchor":33,"docTitle":19,"url":34},"1.1. Types of file systems","types-of-file-systems_overview-of-available-file-systems","#types-of-file-systems_overview-of-available-file-systems",{"title":36,"visible":15,"weight":23,"urlFragment":29,"anchor":37,"singlePageAnchor":37,"docTitle":19,"url":38},"1.2. Local file systems","local-file-systems_overview-of-available-file-systems","#local-file-systems_overview-of-available-file-systems",{"title":40,"visible":15,"weight":28,"urlFragment":29,"anchor":41,"singlePageAnchor":41,"docTitle":19,"url":42},"1.3. The XFS file system","the-xfs-file-system_overview-of-available-file-systems","#the-xfs-file-system_overview-of-available-file-systems",{"title":44,"visible":15,"weight":45,"urlFragment":29,"anchor":46,"singlePageAnchor":46,"docTitle":19,"url":47},"1.4. The ext4 file system",4,"the-ext4-file-system_overview-of-available-file-systems","#the-ext4-file-system_overview-of-available-file-systems",{"title":49,"visible":15,"weight":50,"urlFragment":29,"anchor":51,"singlePageAnchor":51,"docTitle":19,"url":52},"1.5. Comparison of XFS and ext4",5,"comparison-of-xfs-and-ext4_overview-of-available-file-systems","#comparison-of-xfs-and-ext4_overview-of-available-file-systems",{"title":54,"visible":15,"weight":55,"urlFragment":29,"anchor":56,"singlePageAnchor":56,"docTitle":19,"url":57},"1.6. Choosing a local file system",6,"choosing-a-local-file-system_overview-of-available-file-systems","#choosing-a-local-file-system_overview-of-available-file-systems",{"title":59,"visible":15,"weight":60,"urlFragment":29,"anchor":61,"singlePageAnchor":61,"docTitle":19,"url":62},"1.7. Network file systems",7,"network-file-systems_overview-of-available-file-systems","#network-file-systems_overview-of-available-file-systems",{"title":64,"visible":15,"weight":65,"urlFragment":29,"anchor":66,"singlePageAnchor":66,"docTitle":19,"url":67},"1.8. Shared storage file systems",8,"shared-storage-file-systems_overview-of-available-file-systems","#shared-storage-file-systems_overview-of-available-file-systems",{"title":69,"visible":15,"weight":70,"urlFragment":29,"anchor":71,"singlePageAnchor":71,"docTitle":19,"url":72},"1.9. Choosing between network and shared storage file systems",9,"choosing-between-network-and-shared-storage-file-systems_overview-of-available-file-systems","#choosing-between-network-and-shared-storage-file-systems_overview-of-available-file-systems",{"title":74,"visible":15,"weight":75,"urlFragment":29,"anchor":76,"singlePageAnchor":76,"docTitle":19,"url":77},"1.10. Volume-managing file systems",10,"volume-managing-file-systems_overview-of-available-file-systems","#volume-managing-file-systems_overview-of-available-file-systems","#overview-of-available-file-systems_managing-file-systems",{"title":80,"visible":15,"weight":45,"urlFragment":81,"anchor":18,"singlePageAnchor":81,"sections":82,"docTitle":19,"url":148},"2. Managing local storage by using the RHEL system role","managing-local-storage-using-rhel-system-roles_managing-file-systems",[83,87,91,95,99,103,107,111,115,119,123,128,133,138,143],{"title":84,"visible":15,"weight":16,"urlFragment":81,"anchor":85,"singlePageAnchor":85,"docTitle":19,"url":86},"2.1. Introduction to the storage RHEL system role","storage-role-intro_managing-local-storage-using-rhel-system-roles","#storage-role-intro_managing-local-storage-using-rhel-system-roles",{"title":88,"visible":15,"weight":23,"urlFragment":81,"anchor":89,"singlePageAnchor":89,"docTitle":19,"url":90},"2.2. Creating an XFS file system on a block device by using the storage RHEL system role","an-example-ansible-playbook-to-create-an-xfs-file-system_managing-local-storage-using-rhel-system-roles","#an-example-ansible-playbook-to-create-an-xfs-file-system_managing-local-storage-using-rhel-system-roles",{"title":92,"visible":15,"weight":28,"urlFragment":81,"anchor":93,"singlePageAnchor":93,"docTitle":19,"url":94},"2.3. Persistently mounting a file system by using the storage RHEL system role","an-example-ansible-playbook-to-persistently-mount-a-file-system_managing-local-storage-using-rhel-system-roles","#an-example-ansible-playbook-to-persistently-mount-a-file-system_managing-local-storage-using-rhel-system-roles",{"title":96,"visible":15,"weight":45,"urlFragment":81,"anchor":97,"singlePageAnchor":97,"docTitle":19,"url":98},"2.4. Managing logical volumes by using the storage RHEL system role","an-example-playbook-to-manage-logical-volumes_managing-local-storage-using-rhel-system-roles","#an-example-playbook-to-manage-logical-volumes_managing-local-storage-using-rhel-system-roles",{"title":100,"visible":15,"weight":50,"urlFragment":81,"anchor":101,"singlePageAnchor":101,"docTitle":19,"url":102},"2.5. Enabling online block discard by using the storage RHEL system role","an-example-ansible-playbook-to-enable-online-block-discard_managing-local-storage-using-rhel-system-roles","#an-example-ansible-playbook-to-enable-online-block-discard_managing-local-storage-using-rhel-system-roles",{"title":104,"visible":15,"weight":55,"urlFragment":81,"anchor":105,"singlePageAnchor":105,"docTitle":19,"url":106},"2.6. Creating and mounting an Ext4 file system by using the storage RHEL system role","an-example-playbook-to-create-mount-an-ext4-file-system_managing-local-storage-using-rhel-system-roles","#an-example-playbook-to-create-mount-an-ext4-file-system_managing-local-storage-using-rhel-system-roles",{"title":108,"visible":15,"weight":60,"urlFragment":81,"anchor":109,"singlePageAnchor":109,"docTitle":19,"url":110},"2.7. Creating and mounting an Ext3 file system by using the storage RHEL system role","an-example-ansible-playbook-to-create-mount-ext3-file-system_managing-local-storage-using-rhel-system-roles","#an-example-ansible-playbook-to-create-mount-ext3-file-system_managing-local-storage-using-rhel-system-roles",{"title":112,"visible":15,"weight":65,"urlFragment":81,"anchor":113,"singlePageAnchor":113,"docTitle":19,"url":114},"2.8. Resizing an existing file system on LVM by using the storage RHEL system role","example-ansible-playbook-to-resize-an-existing-lvm-file-system-using-the-storage-rhel-system-role_managing-local-storage-using-rhel-system-roles","#example-ansible-playbook-to-resize-an-existing-lvm-file-system-using-the-storage-rhel-system-role_managing-local-storage-using-rhel-system-roles",{"title":116,"visible":15,"weight":70,"urlFragment":81,"anchor":117,"singlePageAnchor":117,"docTitle":19,"url":118},"2.9. Creating a swap volume by using the storage RHEL system role","example-ansible-playbook-to-create-a-swap-partition-using-the-storage-rhel-system-role_managing-local-storage-using-rhel-system-roles","#example-ansible-playbook-to-create-a-swap-partition-using-the-storage-rhel-system-role_managing-local-storage-using-rhel-system-roles",{"title":120,"visible":15,"weight":75,"urlFragment":81,"anchor":121,"singlePageAnchor":121,"docTitle":19,"url":122},"2.10. Configuring a RAID volume by using the storage RHEL system role","configuring-a-raid-volume-using-the-storage-system-role_managing-local-storage-using-rhel-system-roles","#configuring-a-raid-volume-using-the-storage-system-role_managing-local-storage-using-rhel-system-roles",{"title":124,"visible":15,"weight":125,"urlFragment":81,"anchor":126,"singlePageAnchor":126,"docTitle":19,"url":127},"2.11. Configuring an LVM pool with RAID by using the storage RHEL system role",11,"configuring-lvm-pool-with-raid-using-storage-system-role_managing-local-storage-using-rhel-system-roles","#configuring-lvm-pool-with-raid-using-storage-system-role_managing-local-storage-using-rhel-system-roles",{"title":129,"visible":15,"weight":130,"urlFragment":81,"anchor":131,"singlePageAnchor":131,"docTitle":19,"url":132},"2.12. Configuring a stripe size for RAID LVM volumes by using the storage RHEL system role",12,"configuring-a-stripe-size-for-raid-lvm-system-role_managing-local-storage-using-rhel-system-roles","#configuring-a-stripe-size-for-raid-lvm-system-role_managing-local-storage-using-rhel-system-roles",{"title":134,"visible":15,"weight":135,"urlFragment":81,"anchor":136,"singlePageAnchor":136,"docTitle":19,"url":137},"2.13. Compressing and deduplicating a VDO volume on LVM by using the storage RHEL system role",13,"example-ansible-playbook-to-compress-and-deduplicate-a-vdo-volume-on-lvm-using-the-storage-rhel-system-role_managing-local-storage-using-rhel-system-roles","#example-ansible-playbook-to-compress-and-deduplicate-a-vdo-volume-on-lvm-using-the-storage-rhel-system-role_managing-local-storage-using-rhel-system-roles",{"title":139,"visible":15,"weight":140,"urlFragment":81,"anchor":141,"singlePageAnchor":141,"docTitle":19,"url":142},"2.14. Creating a LUKS2 encrypted volume by using the storage RHEL system role",14,"creating-a-luks2-encrypted-volume-using-the-storage-role_managing-local-storage-using-rhel-system-roles","#creating-a-luks2-encrypted-volume-using-the-storage-role_managing-local-storage-using-rhel-system-roles",{"title":144,"visible":15,"weight":145,"urlFragment":81,"anchor":146,"singlePageAnchor":146,"docTitle":19,"url":147},"2.15. Expressing pool volume sizes as percentage by using the storage RHEL system role",15,"example-ansible-playbook-to-express-pool-volume-sizes-as-percentage-using-the-storage-rhel-system-role_managing-local-storage-using-rhel-system-roles","#example-ansible-playbook-to-express-pool-volume-sizes-as-percentage-using-the-storage-rhel-system-role_managing-local-storage-using-rhel-system-roles","#managing-local-storage-using-rhel-system-roles_managing-file-systems",{"title":150,"visible":15,"weight":50,"urlFragment":151,"anchor":18,"singlePageAnchor":151,"sections":152,"docTitle":19,"url":165},"3. Managing partitions using the web console","managing-partitions-using-the-web-console_managing-file-systems",[153,157,161],{"title":154,"visible":15,"weight":16,"urlFragment":151,"anchor":155,"singlePageAnchor":155,"docTitle":19,"url":156},"3.1. Displaying partitions formatted with file systems in the web console","displaying-partitions-in-the-web-console_managing-partitions-using-the-web-console","#displaying-partitions-in-the-web-console_managing-partitions-using-the-web-console",{"title":158,"visible":15,"weight":23,"urlFragment":151,"anchor":159,"singlePageAnchor":159,"docTitle":19,"url":160},"3.2. Creating partitions in the web console","creating-partitions-in-the-web-console_managing-partitions-using-the-web-console","#creating-partitions-in-the-web-console_managing-partitions-using-the-web-console",{"title":162,"visible":15,"weight":28,"urlFragment":151,"anchor":163,"singlePageAnchor":163,"docTitle":19,"url":164},"3.3. Deleting partitions in the web console","deleting-partitions-in-the-web-console_managing-partitions-using-the-web-console","#deleting-partitions-in-the-web-console_managing-partitions-using-the-web-console","#managing-partitions-using-the-web-console_managing-file-systems",{"title":167,"visible":15,"weight":55,"urlFragment":168,"anchor":18,"singlePageAnchor":168,"sections":169,"docTitle":19,"url":235},"4. Mounting NFS shares","mounting-nfs-shares_managing-file-systems",[170,174,178,182,186,190,194,198,202,206,210],{"title":171,"visible":15,"weight":16,"urlFragment":168,"anchor":172,"singlePageAnchor":172,"docTitle":19,"url":173},"4.1. Services required on an NFS client","services-required-on-an-nfs-client_mounting-nfs-shares","#services-required-on-an-nfs-client_mounting-nfs-shares",{"title":175,"visible":15,"weight":23,"urlFragment":168,"anchor":176,"singlePageAnchor":176,"docTitle":19,"url":177},"4.2. Preparing an NFSv3 client to run behind a firewall","preparing-an-nfsv3-client-to-run-behind-a-firewall_mounting-nfs-shares","#preparing-an-nfsv3-client-to-run-behind-a-firewall_mounting-nfs-shares",{"title":179,"visible":15,"weight":28,"urlFragment":168,"anchor":180,"singlePageAnchor":180,"docTitle":19,"url":181},"4.3. Preparing an NFSv4.0 client to run behind a firewall","preparing-an-nfsv4-0-client-to-run-behind-a-firewall_mounting-nfs-shares","#preparing-an-nfsv4-0-client-to-run-behind-a-firewall_mounting-nfs-shares",{"title":183,"visible":15,"weight":45,"urlFragment":168,"anchor":184,"singlePageAnchor":184,"docTitle":19,"url":185},"4.4. Manually mounting an NFS share","manually-mounting-an-nfs-share_mounting-nfs-shares","#manually-mounting-an-nfs-share_mounting-nfs-shares",{"title":187,"visible":15,"weight":50,"urlFragment":168,"anchor":188,"singlePageAnchor":188,"docTitle":19,"url":189},"4.5. Mounting an NFS share automatically when the system boots","mounting-an-nfs-share-automatically-when-the-system-boots_mounting-nfs-shares","#mounting-an-nfs-share-automatically-when-the-system-boots_mounting-nfs-shares",{"title":191,"visible":15,"weight":55,"urlFragment":168,"anchor":192,"singlePageAnchor":192,"docTitle":19,"url":193},"4.6. Connecting NFS mounts in the web console","connecting-nfs-mounts-in-the-web-console_mounting-nfs-shares","#connecting-nfs-mounts-in-the-web-console_mounting-nfs-shares",{"title":195,"visible":15,"weight":60,"urlFragment":168,"anchor":196,"singlePageAnchor":196,"docTitle":19,"url":197},"4.7. Customizing NFS mount options in the web console","customizing-nfs-mount-options-in-the-web-console_mounting-nfs-shares","#customizing-nfs-mount-options-in-the-web-console_mounting-nfs-shares",{"title":199,"visible":15,"weight":65,"urlFragment":168,"anchor":200,"singlePageAnchor":200,"docTitle":19,"url":201},"4.8. Setting up an NFS client with Kerberos in a Red Hat Identity Management domain","setting-up-an-nfs-client-with-kerberos-in-a-red-hat-identity-management-domain_mounting-nfs-shares","#setting-up-an-nfs-client-with-kerberos-in-a-red-hat-identity-management-domain_mounting-nfs-shares",{"title":203,"visible":15,"weight":70,"urlFragment":168,"anchor":204,"singlePageAnchor":204,"docTitle":19,"url":205},"4.9. Configuring GNOME to store user settings on home directories hosted on an NFS share","configuring-gnome-to-store-user-settings-on-home-directories-hosted-on-an-nfs-share_mounting-nfs-shares","#configuring-gnome-to-store-user-settings-on-home-directories-hosted-on-an-nfs-share_mounting-nfs-shares",{"title":207,"visible":15,"weight":75,"urlFragment":168,"anchor":208,"singlePageAnchor":208,"docTitle":19,"url":209},"4.10. Frequently used NFS mount options","frequently-used-nfs-mount-options_mounting-nfs-shares","#frequently-used-nfs-mount-options_mounting-nfs-shares",{"title":211,"visible":15,"weight":125,"urlFragment":168,"anchor":212,"singlePageAnchor":212,"sections":213,"docTitle":19,"url":234},"4.11. Enabling client-side caching of NFS content","enabling-client-side-caching-of-nfs-content_mounting-nfs-shares",[214,218,222,226,230],{"title":215,"visible":15,"weight":16,"urlFragment":168,"anchor":216,"singlePageAnchor":216,"docTitle":19,"url":217},"4.11.1. How NFS caching works","how-nfs-caching-works_enabling-client-side-caching-of-nfs-content","#how-nfs-caching-works_enabling-client-side-caching-of-nfs-content",{"title":219,"visible":15,"weight":23,"urlFragment":168,"anchor":220,"singlePageAnchor":220,"docTitle":19,"url":221},"4.11.2. Installing and configuring the cachefilesd service","installing-and-configuring-the-cachefilesd-service_enabling-client-side-caching-of-nfs-content","#installing-and-configuring-the-cachefilesd-service_enabling-client-side-caching-of-nfs-content",{"title":223,"visible":15,"weight":28,"urlFragment":168,"anchor":224,"singlePageAnchor":224,"docTitle":19,"url":225},"4.11.3. Sharing NFS cache","sharing-nfs-cache_enabling-client-side-caching-of-nfs-content","#sharing-nfs-cache_enabling-client-side-caching-of-nfs-content",{"title":227,"visible":15,"weight":45,"urlFragment":168,"anchor":228,"singlePageAnchor":228,"docTitle":19,"url":229},"4.11.4. NFS cache limitations","nfs-cache-limitations_enabling-client-side-caching-of-nfs-content","#nfs-cache-limitations_enabling-client-side-caching-of-nfs-content",{"title":231,"visible":15,"weight":50,"urlFragment":168,"anchor":232,"singlePageAnchor":232,"docTitle":19,"url":233},"4.11.5. How cache culling works","how-cache-culling-works_enabling-client-side-caching-of-nfs-content","#how-cache-culling-works_enabling-client-side-caching-of-nfs-content","#enabling-client-side-caching-of-nfs-content_mounting-nfs-shares","#mounting-nfs-shares_managing-file-systems",{"title":237,"visible":15,"weight":60,"urlFragment":238,"anchor":18,"singlePageAnchor":238,"sections":239,"docTitle":19,"url":281},"5. Mounting an SMB Share","mounting-an-smb-share-on-red-hat-enterprise-linux_managing-file-systems",[240,244,248,252,256,260,277],{"title":241,"visible":15,"weight":16,"urlFragment":238,"anchor":242,"singlePageAnchor":242,"docTitle":19,"url":243},"5.1. Supported SMB protocol versions","con_supported-smb-protocol-versions_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux","#con_supported-smb-protocol-versions_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux",{"title":245,"visible":15,"weight":23,"urlFragment":238,"anchor":246,"singlePageAnchor":246,"docTitle":19,"url":247},"5.2. UNIX extensions support","con_unix-extensions-support_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux","#con_unix-extensions-support_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux",{"title":249,"visible":15,"weight":28,"urlFragment":238,"anchor":250,"singlePageAnchor":250,"docTitle":19,"url":251},"5.3. Manually mounting an SMB share","proc_manually-mounting-an-smb-share_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux","#proc_manually-mounting-an-smb-share_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux",{"title":253,"visible":15,"weight":45,"urlFragment":238,"anchor":254,"singlePageAnchor":254,"docTitle":19,"url":255},"5.4. Mounting an SMB share automatically when the system boots","proc_mounting-an-smb-share-automatically-when-the-system-boots_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux","#proc_mounting-an-smb-share-automatically-when-the-system-boots_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux",{"title":257,"visible":15,"weight":50,"urlFragment":238,"anchor":258,"singlePageAnchor":258,"docTitle":19,"url":259},"5.5. Creating a credentials file to authenticate to an SMB share","proc_authenticating-to-an-smb-share-using-a-credentials-file_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux","#proc_authenticating-to-an-smb-share-using-a-credentials-file_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux",{"title":261,"visible":15,"weight":55,"urlFragment":238,"anchor":262,"singlePageAnchor":262,"sections":263,"docTitle":19,"url":276},"5.6. Performing a multi-user SMB mount","performing-a-multi-user-smb-mount_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux",[264,268,272],{"title":265,"visible":15,"weight":16,"urlFragment":238,"anchor":266,"singlePageAnchor":266,"docTitle":19,"url":267},"5.6.1. Mounting a share with the multiuser option","proc_mounting-a-share-with-the-multiuser-option_assembly_performing-a-multi-user-smb-mount","#proc_mounting-a-share-with-the-multiuser-option_assembly_performing-a-multi-user-smb-mount",{"title":269,"visible":15,"weight":23,"urlFragment":238,"anchor":270,"singlePageAnchor":270,"docTitle":19,"url":271},"5.6.2. Verifying if an SMB share is mounted with the multiuser option","proc_verifying-if-an-smb-share-is-mounted-with-the-multiuser-option_assembly_performing-a-multi-user-smb-mount","#proc_verifying-if-an-smb-share-is-mounted-with-the-multiuser-option_assembly_performing-a-multi-user-smb-mount",{"title":273,"visible":15,"weight":28,"urlFragment":238,"anchor":274,"singlePageAnchor":274,"docTitle":19,"url":275},"5.6.3. Accessing a share as a user","proc_accessing-a-share-as-a-user_assembly_performing-a-multi-user-smb-mount","#proc_accessing-a-share-as-a-user_assembly_performing-a-multi-user-smb-mount","#performing-a-multi-user-smb-mount_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux",{"title":278,"visible":15,"weight":60,"urlFragment":238,"anchor":279,"singlePageAnchor":279,"docTitle":19,"url":280},"5.7. Frequently used SMB mount options","con_frequently-used-mount-options_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux","#con_frequently-used-mount-options_assembly_mounting-an-smb-share-on-red-hat-enterprise-linux","#mounting-an-smb-share-on-red-hat-enterprise-linux_managing-file-systems",{"title":283,"visible":15,"weight":65,"urlFragment":284,"anchor":18,"singlePageAnchor":284,"sections":285,"docTitle":19,"url":323},"6. Overview of persistent naming attributes","assembly_overview-of-persistent-naming-attributes_managing-file-systems",[286,290,294,307,311,315,319],{"title":287,"visible":15,"weight":16,"urlFragment":284,"anchor":288,"singlePageAnchor":288,"docTitle":19,"url":289},"6.1. Disadvantages of non-persistent naming attributes","con_disadvantages-of-non-persistent-naming-attributes_assembly_overview-of-persistent-naming-attributes","#con_disadvantages-of-non-persistent-naming-attributes_assembly_overview-of-persistent-naming-attributes",{"title":291,"visible":15,"weight":23,"urlFragment":284,"anchor":292,"singlePageAnchor":292,"docTitle":19,"url":293},"6.2. File system and device identifiers","file-system-and-device-identifiers_assembly_overview-of-persistent-naming-attributes","#file-system-and-device-identifiers_assembly_overview-of-persistent-naming-attributes",{"title":295,"visible":15,"weight":28,"urlFragment":284,"anchor":296,"singlePageAnchor":296,"sections":297,"docTitle":19,"url":306},"6.3. Device names managed by the udev mechanism in /dev/disk/","con_device-names-managed-by-the-udev-mechanism-in-dev-disk-_assembly_overview-of-persistent-naming-attributes",[298,302],{"title":299,"visible":15,"weight":16,"urlFragment":284,"anchor":300,"singlePageAnchor":300,"docTitle":19,"url":301},"6.3.1. File system identifiers","file-system-identifiers_assembly_overview-of-persistent-naming-attributes","#file-system-identifiers_assembly_overview-of-persistent-naming-attributes",{"title":303,"visible":15,"weight":23,"urlFragment":284,"anchor":304,"singlePageAnchor":304,"docTitle":19,"url":305},"6.3.2. Device identifiers","device-identifiers_assembly_overview-of-persistent-naming-attributes","#device-identifiers_assembly_overview-of-persistent-naming-attributes","#con_device-names-managed-by-the-udev-mechanism-in-dev-disk-_assembly_overview-of-persistent-naming-attributes",{"title":308,"visible":15,"weight":45,"urlFragment":284,"anchor":309,"singlePageAnchor":309,"docTitle":19,"url":310},"6.4. The World Wide Identifier with DM Multipath","con_the-world-wide-identifier-with-dm-multipath_assembly_overview-of-persistent-naming-attributes","#con_the-world-wide-identifier-with-dm-multipath_assembly_overview-of-persistent-naming-attributes",{"title":312,"visible":15,"weight":50,"urlFragment":284,"anchor":313,"singlePageAnchor":313,"docTitle":19,"url":314},"6.5. Limitations of the udev device naming convention","con_limitations-of-the-udev-device-naming-convention_assembly_overview-of-persistent-naming-attributes","#con_limitations-of-the-udev-device-naming-convention_assembly_overview-of-persistent-naming-attributes",{"title":316,"visible":15,"weight":55,"urlFragment":284,"anchor":317,"singlePageAnchor":317,"docTitle":19,"url":318},"6.6. Listing persistent naming attributes","proc_listing-persistent-naming-attributes_assembly_overview-of-persistent-naming-attributes","#proc_listing-persistent-naming-attributes_assembly_overview-of-persistent-naming-attributes",{"title":320,"visible":15,"weight":60,"urlFragment":284,"anchor":321,"singlePageAnchor":321,"docTitle":19,"url":322},"6.7. Modifying persistent naming attributes","proc_modifying-persistent-naming-attributes_assembly_overview-of-persistent-naming-attributes","#proc_modifying-persistent-naming-attributes_assembly_overview-of-persistent-naming-attributes","#assembly_overview-of-persistent-naming-attributes_managing-file-systems",{"title":325,"visible":15,"weight":70,"urlFragment":326,"anchor":18,"singlePageAnchor":326,"sections":327,"docTitle":19,"url":348},"7. Partition operations with parted","partition-operations-with-parted_managing-file-systems",[328,332,336,340,344],{"title":329,"visible":15,"weight":16,"urlFragment":326,"anchor":330,"singlePageAnchor":330,"docTitle":19,"url":331},"7.1. Viewing the partition table with parted","viewing-the-partition-table-with-parted_partition-operations-with-parted","#viewing-the-partition-table-with-parted_partition-operations-with-parted",{"title":333,"visible":15,"weight":23,"urlFragment":326,"anchor":334,"singlePageAnchor":334,"docTitle":19,"url":335},"7.2. Creating a partition table on a disk with parted","proc_creating-a-partition-table-on-a-disk-with-parted_partition-operations-with-parted","#proc_creating-a-partition-table-on-a-disk-with-parted_partition-operations-with-parted",{"title":337,"visible":15,"weight":28,"urlFragment":326,"anchor":338,"singlePageAnchor":338,"docTitle":19,"url":339},"7.3. Creating a partition with parted","proc_creating-a-partition-with-parted_partition-operations-with-parted","#proc_creating-a-partition-with-parted_partition-operations-with-parted",{"title":341,"visible":15,"weight":45,"urlFragment":326,"anchor":342,"singlePageAnchor":342,"docTitle":19,"url":343},"7.4. Removing a partition with parted","proc_removing-a-partition-with-parted_partition-operations-with-parted","#proc_removing-a-partition-with-parted_partition-operations-with-parted",{"title":345,"visible":15,"weight":50,"urlFragment":326,"anchor":346,"singlePageAnchor":346,"docTitle":19,"url":347},"7.5. Resizing a partition with parted","proc_resizing-a-partition-with-parted_partition-operations-with-parted","#proc_resizing-a-partition-with-parted_partition-operations-with-parted","#partition-operations-with-parted_managing-file-systems",{"title":350,"visible":15,"weight":75,"urlFragment":351,"anchor":18,"singlePageAnchor":351,"sections":352,"docTitle":19,"url":374},"8. Strategies for repartitioning a disk","strategies-for-repartitioning-a-disk_managing-file-systems",[353,357,361],{"title":354,"visible":15,"weight":16,"urlFragment":351,"anchor":355,"singlePageAnchor":355,"docTitle":19,"url":356},"8.1. Using unpartitioned free space","using-unpartitioned-free-space_strategies-for-repartitioning-a-disk","#using-unpartitioned-free-space_strategies-for-repartitioning-a-disk",{"title":358,"visible":15,"weight":23,"urlFragment":351,"anchor":359,"singlePageAnchor":359,"docTitle":19,"url":360},"8.2. Using space from an unused partition","using-space-from-an-unused-partition_strategies-for-repartitioning-a-disk","#using-space-from-an-unused-partition_strategies-for-repartitioning-a-disk",{"title":362,"visible":15,"weight":28,"urlFragment":351,"anchor":363,"singlePageAnchor":363,"sections":364,"docTitle":19,"url":373},"8.3. Using free space from an active partition","using-free-space-from-an-active-partition_strategies-for-repartitioning-a-disk",[365,369],{"title":366,"visible":15,"weight":16,"urlFragment":351,"anchor":367,"singlePageAnchor":367,"docTitle":19,"url":368},"8.3.1. Destructive repartitioning","destructive-repartitioning_using-free-space-from-an-active-partition","#destructive-repartitioning_using-free-space-from-an-active-partition",{"title":370,"visible":15,"weight":23,"urlFragment":351,"anchor":371,"singlePageAnchor":371,"docTitle":19,"url":372},"8.3.2. Non-destructive repartitioning","non-destructive-repartitioning_using-free-space-from-an-active-partition","#non-destructive-repartitioning_using-free-space-from-an-active-partition","#using-free-space-from-an-active-partition_strategies-for-repartitioning-a-disk","#strategies-for-repartitioning-a-disk_managing-file-systems",{"title":376,"visible":15,"weight":125,"urlFragment":377,"anchor":18,"singlePageAnchor":377,"sections":378,"docTitle":19,"url":387},"9. Getting started with XFS","getting-started-with-xfs_managing-file-systems",[379,383],{"title":380,"visible":15,"weight":16,"urlFragment":377,"anchor":381,"singlePageAnchor":381,"docTitle":19,"url":382},"9.1. The XFS file system","the-xfs-file-system_getting-started-with-xfs","#the-xfs-file-system_getting-started-with-xfs",{"title":384,"visible":15,"weight":23,"urlFragment":377,"anchor":385,"singlePageAnchor":385,"docTitle":19,"url":386},"9.2. Comparison of tools used with ext4 and XFS","comparison-of-tools-used-with-ext4-and-xfs_getting-started-with-xfs","#comparison-of-tools-used-with-ext4-and-xfs_getting-started-with-xfs","#getting-started-with-xfs_managing-file-systems",{"title":389,"visible":15,"weight":130,"urlFragment":390,"anchor":18,"singlePageAnchor":390,"sections":391,"docTitle":19,"url":396},"10. Creating an XFS file system","assembly_creating-an-xfs-file-system_managing-file-systems",[392],{"title":393,"visible":15,"weight":16,"urlFragment":390,"anchor":394,"singlePageAnchor":394,"docTitle":19,"url":395},"10.1. Creating an XFS file system with mkfs.xfs","proc_creating-an-xfs-file-system-with-mkfs-xfs-creating-an-xfs-file-system","#proc_creating-an-xfs-file-system-with-mkfs-xfs-creating-an-xfs-file-system","#assembly_creating-an-xfs-file-system_managing-file-systems",{"title":398,"visible":15,"weight":135,"urlFragment":399,"anchor":18,"singlePageAnchor":399,"sections":400,"docTitle":19,"url":409},"11. Backing up an XFS file system","backing-up-an-xfs-file-system_managing-file-systems",[401,405],{"title":402,"visible":15,"weight":16,"urlFragment":399,"anchor":403,"singlePageAnchor":403,"docTitle":19,"url":404},"11.1. Features of XFS backup","con_features-of-xfs-backup-backing-up-an-xfs-file-system","#con_features-of-xfs-backup-backing-up-an-xfs-file-system",{"title":406,"visible":15,"weight":23,"urlFragment":399,"anchor":407,"singlePageAnchor":407,"docTitle":19,"url":408},"11.2. Backing up an XFS file system with xfsdump","proc_backing-up-an-xfs-file-system-with-xfsdump-backing-up-an-xfs-file-system","#proc_backing-up-an-xfs-file-system-with-xfsdump-backing-up-an-xfs-file-system","#backing-up-an-xfs-file-system_managing-file-systems",{"title":411,"visible":15,"weight":140,"urlFragment":412,"anchor":18,"singlePageAnchor":412,"sections":413,"docTitle":19,"url":426},"12. Restoring an XFS file system from backup","restoring-an-xfs-file-system-from-backup_managing-file-systems",[414,418,422],{"title":415,"visible":15,"weight":16,"urlFragment":412,"anchor":416,"singlePageAnchor":416,"docTitle":19,"url":417},"12.1. Features of restoring XFS from backup","con_features-of-restoring-xfs-from-backup-restoring-an-xfs-file-system-from-backup","#con_features-of-restoring-xfs-from-backup-restoring-an-xfs-file-system-from-backup",{"title":419,"visible":15,"weight":23,"urlFragment":412,"anchor":420,"singlePageAnchor":420,"docTitle":19,"url":421},"12.2. Restoring an XFS file system from backup with xfsrestore","proc_restoring-an-xfs-file-system-from-backup-with-xfsrestore-restoring-an-xfs-file-system-from-backup","#proc_restoring-an-xfs-file-system-from-backup-with-xfsrestore-restoring-an-xfs-file-system-from-backup",{"title":423,"visible":15,"weight":28,"urlFragment":412,"anchor":424,"singlePageAnchor":424,"docTitle":19,"url":425},"12.3. Informational messages when restoring an XFS backup from a tape","con_informational-messages-when-restoring-an-xfs-backup-from-a-tape-restoring-an-xfs-file-system-from-backup","#con_informational-messages-when-restoring-an-xfs-backup-from-a-tape-restoring-an-xfs-file-system-from-backup","#restoring-an-xfs-file-system-from-backup_managing-file-systems",{"title":428,"visible":15,"weight":145,"urlFragment":429,"anchor":18,"singlePageAnchor":429,"sections":430,"docTitle":19,"url":435},"13. Increasing the size of an XFS file system","increasing-the-size-of-an-xfs-file-system_managing-file-systems",[431],{"title":432,"visible":15,"weight":16,"urlFragment":429,"anchor":433,"singlePageAnchor":433,"docTitle":19,"url":434},"13.1. Increasing the size of an XFS file system with xfs_growfs","proc_increasing-the-size-of-an-xfs-file-system-with-xfs_growfs_increasing-the-size-of-an-xfs-file-system","#proc_increasing-the-size-of-an-xfs-file-system-with-xfs_growfs_increasing-the-size-of-an-xfs-file-system","#increasing-the-size-of-an-xfs-file-system_managing-file-systems",{"title":437,"visible":15,"weight":438,"urlFragment":439,"anchor":18,"singlePageAnchor":439,"sections":440,"docTitle":19,"url":461},"14. Configuring XFS error behavior",16,"configuring-xfs-error-behavior_managing-file-systems",[441,445,449,453,457],{"title":442,"visible":15,"weight":16,"urlFragment":439,"anchor":443,"singlePageAnchor":443,"docTitle":19,"url":444},"14.1. Configurable error handling in XFS","configurable-error-handling-in-xfs_configuring-xfs-error-behavior","#configurable-error-handling-in-xfs_configuring-xfs-error-behavior",{"title":446,"visible":15,"weight":23,"urlFragment":439,"anchor":447,"singlePageAnchor":447,"docTitle":19,"url":448},"14.2. Configuration files for specific and undefined XFS error conditions","configuration-files-for-specific-and-undefined-xfs-error-conditions_configuring-xfs-error-behavior","#configuration-files-for-specific-and-undefined-xfs-error-conditions_configuring-xfs-error-behavior",{"title":450,"visible":15,"weight":28,"urlFragment":439,"anchor":451,"singlePageAnchor":451,"docTitle":19,"url":452},"14.3. Setting XFS behavior for specific conditions","setting-specific-and-undefined-xfs-error-conditions_configuring-xfs-error-behavior","#setting-specific-and-undefined-xfs-error-conditions_configuring-xfs-error-behavior",{"title":454,"visible":15,"weight":45,"urlFragment":439,"anchor":455,"singlePageAnchor":455,"docTitle":19,"url":456},"14.4. Setting XFS behavior for undefined conditions","setting-undefined-xfs-error-conditions_configuring-xfs-error-behavior","#setting-undefined-xfs-error-conditions_configuring-xfs-error-behavior",{"title":458,"visible":15,"weight":50,"urlFragment":439,"anchor":459,"singlePageAnchor":459,"docTitle":19,"url":460},"14.5. Setting the XFS unmount behavior","setting-the-unmount-behavior_configuring-xfs-error-behavior","#setting-the-unmount-behavior_configuring-xfs-error-behavior","#configuring-xfs-error-behavior_managing-file-systems",{"title":463,"visible":15,"weight":464,"urlFragment":465,"anchor":18,"singlePageAnchor":465,"sections":466,"docTitle":19,"url":499},"15. Checking and repairing a file system",17,"checking-and-repairing-a-file-system__managing-file-systems",[467,471,475,479,483,487,491,495],{"title":468,"visible":15,"weight":16,"urlFragment":465,"anchor":469,"singlePageAnchor":469,"docTitle":19,"url":470},"15.1. Scenarios that require a file system check","file-system-checking-and-repair_checking-and-repairing-a-file-system","#file-system-checking-and-repair_checking-and-repairing-a-file-system",{"title":472,"visible":15,"weight":23,"urlFragment":465,"anchor":473,"singlePageAnchor":473,"docTitle":19,"url":474},"15.2. Potential side effects of running fsck","potential-side-effects-of-running-fsck_checking-and-repairing-a-file-system","#potential-side-effects-of-running-fsck_checking-and-repairing-a-file-system",{"title":476,"visible":15,"weight":28,"urlFragment":465,"anchor":477,"singlePageAnchor":477,"docTitle":19,"url":478},"15.3. Error-handling mechanisms in XFS","error-handling-mechanisms-in-xfs_checking-and-repairing-a-file-system","#error-handling-mechanisms-in-xfs_checking-and-repairing-a-file-system",{"title":480,"visible":15,"weight":45,"urlFragment":465,"anchor":481,"singlePageAnchor":481,"docTitle":19,"url":482},"15.4. Checking an XFS file system with xfs_repair","checking-an-xfs-file-system-with-xfs-repair_checking-and-repairing-a-file-system","#checking-an-xfs-file-system-with-xfs-repair_checking-and-repairing-a-file-system",{"title":484,"visible":15,"weight":50,"urlFragment":465,"anchor":485,"singlePageAnchor":485,"docTitle":19,"url":486},"15.5. Repairing an XFS file system with xfs_repair","proc_repairing-an-xfs-file-system-with-xfs_repair_checking-and-repairing-a-file-system","#proc_repairing-an-xfs-file-system-with-xfs_repair_checking-and-repairing-a-file-system",{"title":488,"visible":15,"weight":55,"urlFragment":465,"anchor":489,"singlePageAnchor":489,"docTitle":19,"url":490},"15.6. Error handling mechanisms in ext2, ext3, and ext4","error-handling-mechanisms-in-ext2-ext3-and-ext4_checking-and-repairing-a-file-system","#error-handling-mechanisms-in-ext2-ext3-and-ext4_checking-and-repairing-a-file-system",{"title":492,"visible":15,"weight":60,"urlFragment":465,"anchor":493,"singlePageAnchor":493,"docTitle":19,"url":494},"15.7. Checking an ext2, ext3, or ext4 file system with e2fsck","checking-an-ext2-ext3-or-ext4-file-system-with-e2fsck_checking-and-repairing-a-file-system","#checking-an-ext2-ext3-or-ext4-file-system-with-e2fsck_checking-and-repairing-a-file-system",{"title":496,"visible":15,"weight":65,"urlFragment":465,"anchor":497,"singlePageAnchor":497,"docTitle":19,"url":498},"15.8. Repairing an ext2, ext3, or ext4 file system with e2fsck","repairing-an-ext2-ext3-or-ext4-file-system-with-e2fsck_checking-and-repairing-a-file-system","#repairing-an-ext2-ext3-or-ext4-file-system-with-e2fsck_checking-and-repairing-a-file-system","#checking-and-repairing-a-file-system__managing-file-systems",{"title":501,"visible":15,"weight":502,"urlFragment":503,"anchor":18,"singlePageAnchor":503,"sections":504,"docTitle":19,"url":533},"16. Mounting file systems",18,"mounting-file-systems_managing-file-systems",[505,509,513,517,521,525,529],{"title":506,"visible":15,"weight":16,"urlFragment":503,"anchor":507,"singlePageAnchor":507,"docTitle":19,"url":508},"16.1. The Linux mount mechanism","the-linux-mount-mechanism_mounting-file-systems","#the-linux-mount-mechanism_mounting-file-systems",{"title":510,"visible":15,"weight":23,"urlFragment":503,"anchor":511,"singlePageAnchor":511,"docTitle":19,"url":512},"16.2. Listing currently mounted file systems","listing-currently-mounted-file-systems_mounting-file-systems","#listing-currently-mounted-file-systems_mounting-file-systems",{"title":514,"visible":15,"weight":28,"urlFragment":503,"anchor":515,"singlePageAnchor":515,"docTitle":19,"url":516},"16.3. Mounting a file system with mount","mounting-a-file-system-with-mount_mounting-file-systems","#mounting-a-file-system-with-mount_mounting-file-systems",{"title":518,"visible":15,"weight":45,"urlFragment":503,"anchor":519,"singlePageAnchor":519,"docTitle":19,"url":520},"16.4. Moving a mount point","moving-a-mount-point_mounting-file-systems","#moving-a-mount-point_mounting-file-systems",{"title":522,"visible":15,"weight":50,"urlFragment":503,"anchor":523,"singlePageAnchor":523,"docTitle":19,"url":524},"16.5. Unmounting a file system with umount","unmounting-a-file-system-with-umount_mounting-file-systems","#unmounting-a-file-system-with-umount_mounting-file-systems",{"title":526,"visible":15,"weight":55,"urlFragment":503,"anchor":527,"singlePageAnchor":527,"docTitle":19,"url":528},"16.6. Mounting and unmounting file systems in the web console","mounting-and-unmounting-file-systems-in-the-web-console_mounting-file-systems","#mounting-and-unmounting-file-systems-in-the-web-console_mounting-file-systems",{"title":530,"visible":15,"weight":60,"urlFragment":503,"anchor":531,"singlePageAnchor":531,"docTitle":19,"url":532},"16.7. Common mount options","common-mount-options_mounting-file-systems","#common-mount-options_mounting-file-systems","#mounting-file-systems_managing-file-systems",{"title":535,"visible":15,"weight":536,"urlFragment":537,"anchor":18,"singlePageAnchor":537,"sections":538,"docTitle":19,"url":559},"17. Sharing a mount on multiple mount points",19,"sharing-a-mount-on-multiple-mount-points_managing-file-systems",[539,543,547,551,555],{"title":540,"visible":15,"weight":16,"urlFragment":537,"anchor":541,"singlePageAnchor":541,"docTitle":19,"url":542},"17.1. Types of shared mounts","types-of-shared-mounts_sharing-a-mount-on-multiple-mount-points","#types-of-shared-mounts_sharing-a-mount-on-multiple-mount-points",{"title":544,"visible":15,"weight":23,"urlFragment":537,"anchor":545,"singlePageAnchor":545,"docTitle":19,"url":546},"17.2. Creating a private mount point duplicate","creating-a-private-mount-point-duplicate_sharing-a-mount-on-multiple-mount-points","#creating-a-private-mount-point-duplicate_sharing-a-mount-on-multiple-mount-points",{"title":548,"visible":15,"weight":28,"urlFragment":537,"anchor":549,"singlePageAnchor":549,"docTitle":19,"url":550},"17.3. Creating a shared mount point duplicate","creating-a-shared-mount-point-duplicate_sharing-a-mount-on-multiple-mount-points","#creating-a-shared-mount-point-duplicate_sharing-a-mount-on-multiple-mount-points",{"title":552,"visible":15,"weight":45,"urlFragment":537,"anchor":553,"singlePageAnchor":553,"docTitle":19,"url":554},"17.4. Creating a slave mount point duplicate","creating-a-slave-mount-point-duplicate_sharing-a-mount-on-multiple-mount-points","#creating-a-slave-mount-point-duplicate_sharing-a-mount-on-multiple-mount-points",{"title":556,"visible":15,"weight":50,"urlFragment":537,"anchor":557,"singlePageAnchor":557,"docTitle":19,"url":558},"17.5. Preventing a mount point from being duplicated","preventing-a-mount-point-from-being-duplicated_sharing-a-mount-on-multiple-mount-points","#preventing-a-mount-point-from-being-duplicated_sharing-a-mount-on-multiple-mount-points","#sharing-a-mount-on-multiple-mount-points_managing-file-systems",{"title":561,"visible":15,"weight":562,"urlFragment":563,"anchor":18,"singlePageAnchor":563,"sections":564,"docTitle":19,"url":573},"18. Persistently mounting file systems",20,"assembly_persistently-mounting-file-systems_managing-file-systems",[565,569],{"title":566,"visible":15,"weight":16,"urlFragment":563,"anchor":567,"singlePageAnchor":567,"docTitle":19,"url":568},"18.1. The /etc/fstab file","con_the-etc-fstab-file_assembly_persistently-mounting-file-systems","#con_the-etc-fstab-file_assembly_persistently-mounting-file-systems",{"title":570,"visible":15,"weight":23,"urlFragment":563,"anchor":571,"singlePageAnchor":571,"docTitle":19,"url":572},"18.2. Adding a file system to /etc/fstab","adding-a-file-system-to-etc-fstab_assembly_persistently-mounting-file-systems","#adding-a-file-system-to-etc-fstab_assembly_persistently-mounting-file-systems","#assembly_persistently-mounting-file-systems_managing-file-systems",{"title":575,"visible":15,"weight":576,"urlFragment":577,"anchor":18,"singlePageAnchor":577,"sections":578,"docTitle":19,"url":611},"19. Mounting file systems on demand",21,"mounting-file-systems-on-demand_managing-file-systems",[579,583,587,591,595,599,603,607],{"title":580,"visible":15,"weight":16,"urlFragment":577,"anchor":581,"singlePageAnchor":581,"docTitle":19,"url":582},"19.1. The autofs service","the-autofs-service_mounting-file-systems-on-demand","#the-autofs-service_mounting-file-systems-on-demand",{"title":584,"visible":15,"weight":23,"urlFragment":577,"anchor":585,"singlePageAnchor":585,"docTitle":19,"url":586},"19.2. The autofs configuration files","the-autofs-configuration-files_mounting-file-systems-on-demand","#the-autofs-configuration-files_mounting-file-systems-on-demand",{"title":588,"visible":15,"weight":28,"urlFragment":577,"anchor":589,"singlePageAnchor":589,"docTitle":19,"url":590},"19.3. Configuring autofs mount points","configuring-autofs-mount-points_mounting-file-systems-on-demand","#configuring-autofs-mount-points_mounting-file-systems-on-demand",{"title":592,"visible":15,"weight":45,"urlFragment":577,"anchor":593,"singlePageAnchor":593,"docTitle":19,"url":594},"19.4. Automounting NFS server user home directories with autofs service","automounting-user-home-directories-with-autofs-service_mounting-file-systems-on-demand","#automounting-user-home-directories-with-autofs-service_mounting-file-systems-on-demand",{"title":596,"visible":15,"weight":50,"urlFragment":577,"anchor":597,"singlePageAnchor":597,"docTitle":19,"url":598},"19.5. Overriding or augmenting autofs site configuration files","overriding-or-augmenting-autofs-site-configuration-files_mounting-file-systems-on-demand","#overriding-or-augmenting-autofs-site-configuration-files_mounting-file-systems-on-demand",{"title":600,"visible":15,"weight":55,"urlFragment":577,"anchor":601,"singlePageAnchor":601,"docTitle":19,"url":602},"19.6. Using LDAP to store automounter maps","using-ldap-to-store-automounter-maps_mounting-file-systems-on-demand","#using-ldap-to-store-automounter-maps_mounting-file-systems-on-demand",{"title":604,"visible":15,"weight":60,"urlFragment":577,"anchor":605,"singlePageAnchor":605,"docTitle":19,"url":606},"19.7. Using systemd.automount to mount a file system on demand with /etc/fstab","proc_using-systemd-automount-to-mount-a-file-system-on-demand-with-etc-fstab_mounting-file-systems-on-demand","#proc_using-systemd-automount-to-mount-a-file-system-on-demand-with-etc-fstab_mounting-file-systems-on-demand",{"title":608,"visible":15,"weight":65,"urlFragment":577,"anchor":609,"singlePageAnchor":609,"docTitle":19,"url":610},"19.8. Using systemd.automount to mount a file system on-demand with a mount unit","proc_using-systemd-automount-to-mount-a-file-system-on-demand-with-a-mount-unit_mounting-file-systems-on-demand","#proc_using-systemd-automount-to-mount-a-file-system-on-demand-with-a-mount-unit_mounting-file-systems-on-demand","#mounting-file-systems-on-demand_managing-file-systems",{"title":613,"visible":15,"weight":614,"urlFragment":615,"anchor":18,"singlePageAnchor":615,"sections":616,"docTitle":19,"url":625},"20. Using SSSD component from IdM to cache the autofs maps",22,"using-sssd-component-from-idm-to-cache-the-autofs-map_managing-file-systems",[617,621],{"title":618,"visible":15,"weight":16,"urlFragment":615,"anchor":619,"singlePageAnchor":619,"docTitle":19,"url":620},"20.1. Configuring autofs manually to use IdM server as an LDAP server","configuring-autofs-manually-to-use-sssd-and-idm_using-sssd-component-from-idm-to-cache-the-autofs-map","#configuring-autofs-manually-to-use-sssd-and-idm_using-sssd-component-from-idm-to-cache-the-autofs-map",{"title":622,"visible":15,"weight":23,"urlFragment":615,"anchor":623,"singlePageAnchor":623,"docTitle":19,"url":624},"20.2. Configuring SSSD to cache autofs maps","configuring-sssd-to-cache-autofs-map_using-sssd-component-from-idm-to-cache-the-autofs-map","#configuring-sssd-to-cache-autofs-map_using-sssd-component-from-idm-to-cache-the-autofs-map","#using-sssd-component-from-idm-to-cache-the-autofs-map_managing-file-systems",{"title":627,"visible":15,"weight":628,"urlFragment":629,"anchor":18,"singlePageAnchor":629,"sections":630,"docTitle":19,"url":639},"21. Setting read-only permissions for the root file system",23,"setting-read-only-permissions-for-the-root-file-system_managing-file-systems",[631,635],{"title":632,"visible":15,"weight":16,"urlFragment":629,"anchor":633,"singlePageAnchor":633,"docTitle":19,"url":634},"21.1. Files and directories that always retain write permissions","files-and-directories-that-always-retain-write-permissions_setting-read-only-permissions-for-the-root-file-system","#files-and-directories-that-always-retain-write-permissions_setting-read-only-permissions-for-the-root-file-system",{"title":636,"visible":15,"weight":23,"urlFragment":629,"anchor":637,"singlePageAnchor":637,"docTitle":19,"url":638},"21.2. Configuring the root file system to mount with read-only permissions on boot","configuring-the-root-file-system-to-mount-with-read-only-permissions-on-boot_setting-read-only-permissions-for-the-root-file-system","#configuring-the-root-file-system-to-mount-with-read-only-permissions-on-boot_setting-read-only-permissions-for-the-root-file-system","#setting-read-only-permissions-for-the-root-file-system_managing-file-systems",{"title":641,"visible":15,"weight":642,"urlFragment":643,"anchor":18,"singlePageAnchor":643,"sections":644,"docTitle":19,"url":673},"22. Limiting storage space usage on XFS with quotas",24,"assembly_limiting-storage-space-usage-on-xfs-with-quotas_managing-file-systems",[645,649,653,657,661,665,669],{"title":646,"visible":15,"weight":16,"urlFragment":643,"anchor":647,"singlePageAnchor":647,"docTitle":19,"url":648},"22.1. Disk quotas","con_disk-quotas_assembly_limiting-storage-space-usage-on-xfs-with-quotas","#con_disk-quotas_assembly_limiting-storage-space-usage-on-xfs-with-quotas",{"title":650,"visible":15,"weight":23,"urlFragment":643,"anchor":651,"singlePageAnchor":651,"docTitle":19,"url":652},"22.2. The xfs_quota tool","the-xfs_quota-tool_assembly_limiting-storage-space-usage-on-xfs-with-quotas","#the-xfs_quota-tool_assembly_limiting-storage-space-usage-on-xfs-with-quotas",{"title":654,"visible":15,"weight":28,"urlFragment":643,"anchor":655,"singlePageAnchor":655,"docTitle":19,"url":656},"22.3. File system quota management in XFS","file-system-quota-management-in-xfs_assembly_limiting-storage-space-usage-on-xfs-with-quotas","#file-system-quota-management-in-xfs_assembly_limiting-storage-space-usage-on-xfs-with-quotas",{"title":658,"visible":15,"weight":45,"urlFragment":643,"anchor":659,"singlePageAnchor":659,"docTitle":19,"url":660},"22.4. Enabling disk quotas for XFS","enabling-disk-quotas-for-xfs_assembly_limiting-storage-space-usage-on-xfs-with-quotas","#enabling-disk-quotas-for-xfs_assembly_limiting-storage-space-usage-on-xfs-with-quotas",{"title":662,"visible":15,"weight":50,"urlFragment":643,"anchor":663,"singlePageAnchor":663,"docTitle":19,"url":664},"22.5. Reporting XFS usage","running-the-xfs_quota-tool_assembly_limiting-storage-space-usage-on-xfs-with-quotas","#running-the-xfs_quota-tool_assembly_limiting-storage-space-usage-on-xfs-with-quotas",{"title":666,"visible":15,"weight":55,"urlFragment":643,"anchor":667,"singlePageAnchor":667,"docTitle":19,"url":668},"22.6. Modifying XFS quota limits","running-the-xfs_quota-tool-in-expert-mode_assembly_limiting-storage-space-usage-on-xfs-with-quotas","#running-the-xfs_quota-tool-in-expert-mode_assembly_limiting-storage-space-usage-on-xfs-with-quotas",{"title":670,"visible":15,"weight":60,"urlFragment":643,"anchor":671,"singlePageAnchor":671,"docTitle":19,"url":672},"22.7. Setting project limits for XFS","setting-project-limits-for-xfs_assembly_limiting-storage-space-usage-on-xfs-with-quotas","#setting-project-limits-for-xfs_assembly_limiting-storage-space-usage-on-xfs-with-quotas","#assembly_limiting-storage-space-usage-on-xfs-with-quotas_managing-file-systems",{"title":675,"visible":15,"weight":676,"urlFragment":677,"anchor":18,"singlePageAnchor":677,"sections":678,"docTitle":19,"url":719},"23. Limiting storage space usage on ext4 with quotas",25,"limiting-storage-space-usage-on-ext4-with-quotas_managing-file-systems",[679,683,687,691,695,699,703,707,711,715],{"title":680,"visible":15,"weight":16,"urlFragment":677,"anchor":681,"singlePageAnchor":681,"docTitle":19,"url":682},"23.1. Installing the quota tool","installing-quota-rpm_limiting-storage-space-usage-on-ext4-with-quotas","#installing-quota-rpm_limiting-storage-space-usage-on-ext4-with-quotas",{"title":684,"visible":15,"weight":23,"urlFragment":677,"anchor":685,"singlePageAnchor":685,"docTitle":19,"url":686},"23.2. Enabling quota feature on file system creation","enabling-quota-feature-in-file-system-creation_limiting-storage-space-usage-on-ext4-with-quotas","#enabling-quota-feature-in-file-system-creation_limiting-storage-space-usage-on-ext4-with-quotas",{"title":688,"visible":15,"weight":28,"urlFragment":677,"anchor":689,"singlePageAnchor":689,"docTitle":19,"url":690},"23.3. Enabling quota feature on existing file systems","enabling-quota-feature-on-existing-file-system_limiting-storage-space-usage-on-ext4-with-quotas","#enabling-quota-feature-on-existing-file-system_limiting-storage-space-usage-on-ext4-with-quotas",{"title":692,"visible":15,"weight":45,"urlFragment":677,"anchor":693,"singlePageAnchor":693,"docTitle":19,"url":694},"23.4. Enabling quota enforcement","enabling-quota-enforcement_limiting-storage-space-usage-on-ext4-with-quotas","#enabling-quota-enforcement_limiting-storage-space-usage-on-ext4-with-quotas",{"title":696,"visible":15,"weight":50,"urlFragment":677,"anchor":697,"singlePageAnchor":697,"docTitle":19,"url":698},"23.5. Assigning quotas per user","assigning-quotas-per-user_limiting-storage-space-usage-on-ext4-with-quotas","#assigning-quotas-per-user_limiting-storage-space-usage-on-ext4-with-quotas",{"title":700,"visible":15,"weight":55,"urlFragment":677,"anchor":701,"singlePageAnchor":701,"docTitle":19,"url":702},"23.6. Assigning quotas per group","assigning-quotas-per-group_limiting-storage-space-usage-on-ext4-with-quotas","#assigning-quotas-per-group_limiting-storage-space-usage-on-ext4-with-quotas",{"title":704,"visible":15,"weight":60,"urlFragment":677,"anchor":705,"singlePageAnchor":705,"docTitle":19,"url":706},"23.7. Assigning quotas per project","assigning-quotas-per-project_limiting-storage-space-usage-on-ext4-with-quotas","#assigning-quotas-per-project_limiting-storage-space-usage-on-ext4-with-quotas",{"title":708,"visible":15,"weight":65,"urlFragment":677,"anchor":709,"singlePageAnchor":709,"docTitle":19,"url":710},"23.8. Setting the grace period for soft limits","setting-the-grace-period-for-soft-limits_limiting-storage-space-usage-on-ext4-with-quotas","#setting-the-grace-period-for-soft-limits_limiting-storage-space-usage-on-ext4-with-quotas",{"title":712,"visible":15,"weight":70,"urlFragment":677,"anchor":713,"singlePageAnchor":713,"docTitle":19,"url":714},"23.9. Turning file system quotas off","turning-file-system-quotas-off_limiting-storage-space-usage-on-ext4-with-quotas","#turning-file-system-quotas-off_limiting-storage-space-usage-on-ext4-with-quotas",{"title":716,"visible":15,"weight":75,"urlFragment":677,"anchor":717,"singlePageAnchor":717,"docTitle":19,"url":718},"23.10. Reporting on disk quotas","reporting-on-disk-quotas_limiting-storage-space-usage-on-ext4-with-quotas","#reporting-on-disk-quotas_limiting-storage-space-usage-on-ext4-with-quotas","#limiting-storage-space-usage-on-ext4-with-quotas_managing-file-systems",{"title":721,"visible":15,"weight":722,"urlFragment":723,"anchor":18,"singlePageAnchor":723,"sections":724,"docTitle":19,"url":741},"24. Discarding unused blocks",26,"discarding-unused-blocks_managing-file-systems",[725,729,733,737],{"title":726,"visible":15,"weight":16,"urlFragment":723,"anchor":727,"singlePageAnchor":727,"docTitle":19,"url":728},"24.1. Types of block discard operations","types-of-block-discard-operations_discarding-unused-blocks","#types-of-block-discard-operations_discarding-unused-blocks",{"title":730,"visible":15,"weight":23,"urlFragment":723,"anchor":731,"singlePageAnchor":731,"docTitle":19,"url":732},"24.2. Performing batch block discard","performing-batch-block-discard_discarding-unused-blocks","#performing-batch-block-discard_discarding-unused-blocks",{"title":734,"visible":15,"weight":28,"urlFragment":723,"anchor":735,"singlePageAnchor":735,"docTitle":19,"url":736},"24.3. Enabling online block discard","enabling-online-block-discard_discarding-unused-blocks","#enabling-online-block-discard_discarding-unused-blocks",{"title":738,"visible":15,"weight":45,"urlFragment":723,"anchor":739,"singlePageAnchor":739,"docTitle":19,"url":740},"24.4. Enabling periodic block discard","enabling-periodic-block-discard_discarding-unused-blocks","#enabling-periodic-block-discard_discarding-unused-blocks","#discarding-unused-blocks_managing-file-systems",{"title":743,"visible":15,"weight":744,"urlFragment":745,"anchor":18,"singlePageAnchor":745,"sections":746,"docTitle":19,"url":827},"25. Setting up Stratis file systems",27,"setting-up-stratis-file-systems_managing-file-systems",[747,751,755,759,763,767,771,775,779,783,787,791,795,799,803,807,811,815,819,823],{"title":748,"visible":15,"weight":16,"urlFragment":745,"anchor":749,"singlePageAnchor":749,"docTitle":19,"url":750},"25.1. What is Stratis","the-purpose-and-features-of-stratis_setting-up-stratis-file-systems","#the-purpose-and-features-of-stratis_setting-up-stratis-file-systems",{"title":752,"visible":15,"weight":23,"urlFragment":745,"anchor":753,"singlePageAnchor":753,"docTitle":19,"url":754},"25.2. Components of a Stratis volume","components-of-a-stratis-volume_setting-up-stratis-file-systems","#components-of-a-stratis-volume_setting-up-stratis-file-systems",{"title":756,"visible":15,"weight":28,"urlFragment":745,"anchor":757,"singlePageAnchor":757,"docTitle":19,"url":758},"25.3. Block devices usable with Stratis","block-devices-usable-with-stratis_setting-up-stratis-file-systems","#block-devices-usable-with-stratis_setting-up-stratis-file-systems",{"title":760,"visible":15,"weight":45,"urlFragment":745,"anchor":761,"singlePageAnchor":761,"docTitle":19,"url":762},"25.4. Installing Stratis","installing-stratis_setting-up-stratis-file-systems","#installing-stratis_setting-up-stratis-file-systems",{"title":764,"visible":15,"weight":50,"urlFragment":745,"anchor":765,"singlePageAnchor":765,"docTitle":19,"url":766},"25.5. Creating an unencrypted Stratis pool","create-unencrypted-stratis-pool_setting-up-stratis-file-systems","#create-unencrypted-stratis-pool_setting-up-stratis-file-systems",{"title":768,"visible":15,"weight":55,"urlFragment":745,"anchor":769,"singlePageAnchor":769,"docTitle":19,"url":770},"25.6. Creating an unencrypted Stratis pool by using the web console","creating-an-unencrypted-stratis-pool-using-the-web-console_setting-up-stratis-file-systems","#creating-an-unencrypted-stratis-pool-using-the-web-console_setting-up-stratis-file-systems",{"title":772,"visible":15,"weight":60,"urlFragment":745,"anchor":773,"singlePageAnchor":773,"docTitle":19,"url":774},"25.7. Creating an encrypted Stratis pool","create-encrypted-stratis-pool_setting-up-stratis-file-systems","#create-encrypted-stratis-pool_setting-up-stratis-file-systems",{"title":776,"visible":15,"weight":65,"urlFragment":745,"anchor":777,"singlePageAnchor":777,"docTitle":19,"url":778},"25.8. Creating an encrypted Stratis pool by using the web console","creating-an-encrypted-stratis-pool-using-the-web-console_setting-up-stratis-file-systems","#creating-an-encrypted-stratis-pool-using-the-web-console_setting-up-stratis-file-systems",{"title":780,"visible":15,"weight":70,"urlFragment":745,"anchor":781,"singlePageAnchor":781,"docTitle":19,"url":782},"25.9. Renaming a Stratis pool by using the web console","renaming-a-stratis-pool-using-the-web-console_setting-up-stratis-file-systems","#renaming-a-stratis-pool-using-the-web-console_setting-up-stratis-file-systems",{"title":784,"visible":15,"weight":75,"urlFragment":745,"anchor":785,"singlePageAnchor":785,"docTitle":19,"url":786},"25.10. Setting overprovisioning mode in Stratis filesystem","proc_setting-overprovisioning-mode-in-stratis-fs_setting-up-stratis-file-systems","#proc_setting-overprovisioning-mode-in-stratis-fs_setting-up-stratis-file-systems",{"title":788,"visible":15,"weight":125,"urlFragment":745,"anchor":789,"singlePageAnchor":789,"docTitle":19,"url":790},"25.11. Binding a Stratis pool to NBDE","bind-stratis-pool-nbde_setting-up-stratis-file-systems","#bind-stratis-pool-nbde_setting-up-stratis-file-systems",{"title":792,"visible":15,"weight":130,"urlFragment":745,"anchor":793,"singlePageAnchor":793,"docTitle":19,"url":794},"25.12. Binding a Stratis pool to TPM","bind-stratis-pool-tpm_setting-up-stratis-file-systems","#bind-stratis-pool-tpm_setting-up-stratis-file-systems",{"title":796,"visible":15,"weight":135,"urlFragment":745,"anchor":797,"singlePageAnchor":797,"docTitle":19,"url":798},"25.13. Unlocking an encrypted Stratis pool with kernel keyring","unlock-encrypted-stratis-pool-keyring_setting-up-stratis-file-systems","#unlock-encrypted-stratis-pool-keyring_setting-up-stratis-file-systems",{"title":800,"visible":15,"weight":140,"urlFragment":745,"anchor":801,"singlePageAnchor":801,"docTitle":19,"url":802},"25.14. Unbinding a Stratis pool from supplementary encryption","unbind-encrypted-stratis-pool-from-supplementary-encryption_setting-up-stratis-file-systems","#unbind-encrypted-stratis-pool-from-supplementary-encryption_setting-up-stratis-file-systems",{"title":804,"visible":15,"weight":145,"urlFragment":745,"anchor":805,"singlePageAnchor":805,"docTitle":19,"url":806},"25.15. Starting and stopping Stratis pool","proc_starting-and-stopping-stratis-pool_setting-up-stratis-file-systems","#proc_starting-and-stopping-stratis-pool_setting-up-stratis-file-systems",{"title":808,"visible":15,"weight":438,"urlFragment":745,"anchor":809,"singlePageAnchor":809,"docTitle":19,"url":810},"25.16. Creating a Stratis file system","creating-a-stratis-file-system_setting-up-stratis-file-systems","#creating-a-stratis-file-system_setting-up-stratis-file-systems",{"title":812,"visible":15,"weight":464,"urlFragment":745,"anchor":813,"singlePageAnchor":813,"docTitle":19,"url":814},"25.17. Creating a file system on a Stratis pool by using the web console","creating-a-file-system-on-a-stratis-pool-using-the-web-console_setting-up-stratis-file-systems","#creating-a-file-system-on-a-stratis-pool-using-the-web-console_setting-up-stratis-file-systems",{"title":816,"visible":15,"weight":502,"urlFragment":745,"anchor":817,"singlePageAnchor":817,"docTitle":19,"url":818},"25.18. Mounting a Stratis file system","mounting-a-stratis-file-system_setting-up-stratis-file-systems","#mounting-a-stratis-file-system_setting-up-stratis-file-systems",{"title":820,"visible":15,"weight":536,"urlFragment":745,"anchor":821,"singlePageAnchor":821,"docTitle":19,"url":822},"25.19. Persistently mounting a Stratis file system","persistently-mounting-a-stratis-file-system_setting-up-stratis-file-systems","#persistently-mounting-a-stratis-file-system_setting-up-stratis-file-systems",{"title":824,"visible":15,"weight":562,"urlFragment":745,"anchor":825,"singlePageAnchor":825,"docTitle":19,"url":826},"25.20. Setting up non-root Stratis filesystems in /etc/fstab using a systemd service","proc_setting-up-non-root-stratis-fs-fstab-systemd_setting-up-stratis-file-systems","#proc_setting-up-non-root-stratis-fs-fstab-systemd_setting-up-stratis-file-systems","#setting-up-stratis-file-systems_managing-file-systems",{"title":829,"visible":15,"weight":830,"urlFragment":831,"anchor":18,"singlePageAnchor":831,"sections":832,"docTitle":19,"url":849},"26. Extending a Stratis volume with additional block devices",28,"extending-a-stratis-volume-with-additional-block-devices_managing-file-systems",[833,837,841,845],{"title":834,"visible":15,"weight":16,"urlFragment":831,"anchor":835,"singlePageAnchor":835,"docTitle":19,"url":836},"26.1. Components of a Stratis volume","components-of-a-stratis-volume_extending-a-stratis-volume-with-additional-block-devices","#components-of-a-stratis-volume_extending-a-stratis-volume-with-additional-block-devices",{"title":838,"visible":15,"weight":23,"urlFragment":831,"anchor":839,"singlePageAnchor":839,"docTitle":19,"url":840},"26.2. Adding block devices to a Stratis pool","adding-block-devices-to-a-stratis-pool_extending-a-stratis-volume-with-additional-block-devices","#adding-block-devices-to-a-stratis-pool_extending-a-stratis-volume-with-additional-block-devices",{"title":842,"visible":15,"weight":28,"urlFragment":831,"anchor":843,"singlePageAnchor":843,"docTitle":19,"url":844},"26.3. Adding a block device to a Stratis pool by using the web console","adding-a-block-device-to-a-stratis-pool-using-the-web-console_extending-a-stratis-volume-with-additional-block-devices","#adding-a-block-device-to-a-stratis-pool-using-the-web-console_extending-a-stratis-volume-with-additional-block-devices",{"title":846,"visible":15,"weight":45,"urlFragment":831,"anchor":847,"singlePageAnchor":847,"docTitle":19,"url":848},"26.4. Additional resources","additional_resources","#additional_resources","#extending-a-stratis-volume-with-additional-block-devices_managing-file-systems",{"title":851,"visible":15,"weight":852,"urlFragment":853,"anchor":18,"singlePageAnchor":853,"sections":854,"docTitle":19,"url":871},"27. Monitoring Stratis file systems",29,"monitoring-stratis-file-systems_managing-file-systems",[855,859,863,867],{"title":856,"visible":15,"weight":16,"urlFragment":853,"anchor":857,"singlePageAnchor":857,"docTitle":19,"url":858},"27.1. Stratis sizes reported by different utilities","stratis-sizes-reported-by-different-utilities_monitoring-stratis-file-systems","#stratis-sizes-reported-by-different-utilities_monitoring-stratis-file-systems",{"title":860,"visible":15,"weight":23,"urlFragment":853,"anchor":861,"singlePageAnchor":861,"docTitle":19,"url":862},"27.2. Displaying information about Stratis volumes","displaying-information-about-stratis-volumes_monitoring-stratis-file-systems","#displaying-information-about-stratis-volumes_monitoring-stratis-file-systems",{"title":864,"visible":15,"weight":28,"urlFragment":853,"anchor":865,"singlePageAnchor":865,"docTitle":19,"url":866},"27.3. Viewing a Stratis pool by using the web console","viewing-a-stratis-pool-using-the-web-console_monitoring-stratis-file-systems","#viewing-a-stratis-pool-using-the-web-console_monitoring-stratis-file-systems",{"title":868,"visible":15,"weight":45,"urlFragment":853,"anchor":869,"singlePageAnchor":869,"docTitle":19,"url":870},"27.4. Additional resources","additional_resources_2","#additional_resources_2","#monitoring-stratis-file-systems_managing-file-systems",{"title":873,"visible":15,"weight":874,"urlFragment":875,"anchor":18,"singlePageAnchor":875,"sections":876,"docTitle":19,"url":901},"28. Using snapshots on Stratis file systems",30,"using-snapshots-on-stratis-file-systems_managing-file-systems",[877,881,885,889,893,897],{"title":878,"visible":15,"weight":16,"urlFragment":875,"anchor":879,"singlePageAnchor":879,"docTitle":19,"url":880},"28.1. Characteristics of Stratis snapshots","characteristics-of-stratis-snapshots_using-snapshots-on-stratis-file-systems","#characteristics-of-stratis-snapshots_using-snapshots-on-stratis-file-systems",{"title":882,"visible":15,"weight":23,"urlFragment":875,"anchor":883,"singlePageAnchor":883,"docTitle":19,"url":884},"28.2. Creating a Stratis snapshot","creating-a-stratis-snapshot_using-snapshots-on-stratis-file-systems","#creating-a-stratis-snapshot_using-snapshots-on-stratis-file-systems",{"title":886,"visible":15,"weight":28,"urlFragment":875,"anchor":887,"singlePageAnchor":887,"docTitle":19,"url":888},"28.3. Accessing the content of a Stratis snapshot","accessing-the-content-of-a-stratis-snapshot_using-snapshots-on-stratis-file-systems","#accessing-the-content-of-a-stratis-snapshot_using-snapshots-on-stratis-file-systems",{"title":890,"visible":15,"weight":45,"urlFragment":875,"anchor":891,"singlePageAnchor":891,"docTitle":19,"url":892},"28.4. Reverting a Stratis file system to a previous snapshot","reverting-a-stratis-file-system-to-a-previous-snapshot_using-snapshots-on-stratis-file-systems","#reverting-a-stratis-file-system-to-a-previous-snapshot_using-snapshots-on-stratis-file-systems",{"title":894,"visible":15,"weight":50,"urlFragment":875,"anchor":895,"singlePageAnchor":895,"docTitle":19,"url":896},"28.5. Removing a Stratis snapshot","removing-a-stratis-snapshot_using-snapshots-on-stratis-file-systems","#removing-a-stratis-snapshot_using-snapshots-on-stratis-file-systems",{"title":898,"visible":15,"weight":55,"urlFragment":875,"anchor":899,"singlePageAnchor":899,"docTitle":19,"url":900},"28.6. Additional resources","additional_resources_3","#additional_resources_3","#using-snapshots-on-stratis-file-systems_managing-file-systems",{"title":903,"visible":15,"weight":904,"urlFragment":905,"anchor":18,"singlePageAnchor":905,"sections":906,"docTitle":19,"url":931},"29. Removing Stratis file systems",31,"removing-stratis-file-systems_managing-file-systems",[907,911,915,919,923,927],{"title":908,"visible":15,"weight":16,"urlFragment":905,"anchor":909,"singlePageAnchor":909,"docTitle":19,"url":910},"29.1. Components of a Stratis volume","components-of-a-stratis-volume_removing-stratis-file-systems","#components-of-a-stratis-volume_removing-stratis-file-systems",{"title":912,"visible":15,"weight":23,"urlFragment":905,"anchor":913,"singlePageAnchor":913,"docTitle":19,"url":914},"29.2. Removing a Stratis file system","removing-a-stratis-file-system_removing-stratis-file-systems","#removing-a-stratis-file-system_removing-stratis-file-systems",{"title":916,"visible":15,"weight":28,"urlFragment":905,"anchor":917,"singlePageAnchor":917,"docTitle":19,"url":918},"29.3. Deleting a file system from a Stratis pool by using the web console","deleting-a-file-system-from-a-stratis-pool-using-the-web-console_removing-stratis-file-systems","#deleting-a-file-system-from-a-stratis-pool-using-the-web-console_removing-stratis-file-systems",{"title":920,"visible":15,"weight":45,"urlFragment":905,"anchor":921,"singlePageAnchor":921,"docTitle":19,"url":922},"29.4. Removing a Stratis pool","removing-a-stratis-pool_removing-stratis-file-systems","#removing-a-stratis-pool_removing-stratis-file-systems",{"title":924,"visible":15,"weight":50,"urlFragment":905,"anchor":925,"singlePageAnchor":925,"docTitle":19,"url":926},"29.5. Deleting a Stratis pool by using the web console","deleting-a-stratis-pool-using-the-web-console_removing-stratis-file-systems","#deleting-a-stratis-pool-using-the-web-console_removing-stratis-file-systems",{"title":928,"visible":15,"weight":55,"urlFragment":905,"anchor":929,"singlePageAnchor":929,"docTitle":19,"url":930},"29.6. Additional resources","additional_resources_4","#additional_resources_4","#removing-stratis-file-systems_managing-file-systems",{"title":933,"visible":15,"weight":934,"urlFragment":935,"anchor":18,"singlePageAnchor":935,"sections":936,"docTitle":19,"url":957},"30. Getting started with an ext4 file system",32,"getting-started-with-an-ext4-file-system_managing-file-systems",[937,941,945,949,953],{"title":938,"visible":15,"weight":16,"urlFragment":935,"anchor":939,"singlePageAnchor":939,"docTitle":19,"url":940},"30.1. Features of an ext4 file system","features-of-an-ext4-file-system_getting-started-with-an-ext4-file-system","#features-of-an-ext4-file-system_getting-started-with-an-ext4-file-system",{"title":942,"visible":15,"weight":23,"urlFragment":935,"anchor":943,"singlePageAnchor":943,"docTitle":19,"url":944},"30.2. Creating an ext4 file system","creating-an-ext4-file-system_getting-started-with-an-ext4-file-system","#creating-an-ext4-file-system_getting-started-with-an-ext4-file-system",{"title":946,"visible":15,"weight":28,"urlFragment":935,"anchor":947,"singlePageAnchor":947,"docTitle":19,"url":948},"30.3. Mounting an ext4 file system","mounting-an-ext4-file-system_getting-started-with-an-ext4-file-system","#mounting-an-ext4-file-system_getting-started-with-an-ext4-file-system",{"title":950,"visible":15,"weight":45,"urlFragment":935,"anchor":951,"singlePageAnchor":951,"docTitle":19,"url":952},"30.4. Resizing an ext4 file system","resizing-an-ext4-file-system_getting-started-with-an-ext4-file-system","#resizing-an-ext4-file-system_getting-started-with-an-ext4-file-system",{"title":954,"visible":15,"weight":50,"urlFragment":935,"anchor":955,"singlePageAnchor":955,"docTitle":19,"url":956},"30.5. Comparison of tools used with ext4 and XFS","comparison-of-tools-used-with-ext4-and-xfs_getting-started-with-an-ext4-file-system","#comparison-of-tools-used-with-ext4-and-xfs_getting-started-with-an-ext4-file-system","#getting-started-with-an-ext4-file-system_managing-file-systems",{"title":959,"visible":15,"weight":960,"urlFragment":961,"anchor":18,"singlePageAnchor":962,"docTitle":19,"url":963},"Legal Notice",33,"legal-notice","idm139822467588976","#idm139822467588976",[965,968,971],{"text":966,"link":967},"Red Hat Enterprise Linux","/documentation/red_hat_enterprise_linux/",{"text":969,"link":970},"9","/documentation/red_hat_enterprise_linux/9/",{"text":11},{"name":11,"translations":973,"productVersion":974,"singlePage":975,"pdf":978,"publishingStatus":980},[5,6,7,8,9],{"name":969},{"contentUrl":976,"name":11,"new":977,"url":19},"https://d2bhdhkti9t3uj.cloudfront.net/html/82cda189-15fb-4a5b-98df-0b04a8bb4c23/97a838983dd776efa0fa4260a70634a7.html","https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html-single/managing_file_systems/index",{"url":979},"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/pdf/managing_file_systems/Red_Hat_Enterprise_Linux-9-Managing_file_systems-en-US.pdf","PUBLISHED",[982,987,990,994,998,1002,1006],{"name":983,"new":984,"url":985,"urlAliases":986},"10.0-Beta","https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/10-beta","10-beta",[],{"name":969,"new":988,"url":969,"urlAliases":989},"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9",[],{"name":991,"new":992,"url":991,"urlAliases":993},"8","https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/8",[],{"name":995,"new":996,"url":995,"urlAliases":997},"7","https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/7",[],{"name":999,"new":1000,"url":999,"urlAliases":1001},"6","https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/6",[],{"name":1003,"new":1004,"url":1003,"urlAliases":1005},"5","https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/5",[],{"name":1007,"new":1008,"url":1007,"urlAliases":1009},"4","https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/4",[],{"managing_file_systems/index":1011,"managing_file_systems/proc_providing-feedback-on-red-hat-documentation_managing-file-systems":1012,"managing_file_systems/overview-of-available-file-systems_managing-file-systems":1013,"managing_file_systems/managing-local-storage-using-rhel-system-roles_managing-file-systems":1014,"managing_file_systems/managing-partitions-using-the-web-console_managing-file-systems":1015,"managing_file_systems/mounting-nfs-shares_managing-file-systems":1016,"managing_file_systems/mounting-an-smb-share-on-red-hat-enterprise-linux_managing-file-systems":1017,"managing_file_systems/assembly_overview-of-persistent-naming-attributes_managing-file-systems":1018,"managing_file_systems/partition-operations-with-parted_managing-file-systems":1019,"managing_file_systems/strategies-for-repartitioning-a-disk_managing-file-systems":1020,"managing_file_systems/getting-started-with-xfs_managing-file-systems":1021,"managing_file_systems/assembly_creating-an-xfs-file-system_managing-file-systems":1022,"managing_file_systems/backing-up-an-xfs-file-system_managing-file-systems":1023,"managing_file_systems/restoring-an-xfs-file-system-from-backup_managing-file-systems":1024,"managing_file_systems/increasing-the-size-of-an-xfs-file-system_managing-file-systems":1025,"managing_file_systems/configuring-xfs-error-behavior_managing-file-systems":1026,"managing_file_systems/checking-and-repairing-a-file-system__managing-file-systems":1027,"managing_file_systems/mounting-file-systems_managing-file-systems":1028,"managing_file_systems/sharing-a-mount-on-multiple-mount-points_managing-file-systems":1029,"managing_file_systems/assembly_persistently-mounting-file-systems_managing-file-systems":1030,"managing_file_systems/mounting-file-systems-on-demand_managing-file-systems":1031,"managing_file_systems/using-sssd-component-from-idm-to-cache-the-autofs-map_managing-file-systems":1032,"managing_file_systems/setting-read-only-permissions-for-the-root-file-system_managing-file-systems":1033,"managing_file_systems/assembly_limiting-storage-space-usage-on-xfs-with-quotas_managing-file-systems":1034,"managing_file_systems/limiting-storage-space-usage-on-ext4-with-quotas_managing-file-systems":1035,"managing_file_systems/discarding-unused-blocks_managing-file-systems":1036,"managing_file_systems/setting-up-stratis-file-systems_managing-file-systems":1037,"managing_file_systems/extending-a-stratis-volume-with-additional-block-devices_managing-file-systems":1038,"managing_file_systems/monitoring-stratis-file-systems_managing-file-systems":1039,"managing_file_systems/using-snapshots-on-stratis-file-systems_managing-file-systems":1040,"managing_file_systems/removing-stratis-file-systems_managing-file-systems":1041,"managing_file_systems/getting-started-with-an-ext4-file-system_managing-file-systems":1042,"managing_file_systems/legal-notice":1043},{"prevt":18,"next":24},{"prevt":17,"next":29},{"prevt":18,"next":29},{"prevt":18,"next":81},{"prevt":18,"next":151},{"prevt":18,"next":168},{"prevt":18,"next":238},{"prevt":18,"next":284},{"prevt":18,"next":326},{"prevt":18,"next":351},{"prevt":18,"next":377},{"prevt":18,"next":18},{"prevt":18,"next":399},{"prevt":18,"next":412},{"prevt":18,"next":18},{"prevt":18,"next":439},{"prevt":18,"next":465},{"prevt":18,"next":503},{"prevt":18,"next":537},{"prevt":18,"next":563},{"prevt":18,"next":577},{"prevt":18,"next":615},{"prevt":18,"next":629},{"prevt":18,"next":643},{"prevt":18,"next":677},{"prevt":18,"next":723},{"prevt":18,"next":745},{"prevt":18,"next":831},{"prevt":18,"next":853},{"prevt":18,"next":875},{"prevt":18,"next":905},{"prevt":18,"next":935},{"prevt":935,"next":18},{"product":18,"version":18},{"managing_file_systems":1046},[977],{"products":1048},[1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061],"builds_for_red_hat_openshift","migration_toolkit_for_virtualization","openshift_container_platform","openshift_sandboxed_containers","red_hat_advanced_cluster_security_for_kubernetes","red_hat_advanced_cluster_management_for_kubernetes","red_hat_openshift_data_foundation","red_hat_openshift_dev_spaces","red_hat_openshift_gitops","red_hat_openshift_local","red_hat_openshift_pipelines","red_hat_openshift_serverless","workload_availability_for_red_hat_openshift",[],{"default":1064},[1065,1074,1080,1089,1097,1105,1112,1120,1127],{"nid":1066,"type":1067,"langcode":1068,"Published":16,"title":1069,"Created":1070,"Updated":1071,"body_value":18,"field_documentation banner_text_value":18,"field_documentation banner_text_format":18,"field_paths_value":1072,"field_documentation_training_url_uri":18,"field_title_title_id":18,"field_rebrand banner_link_uri":1073},580,"rebrand banner","en","OpenShift Container Storage is now OpenShift Data Foundation starting with version 4.9.","2023-01-11 15:38:32","2023-01-11 15:40:04","/documentation/red_hat_openshift_container_storage\r\n/documentation/red_hat_openshift_container_storage/\r\n/documentation/red_hat_openshift_container_storage/*","internal:/documentation/red_hat_openshift_data_foundation/",{"nid":1075,"type":1067,"langcode":1068,"Published":16,"title":1069,"Created":1076,"Updated":1077,"body_value":18,"field_documentation banner_text_value":18,"field_documentation banner_text_format":18,"field_paths_value":1078,"field_documentation_training_url_uri":18,"field_title_title_id":18,"field_rebrand banner_link_uri":1079},581,"2023-01-11 15:41:31","2023-01-11 15:42:04","/documentation/red_hat_openshift_data_foundation/4.9\r\n/documentation/red_hat_openshift_data_foundation/4.9/\r\n/documentation/red_hat_openshift_data_foundation/4.9/*\r\n/documentation/red_hat_openshift_data_foundation/4.10\r\n/documentation/red_hat_openshift_data_foundation/4.10/\r\n/documentation/red_hat_openshift_data_foundation/4.10/*\r\n/documentation/red_hat_openshift_data_foundation/4.11\r\n/documentation/red_hat_openshift_data_foundation/4.11/\r\n/documentation/red_hat_openshift_data_foundation/4.11/*","internal:/documentation/red_hat_openshift_container_storage/",{"nid":1081,"type":1082,"langcode":1068,"Published":16,"title":1083,"Created":1084,"Updated":1085,"body_value":18,"field_documentation banner_text_value":1086,"field_documentation banner_text_format":1087,"field_paths_value":1088,"field_documentation_training_url_uri":18,"field_title_title_id":18,"field_rebrand banner_link_uri":18},582,"developer preview banner","MicroShift is Developer Preview software only","2023-01-11 15:50:24","2023-01-30 19:00:52","\u003Cp slot=header>MicroShift is Developer Preview software only.\u003C/p>For more information about the support scope of Red Hat Developer Preview software, see \u003Ca href=\"https://access.redhat.com/support/offerings/devpreview/\">Developer Preview Support Scope\u003C/a>.","documentation banner","/documentation/microshift/4.12\r\n/documentation/microshift/4.12/*\r\n/documentation/red_hat_build_of_microshift/4.12\r\n/documentation/red_hat_build_of_microshift/4.12/*",{"nid":1090,"type":1091,"langcode":1068,"Published":16,"title":1092,"Created":1093,"Updated":1094,"body_value":18,"field_documentation banner_text_value":1095,"field_documentation banner_text_format":1087,"field_paths_value":1096,"field_documentation_training_url_uri":18,"field_title_title_id":18,"field_rebrand banner_link_uri":18},583,"obsolete documentation banner","RHACS EOL - DAT-3433","2023-01-23 16:36:43","2023-01-23 16:39:14","\u003Cp slot=header>You are viewing documentation for a release that is no longer maintained. To view the documentation for the most recent version, see the \u003Ca href=\"/documentation/red_hat_advanced_cluster_security_for_kubernetes/\">latest RHACS docs\u003C/a>.\u003C/p>","/documentation/red_hat_advanced_cluster_security_for_kubernetes/3.69\r\n/documentation/red_hat_advanced_cluster_security_for_kubernetes/3.69/*\r\n/documentation/red_hat_advanced_cluster_security_for_kubernetes/3.70\r\n/documentation/red_hat_advanced_cluster_security_for_kubernetes/3.70/*\r\n/documentation/red_hat_advanced_cluster_security_for_kubernetes/3.71\r\n/documentation/red_hat_advanced_cluster_security_for_kubernetes/3.71/*",{"nid":1098,"type":1099,"langcode":1068,"Published":16,"title":1100,"Created":1101,"Updated":1102,"body_value":18,"field_documentation banner_text_value":1103,"field_documentation banner_text_format":1087,"field_paths_value":1104,"field_documentation_training_url_uri":18,"field_title_title_id":18,"field_rebrand banner_link_uri":18},584,"end of life banner","EOL banner for RHV","2023-05-23 14:58:05","2023-05-24 15:19:42","\u003Cp slot=header>The Red Hat Virtualization\u003C/p>Maintenance Phase runs until August 31, 2024, followed by the Extended Life Phase with no more software fixes through August 31, 2026. See \u003Ca href=\"https://access.redhat.com/articles/6975303\">Migration Paths for OpenShift Container Platform deployed on Red Hat Virtualization\u003C/a> for details.","/documentation/red_hat_virtualization/4.4",{"nid":1106,"type":1099,"langcode":1068,"Published":16,"title":1107,"Created":1108,"Updated":1109,"body_value":18,"field_documentation banner_text_value":1110,"field_documentation banner_text_format":1087,"field_paths_value":1111,"field_documentation_training_url_uri":18,"field_title_title_id":18,"field_rebrand banner_link_uri":18},585,"RHHI-V EOL","2023-06-01 16:52:57","2023-06-01 17:03:44","\u003Cp slot=header>Red Hat Hyperconverged Infrastructure for Virtualization\u003C/p> is in the \u003Ca href=\"https://access.redhat.com/support/policy/updates/rhhiv\">Maintenance Support Phase\u003C/a> of its lifecycle until October 31, 2024. After that date, the product will be End of Life. See the \u003Ca href=\"https://access.redhat.com/announcements/6972521\">RHHI-V announcement\u003C/a> for next steps.","/documentation/red_hat_hyperconverged_infrastructure_for_virtualization/1.8",{"nid":1113,"type":1114,"langcode":1068,"Published":16,"title":1115,"Created":1116,"Updated":1117,"body_value":18,"field_documentation banner_text_value":1118,"field_documentation banner_text_format":1087,"field_paths_value":1119,"field_documentation_training_url_uri":18,"field_title_title_id":18,"field_rebrand banner_link_uri":18},586,"preview banner","MicroShift is Technology Preview software only","2024-03-18 16:53:05","2024-03-18 16:54:56","\u003Cp slot=header>MicroShift is Technology Preview software only.\u003C/p>For more information about the support scope of Red Hat Technology Preview software, see \u003Ca href=\"https://access.redhat.com/support/offerings/techpreview/\">Technology Preview Support Scope\u003C/a>.","/documentation/red_hat_build_of_microshift/4.13\r\n/documentation/red_hat_build_of_microshift/4.13/*",{"nid":1121,"type":1114,"langcode":1068,"Published":16,"title":1122,"Created":1123,"Updated":1124,"body_value":18,"field_documentation banner_text_value":1125,"field_documentation banner_text_format":1087,"field_paths_value":1126,"field_documentation_training_url_uri":18,"field_title_title_id":18,"field_rebrand banner_link_uri":18},588,"Ansible 2.5 upgrade limitation","2024-09-30 16:53:05","2024-10-28 16:54:56","\u003Cp slot=\"header\">Support added for upgrades from 2.4\u003C/p>Ansible Automation Platform 2.5-3, released on October 28, 2024, adds support for upgrades from 2.4. See the upgrade documentation for more information.","",{"nid":1128,"alertType":1129,"type":1130,"langcode":1068,"Published":16,"title":1131,"Created":1126,"Updated":1126,"body_value":18,"field_documentation banner_text_value":1132,"field_documentation banner_text_format":1087,"field_paths_value":1133,"field_documentation_training_url_uri":18,"field_title_title_id":18,"field_rebrand banner_link_uri":18},587,"warning","Warning banner","Red Hat build of Apache Camel K","\u003Cp slot=header>Red Hat Camel K is deprecated\u003C/p>Red Hat Camel K is deprecated and the End of Life date for this product is June 30, 2025. For help migrating to the current go-to solution, \u003Ca target=_blank href=\"https://docs.redhat.com/en/documentation/red_hat_build_of_apache_camel\">Red Hat build of Apache Camel\u003C/a>, see the \u003Ca target=_blank href=\"https://docs.redhat.com/en/documentation/red_hat_build_of_apache_camel_k/1.10.7/html/migration_guide_camel_k_to_camel_extensions_for_quarkus/index\">Migration Guide\u003C/a>.","/documentation/red_hat_build_of_apache_camel_k/*",{"product":966},["Reactive",1136],{"$snuxt-i18n-meta":1137,"$sisLoading":1138,"$sisSinglePage":15,"$sisInFocusMode":1138,"$smobileTocOpen":1138,"$sisLargeTOC":1138,"$scurrentChapter":17,"$scurrentSection":17,"$scurrentSubSection":1126},{},false,["Set"],["ShallowReactive",1141],{"s8LoCEfG4A":18,"rFVLKcOK8e":18,"uUstF4AIyn":18,"MdHNSZP4nR":18,"Pn02PlJOas":18},"/en/documentation/red_hat_enterprise_linux/9/html-single/managing_file_systems/index"]</script>
<script>window.__NUXT__={};window.__NUXT__.config={public:{contentEnv:"",collectFeedback:true,i18n:{baseUrl:"",defaultLocale:"en",defaultDirection:"ltr",strategy:"prefix",lazy:false,rootRedirect:"",routesNameSeparator:"___",defaultLocaleRouteNameSuffix:"default",skipSettingLocaleOnNavigate:false,differentDomains:false,trailingSlash:false,configLocales:[{code:"en",name:"English",iso:"en-US"},{code:"fr",name:"Français",iso:"fr-FR"},{code:"ko",name:"한국어",iso:"ko-KR"},{code:"ja",name:"日本語",iso:"ja-JP"},{code:"zh-cn",name:"中文 (中国)",iso:"zh-CN"},{code:"de",name:"Deutsch",iso:"de_DE"},{code:"it",name:"Italiano",iso:"it_IT"},{code:"pt-br",name:"Português",iso:"pt_BR"},{code:"es",name:"Español",iso:"es-ES"}],locales:{en:{domain:""},fr:{domain:""},ko:{domain:""},ja:{domain:""},"zh-cn":{domain:""},de:{domain:""},it:{domain:""},"pt-br":{domain:""},es:{domain:""}},detectBrowserLanguage:{alwaysRedirect:false,cookieCrossOrigin:false,cookieDomain:"",cookieKey:"i18n_redirected",cookieSecure:false,fallbackLocale:"",redirectOn:"root",useCookie:true},experimental:{localeDetector:"",switchLocalePathLinkSSR:false,autoImportTranslationFunctions:false}}},app:{baseURL:"/",buildId:"5ff82c51-785e-4a7d-aca6-77d6692e8c7a",buildAssetsDir:"/_nuxt/",cdnURL:""}}</script></body></html>
