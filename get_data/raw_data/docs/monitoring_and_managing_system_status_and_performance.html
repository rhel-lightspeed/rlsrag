<!DOCTYPE html><html  data-capo=""><head><script type="importmap">
  {
    "imports": {
      "@patternfly/elements/": "/scripts/v1/@patternfly/elements/",
      "@patternfly/pfe-clipboard/": "/scripts/v1/@patternfly/pfe-clipboard/",
      "@rhds/elements/": "/scripts/v1/@rhds/elements/elements/",
      "@cpelements/elements/": "/scripts/v1/@cpelements/elements/elements/"
    },
    "scopes": {
      "/": {
        "@floating-ui/core": "/scripts/v1/@floating-ui/core/dist/floating-ui.core.mjs",
        "@floating-ui/dom": "/scripts/v1/@floating-ui/dom/dist/floating-ui.dom.mjs",
        "@floating-ui/utils": "/scripts/v1/@floating-ui/utils/dist/floating-ui.utils.mjs",
        "@floating-ui/utils/dom": "/scripts/v1/@floating-ui/utils/dom/dist/floating-ui.utils.dom.mjs",
        "@lit/reactive-element": "/scripts/v1/@lit/reactive-element/reactive-element.js",
        "@lit/reactive-element/decorators/": "/scripts/v1/@lit/reactive-element/decorators/",
        "@patternfly/pfe-core": "/scripts/v1/@patternfly/pfe-core/core.js",
        "@patternfly/pfe-core/": "/scripts/v1/@patternfly/pfe-core/",
        "@rhds/tokens/media.js": "/scripts/v1/@rhds/tokens/js/media.js",
        "lit": "/scripts/v1/lit/index.js",
        "lit-element/lit-element.js": "/scripts/v1/lit-element/lit-element.js",
        "lit-html": "/scripts/v1/lit-html/lit-html.js",
        "lit-html/": "/scripts/v1/lit-html/",
        "lit/": "/scripts/v1/lit/",
        "tslib": "/scripts/v1/tslib/tslib.es6.mjs",
        "@cpelements/rh-table/dist/rh-table.js": "/scripts/v1/@cpelements/rh-table/dist/rh-table.js"
      }
    }
  }
</script><meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Monitoring and managing system status and performance | Red Hat Product Documentation</title>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<script type="text/javascript" id="trustarc" src="//static.redhat.com/libs/redhat/marketing/latest/trustarc/trustarc.js"></script>
<script src="//www.redhat.com/dtm.js"></script>
<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Red+Hat+Display:wght@400;500;700&family=Red+Hat+Text:wght@400;500;700&display=swap">
<link rel="stylesheet" href="/styles/rh-table--lightdom.min.css">
<style>.section .titlepage{gap:.75rem}.section .titlepage,div.edit{align-items:center;display:flex}div.edit{font-size:.9rem;margin-bottom:8px}div.edit>a{align-items:center;display:flex}.edit pf-icon{margin-right:4px}</style>
<style>#error[data-v-df31ff14]{align-items:center;display:flex;flex-direction:column;justify-content:center;min-height:80vh}h1[data-v-df31ff14]{font-size:calc(var(--rh-font-size-body-text-md, 1rem)*4);font-weight:700;margin-bottom:0}h1[data-v-df31ff14],h1 span[data-v-df31ff14]{line-height:var(--rh-line-height-heading,1.3)}h1 span[data-v-df31ff14]{color:var(--rh-color-text-brand-on-light,#e00);display:block;text-transform:uppercase}h1 span[data-v-df31ff14],p[data-v-df31ff14]{font-size:var(--rh-font-size-body-text-lg,1.125rem)}aside[data-v-df31ff14]{align-items:center;background:var(--rh-color-surface-lightest,#fff);border:var(--rh-border-width-sm,1px) solid var(--rh-color-border-subtle-on-light,#c7c7c7);border-radius:var(--rh-border-radius-default,3px);border-top:calc(var(--rh-border-width-md, 2px)*2) solid var(--rh-color-text-brand-on-light,#e00);box-shadow:var(--rh-box-shadow-sm,0 2px 4px 0 hsla(0,0%,8%,.2));display:flex;flex-direction:column;justify-content:space-between;margin-top:var(--rh-space-2xl,32px);padding:var(--rh-space-xl,24px)}aside[data-v-df31ff14],aside>div[data-v-df31ff14]{width:100%}.text-container[data-v-df31ff14]{margin:auto;max-width:442px;text-align:center}.desktop[data-v-df31ff14]{display:none}.sr-only[data-v-df31ff14]{height:1px;overflow:hidden;padding:0;position:absolute;width:1px;clip:rect(0,0,0,0);border:0;clip-path:inset(50%);white-space:nowrap}form[data-v-df31ff14]{display:flex}button[data-v-df31ff14],input[data-v-df31ff14]{border:1px solid var(--rh-color-black-500,#8a8d90);box-sizing:border-box;height:40px}input[data-v-df31ff14]{border-right:none;flex:1;font-family:var(--rh-font-family-heading,RedHatDisplay,"Red Hat Display","Noto Sans Arabic","Noto Sans Hebrew","Noto Sans JP","Noto Sans KR","Noto Sans Malayalam","Noto Sans SC","Noto Sans TC","Noto Sans Thai",Helvetica,Arial,sans-serif);font-size:var(--rh-font-size-body-text-md,1rem);padding-left:var(--rh-space-md,8px);width:100%}button[data-v-df31ff14]{-webkit-appearance:none;-moz-appearance:none;appearance:none;background:transparent;border-left:none;display:flex;width:var(--rh-size-icon-04,40px)}button[data-v-df31ff14]:before{background:var(--rh-context-light-color-text-link,#06c);content:"";cursor:pointer;display:block;height:28px;margin:auto;width:28px}.search-icon[data-v-df31ff14]{margin:auto}ul[data-v-df31ff14]{max-width:275px;padding:0}ul li[data-v-df31ff14]{display:inline-block;list-style:none;margin-right:var(--rh-space-xl,24px);padding:var(--rh-space-xs,4px) 0}ul li a[data-v-df31ff14]{color:var(--rh-context-light-color-text-link,#06c);text-decoration:none}@media (min-width:992px){aside[data-v-df31ff14]{flex-direction:row}.mobile[data-v-df31ff14]{display:none}.desktop[data-v-df31ff14]{display:block}input[data-v-df31ff14]{width:auto}}</style>
<style>@keyframes fade-in{0%{opacity:0;visibility:hidden}1%{visibility:visible}to{opacity:1;visibility:visible}}@media (min-height:48em){.rhdocs{--rh-table--maxHeight:calc(100vh - 12.5rem)}}*,.rhdocs *,.rhdocs :after,.rhdocs :before,:after,:before{box-sizing:border-box}.rhdocs img,.rhdocs object,.rhdocs svg,img,object,svg{display:inline-block;max-width:100%;vertical-align:middle}.rhdocs hr{border:0;border-top:.0625rem solid #d2d2d2;clear:both;margin:1rem 0}.rhdocs a{color:#06c;text-decoration:underline}.rhdocs a:focus,.rhdocs a:hover{color:#036}.rhdocs a.anchor-heading{color:#151515;cursor:pointer;text-decoration:none;word-break:break-all}.rhdocs p{margin:1.49963rem 0}.rhdocs li>p{margin:0}.rhdocs h1,.rhdocs h2,.rhdocs h3,.rhdocs h4,.rhdocs h5,.rhdocs h6{font-family:RedHatDisplay,Red Hat Display,Helvetica Neue,Arial,sans-serif;font-weight:500;margin:0 0 .625rem}.rhdocs h1{font-size:2.25rem;margin:2rem 0}.rhdocs h2{font-size:1.625rem;margin:2rem 0}.rhdocs h3{font-size:1.5rem;font-weight:400}.rhdocs h4,.rhdocs h5{font-size:1.25rem}.rhdocs h5{font-weight:400}.rhdocs h6{font-size:1.125rem;font-weight:500;line-height:1.6667}.rhdocs ol,.rhdocs ul{margin:1rem 0;padding:0 0 0 1.5rem}.rhdocs ol ::marker,.rhdocs ul ::marker{font:inherit}.rhdocs li{margin:0 0 .5em;padding:0}.rhdocs li>p{margin:.5rem 0}.rhdocs li>ol,.rhdocs li>ul{margin:0}.rhdocs dl dd{margin:.5rem 0 .5rem 1rem}.rhdocs dl dd>p{margin:.5rem 0}.rhdocs .informaltable,.rhdocs .table-contents,.rhdocs .table-wrapper{max-height:var(--rh-table--maxHeight);overflow:auto}.rhdocs table{border:0;font-size:1rem;line-height:1.6667;table-layout:fixed}.rhdocs table caption{color:#585858;margin-bottom:.5rem;margin-top:.5rem;text-align:left}.rhdocs table td,.rhdocs table th{border:0;border-bottom:.0625rem solid #d2d2d2;border-bottom:.0625rem solid var(--pfe-table--Border,#d2d2d2);padding:.5em 1rem}.rhdocs table td.halign-left,.rhdocs table th.halign-left{text-align:left}.rhdocs table td.halign-center,.rhdocs table th.halign-center,table td.halign-center,table th.halign-center{text-align:center}.rhdocs table td.halign-right,.rhdocs table th.halign-right{text-align:right}.rhdocs table td.valign-top,.rhdocs table th.valign-top{vertical-align:top}.rhdocs table td.valign-middle,.rhdocs table th.valign-middle{vertical-align:middle}.rhdocs table td.valign-bottom,.rhdocs table th.valign-bottom{vertical-align:bottom}.rhdocs table thead td,.rhdocs table thead th{background:#f5f5f5;font-weight:600}.rhdocs rh-table table,.rhdocs rh-table.rh-table--expanded-vertically{max-height:-moz-max-content;max-height:max-content}.rhdocs pre.nowrap{overflow:auto;overflow-wrap:normal;white-space:pre;word-break:normal}.rhdocs .codeblock__wrapper pre{background:transparent}.rh-table--full-screen code,.rhdocs .content--md code,.rhdocs .content--sm code,.rhdocs .rh-table--full-screen code{overflow-wrap:normal;word-break:normal}.rhdocs[class] pre code,[class] pre code{background:inherit;color:inherit;font-family:inherit;font-size:inherit;font-weight:inherit;line-height:inherit;padding:0}.rhdocs .keycap,.rhdocs kbd{background-color:#eee;background-image:linear-gradient(180deg,#ddd,#eee,#fff);border-radius:.1875rem;box-shadow:0 -.0625rem 0 0 #fff,0 .0625rem 0 .1875rem #aaa;font-family:RedHatMono,Red Hat Mono,Consolas,monospace;font-size:90%;font-weight:400;margin:0 .25rem;padding:.125rem .375rem}.keycap strong,.rhdocs .keycap strong{font-weight:inherit}.rhdocs kbd.keyseq,kbd.keyseq{background:transparent;border:0;box-shadow:none;padding:0}.rhdocs kbd.keyseq kbd,kbd.keyseq kbd{display:inline-block;margin:0 .375rem}.rhdocs kbd.keyseq kbd:first-child,kbd.keyseq kbd:first-child{margin-left:0}.rhdocs b.button{font-size:90%;font-weight:700;padding:.1875rem}.rhdocs b.button:before{content:"["}.rhdocs b.button:after{content:"]"}html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}.rhdocs audio,.rhdocs canvas,.rhdocs progress,.rhdocs video{display:inline-block;vertical-align:baseline}.rhdocs audio:not([controls]){display:none;height:0}[hidden],template{display:none}.rhdocs a{background:transparent}.rhdocs a:active,.rhdocs a:hover{outline:0}.rhdocs a.anchor-heading:hover:before{color:#151515;content:"#";margin-left:-1.6rem;position:absolute}.rhdocs a.anchor-heading:focus-visible{color:#151515}@media screen and (max-width:990px){.rhdocs a.anchor-heading:hover:before{font-size:16px;margin-left:-1rem;padding-top:8px}.rhdocs h1 a.anchor-heading:hover:before{padding-top:12px}.rhdocs h4 a.anchor-heading:hover:before,.rhdocs h5 a.anchor-heading:hover:before{padding-top:4px}.rhdocs h6 a.anchor-heading:hover:before{padding-top:2px}}.rhdocs abbr[title]{border-bottom:.0625rem dotted}.rhdocs dfn{font-style:italic}.rhdocs h1{font-size:2em;margin:.67em 0}.rhdocs mark{background:#ff0;color:#000}.rhdocs small{font-size:80%}.rhdocs sub,.rhdocs sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}.rhdocs sup{top:-.5em}.rhdocs sub{bottom:-.25em}.rhdocs img{border:0}.rhdocs svg:not(:root){overflow:hidden}.rhdocs figure{margin:1em 2.5rem}.rhdocs hr{box-sizing:content-box;height:0}.rhdocs code,.rhdocs kbd,.rhdocs pre,.rhdocs samp{font-family:monospace,monospace;font-size:1em}.rhdocs button,.rhdocs optgroup,.rhdocs select,.rhdocs textarea,.rhdocsinput{color:inherit;font:inherit;margin:0}.rhdocs button.copy-link-btn{background:none;border:2px solid #fff;font:1px Red Hat Text}.rhdocs button.copy-link-btn:hover{border-bottom:2px solid #06c}.rhdocs button.copy-link-btn .link-icon{padding-bottom:4px}.rhdocs button{overflow:visible}.rhdocs button,.rhdocs select{text-transform:none}.rhdocs button,.rhdocs html input[type=button],.rhdocs input[type=reset],.rhdocs input[type=submit]{-moz-appearance:button;appearance:button;-webkit-appearance:button;cursor:pointer}.rhdocs button[disabled],.rhdocs html input[disabled]{cursor:default}.rhdocs button::-moz-focus-inner,.rhdocs input::-moz-focus-inner{border:0;padding:0}.rhdocs input{line-height:normal}.rhdocs input[type=checkbox],.rhdocs input[type=radio]{box-sizing:border-box;padding:0}.rhdocs input[type=number]::-webkit-inner-spin-button,.rhdocs input[type=number]::-webkit-outer-spin-button{height:auto}.rhdocs input[type=search]{-moz-appearance:textfield;appearance:textfield;-webkit-appearance:textfield;box-sizing:content-box}.rhdocs input[type=search]::-webkit-search-cancel-button,.rhdocs input[type=search]::-webkit-search-decoration{-webkit-appearance:none}.rhdocs fieldset{border:.0625rem solid silver;margin:0 .125rem;padding:.35em .625em .75em}.rhdocs legend{border:0;padding:0}.rhdocs textarea{overflow:auto}.rhdocs optgroup{font-weight:700}.rhdocs table{border-collapse:collapse;border-spacing:0}.rhdocs td,.rhdocs th{padding:0}.rhdocs ._additional-resources[class][class][id]:last-child{margin-top:-2rem}.rhdocs ._additional-resources[class][class]:only-child{grid-column:1/-1}._additional-resources[class][class] .additional-resources__heading,._additional-resources[class][class] .heading,._additional-resources[class][class] h1,._additional-resources[class][class] h2,._additional-resources[class][class] h3,._additional-resources[class][class] h4,._additional-resources[class][class] h5,._additional-resources[class][class] h6,._additional-resources[class][class] p.title{display:block;font-family:RedHatDisplay,Red Hat Display,Helvetica Neue,Arial,sans-serif;font-size:1.125rem;font-weight:700;line-height:1.5rem;margin:0 0 .5rem;padding:0;text-transform:uppercase}._additional-resources[class][class] ul{border:0;list-style:none;margin:0;padding:0;position:relative}.related-topic-content__wrapper ._additional-resources[class][class] ul{display:block}._additional-resources[class][class] ul:after{background-color:#fff;bottom:0;content:"";display:block;height:.125rem;position:absolute;width:100%}._additional-resources[class][class] li{border-bottom:.0625rem solid #d2d2d2;box-sizing:content-box;margin:0;padding:1rem 1.5rem 1rem 0;-moz-column-break-inside:avoid;break-inside:avoid}._additional-resources[class][class] li:only-child{grid-column:1/-1}._additional-resources[class][class] li:last-child{border:0}@media (min-width:1100px){._additional-resources[class][class] li:last-child{border-bottom:.0625rem solid #d2d2d2}}._additional-resources[class][class] li p:only-child{margin:0;padding:0}._additional-resources[class][class] li a{text-decoration:none}._additional-resources[class][class] li a:focus,._additional-resources[class][class] li a:hover{text-decoration:underline}.rhdocs table .admonitionblock>div:nth-child(2),.rhdocs table .caution>div:nth-child(2),.rhdocs table .important>div:nth-child(2),.rhdocs table .note>div:nth-child(2),.rhdocs table .tip>div:nth-child(2),.rhdocs table .warning>div:nth-child(2){margin:.5rem 0}.rhdocs table .admonitionblock>div:nth-child(2)>:first-child,.rhdocs table .caution>div:nth-child(2)>:first-child,.rhdocs table .important>div:nth-child(2)>:first-child,.rhdocs table .note>div:nth-child(2)>:first-child,.rhdocs table .tip>div:nth-child(2)>:first-child,.rhdocs table .warning>div:nth-child(2)>:first-child{margin-top:0}.rhdocs table .admonitionblock>div:nth-child(2)>:last-child,.rhdocs table .caution>div:nth-child(2)>:last-child,.rhdocs table .important>div:nth-child(2)>:last-child,.rhdocs table .note>div:nth-child(2)>:last-child,.rhdocs table .tip>div:nth-child(2)>:last-child,.rhdocs table .warning>div:nth-child(2)>:last-child{margin-bottom:0}.rhdocs .codeblock__wrapper+.codeblock__wrapper,.rhdocs pre+pre,.rhdocs pre[class]+pre[class]{margin-top:2rem}.rhdocs .codeblock__wrapper{background:#f8f8f8;overflow:visible;position:relative;transform:translate(0);z-index:0}.codeblock__wrapper:before{background-repeat:no-repeat;background-size:6.25rem 100%;bottom:var(--scrollbar__height,1px);content:"";display:block;height:7.125rem;max-height:100%;max-height:calc(100% - var(--scrollbar__height, 2px));position:absolute;right:var(--scrollbar__width,6px);top:.0625rem;width:4.0625rem;z-index:1}.rhdocs .codeblock__inner-wrapper,.rhdocs pre{max-height:calc(100vh - 6.25rem)}@media (min-height:48em){.rhdocs .codeblock__inner-wrapper,.rhdocs pre{max-height:calc(100vh - 12.5rem)}}.rhdocs .codeblock__inner-wrapper{display:grid;grid-template-columns:1fr 4.375rem}.rhdocs .codeblock__wrapper--expanded .codeblock__inner-wrapper{max-height:-moz-max-content;max-height:max-content}.codeblock__copy span{display:block;height:0;position:absolute;visibility:hidden;width:0}.codeblock__copy:focus{outline:.0625rem dashed currentcolor}.codeblock__copy svg#icon--copy{height:1rem;width:1rem}.codeblock__expand{-webkit-appearance:none;-moz-appearance:none;appearance:none;background:#f0efef;border:0;cursor:pointer;height:1.75rem;left:calc(100% - 2.75rem - var(--scrollbar__width, 0px));position:absolute;text-indent:-9999em;top:3.25rem;width:1.75rem;z-index:2}.codeblock__expand:before{background:#6a6e73;content:"";height:100%;left:0;-webkit-mask-image:url("data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 320 512'%3E%3C!--! Font Awesome Pro 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license (Commercial License) Copyright 2022 Fonticons, Inc.--%3E%3Cpath d='M182.6 9.4c-12.5-12.5-32.8-12.5-45.3 0l-96 96c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l41.4-41.4v293.4l-41.4-41.3c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3l96 96c12.5 12.5 32.8 12.5 45.3 0l96-96c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L192 402.7V109.3l41.4 41.4c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3l-96-96z'/%3E%3C/svg%3E");mask-image:url("data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 320 512'%3E%3C!--! Font Awesome Pro 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license (Commercial License) Copyright 2022 Fonticons, Inc.--%3E%3Cpath d='M182.6 9.4c-12.5-12.5-32.8-12.5-45.3 0l-96 96c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l41.4-41.4v293.4l-41.4-41.3c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3l96 96c12.5 12.5 32.8 12.5 45.3 0l96-96c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L192 402.7V109.3l41.4 41.4c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3l-96-96z'/%3E%3C/svg%3E");-webkit-mask-position:center center;mask-position:center center;-webkit-mask-repeat:no-repeat;mask-repeat:no-repeat;-webkit-mask-size:auto 1rem;mask-size:auto 1rem;position:absolute;top:0;width:100%}.codeblock__wrapper--expanded .codeblock__expand{background:#2b9af3}.codeblock__wrapper--expanded .codeblock__expand:before{background:#fff}.codeblock__expand:focus:before,.codeblock__expand:hover:before{background:#06c}.codeblock__wrapper--expanded .codeblock__expand:focus:before,.codeblock__wrapper--expanded .codeblock__expand:hover:before{background:#fff}.codeblock__expand:focus{outline:.0625rem dashed currentcolor}.rhdocs .calloutlist>ol,.rhdocs .colist>ol{counter-reset:colist;list-style:none;margin:1rem 0 2rem;padding:0}.rhdocs .calloutlist>ol>li,.rhdocs .colist>ol>li{counter-increment:colist;font-size:1rem;margin:.5rem 0;padding-left:1.75rem;position:relative}.rhdocs .calloutlist>ol>li .colist-num,.rhdocs .colist>ol>li .colist-num{display:none}.calloutlist>ol>li:before,.colist>ol>li:before{content:counter(colist);left:0;position:absolute;top:.1875rem}.calloutlist dt{clear:left;float:left;margin:0;padding:0 .5rem 0 0}.included-in-guides[class],.included-in-guides[class][id]:last-child{background:#fff;border:.0625rem solid #d2d2d2;border-radius:.1875rem;margin:2em 0 4em;padding:2rem 2rem 1rem}.included-in-guides[class][id]:last-child{margin-top:-2rem}.included-in-guides[class]:only-child{grid-column:1/-1}.included-in-guides[class] .additional-resources__heading,.included-in-guides[class] .heading,.included-in-guides[class] h1,.included-in-guides[class] h2,.included-in-guides[class] h3,.included-in-guides[class] h4,.included-in-guides[class] h5,.included-in-guides[class] h6,.included-in-guides[class] p.title{display:block;font-family:RedHatDisplay,Red Hat Display,Helvetica Neue,Arial,sans-serif;font-size:1.125rem;font-weight:700;line-height:1.5rem;margin:0 0 .5rem;padding:0;text-transform:uppercase}.included-in-guides[class] ul{border:0;list-style:none;margin:0;padding:0;position:relative}.related-topic-content__wrapper .included-in-guides[class] ul{display:block}.included-in-guides[class] ul:after{background-color:#fff;bottom:0;content:"";display:block;height:.125rem;position:absolute;width:100%}.included-in-guides[class] li{border-bottom:.0625rem solid #d2d2d2;box-sizing:content-box;margin:0;padding:1rem 1.5rem 1rem 0;-moz-column-break-inside:avoid;break-inside:avoid}.included-in-guides[class] li:only-child{grid-column:1/-1}.included-in-guides[class] li:last-child{border:0}@media (min-width:1100px){.included-in-guides[class] li:last-child{border-bottom:.0625rem solid #d2d2d2}}.included-in-guides[class] li p:only-child{margin:0;padding:0}.included-in-guides[class] li a{text-decoration:none}.included-in-guides[class] li a:focus,.included-in-guides[class] li a:hover{text-decoration:underline}.menuseq{display:inline-flex;overflow:hidden;text-indent:-9999em}.menuseq .menu,.menuseq .menuitem,.menuseq .submenu{display:block;position:relative;text-indent:0}.menuseq .menu+.menu:before,.menuseq .menu+.menuitem:before,.menuseq .menu+.submenu:before,.menuseq .menuitem+.menu:before,.menuseq .menuitem+.menuitem:before,.menuseq .menuitem+.submenu:before,.menuseq .submenu+.menu:before,.menuseq .submenu+.menuitem:before,.menuseq .submenu+.submenu:before{content:">";display:inline-block;font-weight:700;padding:0 .25em}.related-topic-content__wrapper{margin:2em 0}.related-topic-content__wrapper--for-guide{margin-bottom:-2.5rem;padding-bottom:.0625rem;position:relative;z-index:1}.related-topic-content__wrapper--for-guide:before{background:#f0f0f0;content:"";display:block;height:100%;left:-3rem;position:absolute;right:-4.5rem;top:0;width:auto;z-index:-1}@media (min-width:1100px){.related-topic-content__wrapper--for-guide:before{left:-2.5rem;right:-3.625rem}}.related-topic-content__wrapper--for-guide summary{padding:1em 2em 1em 2.1875rem}@media (min-width:950px){.related-topic-content__inner-wrapper{display:grid;gap:2em;grid-template-columns:repeat(2,minmax(0,1fr))}}.local-render .rhdocs-content{margin:0 auto}.rhdocs cp-documentation{display:block;padding-bottom:2.5rem}.rhdocs cp-documentation.PFElement,.rhdocs cp-documentation[pfelement]{padding:0}rh-table{display:block}::-webkit-scrollbar,:host .rhdocs ::-webkit-scrollbar{height:.625rem;width:.625rem}::-webkit-scrollbar,::-webkit-scrollbar-track,:host .rhdocs ::-webkit-scrollbar,:host .rhdocs ::-webkit-scrollbar-track{background-color:#d6d6d6}::-webkit-scrollbar-thumb,:host .rhdocs ::-webkit-scrollbar-thumb{background-color:#8e8e8e}*,:host .rhdocs *{scrollbar-color:#8e8e8e #d6d6d6}.rhdocs p:empty,p:empty{display:none}.rhdocs[class] h1 code,.rhdocs[class] h2 code,.rhdocs[class] h3 code,.rhdocs[class] h4 code,.rhdocs[class] h5 code,.rhdocs[class] h6 code,[class] h1 code,[class] h2 code,[class] h3 code,[class] h4 code,[class] h5 code,[class] h6 code{background:transparent;border:0;color:inherit;font:inherit;margin:0;padding:0}.pane-page-title h1,.rhdocs__header__primary-wrapper h1{font-family:RedHatDisplay,Red Hat Display,Helvetica Neue,Arial,sans-serif;font-size:2.25rem;line-height:1.333}.rhdocs details[class]{list-style:none;margin:1rem 0 3rem;padding:0}.rhdocs-toc[class]{background:#f2f2f2;margin:1rem 0 2rem;padding:1rem}.rhdocs-toc[class]>:last-child{margin-bottom:0}.rhdocs-toc[class] .rhdocs-toctitle{font-size:1.25rem;font-weight:400;line-height:1.6667;margin-top:0;text-transform:none}.rhdocs-toc[class] li{margin-bottom:.25em;padding-left:.5em}.preamble{margin:0 0 2rem}.sect1{margin:2rem 0 1rem}:host .sect1,cp-documentation .sect1{margin:0 0 2rem;padding:.0625rem 0 0}:host(.cp-documentation--has-external-header) .sect1:first-child>h2:first-child,:host(.cp-documentation--has-external-header) .sect1:first-child>h3:first-child{margin-top:0}.listingblock,.literalblock{margin:1rem 0}.quoteblock,.verseblock{border-left:.25rem solid #d2d2d2;margin:1rem 0;padding:1rem 1rem 1rem 2rem}.quoteblock.pullleft,.verseblock.pullleft{float:left;margin-right:3rem;width:25rem}@media (min-width:768px){.quoteblock.pullleft,.verseblock.pullleft{margin-left:-1rem}}.quoteblock.pullright,.verseblock.pullright{float:right;margin-left:3rem;width:25rem}@media (min-width:768){.quoteblock.pullright,.verseblock.pullright{margin-right:-2rem}}@media (min-width:1100px){.quoteblock.pullright,.verseblock.pullright{margin-right:-10rem}}.quoteblock>:first-child,.verseblock>:first-child{margin-top:0}.quoteblock .content,.verseblock .content{font-family:RedHatText,Red Hat Text,Helvetica Neue,Arial,sans-serif;font-size:1.25rem;line-height:1.6667}.quoteblock .attribution,.verseblock .attribution{font-size:.875rem;font-style:italic;font-weight:600;line-height:1.6667;text-transform:uppercase}.quoteblock .attribution .citetitle,.verseblock .attribution .citetitle{color:#585858}.quoteblock .attribution cite,.verseblock .attribution cite{font-size:1em}.quoteblock blockquote{font-style:italic;margin:0;padding:0}.quoteblock blockquote .content>:first-child{margin-top:0}.quoteblock blockquote .content>:first-child:before{color:#e00;content:"â€œ";display:block;float:left;font-size:2.75rem;font-style:normal;line-height:1.125em;margin-right:.5rem}.quoteblock blockquote .content>:first-child .content>:first-child:before{content:none}.imageblock{margin:1rem 0}.imageblock.pullleft{float:left;margin-right:3rem;width:25rem}@media (min-width:768px){.imageblock.pullleft{margin-left:-1rem}}.imageblock.pullright{float:right;margin-left:3rem;width:25rem}@media (min-width:768){.imageblock.pullright{margin-right:-2rem}}@media (min-width:1100px){.imageblock.pullright{margin-right:-10rem}}.imageblock.interrupter{margin:2rem 0}@media (min-width:768px){.imageblock.interrupter{margin-left:-1rem;margin-right:-2rem}.imageblock.interrupter .caption{margin-left:1rem;margin-right:2rem}}@media (min-width:1100px){.imageblock.interrupter{margin-right:-10rem}.imageblock.interrupter .caption{margin-right:10rem}}.imageblock.interrupter img{max-width:100%}.imageblock .caption{color:#585858;display:block;font-size:.875rem;line-height:1.6667;margin:.5rem 0 0}.rhdocs-footnotes{border-top:.0625rem solid #d2d2d2;margin:3rem 0 1rem;padding:1rem 0 0}.rhdocs-footnotes>ol{margin:0;padding:0 0 0 1.5rem}@supports (counter-reset:footnotenum){.rhdocs-footnotes>ol{counter-reset:footnotenum;list-style:none;padding:0}.rhdocs-footnotes>ol>li{counter-increment:footnotenum}.rhdocs-footnotes>ol>li:before{color:#585858;content:"[" counter(footnotenum) "]";display:inline-block;margin-right:.25rem}}.rhdocs-footer{background:#ededed;color:#151515;font-size:.875rem;line-height:1.6667;margin:3rem 0 0;padding:1rem}.center{margin-left:auto;margin-right:auto}.stretch{width:100%}.visually-hidden{overflow:hidden;position:absolute;clip:rect(0,0,0,0);border:0;height:.0625rem;margin:-.0625rem;padding:0;width:.0625rem}.rh-docs-legal-notice{margin-top:4em}pre,pre[class]{margin:0;padding:1.25em 1em;position:relative}code[class*=language-],pre[class*=language-]{color:#151515;-moz-tab-size:4;-o-tab-size:4;tab-size:4}code.language-none,code.language-text,code.language-txt,pre.language-none,pre.language-text,pre.language-txt{color:#151515}code[class*=language-] ::-moz-selection,code[class*=language-]::-moz-selection,pre[class*=language-] ::-moz-selection,pre[class*=language-]::-moz-selection{background:#cceae7;color:#263238}code[class*=language-] ::selection,code[class*=language-]::selection,pre[class*=language-] ::selection,pre[class*=language-]::selection{background:#cceae7;color:#263238}:not(pre)>code[class*=language-]{border-radius:.2em;padding:.1em;white-space:normal}.token.atrule{color:#40199a}.token.attr-name{color:#06c}.token.attr-value,.token.attribute{color:#b300b3}.token.boolean{color:#40199a}.token.builtin,.token.cdata,.token.char,.token.class,.token.class-name{color:#06c}.token.comment{color:#6a6e73}.token.constant{color:#40199a}.token.deleted{color:#c9190b}.token.doctype{color:#6a6e73}.token.entity{color:#c9190b}.token.function{color:#40199a}.token.hexcode{color:#b300b3}.token.id,.token.important{color:#40199a;font-weight:700}.token.inserted{color:#06c}.token.keyword{color:#40199a}.token.number{color:#b300b3}.token.operator{color:#06c}.token.prolog{color:#6a6e73}.token.property{color:#06c}.token.pseudo-class,.token.pseudo-element{color:#b300b3}.token.punctuation,.token.regex{color:#06c}.token.selector{color:#c9190b}.token.string{color:#b300b3}.token.symbol{color:#40199a}.token.unit{color:#b300b3}.token.url,.token.variable{color:#c9190b}.rhdocs.local-render{margin:0 auto;max-width:45.8125rem;padding:0 1.5rem}@media print{.field code,.field pre,code[class*=language-],pre,pre[class*=language-]{white-space:pre-wrap!important;word-wrap:break-word!important;overflow-wrap:break-word!important;word-break:break-word!important}}.book-nav__list[class]{display:flex;justify-content:space-between;line-height:var(--jupiter__lineHeight--xs,1.3333);list-style:none;margin:5rem 0 0;padding:0}@media (min-width:1200px){.book-nav__list[class]{display:grid;gap:2rem;grid-template-columns:repeat(2,minmax(0,1fr))}}.book-nav__item a{display:inline-block;font-size:.875rem;font-weight:500;padding-left:1.25rem;position:relative;text-transform:uppercase}.book-nav__item a:before{background:url(/sites/dxp-docs/penumbra-dist/jupiter/images/arrow-down-solid.svg) no-repeat;background-size:contain;content:"";display:block;height:.875rem;left:0;position:absolute;top:.125rem;transform:rotate(90deg);width:.875rem}.book>.titlepage:not(:last-child),.rhdocs .chapter,section[id]{padding-bottom:3.75rem}.book>.titlepage .chapter:last-child,.book>.titlepage section[id]:last-child,.chapter .chapter:last-child,.chapter section[id]:last-child,section[id] .chapter:last-child,section[id] section[id]:last-child{margin-bottom:-3.75rem}.rhdocs .codeblock__wrapper+section[id],pre+section[id]{padding-top:3.75rem}.rhdocs .cta-link{font-size:inherit}.rhdocs a{word-wrap:break-word;overflow-wrap:break-word}.rhdocs .caution,.rhdocs .important,.rhdocs .note,.rhdocs .tip,.rhdocs .warning{padding:.8888888889em;position:relative}.rhdocs .QSIPopOver{bottom:18.75rem!important;top:auto!important}.rhdocs .alert{position:relative}.rhdocs button.dismiss-button{background:none;border:0;cursor:pointer;height:2.5rem;margin-top:-1.25rem;padding:0;position:absolute;right:.3125rem;text-align:center;top:50%;width:2.5rem;z-index:50}.rhdocs button.dismiss-button:after{content:"\f109";display:inline-block;filter:alpha(opacity=30);font-family:rh-web-iconfont;font-size:1.3125rem;font-style:normal;font-variant:normal;font-weight:400;line-height:1;line-height:2.5rem;opacity:.3;text-decoration:inherit;text-rendering:optimizeLegibility;text-transform:none!important;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;font-smoothing:antialiased}.rhdocs .book>.titlepage,.rhdocs .chapter,.rhdocs section[id]{padding-bottom:var(--rh-space-4xl,64px)}.rhdocs .alert{border:0;border-radius:0}.rhdocs .alert>h2:first-child,.rhdocs .alert>h3:first-child,.rhdocs .alert>h4:first-child,.rhdocs .alert>h5:first-child,.rhdocs .alert>h6:first-child,.rhdocs .alert>p:first-child{margin-top:0!important}.rhdocs .alert>p:last-child{margin-bottom:0!important}.rhdocs .alert-w-icon[class]{padding-left:2.8125rem}.rhdocs .alert-w-icon .alert-icon{float:left;font-size:1.125rem;margin-left:-1.875rem;margin-right:.625rem}.rhdocs .alert-w-icon .alert-icon[class*=" rh-icon-"],.rhdocs .alert-w-icon .alert-icon[class^=rh-icon-]{font-size:2.25rem;line-height:1em;margin-left:-2.5rem;margin-top:-.375rem}.rhdocs .alert-w-icon .alert-icon[class*=" icon-innov-prev"],.rhdocs .alert-w-icon .alert-icon[class^=icon-innov-prev]{font-size:1.3125rem;margin-top:.25rem}.rhdocs .alert-w-icon.alert-plain{background:none;color:#151515;padding-left:5rem}.rhdocs .alert-w-icon.alert-plain .alert-icon{font-size:3rem;margin-left:-4.375rem;margin-right:0}.rhdocs .alert-w-icon.alert-plain.alert-success .alert-icon{color:#3f9c35}.rhdocs .alert-w-icon.alert-plain.alert-info .alert-icon{color:#0088ce}.rhdocs .alert-w-icon.alert-plain.alert-warning .alert-icon{color:#f0ab00}.rhdocs .alert-w-icon.alert-plain.alert-danger .alert-icon{color:#e00}#target_banner .copy-url{float:right;margin-top:0}#target_banner .dropdown-menu{font-size:inherit}.titlepage .svg-img[data*="title_logo.svg"]{margin:1.5rem 0;width:15rem}.para{margin:1.49963rem 0}.para[class]{margin-bottom:1.49963rem}dd{margin-bottom:2.5rem}.rhdocs .card-light,.rhdocs .card-light-gray,.rhdocs .card-light-grey{background:#f0f0f0;border:.0625rem solid #f0f0f0;color:#151515}.rhdocs .card-light-gray.push-bottom:first-child,.rhdocs .card-light-grey.push-bottom:first-child,.rhdocs .card-light.push-bottom:first-child{margin-bottom:3.125rem!important}.rhdocs .card-light a.card-link,.rhdocs .card-light h1,.rhdocs .card-light h2,.rhdocs .card-light h3,.rhdocs .card-light h4,.rhdocs .card-light h5,.rhdocs .card-light h6,.rhdocs .card-light-gray a.card-link,.rhdocs .card-light-gray h1,.rhdocs .card-light-gray h2,.rhdocs .card-light-gray h3,.rhdocs .card-light-gray h4,.rhdocs .card-light-gray h5,.rhdocs .card-light-gray h6,.rhdocs .card-light-grey a.card-link,.rhdocs .card-light-grey h1,.rhdocs .card-light-grey h2,.rhdocs .card-light-grey h3,.rhdocs .card-light-grey h4,.rhdocs .card-light-grey h5,.rhdocs .card-light-grey h6{color:#151515}.rhdocs .card-light-gray.card-active:after,.rhdocs .card-light-grey.card-active:after,.rhdocs .card-light.card-active:after{border-top-color:#f0f0f0}.rhdocs .card-md,.rhdocs .card-narrow{display:block;padding:1.1875rem;white-space:normal;word-wrap:break-word}.rhdocs .card .card-heading.card-heading-sm,.rhdocs .card-sm .card .card-heading{font-size:1.0625em;font-weight:500;line-height:1.5}.rhdocs .card .card-heading.card-heading-flush{margin-bottom:.25rem}.rhdocs .card .card-heading.card-heading-red{color:#d10000}.rhdocs .card>p{margin-top:0}.rhdocs .card>p:last-child{margin-bottom:0}.rhdocs .new-experience{background-color:#e7f1fa;border:.0625rem solid #bee1f4;font-size:1rem;margin:1.5rem;padding:1.5rem;position:relative;z-index:1}@media (min-width:48rem){.new-experience{display:flex}.new-experience--contained{left:50%;position:relative;transform:translateX(-50%);width:calc(100vw - 2.5rem)}}.new-experience__primary-content{flex-grow:1}@media (min-width:48rem){.new-experience__primary-content{margin-right:1.25rem}}.new-experience__title{font-size:inherit;font-weight:inherit;line-height:1.6;margin:0;padding:0}.new-experience__title+a,.new-experience__title+pfe-cta{display:inline-block;margin-top:1.5em}.new-experience__secondary-content{min-width:12.5rem}@media (min-width:48rem){.new-experience__secondary-content{text-align:right}}.example{border-left:.3125rem solid #ccc;margin-bottom:2rem;padding:1rem 0 1rem 1rem}dl.calloutlist[class]{display:grid;gap:1.25em .75em;grid-template-columns:min-content 1fr}dl.calloutlist[class] dt{float:none;margin:0;padding:0}dl.calloutlist[class] dd{margin:0;padding:0}dl.calloutlist[class] dd>:first-child{margin-top:0}dl.calloutlist[class] dd>:last-child{margin-bottom:0}.toast{background-color:#000;background-color:rgba(0,0,0,.9);bottom:.9375rem;box-shadow:0 .125rem .3125rem 0 rgba(0,0,0,.26);color:#fff;left:.9375rem;max-width:32.8125rem;min-width:6.25rem;padding:.9375rem;position:fixed;right:.9375rem;transform:translate3d(0,150%,0);transition:transform .2s cubic-bezier(.465,.183,.153,.946);will-change:transform;z-index:999}.toast.show{transform:translateZ(0)}.toast a{color:#fff;text-decoration:underline}.toast a:focus,.toast a:hover{color:#2b9af3}.toast a.btn{text-decoration:none}.toast .btn.btn-link{color:#fff}.toast .close{color:#fff;opacity:.3;text-decoration:none}.toast .close:focus,.toast .close:hover{color:#fff;opacity:.5}.no-csstransforms3d.csstransitions .toast{transition:all .2s cubic-bezier(.465,.183,.153,.946)}.no-csstransforms3d .toast{opacity:0;visibility:hidden}.no-csstransforms3d .toast.show{opacity:1;visibility:visible}.annotator-outer[class][class]{display:none;flex-direction:column;flex-grow:1;height:auto;margin:0;position:static;width:auto}@media (min-width:1400px){.annotator-outer[class][class]{display:flex}}.annotator-frame[class] *{height:auto}@media (min-width:1400px){.annotator-frame .h-sidebar-iframe[class]{position:static;width:calc(100% + 1.5rem)}}.annotator-toolbar[class][class]{position:static;width:auto}.annotator-toolbar>ul,.annotator-toolbar>ul>li{display:block;height:auto;list-style:none;margin:0;padding:0;width:auto}.annotator-toolbar>ul>li{display:flex;justify-content:flex-end}.annotator-frame[class] .annotator-frame-button--sidebar_toggle,.annotator-outer .annotator-frame-button[class][class],.app-content-wrapper *{font-family:RedHatText,Red Hat Text,Helvetica Neue,Arial,sans-serif!important}.annotator-outer .annotator-frame-button[class][class]{font-size:.9375rem;font-weight:500;height:auto;line-height:1.333;margin-right:1.875rem;padding:.75em 1em;position:static}@media (min-width:1400px){.annotator-outer .annotator-frame-button[class][class]{margin-right:0}}.annotator-outer iframe{flex-grow:1;margin-bottom:1.25rem}@media (min-width:1400px){.annotator-outer iframe{min-height:37.5rem}}.producttitle{color:#000;font-size:1.25rem;text-transform:uppercase}.producttitle .productnumber{color:var(--jupiter__palette__red--50,#e00)}.cp-modal-open,.zoom-open{overflow:hidden}.cp-modal,.cp-video-modal,.zoom-modal{bottom:0;display:none;filter:alpha(opacity=0);left:0;opacity:0;outline:0;overflow:hidden;position:fixed;right:0;top:0;transition:all .2s cubic-bezier(.465,.183,.153,.946);z-index:1040;z-index:1050;-webkit-overflow-scrolling:touch}.rhdocs .in.cp-modal,.rhdocs .in.cp-video-modal,.rhdocs .in.zoom-modal{display:block;filter:alpha(opacity=100);opacity:1;overflow-x:hidden;overflow-y:auto}.rhdocs .cp-modal .close,.rhdocs .cp-video-modal .close,.rhdocs .zoom-modal .close{background-color:#fff;border-radius:50%;color:#1a1a1a;font-size:1.75rem;height:28px;height:1.75rem;line-height:1.75rem;margin-bottom:.375rem;margin-top:0;opacity:.9;position:absolute;right:-.5rem;text-shadow:none;top:0;width:28px;width:1.75rem}.cp-modal .close:after,.cp-video-modal .close:after,.zoom-modal .close:after{line-height:1.75rem}.cp-modal-wrap,.zoom-wrap{margin:.625rem;padding-top:.5rem;position:relative}@media (min-width:48rem){.rhdocs .cp-modal-wrap,.rhdocs .zoom-wrap{margin:2.8125rem auto;width:38.4375rem}}@media (min-width:62rem){.rhdocs .cp-modal-wrap,.rhdocs .zoom-wrap{width:49.8958rem}}@media (min-width:75rem){.rhdocs .cp-modal-wrap,.rhdocs .zoom-wrap{width:60.3125rem}}.rhdocs .cp-modal-body :last-child{margin-bottom:0}.rhdocs .cp-modal-backdrop,.rhdocs .zoom-backdrop{background-color:#000;bottom:0;display:none;filter:alpha(opacity=0);left:0;opacity:0;position:fixed;right:0;top:0;transition:opacity .2s cubic-bezier(.465,.183,.153,.946);z-index:1040}.rhdocs .in.cp-modal-backdrop,.rhdocs .in.zoom-backdrop{display:block;filter:alpha(opacity=80);opacity:.8}.rhdocs .cp-modal-body{background:#fff;padding:1.875rem}.rhdocs .cp-modal[data-cp-modal-video=true] .cp-modal-body,.rhdocs .cp-video-modal .cp-modal-body{padding:0}.rhdocs [data-action=zoom]{position:relative}.rhdocs [data-action=zoom]:after{background:rgba(0,0,0,.4);bottom:0;color:#fff;display:inline-block;font-family:rh-web-iconfont;font-style:normal;font-variant:normal;font-weight:400;line-height:1;padding:.375rem;position:absolute;right:0;text-decoration:inherit;text-decoration:none!important;text-rendering:optimizeLegibility;text-transform:none!important;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;font-smoothing:antialiased}.rhdocs [data-action=zoom]:focus:after,.rhdocs [data-action=zoom]:hover:after{background:rgba(0,0,0,.9)}.rhdocs .zoom-wrap .zoom-larger{text-align:center}.rhdocs .zoom-wrap .zoom-larger a{color:#fff}.rhdocs .zoom-wrap .zoom-larger a:focus,.rhdocs .zoom-wrap .zoom-larger a:hover{color:#fff;text-decoration:underline}.rhdocs .zoom-wrap .zoom-larger a:after{content:"â¿»";display:inline-block;margin-left:.25rem}.rhdocs .zoom-body{background:#fff;border-radius:.5rem;margin:0 0 1rem;padding:1rem;text-align:center}.rhdocs .zoom-body .video-wrapper{height:0;overflow:hidden;padding-bottom:56.25%;position:relative}.rhdocs .zoom-body .video-wrapper[data-aspect-ratio="4:3"]{padding-bottom:75%}.rhdocs .zoom-body iframe{height:100%;left:0;position:absolute;top:0;width:100%}.rhdocs .para>.title[class],.rhdocs p.title[class]{font-size:1rem;font-style:normal;font-weight:700;line-height:1.6667;margin:1.25rem 0 0;text-transform:none}.rhdocs .para>.title[class]+.content>:first-child,.rhdocs .para>.title[class]+p,.rhdocs p.title[class]+.content>:first-child,.rhdocs p.title[class]+p{margin-top:0}.rhdocs [class] pre .caution,.rhdocs [class] pre .important,.rhdocs [class] pre .note,.rhdocs [class] pre .tip,.rhdocs [class] pre .warning{background:transparent;border:0;color:inherit;font:inherit;margin:0;padding:0}.rhdocs [class] pre .caution:after,.rhdocs [class] pre .important:after,.rhdocs [class] pre .note:after,.rhdocs [class] pre .tip:after,.rhdocs [class] pre .warning:after{content:none}.rhdocs [class] code.email{background-color:transparent;font:inherit;padding:0}.rhdocs [class] .author{margin-bottom:1.5rem}.rhdocs [class] .author .author{margin-bottom:0}.rhdocs table{margin:2rem 0}.rhdocs [class] table{width:auto}.rhdocs table .table-contents table{max-width:100%;overflow:auto}.rhdocs rh-table table{margin:0;max-width:9999em;overflow:visible}.rhdocs td,.rhdocs th{border-left:0;padding:.5em 1rem;transition:background .25s ease-out}.rhdocs td.content--md[class][class],.rhdocs th.content--md[class][class]{min-width:13em}.rhdocs td.content--lg[class][class],.rhdocs th.content--lg[class][class]{min-width:20em}.rhdocs thead th{padding-top:1.5em}.rhdocs caption{color:currentColor;color:var(--pfe-table__caption--Color,currentColor);font-weight:700;margin-bottom:.5rem;margin-top:.5rem;text-align:center}.rhdocs .revhistory table td,.rhdocs .revhistory table th{border-color:transparent}.rhdocs .revhistory table td{padding:.625rem .875rem}.rhdocs .revhistory table.simplelist{margin:0}@media print{#masthead{display:none!important}}.rh-table--is-full-screen #to-top{display:none}.rhdocs{--rh-table--maxHeight:calc(100vh - 6.25rem);color:#151515;font-family:var(--rh-font-family-body-text,RedHatText,"Red Hat Text","Noto Sans Arabic","Noto Sans Hebrew","Noto Sans JP","Noto Sans KR","Noto Sans Malayalam","Noto Sans SC","Noto Sans TC","Noto Sans Thai",Helvetica,Arial,sans-serif);font-size:var(--rh-body-copy-lage,1.125rem);line-height:1.6667;-moz-tab-size:4;-o-tab-size:4;tab-size:4}.rhdocs rh-codeblock::slotted(#content){border-radius:.25rem;padding:var (--rh-space-lg,16px)}.rhdocs rh-codeblock .screen{display:grid;grid-template-columns:1fr 4.375rem}.rhdocs rh-codeblock[class][class][class][class][class]{max-width:99999em}.rhdocs .codeblock__copy span{display:block;height:0;position:absolute;visibility:hidden;width:0}.rhdocs .codeblock__copy:focus{outline:.0625rem dashed currentcolor}.rhdocs .codeblock__copy svg#icon--copy{height:1rem;width:1rem}.rhdocs pre{border:0;max-height:-moz-max-content;max-height:max-content}.rhdocs pre,pre[class]{margin:0;padding:1.25em 1em;position:relative}.rhdocs rh-code-block>div.codeblock__inner-wrapper>pre,.rhdocs rh-code-block>div.codeblock__inner-wrapper>pre[class]{margin:0;padding:0;position:relative}.rhdocs code[class*=language-],pre[class*=language-]{color:#151515;-moz-tab-size:4;-o-tab-size:4;tab-size:4}.rhdocs code.literal{background:#eee;border-radius:.25rem;color:#000;font-size:.875rem;line-height:1.6667;overflow-wrap:break-word;padding:.125em .5em;word-break:break-word}.rhdocs code.literal,.rhdocs kbd,.rhdocs span.keycap{font-family:RedHatMono,Red Hat Mono,Consolas,monospace}.rhdocs kbd,.rhdocs span.keycap{background-color:#eee;background-image:linear-gradient(180deg,#ddd,#eee,#fff);border-radius:.1875rem;box-shadow:0 -.0625rem 0 0 #fff,0 .0625rem 0 .1875rem #aaa;font-size:90%;font-weight:400;margin:0 .25rem;padding:.125rem .375rem}.rhdocs ol,.rhdocs ul{margin:1rem 0;padding:0 0 0 1.5rem}.rhdocs ._additional-resources[class][class],.rhdocs ._additional-resources[class][class][id]:last-child{background:#fff;border:.0625rem solid #d2d2d2;border-radius:.1875rem;margin:2em 0 4em;padding:2rem 2rem 1rem}.rhdocs ._additional-resources[class][class] ul{border:0;list-style:none;margin:0;padding:0;position:relative}.rhdocs ._additional-resources[class][class] li{border-bottom:.0625rem solid #d2d2d2;box-sizing:content-box;margin:0;padding:1rem 1.5rem 1rem 0;-moz-column-break-inside:avoid;break-inside:avoid}.rhdocs ._additional-resources[class][class] li:last-child{border:0}.rhdocs section.section#additional_resource .additional-resources__heading,.rhdocs section.section#additional_resource .heading,.rhdocs section.section#additional_resource h1,.rhdocs section.section#additional_resource h2,.rhdocs section.section#additional_resource h3,.rhdocs section.section#additional_resource h4,.rhdocs section.section#additional_resource h5,.rhdocs section.section#additional_resource h6,.rhdocs section.section#additional_resource p.title{display:block;font-family:RedHatDisplay,Red Hat Display,Helvetica Neue,Arial,sans-serif;font-size:1.125rem;font-weight:700;line-height:1.5rem;margin:0 0 .5rem;padding:0;text-transform:uppercase}.rhdocs section.section:first-of-type{margin-top:var(--rh-space-4xl,64px)}.rhdocs section.section p{margin-bottom:var(--rh-space-lg,16px);margin-top:0;word-wrap:break-word}.rhdocs .section.section h1,.rhdocs .section.section h2,.rhdocs .section.section h3,.rhdocs .section.section h4,.rhdocs .section.section h5,.rhdocs .section.section h6,.rhdocs h1,.rhdocs h2,.rhdocs h3,.rhdocs h4,.rhdocs h5,.rhdocs h6{font-family:RedHatDisplay,Red Hat Display,Helvetica Neue,Arial,sans-serif;font-weight:400;line-height:1.3333}.rhdocs h1:first-of-type,.rhdocs h2:first-of-type,.rhdocs h3:first-of-type,.rhdocs h4:first-of-type,.rhdocs h5:first-of-type,.rhdocs h6:first-of-type{margin-top:0}.rhdocs h1,.rhdocs h2,.rhdocs h3,.rhdocs h4,.rhdocs h5,.rhdocs h6{font-family:RedHatDisplay,Red Hat Display,Helvetica,Arial,sans-serif;font-weight:400;line-height:1.3333}.rhdocs h2,.rhdocs section.section h2{font-size:var(--rh-font-size-heading-md,1.75rem)}.rhdocs h3,.rhdocs section.section h3{font-size:1.5rem;font-weight:400}.rhdocs dl dt{font-weight:600;margin:.5rem 0}.rhdocs dl{display:block;margin-block-end:1em;margin-block-start:1em;margin-inline-end:0;margin-inline-start:0}.rhdocs .para{margin:1.49963rem 0}.rhdocs dl.calloutlist[class] dt{float:none;margin:0;padding:0}.rhdocs dl.calloutlist[class] dd>:last-child{margin-bottom:0}.rhdocs dl.calloutlist[class]{display:grid;gap:1.25em .75em;grid-template-columns:fit-content(40%) 1fr}.rhdocs .calloutlist dt{clear:left;display:flex;flex-wrap:wrap;float:left;margin:0;padding:0 .5rem 0 0}.rhdocs .calloutlist dt a:not(:first-child){padding-left:4px}.rhdocs dl.calloutlist[class] dd{margin:0;padding:0}.rhdocs .callout,.rhdocs .colist>ol>li:before,.rhdocs .conum{background:#06c;border-radius:50%;color:#fff;display:inline-block;font-family:RedHatText,Red Hat Text,Helvetica Neue,Arial,sans-serif;font-size:.75rem;font-style:normal;font-weight:600;height:1.25rem;line-height:1.35rem;padding:0;position:relative;text-align:center;top:-.125em;vertical-align:middle;width:1.25rem}.rhdocs img,.rhdocs object,.rhdocs svg{display:inline-block;max-width:100%;vertical-align:middle}.rhdocs .titlepage .svg-img[data*="title_logo.svg"]{margin:1.5rem 0;width:15rem}.rhdocs[class] .author{margin-bottom:1.5rem}.rhdocs[class] .author .author{margin-bottom:0}.rhdocs .para>.title[class],p.title[class]{font-size:1rem;font-style:normal;font-weight:700;line-height:1.6667;margin:1.25rem 0 0}.rhdocs .example{border-left:.3125rem solid #ccc;margin-bottom:2rem;padding:1rem 0 1rem 1rem}.rhdocs code{background:#eee;color:#000;font-family:RedHatMono,Red Hat Mono,Consolas,monospace;font-size:.875rem;line-height:1.6667;overflow-wrap:break-word;padding:.125em .5em;word-break:break-word}.rhdocs .para[class]{margin-bottom:1.49963rem}.rhdocs[class] code.email{background-color:transparent;font:inherit;padding:0}rh-alert.admonition #description,rh-alert.admonition p{font-size:var(--rh-font-size-body-text-md,1rem)}rh-alert{width:-moz-fit-content;width:fit-content}.rhdocs .producttitle{color:#000;font-size:1.25rem;text-transform:uppercase}.rhdocs dl{margin:1rem 0}.rhdocs dl dt{font-weight:600;margin:.5rem 0}.rhdocs ol ol{list-style:lower-roman}.rhdocs .codeblock--processed pf-clipboard-copy::part(input),.rhdocs .codeblock--processed pf-clipboard-copy::part(span){display:none}.token.tag{color:#c9190b}.calloutlist div.para{margin:0}rh-alert.admonition{margin-bottom:var(--rh-space-lg,1rem)}.guibutton,.guimenu,.guimenuitem{font-weight:700}.guibutton{font-size:90%;padding:.1875rem}.guibutton:before{content:"["}.guibutton:after{content:"]"}.docs-content-container,.rhdocs{--rh-table--maxHeight:calc(100vh - 6.25rem);color:#151515;font-family:RedHatText,Red Hat Text,Helvetica Neue,Arial,sans-serif;font-size:1.125rem;line-height:1.6667;-moz-tab-size:4;-o-tab-size:4;tab-size:4}pre[hidden]{display:none}.codeblock[class][class][class][class][class]{max-width:99999em}.codeblock__wrapper{background:var(--rh-color-surface-lighter,#f2f2f2);margin:1rem 0;overflow:visible;position:relative;transform:translate(0);z-index:0}.codeblock__inner-wrapper:after{content:"";display:block;min-height:.625rem;width:4.375rem}.codeblock__copy{--pfe-clipboard--icon--Color--hover:#06c;-webkit-appearance:none;-moz-appearance:none;appearance:none;background:#f0efef;height:1.75rem;left:calc(100% - 2.75rem - var(--scrollbar__width, 0px));padding:.3125rem .375rem;position:absolute;top:1rem;width:1.75rem;z-index:2}.codeblock__inner-wrapper pre{border:0;max-height:-moz-max-content;max-height:max-content}.pfe-clipboard:not([copied]) .pfe-clipboard__text--success,:host(:not([copied])) .pfe-clipboard__text--success{display:none!important}.codeblock[class]{margin:0;overflow:visible;padding-right:0}pre{display:block;font-size:.8125rem;line-height:1.42857;margin:0 0 .625rem;word-break:break-all;word-wrap:break-word;background-color:var(--rh-color-surface-lighter,#f2f2f2);border:.0625rem solid #ccc;border-radius:.25rem;color:#333}.docs-content-container pre,.rhdocs pre{background:var(--rh-color-surface-lighter,#f2f2f2);color:#151515;font-family:RedHatMono,Red Hat Mono,Consolas,monospace;font-size:.875rem;line-height:1.6667;overflow-wrap:normal;white-space:pre;word-break:normal}.rhdocs pre[class]{line-height:1.6667;overflow-x:auto}rh-codeblock pre[class][class]{overflow-x:auto}.pfe-clipboard__text--success{background-color:#ddd;border:1px solid #000;border-radius:2px}*,:after,:before{box-sizing:border-box}:root{--rh-space-xs:4px;--rh-space-sm:6px;--rh-space-md:8px;--rh-space-lg:16px;--rh-space-xl:24px;--rh-space-2xl:32px;--rh-space-3xl:48px;--rh-space-4xl:64px;--rh-space-5xl:80px;--rh-space-6xl:96px;--rh-space-7xl:128px;--rh-font-size-body-text-xs:.75rem;--rh-font-size-body-text-sm:.875rem;--rh-font-size-body-text-md:1rem;--rh-font-size-body-text-lg:1.125rem;--rh-font-size-body-text-xl:1.25rem;--rh-font-size-body-text-2xl:1.5rem;--rh-font-size-heading-xs:1.25rem;--rh-font-size-heading-sm:1.5rem;--rh-font-size-heading-md:1.75rem;--rh-font-size-heading-lg:2.25rem;--rh-font-size-heading-xl:2.5rem;--rh-font-size-heading-2xl:3rem;--pfe-navigation--logo--maxWidth:200px;--pfe-navigation__logo--height:40px;--pfe-navigation--fade-transition-delay:500ms;--pfe-navigation__nav-bar--highlight-color:var(--rh-color-brand-red-on-dark,#e00);--pf-global--icon--FontSize--sm:.75rem}body,html{font-family:Red Hat Text,sans-serif;font-size:var(--rh-font-size-body-text-md,1rem);line-height:var(--rh-line-height-body-text,1.5);margin:0}h1,h2,h3,h4,h5,h6{font-family:Red Hat Display,sans-serif;font-weight:400;line-height:var(--rh-line-height-heading,1.3)}h1{font-size:var(--rh-font-size-heading-2xl,3rem);line-height:62px}h2{font-size:var(--rh-font-size-heading-xl,2.5rem);line-height:48px}h3{font-size:var(--rh-font-size-heading-lg,2.25rem)}h4{font-size:var(--rh-font-size-heading-md,2.25rem)}h5{font-size:var(--rh-font-size-heading-sm,2.25rem)}h6{font-size:var(--rh-font-size-heading-xs,2.25rem)}main{line-height:30px}section{padding-bottom:3rem;padding-top:3rem}img{height:auto;max-width:100%}a{color:var(--rh-color-interactive-blue-darker,#06c);text-decoration:none}a:hover{color:var(--rh-color-interactive-blue-darkest,#004080)}rh-alert.html-container a{text-decoration:underline}.container{padding-left:12px;padding-right:12px}.container,.container-fluid{margin-left:auto;margin-right:auto;width:100%}.container-fluid{padding:12px}@media (min-width:576px){.container{max-width:540px}}@media (min-width:768px){.container{max-width:720px}}@media (min-width:992px){.container{max-width:960px}}@media (min-width:1200px){.container{min-width:1140px}}@media (min-width:1400px){.container{min-width:1320px}}.grid{display:grid;gap:var(--rh-space-xl,24px)}.grid-center{margin:auto}.grid.grid-col-2{grid-template-columns:repeat(2,1fr)}.grid.grid-col-3{grid-template-columns:repeat(3,1fr)}.grid.grid-col-4{grid-template-columns:repeat(4,1fr)}.grid.grid-col-5{grid-template-columns:repeat(5,1fr)}.grid.grid-col-6{grid-template-columns:repeat(6,1fr)}.grid.grid-col-7{grid-template-columns:repeat(7,1fr)}.grid.grid-col-8{grid-template-columns:repeat(8,1fr)}.grid.grid-col-9{grid-template-columns:repeat(9,1fr)}.grid.grid-col-10{grid-template-columns:repeat(10,1fr)}.grid.grid-col-11{grid-template-columns:repeat(11,1fr)}.grid.grid-col-12{grid-template-columns:repeat(12,1fr)}@media (min-width:768px){.grid.grid-col-md-2{grid-template-columns:repeat(2,1fr)}.grid.grid-col-md-3{grid-template-columns:repeat(3,1fr)}.grid.grid-col-md-4{grid-template-columns:repeat(4,1fr)}.grid.grid-col-md-5{grid-template-columns:repeat(5,1fr)}.grid.grid-col-md-6{grid-template-columns:repeat(6,1fr)}.grid.grid-col-md-7{grid-template-columns:repeat(7,1fr)}.grid.grid-col-md-8{grid-template-columns:repeat(8,1fr)}.grid.grid-col-md-9{grid-template-columns:repeat(9,1fr)}.grid.grid-col-md-10{grid-template-columns:repeat(10,1fr)}.grid.grid-col-md-11{grid-template-columns:repeat(11,1fr)}.grid.grid-col-md-12{grid-template-columns:repeat(12,1fr)}}@media (min-width:992px){.grid.grid-col-lg-2{grid-template-columns:repeat(2,1fr)}.grid.grid-col-lg-3{grid-template-columns:repeat(3,1fr)}.grid.grid-col-lg-4{grid-template-columns:repeat(4,1fr)}.grid.grid-col-lg-5{grid-template-columns:repeat(5,1fr)}.grid.grid-col-lg-6{grid-template-columns:repeat(6,1fr)}.grid.grid-col-lg-7{grid-template-columns:repeat(7,1fr)}.grid.grid-col-lg-8{grid-template-columns:repeat(8,1fr)}.grid.grid-col-lg-9{grid-template-columns:repeat(9,1fr)}.grid.grid-col-lg-10{grid-template-columns:repeat(10,1fr)}.grid.grid-col-lg-11{grid-template-columns:repeat(11,1fr)}.grid.grid-col-lg-12{grid-template-columns:repeat(12,1fr)}}.span-1{grid-column:span 1}.span-2{grid-column:span 2}.span-3{grid-column:span 3}.span-4{grid-column:span 4}.span-5{grid-column:span 5}.span-6{grid-column:span 6}.span-7{grid-column:span 7}.span-8{grid-column:span 8}.span-9{grid-column:span 9}.span-10{grid-column:span 10}.span-11{grid-column:span 11}.span-12{grid-column:span 12}@media (min-width:399px){.span-xs-1{grid-column:span 1}.span-xs-2{grid-column:span 2}.span-xs-3{grid-column:span 3}.span-xs-4{grid-column:span 4}.span-xs-5{grid-column:span 5}.span-xs-6{grid-column:span 6}.span-xs-7{grid-column:span 7}.span-xs-8{grid-column:span 8}.span-xs-9{grid-column:span 9}.span-xs-10{grid-column:span 10}.span-xs-11{grid-column:span 11}.span-xs-12{grid-column:span 12}}@media (min-width:768px){.span-md-1{grid-column:span 1}.span-md-2{grid-column:span 2}.span-md-3{grid-column:span 3}.span-md-4{grid-column:span 4}.span-md-5{grid-column:span 5}.span-md-6{grid-column:span 6}.span-md-7{grid-column:span 7}.span-md-8{grid-column:span 8}.span-md-9{grid-column:span 9}.span-md-10{grid-column:span 10}.span-md-11{grid-column:span 11}.span-md-12{grid-column:span 12}}@media (min-width:992px){.span-lg-1{grid-column:span 1}.span-lg-2{grid-column:span 2}.span-lg-3{grid-column:span 3}.span-lg-4{grid-column:span 4}.span-lg-5{grid-column:span 5}.span-lg-6{grid-column:span 6}.span-lg-7{grid-column:span 7}.span-lg-8{grid-column:span 8}.span-lg-9{grid-column:span 9}.span-lg-10{grid-column:span 10}.span-lg-11{grid-column:span 11}.span-lg-12{grid-column:span 12}}@media (min-width:1025px){.span-xl-1{grid-column:span 1}.span-xl-2{grid-column:span 2}.span-xl-3{grid-column:span 3}.span-xl-4{grid-column:span 4}.span-xl-5{grid-column:span 5}.span-xl-6{grid-column:span 6}.span-xl-7{grid-column:span 7}.span-xl-8{grid-column:span 8}.span-xl-9{grid-column:span 9}.span-xl-10{grid-column:span 10}.span-xl-11{grid-column:span 11}.span-xl-12{grid-column:span 12}}@media (min-width:1200px){.span-2xl-1{grid-column:span 1}.span-2xl-2{grid-column:span 2}.span-2xl-3{grid-column:span 3}.span-2xl-4{grid-column:span 4}.span-2xl-5{grid-column:span 5}.span-2xl-6{grid-column:span 6}.span-2xl-7{grid-column:span 7}.span-2xl-8{grid-column:span 8}.span-2xl-9{grid-column:span 9}.span-2xl-10{grid-column:span 10}.span-2xl-11{grid-column:span 11}.span-2xl-12{grid-column:span 12}}.flex{display:flex;flex-direction:column;gap:var(--rh-space-lg,16px)}.flex-row{flex-direction:row}.flex-column{flex-direction:column}@media (min-width:768px){.flex-md-row{flex-direction:row}.flex-md-column{flex-direction:column}}.typography-h1{font-size:var(--rh-font-size-heading-2xl,3rem)}.typography-h2{font-size:var(--rh-font-size-heading-xl,2.5rem)}.typography-h3{font-size:var(--rh-font-size-heading-lg,2.25rem)}.typography-h4{font-size:var(--rh-font-size-heading-md,1.75rem)}.typography-h5{font-size:var(--rh-font-size-heading-sm,1.5rem)}.typography-h6{font-size:var(--rh-font-size-heading-xs,1.25rem)}.content section{padding:0}.content h1,.content h2,.content h3,.content h4,.content h5,.content h6{margin:var(--rh-space-lg,16px) 0}.sr-only{height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px;clip:rect(0,0,0,0);border:0}.list-unstyled{list-style:none;padding-left:0}.tooltip-content{align-items:center;display:flex;font-family:Red Hat Text;justify-content:center;text-transform:none}.tooltip-content .check-icon{margin-left:var(--rh-space-md,8px)}.doc-image-link{display:inline-block;text-decoration:none}.modal-img{display:block;width:100%}.modal-helper-text{margin-top:.5rem;text-align:center}.modal-helper-text a{color:#000;cursor:pointer}.modal-helper-text a:hover{text-decoration:underline}.modal-helper-text a:after{content:"⿻";margin-left:.25rem}pf-modal.pf-img-modal{--pf-c-modal-box--MaxHeight:90vh;overflow-y:scroll}pf-modal.pf-img-modal::part(close-button){background-color:#fff;border-radius:50%;color:#000;margin-right:-2rem;margin-top:-2rem}pf-modal.pf-img-modal::part(close-button):hover{opacity:.7}h2.truste-title{line-height:normal;margin-top:0}rh-alert p[slot=header]{color:#002952}@media (width < 992px){html:has(nav.mobile-nav .mobile-nav-wrapper){scroll-behavior:smooth;scroll-padding-top:4rem}html:has(nav.mobile-nav .mobile-jump-links){scroll-padding-top:7rem}html:has(nav.mobile-nav.hide-mobile-nav){scroll-padding-top:2rem}}.highlight{background:#fff4cc;color:#000}</style>
<style>rh-alert[data-v-84359384]{width:100%}</style>
<style>.search-btn[data-v-edc0d12c]{align-items:center;background-color:var(--rh-color-canvas-black,#151515);border:3px solid var(--rh-color-canvas-black,#151515);cursor:pointer;display:flex;flex-direction:column;height:100%;justify-content:center;outline:none;padding:14px var(--rh-space-md,8px)}.search-btn[data-v-edc0d12c]:focus{border-top:3px solid var(--rh-color-accent-brand-on-light,#e00);outline:2px dotted var(--rh-color-white,#fff)}.search-btn .search-icon[data-v-edc0d12c]{height:26px;padding:2px 0 var(--rh-space-xs,4px);width:20px}.search-btn .search-icon[data-v-edc0d12c],.search-icon-helper-text[data-v-edc0d12c]{color:var(--rh-color-white,#fff)}.search-mobile[data-v-edc0d12c]{margin-bottom:var(--rh-space-2xl,32px)}.search-mobile form[data-v-edc0d12c]{display:flex;gap:var(--rh-space-md,8px);margin:auto}.search-box[data-v-edc0d12c]{width:35rem}nav[data-v-edc0d12c]{background-color:#151515;justify-content:space-between;width:100%}a[data-v-edc0d12c],a[data-v-edc0d12c]:visited{color:#fff;display:inline-block;font-size:var(--rh-font-size-body-text-md,1rem)}.skip-link[class][class][data-v-edc0d12c]{font-size:var(--pf-global--FontSize--sm,.875rem);line-height:18px}.skip-link[class][class][data-v-edc0d12c]:focus{border-radius:.21429em;height:auto;left:50%;padding:.42857em .57143em;position:fixed;top:8px;transform:translateX(-50%);width:auto;z-index:99999;clip:auto;background:#fff;background:var(--pfe-navigation__skip-link--BackgroundColor,var(--pfe-theme--color--surface--lightest,#fff));color:#06c;color:var(--pfe-navigation__skip-link--Color,var(--pfe-theme--color--link,#06c));text-decoration:none}.visually-hidden[data-v-edc0d12c]{border:1px solid #06c;height:1px;overflow:hidden;padding:0;position:absolute;width:1px;clip:rect(0,0,0,0);white-space:nowrap}h3[data-v-edc0d12c]{color:#464646;font-family:var(--rh-font-family-heading,"Red Hat Display",Helvetica,Arial,sans-serif);font-size:var(--rh-font-size-body-text-lg,1.125rem)}.language-picker[data-v-edc0d12c]{align-items:center;background-color:#fff;display:flex;flex-direction:column;padding:var(--rh-space-xl,24px);width:100%}.language-picker h3[data-v-edc0d12c]{margin:0;padding:0 1rem 1rem}.language-picker ul[data-v-edc0d12c]{margin:0;padding:0}.language-picker a[data-v-edc0d12c]{color:#06c}.language-picker li[data-v-edc0d12c]{list-style:none}.language-dropdown[data-v-edc0d12c]{background:#fff;box-shadow:0 3px 6px rgba(0,0,0,.098);display:block!important;position:absolute;right:0;width:100%;z-index:104}.pfe-navigation.pfe-navigation--processed>[slot=secondary-links][data-v-edc0d12c]{height:auto;overflow:visible;visibility:visible;width:auto}.upper-navigation[data-v-edc0d12c]{padding:0 var(--rh-space-2xl,32px)}.upper-nav-container[data-v-edc0d12c]{border-bottom:1px solid #404040;margin:0}.upper-nav-hidden[data-v-edc0d12c]:not(:focus):not(:active){clip:rect(0 0 0 0);clip-path:inset(50%);height:1px;overflow:hidden;position:absolute;white-space:nowrap;width:1px}.upper-nav-menu[data-v-edc0d12c]{align-items:center;display:flex;justify-content:flex-end;line-height:1.444;list-style:none;margin-bottom:0;margin-top:0;padding-left:0}.upper-nav-menu[data-v-edc0d12c],.upper-nav-menu>li[data-v-edc0d12c]{position:relative}.upper-nav-menu>li:not(:first-child)>a[data-v-edc0d12c]:before,.upper-nav-menu>li:not(:first-child)>button[data-v-edc0d12c]:before{background-color:#404040;content:"";height:40%;left:0;position:absolute;top:30%;width:1px}li[data-v-edc0d12c]{display:list-item;margin:0;padding:0;text-align:-webkit-match-parent}.upper-nav-menu button.upper-nav-links[data-v-edc0d12c]{border:0;border-top:3px solid transparent;cursor:pointer;line-height:1.444}.upper-nav-menu button.upper-nav-links[aria-expanded=true][data-v-edc0d12c]{outline-color:#151515}.upper-nav-menu button.upper-nav-links[aria-expanded=true] .upper-nav-arrow[data-v-edc0d12c]{filter:invert(0) sepia(2%) saturate(21%) hue-rotate(257deg) brightness(108%) contrast(100%);transform:rotate(270deg)}.upper-nav-menu button.upper-nav-links[aria-expanded=true][data-v-edc0d12c]:before{display:none}.upper-nav-menu .upper-nav-links[data-v-edc0d12c]{background-color:var(--pfe-navigation--BackgroundColor,var(--pfe-theme--color--surface--darkest,#151515));border-top:3px solid transparent;color:#fff;display:block;font-family:var(--rh-font-family-body-text,"Red Hat Text","RedHatText",Arial,sans-serif);font-size:var(--rh-font-size-body-text-sm,.875rem);outline:none;padding:12px 12px 14px;text-decoration:none}.upper-nav-menu .upper-nav-links[data-v-edc0d12c]:hover{border-top-color:#b8bbbe}.upper-nav-menu .upper-nav-links[data-v-edc0d12c]:focus-within{outline:1px dashed var(--rh-color-white,#fff);outline-offset:-1px}.upper-nav-menu .upper-nav-links[data-v-edc0d12c]:focus-within:before{display:none}.upper-nav-dropdown-container[data-v-edc0d12c]{background:#fff;box-shadow:0 3px 6px rgba(0,0,0,.098);display:none;padding:5px 30px 24px;position:absolute;right:0;top:100%;width:500px;z-index:105}.upper-nav-dropdown-container>ul[data-v-edc0d12c]{-moz-column-count:2;column-count:2;list-style-type:none;padding:0;width:auto}.upper-nav-dropdown-container>ul li[data-v-edc0d12c]{color:#151515;font-family:var(--rh-font-family-heading,"Red Hat Display",Helvetica,Arial,sans-serif);font-size:var(--rh-font-size-body-text-sm,.875rem);list-style-type:none;margin-bottom:0}.upper-nav-dropdown-container>ul li span[data-v-edc0d12c]{font-weight:var(--rh-font-weight-body-text-medium,500)}.upper-nav-dropdown-container>ul ul[data-v-edc0d12c]{padding-left:0;padding-top:9px}.upper-nav-dropdown-container>ul>li[data-v-edc0d12c]{padding-top:19px;-moz-column-break-inside:avoid;break-inside:avoid}.upper-nav-dropdown-container>ul>li>ul>li[data-v-edc0d12c]{line-height:1.45;padding:4px 0}.upper-nav-menu .upper-nav-arrow[data-v-edc0d12c]{display:inline-block;filter:invert(100%) sepia(8%) saturate(7%) hue-rotate(1turn) brightness(100%) contrast(93%);height:18px;margin-left:5px;transform:rotate(90deg);vertical-align:middle;width:8px}#pfe-navigation__secondary-links .show[data-v-edc0d12c],.upper-navigation .show[data-v-edc0d12c]{display:block}.upper-nav-menu .upper-nav-links[aria-expanded=true][data-v-edc0d12c]:active,.upper-nav-menu .upper-nav-links[aria-expanded=true][data-v-edc0d12c]:focus,.upper-nav-menu .upper-nav-links[aria-expanded=true][data-v-edc0d12c]:hover{background-color:#fff;color:#151515}.upper-nav-menu .upper-nav-links[aria-expanded=true][data-v-edc0d12c]{background-color:#fff;border-top-color:#b8bbbe;color:#000;position:relative;z-index:1}.upper-nav-dropdown-container>ul a[data-v-edc0d12c]{color:var(--rh-color-accent-base-on-light,#06c);font-family:var(--rh-font-family-body-text,"Red Hat Text","RedHatText",Arial,sans-serif);font-size:14px;text-decoration:none}.pfe-navigation__search[data-v-edc0d12c]{background-color:var(--rh-color-white,#fff)}.pfe-navigation__search form[data-v-edc0d12c]{display:flex;gap:var(--rh-space-md,8px);margin:auto;max-width:992px}pfe-navigation [slot=secondary-links] .buttons[data-v-edc0d12c]{display:flex;flex-wrap:wrap;gap:var(--rh-space-md,8px);margin-top:4px}pfe-navigation [slot=secondary-links] .buttons a[data-v-edc0d12c]{border:1px solid #d2d2d2;border-radius:3px;color:#06c;cursor:pointer;flex-basis:calc(50% - 5px);font-family:var(--rh-font-family-body-text,"Red Hat Text","RedHatText",Arial,sans-serif);font-weight:var(--rh-font-weight-code-regular,400);padding:1em;text-align:center;text-decoration:none}pfe-navigation [slot=secondary-links] .mobile-lang-select[data-v-edc0d12c]{border:1px solid #d2d2d2;border-bottom-color:#3c3f42;cursor:pointer;display:flex;margin:3rem 0;position:relative}pfe-navigation [slot=secondary-links] .mobile-lang-select label[data-v-edc0d12c]{bottom:100%;color:#000;font-family:var(--rh-font-family-body-text,"Red Hat Text","RedHatText",Arial,sans-serif);font-size:14px;font-weight:500;margin-bottom:5px;position:absolute}pfe-navigation [slot=secondary-links] .mobile-lang-select select[data-v-edc0d12c]{-webkit-appearance:none;-moz-appearance:none;appearance:none;background-color:#fff;border-style:none;color:#000;flex-basis:100%;font-family:var(--rh-font-family-body-text,"Red Hat Text","RedHatText",Arial,sans-serif);font-size:16px;line-height:24px;padding:6px 24px 6px 8px}select[data-v-edc0d12c]{background-image:url("data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http://www.w3.org/2000/svg' width='10' height='6' fill='none' viewBox='0 0 10 6'%3E%3Cpath fill='%23151515' d='M.678 0h8.644c.596 0 .895.797.497 1.195l-4.372 4.58c-.298.3-.695.3-.993 0L.18 1.196C-.216.797.081 0 .678 0'/%3E%3C/svg%3E");background-position:98% 50%;background-repeat:no-repeat}#inputLabel[data-v-edc0d12c]{align-items:center;display:flex;position:relative}#inputLabel form[data-v-edc0d12c]{width:100%}.input-box[data-v-edc0d12c]{font-family:var(--rh-font-family-body-text,"Red Hat Text","RedHatText",Arial,sans-serif);font-size:var(--rh-font-size-body-text-md,1rem);height:36px;padding:0 8px;width:100%}.input-box[data-v-edc0d12c]::-moz-placeholder{color:#6a6e73;font-family:var(--rh-font-family-body-text,"Red Hat Text","RedHatText",Arial,sans-serif);font-size:var(--rh-font-size-body-text-md,1rem);font-weight:var(--rh-font-weight-code-regular,400);line-height:24px}.input-box[data-v-edc0d12c]::placeholder{color:#6a6e73;font-family:var(--rh-font-family-body-text,"Red Hat Text","RedHatText",Arial,sans-serif);font-size:var(--rh-font-size-body-text-md,1rem);font-weight:var(--rh-font-weight-code-regular,400);line-height:24px}@media(max-width:960px){.search-box[data-v-edc0d12c]{width:28rem}}@media (max-width:768px){.right-navigation[data-v-edc0d12c],.upper-navigation[data-v-edc0d12c]{display:none}}@media (min-width:767px){.pfe-navigation__search form[data-v-edc0d12c]{padding:var(--rh-space-2xl,32px) 0}}</style>
<style>.element-invisible,.sr-only,.visually-hidden{height:1px;overflow:hidden;padding:0;position:absolute;width:1px;clip:rect(0,0,0,0);border:0;white-space:nowrap}@keyframes reveal-nav{0%{max-height:72px;max-height:var(--pfe-navigation__nav-bar--Height,72px);opacity:0;visibility:hidden}99%{max-height:72px;max-height:var(--pfe-navigation__nav-bar--Height,72px)}to{max-height:9999em;opacity:1;visibility:visible}}@keyframes reveal-nav-parts{0%{max-height:72px;max-height:var(--pfe-navigation__nav-bar--Height,72px);opacity:0;visibility:hidden}1%{visibility:visible}99%{max-height:72px;max-height:var(--pfe-navigation__nav-bar--Height,72px)}to{max-height:9999em;opacity:1;visibility:visible}}@media print{.pfe-navigation__menu,pfe-navigation [slot]{display:none!important}}pfe-navigation{--pfe-broadcasted--text:var(--pfe-theme--color--text,#151515);--pfe-broadcasted--text--muted:var(--pfe-theme--color--text--muted,#6a6e73);--pfe-broadcasted--link:var(--pfe-theme--color--link,#06c);--pfe-broadcasted--link--hover:var(--pfe-theme--color--link--hover,#004080);--pfe-broadcasted--link--focus:var(--pfe-theme--color--link--focus,#004080);--pfe-broadcasted--link--visited:var(--pfe-theme--color--link--visited,#6753ac);--pfe-broadcasted--link-decoration:var(--pfe-theme--link-decoration,none);--pfe-broadcasted--link-decoration--hover:var(--pfe-theme--link-decoration--hover,underline);--pfe-broadcasted--link-decoration--focus:var(--pfe-theme--link-decoration--focus,underline);--pfe-broadcasted--link-decoration--visited:var(--pfe-theme--link-decoration--visited,none)}@supports (display:grid){pfe-navigation{animation:reveal-nav .1618s 4s 1 forwards;max-height:72px;max-height:var(--pfe-navigation__nav-bar--Height,72px)}pfe-navigation>*{animation:reveal-nav-parts .1618s 4s 1 forwards;opacity:0;transition:opacity .1618s ease-in-out;transition:opacity var(--pfe-reveal-duration,.1618s) ease-in-out;visibility:hidden}}pfe-navigation.pfe-navigation--processed,pfe-navigation.pfe-navigation--processed>*{animation:none;opacity:1;visibility:visible}pfe-navigation pfe-primary-detail{display:none}pfe-navigation[pfelement]{display:block}pfe-navigation-dropdown{color:#151515;color:var(--pfe-navigation__dropdown--Color,#151515)}#pfe-navigation[breakpoint=desktop] .hidden-at-desktop[class][class][class],#pfe-navigation[breakpoint=mobile] .hidden-at-mobile[class][class][class],#pfe-navigation[breakpoint=tablet] .hidden-at-tablet[class][class][class],pfe-navigation[breakpoint=desktop] .hidden-at-desktop[class][class][class],pfe-navigation[breakpoint=mobile] .hidden-at-mobile[class][class][class],pfe-navigation[breakpoint=tablet] .hidden-at-tablet[class][class][class]{display:none}#pfe-navigation,#pfe-navigation *,pfe-navigation,pfe-navigation *{box-sizing:border-box}#pfe-navigation [pfelement] .pfe-navigation__log-in-link,pfe-navigation [pfelement] .pfe-navigation__log-in-link{display:none}#pfe-navigation,pfe-navigation{align-items:stretch;background:#151515;background:var(--pfe-navigation__nav-bar--Background,#151515);color:#fff;color:var(--pfe-navigation__nav-bar--Color--default,var(--pfe-theme--color--ui-base--text,#fff));display:flex;font-family:Red Hat Text,RedHatText,Arial,Helvetica,sans-serif;font-family:var(--pfe-navigation--FontFamily,Red Hat Text,RedHatText,Arial,Helvetica,sans-serif);font-size:1rem;font-size:var(--pf-global--FontSize--md,1rem);height:72px;height:var(--pfe-navigation__nav-bar--Height,72px);height:auto;line-height:1.5;margin:0;max-width:9999em;min-height:72px;min-height:var(--pfe-navigation__nav-bar--Height,72px);padding:0 16px;position:relative;z-index:95;z-index:var(--pfe-navigation--ZIndex,var(--pfe-theme--zindex--navigation,95))}@media (min-width:768px){#pfe-navigation,pfe-navigation{flex-wrap:wrap;margin:0;max-width:9999em;padding:0 16px}}@media (min-width:1200px){#pfe-navigation,pfe-navigation{margin:0 auto;padding:0 32px}}#pfe-navigation .pfe-navigation__dropdown,#pfe-navigation pfe-navigation-dropdown,pfe-navigation .pfe-navigation__dropdown,pfe-navigation pfe-navigation-dropdown{display:none}#pfe-navigation>[slot=account],#pfe-navigation>[slot=search],#pfe-navigation>[slot=secondary-links],pfe-navigation>[slot=account],pfe-navigation>[slot=search],pfe-navigation>[slot=secondary-links]{height:0;overflow:hidden;visibility:hidden;width:0}@media (min-width:768px){#pfe-navigation nav.pfe-navigation,pfe-navigation nav.pfe-navigation{align-items:stretch;display:flex;flex-wrap:wrap}}@media (min-width:992px){#pfe-navigation nav.pfe-navigation,pfe-navigation nav.pfe-navigation{flex-wrap:nowrap}}#pfe-navigation .pfe-navigation__logo-wrapper,pfe-navigation .pfe-navigation__logo-wrapper{align-items:center;display:flex;justify-content:flex-start;margin:0;min-width:150px;padding:10px 16px 10px 0}@media (min-width:768px){.pfe-navigation--no-main-menu #pfe-navigation .pfe-navigation__logo-wrapper,.pfe-navigation--no-main-menu pfe-navigation .pfe-navigation__logo-wrapper{margin-right:auto}}.pfe-navigation--collapse-secondary-links .pfe-navigation--no-main-menu #pfe-navigation .pfe-navigation__logo-wrapper,.pfe-navigation--collapse-secondary-links .pfe-navigation--no-main-menu pfe-navigation .pfe-navigation__logo-wrapper{margin-right:0}#pfe-navigation .pfe-navigation__logo-link,pfe-navigation .pfe-navigation__logo-link{border-radius:3px;display:block;margin-left:-8px;outline:0;padding:6px 8px;position:relative}#pfe-navigation .pfe-navigation__logo-link:focus,pfe-navigation .pfe-navigation__logo-link:focus{outline:0}#pfe-navigation .pfe-navigation__logo-link:focus:after,pfe-navigation .pfe-navigation__logo-link:focus:after{border:1px dashed #fff;bottom:0;content:"";display:block;left:0;position:absolute;right:0;top:0}#pfe-navigation .pfe-navigation__logo-image,pfe-navigation .pfe-navigation__logo-image{display:block;height:auto;width:100%}@media (min-width:576px){#pfe-navigation .pfe-navigation__logo-image,pfe-navigation .pfe-navigation__logo-image{height:40px;height:var(--pfe-navigation__logo--height,40px);width:auto}}@media print{#pfe-navigation .pfe-navigation__logo-image,pfe-navigation .pfe-navigation__logo-image{display:none}}#pfe-navigation .pfe-navigation__logo-image:only-child,pfe-navigation .pfe-navigation__logo-image:only-child{display:block}@media (min-width:576px){#pfe-navigation .pfe-navigation__logo-image.pfe-navigation__logo-image--small,pfe-navigation .pfe-navigation__logo-image.pfe-navigation__logo-image--small{height:32px;height:var(--pfe-navigation__logo--height,32px)}}@media print{#pfe-navigation .pfe-navigation__logo-image.pfe-navigation__logo-image--screen,pfe-navigation .pfe-navigation__logo-image.pfe-navigation__logo-image--screen{display:none!important}}@media screen{#pfe-navigation .pfe-navigation__logo-image.pfe-navigation__logo-image--print,pfe-navigation .pfe-navigation__logo-image.pfe-navigation__logo-image--print{display:none!important}}#pfe-navigation .pfe-navigation__logo-image.pfe-navigation__logo-image--screen.pfe-navigation__logo-image--print,pfe-navigation .pfe-navigation__logo-image.pfe-navigation__logo-image--screen.pfe-navigation__logo-image--print{display:inline-block!important}#pfe-navigation .pfe-navigation__fallback-links a,#pfe-navigation .pfe-navigation__log-in-link,#pfe-navigation .pfe-navigation__menu-link,#pfe-navigation .pfe-navigation__secondary-link,pfe-navigation .pfe-navigation__fallback-links a,pfe-navigation .pfe-navigation__log-in-link,pfe-navigation .pfe-navigation__menu-link,pfe-navigation .pfe-navigation__secondary-link{--pfe-icon--color:var(--pfe-navigation__dropdown--link--Color,var(--pfe-theme--color--link,#06c));align-items:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;background:0 0;border:0;color:#06c;color:var(--pfe-navigation__dropdown--link--Color,var(--pfe-theme--color--link,#06c));color:#fff;color:var(--pfe-navigation__nav-bar--Color--default,var(--pfe-theme--color--ui-base--text,#fff));cursor:pointer;display:flex;font-family:inherit;font-size:1rem;font-size:var(--pf-global--FontSize--md,1rem);justify-content:flex-start;justify-content:center;margin:0;outline:0;padding:8px 24px;position:relative;text-align:center;text-decoration:none;white-space:nowrap;width:100%}@media print{#pfe-navigation .pfe-navigation__fallback-links a,#pfe-navigation .pfe-navigation__log-in-link,#pfe-navigation .pfe-navigation__menu-link,#pfe-navigation .pfe-navigation__secondary-link,pfe-navigation .pfe-navigation__fallback-links a,pfe-navigation .pfe-navigation__log-in-link,pfe-navigation .pfe-navigation__menu-link,pfe-navigation .pfe-navigation__secondary-link{display:none!important}}@media (min-width:768px){#pfe-navigation .pfe-navigation__fallback-links a,#pfe-navigation .pfe-navigation__log-in-link,#pfe-navigation .pfe-navigation__menu-link,#pfe-navigation .pfe-navigation__secondary-link,pfe-navigation .pfe-navigation__fallback-links a,pfe-navigation .pfe-navigation__log-in-link,pfe-navigation .pfe-navigation__menu-link,pfe-navigation .pfe-navigation__secondary-link{--pfe-icon--color:var(--pfe-navigation__nav-bar--Color--default,var(--pfe-theme--color--ui-base--text,#fff));color:#fff;color:var(--pfe-navigation__nav-bar--Color--default,var(--pfe-theme--color--ui-base--text,#fff));display:flex;flex-direction:column;font-size:12px;font-size:var(--pfe-navigation--FontSize--xs,12px);height:72px;height:var(--pfe-navigation__nav-bar--Height,72px);justify-content:flex-end;padding:14px 8px;width:auto}@supports (display:grid){#pfe-navigation .pfe-navigation__fallback-links a,#pfe-navigation .pfe-navigation__log-in-link,#pfe-navigation .pfe-navigation__menu-link,#pfe-navigation .pfe-navigation__secondary-link,pfe-navigation .pfe-navigation__fallback-links a,pfe-navigation .pfe-navigation__log-in-link,pfe-navigation .pfe-navigation__menu-link,pfe-navigation .pfe-navigation__secondary-link{align-items:center;display:grid;grid-template-rows:26px 18px;justify-items:center}}#pfe-navigation .pfe-navigation__fallback-links a[class]:focus,#pfe-navigation .pfe-navigation__fallback-links a[class]:hover,#pfe-navigation .pfe-navigation__log-in-link[class]:focus,#pfe-navigation .pfe-navigation__log-in-link[class]:hover,#pfe-navigation .pfe-navigation__menu-link[class]:focus,#pfe-navigation .pfe-navigation__menu-link[class]:hover,#pfe-navigation .pfe-navigation__secondary-link[class]:focus,#pfe-navigation .pfe-navigation__secondary-link[class]:hover,pfe-navigation .pfe-navigation__fallback-links a[class]:focus,pfe-navigation .pfe-navigation__fallback-links a[class]:hover,pfe-navigation .pfe-navigation__log-in-link[class]:focus,pfe-navigation .pfe-navigation__log-in-link[class]:hover,pfe-navigation .pfe-navigation__menu-link[class]:focus,pfe-navigation .pfe-navigation__menu-link[class]:hover,pfe-navigation .pfe-navigation__secondary-link[class]:focus,pfe-navigation .pfe-navigation__secondary-link[class]:hover{box-shadow:inset 0 4px 0 0 #06c;box-shadow:inset 0 4px 0 0 var(--pfe-navigation__nav-bar--highlight-color,var(--pfe-theme--color--ui-accent,#06c))}}#pfe-navigation .pfe-navigation__fallback-links a:focus,#pfe-navigation .pfe-navigation__fallback-links a:hover,#pfe-navigation .pfe-navigation__log-in-link:focus,#pfe-navigation .pfe-navigation__log-in-link:hover,#pfe-navigation .pfe-navigation__menu-link:focus,#pfe-navigation .pfe-navigation__menu-link:hover,#pfe-navigation .pfe-navigation__secondary-link:focus,#pfe-navigation .pfe-navigation__secondary-link:hover,pfe-navigation .pfe-navigation__fallback-links a:focus,pfe-navigation .pfe-navigation__fallback-links a:hover,pfe-navigation .pfe-navigation__log-in-link:focus,pfe-navigation .pfe-navigation__log-in-link:hover,pfe-navigation .pfe-navigation__menu-link:focus,pfe-navigation .pfe-navigation__menu-link:hover,pfe-navigation .pfe-navigation__secondary-link:focus,pfe-navigation .pfe-navigation__secondary-link:hover{box-shadow:inset 4px 0 0 0 #06c;box-shadow:inset 4px 0 0 0 var(--pfe-navigation__nav-bar--highlight-color,var(--pfe-theme--color--ui-accent,#06c))}@media (min-width:768px){#pfe-navigation .pfe-navigation__fallback-links a:focus,#pfe-navigation .pfe-navigation__fallback-links a:hover,#pfe-navigation .pfe-navigation__log-in-link:focus,#pfe-navigation .pfe-navigation__log-in-link:hover,#pfe-navigation .pfe-navigation__menu-link:focus,#pfe-navigation .pfe-navigation__menu-link:hover,#pfe-navigation .pfe-navigation__secondary-link:focus,#pfe-navigation .pfe-navigation__secondary-link:hover,pfe-navigation .pfe-navigation__fallback-links a:focus,pfe-navigation .pfe-navigation__fallback-links a:hover,pfe-navigation .pfe-navigation__log-in-link:focus,pfe-navigation .pfe-navigation__log-in-link:hover,pfe-navigation .pfe-navigation__menu-link:focus,pfe-navigation .pfe-navigation__menu-link:hover,pfe-navigation .pfe-navigation__secondary-link:focus,pfe-navigation .pfe-navigation__secondary-link:hover{box-shadow:inset 0 4px 0 0 #06c;box-shadow:inset 0 4px 0 0 var(--pfe-navigation__nav-bar--highlight-color,var(--pfe-theme--color--ui-accent,#06c))}}.pfe-navigation--collapse-secondary-links #pfe-navigation .pfe-navigation__fallback-links a:focus,.pfe-navigation--collapse-secondary-links #pfe-navigation .pfe-navigation__fallback-links a:hover,.pfe-navigation--collapse-secondary-links #pfe-navigation .pfe-navigation__log-in-link:focus,.pfe-navigation--collapse-secondary-links #pfe-navigation .pfe-navigation__log-in-link:hover,.pfe-navigation--collapse-secondary-links #pfe-navigation .pfe-navigation__menu-link:focus,.pfe-navigation--collapse-secondary-links #pfe-navigation .pfe-navigation__menu-link:hover,.pfe-navigation--collapse-secondary-links #pfe-navigation .pfe-navigation__secondary-link:focus,.pfe-navigation--collapse-secondary-links #pfe-navigation .pfe-navigation__secondary-link:hover,.pfe-navigation--collapse-secondary-links pfe-navigation .pfe-navigation__fallback-links a:focus,.pfe-navigation--collapse-secondary-links pfe-navigation .pfe-navigation__fallback-links a:hover,.pfe-navigation--collapse-secondary-links pfe-navigation .pfe-navigation__log-in-link:focus,.pfe-navigation--collapse-secondary-links pfe-navigation .pfe-navigation__log-in-link:hover,.pfe-navigation--collapse-secondary-links pfe-navigation .pfe-navigation__menu-link:focus,.pfe-navigation--collapse-secondary-links pfe-navigation .pfe-navigation__menu-link:hover,.pfe-navigation--collapse-secondary-links pfe-navigation .pfe-navigation__secondary-link:focus,.pfe-navigation--collapse-secondary-links pfe-navigation .pfe-navigation__secondary-link:hover{box-shadow:inset 4px 0 0 0 #06c;box-shadow:inset 4px 0 0 0 var(--pfe-navigation__nav-bar--highlight-color,var(--pfe-theme--color--ui-accent,#06c))}#pfe-navigation .pfe-navigation__fallback-links a:focus,#pfe-navigation .pfe-navigation__log-in-link:focus,#pfe-navigation .pfe-navigation__menu-link:focus,#pfe-navigation .pfe-navigation__secondary-link:focus,pfe-navigation .pfe-navigation__fallback-links a:focus,pfe-navigation .pfe-navigation__log-in-link:focus,pfe-navigation .pfe-navigation__menu-link:focus,pfe-navigation .pfe-navigation__secondary-link:focus{outline:0}#pfe-navigation .pfe-navigation__fallback-links a:focus:after,#pfe-navigation .pfe-navigation__log-in-link:focus:after,#pfe-navigation .pfe-navigation__menu-link:focus:after,#pfe-navigation .pfe-navigation__secondary-link:focus:after,pfe-navigation .pfe-navigation__fallback-links a:focus:after,pfe-navigation .pfe-navigation__log-in-link:focus:after,pfe-navigation .pfe-navigation__menu-link:focus:after,pfe-navigation .pfe-navigation__secondary-link:focus:after{border:1px dashed;bottom:0;content:"";display:block;left:0;position:absolute;right:0;top:0}#pfe-navigation .pfe-navigation__fallback-links a pfe-icon,#pfe-navigation .pfe-navigation__log-in-link pfe-icon,#pfe-navigation .pfe-navigation__menu-link pfe-icon,#pfe-navigation .pfe-navigation__secondary-link pfe-icon,pfe-navigation .pfe-navigation__fallback-links a pfe-icon,pfe-navigation .pfe-navigation__log-in-link pfe-icon,pfe-navigation .pfe-navigation__menu-link pfe-icon,pfe-navigation .pfe-navigation__secondary-link pfe-icon{pointer-events:none}#pfe-navigation .pfe-navigation__fallback-links a .secondary-link__icon-wrapper,#pfe-navigation .pfe-navigation__fallback-links a>pfe-icon,#pfe-navigation .pfe-navigation__log-in-link .secondary-link__icon-wrapper,#pfe-navigation .pfe-navigation__log-in-link>pfe-icon,#pfe-navigation .pfe-navigation__menu-link .secondary-link__icon-wrapper,#pfe-navigation .pfe-navigation__menu-link>pfe-icon,#pfe-navigation .pfe-navigation__secondary-link .secondary-link__icon-wrapper,#pfe-navigation .pfe-navigation__secondary-link>pfe-icon,pfe-navigation .pfe-navigation__fallback-links a .secondary-link__icon-wrapper,pfe-navigation .pfe-navigation__fallback-links a>pfe-icon,pfe-navigation .pfe-navigation__log-in-link .secondary-link__icon-wrapper,pfe-navigation .pfe-navigation__log-in-link>pfe-icon,pfe-navigation .pfe-navigation__menu-link .secondary-link__icon-wrapper,pfe-navigation .pfe-navigation__menu-link>pfe-icon,pfe-navigation .pfe-navigation__secondary-link .secondary-link__icon-wrapper,pfe-navigation .pfe-navigation__secondary-link>pfe-icon{--pfe-icon--size:18px;padding-right:5px}@media (min-width:768px){#pfe-navigation .pfe-navigation__fallback-links a .secondary-link__icon-wrapper,#pfe-navigation .pfe-navigation__fallback-links a>pfe-icon,#pfe-navigation .pfe-navigation__log-in-link .secondary-link__icon-wrapper,#pfe-navigation .pfe-navigation__log-in-link>pfe-icon,#pfe-navigation .pfe-navigation__menu-link .secondary-link__icon-wrapper,#pfe-navigation .pfe-navigation__menu-link>pfe-icon,#pfe-navigation .pfe-navigation__secondary-link .secondary-link__icon-wrapper,#pfe-navigation .pfe-navigation__secondary-link>pfe-icon,pfe-navigation .pfe-navigation__fallback-links a .secondary-link__icon-wrapper,pfe-navigation .pfe-navigation__fallback-links a>pfe-icon,pfe-navigation .pfe-navigation__log-in-link .secondary-link__icon-wrapper,pfe-navigation .pfe-navigation__log-in-link>pfe-icon,pfe-navigation .pfe-navigation__menu-link .secondary-link__icon-wrapper,pfe-navigation .pfe-navigation__menu-link>pfe-icon,pfe-navigation .pfe-navigation__secondary-link .secondary-link__icon-wrapper,pfe-navigation .pfe-navigation__secondary-link>pfe-icon{padding-right:0;padding:2px 0 4px}}.pfe-navigation--collapse-secondary-links #pfe-navigation .pfe-navigation__fallback-links a .secondary-link__icon-wrapper,.pfe-navigation--collapse-secondary-links #pfe-navigation .pfe-navigation__fallback-links a>pfe-icon,.pfe-navigation--collapse-secondary-links #pfe-navigation .pfe-navigation__log-in-link .secondary-link__icon-wrapper,.pfe-navigation--collapse-secondary-links #pfe-navigation .pfe-navigation__log-in-link>pfe-icon,.pfe-navigation--collapse-secondary-links #pfe-navigation .pfe-navigation__menu-link .secondary-link__icon-wrapper,.pfe-navigation--collapse-secondary-links #pfe-navigation .pfe-navigation__menu-link>pfe-icon,.pfe-navigation--collapse-secondary-links #pfe-navigation .pfe-navigation__secondary-link .secondary-link__icon-wrapper,.pfe-navigation--collapse-secondary-links #pfe-navigation .pfe-navigation__secondary-link>pfe-icon,.pfe-navigation--collapse-secondary-links pfe-navigation .pfe-navigation__fallback-links a .secondary-link__icon-wrapper,.pfe-navigation--collapse-secondary-links pfe-navigation .pfe-navigation__fallback-links a>pfe-icon,.pfe-navigation--collapse-secondary-links pfe-navigation .pfe-navigation__log-in-link .secondary-link__icon-wrapper,.pfe-navigation--collapse-secondary-links pfe-navigation .pfe-navigation__log-in-link>pfe-icon,.pfe-navigation--collapse-secondary-links pfe-navigation .pfe-navigation__menu-link .secondary-link__icon-wrapper,.pfe-navigation--collapse-secondary-links pfe-navigation .pfe-navigation__menu-link>pfe-icon,.pfe-navigation--collapse-secondary-links pfe-navigation .pfe-navigation__secondary-link .secondary-link__icon-wrapper,.pfe-navigation--collapse-secondary-links pfe-navigation .pfe-navigation__secondary-link>pfe-icon{padding:0 16px 0 0}#pfe-navigation .pfe-navigation__fallback-links a pfe-icon,#pfe-navigation .pfe-navigation__log-in-link pfe-icon,#pfe-navigation .pfe-navigation__menu-link pfe-icon,#pfe-navigation .pfe-navigation__secondary-link pfe-icon,pfe-navigation .pfe-navigation__fallback-links a pfe-icon,pfe-navigation .pfe-navigation__log-in-link pfe-icon,pfe-navigation .pfe-navigation__menu-link pfe-icon,pfe-navigation .pfe-navigation__secondary-link pfe-icon{display:block;height:18px}#pfe-navigation .pfe-navigation__fallback-links a[class],#pfe-navigation .pfe-navigation__fallback-links a[href],#pfe-navigation .pfe-navigation__log-in-link[class],#pfe-navigation .pfe-navigation__log-in-link[href],#pfe-navigation .pfe-navigation__menu-link[class],#pfe-navigation .pfe-navigation__menu-link[href],#pfe-navigation .pfe-navigation__secondary-link[class],#pfe-navigation .pfe-navigation__secondary-link[href],pfe-navigation .pfe-navigation__fallback-links a[class],pfe-navigation .pfe-navigation__fallback-links a[href],pfe-navigation .pfe-navigation__log-in-link[class],pfe-navigation .pfe-navigation__log-in-link[href],pfe-navigation .pfe-navigation__menu-link[class],pfe-navigation .pfe-navigation__menu-link[href],pfe-navigation .pfe-navigation__secondary-link[class],pfe-navigation .pfe-navigation__secondary-link[href]{align-items:center;justify-content:center}#pfe-navigation .pfe-navigation__account-toggle,#pfe-navigation [slot=account]>a[href],pfe-navigation .pfe-navigation__account-toggle,pfe-navigation [slot=account]>a[href]{--pfe-icon--color:var(--pfe-navigation__dropdown--link--Color,var(--pfe-theme--color--link,#06c));align-items:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;background:0 0;border:0;color:#06c;color:var(--pfe-navigation__dropdown--link--Color,var(--pfe-theme--color--link,#06c));cursor:pointer;font-family:inherit;font-size:1rem;font-size:var(--pf-global--FontSize--md,1rem);justify-content:flex-start;margin:0;outline:0;position:relative;text-align:center;text-decoration:none;white-space:nowrap;width:100%;--pfe-icon--color:var(--pfe-navigation__nav-bar--Color--default,var(--pfe-theme--color--ui-base--text,#fff));color:#fff;color:var(--pfe-navigation__nav-bar--Color--default,var(--pfe-theme--color--ui-base--text,#fff));display:flex;flex-direction:column;font-size:12px;font-size:var(--pfe-navigation--FontSize--xs,12px);height:72px;height:var(--pfe-navigation__nav-bar--Height,72px);justify-content:flex-end;padding:14px 8px;width:auto}@media print{#pfe-navigation .pfe-navigation__account-toggle,#pfe-navigation [slot=account]>a[href],pfe-navigation .pfe-navigation__account-toggle,pfe-navigation [slot=account]>a[href]{display:none!important}}#pfe-navigation .pfe-navigation__account-toggle:focus,#pfe-navigation .pfe-navigation__account-toggle:hover,#pfe-navigation [slot=account]>a[href]:focus,#pfe-navigation [slot=account]>a[href]:hover,pfe-navigation .pfe-navigation__account-toggle:focus,pfe-navigation .pfe-navigation__account-toggle:hover,pfe-navigation [slot=account]>a[href]:focus,pfe-navigation [slot=account]>a[href]:hover{box-shadow:inset 4px 0 0 0 #06c;box-shadow:inset 4px 0 0 0 var(--pfe-navigation__nav-bar--highlight-color,var(--pfe-theme--color--ui-accent,#06c))}#pfe-navigation .pfe-navigation__account-toggle:focus,#pfe-navigation [slot=account]>a[href]:focus,pfe-navigation .pfe-navigation__account-toggle:focus,pfe-navigation [slot=account]>a[href]:focus{outline:0}#pfe-navigation .pfe-navigation__account-toggle:focus:after,#pfe-navigation [slot=account]>a[href]:focus:after,pfe-navigation .pfe-navigation__account-toggle:focus:after,pfe-navigation [slot=account]>a[href]:focus:after{border:1px dashed;bottom:0;content:"";display:block;left:0;position:absolute;right:0;top:0}#pfe-navigation .pfe-navigation__account-toggle pfe-icon,#pfe-navigation [slot=account]>a[href] pfe-icon,pfe-navigation .pfe-navigation__account-toggle pfe-icon,pfe-navigation [slot=account]>a[href] pfe-icon{pointer-events:none}@supports (display:grid){#pfe-navigation .pfe-navigation__account-toggle,#pfe-navigation [slot=account]>a[href],pfe-navigation .pfe-navigation__account-toggle,pfe-navigation [slot=account]>a[href]{align-items:center;display:grid;grid-template-rows:26px 18px;justify-items:center}}#pfe-navigation .pfe-navigation__account-toggle[class]:focus,#pfe-navigation .pfe-navigation__account-toggle[class]:hover,#pfe-navigation [slot=account]>a[href][class]:focus,#pfe-navigation [slot=account]>a[href][class]:hover,pfe-navigation .pfe-navigation__account-toggle[class]:focus,pfe-navigation .pfe-navigation__account-toggle[class]:hover,pfe-navigation [slot=account]>a[href][class]:focus,pfe-navigation [slot=account]>a[href][class]:hover{box-shadow:inset 0 4px 0 0 #06c;box-shadow:inset 0 4px 0 0 var(--pfe-navigation__nav-bar--highlight-color,var(--pfe-theme--color--ui-accent,#06c))}@media print{#pfe-navigation .pfe-navigation__account-toggle,#pfe-navigation [slot=account]>a[href],pfe-navigation .pfe-navigation__account-toggle,pfe-navigation [slot=account]>a[href]{display:none}}#pfe-navigation .pfe-navigation__account-toggle pfe-icon,#pfe-navigation [slot=account]>a[href] pfe-icon,pfe-navigation .pfe-navigation__account-toggle pfe-icon,pfe-navigation [slot=account]>a[href] pfe-icon{--pfe-icon--size:18px;padding:2px 0 4px}@media (min-width:768px){#pfe-navigation .pfe-navigation__account-toggle pfe-icon,#pfe-navigation [slot=account]>a[href] pfe-icon,pfe-navigation .pfe-navigation__account-toggle pfe-icon,pfe-navigation [slot=account]>a[href] pfe-icon{padding-right:0}}#pfe-navigation .pfe-navigation__account-toggle:focus,#pfe-navigation .pfe-navigation__account-toggle:hover,#pfe-navigation .pfe-navigation__account-toggle[aria-expanded=true],#pfe-navigation [slot=account]>a[href][href]:focus,#pfe-navigation [slot=account]>a[href][href]:hover,pfe-navigation .pfe-navigation__account-toggle:focus,pfe-navigation .pfe-navigation__account-toggle:hover,pfe-navigation .pfe-navigation__account-toggle[aria-expanded=true],pfe-navigation [slot=account]>a[href][href]:focus,pfe-navigation [slot=account]>a[href][href]:hover{box-shadow:inset 0 4px 0 0 #06c;box-shadow:inset 0 4px 0 0 var(--pfe-navigation__nav-bar--highlight-color,var(--pfe-theme--color--ui-accent,#06c))}#pfe-navigation .pfe-navigation__account-toggle[aria-expanded=true],pfe-navigation .pfe-navigation__account-toggle[aria-expanded=true]{--pfe-icon--color:var(--pfe-navigation__nav-bar--Color--active,var(--pfe-theme--color--text,#151515));background:#fff;background:var(--pfe-navigation__nav-bar--toggle--BackgroundColor--active,var(--pfe-theme--color--surface--lightest,#fff));color:#151515;color:var(--pfe-navigation__nav-bar--Color--active,var(--pfe-theme--color--text,#151515))}#pfe-navigation .pfe-navigation__account-toggle[aria-expanded=true]:focus,pfe-navigation .pfe-navigation__account-toggle[aria-expanded=true]:focus{outline:0}#pfe-navigation .pfe-navigation__account-toggle[aria-expanded=true]:focus:after,pfe-navigation .pfe-navigation__account-toggle[aria-expanded=true]:focus:after{border:1px dashed #151515;border:1px dashed var(--pfe-navigation__nav-bar--Color--active,var(--pfe-theme--color--text,#151515));bottom:0;content:"";display:block;left:0;position:absolute;right:0;top:0}#pfe-navigation .pfe-navigation__fallback-links,#pfe-navigation .pfe-navigation__menu,pfe-navigation .pfe-navigation__fallback-links,pfe-navigation .pfe-navigation__menu{font-size:inherit;list-style:none;margin:0;padding:0}@media (min-width:768px){#pfe-navigation .pfe-navigation__fallback-links,#pfe-navigation .pfe-navigation__menu,pfe-navigation .pfe-navigation__fallback-links,pfe-navigation .pfe-navigation__menu{align-items:stretch;display:flex}}#pfe-navigation .pfe-navigation__fallback-links li,#pfe-navigation .pfe-navigation__menu li,pfe-navigation .pfe-navigation__fallback-links li,pfe-navigation .pfe-navigation__menu li{font-size:inherit;margin:0;padding:0}#pfe-navigation .pfe-navigation__fallback-links li:before,#pfe-navigation .pfe-navigation__menu li:before,pfe-navigation .pfe-navigation__fallback-links li:before,pfe-navigation .pfe-navigation__menu li:before{content:none}#pfe-navigation .pfe-navigation__fallback-links,pfe-navigation .pfe-navigation__fallback-links{margin-left:auto}#pfe-navigation .pfe-navigation__menu-link,pfe-navigation .pfe-navigation__menu-link{display:flex;font-size:1rem;font-size:var(--pf-global--FontSize--md,1rem);white-space:nowrap}#pfe-navigation.pfe-navigation--processed,pfe-navigation.pfe-navigation--processed{display:block;padding:0}#pfe-navigation.pfe-navigation--processed:before,pfe-navigation.pfe-navigation--processed:before{content:none}#pfe-navigation.pfe-navigation--processed>[slot=account],#pfe-navigation.pfe-navigation--processed>[slot=search],#pfe-navigation.pfe-navigation--processed>[slot=secondary-links],pfe-navigation.pfe-navigation--processed>[slot=account],pfe-navigation.pfe-navigation--processed>[slot=search],pfe-navigation.pfe-navigation--processed>[slot=secondary-links]{height:auto;overflow:visible;visibility:visible;width:auto}#pfe-navigation.pfe-navigation--processed pfe-navigation-dropdown,pfe-navigation.pfe-navigation--processed pfe-navigation-dropdown{display:block}#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown,#pfe-navigation.pfe-navigation--processed pfe-navigation-dropdown,#pfe-navigation.pfe-navigation--processed>[slot],pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown,pfe-navigation.pfe-navigation--processed pfe-navigation-dropdown,pfe-navigation.pfe-navigation--processed>[slot]{animation:none;opacity:1}#pfe-navigation.pfe-navigation--processed [slot=secondary-links],pfe-navigation.pfe-navigation--processed [slot=secondary-links]{display:block;height:auto;list-style:none;margin:0 0 8px;padding:0;width:auto}@media (min-width:768px){#pfe-navigation.pfe-navigation--processed [slot=secondary-links],pfe-navigation.pfe-navigation--processed [slot=secondary-links]{margin:0}}.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed [slot=secondary-links],.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed [slot=secondary-links]{margin:0 0 8px}#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button{--pfe-icon--color:var(--pfe-navigation__dropdown--link--Color,var(--pfe-theme--color--link,#06c));align-items:center;-webkit-appearance:none;-moz-appearance:none;appearance:none;background:0 0;border:0;color:#06c;color:var(--pfe-navigation__dropdown--link--Color,var(--pfe-theme--color--link,#06c));cursor:pointer;display:flex;font-family:inherit;font-size:1rem;font-size:var(--pf-global--FontSize--md,1rem);justify-content:flex-start;margin:0;outline:0;padding:8px 24px;position:relative;text-align:center;text-decoration:none;white-space:nowrap;width:100%}@media print{#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button{display:none!important}}@media (min-width:768px){#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button{--pfe-icon--color:var(--pfe-navigation__nav-bar--Color--default,var(--pfe-theme--color--ui-base--text,#fff));color:#fff;color:var(--pfe-navigation__nav-bar--Color--default,var(--pfe-theme--color--ui-base--text,#fff));display:flex;flex-direction:column;font-size:12px;font-size:var(--pfe-navigation--FontSize--xs,12px);height:72px;height:var(--pfe-navigation__nav-bar--Height,72px);justify-content:flex-end;padding:14px 8px;width:auto}@supports (display:grid){#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button{align-items:center;display:grid;grid-template-rows:26px 18px;justify-items:center}}#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a[class]:focus,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a[class]:hover,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button[class]:focus,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button[class]:hover,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a[class]:focus,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a[class]:hover,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button[class]:focus,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button[class]:hover{box-shadow:inset 0 4px 0 0 #06c;box-shadow:inset 0 4px 0 0 var(--pfe-navigation__nav-bar--highlight-color,var(--pfe-theme--color--ui-accent,#06c))}}#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:focus,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:hover,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:focus,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:hover,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:focus,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:hover,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:focus,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:hover{box-shadow:inset 4px 0 0 0 #06c;box-shadow:inset 4px 0 0 0 var(--pfe-navigation__nav-bar--highlight-color,var(--pfe-theme--color--ui-accent,#06c))}@media (min-width:768px){#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:focus,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:hover,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:focus,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:hover,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:focus,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:hover,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:focus,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:hover{box-shadow:inset 0 4px 0 0 #06c;box-shadow:inset 0 4px 0 0 var(--pfe-navigation__nav-bar--highlight-color,var(--pfe-theme--color--ui-accent,#06c))}}.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:focus,.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:hover,.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:focus,.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:hover,.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:focus,.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:hover,.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:focus,.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:hover{box-shadow:inset 4px 0 0 0 #06c;box-shadow:inset 4px 0 0 0 var(--pfe-navigation__nav-bar--highlight-color,var(--pfe-theme--color--ui-accent,#06c))}#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:focus,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:focus,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:focus,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:focus{outline:0}#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:focus:after,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:focus:after,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:focus:after,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:focus:after{border:1px dashed;bottom:0;content:"";display:block;left:0;position:absolute;right:0;top:0}#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a pfe-icon,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button pfe-icon,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a pfe-icon,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button pfe-icon{pointer-events:none}#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a .secondary-link__icon-wrapper,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a>pfe-icon,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button .secondary-link__icon-wrapper,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button>pfe-icon,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a .secondary-link__icon-wrapper,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a>pfe-icon,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button .secondary-link__icon-wrapper,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button>pfe-icon{--pfe-icon--size:18px;padding-right:5px}@media (min-width:768px){#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a .secondary-link__icon-wrapper,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a>pfe-icon,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button .secondary-link__icon-wrapper,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button>pfe-icon,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a .secondary-link__icon-wrapper,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a>pfe-icon,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button .secondary-link__icon-wrapper,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button>pfe-icon{padding-right:0;padding:2px 0 4px}}.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a .secondary-link__icon-wrapper,.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a>pfe-icon,.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button .secondary-link__icon-wrapper,.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button>pfe-icon,.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a .secondary-link__icon-wrapper,.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a>pfe-icon,.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button .secondary-link__icon-wrapper,.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button>pfe-icon{padding:0 16px 0 0}#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a pfe-icon,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button pfe-icon,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a pfe-icon,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button pfe-icon{display:block;height:18px}@media (min-width:768px){#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:focus,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:focus,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:focus,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:focus{outline:0}#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:focus:after,#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:focus:after,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:focus:after,pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:focus:after{border:1px dashed #fff;border:1px dashed var(--pfe-navigation__nav-bar--Color--default,var(--pfe-theme--color--ui-base--text,#fff));bottom:0;content:"";display:block;left:0;position:absolute;right:0;top:0}}.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:focus,.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:focus,.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a:focus,.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button:focus{box-shadow:none}@media (min-width:768px){#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a[aria-expanded=true],#pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button[aria-expanded=true],pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a[aria-expanded=true],pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button[aria-expanded=true]{--pfe-icon--color:var(--pfe-navigation__nav-bar--Color--active,var(--pfe-theme--color--text,#151515));background:#fff;background:var(--pfe-navigation__nav-bar--toggle--BackgroundColor--active,var(--pfe-theme--color--surface--lightest,#fff));color:#151515;color:var(--pfe-navigation__nav-bar--Color--active,var(--pfe-theme--color--text,#151515))}}.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a[aria-expanded=true],.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button[aria-expanded=true],.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed [slot=secondary-links]>a[aria-expanded=true],.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed [slot=secondary-links]>button[aria-expanded=true]{background:0 0;box-shadow:none}#pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown__wrapper--single-column,pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown__wrapper--single-column{position:relative}#pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown__wrapper,pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown__wrapper{display:block}#pfe-navigation.pfe-navigation--processed [slot=secondary-links] .pfe-navigation__dropdown-wrapper[class],pfe-navigation.pfe-navigation--processed [slot=secondary-links] .pfe-navigation__dropdown-wrapper[class]{height:0;transition:height .25s ease-in-out;transition:var(--pfe-navigation--accordion-transition,height .25s ease-in-out)}@media (prefers-reduced-motion){#pfe-navigation.pfe-navigation--processed [slot=secondary-links] .pfe-navigation__dropdown-wrapper[class],pfe-navigation.pfe-navigation--processed [slot=secondary-links] .pfe-navigation__dropdown-wrapper[class]{transition:none}}@media (min-width:768px){#pfe-navigation.pfe-navigation--processed [slot=secondary-links] .pfe-navigation__dropdown-wrapper[class],pfe-navigation.pfe-navigation--processed [slot=secondary-links] .pfe-navigation__dropdown-wrapper[class]{position:absolute;right:0;top:72px;top:var(--pfe-navigation__nav-bar--Height,72px)}}.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed [slot=secondary-links] .pfe-navigation__dropdown-wrapper[class],.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed [slot=secondary-links] .pfe-navigation__dropdown-wrapper[class]{position:static}@media (min-width:768px){#pfe-navigation.pfe-navigation--processed [slot=secondary-links] .pfe-navigation__dropdown-wrapper[class][aria-hidden=false],pfe-navigation.pfe-navigation--processed [slot=secondary-links] .pfe-navigation__dropdown-wrapper[class][aria-hidden=false]{height:auto}}.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed [slot=secondary-links] .pfe-navigation__dropdown-wrapper[class][aria-hidden=false],.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed [slot=secondary-links] .pfe-navigation__dropdown-wrapper[class][aria-hidden=false]{height:0}#pfe-navigation.pfe-navigation--processed[breakpoint=mobile] [slot=secondary-links][mobile-slider] .pfe-navigation__dropdown-wrapper,pfe-navigation.pfe-navigation--processed[breakpoint=mobile] [slot=secondary-links][mobile-slider] .pfe-navigation__dropdown-wrapper{left:100vw;left:calc(100vw - 32px);left:calc(100vw - var(--pfe-navigation__mobile-dropdown--PaddingHorizontal,32px));position:absolute;top:0;width:100vw}#pfe-navigation.pfe-navigation--processed[breakpoint=mobile] [slot=secondary-links][mobile-slider] .pfe-navigation__dropdown-wrapper[aria-hidden=false],pfe-navigation.pfe-navigation--processed[breakpoint=mobile] [slot=secondary-links][mobile-slider] .pfe-navigation__dropdown-wrapper[aria-hidden=false]{height:100vh;height:calc(100vh - 72px);height:calc(100vh - var(--pfe-navigation__nav-bar--Height,72px));overflow-y:scroll}#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles,#pfe-navigation.pfe-navigation--processed .pfe-navigation__site-switcher .pfe-navigation__dropdown-wrapper,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles,pfe-navigation.pfe-navigation--processed .pfe-navigation__site-switcher .pfe-navigation__dropdown-wrapper{background:#fff;background:var(--pfe-navigation__dropdown--Background,var(--pfe-theme--color--surface--lightest,#fff));padding:0 24px;padding:0 var(--pfe-navigation__dropdown--full-width--spacing--mobile,24px)}@media (min-width:768px){#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles,#pfe-navigation.pfe-navigation--processed .pfe-navigation__site-switcher .pfe-navigation__dropdown-wrapper,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles,pfe-navigation.pfe-navigation--processed .pfe-navigation__site-switcher .pfe-navigation__dropdown-wrapper{padding:0 64px24px;padding:0 var(--pfe-navigation__dropdown--full-width--spacing--desktop,64px) var(--pfe-navigation__dropdown--full-width--spacing--mobile,24px)}}.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container,.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles,.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed .pfe-navigation__site-switcher .pfe-navigation__dropdown-wrapper,.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container,.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles,.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed .pfe-navigation__site-switcher .pfe-navigation__dropdown-wrapper{padding:0 24px;padding:0 var(--pfe-navigation__dropdown--full-width--spacing--mobile,24px)}#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container a,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles a,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container a,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles a{border:1px solid transparent;color:#06c;color:var(--pfe-navigation__dropdown--link--Color,var(--pfe-theme--color--link,#06c));display:inline-block}#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container a:hover,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles a:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container a:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles a:hover{color:#036;color:var(--pfe-navigation__dropdown--link--Color--hover,#036);text-decoration:underline}#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles a:focus{border:1px dashed;outline:0}#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container .pfe-link-list--header,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container [role=heading][aria-heading-level],#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h2,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h3,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h4,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h5,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h6,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles .pfe-link-list--header,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles [role=heading][aria-heading-level],#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h2,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h3,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h4,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h5,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h6,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container .pfe-link-list--header,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container [role=heading][aria-heading-level],pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h2,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h3,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h4,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h5,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h6,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles .pfe-link-list--header,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles [role=heading][aria-heading-level],pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h2,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h3,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h4,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h5,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h6{margin:32px 0 .75em;margin:var(--pfe-navigation--gutter,32px) 0 .75em;padding:0;-moz-column-break-inside:avoid;break-inside:avoid;color:#464646;color:var(--pfe-navigation__dropdown--headings--Color,#464646);font-family:Red Hat Display,RedHatDisplay,Arial,Helvetica,sans-serif;font-family:var(--pfe-navigation--FontFamilyHeadline,Red Hat Display,RedHatDisplay,Arial,Helvetica,sans-serif);font-size:1.125rem;font-size:var(--pf-global--FontSize--lg,1.125rem);font-weight:500}#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container .pfe-link-list--header:first-child,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container [role=heading][aria-heading-level]:first-child,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h2:first-child,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h3:first-child,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h4:first-child,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h5:first-child,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h6:first-child,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles .pfe-link-list--header:first-child,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles [role=heading][aria-heading-level]:first-child,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h2:first-child,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h3:first-child,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h4:first-child,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h5:first-child,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h6:first-child,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container .pfe-link-list--header:first-child,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container [role=heading][aria-heading-level]:first-child,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h2:first-child,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h3:first-child,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h4:first-child,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h5:first-child,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h6:first-child,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles .pfe-link-list--header:first-child,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles [role=heading][aria-heading-level]:first-child,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h2:first-child,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h3:first-child,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h4:first-child,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h5:first-child,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h6:first-child{margin-top:0}#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container .pfe-link-list--header a,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container [role=heading][aria-heading-level] a,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h2 a,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h3 a,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h4 a,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h5 a,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h6 a,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles .pfe-link-list--header a,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles [role=heading][aria-heading-level] a,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h2 a,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h3 a,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h4 a,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h5 a,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h6 a,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container .pfe-link-list--header a,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container [role=heading][aria-heading-level] a,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h2 a,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h3 a,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h4 a,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h5 a,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h6 a,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles .pfe-link-list--header a,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles [role=heading][aria-heading-level] a,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h2 a,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h3 a,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h4 a,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h5 a,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h6 a{border:1px solid transparent;color:#464646;color:var(--pfe-navigation__dropdown--headings--Color,#464646);text-decoration:underline}#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container .pfe-link-list--header a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container .pfe-link-list--header a:hover,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container [role=heading][aria-heading-level] a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container [role=heading][aria-heading-level] a:hover,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h2 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h2 a:hover,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h3 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h3 a:hover,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h4 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h4 a:hover,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h5 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h5 a:hover,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h6 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h6 a:hover,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles .pfe-link-list--header a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles .pfe-link-list--header a:hover,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles [role=heading][aria-heading-level] a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles [role=heading][aria-heading-level] a:hover,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h2 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h2 a:hover,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h3 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h3 a:hover,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h4 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h4 a:hover,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h5 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h5 a:hover,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h6 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h6 a:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container .pfe-link-list--header a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container .pfe-link-list--header a:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container [role=heading][aria-heading-level] a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container [role=heading][aria-heading-level] a:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h2 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h2 a:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h3 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h3 a:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h4 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h4 a:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h5 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h5 a:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h6 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h6 a:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles .pfe-link-list--header a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles .pfe-link-list--header a:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles [role=heading][aria-heading-level] a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles [role=heading][aria-heading-level] a:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h2 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h2 a:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h3 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h3 a:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h4 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h4 a:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h5 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h5 a:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h6 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h6 a:hover{color:#036;color:var(--pfe-navigation__dropdown--link--Color--hover,#036);text-decoration:none}#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container .pfe-link-list--header a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container [role=heading][aria-heading-level] a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h2 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h3 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h4 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h5 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h6 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles .pfe-link-list--header a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles [role=heading][aria-heading-level] a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h2 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h3 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h4 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h5 a:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h6 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container .pfe-link-list--header a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container [role=heading][aria-heading-level] a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h2 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h3 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h4 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h5 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container h6 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles .pfe-link-list--header a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles [role=heading][aria-heading-level] a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h2 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h3 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h4 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h5 a:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles h6 a:focus{border:1px dashed;outline:0}#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container li,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles li,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container li,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles li{margin:0 0 16px;-moz-column-break-inside:avoid;break-inside:avoid}#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container a,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-card,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-cta,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles a,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-card,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-cta,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container a,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-card,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-cta,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles a,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-card,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-cta{-moz-column-break-inside:avoid;break-inside:avoid}#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-cta[pfe-priority=primary],#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-cta[priority=primary],#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-cta[pfe-priority=primary],#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-cta[priority=primary],pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-cta[pfe-priority=primary],pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-cta[priority=primary],pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-cta[pfe-priority=primary],pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-cta[priority=primary]{--pfe-cta--BackgroundColor:var(--pfe-navigation__dropdown--pfe-cta--BackgroundColor,#e00);--pfe-cta--BackgroundColor--hover:var(--pfe-navigation__dropdown--pfe-cta--hover--BackgroundColor,#c00);--pfe-theme--ui--border-width:0}#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-cta[pfe-priority=primary]:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-cta[pfe-priority=primary]:hover,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-cta[priority=primary]:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-cta[priority=primary]:hover,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-cta[pfe-priority=primary]:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-cta[pfe-priority=primary]:hover,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-cta[priority=primary]:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-cta[priority=primary]:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-cta[pfe-priority=primary]:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-cta[pfe-priority=primary]:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-cta[priority=primary]:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-cta[priority=primary]:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-cta[pfe-priority=primary]:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-cta[pfe-priority=primary]:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-cta[priority=primary]:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-cta[priority=primary]:hover{--pfe-cta--BackgroundColor:var(--pfe-navigation__dropdown--pfe-cta--hover--BackgroundColor,#c00)}pfe-card #pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-cta,pfe-card #pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-cta,pfe-card pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container pfe-cta,pfe-card pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles pfe-cta{margin-top:0}#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container li,#pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container ul,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles li,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles ul,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container li,pfe-navigation.pfe-navigation--processed .pfe-navigation-item__tray--container ul,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles li,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--default-styles ul{list-style:none;margin:0;padding:0}#pfe-navigation.pfe-navigation--processed .pfe-navigation-grid,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles,pfe-navigation.pfe-navigation--processed .pfe-navigation-grid,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles{color:#151515;color:var(--pfe-navigation__dropdown--Color,#151515);-moz-column-count:auto;column-count:auto;display:block;font-size:1rem;font-size:var(--pf-global--FontSize--md,1rem);gap:0;margin-left:auto;margin-right:auto;max-width:1136px;max-width:var(--pfe-navigation--content-max-width,1136px);padding-bottom:12px;padding-top:12px;width:calc(100% + 32px)}@media (min-width:768px){#pfe-navigation.pfe-navigation--processed .pfe-navigation-grid,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles,pfe-navigation.pfe-navigation--processed .pfe-navigation-grid,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles{-moz-column-count:3;column-count:3;display:block;gap:32px;gap:var(--pfe-navigation--gutter,32px);padding-bottom:12px;padding-top:12px}}@media (min-width:1200px){#pfe-navigation.pfe-navigation--processed .pfe-navigation-grid,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles,pfe-navigation.pfe-navigation--processed .pfe-navigation-grid,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles{-moz-column-count:auto;column-count:auto;display:flex;flex-wrap:wrap;padding-bottom:32px;padding-top:32px}@supports (display:grid){#pfe-navigation.pfe-navigation--processed .pfe-navigation-grid,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles,pfe-navigation.pfe-navigation--processed .pfe-navigation-grid,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles{display:grid;gap:32px;gap:var(--pfe-navigation--gutter,32px);grid-auto-flow:row;grid-template-columns:repeat(4,minmax(0,1fr))}}}.pfe-navigation--collapse-main-menu #pfe-navigation.pfe-navigation--processed .pfe-navigation-grid,.pfe-navigation--collapse-main-menu #pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles,.pfe-navigation--collapse-main-menu pfe-navigation.pfe-navigation--processed .pfe-navigation-grid,.pfe-navigation--collapse-main-menu pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles{-moz-column-count:3;column-count:3;display:block;gap:32px;gap:var(--pfe-navigation--gutter,32px);padding-bottom:12px;padding-top:12px}.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed .pfe-navigation-grid,.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles,.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed .pfe-navigation-grid,.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles{-moz-column-count:auto;column-count:auto;display:block;gap:0;margin-left:-16px;margin-right:-16px;max-width:1136px;max-width:var(--pfe-navigation--content-max-width,1136px);padding-bottom:12px;padding-top:12px;width:calc(100% + 32px)}.pfe-navigation__menu-item--open #pfe-navigation.pfe-navigation--processed .pfe-navigation-grid,.pfe-navigation__menu-item--open #pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles,.pfe-navigation__menu-item--open pfe-navigation.pfe-navigation--processed .pfe-navigation-grid,.pfe-navigation__menu-item--open pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles{transition-delay:0s;visibility:visible}#pfe-navigation.pfe-navigation--processed .pfe-navigation-grid>*,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles>*,pfe-navigation.pfe-navigation--processed .pfe-navigation-grid>*,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles>*{margin:0 0 18px;-moz-column-break-inside:avoid;break-inside:avoid}@media (min-width:1200px){#pfe-navigation.pfe-navigation--processed .pfe-navigation-grid>*,#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles>*,pfe-navigation.pfe-navigation--processed .pfe-navigation-grid>*,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles>*{margin:0}}.pfe-navigation--collapse-main-menu #pfe-navigation.pfe-navigation--processed .pfe-navigation-grid>*,.pfe-navigation--collapse-main-menu #pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles>*,.pfe-navigation--collapse-main-menu pfe-navigation.pfe-navigation--processed .pfe-navigation-grid>*,.pfe-navigation--collapse-main-menu pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--default-styles>*{margin:0 0 18px}#pfe-navigation.pfe-navigation--processed .pfe-navigation-grid,pfe-navigation.pfe-navigation--processed .pfe-navigation-grid{max-width:100%}#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--1-x,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown--1-x{display:block}#pfe-navigation.pfe-navigation--processed .pfe-navigation__site-switcher .pfe-navigation__dropdown,pfe-navigation.pfe-navigation--processed .pfe-navigation__site-switcher .pfe-navigation__dropdown{background:#fff}#pfe-navigation.pfe-navigation--processed .pfe-navigation__site-switcher .pfe-navigation__dropdown site-switcher,pfe-navigation.pfe-navigation--processed .pfe-navigation__site-switcher .pfe-navigation__dropdown site-switcher{margin-left:auto;margin-right:auto;max-width:1136px;max-width:var(--pfe-navigation--content-max-width,1136px);padding:12px 24px;padding:12px var(--pfe-navigation__dropdown--full-width--spacing--mobile,24px)}@media (min-width:1200px){#pfe-navigation.pfe-navigation--processed .pfe-navigation__site-switcher .pfe-navigation__dropdown site-switcher,pfe-navigation.pfe-navigation--processed .pfe-navigation__site-switcher .pfe-navigation__dropdown site-switcher{padding:32px 64px;padding:32px var(--pfe-navigation__dropdown--full-width--spacing--desktop,64px)}}.pfe-navigation--collapse-main-menu #pfe-navigation.pfe-navigation--processed .pfe-navigation__site-switcher .pfe-navigation__dropdown site-switcher,.pfe-navigation--collapse-main-menu pfe-navigation.pfe-navigation--processed .pfe-navigation__site-switcher .pfe-navigation__dropdown site-switcher{padding:12px 24px;padding:12px var(--pfe-navigation__dropdown--full-width--spacing--mobile,24px)}#pfe-navigation.pfe-navigation--processed .pfe-navigation__site-switcher .pfe-navigation__dropdown site-switcher .container,pfe-navigation.pfe-navigation--processed .pfe-navigation__site-switcher .pfe-navigation__dropdown site-switcher .container{margin:0;padding:0;width:auto}#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--invisible[class],pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--invisible[class]{padding:0}#pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--invisible pfe-navigation-dropdown,pfe-navigation.pfe-navigation--processed .pfe-navigation__dropdown-wrapper--invisible pfe-navigation-dropdown{visibility:hidden}#pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown--single-column[class],pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown--single-column[class]{padding:0}@media (min-width:768px){#pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown--single-column[class],pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown--single-column[class]{box-shadow:0 1px 2px rgba(0,0,0,.12);box-shadow:var(--pfe-navigation__dropdown--BoxShadow,0 1px 2px rgba(0,0,0,.12));max-width:100%;min-width:13em;padding:0 32px;position:absolute;top:100%}}.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown--single-column[class],.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown--single-column[class]{box-shadow:none;max-width:100%;position:static}@media (min-width:768px){#pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown--single-column[class],pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown--single-column[class]{right:0}}#pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown--full[class],pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown--full[class]{width:100%}@media (min-width:768px){#pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown--full[class],pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown--full[class]{left:0;position:absolute;right:0}}.pfe-navigation--collapse-secondary-links #pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown--full[class],.pfe-navigation--collapse-secondary-links pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown--full[class]{position:static}#pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown--full[class] .pfe-navigation__dropdown,pfe-navigation.pfe-navigation--processed .pfe-navigation__custom-dropdown--full[class] .pfe-navigation__dropdown{width:100%}#pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles,pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles{padding-left:16px;padding-right:16px}#pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles form,pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles form{align-items:center;display:flex}#pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles button,#pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles input,pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles button,pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles input{padding:10px;transition:box-shadow .2s}#pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles input,pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles input{border:1px solid #f0f0f0;border-bottom-color:#8b8e91;color:#717579;flex-basis:0%;flex-grow:1;flex-shrink:1;font-size:1rem;font-size:var(--pf-global--FontSize--md,1rem);margin-right:8px}#pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles input::-moz-placeholder,pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles input::-moz-placeholder{color:#717579}#pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles input::placeholder,pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles input::placeholder{color:#717579}#pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles button,pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles button{background-color:#e00;border:1px solid #e00;border-radius:2px;color:#fff;flex-basis:auto;flex-grow:0;flex-shrink:1;font-size:1rem;font-size:var(--pf-global--FontSize--md,1rem)}#pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles input:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles input:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles input:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles input:hover{outline:0}#pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles input:focus:after,#pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles input:hover:after,pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles input:focus:after,pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles input:hover:after{border:1px dashed #000;bottom:0;content:"";display:block;left:0;position:absolute;right:0;top:0}#pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles button:focus,#pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles button:hover,pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles button:focus,pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles button:hover{outline:0}#pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles button:focus:after,#pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles button:hover:after,pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles button:focus:after,pfe-navigation.pfe-navigation--processed .pfe-navigation__search--default-styles button:hover:after{border:1px dashed #fff;bottom:0;content:"";display:block;left:0;position:absolute;right:0;top:0}#pfe-navigation .pfe-navigation__site-switcher__back-wrapper,pfe-navigation .pfe-navigation__site-switcher__back-wrapper{border-bottom:1px solid #d2d2d2;border-bottom:var(--pfe-navigation__dropdown--separator--Border,1px solid var(--pfe-theme--color--ui--border--lighter,#d2d2d2));display:block}@media (min-width:768px){#pfe-navigation .pfe-navigation__site-switcher__back-wrapper,pfe-navigation .pfe-navigation__site-switcher__back-wrapper{display:none}}.pfe-navigation--collapse-secondary-links #pfe-navigation .pfe-navigation__site-switcher__back-wrapper,.pfe-navigation--collapse-secondary-links pfe-navigation .pfe-navigation__site-switcher__back-wrapper{display:block}#pfe-navigation .pfe-navigation__site-switcher__back-button,pfe-navigation .pfe-navigation__site-switcher__back-button{background-color:transparent;border:1px solid transparent;color:#06c;color:var(--pfe-navigation__dropdown--link--Color,var(--pfe-theme--color--link,#06c));cursor:pointer;font-size:1rem;font-size:var(--pf-global--FontSize--md,1rem);padding:21px 21px 21px 45px;position:relative;text-align:left;width:100%}#pfe-navigation .pfe-navigation__site-switcher__back-button:before,pfe-navigation .pfe-navigation__site-switcher__back-button:before{border:2px solid #06c;border:2px solid var(--pfe-navigation__dropdown--link--Color,var(--pfe-theme--color--link,#06c));border-right:0;border-top:0;content:"";display:block;height:8px;left:35px;position:absolute;right:auto;top:27px;transform:rotate(45deg);transform-origin:left top;width:8px}#pfe-navigation .pfe-navigation__site-switcher__back-button:focus,#pfe-navigation .pfe-navigation__site-switcher__back-button:hover,pfe-navigation .pfe-navigation__site-switcher__back-button:focus,pfe-navigation .pfe-navigation__site-switcher__back-button:hover{border:1px dashed #151515;border-top:1px dashed #151515;border:1px dashed var(--pfe-navigation__dropdown--Color,#151515);color:#036;color:var(--pfe-navigation__dropdown--link--Color--hover,#036);outline:0}#pfe-navigation.pfe-navigation--processed site-switcher,pfe-navigation.pfe-navigation--processed site-switcher{-moz-columns:auto;columns:auto;display:block}#pfe-navigation.pfe-navigation--stuck,pfe-navigation.pfe-navigation--stuck{left:0;position:fixed;top:0;width:100%;z-index:95;z-index:var(--pfe-theme--zindex--navigation,95)}#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__outer-menu-wrapper__inner,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__outer-menu-wrapper__inner{opacity:1!important}#pfe-navigation.pfe-navigation--in-crusty-browser pfe-navigation-account,#pfe-navigation.pfe-navigation--in-crusty-browser rh-account-dropdown,pfe-navigation.pfe-navigation--in-crusty-browser pfe-navigation-account,pfe-navigation.pfe-navigation--in-crusty-browser rh-account-dropdown{display:none!important}#pfe-navigation.pfe-navigation--in-crusty-browser[open-toggle=pfe-navigation__account-toggle] pfe-navigation-account,#pfe-navigation.pfe-navigation--in-crusty-browser[open-toggle=pfe-navigation__account-toggle] rh-account-dropdown,pfe-navigation.pfe-navigation--in-crusty-browser[open-toggle=pfe-navigation__account-toggle] pfe-navigation-account,pfe-navigation.pfe-navigation--in-crusty-browser[open-toggle=pfe-navigation__account-toggle] rh-account-dropdown{display:block!important}#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__menu-item,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__menu-item{display:block}#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__menu-link[aria-expanded=true],pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__menu-link[aria-expanded=true]{--pfe-icon--color:var(--pfe-navigation__nav-bar--Color--active,var(--pfe-theme--color--text,#151515));background:#fff;background:var(--pfe-navigation__nav-bar--toggle--BackgroundColor--active,var(--pfe-theme--color--surface--lightest,#fff));color:#151515;color:var(--pfe-navigation__nav-bar--Color--active,var(--pfe-theme--color--text,#151515))}#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__menu-link[aria-expanded=true]:focus,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__menu-link[aria-expanded=true]:focus{outline:0}#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__menu-link[aria-expanded=true]:focus:after,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__menu-link[aria-expanded=true]:focus:after{border:1px dashed;bottom:0;content:"";display:block;left:0;position:absolute;right:0;top:0}#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__dropdown,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__dropdown{display:flex;flex-wrap:wrap}#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__dropdown>.style-scope,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__dropdown>.style-scope{flex-basis:25%}#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__dropdown .pfe-navigation__footer.style-scope,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__dropdown .pfe-navigation__footer.style-scope{flex-basis:100%}#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__dropdown .pfe-navigation__footer.style-scope>.style-scope,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__dropdown .pfe-navigation__footer.style-scope>.style-scope{margin-right:16px}#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__dropdown--single-column,#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__dropdown--single-column ul,#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__dropdown--single-column>.style-scope,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__dropdown--single-column,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__dropdown--single-column ul,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__dropdown--single-column>.style-scope{display:flex;flex-direction:column;flex-wrap:nowrap}#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__dropdown--single-column>.style-scope,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__dropdown--single-column>.style-scope{flex-basis:auto}#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__search-toggle,#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__secondary-link,#pfe-navigation.pfe-navigation--in-crusty-browser [slot=secondary-links]>a,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__search-toggle,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__secondary-link,pfe-navigation.pfe-navigation--in-crusty-browser [slot=secondary-links]>a{color:#fff!important;justify-content:center!important}#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__search-toggle[aria-expanded=true],#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__secondary-link[aria-expanded=true],#pfe-navigation.pfe-navigation--in-crusty-browser [slot=secondary-links]>a[aria-expanded=true],pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__search-toggle[aria-expanded=true],pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__secondary-link[aria-expanded=true],pfe-navigation.pfe-navigation--in-crusty-browser [slot=secondary-links]>a[aria-expanded=true]{color:#151515!important}#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__account-wrapper--logged-in .pfe-navigation__log-in-link,#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__search-toggle .secondary-link__icon-wrapper,#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__search-toggle pfe-icon,#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__secondary-link .secondary-link__icon-wrapper,#pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__secondary-link pfe-icon,#pfe-navigation.pfe-navigation--in-crusty-browser [slot=secondary-links]>a .secondary-link__icon-wrapper,#pfe-navigation.pfe-navigation--in-crusty-browser [slot=secondary-links]>a pfe-icon,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__account-wrapper--logged-in .pfe-navigation__log-in-link,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__search-toggle .secondary-link__icon-wrapper,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__search-toggle pfe-icon,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__secondary-link .secondary-link__icon-wrapper,pfe-navigation.pfe-navigation--in-crusty-browser .pfe-navigation__secondary-link pfe-icon,pfe-navigation.pfe-navigation--in-crusty-browser [slot=secondary-links]>a .secondary-link__icon-wrapper,pfe-navigation.pfe-navigation--in-crusty-browser [slot=secondary-links]>a pfe-icon{display:none!important}[id=pfe-navigation__account-dropdown][class][class]{display:block;height:auto;left:0;padding:0;position:absolute;top:72px;top:var(--pfe-navigation__nav-bar--Height,72px);width:100%}[id=pfe-navigation__account-dropdown].pfe-navigation__dropdown-wrapper--invisible[class]{display:none}.pfe-navigation__dropdown-wrapper{overflow:hidden}@media (min-width:768px){.pfe-navigation__custom-dropdown--single-column{min-width:25em}}.pfe-navigation--collapse-secondary-links .pfe-navigation__custom-dropdown--single-column{min-width:0}.secondary-link__icon-wrapper{align-items:center;display:flex;justify-content:center}.secondary-link__alert-count{background:#06c;background:var(--pfe-navigation__nav-bar--alert-color,var(--pfe-theme--color--link,#06c));border-radius:20px;color:#fff;color:var(--pfe-navigation__nav-bar--Color--on-highlight,var(--pfe-theme--color--text--on-saturated,#fff));display:block;font-size:12px;font-size:var(--pfe-navigation--FontSize--xs,12px);line-height:20px;margin:0 4px 0 2px;min-width:23px;overflow:hidden;padding:0 8px}.secondary-link__alert-count:empty{display:none}#pfe-navigation__1x-skip-links{left:0;position:absolute;top:0}#pfe-navigation__1x-skip-links,#pfe-navigation__1x-skip-links li{height:0;list-style:none;margin:0;padding:0;width:0}.skip-link[class][class]{font-size:.875rem;font-size:var(--pf-global--FontSize--sm,.875rem);line-height:18px}.skip-link[class][class]:focus{border-radius:.21429em;height:auto;left:50%;padding:.42857em .57143em;position:fixed;top:8px;transform:translateX(-50%);width:auto;z-index:99999;clip:auto;background:#fff;background:var(--pfe-navigation__skip-link--BackgroundColor,var(--pfe-theme--color--surface--lightest,#fff));color:#06c;color:var(--pfe-navigation__skip-link--Color,var(--pfe-theme--color--link,#06c));text-decoration:none}pfe-navigation pfe-navigation-account[slot=account]{background:#fff;background:var(--pfe-navigation__dropdown--Background,var(--pfe-theme--color--surface--lightest,#fff));width:100%}</style>
<style>:host([size=sm]) #container[data-v-8589d091]{--_size:var(--pf-global--icon--FontSize--sm,12px)}.content-wrapper[data-v-8589d091]{height:auto;margin:0 auto;min-height:46vh}.content[data-v-8589d091]{max-width:1000px}#left-content[data-v-8589d091]{max-width:330px;z-index:1}.line-below-chp[data-v-8589d091]{margin:var(--rh-space-xl,24px) 0 var(--rh-space-3xl,48px)}.toc-container[data-v-8589d091]{border-right:1px solid var(--rh-color-gray-30,#c7c7c7);min-height:100vh;position:sticky;top:0;transition:transform .3s ease-in-out}nav#toc[data-v-8589d091]{height:auto;overflow-y:auto;padding-bottom:var(--rh-space-2xl,32px)}.max-height-85[data-v-8589d091]{max-height:85vh}.max-height-75[data-v-8589d091]{max-height:75vh}.toc-filter[data-v-8589d091]{background-color:#fff;padding:var(--rh-space-lg,16px) var(--rh-space-2xl,32px);position:sticky;top:-1px;width:100%;z-index:1}#text[data-v-8589d091],.toc-filter[data-v-8589d091]{align-items:center;display:flex}#text[data-v-8589d091]{flex:1;flex-direction:row}#search-icon[data-v-8589d091]{color:#151515;left:2.5rem;position:absolute;top:55%;transform:translateY(-50%)}pf-icon[data-v-8589d091]{--pf-icon--size:16px}#text:focus-within #icon[data-v-8589d091],#text:hover #icon[data-v-8589d091]{color:#151515}#text[data-v-8589d091]:after,#text[data-v-8589d091]:before{content:"";inset:0;pointer-events:none;position:absolute}#text-input[data-v-8589d091]:focus,#text-input:focus+#utilities[data-v-8589d091]{border-bottom:2px solid #06c;outline:none}#text-input[data-v-8589d091]{background-color:transparent;border:1px solid #f0f0f0;border-bottom-color:#8a8d90;color:#151515;font-family:inherit;font-size:100%;grid-area:text-input;line-height:1.5;overflow:hidden;padding:.375rem .25rem .375rem 2rem;position:relative;text-overflow:ellipsis;white-space:nowrap;width:100%}#utilities[data-v-8589d091]{align-items:center;border:1px solid #f0f0f0;border-bottom:1px solid #8a8d90;border-left:0;display:flex}#utilities rh-badge[data-v-8589d091]{border-radius:80px;font-weight:var(--rh-font-weight-heading-medium,500);--_background-color:#e0e0e0;margin-right:8px}#clear-button[data-v-8589d091]{--pf-c-button--PaddingTop:0.625rem;--pf-c-button--PaddingRight:.25rem;--pf-c-button--PaddingBottom:0.625rem;--pf-c-button--PaddingLeft:.25rem;margin-right:8px}#text-input.no-right-border[data-v-8589d091]{border-right:0}.btn-container[data-v-8589d091]{bottom:0;display:flex;justify-content:flex-end;padding:1rem;pointer-events:none;position:fixed;right:0;z-index:2}.top-scroll-btn[data-v-8589d091]{--pf-c-button--BorderRadius:64px;pointer-events:all}.focusable[data-v-8589d091]:focus-visible{border:2px solid var(--rh-color-interactive-blue,#06c)}.mobile-nav-wrapper[data-v-8589d091]{align-items:center;border-bottom:1px solid #c7c7c7;display:flex;height:auto;justify-content:space-between;padding:var(--rh-space-sm,.5rem)}.mobile-nav[data-v-8589d091]{align-items:center;background-color:var(--rh-color-bg-page,#fff);min-height:51px;position:sticky;top:0;z-index:5}.active-mobile-menu[data-v-8589d091]{color:#151515;padding-left:.5rem}.hidden[data-v-8589d091]{display:none}.mobile-nav-btn[data-v-8589d091]{background-color:transparent;border:none;font-family:inherit;font-size:.875rem;font-weight:500;margin:0;min-height:40px;min-width:40px}.border-right[data-v-8589d091]{border-right:1px solid #c7c7c7}.toc-focus-container[data-v-8589d091]{position:sticky;top:0;z-index:2}.toc-focus-btn[data-v-8589d091]{align-items:center;background-color:var(--rh-color-white,#fff);border:1px solid var(--rh-color-blue-50,#06c);border-radius:50%;cursor:pointer;display:flex;height:40px;justify-content:center;position:absolute;right:-20px;top:15px;width:40px}.toc-focus-btn[data-v-8589d091]:focus-visible,.toc-focus-btn[data-v-8589d091]:hover{background-color:var(--rh-color-blue-10,#e0f0ff);box-shadow:var(--rh-box-shadow-sm,0 2px 4px 0 hsla(0,0%,8%,.2))}.toc-focus-btn[data-v-8589d091]:focus-visible{border:2px solid var(--rh-color-blue-50,#06c)}.toc-focus-btn-icon[data-v-8589d091]{color:var(--rh-color-blue-50,#06c)}.toc-wrapper[data-v-8589d091]{padding:0}.product-container[data-v-8589d091]{border-bottom:1px solid var(--rh-color-gray-30,#c7c7c7);padding:var(--rh-space-xl,24px) var(--rh-space-2xl,32px)}.product-container h1.product-title[data-v-8589d091]{font-size:var(--rh-font-size-code-xl,1.25rem);line-height:30px;margin-bottom:0;margin-top:0}.product-container .product-version[data-v-8589d091]{align-items:center;display:flex;flex-wrap:wrap;margin-top:var(--rh-space-lg,16px)}.product-version .version-label[data-v-8589d091]{color:var(--rh-color-canvas-black,#151515);font-family:Red Hat Text;font-size:var(--rh-font-size-body-text-sm,.875rem);font-weight:500}.product-version .version-select-dropdown[data-v-8589d091]{margin:var(--rh-space-md,8px) var(--rh-space-sm,6px);max-width:9.75rem;min-height:2rem;min-width:3rem;overflow:hidden;width:-moz-min-content;width:min-content;word-wrap:nowrap;-webkit-appearance:none;-moz-appearance:none;background:var(--rh-color-white,#fff);background-image:url("data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http://www.w3.org/2000/svg' width='10' height='6' fill='none' viewBox='0 0 10 6'%3E%3Cpath fill='%23151515' d='M.678 0h8.644c.596 0 .895.797.497 1.195l-4.372 4.58c-.298.3-.695.3-.993 0L.18 1.196C-.216.797.081 0 .678 0'/%3E%3C/svg%3E");background-position-x:85%;background-position-y:50%;background-repeat:no-repeat;border:1px solid var(--rh-color-gray-30,#c7c7c7);border-bottom:0;box-shadow:0 -1px 0 0 var(--rh-color-gray-60,#4d4d4d) inset;cursor:pointer;font-size:var(--rh-font-size-body-text-md,1rem);padding:var(--rh-space-md,8px);padding-right:24px;text-overflow:ellipsis}pf-popover[data-v-8589d091]{margin-top:var(--rh-space-md,8px);--pf-c-popover__arrow--BackgroundColor:var(--rh-color-canvas-black,#151515);--pf-c-popover__content--BackgroundColor:var(--rh-color-canvas-black,#151515);--pf-c-popover--BoxShadow:0px 4px 8px 0px #15151540;--pf-c-popover__title-text--Color:var(--rh-color-white,#fff);--pf-c-popover--MaxWidth:300px;--pf-c-popover--MinWidth:300px;--pf-c-popover--c-button--Top:20px;--pf-c-popover--c-button--Right:4px;--pf-c-button--m-plain--hover--Color:var(--rh-color-white,#fff)}pf-popover[data-v-8589d091]::part(content){padding:var(--rh-space-2xl,32px)}pf-popover[data-v-8589d091]::part(body){margin-top:var(--rh-space-lg,16px)}pf-popover[data-v-8589d091]::part(close-button){--pf-c-button--m-plain--focus--Color:var(--rh-color-gray-30,#c7c7c7);--pf-c-button--m-plain--Color:var(--rh-color-gray-30,#c7c7c7)}.popover-header-text[data-v-8589d091]{color:var(--rh-color-white,#fff);font-size:var(--rh-font-size-code-md,1rem);margin:0;max-width:80%;padding:0}.popover-body-link[data-v-8589d091]{color:var(--rh-color-blue-30,#92c5f9);text-decoration:none}.popover-trigger-btn[data-v-8589d091]{align-items:center;background:none;border:none;cursor:pointer;display:flex;justify-content:center}#first-button[data-v-8589d091]{width:80%}#second-button[data-v-8589d091]{text-align:right;width:20%}#toc-btn[data-v-8589d091]{text-align:left;width:100%}.toc-error[data-v-8589d091]{margin:0;max-width:100%}#layout label[data-v-8589d091]{font-weight:500}.page-layout-options[data-v-8589d091]{background-color:#fff;display:flex;flex-direction:column;padding-bottom:var(--rh-space-lg,16px)}.sticky-top[data-v-8589d091]{position:sticky;top:0}summary[data-v-8589d091]{cursor:pointer;list-style:none;position:relative}summary[data-v-8589d091]::-webkit-details-marker{display:none}details#jump-links-details .jump-links-heading[data-v-8589d091]{background-color:var(--rh-color-white,#fff);display:block;margin-top:var(--rh-space-lg,16px);padding:var(--rh-space-lg,16px) 0 0 var(--rh-space-xl,24px);position:sticky;top:0}details#jump-links-details .jump-links-heading[data-v-8589d091]:before{border-right:3px solid #151515;border-top:3px solid #151515;color:#151515;content:"";display:flex;height:9px;left:2px;position:absolute;top:26px;transform:rotate(-135deg);width:9px}details#jump-links-details[open] .jump-links-heading[data-v-8589d091]:before{transform:rotate(135deg)}.table-of-contents>ol[data-v-8589d091]{list-style:none;margin:0;padding:0}nav.table-of-contents[data-v-8589d091]{z-index:1}nav.table-of-contents ol[data-v-8589d091]{list-style:none;margin:0;padding:0}#mobile-browse-docs[data-v-8589d091]{font-weight:var(--rh-font-weight-body-text-medium,500);padding-left:var(--rh-space-2xl,32px)}.docs-content-container[data-v-8589d091]{font-size:var(--rh-font-size-body-text-lg,1.125rem);font-weight:var(--rh-font-weight-body-text-regular,400);line-height:1.6667;padding-left:6rem;padding-right:6rem;padding-top:var(--rh-space-3xl,4rem)}.chapter-title[data-v-8589d091]{font-family:Red Hat Display}h1.chapter-title[data-v-8589d091]{font-size:var(--rh-fontsize-heading-xl,2.25rem);line-height:46.8px;margin:0;padding:0}.chapter .section h4[data-v-8589d091]{font-size:24px;font-weight:400}.banner-wrapper[data-v-8589d091]{padding:3rem 6rem 0}.page-format-dropdown[data-v-8589d091]{-webkit-appearance:none;-moz-appearance:none;appearance:none;background:#fff;background-image:url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAoAAAAGCAYAAAD68A/GAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAABtSURBVHgBhc4xCoAwDAXQxE6li0K76w0cPZqjHsEb6AlcHb2BR9ADdG7GmIKTWv0QSOAFPjrndgAo4TtHxszTD4JoVAhh1VoXiNgkUO+971Q8iGgxxlSy1jc3CGof39baWTrzNSOkkksEbG/oBGEJIn6gD3jAAAAAAElFTkSuQmCC");background-position:8.5rem;background-repeat:no-repeat;background-size:auto;border:1px solid #c7c7c7;box-shadow:inset 0 -1px 0 0 #4d4d4d;font-family:Red Hat Text;font-size:var(--rh-font-size-body-text-md,1rem);margin-top:var(--rh-space-xs,4px);max-width:168px;min-height:36px;min-width:168px;overflow:hidden;padding:0 var(--rh-space-xl,24px) 0 var(--rh-space-md,8px);text-overflow:ellipsis;white-space:nowrap}.content-format-selectors[data-v-8589d091]{color:#151515;font-family:Red Hat Text;font-size:var(--rh-font-size-body-text-sm,.875rem);font-weight:var(--rh-font-weight-body-text-medium,500);margin-right:var(--rh-space-2xl,32px);max-width:250px;min-width:250px;padding-top:var(--rh-space-2xl,32px)}.chapter .section .simpara[data-v-8589d091],.chapter .section p[data-v-8589d091]{font-family:Red Hat Text;font-size:var(--rh-font-size-body-text-lg,1.125rem);font-weight:var(--rh-font-weight-body-text-regular,400);line-height:30px}#toggle-focus-mode[data-v-8589d091]{padding-right:var(--rh-space-lg,1rem)}@keyframes slideaway-left-8589d091{0%{display:block}to{opacity:0;transform:translateX(-40px)}}@keyframes slideaway-right-8589d091{0%{display:block}to{opacity:0;transform:translateX(40px)}}@keyframes enter-left-8589d091{0%{display:none;transform:translateX(-40px)}to{opacity:1}}@keyframes enter-right-8589d091{0%{display:none;transform:translateX(40px)}to{opacity:1}}.hide-left[data-v-8589d091]{animation:slideaway-left-8589d091 .2s;display:none}.enter-left[data-v-8589d091]{animation:enter-left-8589d091 .3s;border-right:none;display:block}.enter-right[data-v-8589d091]{animation:enter-right-8589d091 .3s;display:block}.hide-right[data-v-8589d091]{animation:slideaway-right-8589d091 .2s;display:none}.toc-container.enter-toc-container-left[data-v-8589d091]{transform:translateX(-85%)}.alert-section[data-v-8589d091]{padding-bottom:3rem}rh-alert[data-v-8589d091]{width:auto}@media (min-width:992px){#mobile-nav[data-v-8589d091],#toc-list-mobile[data-v-8589d091]{display:none}}@media (min-width:992px) and (max-width:1400px){.docs-ocp-content-container[data-v-8589d091]{padding:var(--rh-space-4xl,64px) var(--rh-space-lg,16px) 0}}@media (width < 992px){#breadcrumbs[data-v-8589d091],.content-format-selectors[data-v-8589d091],.toc-container[data-v-8589d091]{display:none}#mobile-nav-content-wrapper[data-v-8589d091]{border-bottom:1px solid #c7c7c7;border-top:1px solid #c7c7c7}#toc-wrapper-mobile[data-v-8589d091]{padding:var(--rh-space-md,1.5rem)}.product-container[data-v-8589d091]{padding:var(--rh-space-2xl,32px) var(--rh-space-lg,16px)}.product-container.shrink-product-padding[data-v-8589d091]{padding:var(--rh-space-lg,16px)}.product-version .version-select-dropdown[data-v-8589d091]{margin:0 var(--rh-space-lg,16px)}#page-content-options-mobile[data-v-8589d091]{padding:var(--rh-space-lg,2rem)}label[for=page-format][data-v-8589d091],label[for=toggle-focus-mode][data-v-8589d091]{display:block}.page-format-dropdown[data-v-8589d091]{background-position:97%;max-width:100%}nav#mobile-toc-menu[data-v-8589d091]{max-height:50vh;overflow-y:scroll}.mobile-jump-links #first-button[data-v-8589d091]{width:100%}#jump-links-btn[data-v-8589d091]{text-align:left;width:100%}#mobile-jump-links-content-wrapper[data-v-8589d091]{border-bottom:1px solid #c7c7c7;border-top:1px solid #c7c7c7;padding:0 var(--rh-space-lg,16px) var(--rh-space-2xl,32px)}.table-of-contents #browse-docs[data-v-8589d091]{margin-top:1rem;padding-top:var(--rh-space-md,1.5rem)}.mobile-nav[data-v-8589d091]{display:block}.hide-mobile-nav[data-v-8589d091],.mobile-nav[data-v-8589d091]{transition:transform .3s ease-in-out}.hide-mobile-nav[data-v-8589d091]{transform:translateY(-100%)}.docs-content-container[data-v-8589d091]{padding-left:1.25rem;padding-right:1.25rem;padding-top:var(--rh-space-xl,24px)}.banner-wrapper[data-v-8589d091]{padding:0 1rem}.toc-filter-mobile[data-v-8589d091]{align-items:center;display:flex;padding:var(--rh-space-lg,16px);width:100%}#text-input[data-v-8589d091]{padding-left:.5rem}.toc-filter[data-v-8589d091]{display:none}}@media (width <=576px){.content-format-selectors[data-v-8589d091]{display:none}}.informaltable[data-v-8589d091],.rhdocs .informaltable[data-v-8589d091],.rhdocs .table-contents[data-v-8589d091],.rhdocs .table-wrapper[data-v-8589d091],.table-contents[data-v-8589d091],.table-wrapper[data-v-8589d091]{max-height:var(--rh-table--maxHeight);overflow:auto}rh-table[data-v-8589d091]{display:block;margin:2rem 0;max-width:100%}.pvof-doc__wrapper[data-v-8589d091],.rhdocs[data-v-8589d091]{--rh-table--maxHeight:calc(100vh - 12.5rem)}</style>
<style>:is(rh-footer-block) a[data-v-97dd2752]{text-decoration:underline}</style>
<style>:is(rh-footer,:is(rh-footer-universal,rh-global-footer)) a{color:var(--rh-color-link-inline-on-dark,var(--rh-color-interactive-blue-lighter,#92c5f9));text-decoration:none}:is(rh-footer,:is(rh-footer-universal,rh-global-footer)) a:hover{color:var(--rh-color-link-inline-hover-on-dark,var(--rh-color-interactive-blue-lightest,#b9dafc));text-decoration:underline}:is(rh-footer,:is(rh-footer-universal,rh-global-footer)) a:is(:focus,:focus-within){color:var(--rh-color-link-inline-focus-on-dark,var(--rh-color-interactive-blue-lightest,#b9dafc));text-decoration:underline}:is(rh-footer,:is(rh-footer-universal,rh-global-footer)) a:visited{color:var(--rh-color-link-inline-visited-on-dark,var(--rh-color-interactive-blue-lightest,#b9dafc));text-decoration:none}:is(rh-footer,:is(rh-footer-universal,rh-global-footer)) a[slot^=logo]{display:block}:is(rh-footer) a[slot^=logo]>img{display:block;height:100%;height:var(--rh-size-icon-04,40px);width:auto}:is(rh-footer,rh-footer-universal,rh-global-footer) :is(h1,h2,h3,h4,h5,h6){font-family:var(--rh-font-family-heading,RedHatDisplay,"Red Hat Display","Noto Sans Arabic","Noto Sans Hebrew","Noto Sans JP","Noto Sans KR","Noto Sans Malayalam","Noto Sans SC","Noto Sans TC","Noto Sans Thai",Helvetica,Arial,sans-serif);line-height:var(--rh-line-height-heading,1.3)}rh-footer [slot=links]:is(h1,h2,h3,h4,h5):nth-of-type(n+5){--_link-header-margin:calc(var(--rh-space-2xl, 32px) - var(--rh-space-lg, 16px))}rh-footer [slot^=links] a{gap:var(--rh-footer-links-gap,var(--rh-space-md,8px))}:is(rh-footer,:is(rh-footer-universal,rh-global-footer)) [slot^=links] li{display:contents;margin:0;padding:0}:is(rh-footer,:is(rh-footer-universal,rh-global-footer)) [slot^=links] a{color:var(--rh-color-text-primary-on-dark,#fff)!important;display:block;font-size:var(--rh-footer-link-font-size,var(--rh-font-size-body-text-sm,.875rem));width:-moz-fit-content;width:fit-content}:is(rh-footer-universal,rh-global-footer) [slot^=links] a{font-size:inherit}:is(rh-footer,rh-footer-universal,rh-global-footer){--rh-footer-section-side-gap:var(--rh-space-lg,16px)}@media screen and (min-width:768px){:is(rh-footer,rh-footer-universal,rh-global-footer){--rh-footer-section-side-gap:var(--rh-space-2xl,32px)}}@media screen and (min-width:1440px){:is(rh-footer,rh-footer-universal,rh-global-footer){--rh-footer-section-side-gap:var(--rh-space-4xl,64px)}}rh-footer:not(:defined){background-color:var(--rh-color-surface-darker,#1f1f1f);display:grid;grid-template-areas:"footer" "global";grid-template-rows:1fr auto;min-height:var(--rh-footer-nojs-min-height,750px);width:100%}:is(rh-footer-universal,rh-global-footer):not(:defined):before{grid-area:global}rh-footer:not(:defined)>[slot=logo]{padding:var(--rh-space-2xl,32px) var(--_section-side-gap)}:is(rh-footer-universal,rh-global-footer):not(:defined)>*,rh-footer:not(:defined)>:not([slot=logo],:is(rh-footer-universal,rh-global-footer)){border:0;clip:rect(1px,1px,1px,1px);height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px}:is(rh-footer-universal,rh-global-footer):not(:defined){background-color:var(--rh-color-surface-darkest,#151515);display:block;min-height:176px;width:100%}rh-footer-universal rh-footer-copyright{grid-column:-1/1}</style>
<style>.status-legal .status-page-widget[data-v-5f538988]{display:block;margin:.5rem 0;width:11.3125rem;width:-moz-max-content;width:max-content}.status-page-widget[data-v-5f538988]{align-items:center;display:flex;flex-direction:row}.status-legal .status-page-widget .status-description[data-v-5f538988]{color:#ccc;font-weight:600;letter-spacing:.0125rem;line-height:1.5;margin-right:.5rem}.status-good[data-v-5f538988]{background-color:#3e8536}.status-critical[data-v-5f538988]{background-color:#a30100}.status-partial[data-v-5f538988]{background-color:#f5c12d}.status-maintentance[data-v-5f538988]{background-color:#316dc1}.status-minor[data-v-5f538988]{background-color:#b85c00}.status-description[data-v-5f538988]{color:#ccc;font-weight:500;letter-spacing:.2px;line-height:1.5}.current-status-indicator[data-v-5f538988]{border-radius:6px;display:inline-block;height:12px;margin:0 0 0 5px;width:12px}.current-status-indicator.small[data-v-5f538988]{border-radius:4px;display:inline-block;height:8px;margin:0 0 0 5px;width:8px}</style>
<style>.breadcrumbs[data-v-798f280c]{align-items:center;background-color:#f6f6f6;display:flex;gap:var(--rh-space-xl,24px);padding:var(--rh-space-lg,16px) var(--rh-space-2xl,32px)}nav[data-v-798f280c]{flex:1}ol[data-v-798f280c]{background-color:#f6f6f6;font-size:.875rem;list-style:none;margin:0;padding:0}li[data-v-798f280c]{color:#151515;display:inline}a[data-v-798f280c]:after{border-bottom-color:transparent;border-left-color:transparent;box-shadow:inset .25rem .25rem 0 .0625rem #8a8d8d;content:"";display:inline-block;height:1.07143em;margin:0 .5em;position:relative;right:0;top:.75em;transform:translateY(-.5em) rotate(135deg) scale(.5);width:1.07143em}</style>
<style>ol[data-v-fa0dae77]{margin:0;padding:0}li[data-v-fa0dae77],ol[data-v-fa0dae77],ul[data-v-fa0dae77]{list-style:none;margin:0}.chapter-title[data-v-fa0dae77]{font-size:1em}.sub-chapter-title[data-v-fa0dae77],.sub-chapter-title a[data-v-fa0dae77]{font-size:.875rem}#toc .link[data-v-fa0dae77],#toc-mobile .link[data-v-fa0dae77],.heading[data-v-fa0dae77],.sub-nav .link[data-v-fa0dae77],.sub-nav .link .link[data-v-fa0dae77]{display:block;padding:var(--rh-space-md,8px) var(--rh-space-2xl,32px);padding-right:2.5em;text-decoration:none;transition:background-color .25s}.heading[data-v-fa0dae77]:hover,.link[data-v-fa0dae77]:hover,.sub-nav .link[data-v-fa0dae77]:hover{background:var(--rh-color-surface-lighter,#f2f2f2);box-shadow:inset 3px 0 0 0 #d2d2d2;color:#151515}details[open]:first-of-type>.heading[data-v-fa0dae77]:after{transform:rotate(135deg)}.item[data-v-fa0dae77]{line-height:22px}#toc .link[data-v-fa0dae77],#toc-mobile .link[data-v-fa0dae77]{color:var(--rh-color-text-primary-on-light,#151515)}.sub-nav[data-v-fa0dae77],.toc-wrapper[data-v-fa0dae77]{list-style:none;margin:0}.toc-wrapper[data-v-fa0dae77]{min-width:100%;padding:0}.sub-nav[data-v-fa0dae77]{font-size:1em;line-height:24px;padding-left:1rem;padding-left:16px}.sub-nav .link[data-v-fa0dae77]:hover{color:#151515}.active[data-v-fa0dae77]{background:var(--rh-color-surface-lighter,#f2f2f2);box-shadow:inset 3px 0 0 0 var(--rh-color-icon-primary-on-light,#e00)}.chapter-landing-page[data-v-fa0dae77]{font-weight:500}summary[data-v-fa0dae77]{cursor:pointer;list-style:none;position:relative}summary[data-v-fa0dae77]::-webkit-details-marker{display:none}@keyframes slideDown-fa0dae77{0%{height:0;opacity:0}to{height:var(--details-height-open,"100%");opacity:1}}html[data-v-fa0dae77]{--details-transition-time:400ms}details[data-v-fa0dae77]{max-height:var(--details-height-closed,auto);transition:all ease-out var(--details-transition-time,0)}details[open][data-v-fa0dae77]{max-height:var(--details-height-open,auto)}details .heading.sub-chapter-title[data-v-fa0dae77]:after,details .heading[data-v-fa0dae77]:after{border-right:3px solid #151515;border-top:3px solid #151515;color:#151515;content:"";display:flex;float:right;height:9px;margin-left:16px;position:absolute;right:var(--rh-space-xl,24px);top:14px;transform:rotate(45deg);width:9px}details .heading.sub-chapter-title[data-v-fa0dae77]:after{height:8px;width:8px}</style>
<style>.item[data-v-b883c74f]{line-height:22px}#toc .link[data-v-b883c74f],#toc-mobile .link[data-v-b883c74f]{color:var(--rh-color-text-primary-on-light,#151515)}#toc .link[data-v-b883c74f],#toc-mobile .link[data-v-b883c74f],.heading[data-v-b883c74f],.sub-nav .link[data-v-b883c74f],.sub-nav .link .link[data-v-b883c74f]{display:block;padding:var(--rh-space-md,8px) var(--rh-space-2xl,32px);padding-right:2.5em;text-decoration:none;transition:background-color .25s}.heading[data-v-b883c74f]:hover,.link[data-v-b883c74f]:hover,.sub-nav .link[data-v-b883c74f]:hover{background:var(--rh-color-surface-lighter,#f2f2f2);box-shadow:inset 3px 0 0 0 #d2d2d2;color:#151515}ol[data-v-b883c74f]{margin:0;padding:0}li[data-v-b883c74f],ol[data-v-b883c74f],ul[data-v-b883c74f]{list-style:none;margin:0}.chapter-title[data-v-b883c74f]{font-size:1em}.sub-nav[data-v-b883c74f]{font-size:1em;line-height:24px;list-style:none;margin:0;padding-left:1rem;padding-left:16px}.sub-nav .link[data-v-b883c74f]:hover{color:#151515}.active[data-v-b883c74f]{background:var(--rh-color-surface-lighter,#f2f2f2);box-shadow:inset 3px 0 0 0 var(--rh-color-icon-primary-on-light,#e00)}.sub-chapter-title[data-v-b883c74f],.sub-chapter-title a[data-v-b883c74f]{font-size:.875rem}summary[data-v-b883c74f]{cursor:pointer;list-style:none;position:relative}summary[data-v-b883c74f]::-webkit-details-marker{display:none}html[data-v-b883c74f]{--details-transition-time:400ms}.chapter-landing-page[data-v-b883c74f]{font-weight:500}details[open]:first-of-type>.heading[data-v-b883c74f]:after{transform:rotate(135deg)}details[data-v-b883c74f]{max-height:var(--details-height-closed,auto);transition:all ease-out var(--details-transition-time,0)}details[open][data-v-b883c74f]{max-height:var(--details-height-open,auto)}details .heading.sub-chapter-title[data-v-b883c74f]:after,details .heading[data-v-b883c74f]:after{border-right:3px solid #151515;border-top:3px solid #151515;color:#151515;content:"";display:flex;float:right;height:9px;margin-left:16px;position:absolute;right:var(--rh-space-xl,24px);top:14px;transform:rotate(45deg);width:9px}details .heading.sub-chapter-title[data-v-b883c74f]:after{height:8px;width:8px}</style>
<style>.html-container[data-v-9c2a9ddb]{padding:2rem 1.5rem 0}rh-alert[data-v-9c2a9ddb]{color:#151515}@media (max-width:772px){.html-container[data-v-9c2a9ddb]{padding:3rem 1rem 0}}</style>
<style>.search-container[data-v-69710f44]{height:100%}.form-box[data-v-69710f44],.search-container[data-v-69710f44]{justify-content:center}.form-box[data-v-69710f44],.search-box[data-v-69710f44],.search-container[data-v-69710f44]{align-items:center;display:flex;width:100%}.search-box[data-v-69710f44]{justify-content:space-between;position:relative}ul[data-v-69710f44]{list-style-type:none}#search-list[data-v-69710f44]{background:#fff;border:1px solid #f0f0f0;box-shadow:0 4px 4px 0 #00000040;color:#151515;display:block;left:0;margin:0;padding:0;position:absolute;top:37px;width:100%;z-index:200}#search-list li[data-v-69710f44]{align-items:center;display:flex;justify-content:space-between;padding:.75rem}#search-list .active[data-v-69710f44],#search-list li[data-v-69710f44]:hover{background:#f0f0f0}.group-title[data-v-69710f44]{border-top:1px solid #4d4d4d;color:#4d4d4d;cursor:default;font-size:12px;font-weight:400;pointer-events:none}.group-title[data-v-69710f44],.group-title[data-v-69710f44]:hover{background:#fff}.search-item-text-elipsis[data-v-69710f44]{display:inline-block;max-width:48%;overflow:hidden;text-overflow:ellipsis;white-space:nowrap}.search-item-text[data-v-69710f44]{padding-left:1.75rem}.search-item-chip[data-v-69710f44]{float:right}.search-product-version[data-v-69710f44]{background:#fff;border:1px solid #f0f0f0;border-radius:3px;font-size:1rem;font-weight:400;line-height:24px}.search-icon-form[data-v-69710f44]{color:var(--rh-color-gray-50,#707070);left:12px;position:absolute}.input-search-box[data-v-69710f44]{-webkit-appearance:none;-moz-appearance:none;appearance:none;border:0;font-family:var(--rh-font-family-body-text,"Red Hat Text","RedHatText",Arial,sans-serif);font-size:var(--rh-font-size-body-text-md,1rem);height:36px;padding:0 40px;width:100%}.input-clear-btn[data-v-69710f44]{align-items:center;background-color:transparent;border:none;display:flex;height:36px;justify-content:center;margin-right:-30px;outline:none;transform:translateX(-30px)}.input-clear-btn[data-v-69710f44]:focus{border:1px solid var(--rh-color-accent-base-on-light,#06c)}.input-clear-btn:focus .input-clear-icon[data-v-69710f44]{color:var(--rh-color-canvas-black,#151515)}.input-clear-icon[data-v-69710f44]{color:#6b6e72;cursor:pointer}.input-clear-icon[data-v-69710f44]:hover{color:var(--rh-color-canvas-black,#151515)}.form-submit-btn[data-v-69710f44]::part(button){align-items:center;background-color:var(--rh-color-gray-20,#e0e0e0);border-radius:0;display:flex;height:36px;justify-content:center;--_default-border-color:var(--rh-color-gray-20,#e0e0e0)}.input-close-btn[data-v-69710f44]{background:none;border:none;cursor:pointer;margin:0 var(--rh-space-lg,16px)}.input-close-icon[data-v-69710f44]{color:var(--rh-color-white,#fff)}@media (max-width:992px){.form-box[data-v-69710f44]{gap:var(--rh-space-md,8px);margin:auto;width:100%}.input-search-box[data-v-69710f44]{border:1px solid var(--rh-color-gray-30,#c7c7c7)}.input-search-box[data-v-69710f44]::-moz-placeholder{color:#6a6e73;font-family:var(--rh-font-family-body-text,"Red Hat Text","RedHatText",Arial,sans-serif);font-size:var(--rh-font-size-body-text-md,1rem);font-weight:var(--rh-font-weight-code-regular,400);line-height:24px}.input-search-box[data-v-69710f44]::placeholder{color:#6a6e73;font-family:var(--rh-font-family-body-text,"Red Hat Text","RedHatText",Arial,sans-serif);font-size:var(--rh-font-size-body-text-md,1rem);font-weight:var(--rh-font-weight-code-regular,400);line-height:24px}.search-item-text-elipsis[data-v-69710f44]{max-width:60%}}@media (max-width:767px){.input-close-btn[data-v-69710f44]{display:none}.search-container[data-v-69710f44]{border:1px solid #f0f0f0}}</style>
<link rel="stylesheet" href="/_nuxt/entry.DNAluCmw.css" integrity="sha384-FnrZajt9k3u4tri3ClqikI96k+jP7kyrvgKKgdzBr5Y8CQEi3gusKE0+eMSLvGxm">
<link rel="stylesheet" href="/_nuxt/SearchAutocomplete.DkrJaF8R.css" integrity="sha384-Zw8gf6w7SrpWDmknvrab5QanIN+DSJRS/bPB9/lgDkhR7JhDmG/VF++MTMKU8mKB">
<link rel="stylesheet" href="/_nuxt/Breadcrumbs.BLkLxUMB.css" integrity="sha384-f6iEfCywVoZB0/hIKTRaxywtS21KzhBx2JOI/uVjjU9aqFcP7X9cqLH29w2HQvLe">
<link rel="stylesheet" href="/_nuxt/Alert.fTkXFs3h.css" integrity="sha384-yFMpT5E64LAQi3qJ10AJJ1oOH3DrI68OvLSjSivjNCQXZ25pmFxlPavPQ0TEyEpq">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/C3PvZR0C.js" integrity="sha384-H9Can2ny34kmIBk2SNFJRaBH6FotFjI6LVF8tQ4HqJnqY0a1tGDF/4RHxK2LFs7c">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/Ds9UYxCD.js" integrity="sha384-PFyBx6Pvk48yXM+prD4CDErW/3HFtPEqORVyAch5qDvJSyubA93+vR4jsWGRQKZs">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/BUXK7nH-.js" integrity="sha384-Kqf3r1QrD7+NOn9EuK/ba9sTBZjn7vLAjnCoRtq7IKz+QV0JUUBFf1Snf1yVkkgr">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/BxBriHwM.js" integrity="sha384-bejD6BN5N1iVRo5Ymn+LdVN0jvrnJTzgqgFD9xQ5+Yi46U6ff+s5W2AISzRWvJaM">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/DB5Lt3x5.js" integrity="sha384-Ae/gV/4Dt4jnJApC0CWbckKJ7omq+W9Hb4jjdMyhxGJpwk6FlO7pGYMD3bPO/h1y">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/D8BFaW0S.js" integrity="sha384-/m09v/yYk14L9Hra6/9jYtMTn2IdkKQvzpFPRQ5P/baRKwdZQN98873hqvwuYXFS">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/_58Q44fW.js" integrity="sha384-EdSd8jpnetO/BWDAc8C4SpQExZ7pYjMygNPvbLmiA1TaYsNUdVOqIIyOIzaErEeU">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/DOCUiUcq.js" integrity="sha384-9H868K5q7MLzC8TSRXT3pVqDzsOVxZLYvUQ8cLGpHPZCFEyEJjnwSHE+/7FWrJPV">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/CiTVMRA7.js" integrity="sha384-xBIJ2xO0t62/oREKqSxPtW1tRxKY+5YYXbGcJ0QR9IRM28JhL+53NOiAvVFn3rmF">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/CR3F0y4K.js">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/Bn-QuJwp.js">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/T_zvNmZe.js">
<link rel="prefetch" as="script" crossorigin href="/_nuxt/Ciddaed-.js">
<link rel="prefetch" as="image" type="image/svg+xml" href="/_nuxt/Footer_Cloud.DpSdW8MR.svg">
<script type="module">
      import "@rhds/elements/rh-cta/rh-cta.js";
      </script>
<script type="module">
      import '@rhds/elements/rh-alert/rh-alert.js';
      </script>
<script type="module">
        import "/scripts/v1/@cpelements/pfe-navigation/dist/pfe-navigation.min.js";
        import "/scripts/v1/@rhds/elements/elements/rh-button/rh-button.js";
      </script>
<script type="module">import "@rhds/elements/rh-footer/rh-footer.js"</script>
<link rel="canonical" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index">
<script type="module">
      import "@rhds/elements/rh-alert/rh-alert.js";
      import "@rhds/elements/rh-code-block/rh-code-block.js";
      import '@rhds/elements/rh-cta/rh-cta.js';
      import '@patternfly/elements/pf-switch/pf-switch.js';
      import '@cpelements/rh-table/dist/rh-table.js';
      import '@patternfly/pfe-clipboard/dist/pfe-clipboard.min.js';
      import '@patternfly/elements/pf-button/pf-button.js';
      import '@patternfly/elements/pf-modal/pf-modal.js';
      import '@patternfly/elements/pf-icon/pf-icon.js';
      import '@patternfly/elements/pf-popover/pf-popover.js';
      import '@patternfly/elements/pf-tooltip/pf-tooltip.js';
      import '@rhds/elements/rh-badge/rh-badge.js';
      </script>
<meta name="description" content="Monitoring and managing system status and performance | Red Hat Documentation">
<meta name="app-version" content="v0.0.1">
<script type="module">
        import "/scripts/v1/@rhds/elements/elements/rh-button/rh-button.js";
      </script>
<script type="module">
      import '@rhds/elements/rh-alert/rh-alert.js';
      </script>
<script type="module">
        import "/scripts/v1/@rhds/elements/elements/rh-button/rh-button.js";
        import "@patternfly/elements/pf-badge/pf-badge.js";
      </script>
<script type="module" src="/_nuxt/C3PvZR0C.js" crossorigin integrity="sha384-H9Can2ny34kmIBk2SNFJRaBH6FotFjI6LVF8tQ4HqJnqY0a1tGDF/4RHxK2LFs7c"></script></head><body><div id="__nuxt"><!--[--><!--[--><!----><header data-v-edc0d12c><a href="#pfe-navigation" id="global-skip-to-nav" class="skip-link visually-hidden" data-v-edc0d12c>Skip to navigation</a><a href="#main-content" class="skip-link visually-hidden" data-v-edc0d12c>Skip to content</a><nav id="upper-navigation" class="upper-navigation" aria-labelledby="upper-navigation-label" data-analytics-region="upper-navigation" data-v-edc0d12c><p id="upper-navigation-label" class="upper-nav-hidden" data-v-edc0d12c>Featured links</p><div class="upper-nav-container" data-v-edc0d12c><ul class="upper-nav-menu" data-v-edc0d12c><li data-v-edc0d12c><a href="https://access.redhat.com/" class="upper-nav-links" data-analytics-text="Support" data-analytics-category="Featured Links" data-v-edc0d12c>Support</a></li><li data-v-edc0d12c><a href="https://console.redhat.com/" class="upper-nav-links" data-analytics-text="Console" data-analytics-category="Featured Links" data-v-edc0d12c>Console</a></li><li data-v-edc0d12c><a href="https://developers.redhat.com/" class="upper-nav-links" data-analytics-text="Developers" data-analytics-category="Featured Links" data-v-edc0d12c>Developers</a></li><li data-v-edc0d12c><a href="https://www.redhat.com/en/products/trials" class="upper-nav-links" data-analytics-text="Start a trial" data-analytics-category="Featured Links" data-v-edc0d12c>Start a trial</a></li><li data-v-edc0d12c><button id="all-red-hat" class="upper-nav-links" data-analytics-text="All Red Hat" data-analytics-category="Featured Links" aria-expanded="false" data-analytics-linktype="tab" data-v-edc0d12c>All Red Hat<svg class="upper-nav-arrow" xmlns="http://www.w3.org/2000/svg" width="1024" height="1024" viewBox="0 0 1024 1024" aria-hidden="true" data-v-edc0d12c=""><path d="M810.642 511.557c0 8.905-3.447 16.776-10.284 23.613L322.31 1013.216c-6.835 6.837-14.706 10.284-23.61 10.284s-16.776-3.447-23.613-10.284l-51.303-51.303c-6.837-6.837-10.284-14.707-10.284-23.612s3.447-16.775 10.284-23.61L626.972 511.5 223.784 108.31c-6.837-6.835-10.284-14.706-10.284-23.61s3.447-16.776 10.284-23.613l51.303-51.303C281.924 2.947 289.794-.5 298.7-.5s16.775 3.447 23.61 10.284L800.36 487.83c6.837 6.837 10.284 14.708 10.284 23.613v.114" data-v-edc0d12c=""/></svg></button><div class="upper-nav-dropdown-container" data-v-edc0d12c><ul data-v-edc0d12c><li data-v-edc0d12c><span data-v-edc0d12c>For customers</span><ul data-v-edc0d12c><li data-v-edc0d12c><a href="https://access.redhat.com/support" data-pzn-audience="customers" data-analytics-category="All Red Hat|For customers" data-analytics-text="Customer support" data-v-edc0d12c>Customer support</a></li><li data-v-edc0d12c><a href="/products" data-pzn-audience="customers" data-analytics-category="All Red Hat|For customers" data-analytics-text="Documentation" data-v-edc0d12c>Documentation</a></li><li data-v-edc0d12c><a href="https://access.redhat.com/support/cases" data-pzn-audience="customers" data-analytics-category="All Red Hat|For customers" data-analytics-text="Support cases" data-v-edc0d12c>Support Cases</a></li><li data-v-edc0d12c><a href="https://access.redhat.com/management" data-pzn-audience="customers" data-analytics-category="All Red Hat|For customers" data-analytics-text="Subscription management" data-v-edc0d12c>Subscription management</a></li><li data-v-edc0d12c><a href="https://catalog.redhat.com/" data-analytics-category="All Red Hat|For customers" data-analytics-text="Red Hat Ecosystem Catalog" data-v-edc0d12c>Red Hat Ecosystem Catalog</a></li><li data-v-edc0d12c><a href="https://catalog.redhat.com/partners" data-analytics-category="All Red Hat|For customers" data-analytics-text="Find a partner" data-v-edc0d12c>Find a partner</a></li></ul></li><li data-v-edc0d12c><span data-v-edc0d12c>For partners</span><ul data-v-edc0d12c><li data-v-edc0d12c><a href="https://connect.redhat.com/login" data-pzn-audience="partners" data-analytics-category="All Red Hat|For partners" data-analytics-text="Partner login" data-v-edc0d12c>Partner login</a></li><li data-v-edc0d12c><a href="https://connect.redhat.com/en/support" data-pzn-audience="partners" data-analytics-category="All Red Hat|For partners" data-analytics-text="Partner support" data-v-edc0d12c>Partner support</a></li><li data-v-edc0d12c><a href="https://connect.redhat.com/" data-pzn-audience="partners" data-analytics-category="All Red Hat|For partners" data-analytics-text="Become a partner " data-v-edc0d12c>Become a partner</a></li></ul></li><li data-v-edc0d12c><span data-v-edc0d12c>Try, buy, &amp; sell</span><ul data-v-edc0d12c><li data-v-edc0d12c><a href="https://marketplace.redhat.com/en-us" data-analytics-category="All Red Hat|Try, buy, &amp; sell" data-analytics-text="Red Hat Marketplace" data-v-edc0d12c>Red Hat Marketplace</a></li><li data-v-edc0d12c><a href="https://www.redhat.com/en/store" data-analytics-category="All Red Hat|Try, buy, &amp; sell" data-analytics-text="Red Hat Store" data-v-edc0d12c>Red Hat Store</a></li><li data-v-edc0d12c><a href="https://www.redhat.com/en/contact" data-analytics-category="All Red Hat|Try, buy, &amp; sell" data-analytics-text="Contact sales" data-v-edc0d12c>Contact Sales</a></li><li data-v-edc0d12c><a href="https://www.redhat.com/en/products/trials" data-analytics-category="All Red Hat|Try, buy, &amp; sell" data-analytics-text="Start a trial" data-v-edc0d12c>Start a trial</a></li></ul></li><li data-v-edc0d12c><span data-v-edc0d12c>Learning resources</span><ul data-v-edc0d12c><li data-v-edc0d12c><a href="https://www.redhat.com/en/services/training-and-certification" data-analytics-category="All Red Hat|Learning resources" data-analytics-text="Training and certification " data-v-edc0d12c>Training and certification</a></li><li data-v-edc0d12c><a href="https://developers.redhat.com/" data-pzn-audience="developers|community" data-analytics-category="All Red Hat|Learning resources" data-analytics-text="For developers" data-v-edc0d12c>For developers</a></li><li data-v-edc0d12c><a href="https://cloud.redhat.com/learn" data-analytics-category="All Red Hat|Learning resources" data-analytics-text="Hybrid cloud learning hub" data-v-edc0d12c>Hybrid cloud learning hub</a></li><li data-v-edc0d12c><a href="https://www.redhat.com/en/interactive-labs" data-analytics-category="All Red Hat|Learning resources" data-analytics-text="Interactive labs" data-v-edc0d12c>Interactive labs</a></li><li data-v-edc0d12c><a href="https://learn.redhat.com/" data-analytics-category="All Red Hat|Learning resources" data-analytics-text="Learning community" data-v-edc0d12c>Learning community</a></li><li data-v-edc0d12c><a href="https://www.redhat.com/en/tv" data-analytics-category="All Red Hat|Learning resources" data-analytics-text="Red Hat TV" data-v-edc0d12c>Red Hat TV</a></li></ul></li><li data-v-edc0d12c><span data-v-edc0d12c>Open source communities</span><ul data-v-edc0d12c><li data-v-edc0d12c><a href="https://www.ansible.com/community" data-analytics-category="All Red Hat|Open source communities" data-analytics-text="Ansible" data-v-edc0d12c>Ansible</a></li><li data-v-edc0d12c><a href="https://www.redhat.com/sysadmin/" id="community" data-analytics-category="All Red Hat|Open source communities" data-analytics-text="For system administrators" data-v-edc0d12c>For system administrators</a></li><li data-v-edc0d12c><a href="https://www.redhat.com/architect/" data-pzn-audience="community" data-analytics-category="All Red Hat|Open source communities" data-analytics-text="For architects" data-v-edc0d12c>For architects</a></li></ul></li></ul></div></li></ul></div></nav><pfe-navigation full-width id="pfe-navigation" pf-sticky="true" lang="en" data-v-edc0d12c><nav class="pfe-navigation" aria-label="Main Navigation" data-v-edc0d12c><div class="pfe-navigation__logo-wrapper" id="pfe-navigation__logo-wrapper" data-v-edc0d12c><a href="/en" class="pfe-navigation__logo-link" data-v-edc0d12c><img class="pfe-navigation__logo-image pfe-navigation__logo-image--screen pfe-navigation__logo-image--small" src="/Logo-Red_Hat-Documentation-A-Reverse-RGB.svg" width="240" height="40" alt="Red Hat Documentation" data-v-edc0d12c></a></div></nav><span data-v-edc0d12c></span><div slot="secondary-links" data-v-edc0d12c><div class="hidden-at-desktop hidden-at-tablet search-mobile" data-v-edc0d12c><div id="search-form" class="search-container" opensearchbox="true" data-v-edc0d12c data-v-69710f44><form role="search" class="form-box" autocomplete="off" data-v-69710f44><div class="search-box" data-v-69710f44><pf-icon icon="search" size="md" class="search-icon-form" data-v-69710f44></pf-icon><input type="text" id="input-search" class="input-search-box" placeholder="Search documentation" value aria-autocomplete="list" data-v-69710f44><!----><!----><!----><rh-button disabled variant="tertiary" class="form-submit-btn" data-v-69710f44><img src="data:image/svg+xml,%3csvg%20width=&#39;14&#39;%20height=&#39;14&#39;%20viewBox=&#39;0%200%2014%2014&#39;%20fill=&#39;none&#39;%20xmlns=&#39;http://www.w3.org/2000/svg&#39;%3e%3cpath%20d=&#39;M7%200L5.6%201.4L10.3%206H0V8H10.3L5.6%2012.6L7%2014L14%207L7%200Z&#39;%20fill=&#39;%23707070&#39;/%3e%3c/svg%3e" alt="Submit button" data-v-69710f44></rh-button></div></form><!----></div></div><div class="hidden-at-desktop hidden-at-tablet buttons" data-v-edc0d12c><a href="https://access.redhat.com/" data-analytics-category="More Red Hat" data-analytics-text="Support" data-v-edc0d12c>Support</a><a href="https://console.redhat.com/" data-analytics-category="More Red Hat" data-analytics-text="Console" data-v-edc0d12c>Console</a><a href="https://developers.redhat.com/" data-analytics-category="More Red Hat" data-analytics-text="Developers" data-v-edc0d12c>Developers</a><a href="https://www.redhat.com/en/products/trials" data-analytics-category="More Red Hat" data-analytics-text="Start a trial" data-v-edc0d12c>Start a trial</a><a href="https://www.redhat.com/en/contact" data-analytics-category="More Red Hat" data-analytics-text="Contact" data-v-edc0d12c>Contact</a></div><div class="hidden-at-desktop hidden-at-tablet mobile-lang-select" data-v-edc0d12c><label for="lang_selection" data-v-edc0d12c>Select your language</label><select id="lang_selection" data-v-edc0d12c><!--[--><option value="en" xml:lang="en" hreflang="en" data-v-edc0d12c>English</option><option value="fr" xml:lang="fr" hreflang="fr" data-v-edc0d12c>Français</option><option value="ko" xml:lang="ko" hreflang="ko" data-v-edc0d12c>한국어</option><option value="ja" xml:lang="ja" hreflang="ja" data-v-edc0d12c>日本語</option><option value="zh-cn" xml:lang="zh-cn" hreflang="zh-cn" data-v-edc0d12c>中文 (中国)</option><option value="de" xml:lang="de" hreflang="de" data-v-edc0d12c>Deutsch</option><option value="it" xml:lang="it" hreflang="it" data-v-edc0d12c>Italiano</option><option value="pt-br" xml:lang="pt-br" hreflang="pt-br" data-v-edc0d12c>Português</option><option value="es" xml:lang="es" hreflang="es" data-v-edc0d12c>Español</option><!--]--></select></div></div></pfe-navigation></header><main id="main-content"><!--[--><!--[--><!--[--><!----><!----><!--]--><div class="breadcrumbs" id="breadcrumbs" data-v-8589d091 data-v-798f280c><nav aria-label="Breadcrumb" class="breadcrumb" data-v-798f280c><ol data-v-798f280c><li data-v-798f280c><a href="/" data-v-798f280c>Home</a></li><li data-v-798f280c><a href="/en/products" data-v-798f280c>Products</a></li><!--[--><li data-v-798f280c><a href="/en/documentation/red_hat_enterprise_linux/" data-v-798f280c>Red Hat Enterprise Linux</a></li><li data-v-798f280c><a href="/en/documentation/red_hat_enterprise_linux/9/" data-v-798f280c>9</a></li><li data-v-798f280c><!--[-->Monitoring and managing system status and performance<!--]--></li><!--]--></ol></nav><span data-v-798f280c></span></div><!----><nav id="mobile-nav" class="mobile-nav" aria-label="mobile menu" data-v-8589d091><div class="mobile-nav-wrapper" data-v-8589d091><div id="first-button" data-v-8589d091><button id="toc-btn" aria-expanded="false" aria-controls="mobile-nav-content-wrapper" class="mobile-nav-btn" data-v-8589d091><span class="sr-only" data-v-8589d091>Open </span>Table of contents</button></div><div id="second-button" data-v-8589d091><button id="settings-btn" aria-expanded="false" aria-controls="mobile-nav-content-wrapper" class="mobile-nav-btn" data-v-8589d091><pf-icon icon="cog" size="md" data-v-8589d091></pf-icon><span class="sr-only" data-v-8589d091>Open page settings</span></button></div></div><div id="mobile-nav-content-wrapper" class="hidden" role="navigation" tabindex="0" data-v-8589d091><div id="toc-mobile" class="hidden" aria-labelledby="toc-btn" data-v-8589d091><div class="shrink-product-padding product-container" id="product-container-mobile" data-v-8589d091><h1 class="product-title" data-v-8589d091>Red Hat Enterprise Linux</h1><!----></div><div class="toc-filter-mobile" data-v-8589d091><span id="text" part="text" data-v-8589d091><input id="text-input" aria-label="Search input" part="text-input" placeholder="Filter table of contents" type="text" class value data-v-8589d091><!----></span></div><div id="toc-wrapper-mobile" class="span-xs-12 span-sm-4 span-md-3" lang="en" data-v-8589d091><nav id="mobile-toc-menu" class="table-of-contents" aria-label="table of content - mobile" data-v-8589d091><!----></nav></div><!----></div><div id="page-content-options-mobile" class="hidden" aria-labelledby="settings-btn" data-v-8589d091><div class="page-layout-options" data-v-8589d091><label for="page-format-mobile" data-v-8589d091>Format</label><select id="page-format-mobile" class="page-format-dropdown" data-v-8589d091><option class="page-type" value="html" data-v-8589d091>Multi-page</option><option selected class="page-type" value="html-single" data-v-8589d091>Single-page</option><option class="page-type" value="pdf" data-v-8589d091>View full doc as PDF</option></select></div></div></div><!----><!----></nav><div class="grid grid-col-12 content-wrapper" data-v-8589d091><aside id="left-content" class="span-xs-12 span-sm-4 span-md-3" lang="en-us" aria-label="left navigation" xml:lang="en-us" data-v-8589d091><div class="toc-container" id="toc-container" visible="true" data-v-8589d091><div class="toc-focus-container" id="toc-focus-container" data-v-8589d091><button class="toc-focus-btn" aria-label="toggle left menu" aria-controls="toc-container" aria-expanded="true" data-v-8589d091><pf-icon size="md" icon="angle-left" class="toc-focus-btn-icon" data-v-8589d091></pf-icon></button></div><div class="product-container" id="product-container-desktop" data-v-8589d091><h1 class="product-title" data-v-8589d091>Red Hat Enterprise Linux</h1><!----></div><div class="toc-filter" id="toc-filter" data-v-8589d091><span id="text" part="text" data-v-8589d091><span id="search-icon" part="search-icon" data-v-8589d091><pf-icon icon="filter" size="md" data-v-8589d091></pf-icon></span><input id="text-input" aria-label="Search input" part="text-input" placeholder="Filter table of contents" type="text" class value data-v-8589d091><!----></span></div><div id="toc-wrapper" class="toc-wrapper" data-v-8589d091><nav id="toc" class="max-height-85 table-of-contents" aria-label="Table of contents" data-v-8589d091><ol id="toc-list" data-v-8589d091><!--[--><li class="item chapter" data-v-fa0dae77><a class="link active" href id="chapter-index" data-v-fa0dae77>Monitoring and managing system status and performance</a></li><li class="item chapter" data-v-fa0dae77><a class="link" href="#proc_providing-feedback-on-red-hat-documentation_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-proc_providing-feedback-on-red-hat-documentation_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Providing feedback on Red Hat documentation</a></li><li class="item chapter" data-v-fa0dae77><details id="toc--getting-started-with-tuned_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="getting-started-with-tuned_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>1. Getting started with TuneD</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#getting-started-with-tuned_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-getting-started-with-tuned_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Getting started with TuneD</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#the-purpose-of-tuned_getting-started-with-tuned" id="sub-link-to-monitoring_and_managing_system_status_and_performance-the-purpose-of-tuned_getting-started-with-tuned" data-v-b883c74f>1.1. The purpose of TuneD</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#tuned-profiles_getting-started-with-tuned" id="sub-link-to-monitoring_and_managing_system_status_and_performance-tuned-profiles_getting-started-with-tuned" data-v-b883c74f>1.2. TuneD profiles</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#the-default-tuned-profile_getting-started-with-tuned" id="sub-link-to-monitoring_and_managing_system_status_and_performance-the-default-tuned-profile_getting-started-with-tuned" data-v-b883c74f>1.3. The default TuneD profile</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#merged-tuned-profiles_getting-started-with-tuned" id="sub-link-to-monitoring_and_managing_system_status_and_performance-merged-tuned-profiles_getting-started-with-tuned" data-v-b883c74f>1.4. Merged TuneD profiles</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#the-location-of-tuned-profiles_getting-started-with-tuned" id="sub-link-to-monitoring_and_managing_system_status_and_performance-the-location-of-tuned-profiles_getting-started-with-tuned" data-v-b883c74f>1.5. The location of TuneD profiles</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#tuned-profiles-distributed-with-rhel_getting-started-with-tuned" id="sub-link-to-monitoring_and_managing_system_status_and_performance-tuned-profiles-distributed-with-rhel_getting-started-with-tuned" data-v-b883c74f>1.6. TuneD profiles distributed with RHEL</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#tuned-cpu-partitioning-profile_getting-started-with-tuned" id="sub-link-to-monitoring_and_managing_system_status_and_performance-tuned-cpu-partitioning-profile_getting-started-with-tuned" data-v-b883c74f>1.7. TuneD cpu-partitioning profile</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#using-the-tuned-cpu-partitioning-profile-for-low-latency-tuning_getting-started-with-tuned" id="sub-link-to-monitoring_and_managing_system_status_and_performance-using-the-tuned-cpu-partitioning-profile-for-low-latency-tuning_getting-started-with-tuned" data-v-b883c74f>1.8. Using the TuneD cpu-partitioning profile for low-latency tuning</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#customizing-the-cpu-partitioning-tuned-profile_getting-started-with-tuned" id="sub-link-to-monitoring_and_managing_system_status_and_performance-customizing-the-cpu-partitioning-tuned-profile_getting-started-with-tuned" data-v-b883c74f>1.9. Customizing the cpu-partitioning TuneD profile</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#real-time-tuned-profiles-distributed-with-rhel_getting-started-with-tuned" id="sub-link-to-monitoring_and_managing_system_status_and_performance-real-time-tuned-profiles-distributed-with-rhel_getting-started-with-tuned" data-v-b883c74f>1.10. Real-time TuneD profiles distributed with RHEL</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#static-and-dynamic-tuning-in-tuned_getting-started-with-tuned" id="sub-link-to-monitoring_and_managing_system_status_and_performance-static-and-dynamic-tuning-in-tuned_getting-started-with-tuned" data-v-b883c74f>1.11. Static and dynamic tuning in TuneD</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#tuned-no-daemon-mode_getting-started-with-tuned" id="sub-link-to-monitoring_and_managing_system_status_and_performance-tuned-no-daemon-mode_getting-started-with-tuned" data-v-b883c74f>1.12. TuneD no-daemon mode</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#installing-and-enabling-tuned_getting-started-with-tuned" id="sub-link-to-monitoring_and_managing_system_status_and_performance-installing-and-enabling-tuned_getting-started-with-tuned" data-v-b883c74f>1.13. Installing and enabling TuneD</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#listing-available-tuned-profiles_getting-started-with-tuned" id="sub-link-to-monitoring_and_managing_system_status_and_performance-listing-available-tuned-profiles_getting-started-with-tuned" data-v-b883c74f>1.14. Listing available TuneD profiles</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#setting-a-tuned-profile_getting-started-with-tuned" id="sub-link-to-monitoring_and_managing_system_status_and_performance-setting-a-tuned-profile_getting-started-with-tuned" data-v-b883c74f>1.15. Setting a TuneD profile</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><details id="nested-toc--using-the-tuned-d-bus-interface_getting-started-with-tuned" data-v-b883c74f><summary class="heading sub-chapter-title" id="using-the-tuned-d-bus-interface_getting-started-with-tuned--summary" data-v-b883c74f>1.16. Using the TuneD D-Bus interface</summary><ol id="sub-nav--using-the-tuned-d-bus-interface_getting-started-with-tuned" class="sub-nav" data-v-b883c74f><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title chapter-landing-page" href="#using-the-tuned-d-bus-interface_getting-started-with-tuned" id="chapter-landing--monitoring_and_managing_system_status_and_performance-using-the-tuned-d-bus-interface_getting-started-with-tuned" data-v-b883c74f>Using the TuneD D-Bus interface</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#using-the-tuned-d-bus-interface-to-show-available-tuned-d-bus-api-methods_using-the-tuned-d-bus-interface" id="sub-link-to-monitoring_and_managing_system_status_and_performance-using-the-tuned-d-bus-interface-to-show-available-tuned-d-bus-api-methods_using-the-tuned-d-bus-interface" data-v-b883c74f>1.16.1. Using the TuneD D-Bus interface to show available TuneD D-Bus API methods</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#using-the-tuned-d-bus-interface-to-change-the-active-tuned-profile_using-the-tuned-d-bus-interface" id="sub-link-to-monitoring_and_managing_system_status_and_performance-using-the-tuned-d-bus-interface-to-change-the-active-tuned-profile_using-the-tuned-d-bus-interface" data-v-b883c74f>1.16.2. Using the TuneD D-Bus interface to change the active TuneD profile</a></li><!--]--><!--]--></ol></details></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#disabling-tuned_getting-started-with-tuned" id="sub-link-to-monitoring_and_managing_system_status_and_performance-disabling-tuned_getting-started-with-tuned" data-v-b883c74f>1.17. Disabling TuneD</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--customizing-tuned-profiles_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="customizing-tuned-profiles_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>2. Customizing TuneD profiles</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#customizing-tuned-profiles_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-customizing-tuned-profiles_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Customizing TuneD profiles</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#tuned-profiles_customizing-tuned-profiles" id="sub-link-to-monitoring_and_managing_system_status_and_performance-tuned-profiles_customizing-tuned-profiles" data-v-b883c74f>2.1. TuneD profiles</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#the-default-tuned-profile_customizing-tuned-profiles" id="sub-link-to-monitoring_and_managing_system_status_and_performance-the-default-tuned-profile_customizing-tuned-profiles" data-v-b883c74f>2.2. The default TuneD profile</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#merged-tuned-profiles_customizing-tuned-profiles" id="sub-link-to-monitoring_and_managing_system_status_and_performance-merged-tuned-profiles_customizing-tuned-profiles" data-v-b883c74f>2.3. Merged TuneD profiles</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#the-location-of-tuned-profiles_customizing-tuned-profiles" id="sub-link-to-monitoring_and_managing_system_status_and_performance-the-location-of-tuned-profiles_customizing-tuned-profiles" data-v-b883c74f>2.4. The location of TuneD profiles</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#inheritance-between-tuned-profiles_customizing-tuned-profiles" id="sub-link-to-monitoring_and_managing_system_status_and_performance-inheritance-between-tuned-profiles_customizing-tuned-profiles" data-v-b883c74f>2.5. Inheritance between TuneD profiles</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#static-and-dynamic-tuning-in-tuned_customizing-tuned-profiles" id="sub-link-to-monitoring_and_managing_system_status_and_performance-static-and-dynamic-tuning-in-tuned_customizing-tuned-profiles" data-v-b883c74f>2.6. Static and dynamic tuning in TuneD</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#tuned-plug-ins_customizing-tuned-profiles" id="sub-link-to-monitoring_and_managing_system_status_and_performance-tuned-plug-ins_customizing-tuned-profiles" data-v-b883c74f>2.7. TuneD plug-ins</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#available-tuned-plug-ins_customizing-tuned-profiles" id="sub-link-to-monitoring_and_managing_system_status_and_performance-available-tuned-plug-ins_customizing-tuned-profiles" data-v-b883c74f>2.8. Available TuneD plug-ins</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#functionalities-of-the-scheduler-tuned-plug-in_customizing-tuned-profiles" id="sub-link-to-monitoring_and_managing_system_status_and_performance-functionalities-of-the-scheduler-tuned-plug-in_customizing-tuned-profiles" data-v-b883c74f>2.9. Functionalities of the scheduler TuneD plugin</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#variables-in-tuned-profiles_customizing-tuned-profiles" id="sub-link-to-monitoring_and_managing_system_status_and_performance-variables-in-tuned-profiles_customizing-tuned-profiles" data-v-b883c74f>2.10. Variables in TuneD profiles</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#built-in-functions-in-tuned-profiles_customizing-tuned-profiles" id="sub-link-to-monitoring_and_managing_system_status_and_performance-built-in-functions-in-tuned-profiles_customizing-tuned-profiles" data-v-b883c74f>2.11. Built-in functions in TuneD profiles</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#built-in-functions-available-in-tuned-profiles_customizing-tuned-profiles" id="sub-link-to-monitoring_and_managing_system_status_and_performance-built-in-functions-available-in-tuned-profiles_customizing-tuned-profiles" data-v-b883c74f>2.12. Built-in functions available in TuneD profiles</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#creating-new-tuned-profiles_customizing-tuned-profiles" id="sub-link-to-monitoring_and_managing_system_status_and_performance-creating-new-tuned-profiles_customizing-tuned-profiles" data-v-b883c74f>2.13. Creating new TuneD profiles</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#modifying-existing-tuned-profiles_customizing-tuned-profiles" id="sub-link-to-monitoring_and_managing_system_status_and_performance-modifying-existing-tuned-profiles_customizing-tuned-profiles" data-v-b883c74f>2.14. Modifying existing TuneD profiles</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#setting-the-disk-scheduler-using-tuned_customizing-tuned-profiles" id="sub-link-to-monitoring_and_managing_system_status_and_performance-setting-the-disk-scheduler-using-tuned_customizing-tuned-profiles" data-v-b883c74f>2.15. Setting the disk scheduler using TuneD</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--reviewing-a-system-using-tuna-interface_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="reviewing-a-system-using-tuna-interface_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>3. Reviewing a system by using the tuna interface</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#reviewing-a-system-using-tuna-interface_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-reviewing-a-system-using-tuna-interface_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Reviewing a system by using the tuna interface</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#installing-tuna-tool_reviewing-a-system-using-tuna-interface" id="sub-link-to-monitoring_and_managing_system_status_and_performance-installing-tuna-tool_reviewing-a-system-using-tuna-interface" data-v-b883c74f>3.1. Installing the tuna tool</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#viewing-the-system-status-using-tuna-tool_reviewing-a-system-using-tuna-interface" id="sub-link-to-monitoring_and_managing_system_status_and_performance-viewing-the-system-status-using-tuna-tool_reviewing-a-system-using-tuna-interface" data-v-b883c74f>3.2. Viewing the system status by using the tuna tool</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#tuning-cpus-using-tuna-tool_reviewing-a-system-using-tuna-interface" id="sub-link-to-monitoring_and_managing_system_status_and_performance-tuning-cpus-using-tuna-tool_reviewing-a-system-using-tuna-interface" data-v-b883c74f>3.3. Tuning CPUs by using the tuna tool</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#tuning-irqs-using-tuna-tool_reviewing-a-system-using-tuna-interface" id="sub-link-to-monitoring_and_managing_system_status_and_performance-tuning-irqs-using-tuna-tool_reviewing-a-system-using-tuna-interface" data-v-b883c74f>3.4. Tuning IRQs by using the tuna tool</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--monitoring-performance-by-using-the-metrics-rhel-system-role_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="monitoring-performance-by-using-the-metrics-rhel-system-role_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>4. Configuring performance monitoring with PCP by using RHEL system roles</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#monitoring-performance-by-using-the-metrics-rhel-system-role_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-monitoring-performance-by-using-the-metrics-rhel-system-role_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Configuring performance monitoring with PCP by using RHEL system roles</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#configuring-performance-co-pilot-by-using-the-metrics-rhel-system-role_monitoring-performance-by-using-the-metrics-rhel-system-role" id="sub-link-to-monitoring_and_managing_system_status_and_performance-configuring-performance-co-pilot-by-using-the-metrics-rhel-system-role_monitoring-performance-by-using-the-metrics-rhel-system-role" data-v-b883c74f>4.1. Configuring Performance Co-Pilot by using the metrics RHEL system role</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#configuring-performance-co-pilot-with-authentication-by-using-the-metrics-rhel-system-role_monitoring-performance-by-using-the-metrics-rhel-system-role" id="sub-link-to-monitoring_and_managing_system_status_and_performance-configuring-performance-co-pilot-with-authentication-by-using-the-metrics-rhel-system-role_monitoring-performance-by-using-the-metrics-rhel-system-role" data-v-b883c74f>4.2. Configuring Performance Co-Pilot with authentication by using the metrics RHEL system role</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#setting-up-grafana-by-using-the-metrics-rhel-system-role-to-monitor-multiple-hosts-with-performance-co-pilot_monitoring-performance-by-using-the-metrics-rhel-system-role" id="sub-link-to-monitoring_and_managing_system_status_and_performance-setting-up-grafana-by-using-the-metrics-rhel-system-role-to-monitor-multiple-hosts-with-performance-co-pilot_monitoring-performance-by-using-the-metrics-rhel-system-role" data-v-b883c74f>4.3. Setting up Grafana by using the metrics RHEL system role to monitor multiple hosts with Performance Co-Pilot</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#configuring-web-hooks-in-performance-co-pilot-by-using-the-metrics-rhel-system-role_monitoring-performance-by-using-the-metrics-rhel-system-role" id="sub-link-to-monitoring_and_managing_system_status_and_performance-configuring-web-hooks-in-performance-co-pilot-by-using-the-metrics-rhel-system-role_monitoring-performance-by-using-the-metrics-rhel-system-role" data-v-b883c74f>4.4. Configuring web hooks in Performance Co-Pilot by using the metrics RHEL system role</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--setting-up-pcp_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="setting-up-pcp_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>5. Setting up PCP</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#setting-up-pcp_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-setting-up-pcp_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Setting up PCP</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#overview-of-pcp_setting-up-pcp" id="sub-link-to-monitoring_and_managing_system_status_and_performance-overview-of-pcp_setting-up-pcp" data-v-b883c74f>5.1. Overview of PCP</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#installing-and-enabling-pcp_setting-up-pcp" id="sub-link-to-monitoring_and_managing_system_status_and_performance-installing-and-enabling-pcp_setting-up-pcp" data-v-b883c74f>5.2. Installing and enabling PCP</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#deploying-a-minimal-pcp-setup_setting-up-pcp" id="sub-link-to-monitoring_and_managing_system_status_and_performance-deploying-a-minimal-pcp-setup_setting-up-pcp" data-v-b883c74f>5.3. Deploying a minimal PCP setup</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#system-services-distributed-with-pcp_setting-up-pcp" id="sub-link-to-monitoring_and_managing_system_status_and_performance-system-services-distributed-with-pcp_setting-up-pcp" data-v-b883c74f>5.4. System services and tools distributed with PCP</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#pcp-deployment-architectures_setting-up-pcp" id="sub-link-to-monitoring_and_managing_system_status_and_performance-pcp-deployment-architectures_setting-up-pcp" data-v-b883c74f>5.5. PCP deployment architectures</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#recommended-deployment-architecture_setting-up-pcp" id="sub-link-to-monitoring_and_managing_system_status_and_performance-recommended-deployment-architecture_setting-up-pcp" data-v-b883c74f>5.6. Recommended deployment architecture</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#sizing-factors_setting-up-pcp" id="sub-link-to-monitoring_and_managing_system_status_and_performance-sizing-factors_setting-up-pcp" data-v-b883c74f>5.7. Sizing factors</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#configuration-options-for-pcp-scaling_setting-up-pcp" id="sub-link-to-monitoring_and_managing_system_status_and_performance-configuration-options-for-pcp-scaling_setting-up-pcp" data-v-b883c74f>5.8. Configuration options for PCP scaling</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#example-analyzing-the-centralized-logging-deployment_setting-up-pcp" id="sub-link-to-monitoring_and_managing_system_status_and_performance-example-analyzing-the-centralized-logging-deployment_setting-up-pcp" data-v-b883c74f>5.9. Example: Analyzing the centralized logging deployment</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#example-analyzing-the-federated-setup-deployment_setting-up-pcp" id="sub-link-to-monitoring_and_managing_system_status_and_performance-example-analyzing-the-federated-setup-deployment_setting-up-pcp" data-v-b883c74f>5.10. Example: Analyzing the federated setup deployment</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><details id="nested-toc--establishing-secure-pcp-connections_setting-up-pcp" data-v-b883c74f><summary class="heading sub-chapter-title" id="establishing-secure-pcp-connections_setting-up-pcp--summary" data-v-b883c74f>5.11. Establishing secure PCP connections</summary><ol id="sub-nav--establishing-secure-pcp-connections_setting-up-pcp" class="sub-nav" data-v-b883c74f><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title chapter-landing-page" href="#establishing-secure-pcp-connections_setting-up-pcp" id="chapter-landing--monitoring_and_managing_system_status_and_performance-establishing-secure-pcp-connections_setting-up-pcp" data-v-b883c74f>Establishing secure PCP connections</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#secure-pcp-connections_establishing-secure-pcp-connections" id="sub-link-to-monitoring_and_managing_system_status_and_performance-secure-pcp-connections_establishing-secure-pcp-connections" data-v-b883c74f>5.11.1. Secure PCP connections</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#configuring-secure-connections-for-pcp-collector-components_establishing-secure-pcp-connections" id="sub-link-to-monitoring_and_managing_system_status_and_performance-configuring-secure-connections-for-pcp-collector-components_establishing-secure-pcp-connections" data-v-b883c74f>5.11.2. Configuring secure connections for PCP collector components</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#configuring-secure-connections-for-pcp-monitoring-components_establishing-secure-pcp-connections" id="sub-link-to-monitoring_and_managing_system_status_and_performance-configuring-secure-connections-for-pcp-monitoring-components_establishing-secure-pcp-connections" data-v-b883c74f>5.11.3. Configuring secure connections for PCP monitoring components</a></li><!--]--><!--]--></ol></details></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#troubleshooting-high-memory-usage_setting-up-pcp" id="sub-link-to-monitoring_and_managing_system_status_and_performance-troubleshooting-high-memory-usage_setting-up-pcp" data-v-b883c74f>5.12. Troubleshooting high memory usage</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--logging-performance-data-with-pmlogger_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="logging-performance-data-with-pmlogger_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>6. Logging performance data with pmlogger</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#logging-performance-data-with-pmlogger_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-logging-performance-data-with-pmlogger_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Logging performance data with pmlogger</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#modifying-the-pmlogger-configuration-file-with-pmlogconf_logging-performance-data-with-pmlogger" id="sub-link-to-monitoring_and_managing_system_status_and_performance-modifying-the-pmlogger-configuration-file-with-pmlogconf_logging-performance-data-with-pmlogger" data-v-b883c74f>6.1. Modifying the pmlogger configuration file with pmlogconf</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#editing-the-pmlogger-configuration-file-manually_logging-performance-data-with-pmlogger" id="sub-link-to-monitoring_and_managing_system_status_and_performance-editing-the-pmlogger-configuration-file-manually_logging-performance-data-with-pmlogger" data-v-b883c74f>6.2. Editing the pmlogger configuration file manually</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#enabling-the-pmlogger-service_logging-performance-data-with-pmlogger" id="sub-link-to-monitoring_and_managing_system_status_and_performance-enabling-the-pmlogger-service_logging-performance-data-with-pmlogger" data-v-b883c74f>6.3. Enabling the pmlogger service</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#setting-up-a-client-system-for-metrics-collection_logging-performance-data-with-pmlogger" id="sub-link-to-monitoring_and_managing_system_status_and_performance-setting-up-a-client-system-for-metrics-collection_logging-performance-data-with-pmlogger" data-v-b883c74f>6.4. Setting up a client system for metrics collection</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#setting-up-the-central-server-to-collect-data_logging-performance-data-with-pmlogger" id="sub-link-to-monitoring_and_managing_system_status_and_performance-setting-up-the-central-server-to-collect-data_logging-performance-data-with-pmlogger" data-v-b883c74f>6.5. Setting up a central server to collect data</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#systemd-units-and-pmlogger_logging-performance-data-with-pmlogger" id="sub-link-to-monitoring_and_managing_system_status_and_performance-systemd-units-and-pmlogger_logging-performance-data-with-pmlogger" data-v-b883c74f>6.6. Systemd units and pmlogger</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#replaying-the-pcp-log-archives_logging-performance-data-with-pmlogger" id="sub-link-to-monitoring_and_managing_system_status_and_performance-replaying-the-pcp-log-archives_logging-performance-data-with-pmlogger" data-v-b883c74f>6.7. Replaying the PCP log archives with pmrep</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#enabling-pcp-version-3-archives_logging-performance-data-with-pmlogger" id="sub-link-to-monitoring_and_managing_system_status_and_performance-enabling-pcp-version-3-archives_logging-performance-data-with-pmlogger" data-v-b883c74f>6.8. Enabling PCP version 3 archives</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--monitoring-performance-with-performance-co-pilot_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="monitoring-performance-with-performance-co-pilot_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>7. Monitoring performance with Performance Co-Pilot</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#monitoring-performance-with-performance-co-pilot_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-monitoring-performance-with-performance-co-pilot_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Monitoring performance with Performance Co-Pilot</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#monitoring-postfix-with-pmda-postfix_monitoring-performance-with-performance-co-pilot" id="sub-link-to-monitoring_and_managing_system_status_and_performance-monitoring-postfix-with-pmda-postfix_monitoring-performance-with-performance-co-pilot" data-v-b883c74f>7.1. Monitoring postfix with pmda-postfix</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#visually-tracing-pcp-log-archives-with-pcp-charts_monitoring-performance-with-performance-co-pilot" id="sub-link-to-monitoring_and_managing_system_status_and_performance-visually-tracing-pcp-log-archives-with-pcp-charts_monitoring-performance-with-performance-co-pilot" data-v-b883c74f>7.2. Visually tracing PCP log archives with the PCP Charts application</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#collecting-data-from-sql-server-using-pcp_monitoring-performance-with-performance-co-pilot" id="sub-link-to-monitoring_and_managing_system_status_and_performance-collecting-data-from-sql-server-using-pcp_monitoring-performance-with-performance-co-pilot" data-v-b883c74f>7.3. Collecting data from SQL server using PCP</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_generating-pcp-archives-from-sadc-archives_monitoring-performance-with-performance-co-pilot" id="sub-link-to-monitoring_and_managing_system_status_and_performance-proc_generating-pcp-archives-from-sadc-archives_monitoring-performance-with-performance-co-pilot" data-v-b883c74f>7.4. Generating PCP archives from sadc archives</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--performance-analysis-of-xfs-with-pcp_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="performance-analysis-of-xfs-with-pcp_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>8. Performance analysis of XFS with PCP</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#performance-analysis-of-xfs-with-pcp_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-performance-analysis-of-xfs-with-pcp_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Performance analysis of XFS with PCP</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#installing-xfs-pmda-manually_performance-analysis-of-xfs-with-pcp" id="sub-link-to-monitoring_and_managing_system_status_and_performance-installing-xfs-pmda-manually_performance-analysis-of-xfs-with-pcp" data-v-b883c74f>8.1. Installing XFS PMDA manually</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#examining-xfs-performance-metrics-with-pminfo_performance-analysis-of-xfs-with-pcp" id="sub-link-to-monitoring_and_managing_system_status_and_performance-examining-xfs-performance-metrics-with-pminfo_performance-analysis-of-xfs-with-pcp" data-v-b883c74f>8.2. Examining XFS performance metrics with pminfo</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#resetting-xfs-performance-metrics-with-pmstore_performance-analysis-of-xfs-with-pcp" id="sub-link-to-monitoring_and_managing_system_status_and_performance-resetting-xfs-performance-metrics-with-pmstore_performance-analysis-of-xfs-with-pcp" data-v-b883c74f>8.3. Resetting XFS performance metrics with pmstore</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#pcp-metric-groups-for-xfs_performance-analysis-of-xfs-with-pcp" id="sub-link-to-monitoring_and_managing_system_status_and_performance-pcp-metric-groups-for-xfs_performance-analysis-of-xfs-with-pcp" data-v-b883c74f>8.4. PCP metric groups for XFS</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#per-device-pcp-metric-groups-for-xfs_performance-analysis-of-xfs-with-pcp" id="sub-link-to-monitoring_and_managing_system_status_and_performance-per-device-pcp-metric-groups-for-xfs_performance-analysis-of-xfs-with-pcp" data-v-b883c74f>8.5. Per-device PCP metric groups for XFS</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>9. Setting up graphical representation of PCP metrics</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Setting up graphical representation of PCP metrics</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#setting-up-pcp-with-pcp-zeroconf_setting-up-graphical-representation-of-pcp-metrics" id="sub-link-to-monitoring_and_managing_system_status_and_performance-setting-up-pcp-with-pcp-zeroconf_setting-up-graphical-representation-of-pcp-metrics" data-v-b883c74f>9.1. Setting up PCP with pcp-zeroconf</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#setting-up-a-grafana-server_setting-up-graphical-representation-of-pcp-metrics" id="sub-link-to-monitoring_and_managing_system_status_and_performance-setting-up-a-grafana-server_setting-up-graphical-representation-of-pcp-metrics" data-v-b883c74f>9.2. Setting up a Grafana server</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#accessing-the-grafana-web-ui_setting-up-graphical-representation-of-pcp-metrics" id="sub-link-to-monitoring_and_managing_system_status_and_performance-accessing-the-grafana-web-ui_setting-up-graphical-representation-of-pcp-metrics" data-v-b883c74f>9.3. Accessing the Grafana web UI</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#configuring-secure-connections-for-grafana_setting-up-graphical-representation-of-pcp-metrics" id="sub-link-to-monitoring_and_managing_system_status_and_performance-configuring-secure-connections-for-grafana_setting-up-graphical-representation-of-pcp-metrics" data-v-b883c74f>9.4. Configuring secure connections for Grafana</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#configuring-pcp-redis_setting-up-graphical-representation-of-pcp-metrics" id="sub-link-to-monitoring_and_managing_system_status_and_performance-configuring-pcp-redis_setting-up-graphical-representation-of-pcp-metrics" data-v-b883c74f>9.5. Configuring PCP Redis</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#creating-panel-and-alerts-in-pcp-redis-data-source_setting-up-graphical-representation-of-pcp-metrics" id="sub-link-to-monitoring_and_managing_system_status_and_performance-creating-panel-and-alerts-in-pcp-redis-data-source_setting-up-graphical-representation-of-pcp-metrics" data-v-b883c74f>9.6. Creating panels and alerts in PCP Redis data source</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#adding-notification-channels-for-alerts_setting-up-graphical-representation-of-pcp-metrics" id="sub-link-to-monitoring_and_managing_system_status_and_performance-adding-notification-channels-for-alerts_setting-up-graphical-representation-of-pcp-metrics" data-v-b883c74f>9.7. Adding notification channels for alerts</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#setting-up-authentication-between-pcp-components_setting-up-graphical-representation-of-pcp-metrics" id="sub-link-to-monitoring_and_managing_system_status_and_performance-setting-up-authentication-between-pcp-components_setting-up-graphical-representation-of-pcp-metrics" data-v-b883c74f>9.8. Setting up authentication between PCP components</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#installing-pcp-bpftrace_setting-up-graphical-representation-of-pcp-metrics" id="sub-link-to-monitoring_and_managing_system_status_and_performance-installing-pcp-bpftrace_setting-up-graphical-representation-of-pcp-metrics" data-v-b883c74f>9.9. Installing PCP bpftrace</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#viewing-the-pcp-bpftrace-system-analysis-dashboard_setting-up-graphical-representation-of-pcp-metrics" id="sub-link-to-monitoring_and_managing_system_status_and_performance-viewing-the-pcp-bpftrace-system-analysis-dashboard_setting-up-graphical-representation-of-pcp-metrics" data-v-b883c74f>9.10. Viewing the PCP bpftrace System Analysis dashboard</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#installing-pcp-vector_setting-up-graphical-representation-of-pcp-metrics" id="sub-link-to-monitoring_and_managing_system_status_and_performance-installing-pcp-vector_setting-up-graphical-representation-of-pcp-metrics" data-v-b883c74f>9.11. Installing PCP Vector</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#viewing-the-pcp-vector-checklist_setting-up-graphical-representation-of-pcp-metrics" id="sub-link-to-monitoring_and_managing_system_status_and_performance-viewing-the-pcp-vector-checklist_setting-up-graphical-representation-of-pcp-metrics" data-v-b883c74f>9.12. Viewing the PCP Vector Checklist</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#using-heatmaps-in-grafana_setting-up-graphical-representation-of-pcp-metrics" id="sub-link-to-monitoring_and_managing_system_status_and_performance-using-heatmaps-in-grafana_setting-up-graphical-representation-of-pcp-metrics" data-v-b883c74f>9.13. Using heatmaps in Grafana</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#troubleshooting-grafana-issues_setting-up-graphical-representation-of-pcp-metrics" id="sub-link-to-monitoring_and_managing_system_status_and_performance-troubleshooting-grafana-issues_setting-up-graphical-representation-of-pcp-metrics" data-v-b883c74f>9.14. Troubleshooting Grafana issues</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--using-the-web-console-for-selecting-performance-profiles_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="using-the-web-console-for-selecting-performance-profiles_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>10. Optimizing the system performance using the web console</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#using-the-web-console-for-selecting-performance-profiles_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-using-the-web-console-for-selecting-performance-profiles_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Optimizing the system performance using the web console</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#performance-tuning-options-in-the-web-console_optimizing-the-system-performance-using-the-web-console" id="sub-link-to-monitoring_and_managing_system_status_and_performance-performance-tuning-options-in-the-web-console_optimizing-the-system-performance-using-the-web-console" data-v-b883c74f>10.1. Performance tuning options in the web console</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#setting-a-performance-profile-in-the-web-console_optimizing-the-system-performance-using-the-web-console" id="sub-link-to-monitoring_and_managing_system_status_and_performance-setting-a-performance-profile-in-the-web-console_optimizing-the-system-performance-using-the-web-console" data-v-b883c74f>10.2. Setting a performance profile in the web console</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#monitoring-performance-using-the-web-console_optimizing-the-system-performance-using-the-web-console" id="sub-link-to-monitoring_and_managing_system_status_and_performance-monitoring-performance-using-the-web-console_optimizing-the-system-performance-using-the-web-console" data-v-b883c74f>10.3. Monitoring performance on the local system by using the web console</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_enabling-performance-metrics-export-with-pcp-from-the-web-console_optimizing-the-system-performance-using-the-web-console" id="sub-link-to-monitoring_and_managing_system_status_and_performance-proc_enabling-performance-metrics-export-with-pcp-from-the-web-console_optimizing-the-system-performance-using-the-web-console" data-v-b883c74f>10.4. Monitoring performance on several systems by using the web console and Grafana</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--setting-the-disk-scheduler_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="setting-the-disk-scheduler_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>11. Setting the disk scheduler</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#setting-the-disk-scheduler_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-setting-the-disk-scheduler_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Setting the disk scheduler</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#available-disk-schedulers_setting-the-disk-scheduler" id="sub-link-to-monitoring_and_managing_system_status_and_performance-available-disk-schedulers_setting-the-disk-scheduler" data-v-b883c74f>11.1. Available disk schedulers</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#different-disk-schedulers-for-different-use-cases_setting-the-disk-scheduler" id="sub-link-to-monitoring_and_managing_system_status_and_performance-different-disk-schedulers-for-different-use-cases_setting-the-disk-scheduler" data-v-b883c74f>11.2. Different disk schedulers for different use cases</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#the-default-disk-scheduler_setting-the-disk-scheduler" id="sub-link-to-monitoring_and_managing_system_status_and_performance-the-default-disk-scheduler_setting-the-disk-scheduler" data-v-b883c74f>11.3. The default disk scheduler</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#determining-the-active-disk-scheduler_setting-the-disk-scheduler" id="sub-link-to-monitoring_and_managing_system_status_and_performance-determining-the-active-disk-scheduler_setting-the-disk-scheduler" data-v-b883c74f>11.4. Determining the active disk scheduler</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#setting-the-disk-scheduler-using-tuned_setting-the-disk-scheduler" id="sub-link-to-monitoring_and_managing_system_status_and_performance-setting-the-disk-scheduler-using-tuned_setting-the-disk-scheduler" data-v-b883c74f>11.5. Setting the disk scheduler using TuneD</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#setting-the-disk-scheduler-using-udev-rules_setting-the-disk-scheduler" id="sub-link-to-monitoring_and_managing_system_status_and_performance-setting-the-disk-scheduler-using-udev-rules_setting-the-disk-scheduler" data-v-b883c74f>11.6. Setting the disk scheduler using udev rules</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#temporarily-setting-a-scheduler-for-a-specific-disk_setting-the-disk-scheduler" id="sub-link-to-monitoring_and_managing_system_status_and_performance-temporarily-setting-a-scheduler-for-a-specific-disk_setting-the-disk-scheduler" data-v-b883c74f>11.7. Temporarily setting a scheduler for a specific disk</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--assembly_tuning-the-performance-of-a-samba-server_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="assembly_tuning-the-performance-of-a-samba-server_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>12. Tuning the performance of a Samba server</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#assembly_tuning-the-performance-of-a-samba-server_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-assembly_tuning-the-performance-of-a-samba-server_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Tuning the performance of a Samba server</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_setting-the-smb-protocol-version_assembly_tuning-the-performance-of-a-samba-server" id="sub-link-to-monitoring_and_managing_system_status_and_performance-proc_setting-the-smb-protocol-version_assembly_tuning-the-performance-of-a-samba-server" data-v-b883c74f>12.1. Setting the SMB protocol version</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_tuning-shares-with-directories-that-contain-a-large-number-of-files_assembly_tuning-the-performance-of-a-samba-server" id="sub-link-to-monitoring_and_managing_system_status_and_performance-proc_tuning-shares-with-directories-that-contain-a-large-number-of-files_assembly_tuning-the-performance-of-a-samba-server" data-v-b883c74f>12.2. Tuning shares with directories that contain a large number of files</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#con_settings-that-can-have-a-negative-performance-impact_assembly_tuning-the-performance-of-a-samba-server" id="sub-link-to-monitoring_and_managing_system_status_and_performance-con_settings-that-can-have-a-negative-performance-impact_assembly_tuning-the-performance-of-a-samba-server" data-v-b883c74f>12.3. Settings that can have a negative performance impact</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--optimizing-virtual-machine-performance-in-rhel_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="optimizing-virtual-machine-performance-in-rhel_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>13. Optimizing virtual machine performance</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#optimizing-virtual-machine-performance-in-rhel_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-optimizing-virtual-machine-performance-in-rhel_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Optimizing virtual machine performance</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#what-influences-virtual-machine-performance_optimizing-virtual-machine-performance-in-rhel" id="sub-link-to-monitoring_and_managing_system_status_and_performance-what-influences-virtual-machine-performance_optimizing-virtual-machine-performance-in-rhel" data-v-b883c74f>13.1. What influences virtual machine performance</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#optimizing-virtual-machine-performance-using-tuned_optimizing-virtual-machine-performance-in-rhel" id="sub-link-to-monitoring_and_managing_system_status_and_performance-optimizing-virtual-machine-performance-using-tuned_optimizing-virtual-machine-performance-in-rhel" data-v-b883c74f>13.2. Optimizing virtual machine performance by using TuneD</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><details id="nested-toc--assembly_optimizing-libvirt-daemons_optimizing-virtual-machine-performance-in-rhel" data-v-b883c74f><summary class="heading sub-chapter-title" id="assembly_optimizing-libvirt-daemons_optimizing-virtual-machine-performance-in-rhel--summary" data-v-b883c74f>13.3. Optimizing libvirt daemons</summary><ol id="sub-nav--assembly_optimizing-libvirt-daemons_optimizing-virtual-machine-performance-in-rhel" class="sub-nav" data-v-b883c74f><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title chapter-landing-page" href="#assembly_optimizing-libvirt-daemons_optimizing-virtual-machine-performance-in-rhel" id="chapter-landing--monitoring_and_managing_system_status_and_performance-assembly_optimizing-libvirt-daemons_optimizing-virtual-machine-performance-in-rhel" data-v-b883c74f>Optimizing libvirt daemons</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#con_types-of-libvirt-daemons_assembly_optimizing-libvirt-daemons" id="sub-link-to-monitoring_and_managing_system_status_and_performance-con_types-of-libvirt-daemons_assembly_optimizing-libvirt-daemons" data-v-b883c74f>13.3.1. Types of libvirt daemons</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_enabling-modular-libvirt-daemons_assembly_optimizing-libvirt-daemons" id="sub-link-to-monitoring_and_managing_system_status_and_performance-proc_enabling-modular-libvirt-daemons_assembly_optimizing-libvirt-daemons" data-v-b883c74f>13.3.2. Enabling modular libvirt daemons</a></li><!--]--><!--]--></ol></details></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><details id="nested-toc--configuring-virtual-machine-ram_optimizing-virtual-machine-performance-in-rhel" data-v-b883c74f><summary class="heading sub-chapter-title" id="configuring-virtual-machine-ram_optimizing-virtual-machine-performance-in-rhel--summary" data-v-b883c74f>13.4. Configuring virtual machine memory</summary><ol id="sub-nav--configuring-virtual-machine-ram_optimizing-virtual-machine-performance-in-rhel" class="sub-nav" data-v-b883c74f><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title chapter-landing-page" href="#configuring-virtual-machine-ram_optimizing-virtual-machine-performance-in-rhel" id="chapter-landing--monitoring_and_managing_system_status_and_performance-configuring-virtual-machine-ram_optimizing-virtual-machine-performance-in-rhel" data-v-b883c74f>Configuring virtual machine memory</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#adding-and-removing-virtual-machine-ram-using-the-web-console_configuring-virtual-machine-ram" id="sub-link-to-monitoring_and_managing_system_status_and_performance-adding-and-removing-virtual-machine-ram-using-the-web-console_configuring-virtual-machine-ram" data-v-b883c74f>13.4.1. Adding and removing virtual machine memory by using the web console</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#adding-and-removing-virtual-machine-ram-using-the-command-line-interface_configuring-virtual-machine-ram" id="sub-link-to-monitoring_and_managing_system_status_and_performance-adding-and-removing-virtual-machine-ram-using-the-command-line-interface_configuring-virtual-machine-ram" data-v-b883c74f>13.4.2. Adding and removing virtual machine memory by using the command-line interface</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><details id="nested-toc--adding-and-removing-virtual-machine-memory-by-using-virtio-mem_configuring-virtual-machine-ram" data-v-b883c74f><summary class="heading sub-chapter-title" id="adding-and-removing-virtual-machine-memory-by-using-virtio-mem_configuring-virtual-machine-ram--summary" data-v-b883c74f>13.4.3. Adding and removing virtual machine memory by using virtio-mem</summary><ol id="sub-nav--adding-and-removing-virtual-machine-memory-by-using-virtio-mem_configuring-virtual-machine-ram" class="sub-nav" data-v-b883c74f><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title chapter-landing-page" href="#adding-and-removing-virtual-machine-memory-by-using-virtio-mem_configuring-virtual-machine-ram" id="chapter-landing--monitoring_and_managing_system_status_and_performance-adding-and-removing-virtual-machine-memory-by-using-virtio-mem_configuring-virtual-machine-ram" data-v-b883c74f>Adding and removing virtual machine memory by using virtio-mem</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#overview-of-virtio-mem_adding-and-removing-virtual-machine-memory-by-using-virtio-mem" id="sub-link-to-monitoring_and_managing_system_status_and_performance-overview-of-virtio-mem_adding-and-removing-virtual-machine-memory-by-using-virtio-mem" data-v-b883c74f>13.4.3.1. Overview of virtio-mem</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#configuring-memory-onlining-in-virtual-machines_adding-and-removing-virtual-machine-memory-by-using-virtio-mem" id="sub-link-to-monitoring_and_managing_system_status_and_performance-configuring-memory-onlining-in-virtual-machines_adding-and-removing-virtual-machine-memory-by-using-virtio-mem" data-v-b883c74f>13.4.3.2. Configuring memory onlining in virtual machines</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#attaching-a-virtio-mem-device-to-virtual-machines_adding-and-removing-virtual-machine-memory-by-using-virtio-mem" id="sub-link-to-monitoring_and_managing_system_status_and_performance-attaching-a-virtio-mem-device-to-virtual-machines_adding-and-removing-virtual-machine-memory-by-using-virtio-mem" data-v-b883c74f>13.4.3.3. Attaching a virtio-mem device to virtual machines</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#comparison-of-memory-onlining-configurations_adding-and-removing-virtual-machine-memory-by-using-virtio-mem" id="sub-link-to-monitoring_and_managing_system_status_and_performance-comparison-of-memory-onlining-configurations_adding-and-removing-virtual-machine-memory-by-using-virtio-mem" data-v-b883c74f>13.4.3.4. Comparison of memory onlining configurations</a></li><!--]--><!--]--></ol></details></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#additional_resources" id="sub-link-to-monitoring_and_managing_system_status_and_performance-additional_resources" data-v-b883c74f>13.4.4. Additional resources</a></li><!--]--><!--]--></ol></details></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><details id="nested-toc--optimizing-virtual-machine-i-o-performance_optimizing-virtual-machine-performance-in-rhel" data-v-b883c74f><summary class="heading sub-chapter-title" id="optimizing-virtual-machine-i-o-performance_optimizing-virtual-machine-performance-in-rhel--summary" data-v-b883c74f>13.5. Optimizing virtual machine I/O performance</summary><ol id="sub-nav--optimizing-virtual-machine-i-o-performance_optimizing-virtual-machine-performance-in-rhel" class="sub-nav" data-v-b883c74f><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title chapter-landing-page" href="#optimizing-virtual-machine-i-o-performance_optimizing-virtual-machine-performance-in-rhel" id="chapter-landing--monitoring_and_managing_system_status_and_performance-optimizing-virtual-machine-i-o-performance_optimizing-virtual-machine-performance-in-rhel" data-v-b883c74f>Optimizing virtual machine I/O performance</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#tuning-block-i-o-in-virtual-machines_optimizing-virtual-machine-i-o-performance" id="sub-link-to-monitoring_and_managing_system_status_and_performance-tuning-block-i-o-in-virtual-machines_optimizing-virtual-machine-i-o-performance" data-v-b883c74f>13.5.1. Tuning block I/O in virtual machines</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#disk-i-o-throttling-in-virtual-machines_optimizing-virtual-machine-i-o-performance" id="sub-link-to-monitoring_and_managing_system_status_and_performance-disk-i-o-throttling-in-virtual-machines_optimizing-virtual-machine-i-o-performance" data-v-b883c74f>13.5.2. Disk I/O throttling in virtual machines</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#configuring-multi-queue-virtio-scsi_optimizing-virtual-machine-i-o-performance" id="sub-link-to-monitoring_and_managing_system_status_and_performance-configuring-multi-queue-virtio-scsi_optimizing-virtual-machine-i-o-performance" data-v-b883c74f>13.5.3. Enabling multi-queue virtio-scsi</a></li><!--]--><!--]--></ol></details></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><details id="nested-toc--optimizing-virtual-machine-cpu-performance_optimizing-virtual-machine-performance-in-rhel" data-v-b883c74f><summary class="heading sub-chapter-title" id="optimizing-virtual-machine-cpu-performance_optimizing-virtual-machine-performance-in-rhel--summary" data-v-b883c74f>13.6. Optimizing virtual machine CPU performance</summary><ol id="sub-nav--optimizing-virtual-machine-cpu-performance_optimizing-virtual-machine-performance-in-rhel" class="sub-nav" data-v-b883c74f><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title chapter-landing-page" href="#optimizing-virtual-machine-cpu-performance_optimizing-virtual-machine-performance-in-rhel" id="chapter-landing--monitoring_and_managing_system_status_and_performance-optimizing-virtual-machine-cpu-performance_optimizing-virtual-machine-performance-in-rhel" data-v-b883c74f>Optimizing virtual machine CPU performance</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#adding-and-removing-virtual-cpus-using-the-command-line-interface_optimizing-virtual-machine-cpu-performance" id="sub-link-to-monitoring_and_managing_system_status_and_performance-adding-and-removing-virtual-cpus-using-the-command-line-interface_optimizing-virtual-machine-cpu-performance" data-v-b883c74f>13.6.1. Adding and removing virtual CPUs by using the command-line interface</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#managing-virtual-cpus-using-the-web-console_optimizing-virtual-machine-cpu-performance" id="sub-link-to-monitoring_and_managing_system_status_and_performance-managing-virtual-cpus-using-the-web-console_optimizing-virtual-machine-cpu-performance" data-v-b883c74f>13.6.2. Managing virtual CPUs by using the web console</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#configuring-numa-in-a-virtual-machine_optimizing-virtual-machine-cpu-performance" id="sub-link-to-monitoring_and_managing_system_status_and_performance-configuring-numa-in-a-virtual-machine_optimizing-virtual-machine-cpu-performance" data-v-b883c74f>13.6.3. Configuring NUMA in a virtual machine</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#sample-vcpu-performance-tuning-scenario_optimizing-virtual-machine-cpu-performance" id="sub-link-to-monitoring_and_managing_system_status_and_performance-sample-vcpu-performance-tuning-scenario_optimizing-virtual-machine-cpu-performance" data-v-b883c74f>13.6.4. Sample vCPU performance tuning scenario</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_managing-ksm_optimizing-virtual-machine-cpu-performance" id="sub-link-to-monitoring_and_managing_system_status_and_performance-proc_managing-ksm_optimizing-virtual-machine-cpu-performance" data-v-b883c74f>13.6.5. Enabling and disabling kernel same-page merging</a></li><!--]--><!--]--></ol></details></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#optimizing-virtual-machine-network-performance_optimizing-virtual-machine-performance-in-rhel" id="sub-link-to-monitoring_and_managing_system_status_and_performance-optimizing-virtual-machine-network-performance_optimizing-virtual-machine-performance-in-rhel" data-v-b883c74f>13.7. Optimizing virtual machine network performance</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#virtual-machine-performance-monitoring-tools_optimizing-virtual-machine-performance-in-rhel" id="sub-link-to-monitoring_and_managing_system_status_and_performance-virtual-machine-performance-monitoring-tools_optimizing-virtual-machine-performance-in-rhel" data-v-b883c74f>13.8. Virtual machine performance monitoring tools</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#related-information-optimizing-virtual-machine-performance-in-rhel" id="sub-link-to-monitoring_and_managing_system_status_and_performance-related-information-optimizing-virtual-machine-performance-in-rhel" data-v-b883c74f>13.9. Additional resources</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--importance-of-power-management_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="importance-of-power-management_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>14. Importance of power management</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#importance-of-power-management_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-importance-of-power-management_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Importance of power management</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#power-management-basics_importance-of-power-management" id="sub-link-to-monitoring_and_managing_system_status_and_performance-power-management-basics_importance-of-power-management" data-v-b883c74f>14.1. Power management basics</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#audit-and-analysis-overview_importance-of-power-management" id="sub-link-to-monitoring_and_managing_system_status_and_performance-audit-and-analysis-overview_importance-of-power-management" data-v-b883c74f>14.2. Audit and analysis overview</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#tools-for-auditing_importance-of-power-management" id="sub-link-to-monitoring_and_managing_system_status_and_performance-tools-for-auditing_importance-of-power-management" data-v-b883c74f>14.3. Tools for auditing</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--managing-power-consumption-with-powertop_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="managing-power-consumption-with-powertop_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>15. Managing power consumption with PowerTOP</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#managing-power-consumption-with-powertop_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-managing-power-consumption-with-powertop_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Managing power consumption with PowerTOP</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#the-purpose-of-powertop_managing-power-consumption-with-powertop" id="sub-link-to-monitoring_and_managing_system_status_and_performance-the-purpose-of-powertop_managing-power-consumption-with-powertop" data-v-b883c74f>15.1. The purpose of PowerTOP</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><details id="nested-toc--using-powertop_managing-power-consumption-with-powertop" data-v-b883c74f><summary class="heading sub-chapter-title" id="using-powertop_managing-power-consumption-with-powertop--summary" data-v-b883c74f>15.2. Using PowerTOP</summary><ol id="sub-nav--using-powertop_managing-power-consumption-with-powertop" class="sub-nav" data-v-b883c74f><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title chapter-landing-page" href="#using-powertop_managing-power-consumption-with-powertop" id="chapter-landing--monitoring_and_managing_system_status_and_performance-using-powertop_managing-power-consumption-with-powertop" data-v-b883c74f>Using PowerTOP</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#starting-powertop_using-powertop" id="sub-link-to-monitoring_and_managing_system_status_and_performance-starting-powertop_using-powertop" data-v-b883c74f>15.2.1. Starting PowerTOP</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#calibrating-powertop_using-powertop" id="sub-link-to-monitoring_and_managing_system_status_and_performance-calibrating-powertop_using-powertop" data-v-b883c74f>15.2.2. Calibrating PowerTOP</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#setting-the-measuring-interval_using-powertop" id="sub-link-to-monitoring_and_managing_system_status_and_performance-setting-the-measuring-interval_using-powertop" data-v-b883c74f>15.2.3. Setting the measuring interval</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#related-information-using-powertop" id="sub-link-to-monitoring_and_managing_system_status_and_performance-related-information-using-powertop" data-v-b883c74f>15.2.4. Additional resources</a></li><!--]--><!--]--></ol></details></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><details id="nested-toc--powertop-statistics_managing-power-consumption-with-powertop" data-v-b883c74f><summary class="heading sub-chapter-title" id="powertop-statistics_managing-power-consumption-with-powertop--summary" data-v-b883c74f>15.3. PowerTOP statistics</summary><ol id="sub-nav--powertop-statistics_managing-power-consumption-with-powertop" class="sub-nav" data-v-b883c74f><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title chapter-landing-page" href="#powertop-statistics_managing-power-consumption-with-powertop" id="chapter-landing--monitoring_and_managing_system_status_and_performance-powertop-statistics_managing-power-consumption-with-powertop" data-v-b883c74f>PowerTOP statistics</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#overview-tab_managing-power-consumption-with-powertop" id="sub-link-to-monitoring_and_managing_system_status_and_performance-overview-tab_managing-power-consumption-with-powertop" data-v-b883c74f>15.3.1. The Overview tab</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#idle-stats-tab_managing-power-consumption-with-powertop" id="sub-link-to-monitoring_and_managing_system_status_and_performance-idle-stats-tab_managing-power-consumption-with-powertop" data-v-b883c74f>15.3.2. The Idle stats tab</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#device-stats-tab_managing-power-consumption-with-powertop" id="sub-link-to-monitoring_and_managing_system_status_and_performance-device-stats-tab_managing-power-consumption-with-powertop" data-v-b883c74f>15.3.3. The Device stats tab</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#tunables-tab_managing-power-consumption-with-powertop" id="sub-link-to-monitoring_and_managing_system_status_and_performance-tunables-tab_managing-power-consumption-with-powertop" data-v-b883c74f>15.3.4. The Tunables tab</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#wakeup-tab_managing-power-consumption-with-powertop" id="sub-link-to-monitoring_and_managing_system_status_and_performance-wakeup-tab_managing-power-consumption-with-powertop" data-v-b883c74f>15.3.5. The WakeUp tab</a></li><!--]--><!--]--></ol></details></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#con_why-powertop-does-not-display-frequency-stats-values-in-some-instances_managing-power-consumption-with-powertop" id="sub-link-to-monitoring_and_managing_system_status_and_performance-con_why-powertop-does-not-display-frequency-stats-values-in-some-instances_managing-power-consumption-with-powertop" data-v-b883c74f>15.4. Why Powertop does not display Frequency stats values in some instances</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#generating-an-html-output_managing-power-consumption-with-powertop" id="sub-link-to-monitoring_and_managing_system_status_and_performance-generating-an-html-output_managing-power-consumption-with-powertop" data-v-b883c74f>15.5. Generating an HTML output</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><details id="nested-toc--optimizing-power-consumption_managing-power-consumption-with-powertop" data-v-b883c74f><summary class="heading sub-chapter-title" id="optimizing-power-consumption_managing-power-consumption-with-powertop--summary" data-v-b883c74f>15.6. Optimizing power consumption</summary><ol id="sub-nav--optimizing-power-consumption_managing-power-consumption-with-powertop" class="sub-nav" data-v-b883c74f><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title chapter-landing-page" href="#optimizing-power-consumption_managing-power-consumption-with-powertop" id="chapter-landing--monitoring_and_managing_system_status_and_performance-optimizing-power-consumption_managing-power-consumption-with-powertop" data-v-b883c74f>Optimizing power consumption</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#optimizing-power-consumption-using-the-powertop-service_optimizing-power-consumption" id="sub-link-to-monitoring_and_managing_system_status_and_performance-optimizing-power-consumption-using-the-powertop-service_optimizing-power-consumption" data-v-b883c74f>15.6.1. Optimizing power consumption using the powertop service</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#powertop2tuned-utility_optimizing-power-consumption" id="sub-link-to-monitoring_and_managing_system_status_and_performance-powertop2tuned-utility_optimizing-power-consumption" data-v-b883c74f>15.6.2. The powertop2tuned utility</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#optimizing-power-consumption-with-powertop2tuned_optimizing-power-consumption" id="sub-link-to-monitoring_and_managing_system_status_and_performance-optimizing-power-consumption-with-powertop2tuned_optimizing-power-consumption" data-v-b883c74f>15.6.3. Optimizing power consumption using the powertop2tuned utility</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#con_comparison-of-powertop-service-and-powertop2tuned_optimizing-power-consumption" id="sub-link-to-monitoring_and_managing_system_status_and_performance-con_comparison-of-powertop-service-and-powertop2tuned_optimizing-power-consumption" data-v-b883c74f>15.6.4. Comparison of powertop.service and powertop2tuned</a></li><!--]--><!--]--></ol></details></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--getting-started-with-perf_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="getting-started-with-perf_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>16. Getting started with perf</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#getting-started-with-perf_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-getting-started-with-perf_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Getting started with perf</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#introduction-to-perf_getting-started-with-perf" id="sub-link-to-monitoring_and_managing_system_status_and_performance-introduction-to-perf_getting-started-with-perf" data-v-b883c74f>16.1. Introduction to perf</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#installing-perf_getting-started-with-perf" id="sub-link-to-monitoring_and_managing_system_status_and_performance-installing-perf_getting-started-with-perf" data-v-b883c74f>16.2. Installing perf</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#common-perf-commands_getting-started-with-perf" id="sub-link-to-monitoring_and_managing_system_status_and_performance-common-perf-commands_getting-started-with-perf" data-v-b883c74f>16.3. Common perf commands</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--profiling-cpu-usage-in-real-time-with-top_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="profiling-cpu-usage-in-real-time-with-top_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>17. Profiling CPU usage in real time with perf top</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#profiling-cpu-usage-in-real-time-with-top_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-profiling-cpu-usage-in-real-time-with-top_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Profiling CPU usage in real time with perf top</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#the-purpose-of-perf-top_profiling-cpu-usage-in-real-time-with-top" id="sub-link-to-monitoring_and_managing_system_status_and_performance-the-purpose-of-perf-top_profiling-cpu-usage-in-real-time-with-top" data-v-b883c74f>17.1. The purpose of perf top</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#profiling-cpu-usage-with-perf-top_profiling-cpu-usage-in-real-time-with-top" id="sub-link-to-monitoring_and_managing_system_status_and_performance-profiling-cpu-usage-with-perf-top_profiling-cpu-usage-in-real-time-with-top" data-v-b883c74f>17.2. Profiling CPU usage with perf top</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#interpretation-of-perf-top-output_profiling-cpu-usage-in-real-time-with-top" id="sub-link-to-monitoring_and_managing_system_status_and_performance-interpretation-of-perf-top-output_profiling-cpu-usage-in-real-time-with-top" data-v-b883c74f>17.3. Interpretation of perf top output</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#why-perf-displays-some-function-names-as-raw-function-addresses_profiling-cpu-usage-in-real-time-with-top" id="sub-link-to-monitoring_and_managing_system_status_and_performance-why-perf-displays-some-function-names-as-raw-function-addresses_profiling-cpu-usage-in-real-time-with-top" data-v-b883c74f>17.4. Why perf displays some function names as raw function addresses</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#enabling-debug-and-source-repositories_profiling-cpu-usage-in-real-time-with-top" id="sub-link-to-monitoring_and_managing_system_status_and_performance-enabling-debug-and-source-repositories_profiling-cpu-usage-in-real-time-with-top" data-v-b883c74f>17.5. Enabling debug and source repositories</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#getting-debuginfo-packages-for-an-application-or-library-using-gdb_profiling-cpu-usage-in-real-time-with-top" id="sub-link-to-monitoring_and_managing_system_status_and_performance-getting-debuginfo-packages-for-an-application-or-library-using-gdb_profiling-cpu-usage-in-real-time-with-top" data-v-b883c74f>17.6. Getting debuginfo packages for an application or library using GDB</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--counting-events-during-process-execution-with-perf-stat_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="counting-events-during-process-execution-with-perf-stat_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>18. Counting events during process execution with perf stat</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#counting-events-during-process-execution-with-perf-stat_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-counting-events-during-process-execution-with-perf-stat_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Counting events during process execution with perf stat</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#the-purpose-of-perf-stat_counting-events-during-process-execution-with-perf-stat" id="sub-link-to-monitoring_and_managing_system_status_and_performance-the-purpose-of-perf-stat_counting-events-during-process-execution-with-perf-stat" data-v-b883c74f>18.1. The purpose of perf stat</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#counting-events-with-perf-stat_counting-events-during-process-execution-with-perf-stat" id="sub-link-to-monitoring_and_managing_system_status_and_performance-counting-events-with-perf-stat_counting-events-during-process-execution-with-perf-stat" data-v-b883c74f>18.2. Counting events with perf stat</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#interpretation-of-perf-stat-output_counting-events-during-process-execution-with-perf-stat" id="sub-link-to-monitoring_and_managing_system_status_and_performance-interpretation-of-perf-stat-output_counting-events-during-process-execution-with-perf-stat" data-v-b883c74f>18.3. Interpretation of perf stat output</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#attaching-perf-stat-to-a-running-process_counting-events-during-process-execution-with-perf-stat" id="sub-link-to-monitoring_and_managing_system_status_and_performance-attaching-perf-stat-to-a-running-process_counting-events-during-process-execution-with-perf-stat" data-v-b883c74f>18.4. Attaching perf stat to a running process</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--recording-and-analyzing-performance-profiles-with-perf_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="recording-and-analyzing-performance-profiles-with-perf_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>19. Recording and analyzing performance profiles with perf</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#recording-and-analyzing-performance-profiles-with-perf_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-recording-and-analyzing-performance-profiles-with-perf_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Recording and analyzing performance profiles with perf</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#the-purpose-of-perf-record_recording-and-analyzing-performance-profiles-with-perf" id="sub-link-to-monitoring_and_managing_system_status_and_performance-the-purpose-of-perf-record_recording-and-analyzing-performance-profiles-with-perf" data-v-b883c74f>19.1. The purpose of perf record</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#recording-a-performance-profile-without-root-access_recording-and-analyzing-performance-profiles-with-perf" id="sub-link-to-monitoring_and_managing_system_status_and_performance-recording-a-performance-profile-without-root-access_recording-and-analyzing-performance-profiles-with-perf" data-v-b883c74f>19.2. Recording a performance profile without root access</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#recording-a-performance-profile-with-root-access_recording-and-analyzing-performance-profiles-with-perf" id="sub-link-to-monitoring_and_managing_system_status_and_performance-recording-a-performance-profile-with-root-access_recording-and-analyzing-performance-profiles-with-perf" data-v-b883c74f>19.3. Recording a performance profile with root access</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#recording-a-performance-profile-in-per-cpu-mode_recording-and-analyzing-performance-profiles-with-perf" id="sub-link-to-monitoring_and_managing_system_status_and_performance-recording-a-performance-profile-in-per-cpu-mode_recording-and-analyzing-performance-profiles-with-perf" data-v-b883c74f>19.4. Recording a performance profile in per-CPU mode</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#capturing-call-graph-data-with-perf-record_recording-and-analyzing-performance-profiles-with-perf" id="sub-link-to-monitoring_and_managing_system_status_and_performance-capturing-call-graph-data-with-perf-record_recording-and-analyzing-performance-profiles-with-perf" data-v-b883c74f>19.5. Capturing call graph data with perf record</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#analyzing-perf-data-with-perf-report_recording-and-analyzing-performance-profiles-with-perf" id="sub-link-to-monitoring_and_managing_system_status_and_performance-analyzing-perf-data-with-perf-report_recording-and-analyzing-performance-profiles-with-perf" data-v-b883c74f>19.6. Analyzing perf.data with perf report</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#interpretation-of-perf-report-output_recording-and-analyzing-performance-profiles-with-perf" id="sub-link-to-monitoring_and_managing_system_status_and_performance-interpretation-of-perf-report-output_recording-and-analyzing-performance-profiles-with-perf" data-v-b883c74f>19.7. Interpretation of perf report output</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#generating-a-perf-data-file-that-is-readable-on-a-different-device_recording-and-analyzing-performance-profiles-with-perf" id="sub-link-to-monitoring_and_managing_system_status_and_performance-generating-a-perf-data-file-that-is-readable-on-a-different-device_recording-and-analyzing-performance-profiles-with-perf" data-v-b883c74f>19.8. Generating a perf.data file that is readable on a different device</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#analyzing-a-perf-data-file-that-was-created-on-a-different-device_recording-and-analyzing-performance-profiles-with-perf" id="sub-link-to-monitoring_and_managing_system_status_and_performance-analyzing-a-perf-data-file-that-was-created-on-a-different-device_recording-and-analyzing-performance-profiles-with-perf" data-v-b883c74f>19.9. Analyzing a perf.data file that was created on a different device</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#why-perf-displays-some-function-names-as-raw-function-addresses_recording-and-analyzing-performance-profiles-with-perf" id="sub-link-to-monitoring_and_managing_system_status_and_performance-why-perf-displays-some-function-names-as-raw-function-addresses_recording-and-analyzing-performance-profiles-with-perf" data-v-b883c74f>19.10. Why perf displays some function names as raw function addresses</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#enabling-debug-and-source-repositories_recording-and-analyzing-performance-profiles-with-perf" id="sub-link-to-monitoring_and_managing_system_status_and_performance-enabling-debug-and-source-repositories_recording-and-analyzing-performance-profiles-with-perf" data-v-b883c74f>19.11. Enabling debug and source repositories</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#getting-debuginfo-packages-for-an-application-or-library-using-gdb_recording-and-analyzing-performance-profiles-with-perf" id="sub-link-to-monitoring_and_managing_system_status_and_performance-getting-debuginfo-packages-for-an-application-or-library-using-gdb_recording-and-analyzing-performance-profiles-with-perf" data-v-b883c74f>19.12. Getting debuginfo packages for an application or library using GDB</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--investigating-busy-cpus-with-perf_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="investigating-busy-cpus-with-perf_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>20. Investigating busy CPUs with perf</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#investigating-busy-cpus-with-perf_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-investigating-busy-cpus-with-perf_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Investigating busy CPUs with perf</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#displaying-which-cpu-events-were-counted-on-with-perf-stat_investigating-busy-cpus-with-perf" id="sub-link-to-monitoring_and_managing_system_status_and_performance-displaying-which-cpu-events-were-counted-on-with-perf-stat_investigating-busy-cpus-with-perf" data-v-b883c74f>20.1. Displaying which CPU events were counted on with perf stat</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#displaying-which-cpu-samples-were-taken-on-with-perf-report_investigating-busy-cpus-with-perf" id="sub-link-to-monitoring_and_managing_system_status_and_performance-displaying-which-cpu-samples-were-taken-on-with-perf-report_investigating-busy-cpus-with-perf" data-v-b883c74f>20.2. Displaying which CPU samples were taken on with perf report</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#displaying-specific-cpus-during-profiling-with-perf-top_investigating-busy-cpus-with-perf" id="sub-link-to-monitoring_and_managing_system_status_and_performance-displaying-specific-cpus-during-profiling-with-perf-top_investigating-busy-cpus-with-perf" data-v-b883c74f>20.3. Displaying specific CPUs during profiling with perf top</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#monitoring-specific-cpus-with-perf-record-and-perf-report_investigating-busy-cpus-with-perf" id="sub-link-to-monitoring_and_managing_system_status_and_performance-monitoring-specific-cpus-with-perf-record-and-perf-report_investigating-busy-cpus-with-perf" data-v-b883c74f>20.4. Monitoring specific CPUs with perf record and perf report</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--monitoring-application-performance-with-perf_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="monitoring-application-performance-with-perf_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>21. Monitoring application performance with perf</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#monitoring-application-performance-with-perf_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-monitoring-application-performance-with-perf_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Monitoring application performance with perf</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#attaching-perf-record-to-a-running-process_monitoring-application-performance-with-perf" id="sub-link-to-monitoring_and_managing_system_status_and_performance-attaching-perf-record-to-a-running-process_monitoring-application-performance-with-perf" data-v-b883c74f>21.1. Attaching perf record to a running process</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#capturing-call-graph-data-with-perf-record_monitoring-application-performance-with-perf" id="sub-link-to-monitoring_and_managing_system_status_and_performance-capturing-call-graph-data-with-perf-record_monitoring-application-performance-with-perf" data-v-b883c74f>21.2. Capturing call graph data with perf record</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#analyzing-perf-data-with-perf-report_monitoring-application-performance-with-perf" id="sub-link-to-monitoring_and_managing_system_status_and_performance-analyzing-perf-data-with-perf-report_monitoring-application-performance-with-perf" data-v-b883c74f>21.3. Analyzing perf.data with perf report</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--creating-uprobes-with-perf_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="creating-uprobes-with-perf_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>22. Creating uprobes with perf</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#creating-uprobes-with-perf_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-creating-uprobes-with-perf_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Creating uprobes with perf</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_creating-uprobes-at-the-fucntion-level-with-perf_assembly_creating-uprobes-with-perf" id="sub-link-to-monitoring_and_managing_system_status_and_performance-proc_creating-uprobes-at-the-fucntion-level-with-perf_assembly_creating-uprobes-with-perf" data-v-b883c74f>22.1. Creating uprobes at the function level with perf</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_creating-uprobes-on-lines-within-a-function-with-perf_assembly_creating-uprobes-with-perf" id="sub-link-to-monitoring_and_managing_system_status_and_performance-proc_creating-uprobes-on-lines-within-a-function-with-perf_assembly_creating-uprobes-with-perf" data-v-b883c74f>22.2. Creating uprobes on lines within a function with perf</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#ref_perf-script-output-of-a-perf-data-file-generated-over-uprobes_assembly_creating-uprobes-with-perf" id="sub-link-to-monitoring_and_managing_system_status_and_performance-ref_perf-script-output-of-a-perf-data-file-generated-over-uprobes_assembly_creating-uprobes-with-perf" data-v-b883c74f>22.3. Perf script output of data recorded over uprobes</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--profiling-memory-accesses-with-perf-mem_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="profiling-memory-accesses-with-perf-mem_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>23. Profiling memory accesses with perf mem</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#profiling-memory-accesses-with-perf-mem_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-profiling-memory-accesses-with-perf-mem_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Profiling memory accesses with perf mem</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#the-purpose-of-perf-mem_profiling-memory-accesses-with-perf-mem" id="sub-link-to-monitoring_and_managing_system_status_and_performance-the-purpose-of-perf-mem_profiling-memory-accesses-with-perf-mem" data-v-b883c74f>23.1. The purpose of perf mem</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#sampling-memory-access-with-perf-mem_profiling-memory-accesses-with-perf-mem" id="sub-link-to-monitoring_and_managing_system_status_and_performance-sampling-memory-access-with-perf-mem_profiling-memory-accesses-with-perf-mem" data-v-b883c74f>23.2. Sampling memory access with perf mem</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#interpretation-of-perf-mem-report-output_profiling-memory-accesses-with-perf-mem" id="sub-link-to-monitoring_and_managing_system_status_and_performance-interpretation-of-perf-mem-report-output_profiling-memory-accesses-with-perf-mem" data-v-b883c74f>23.3. Interpretation of perf mem report output</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--detecting-false-sharing_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="detecting-false-sharing_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>24. Detecting false sharing</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#detecting-false-sharing_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-detecting-false-sharing_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Detecting false sharing</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#the-purpose-of-perf-c2c_detecting-false-sharing" id="sub-link-to-monitoring_and_managing_system_status_and_performance-the-purpose-of-perf-c2c_detecting-false-sharing" data-v-b883c74f>24.1. The purpose of perf c2c</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#detecting-cache-line-contention-with-perf-c2c_detecting-false-sharing" id="sub-link-to-monitoring_and_managing_system_status_and_performance-detecting-cache-line-contention-with-perf-c2c_detecting-false-sharing" data-v-b883c74f>24.2. Detecting cache-line contention with perf c2c</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#visualizing-a-perf-data-file-recorded-with-perf-c2c-record_detecting-false-sharing" id="sub-link-to-monitoring_and_managing_system_status_and_performance-visualizing-a-perf-data-file-recorded-with-perf-c2c-record_detecting-false-sharing" data-v-b883c74f>24.3. Visualizing a perf.data file recorded with perf c2c record</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#interpretation-of-perf-c2c-report-output_detecting-false-sharing" id="sub-link-to-monitoring_and_managing_system_status_and_performance-interpretation-of-perf-c2c-report-output_detecting-false-sharing" data-v-b883c74f>24.4. Interpretation of perf c2c report output</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#detecting-false-sharing-with-perf-c2c_detecting-false-sharing" id="sub-link-to-monitoring_and_managing_system_status_and_performance-detecting-false-sharing-with-perf-c2c_detecting-false-sharing" data-v-b883c74f>24.5. Detecting false sharing with perf c2c</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--getting-started-with-flamegraphs_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="getting-started-with-flamegraphs_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>25. Getting started with flamegraphs</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#getting-started-with-flamegraphs_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-getting-started-with-flamegraphs_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Getting started with flamegraphs</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#installing-flamegraphs_getting-started-with-flamegraphs" id="sub-link-to-monitoring_and_managing_system_status_and_performance-installing-flamegraphs_getting-started-with-flamegraphs" data-v-b883c74f>25.1. Installing flamegraphs</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#creating-flamegraphs-over-the-entire-system_getting-started-with-flamegraphs" id="sub-link-to-monitoring_and_managing_system_status_and_performance-creating-flamegraphs-over-the-entire-system_getting-started-with-flamegraphs" data-v-b883c74f>25.2. Creating flamegraphs over the entire system</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#creating-flamegraphs-over-specific-processes_getting-started-with-flamegraphs" id="sub-link-to-monitoring_and_managing_system_status_and_performance-creating-flamegraphs-over-specific-processes_getting-started-with-flamegraphs" data-v-b883c74f>25.3. Creating flamegraphs over specific processes</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#interpreting-flamegraphs_getting-started-with-flamegraphs" id="sub-link-to-monitoring_and_managing_system_status_and_performance-interpreting-flamegraphs_getting-started-with-flamegraphs" data-v-b883c74f>25.4. Interpreting flamegraphs</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--creating-custom-circular-buffers-to-collect-specific-data-with-perf_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="creating-custom-circular-buffers-to-collect-specific-data-with-perf_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>26. Monitoring processes for performance bottlenecks using perf circular buffers</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#creating-custom-circular-buffers-to-collect-specific-data-with-perf_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-creating-custom-circular-buffers-to-collect-specific-data-with-perf_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Monitoring processes for performance bottlenecks using perf circular buffers</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#circular-buffers-and-event-specific-snapshots_assembly_creating-custom-circular-buffers-to-collect-specific-data-with-perf" id="sub-link-to-monitoring_and_managing_system_status_and_performance-circular-buffers-and-event-specific-snapshots_assembly_creating-custom-circular-buffers-to-collect-specific-data-with-perf" data-v-b883c74f>26.1. Circular buffers and event-specific snapshots with perf</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#using-perf-to-create-custom-circular-buffers-that-perform-event-specific-snapshots_assembly_creating-custom-circular-buffers-to-collect-specific-data-with-perf" id="sub-link-to-monitoring_and_managing_system_status_and_performance-using-perf-to-create-custom-circular-buffers-that-perform-event-specific-snapshots_assembly_creating-custom-circular-buffers-to-collect-specific-data-with-perf" data-v-b883c74f>26.2. Collecting specific data to monitor for performance bottlenecks using perf circular buffers</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--turning-tracepoints-on-and-off-without-stopping-or-restarting-perf_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="turning-tracepoints-on-and-off-without-stopping-or-restarting-perf_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>27. Adding and removing tracepoints from a running perf collector without stopping or restarting perf</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#turning-tracepoints-on-and-off-without-stopping-or-restarting-perf_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-turning-tracepoints-on-and-off-without-stopping-or-restarting-perf_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Adding and removing tracepoints from a running perf collector without stopping or restarting perf</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#adding-tracepoints-to-a-running-perf-collector-without-stopping-or-restarting-perf_turning-tracepoints-on-and-off-without-stopping-or-restarting-perf" id="sub-link-to-monitoring_and_managing_system_status_and_performance-adding-tracepoints-to-a-running-perf-collector-without-stopping-or-restarting-perf_turning-tracepoints-on-and-off-without-stopping-or-restarting-perf" data-v-b883c74f>27.1. Adding tracepoints to a running perf collector without stopping or restarting perf</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#removing-tracepoints-from-a-running-perf-collector-without-stopping-or-restarting-perf_turning-tracepoints-on-and-off-without-stopping-or-restarting-perf" id="sub-link-to-monitoring_and_managing_system_status_and_performance-removing-tracepoints-from-a-running-perf-collector-without-stopping-or-restarting-perf_turning-tracepoints-on-and-off-without-stopping-or-restarting-perf" data-v-b883c74f>27.2. Removing tracepoints from a running perf collector without stopping or restarting perf</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--profiling-memory-allocation-with-numastat_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="profiling-memory-allocation-with-numastat_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>28. Profiling memory allocation with numastat</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#profiling-memory-allocation-with-numastat_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-profiling-memory-allocation-with-numastat_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Profiling memory allocation with numastat</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#default-numastat-statistics_profiling-memory-allocation-with-numastat" id="sub-link-to-monitoring_and_managing_system_status_and_performance-default-numastat-statistics_profiling-memory-allocation-with-numastat" data-v-b883c74f>28.1. Default numastat statistics</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#viewing-memory-allocation-with-numastat_profiling-memory-allocation-with-numastat" id="sub-link-to-monitoring_and_managing_system_status_and_performance-viewing-memory-allocation-with-numastat_profiling-memory-allocation-with-numastat" data-v-b883c74f>28.2. Viewing memory allocation with numastat</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--configuring-an-operating-system-to-optimize-cpu-utilization_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="configuring-an-operating-system-to-optimize-cpu-utilization_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>29. Configuring an operating system to optimize CPU utilization</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#configuring-an-operating-system-to-optimize-cpu-utilization_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-configuring-an-operating-system-to-optimize-cpu-utilization_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Configuring an operating system to optimize CPU utilization</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#tools-for-monitoring-and-diagnosing-processor-issues_configuring-an-operating-system-to-optimize-cpu-utilization" id="sub-link-to-monitoring_and_managing_system_status_and_performance-tools-for-monitoring-and-diagnosing-processor-issues_configuring-an-operating-system-to-optimize-cpu-utilization" data-v-b883c74f>29.1. Tools for monitoring and diagnosing processor issues</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><details id="nested-toc--types-of-system-topology_configuring-an-operating-system-to-optimize-cpu-utilization" data-v-b883c74f><summary class="heading sub-chapter-title" id="types-of-system-topology_configuring-an-operating-system-to-optimize-cpu-utilization--summary" data-v-b883c74f>29.2. Types of system topology</summary><ol id="sub-nav--types-of-system-topology_configuring-an-operating-system-to-optimize-cpu-utilization" class="sub-nav" data-v-b883c74f><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title chapter-landing-page" href="#types-of-system-topology_configuring-an-operating-system-to-optimize-cpu-utilization" id="chapter-landing--monitoring_and_managing_system_status_and_performance-types-of-system-topology_configuring-an-operating-system-to-optimize-cpu-utilization" data-v-b883c74f>Types of system topology</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#displaying-system-topologies_configuring-an-operating-system-to-optimize-cpu-utilization" id="sub-link-to-monitoring_and_managing_system_status_and_performance-displaying-system-topologies_configuring-an-operating-system-to-optimize-cpu-utilization" data-v-b883c74f>29.2.1. Displaying system topologies</a></li><!--]--><!--]--></ol></details></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#configuring-kernel-tick-time_configuring-an-operating-system-to-optimize-cpu-utilization" id="sub-link-to-monitoring_and_managing_system_status_and_performance-configuring-kernel-tick-time_configuring-an-operating-system-to-optimize-cpu-utilization" data-v-b883c74f>29.3. Configuring kernel tick time</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><details id="nested-toc--overview-of-an-interrupt-request_configuring-an-operating-system-to-optimize-cpu-utilization" data-v-b883c74f><summary class="heading sub-chapter-title" id="overview-of-an-interrupt-request_configuring-an-operating-system-to-optimize-cpu-utilization--summary" data-v-b883c74f>29.4. Overview of an interrupt request</summary><ol id="sub-nav--overview-of-an-interrupt-request_configuring-an-operating-system-to-optimize-cpu-utilization" class="sub-nav" data-v-b883c74f><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title chapter-landing-page" href="#overview-of-an-interrupt-request_configuring-an-operating-system-to-optimize-cpu-utilization" id="chapter-landing--monitoring_and_managing_system_status_and_performance-overview-of-an-interrupt-request_configuring-an-operating-system-to-optimize-cpu-utilization" data-v-b883c74f>Overview of an interrupt request</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#balancing-interrupts-manually_configuring-an-operating-system-to-optimize-cpu-utilization" id="sub-link-to-monitoring_and_managing_system_status_and_performance-balancing-interrupts-manually_configuring-an-operating-system-to-optimize-cpu-utilization" data-v-b883c74f>29.4.1. Balancing interrupts manually</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#setting-the-smp_affinity-mask_configuring-an-operating-system-to-optimize-cpu-utilization" id="sub-link-to-monitoring_and_managing_system_status_and_performance-setting-the-smp_affinity-mask_configuring-an-operating-system-to-optimize-cpu-utilization" data-v-b883c74f>29.4.2. Setting the smp_affinity mask</a></li><!--]--><!--]--></ol></details></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--tuning-scheduling-policy_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="tuning-scheduling-policy_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>30. Tuning scheduling policy</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#tuning-scheduling-policy_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-tuning-scheduling-policy_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Tuning scheduling policy</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#con_categories-of-scheduling-policies_tuning-scheduling-policy" id="sub-link-to-monitoring_and_managing_system_status_and_performance-con_categories-of-scheduling-policies_tuning-scheduling-policy" data-v-b883c74f>30.1. Categories of scheduling policies</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#static-priority-scheduling-with-SCHED_FIFO_tuning-scheduling-policy" id="sub-link-to-monitoring_and_managing_system_status_and_performance-static-priority-scheduling-with-SCHED_FIFO_tuning-scheduling-policy" data-v-b883c74f>30.2. Static priority scheduling with SCHED_FIFO</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#round-robin-priority-scheduling-with-sched_rr_tuning-scheduling-policy" id="sub-link-to-monitoring_and_managing_system_status_and_performance-round-robin-priority-scheduling-with-sched_rr_tuning-scheduling-policy" data-v-b883c74f>30.3. Round robin priority scheduling with SCHED_RR</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#normal-scheduling-with-sched_other_tuning-scheduling-policy" id="sub-link-to-monitoring_and_managing_system_status_and_performance-normal-scheduling-with-sched_other_tuning-scheduling-policy" data-v-b883c74f>30.4. Normal scheduling with SCHED_OTHER</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#setting-scheduler-policies_tuning-scheduling-policy" id="sub-link-to-monitoring_and_managing_system_status_and_performance-setting-scheduler-policies_tuning-scheduling-policy" data-v-b883c74f>30.5. Setting scheduler policies</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#policy-options-for-the-chrt-command_tuning-scheduling-policy" id="sub-link-to-monitoring_and_managing_system_status_and_performance-policy-options-for-the-chrt-command_tuning-scheduling-policy" data-v-b883c74f>30.6. Policy options for the chrt command</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#changing-the-priority-of-service-during-the-boot-process_tuning-scheduling-policy" id="sub-link-to-monitoring_and_managing_system_status_and_performance-changing-the-priority-of-service-during-the-boot-process_tuning-scheduling-policy" data-v-b883c74f>30.7. Changing the priority of services during the boot process</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#priority-map_tuning-scheduling-policy" id="sub-link-to-monitoring_and_managing_system_status_and_performance-priority-map_tuning-scheduling-policy" data-v-b883c74f>30.8. Priority map</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#tuned-cpu-partitioning-profile_tuning-scheduling-policy" id="sub-link-to-monitoring_and_managing_system_status_and_performance-tuned-cpu-partitioning-profile_tuning-scheduling-policy" data-v-b883c74f>30.9. TuneD cpu-partitioning profile</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#using-the-tuned-cpu-partitioning-profile-for-low-latency-tuning_tuning-scheduling-policy" id="sub-link-to-monitoring_and_managing_system_status_and_performance-using-the-tuned-cpu-partitioning-profile-for-low-latency-tuning_tuning-scheduling-policy" data-v-b883c74f>30.10. Using the TuneD cpu-partitioning profile for low-latency tuning</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#customizing-the-cpu-partitioning-tuned-profile_tuning-scheduling-policy" id="sub-link-to-monitoring_and_managing_system_status_and_performance-customizing-the-cpu-partitioning-tuned-profile_tuning-scheduling-policy" data-v-b883c74f>30.11. Customizing the cpu-partitioning TuneD profile</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--tuning-the-network-performance_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="tuning-the-network-performance_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>31. Tuning the network performance</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#tuning-the-network-performance_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-tuning-the-network-performance_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Tuning the network performance</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><details id="nested-toc--tuning-network-adapter-settings_tuning-the-network-performance" data-v-b883c74f><summary class="heading sub-chapter-title" id="tuning-network-adapter-settings_tuning-the-network-performance--summary" data-v-b883c74f>31.1. Tuning network adapter settings</summary><ol id="sub-nav--tuning-network-adapter-settings_tuning-the-network-performance" class="sub-nav" data-v-b883c74f><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title chapter-landing-page" href="#tuning-network-adapter-settings_tuning-the-network-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-tuning-network-adapter-settings_tuning-the-network-performance" data-v-b883c74f>Tuning network adapter settings</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#increasing-the-ring-buffers-to-reduce-a-high-packet-drop-rate_tuning-network-adapter-settings" id="sub-link-to-monitoring_and_managing_system_status_and_performance-increasing-the-ring-buffers-to-reduce-a-high-packet-drop-rate_tuning-network-adapter-settings" data-v-b883c74f>31.1.1. Increasing the ring buffer size to reduce a high packet drop rate by using nmcli</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#tuning-the-network-device-backlog-queue-to-avoid-packet-drops_tuning-network-adapter-settings" id="sub-link-to-monitoring_and_managing_system_status_and_performance-tuning-the-network-device-backlog-queue-to-avoid-packet-drops_tuning-network-adapter-settings" data-v-b883c74f>31.1.2. Tuning the network device backlog queue to avoid packet drops</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#increasing-the-transmit-queue-length-of-a-nic-to-reduce-the-number-of-transmit-errors_tuning-network-adapter-settings" id="sub-link-to-monitoring_and_managing_system_status_and_performance-increasing-the-transmit-queue-length-of-a-nic-to-reduce-the-number-of-transmit-errors_tuning-network-adapter-settings" data-v-b883c74f>31.1.3. Increasing the transmit queue length of a NIC to reduce the number of transmit errors</a></li><!--]--><!--]--></ol></details></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><details id="nested-toc--tuning-irq-balancing_tuning-the-network-performance" data-v-b883c74f><summary class="heading sub-chapter-title" id="tuning-irq-balancing_tuning-the-network-performance--summary" data-v-b883c74f>31.2. Tuning IRQ balancing</summary><ol id="sub-nav--tuning-irq-balancing_tuning-the-network-performance" class="sub-nav" data-v-b883c74f><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title chapter-landing-page" href="#tuning-irq-balancing_tuning-the-network-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-tuning-irq-balancing_tuning-the-network-performance" data-v-b883c74f>Tuning IRQ balancing</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#interrupts-and-interrupt-handlers_tuning-irq-balancing" id="sub-link-to-monitoring_and_managing_system_status_and_performance-interrupts-and-interrupt-handlers_tuning-irq-balancing" data-v-b883c74f>31.2.1. Interrupts and interrupt handlers</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#software-interrupt-requests_tuning-irq-balancing" id="sub-link-to-monitoring_and_managing_system_status_and_performance-software-interrupt-requests_tuning-irq-balancing" data-v-b883c74f>31.2.2. Software interrupt requests</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#napi-polling_tuning-irq-balancing" id="sub-link-to-monitoring_and_managing_system_status_and_performance-napi-polling_tuning-irq-balancing" data-v-b883c74f>31.2.3. NAPI Polling</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#the-irqbalance-service_tuning-irq-balancing" id="sub-link-to-monitoring_and_managing_system_status_and_performance-the-irqbalance-service_tuning-irq-balancing" data-v-b883c74f>31.2.4. The irqbalance service</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#increasing-the-time-softirqs-can-run-on-the-cpu_tuning-irq-balancing" id="sub-link-to-monitoring_and_managing_system_status_and_performance-increasing-the-time-softirqs-can-run-on-the-cpu_tuning-irq-balancing" data-v-b883c74f>31.2.5. Increasing the time SoftIRQs can run on the CPU</a></li><!--]--><!--]--></ol></details></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><details id="nested-toc--improving-the-network-latency_tuning-the-network-performance" data-v-b883c74f><summary class="heading sub-chapter-title" id="improving-the-network-latency_tuning-the-network-performance--summary" data-v-b883c74f>31.3. Improving the network latency</summary><ol id="sub-nav--improving-the-network-latency_tuning-the-network-performance" class="sub-nav" data-v-b883c74f><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title chapter-landing-page" href="#improving-the-network-latency_tuning-the-network-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-improving-the-network-latency_tuning-the-network-performance" data-v-b883c74f>Improving the network latency</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#how-the-cpu-power-states-influence-the-network-latency_improving-the-network-latency" id="sub-link-to-monitoring_and_managing_system_status_and_performance-how-the-cpu-power-states-influence-the-network-latency_improving-the-network-latency" data-v-b883c74f>31.3.1. How the CPU power states influence the network latency</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#c-state-settings-in-the-efi-firmware_improving-the-network-latency" id="sub-link-to-monitoring_and_managing_system_status_and_performance-c-state-settings-in-the-efi-firmware_improving-the-network-latency" data-v-b883c74f>31.3.2. C-state settings in the EFI firmware</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#disabling-c-states-by-using-a-custom-tuned-profile_improving-the-network-latency" id="sub-link-to-monitoring_and_managing_system_status_and_performance-disabling-c-states-by-using-a-custom-tuned-profile_improving-the-network-latency" data-v-b883c74f>31.3.3. Disabling C-states by using a custom TuneD profile</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#disabling-c-states-by-using-a-kernel-command-line-option_improving-the-network-latency" id="sub-link-to-monitoring_and_managing_system_status_and_performance-disabling-c-states-by-using-a-kernel-command-line-option_improving-the-network-latency" data-v-b883c74f>31.3.4. Disabling C-states by using a kernel command line option</a></li><!--]--><!--]--></ol></details></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><details id="nested-toc--improving-the-throughput-of-large-amounts-of-contiguous-data-streams_tuning-the-network-performance" data-v-b883c74f><summary class="heading sub-chapter-title" id="improving-the-throughput-of-large-amounts-of-contiguous-data-streams_tuning-the-network-performance--summary" data-v-b883c74f>31.4. Improving the throughput of large amounts of contiguous data streams</summary><ol id="sub-nav--improving-the-throughput-of-large-amounts-of-contiguous-data-streams_tuning-the-network-performance" class="sub-nav" data-v-b883c74f><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title chapter-landing-page" href="#improving-the-throughput-of-large-amounts-of-contiguous-data-streams_tuning-the-network-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-improving-the-throughput-of-large-amounts-of-contiguous-data-streams_tuning-the-network-performance" data-v-b883c74f>Improving the throughput of large amounts of contiguous data streams</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#considerations-before-configuring-jumbo-frames_improving-the-throughput-of-large-amounts-of-contiguous-data-streams" id="sub-link-to-monitoring_and_managing_system_status_and_performance-considerations-before-configuring-jumbo-frames_improving-the-throughput-of-large-amounts-of-contiguous-data-streams" data-v-b883c74f>31.4.1. Considerations before configuring jumbo frames</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#configuring-the-mtu-in-an-existing-networkmanager-connection-profile_improving-the-throughput-of-large-amounts-of-contiguous-data-streams" id="sub-link-to-monitoring_and_managing_system_status_and_performance-configuring-the-mtu-in-an-existing-networkmanager-connection-profile_improving-the-throughput-of-large-amounts-of-contiguous-data-streams" data-v-b883c74f>31.4.2. Configuring the MTU in an existing NetworkManager connection profile</a></li><!--]--><!--]--></ol></details></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><details id="nested-toc--tuning-tcp-connections-for-high-throughput_tuning-the-network-performance" data-v-b883c74f><summary class="heading sub-chapter-title" id="tuning-tcp-connections-for-high-throughput_tuning-the-network-performance--summary" data-v-b883c74f>31.5. Tuning TCP connections for high throughput</summary><ol id="sub-nav--tuning-tcp-connections-for-high-throughput_tuning-the-network-performance" class="sub-nav" data-v-b883c74f><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title chapter-landing-page" href="#tuning-tcp-connections-for-high-throughput_tuning-the-network-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-tuning-tcp-connections-for-high-throughput_tuning-the-network-performance" data-v-b883c74f>Tuning TCP connections for high throughput</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#testing-the-tcp-throughput-using-iperf3_tuning-tcp-connections-for-high-throughput" id="sub-link-to-monitoring_and_managing_system_status_and_performance-testing-the-tcp-throughput-using-iperf3_tuning-tcp-connections-for-high-throughput" data-v-b883c74f>31.5.1. Testing the TCP throughput using iperf3</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#the-system-wide-tcp-socket-buffer-settings_tuning-tcp-connections-for-high-throughput" id="sub-link-to-monitoring_and_managing_system_status_and_performance-the-system-wide-tcp-socket-buffer-settings_tuning-tcp-connections-for-high-throughput" data-v-b883c74f>31.5.2. The system-wide TCP socket buffer settings</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#increasing-the-system-wide-tcp-socket-buffers_tuning-tcp-connections-for-high-throughput" id="sub-link-to-monitoring_and_managing_system_status_and_performance-increasing-the-system-wide-tcp-socket-buffers_tuning-tcp-connections-for-high-throughput" data-v-b883c74f>31.5.3. Increasing the system-wide TCP socket buffers</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#tcp-window-scaling_tuning-tcp-connections-for-high-throughput" id="sub-link-to-monitoring_and_managing_system_status_and_performance-tcp-window-scaling_tuning-tcp-connections-for-high-throughput" data-v-b883c74f>31.5.4. TCP Window Scaling</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#how-tcp-sack-reduces-the-packet-drop-rate_tuning-tcp-connections-for-high-throughput" id="sub-link-to-monitoring_and_managing_system_status_and_performance-how-tcp-sack-reduces-the-packet-drop-rate_tuning-tcp-connections-for-high-throughput" data-v-b883c74f>31.5.5. How TCP SACK reduces the packet drop rate</a></li><!--]--><!--]--></ol></details></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><details id="nested-toc--tuning-udp-connections_tuning-the-network-performance" data-v-b883c74f><summary class="heading sub-chapter-title" id="tuning-udp-connections_tuning-the-network-performance--summary" data-v-b883c74f>31.6. Tuning UDP connections</summary><ol id="sub-nav--tuning-udp-connections_tuning-the-network-performance" class="sub-nav" data-v-b883c74f><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title chapter-landing-page" href="#tuning-udp-connections_tuning-the-network-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-tuning-udp-connections_tuning-the-network-performance" data-v-b883c74f>Tuning UDP connections</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#detecting-packet-drops_tuning-udp-connections" id="sub-link-to-monitoring_and_managing_system_status_and_performance-detecting-packet-drops_tuning-udp-connections" data-v-b883c74f>31.6.1. Detecting packet drops</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#testing-the-udp-throughput-using-iperf3_tuning-udp-connections" id="sub-link-to-monitoring_and_managing_system_status_and_performance-testing-the-udp-throughput-using-iperf3_tuning-udp-connections" data-v-b883c74f>31.6.2. Testing the UDP throughput using iperf3</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#impact-of-the-mtu-size-on-udp-traffic-throughput_tuning-udp-connections" id="sub-link-to-monitoring_and_managing_system_status_and_performance-impact-of-the-mtu-size-on-udp-traffic-throughput_tuning-udp-connections" data-v-b883c74f>31.6.3. Impact of the MTU size on UDP traffic throughput</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#impact-of-the-cpu-speed-on-udp-traffic-throughput_tuning-udp-connections" id="sub-link-to-monitoring_and_managing_system_status_and_performance-impact-of-the-cpu-speed-on-udp-traffic-throughput_tuning-udp-connections" data-v-b883c74f>31.6.4. Impact of the CPU speed on UDP traffic throughput</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#increasing-the-system-wide-udp-socket-buffers_tuning-udp-connections" id="sub-link-to-monitoring_and_managing_system_status_and_performance-increasing-the-system-wide-udp-socket-buffers_tuning-udp-connections" data-v-b883c74f>31.6.5. Increasing the system-wide UDP socket buffers</a></li><!--]--><!--]--></ol></details></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><details id="nested-toc--identifying-application-read-socket-buffer-bottlenecks_tuning-the-network-performance" data-v-b883c74f><summary class="heading sub-chapter-title" id="identifying-application-read-socket-buffer-bottlenecks_tuning-the-network-performance--summary" data-v-b883c74f>31.7. Identifying application read socket buffer bottlenecks</summary><ol id="sub-nav--identifying-application-read-socket-buffer-bottlenecks_tuning-the-network-performance" class="sub-nav" data-v-b883c74f><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title chapter-landing-page" href="#identifying-application-read-socket-buffer-bottlenecks_tuning-the-network-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-identifying-application-read-socket-buffer-bottlenecks_tuning-the-network-performance" data-v-b883c74f>Identifying application read socket buffer bottlenecks</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#identifying-receive-buffer-collapsing-and-pruning_identifying-application-read-socket-buffer-bottlenecks" id="sub-link-to-monitoring_and_managing_system_status_and_performance-identifying-receive-buffer-collapsing-and-pruning_identifying-application-read-socket-buffer-bottlenecks" data-v-b883c74f>31.7.1. Identifying receive buffer collapsing and pruning</a></li><!--]--><!--]--></ol></details></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><details id="nested-toc--tuning-applications-with-a-large-number-of-incoming-requests_tuning-the-network-performance" data-v-b883c74f><summary class="heading sub-chapter-title" id="tuning-applications-with-a-large-number-of-incoming-requests_tuning-the-network-performance--summary" data-v-b883c74f>31.8. Tuning applications with a large number of incoming requests</summary><ol id="sub-nav--tuning-applications-with-a-large-number-of-incoming-requests_tuning-the-network-performance" class="sub-nav" data-v-b883c74f><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title chapter-landing-page" href="#tuning-applications-with-a-large-number-of-incoming-requests_tuning-the-network-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-tuning-applications-with-a-large-number-of-incoming-requests_tuning-the-network-performance" data-v-b883c74f>Tuning applications with a large number of incoming requests</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#tuning-the-tcp-listen-backlog-to-process-a-high-number-of-tcp-connection-attempts_tuning-applications-with-a-large-number-of-incoming-requests" id="sub-link-to-monitoring_and_managing_system_status_and_performance-tuning-the-tcp-listen-backlog-to-process-a-high-number-of-tcp-connection-attempts_tuning-applications-with-a-large-number-of-incoming-requests" data-v-b883c74f>31.8.1. Tuning the TCP listen backlog to process a high number of TCP connection attempts</a></li><!--]--><!--]--></ol></details></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><details id="nested-toc--avoiding-listen-queue-lock-contention_tuning-the-network-performance" data-v-b883c74f><summary class="heading sub-chapter-title" id="avoiding-listen-queue-lock-contention_tuning-the-network-performance--summary" data-v-b883c74f>31.9. Avoiding listen queue lock contention</summary><ol id="sub-nav--avoiding-listen-queue-lock-contention_tuning-the-network-performance" class="sub-nav" data-v-b883c74f><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title chapter-landing-page" href="#avoiding-listen-queue-lock-contention_tuning-the-network-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-avoiding-listen-queue-lock-contention_tuning-the-network-performance" data-v-b883c74f>Avoiding listen queue lock contention</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#avoiding-rx-queue-lock-contention-the-so_reuseport-and-so_reuseport_bpf-socket-options_avoiding-listen-queue-lock-contention" id="sub-link-to-monitoring_and_managing_system_status_and_performance-avoiding-rx-queue-lock-contention-the-so_reuseport-and-so_reuseport_bpf-socket-options_avoiding-listen-queue-lock-contention" data-v-b883c74f>31.9.1. Avoiding RX queue lock contention: The SO_REUSEPORT and SO_REUSEPORT_BPF socket options</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#avoiding-tx-queue-lock-contention-transmit-packet-steering_avoiding-listen-queue-lock-contention" id="sub-link-to-monitoring_and_managing_system_status_and_performance-avoiding-tx-queue-lock-contention-transmit-packet-steering_avoiding-listen-queue-lock-contention" data-v-b883c74f>31.9.2. Avoiding TX queue lock contention: Transmit packet steering</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#disabling-the-generic-receive-offload-feature-on-servers-with-high-udp-traffic_avoiding-listen-queue-lock-contention" id="sub-link-to-monitoring_and_managing_system_status_and_performance-disabling-the-generic-receive-offload-feature-on-servers-with-high-udp-traffic_avoiding-listen-queue-lock-contention" data-v-b883c74f>31.9.3. Disabling the Generic Receive Offload feature on servers with high UDP traffic</a></li><!--]--><!--]--></ol></details></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><details id="nested-toc--tuning-the-device-driver-and-nic_tuning-the-network-performance" data-v-b883c74f><summary class="heading sub-chapter-title" id="tuning-the-device-driver-and-nic_tuning-the-network-performance--summary" data-v-b883c74f>31.10. Tuning the device driver and NIC</summary><ol id="sub-nav--tuning-the-device-driver-and-nic_tuning-the-network-performance" class="sub-nav" data-v-b883c74f><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title chapter-landing-page" href="#tuning-the-device-driver-and-nic_tuning-the-network-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-tuning-the-device-driver-and-nic_tuning-the-network-performance" data-v-b883c74f>Tuning the device driver and NIC</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#configuring-custom-nic-driver-parameters_tuning-the-device-driver-and-nic" id="sub-link-to-monitoring_and_managing_system_status_and_performance-configuring-custom-nic-driver-parameters_tuning-the-device-driver-and-nic" data-v-b883c74f>31.10.1. Configuring custom NIC driver parameters</a></li><!--]--><!--]--></ol></details></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><details id="nested-toc--configuring-network-adapter-offload-settings_tuning-the-network-performance" data-v-b883c74f><summary class="heading sub-chapter-title" id="configuring-network-adapter-offload-settings_tuning-the-network-performance--summary" data-v-b883c74f>31.11. Configuring network adapter offload settings</summary><ol id="sub-nav--configuring-network-adapter-offload-settings_tuning-the-network-performance" class="sub-nav" data-v-b883c74f><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title chapter-landing-page" href="#configuring-network-adapter-offload-settings_tuning-the-network-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-configuring-network-adapter-offload-settings_tuning-the-network-performance" data-v-b883c74f>Configuring network adapter offload settings</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#temporarily-setting-an-offload-feature_configuring-network-adapter-offload-settings" id="sub-link-to-monitoring_and_managing_system_status_and_performance-temporarily-setting-an-offload-feature_configuring-network-adapter-offload-settings" data-v-b883c74f>31.11.1. Temporarily setting an offload feature</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#permanently-setting-an-offload-feature_configuring-network-adapter-offload-settings" id="sub-link-to-monitoring_and_managing_system_status_and_performance-permanently-setting-an-offload-feature_configuring-network-adapter-offload-settings" data-v-b883c74f>31.11.2. Permanently setting an offload feature</a></li><!--]--><!--]--></ol></details></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><details id="nested-toc--tuning-interrupt-coalescence-settings_tuning-the-network-performance" data-v-b883c74f><summary class="heading sub-chapter-title" id="tuning-interrupt-coalescence-settings_tuning-the-network-performance--summary" data-v-b883c74f>31.12. Tuning interrupt coalescence settings</summary><ol id="sub-nav--tuning-interrupt-coalescence-settings_tuning-the-network-performance" class="sub-nav" data-v-b883c74f><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title chapter-landing-page" href="#tuning-interrupt-coalescence-settings_tuning-the-network-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-tuning-interrupt-coalescence-settings_tuning-the-network-performance" data-v-b883c74f>Tuning interrupt coalescence settings</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#optimizing-rhel-for-latency-or-throughput-sensitive-services_tuning-interrupt-coalescence-settings" id="sub-link-to-monitoring_and_managing_system_status_and_performance-optimizing-rhel-for-latency-or-throughput-sensitive-services_tuning-interrupt-coalescence-settings" data-v-b883c74f>31.12.1. Optimizing RHEL for latency or throughput-sensitive services</a></li><!--]--><!--]--></ol></details></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#benefits-of-tcp-timestamps_tuning-the-network-performance" id="sub-link-to-monitoring_and_managing_system_status_and_performance-benefits-of-tcp-timestamps_tuning-the-network-performance" data-v-b883c74f>31.13. Benefits of TCP Timestamps</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#ref_flow-control-in-ethernet-networks_tuning-the-network-performance" id="sub-link-to-monitoring_and_managing_system_status_and_performance-ref_flow-control-in-ethernet-networks_tuning-the-network-performance" data-v-b883c74f>31.14. Flow control for Ethernet networks</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--factors-affecting-i-o-and-file-system-performance_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="factors-affecting-i-o-and-file-system-performance_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>32. Factors affecting I/O and file system performance</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#factors-affecting-i-o-and-file-system-performance_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-factors-affecting-i-o-and-file-system-performance_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Factors affecting I/O and file system performance</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#tools-for-monitoring-and-diagnosing-i-o-and-file-system-issues_factors-affecting-i-o-and-file-system-performance" id="sub-link-to-monitoring_and_managing_system_status_and_performance-tools-for-monitoring-and-diagnosing-i-o-and-file-system-issues_factors-affecting-i-o-and-file-system-performance" data-v-b883c74f>32.1. Tools for monitoring and diagnosing I/O and file system issues</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#available-tuning-options-for-formatting-a-file-system_factors-affecting-i-o-and-file-system-performance" id="sub-link-to-monitoring_and_managing_system_status_and_performance-available-tuning-options-for-formatting-a-file-system_factors-affecting-i-o-and-file-system-performance" data-v-b883c74f>32.2. Available tuning options for formatting a file system</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#available-tuning-options-for-mounting-a-file-system_factors-affecting-i-o-and-file-system-performance" id="sub-link-to-monitoring_and_managing_system_status_and_performance-available-tuning-options-for-mounting-a-file-system_factors-affecting-i-o-and-file-system-performance" data-v-b883c74f>32.3. Available tuning options for mounting a file system</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#types-of-discarding-unused-blocks_factors-affecting-i-o-and-file-system-performance" id="sub-link-to-monitoring_and_managing_system_status_and_performance-types-of-discarding-unused-blocks_factors-affecting-i-o-and-file-system-performance" data-v-b883c74f>32.4. Types of discarding unused blocks</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#solid-state-disks-tuning-considerations_factors-affecting-i-o-and-file-system-performance" id="sub-link-to-monitoring_and_managing_system_status_and_performance-solid-state-disks-tuning-considerations_factors-affecting-i-o-and-file-system-performance" data-v-b883c74f>32.5. Solid-state disks tuning considerations</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#generic-block-device-tuning-parameters_factors-affecting-i-o-and-file-system-performance" id="sub-link-to-monitoring_and_managing_system_status_and_performance-generic-block-device-tuning-parameters_factors-affecting-i-o-and-file-system-performance" data-v-b883c74f>32.6. Generic block device tuning parameters</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--assembly_using-systemd-to-manage-resources-used-by-applications_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="assembly_using-systemd-to-manage-resources-used-by-applications_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>33. Using systemd to manage resources used by applications</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#assembly_using-systemd-to-manage-resources-used-by-applications_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-assembly_using-systemd-to-manage-resources-used-by-applications_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Using systemd to manage resources used by applications</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#con_role-of-systemd-in-resource-management_assembly_using-systemd-to-manage-resources-used-by-applications" id="sub-link-to-monitoring_and_managing_system_status_and_performance-con_role-of-systemd-in-resource-management_assembly_using-systemd-to-manage-resources-used-by-applications" data-v-b883c74f>33.1. Role of systemd in resource management</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#distribution-models-of-system-sources_assembly_using-systemd-to-manage-resources-used-by-applications" id="sub-link-to-monitoring_and_managing_system_status_and_performance-distribution-models-of-system-sources_assembly_using-systemd-to-manage-resources-used-by-applications" data-v-b883c74f>33.2. Distribution models of system sources</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_allocating-system-resources-using-systemd_assembly_using-systemd-to-manage-resources-used-by-applications" id="sub-link-to-monitoring_and_managing_system_status_and_performance-proc_allocating-system-resources-using-systemd_assembly_using-systemd-to-manage-resources-used-by-applications" data-v-b883c74f>33.3. Allocating system resources using systemd</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#con_overview-of-systemd-hierarchy-for-cgroups_assembly_using-systemd-to-manage-resources-used-by-applications" id="sub-link-to-monitoring_and_managing_system_status_and_performance-con_overview-of-systemd-hierarchy-for-cgroups_assembly_using-systemd-to-manage-resources-used-by-applications" data-v-b883c74f>33.4. Overview of systemd hierarchy for cgroups</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#listing-systemd_units_assembly_using-systemd-to-manage-resources-used-by-applications" id="sub-link-to-monitoring_and_managing_system_status_and_performance-listing-systemd_units_assembly_using-systemd-to-manage-resources-used-by-applications" data-v-b883c74f>33.5. Listing systemd units</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#viewing-systemd-control-group-hierarchy_assembly_using-systemd-to-manage-resources-used-by-applications" id="sub-link-to-monitoring_and_managing_system_status_and_performance-viewing-systemd-control-group-hierarchy_assembly_using-systemd-to-manage-resources-used-by-applications" data-v-b883c74f>33.6. Viewing systemd cgroups hierarchy</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_viewing-cgroups-of-processes_assembly_using-systemd-to-manage-resources-used-by-applications" id="sub-link-to-monitoring_and_managing_system_status_and_performance-proc_viewing-cgroups-of-processes_assembly_using-systemd-to-manage-resources-used-by-applications" data-v-b883c74f>33.7. Viewing cgroups of processes</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#monitoring-resource-consumption_assembly_using-systemd-to-manage-resources-used-by-applications" id="sub-link-to-monitoring_and_managing_system_status_and_performance-monitoring-resource-consumption_assembly_using-systemd-to-manage-resources-used-by-applications" data-v-b883c74f>33.8. Monitoring resource consumption</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_using-systemd-unit-files-to-set-limits-for-applications_assembly_using-systemd-to-manage-resources-used-by-applications" id="sub-link-to-monitoring_and_managing_system_status_and_performance-proc_using-systemd-unit-files-to-set-limits-for-applications_assembly_using-systemd-to-manage-resources-used-by-applications" data-v-b883c74f>33.9. Using systemd unit files to set limits for applications</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_using-systemctl-command-to-set-limits-to-applications_assembly_using-systemd-to-manage-resources-used-by-applications" id="sub-link-to-monitoring_and_managing_system_status_and_performance-proc_using-systemctl-command-to-set-limits-to-applications_assembly_using-systemd-to-manage-resources-used-by-applications" data-v-b883c74f>33.10. Using systemctl command to set limits to applications</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_setting-global-default-cpu-affinity-through-manager-configuration_assembly_using-systemd-to-manage-resources-used-by-applications" id="sub-link-to-monitoring_and_managing_system_status_and_performance-proc_setting-global-default-cpu-affinity-through-manager-configuration_assembly_using-systemd-to-manage-resources-used-by-applications" data-v-b883c74f>33.11. Setting global default CPU affinity through manager configuration</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_configuring-numa-using-systemd_assembly_using-systemd-to-manage-resources-used-by-applications" id="sub-link-to-monitoring_and_managing_system_status_and_performance-proc_configuring-numa-using-systemd_assembly_using-systemd-to-manage-resources-used-by-applications" data-v-b883c74f>33.12. Configuring NUMA policies using systemd</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#ref_numa-policy-configuration-options-with-systemd_assembly_using-systemd-to-manage-resources-used-by-applications" id="sub-link-to-monitoring_and_managing_system_status_and_performance-ref_numa-policy-configuration-options-with-systemd_assembly_using-systemd-to-manage-resources-used-by-applications" data-v-b883c74f>33.13. NUMA policy configuration options for systemd</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#creating-transient-control-groups_assembly_using-systemd-to-manage-resources-used-by-applications" id="sub-link-to-monitoring_and_managing_system_status_and_performance-creating-transient-control-groups_assembly_using-systemd-to-manage-resources-used-by-applications" data-v-b883c74f>33.14. Creating transient cgroups using systemd-run command</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#removing-transient-control-groups_assembly_using-systemd-to-manage-resources-used-by-applications" id="sub-link-to-monitoring_and_managing_system_status_and_performance-removing-transient-control-groups_assembly_using-systemd-to-manage-resources-used-by-applications" data-v-b883c74f>33.15. Removing transient control groups</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--setting-limits-for-applications_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="setting-limits-for-applications_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>34. Understanding control groups</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#setting-limits-for-applications_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-setting-limits-for-applications_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Understanding control groups</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#understanding-control-groups_setting-limits-for-applications" id="sub-link-to-monitoring_and_managing_system_status_and_performance-understanding-control-groups_setting-limits-for-applications" data-v-b883c74f>34.1. Introducing control groups</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#what-kernel-resource-controllers-are_setting-limits-for-applications" id="sub-link-to-monitoring_and_managing_system_status_and_performance-what-kernel-resource-controllers-are_setting-limits-for-applications" data-v-b883c74f>34.2. Introducing kernel resource controllers</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#what-namespaces-are_setting-limits-for-applications" id="sub-link-to-monitoring_and_managing_system_status_and_performance-what-namespaces-are_setting-limits-for-applications" data-v-b883c74f>34.3. Introducing namespaces</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--assembly_using-cgroupfs-to-manually-manage-cgroups_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="assembly_using-cgroupfs-to-manually-manage-cgroups_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>35. Using cgroupfs to manually manage cgroups</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#assembly_using-cgroupfs-to-manually-manage-cgroups_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-assembly_using-cgroupfs-to-manually-manage-cgroups_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Using cgroupfs to manually manage cgroups</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_creating-cgroups-and-enabling-controllers-in-cgroups-v2-file-system_assembly_using-cgroupfs-to-manually-manage-cgroups" id="sub-link-to-monitoring_and_managing_system_status_and_performance-proc_creating-cgroups-and-enabling-controllers-in-cgroups-v2-file-system_assembly_using-cgroupfs-to-manually-manage-cgroups" data-v-b883c74f>35.1. Creating cgroups and enabling controllers in cgroups-v2 file system</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_controlling-distribution-of-cpu-time-for-applications-by-adjusting-cpu-weight_assembly_using-cgroupfs-to-manually-manage-cgroups" id="sub-link-to-monitoring_and_managing_system_status_and_performance-proc_controlling-distribution-of-cpu-time-for-applications-by-adjusting-cpu-weight_assembly_using-cgroupfs-to-manually-manage-cgroups" data-v-b883c74f>35.2. Controlling distribution of CPU time for applications by adjusting CPU weight</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#proc_mounting-cgroups-v1_assembly_using-cgroupfs-to-manually-manage-cgroups" id="sub-link-to-monitoring_and_managing_system_status_and_performance-proc_mounting-cgroups-v1_assembly_using-cgroupfs-to-manually-manage-cgroups" data-v-b883c74f>35.3. Mounting cgroups-v1</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#setting-cpu-limits-to-applications-using-cgroups-v1_assembly_using-cgroupfs-to-manually-manage-cgroups" id="sub-link-to-monitoring_and_managing_system_status_and_performance-setting-cpu-limits-to-applications-using-cgroups-v1_assembly_using-cgroupfs-to-manually-manage-cgroups" data-v-b883c74f>35.4. Setting CPU limits to applications using cgroups-v1</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--analyzing-system-performance-with-bpf-compiler_collection_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="analyzing-system-performance-with-bpf-compiler_collection_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>36. Analyzing system performance with BPF Compiler Collection</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#analyzing-system-performance-with-bpf-compiler_collection_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-analyzing-system-performance-with-bpf-compiler_collection_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Analyzing system performance with BPF Compiler Collection</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#installing-the-bcc-tools-package_analyzing-system-performance-with-bpf-compiler_collection" id="sub-link-to-monitoring_and_managing_system_status_and_performance-installing-the-bcc-tools-package_analyzing-system-performance-with-bpf-compiler_collection" data-v-b883c74f>36.1. Installing the bcc-tools package</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#using-selected-bcc-tools-for-performance-analyses_analyzing-system-performance-with-bpf-compiler_collection" id="sub-link-to-monitoring_and_managing_system_status_and_performance-using-selected-bcc-tools-for-performance-analyses_analyzing-system-performance-with-bpf-compiler_collection" data-v-b883c74f>36.2. Using selected bcc-tools for performance analyses</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--configuring-an-operating-system-to-optimize-memory-access_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="configuring-an-operating-system-to-optimize-memory-access_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>37. Configuring an operating system to optimize memory access</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#configuring-an-operating-system-to-optimize-memory-access_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-configuring-an-operating-system-to-optimize-memory-access_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Configuring an operating system to optimize memory access</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#tools-for-monitoring-and-diagnosing-system-memory-issues_configuring-an-operating-system-to-optimize-memory-access" id="sub-link-to-monitoring_and_managing_system_status_and_performance-tools-for-monitoring-and-diagnosing-system-memory-issues_configuring-an-operating-system-to-optimize-memory-access" data-v-b883c74f>37.1. Tools for monitoring and diagnosing system memory issues</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#overview-of-a-systems-memory_configuring-an-operating-system-to-optimize-memory-access" id="sub-link-to-monitoring_and_managing_system_status_and_performance-overview-of-a-systems-memory_configuring-an-operating-system-to-optimize-memory-access" data-v-b883c74f>37.2. Overview of a system’s memory</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#virtual-memory-parameters_configuring-an-operating-system-to-optimize-memory-access" id="sub-link-to-monitoring_and_managing_system_status_and_performance-virtual-memory-parameters_configuring-an-operating-system-to-optimize-memory-access" data-v-b883c74f>37.3. Virtual memory parameters</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#file-system-parameters_configuring-an-operating-system-to-optimize-memory-access" id="sub-link-to-monitoring_and_managing_system_status_and_performance-file-system-parameters_configuring-an-operating-system-to-optimize-memory-access" data-v-b883c74f>37.4. File system parameters</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#kernel-parameters_configuring-an-operating-system-to-optimize-memory-access" id="sub-link-to-monitoring_and_managing_system_status_and_performance-kernel-parameters_configuring-an-operating-system-to-optimize-memory-access" data-v-b883c74f>37.5. Kernel parameters</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#setting-memory-related-kernel-parameters_configuring-an-operating-system-to-optimize-memory-access" id="sub-link-to-monitoring_and_managing_system_status_and_performance-setting-memory-related-kernel-parameters_configuring-an-operating-system-to-optimize-memory-access" data-v-b883c74f>37.6. Setting memory-related kernel parameters</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--configuring-huge-pages_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="configuring-huge-pages_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>38. Configuring huge pages</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#configuring-huge-pages_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-configuring-huge-pages_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Configuring huge pages</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#available-hugepage-features_configuring-huge-pages" id="sub-link-to-monitoring_and_managing_system_status_and_performance-available-hugepage-features_configuring-huge-pages" data-v-b883c74f>38.1. Available huge page features</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#parameters-for-reserving-hugetlb-pages-at-boot-time_configuring-huge-pages" id="sub-link-to-monitoring_and_managing_system_status_and_performance-parameters-for-reserving-hugetlb-pages-at-boot-time_configuring-huge-pages" data-v-b883c74f>38.2. Parameters for reserving HugeTLB pages at boot time</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#configuring-hugetlb-at-boot-time_configuring-huge-pages" id="sub-link-to-monitoring_and_managing_system_status_and_performance-configuring-hugetlb-at-boot-time_configuring-huge-pages" data-v-b883c74f>38.3. Configuring HugeTLB at boot time</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#parameters-for-reserving-hugetlb-pages-at-run-time_configuring-huge-pages" id="sub-link-to-monitoring_and_managing_system_status_and_performance-parameters-for-reserving-hugetlb-pages-at-run-time_configuring-huge-pages" data-v-b883c74f>38.4. Parameters for reserving HugeTLB pages at run time</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#configuring-hugetlb-at-run-time_configuring-huge-pages" id="sub-link-to-monitoring_and_managing_system_status_and_performance-configuring-hugetlb-at-run-time_configuring-huge-pages" data-v-b883c74f>38.5. Configuring HugeTLB at run time</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#enabling-transparent-hugepages_configuring-huge-pages" id="sub-link-to-monitoring_and_managing_system_status_and_performance-enabling-transparent-hugepages_configuring-huge-pages" data-v-b883c74f>38.6. Enabling transparent hugepages</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#disabling-transparent-hugepages_configuring-huge-pages" id="sub-link-to-monitoring_and_managing_system_status_and_performance-disabling-transparent-hugepages_configuring-huge-pages" data-v-b883c74f>38.7. Disabling transparent hugepages</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#impact-of-page-size-on-translation-lookaside-buffer-size_configuring-huge-pages" id="sub-link-to-monitoring_and_managing_system_status_and_performance-impact-of-page-size-on-translation-lookaside-buffer-size_configuring-huge-pages" data-v-b883c74f>38.8. Impact of page size on translation lookaside buffer size</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--getting-started-with-systemtap_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="getting-started-with-systemtap_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>39. Getting started with SystemTap</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#getting-started-with-systemtap_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-getting-started-with-systemtap_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Getting started with SystemTap</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#the-purpose-of-systemtap_getting-started-with-systemtap" id="sub-link-to-monitoring_and_managing_system_status_and_performance-the-purpose-of-systemtap_getting-started-with-systemtap" data-v-b883c74f>39.1. The purpose of SystemTap</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#installing-systemtap_getting-started-with-systemtap" id="sub-link-to-monitoring_and_managing_system_status_and_performance-installing-systemtap_getting-started-with-systemtap" data-v-b883c74f>39.2. Installing SystemTap</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#privileges-to-run-systemtap_getting-started-with-systemtap" id="sub-link-to-monitoring_and_managing_system_status_and_performance-privileges-to-run-systemtap_getting-started-with-systemtap" data-v-b883c74f>39.3. Privileges to run SystemTap</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#running-systemtap-scripts_getting-started-with-systemtap" id="sub-link-to-monitoring_and_managing_system_status_and_performance-running-systemtap-scripts_getting-started-with-systemtap" data-v-b883c74f>39.4. Running SystemTap scripts</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#useful-examples-of-systemtap-scripts_getting-started-with-systemtap" id="sub-link-to-monitoring_and_managing_system_status_and_performance-useful-examples-of-systemtap-scripts_getting-started-with-systemtap" data-v-b883c74f>39.5. Useful examples of SystemTap scripts</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><details id="toc--cross-instrumentation-of-systemtap_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77><summary class="heading chapter-title" id="cross-instrumentation-of-systemtap_monitoring-and-managing-system-status-and-performance--summary" data-v-fa0dae77>40. Cross-instrumentation of SystemTap</summary><ol class="sub-nav" data-v-fa0dae77><li class="item sub-chapter" data-v-fa0dae77><a class="link sub-chapter-title chapter-landing-page" href="#cross-instrumentation-of-systemtap_monitoring-and-managing-system-status-and-performance" id="chapter-landing--monitoring_and_managing_system_status_and_performance-cross-instrumentation-of-systemtap_monitoring-and-managing-system-status-and-performance" data-v-fa0dae77>Cross-instrumentation of SystemTap</a></li><!--[--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#systemtap-cross-instrumentation_cross-instrumentation-of-systemtap" id="sub-link-to-monitoring_and_managing_system_status_and_performance-systemtap-cross-instrumentation_cross-instrumentation-of-systemtap" data-v-b883c74f>40.1. SystemTap cross-instrumentation</a></li><!--]--><!--[--><li class="item sub-chapter" data-v-b883c74f><a class="link sub-chapter-title" href="#initializing-cross-instrumentation-of-systemtap_cross-instrumentation-of-systemtap" id="sub-link-to-monitoring_and_managing_system_status_and_performance-initializing-cross-instrumentation-of-systemtap_cross-instrumentation-of-systemtap" data-v-b883c74f>40.2. Initializing cross-instrumentation of SystemTap</a></li><!--]--><!--]--></ol></details></li><li class="item chapter" data-v-fa0dae77><a class="link" href="#idm140280140052320" id="chapter-landing--monitoring_and_managing_system_status_and_performance-idm140280140052320" data-v-fa0dae77>Legal Notice</a></li><!--]--></ol></nav><!----></div></div></aside><article class="content span-xs-12 span-sm-6 span-md-12 span-lg-7" aria-live="polite" data-v-8589d091><!----><div lang="en-us" xml:lang="en-us" class="docs-content-container" data-v-8589d091><!----><!----><h1 data-id="content_chapter" class="chapter-title" data-v-8589d091>Monitoring and managing system status and performance</h1><hr class="line-below-chp" data-v-8589d091><section class="rhdocs" data-v-8589d091><body><div xml:lang="en-US" class="book" id="idm140280158333552"><div class="titlepage"><div><div class="producttitle"><span class="productname">Red Hat Enterprise Linux</span> <span class="productnumber">9</span></div><div><h3 class="subtitle">Optimizing system throughput, latency, and power consumption</h3></div><div><div xml:lang="en-US" class="authorgroup"><span class="orgname">Red Hat</span> <span class="orgdiv">Customer Content Services</span></div></div><div><a href="#idm140280140052320">Legal Notice</a></div><div><div class="abstract"><p class="title"><strong>Abstract</strong></p><div class="para">
				Monitor and optimize the throughput, latency, and power consumption of Red Hat Enterprise Linux 9 in different scenarios.
			</div></div></div></div><hr></div><section class="preface" id="proc_providing-feedback-on-red-hat-documentation_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Providing feedback on Red Hat documentation</h2></div></div></div><p class="_abstract _abstract">
			We appreciate your feedback on our documentation. Let us know how we can improve it.
		</p><div class="orderedlist"><p class="title"><strong>Submitting feedback through Jira (account required)</strong></p><ol class="orderedlist" type="1"><li class="listitem">
					Log in to the <a class="link" href="https://issues.redhat.com/projects/RHELDOCS/issues">Jira</a> website.
				</li><li class="listitem">
					Click <span class="strong strong"><strong>Create</strong></span> in the top navigation bar
				</li><li class="listitem">
					Enter a descriptive title in the <span class="strong strong"><strong>Summary</strong></span> field.
				</li><li class="listitem">
					Enter your suggestion for improvement in the <span class="strong strong"><strong>Description</strong></span> field. Include links to the relevant parts of the documentation.
				</li><li class="listitem">
					Click <span class="strong strong"><strong>Create</strong></span> at the bottom of the dialogue.
				</li></ol></div></section><section class="chapter" id="getting-started-with-tuned_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 1. Getting started with TuneD</h2></div></div></div><p class="_abstract _abstract">
			As a system administrator, you can use the <span class="strong strong"><strong>TuneD</strong></span> application to optimize the performance profile of your system for a variety of use cases.
		</p><section class="section" id="the-purpose-of-tuned_getting-started-with-tuned"><div class="titlepage"><div><div><h3 class="title">1.1. The purpose of TuneD</h3></div></div></div><p class="_abstract _abstract">
				<span class="strong strong"><strong>TuneD</strong></span> is a service that monitors your system and optimizes the performance under certain workloads. The core of <span class="strong strong"><strong>TuneD</strong></span> are <span class="emphasis"><em>profiles</em></span>, which tune your system for different use cases.
			</p><p>
				<span class="strong strong"><strong>TuneD</strong></span> is distributed with a number of predefined profiles for use cases such as:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						High throughput
					</li><li class="listitem">
						Low latency
					</li><li class="listitem">
						Saving power
					</li></ul></div><p>
				It is possible to modify the rules defined for each profile and customize how to tune a particular device. When you switch to another profile or deactivate <span class="strong strong"><strong>TuneD</strong></span>, all changes made to the system settings by the previous profile revert back to their original state.
			</p><p>
				You can also configure <span class="strong strong"><strong>TuneD</strong></span> to react to changes in device usage and adjusts settings to improve performance of active devices and reduce power consumption of inactive devices.
			</p></section><section class="section" id="tuned-profiles_getting-started-with-tuned"><div class="titlepage"><div><div><h3 class="title">1.2. TuneD profiles</h3></div></div></div><p class="_abstract _abstract">
				A detailed analysis of a system can be very time-consuming. <span class="strong strong"><strong>TuneD</strong></span> provides a number of predefined profiles for typical use cases. You can also create, modify, and delete profiles.
			</p><p>
				The profiles provided with <span class="strong strong"><strong>TuneD</strong></span> are divided into the following categories:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Power-saving profiles
					</li><li class="listitem">
						Performance-boosting profiles
					</li></ul></div><p>
				The performance-boosting profiles include profiles that focus on the following aspects:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Low latency for storage and network
					</li><li class="listitem">
						High throughput for storage and network
					</li><li class="listitem">
						Virtual machine performance
					</li><li class="listitem">
						Virtualization host performance
					</li></ul></div><h5 id="syntax_of_profile_configuration">Syntax of profile configuration</h5><p>
				The <code class="literal">tuned.conf</code> file can contain one <code class="literal">[main]</code> section and other sections for configuring plug-in instances. However, all sections are optional.
			</p><p>
				Lines starting with the hash sign (<code class="literal">#</code>) are comments.
			</p><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">tuned.conf(5)</code> man page on your system
					</li></ul></div></section><section class="section" id="the-default-tuned-profile_getting-started-with-tuned"><div class="titlepage"><div><div><h3 class="title">1.3. The default TuneD profile</h3></div></div></div><p class="_abstract _abstract">
				During the installation, the best profile for your system is selected automatically. Currently, the default profile is selected according to the following customizable rules:
			</p><rh-table><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 29%; " class="col_1"><!--Empty--><col style="width: 29%; " class="col_2"><!--Empty--><col style="width: 43%; " class="col_3"><!--Empty--></colgroup><thead><tr><th align="left" valign="top" id="idm140280149291312" scope="col">Environment</th><th align="left" valign="top" id="idm140280149290224" scope="col">Default profile</th><th align="left" valign="top" id="idm140280160796032" scope="col">Goal</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm140280149291312"> <p>
								Compute nodes
							</p>
							 </td><td align="left" valign="top" headers="idm140280149290224"> <p>
								<code class="literal">throughput-performance</code>
							</p>
							 </td><td align="left" valign="top" headers="idm140280160796032"> <p>
								The best throughput performance
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm140280149291312"> <p>
								Virtual machines
							</p>
							 </td><td align="left" valign="top" headers="idm140280149290224"> <p>
								<code class="literal">virtual-guest</code>
							</p>
							 </td><td align="left" valign="top" headers="idm140280160796032"> <p>
								The best performance. If you are not interested in the best performance, you can change it to the <code class="literal">balanced</code> or <code class="literal">powersave</code> profile.
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm140280149291312"> <p>
								Other cases
							</p>
							 </td><td align="left" valign="top" headers="idm140280149290224"> <p>
								<code class="literal">balanced</code>
							</p>
							 </td><td align="left" valign="top" headers="idm140280160796032"> <p>
								Balanced performance and power consumption
							</p>
							 </td></tr></tbody></table></rh-table><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">tuned.conf(5)</code> man page on your system
					</li></ul></div></section><section class="section" id="merged-tuned-profiles_getting-started-with-tuned"><div class="titlepage"><div><div><h3 class="title">1.4. Merged TuneD profiles</h3></div></div></div><p class="_abstract _abstract">
				As an experimental feature, it is possible to select more profiles at once. <span class="strong strong"><strong>TuneD</strong></span> will try to merge them during the load.
			</p><p>
				If there are conflicts, the settings from the last specified profile takes precedence.
			</p><div class="example" id="idm140280150601488"><p class="title"><strong>Example 1.1. Low power consumption in a virtual guest</strong></p><div class="example-contents"><p>
					The following example optimizes the system to run in a virtual machine for the best performance and concurrently tunes it for low power consumption, while the low power consumption is the priority:
				</p><pre class="screen"># tuned-adm profile virtual-guest powersave</pre></div></div><rh-alert class="admonition warning" state="danger"><div class="admonition_header" slot="header">Warning</div><div><p>
					Merging is done automatically without checking whether the resulting combination of parameters makes sense. Consequently, the feature might tune some parameters the opposite way, which might be counterproductive: for example, setting the disk for high throughput by using the <code class="literal">throughput-performance</code> profile and concurrently setting the disk spindown to the low value by the <code class="literal">spindown-disk</code> profile.
				</p></div></rh-alert><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">tuned-adm</code> and <code class="literal">tuned.conf(5)</code> man pages on your system
					</li></ul></div></section><section class="section" id="the-location-of-tuned-profiles_getting-started-with-tuned"><div class="titlepage"><div><div><h3 class="title">1.5. The location of TuneD profiles</h3></div></div></div><p class="_abstract _abstract">
				<span class="strong strong"><strong>TuneD</strong></span> stores profiles in the following directories:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal filename">/usr/lib/tuned/</code></span></dt><dd>
							Distribution-specific profiles are stored in the directory. Each profile has its own directory. The profile consists of the main configuration file called <code class="literal">tuned.conf</code>, and optionally other files, for example helper scripts.
						</dd><dt><span class="term"><code class="literal filename">/etc/tuned/</code></span></dt><dd>
							If you need to customize a profile, copy the profile directory into the directory, which is used for custom profiles. If there are two profiles of the same name, the custom profile located in <code class="literal filename">/etc/tuned/</code> is used.
						</dd></dl></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">tuned.conf(5)</code> man page on your system
					</li></ul></div></section><section class="section" id="tuned-profiles-distributed-with-rhel_getting-started-with-tuned"><div class="titlepage"><div><div><h3 class="title">1.6. TuneD profiles distributed with RHEL</h3></div></div></div><p class="_abstract _abstract">
				The following is a list of profiles that are installed with <span class="strong strong"><strong>TuneD</strong></span> on Red Hat Enterprise Linux.
			</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					There might be more product-specific or third-party <span class="strong strong"><strong>TuneD</strong></span> profiles available. Such profiles are usually provided by separate RPM packages.
				</p></div></rh-alert><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">balanced</code></span></dt><dd><p class="simpara">
							The default power-saving profile. It is intended to be a compromise between performance and power consumption. It uses auto-scaling and auto-tuning whenever possible. The only drawback is the increased latency. In the current <span class="strong strong"><strong>TuneD</strong></span> release, it enables the CPU, disk, audio, and video plugins, and activates the <code class="literal">conservative</code> CPU governor. The <code class="literal">radeon_powersave</code> option uses the <code class="literal">dpm-balanced</code> value if it is supported, otherwise it is set to <code class="literal">auto</code>.
						</p><p class="simpara">
							It changes the <code class="literal">energy_performance_preference</code> attribute to the <code class="literal">normal</code> energy setting. It also changes the <code class="literal">scaling_governor</code> policy attribute to either the <code class="literal">conservative</code> or <code class="literal">powersave</code> CPU governor.
						</p></dd><dt><span class="term"><code class="literal">powersave</code></span></dt><dd><p class="simpara">
							A profile for maximum power saving performance. It can throttle the performance in order to minimize the actual power consumption. In the current <span class="strong strong"><strong>TuneD</strong></span> release it enables USB autosuspend, WiFi power saving, and Aggressive Link Power Management (ALPM) power savings for SATA host adapters. It also schedules multi-core power savings for systems with a low wakeup rate and activates the <code class="literal">ondemand</code> governor. It enables AC97 audio power saving or, depending on your system, HDA-Intel power savings with a 10 seconds timeout. If your system contains a supported Radeon graphics card with enabled KMS, the profile configures it to automatic power saving. On ASUS Eee PCs, a dynamic Super Hybrid Engine is enabled.
						</p><p class="simpara">
							It changes the <code class="literal">energy_performance_preference</code> attribute to the <code class="literal">powersave</code> or <code class="literal">power</code> energy setting. It also changes the <code class="literal">scaling_governor</code> policy attribute to either the <code class="literal">ondemand</code> or <code class="literal">powersave</code> CPU governor.
						</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
								In certain cases, the <code class="literal">balanced</code> profile is more efficient compared to the <code class="literal">powersave</code> profile.
							</p><p>
								Consider there is a defined amount of work that needs to be done, for example a video file that needs to be transcoded. Your machine might consume less energy if the transcoding is done on the full power, because the task is finished quickly, the machine starts to idle, and it can automatically step-down to very efficient power save modes. On the other hand, if you transcode the file with a throttled machine, the machine consumes less power during the transcoding, but the process takes longer and the overall consumed energy can be higher.
							</p><p>
								That is why the <code class="literal">balanced</code> profile can be generally a better option.
							</p></div></rh-alert></dd><dt><span class="term"><code class="literal">throughput-performance</code></span></dt><dd><p class="simpara">
							A server profile optimized for high throughput. It disables power savings mechanisms and enables <code class="literal">sysctl</code> settings that improve the throughput performance of the disk and network IO. CPU governor is set to <code class="literal">performance</code>.
						</p><p class="simpara">
							It changes the <code class="literal">energy_performance_preference</code> and <code class="literal">scaling_governor</code> attribute to the <code class="literal">performance</code> profile.
						</p></dd><dt><span class="term"><code class="literal">accelerator-performance</code></span></dt><dd>
							The <code class="literal">accelerator-performance</code> profile contains the same tuning as the <code class="literal">throughput-performance</code> profile. Additionally, it locks the CPU to low C states so that the latency is less than 100us. This improves the performance of certain accelerators, such as GPUs.
						</dd><dt><span class="term"><code class="literal">latency-performance</code></span></dt><dd><p class="simpara">
							A server profile optimized for low latency. It disables power savings mechanisms and enables <code class="literal">sysctl</code> settings that improve latency. CPU governor is set to <code class="literal">performance</code> and the CPU is locked to the low C states (by PM QoS).
						</p><p class="simpara">
							It changes the <code class="literal">energy_performance_preference</code> and <code class="literal">scaling_governor</code> attribute to the <code class="literal">performance</code> profile.
						</p></dd><dt><span class="term"><code class="literal">network-latency</code></span></dt><dd><p class="simpara">
							A profile for low latency network tuning. It is based on the <code class="literal">latency-performance</code> profile. It additionally disables transparent huge pages and NUMA balancing, and tunes several other network-related <code class="literal">sysctl</code> parameters.
						</p><p class="simpara">
							It inherits the <code class="literal">latency-performance</code> profile which changes the <code class="literal">energy_performance_preference</code> and <code class="literal">scaling_governor</code> attribute to the <code class="literal">performance</code> profile.
						</p></dd><dt><span class="term"><code class="literal">hpc-compute</code></span></dt><dd>
							A profile optimized for high-performance computing. It is based on the <code class="literal">latency-performance</code> profile.
						</dd><dt><span class="term"><code class="literal">network-throughput</code></span></dt><dd><p class="simpara">
							A profile for throughput network tuning. It is based on the <code class="literal">throughput-performance</code> profile. It additionally increases kernel network buffers.
						</p><p class="simpara">
							It inherits either the <code class="literal">latency-performance</code> or <code class="literal">throughput-performance</code> profile, and changes the <code class="literal">energy_performance_preference</code> and <code class="literal">scaling_governor</code> attribute to the <code class="literal">performance</code> profile.
						</p></dd><dt><span class="term"><code class="literal">virtual-guest</code></span></dt><dd><p class="simpara">
							A profile designed for Red Hat Enterprise Linux 9 virtual machines and VMWare guests based on the <code class="literal">throughput-performance</code> profile that, among other tasks, decreases virtual memory swappiness and increases disk readahead values. It does not disable disk barriers.
						</p><p class="simpara">
							It inherits the <code class="literal">throughput-performance</code> profile and changes the <code class="literal">energy_performance_preference</code> and <code class="literal">scaling_governor</code> attribute to the <code class="literal">performance</code> profile.
						</p></dd><dt><span class="term"><code class="literal">virtual-host</code></span></dt><dd><p class="simpara">
							A profile designed for virtual hosts based on the <code class="literal">throughput-performance</code> profile that, among other tasks, decreases virtual memory swappiness, increases disk readahead values, and enables a more aggressive value of dirty pages writeback.
						</p><p class="simpara">
							It inherits the <code class="literal">throughput-performance</code> profile and changes the <code class="literal">energy_performance_preference</code> and <code class="literal">scaling_governor</code> attribute to the <code class="literal">performance</code> profile.
						</p></dd><dt><span class="term"><code class="literal">oracle</code></span></dt><dd>
							A profile optimized for Oracle databases loads based on <code class="literal">throughput-performance</code> profile. It additionally disables transparent huge pages and modifies other performance-related kernel parameters. This profile is provided by the <code class="literal package">tuned-profiles-oracle</code> package.
						</dd><dt><span class="term"><code class="literal">desktop</code></span></dt><dd>
							A profile optimized for desktops, based on the <code class="literal">balanced</code> profile. It additionally enables scheduler autogroups for better response of interactive applications.
						</dd><dt><span class="term"><code class="literal">optimize-serial-console</code></span></dt><dd><p class="simpara">
							A profile that tunes down I/O activity to the serial console by reducing the printk value. This should make the serial console more responsive. This profile is intended to be used as an overlay on other profiles. For example:
						</p><pre class="screen"># tuned-adm profile throughput-performance optimize-serial-console</pre></dd><dt><span class="term"><code class="literal">mssql</code></span></dt><dd>
							A profile provided for Microsoft SQL Server. It is based on the <code class="literal">throughput-performance</code> profile.
						</dd><dt><span class="term"><code class="literal">intel-sst</code></span></dt><dd><p class="simpara">
							A profile optimized for systems with user-defined Intel Speed Select Technology configurations. This profile is intended to be used as an overlay on other profiles. For example:
						</p><pre class="screen"># tuned-adm profile cpu-partitioning intel-sst</pre></dd></dl></div></section><section class="section" id="tuned-cpu-partitioning-profile_getting-started-with-tuned"><div class="titlepage"><div><div><h3 class="title">1.7. TuneD cpu-partitioning profile</h3></div></div></div><p class="_abstract _abstract">
				For tuning Red Hat Enterprise Linux 9 for latency-sensitive workloads, Red Hat recommends to use the <code class="literal">cpu-partitioning</code> TuneD profile.
			</p><p>
				Prior to Red Hat Enterprise Linux 9, the low-latency Red Hat documentation described the numerous low-level steps needed to achieve low-latency tuning. In Red Hat Enterprise Linux 9, you can perform low-latency tuning more efficiently by using the <code class="literal">cpu-partitioning</code> TuneD profile. This profile is easily customizable according to the requirements for individual low-latency applications.
			</p><p>
				The following figure is an example to demonstrate how to use the <code class="literal">cpu-partitioning</code> profile. This example uses the CPU and node layout.
			</p><div class="figure" id="cpu-partitioning_getting-started-with-tuned"><p class="title"><strong>Figure 1.1. Figure cpu-partitioning</strong></p><div class="figure-contents"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/367206bd2d1527d49965f718f51722e3/cpu-partitioning.png" alt="cpu partitioning"></div></div></div><p>
				You can configure the cpu-partitioning profile in the <code class="literal">/etc/tuned/cpu-partitioning-variables.conf</code> file using the following configuration options:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">Isolated CPUs with load balancing</span></dt><dd><p class="simpara">
							In the cpu-partitioning figure, the blocks numbered from 4 to 23, are the default isolated CPUs. The kernel scheduler’s process load balancing is enabled on these CPUs. It is designed for low-latency processes with multiple threads that need the kernel scheduler load balancing.
						</p><p class="simpara">
							You can configure the cpu-partitioning profile in the <code class="literal">/etc/tuned/cpu-partitioning-variables.conf</code> file using the <code class="literal">isolated_cores=cpu-list</code> option, which lists CPUs to isolate that will use the kernel scheduler load balancing.
						</p><p class="simpara">
							The list of isolated CPUs is comma-separated or you can specify a range using a dash, such as <code class="literal">3-5</code>. This option is mandatory. Any CPU missing from this list is automatically considered a housekeeping CPU.
						</p></dd><dt><span class="term">Isolated CPUs without load balancing</span></dt><dd><p class="simpara">
							In the cpu-partitioning figure, the blocks numbered 2 and 3, are the isolated CPUs that do not provide any additional kernel scheduler process load balancing.
						</p><p class="simpara">
							You can configure the cpu-partitioning profile in the <code class="literal">/etc/tuned/cpu-partitioning-variables.conf</code> file using the <code class="literal">no_balance_cores=cpu-list</code> option, which lists CPUs to isolate that will not use the kernel scheduler load balancing.
						</p><p class="simpara">
							Specifying the <code class="literal">no_balance_cores</code> option is optional, however any CPUs in this list must be a subset of the CPUs listed in the <code class="literal">isolated_cores</code> list.
						</p><p class="simpara">
							Application threads using these CPUs need to be pinned individually to each CPU.
						</p></dd><dt><span class="term">Housekeeping CPUs</span></dt><dd>
							Any CPU not isolated in the <code class="literal">cpu-partitioning-variables.conf</code> file is automatically considered a housekeeping CPU. On the housekeeping CPUs, all services, daemons, user processes, movable kernel threads, interrupt handlers, and kernel timers are permitted to execute.
						</dd></dl></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">tuned-profiles-cpu-partitioning(7)</code> man page on your system
					</li></ul></div></section><section class="section" id="using-the-tuned-cpu-partitioning-profile-for-low-latency-tuning_getting-started-with-tuned"><div class="titlepage"><div><div><h3 class="title">1.8. Using the TuneD cpu-partitioning profile for low-latency tuning</h3></div></div></div><p class="_abstract _abstract">
				This procedure describes how to tune a system for low-latency using the TuneD’s <code class="literal">cpu-partitioning</code> profile. It uses the example of a low-latency application that can use <code class="literal">cpu-partitioning</code> and the CPU layout as mentioned in the <a class="link" href="#cpu-partitioning_getting-started-with-tuned" title="Figure 1.1. Figure cpu-partitioning">cpu-partitioning</a> figure.
			</p><p>
				The application in this case uses:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						One dedicated reader thread that reads data from the network will be pinned to CPU 2.
					</li><li class="listitem">
						A large number of threads that process this network data will be pinned to CPUs 4-23.
					</li><li class="listitem">
						A dedicated writer thread that writes the processed data to the network will be pinned to CPU 3.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have installed the <code class="literal">cpu-partitioning</code> TuneD profile by using the <code class="literal">dnf install tuned-profiles-cpu-partitioning</code> command as root.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Edit <code class="literal">/etc/tuned/cpu-partitioning-variables.conf</code> file and add the following information:
					</p><pre class="screen"># All isolated CPUs:
isolated_cores=2-23
# Isolated CPUs without the kernel’s scheduler load balancing:
no_balance_cores=2,3</pre></li><li class="listitem"><p class="simpara">
						Set the <code class="literal">cpu-partitioning</code> TuneD profile:
					</p><pre class="screen"># tuned-adm profile cpu-partitioning</pre></li><li class="listitem"><p class="simpara">
						Reboot
					</p><p class="simpara">
						After rebooting, the system is tuned for low-latency, according to the isolation in the cpu-partitioning figure. The application can use taskset to pin the reader and writer threads to CPUs 2 and 3, and the remaining application threads on CPUs 4-23.
					</p></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">tuned-profiles-cpu-partitioning(7)</code> man page on your system
					</li></ul></div></section><section class="section" id="customizing-the-cpu-partitioning-tuned-profile_getting-started-with-tuned"><div class="titlepage"><div><div><h3 class="title">1.9. Customizing the cpu-partitioning TuneD profile</h3></div></div></div><p class="_abstract _abstract">
				You can extend the TuneD profile to make additional tuning changes.
			</p><p>
				For example, the <code class="literal">cpu-partitioning</code> profile sets the CPUs to use <code class="literal">cstate=1</code>. In order to use the <code class="literal">cpu-partitioning</code> profile but to additionally change the CPU cstate from cstate1 to cstate0, the following procedure describes a new TuneD profile named <span class="emphasis"><em>my_profile</em></span>, which inherits the <code class="literal">cpu-partitioning</code> profile and then sets C state-0.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Create the <code class="literal">/etc/tuned/my_profile</code> directory:
					</p><pre class="screen"># mkdir /etc/tuned/<span class="emphasis"><em>my_profile</em></span></pre></li><li class="listitem"><p class="simpara">
						Create a <code class="literal">tuned.conf</code> file in this directory, and add the following content:
					</p><pre class="screen"># vi /etc/tuned/<span class="emphasis"><em>my_profile</em></span>/tuned.conf
[main]
summary=Customized tuning on top of cpu-partitioning
include=cpu-partitioning
[cpu]
force_latency=cstate.id:0|1</pre></li><li class="listitem"><p class="simpara">
						Use the new profile:
					</p><pre class="screen"># tuned-adm profile <span class="emphasis"><em>my_profile</em></span></pre></li></ol></div><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					In the shared example, a reboot is not required. However, if the changes in the <span class="emphasis"><em>my_profile</em></span> profile require a reboot to take effect, then reboot your machine.
				</p></div></rh-alert><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">tuned-profiles-cpu-partitioning(7)</code> man page on your system
					</li></ul></div></section><section class="section" id="real-time-tuned-profiles-distributed-with-rhel_getting-started-with-tuned"><div class="titlepage"><div><div><h3 class="title">1.10. Real-time TuneD profiles distributed with RHEL</h3></div></div></div><p class="_abstract _abstract">
				Real-time profiles are intended for systems running the real-time kernel. Without a special kernel build, they do not configure the system to be real-time. On RHEL, the profiles are available from additional repositories.
			</p><p>
				The following real-time profiles are available:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">realtime</code></span></dt><dd><p class="simpara">
							Use on bare-metal real-time systems.
						</p><p class="simpara">
							Provided by the <code class="literal package">tuned-profiles-realtime</code> package, which is available from the RT or NFV repositories.
						</p></dd><dt><span class="term"><code class="literal">realtime-virtual-host</code></span></dt><dd><p class="simpara">
							Use in a virtualization host configured for real-time.
						</p><p class="simpara">
							Provided by the <code class="literal package">tuned-profiles-nfv-host</code> package, which is available from the NFV repository.
						</p></dd><dt><span class="term"><code class="literal">realtime-virtual-guest</code></span></dt><dd><p class="simpara">
							Use in a virtualization guest configured for real-time.
						</p><p class="simpara">
							Provided by the <code class="literal package">tuned-profiles-nfv-guest</code> package, which is available from the NFV repository.
						</p></dd></dl></div></section><section class="section" id="static-and-dynamic-tuning-in-tuned_getting-started-with-tuned"><div class="titlepage"><div><div><h3 class="title">1.11. Static and dynamic tuning in TuneD</h3></div></div></div><p class="_abstract _abstract">
				Understanding the difference between the two categories of system tuning that <span class="strong strong"><strong>TuneD</strong></span> applies, <span class="emphasis"><em>static</em></span> and <span class="emphasis"><em>dynamic</em></span>, is important when determining which one to use for a given situation or purpose.
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">Static tuning</span></dt><dd>
							Mainly consists of the application of predefined <code class="literal">sysctl</code> and <code class="literal">sysfs</code> settings and one-shot activation of several configuration tools such as <code class="literal">ethtool</code>.
						</dd><dt><span class="term">Dynamic tuning</span></dt><dd><p class="simpara">
							Watches how various system components are used throughout the uptime of your system. <span class="strong strong"><strong>TuneD</strong></span> adjusts system settings dynamically based on that monitoring information.
						</p><p class="simpara">
							For example, the hard drive is used heavily during startup and login, but is barely used later when the user might mainly work with applications such as web browsers or email clients. Similarly, the CPU and network devices are used differently at different times. <span class="strong strong"><strong>TuneD</strong></span> monitors the activity of these components and reacts to the changes in their use.
						</p><p class="simpara">
							By default, dynamic tuning is disabled. To enable it, edit the <code class="literal filename">/etc/tuned/tuned-main.conf</code> file and change the <code class="literal option">dynamic_tuning</code> option to <code class="literal">1</code>. <span class="strong strong"><strong>TuneD</strong></span> then periodically analyzes system statistics and uses them to update your system tuning settings. To configure the time interval in seconds between these updates, use the <code class="literal option">update_interval</code> option.
						</p><p class="simpara">
							Currently implemented dynamic tuning algorithms try to balance the performance and powersave, and are therefore disabled in the performance profiles. Dynamic tuning for individual plug-ins can be enabled or disabled in the <span class="strong strong"><strong>TuneD</strong></span> profiles.
						</p></dd></dl></div><div class="example" id="idm140280148199536"><p class="title"><strong>Example 1.2. Static and dynamic tuning on a workstation</strong></p><div class="example-contents"><p>
					On a typical office workstation, the Ethernet network interface is inactive most of the time. Only a few emails go in and out or some web pages might be loaded.
				</p><p>
					For those kinds of loads, the network interface does not have to run at full speed all the time, as it does by default. <span class="strong strong"><strong>TuneD</strong></span> has a monitoring and tuning plug-in for network devices that can detect this low activity and then automatically lower the speed of that interface, typically resulting in a lower power usage.
				</p><p>
					If the activity on the interface increases for a longer period of time, for example because a DVD image is being downloaded or an email with a large attachment is opened, <span class="strong strong"><strong>TuneD</strong></span> detects this and sets the interface speed to maximum to offer the best performance while the activity level is high.
				</p><p>
					This principle is used for other plug-ins for CPU and disks as well.
				</p></div></div></section><section class="section" id="tuned-no-daemon-mode_getting-started-with-tuned"><div class="titlepage"><div><div><h3 class="title">1.12. TuneD no-daemon mode</h3></div></div></div><p class="_abstract _abstract">
				You can run <span class="strong strong"><strong>TuneD</strong></span> in <code class="literal">no-daemon</code> mode, which does not require any resident memory. In this mode, <span class="strong strong"><strong>TuneD</strong></span> applies the settings and exits.
			</p><p>
				By default, <code class="literal">no-daemon</code> mode is disabled because a lot of <span class="strong strong"><strong>TuneD</strong></span> functionality is missing in this mode, including:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						D-Bus support
					</li><li class="listitem">
						Hot-plug support
					</li><li class="listitem">
						Rollback support for settings
					</li></ul></div><p>
				To enable <code class="literal">no-daemon</code> mode, include the following line in the <code class="literal filename">/etc/tuned/tuned-main.conf</code> file:
			</p><pre class="screen">daemon = 0</pre></section><section class="section" id="installing-and-enabling-tuned_getting-started-with-tuned"><div class="titlepage"><div><div><h3 class="title">1.13. Installing and enabling TuneD</h3></div></div></div><p class="_abstract _abstract">
				This procedure installs and enables the <span class="strong strong"><strong>TuneD</strong></span> application, installs <span class="strong strong"><strong>TuneD</strong></span> profiles, and presets a default <span class="strong strong"><strong>TuneD</strong></span> profile for your system.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Install the <code class="literal package">TuneD</code> package:
					</p><pre class="screen"># dnf install tuned</pre></li><li class="listitem"><p class="simpara">
						Enable and start the <code class="literal">TuneD</code> service:
					</p><pre class="screen"># systemctl enable --now tuned</pre></li><li class="listitem"><p class="simpara">
						Optional: Install <span class="strong strong"><strong>TuneD</strong></span> profiles for real-time systems:
					</p><p class="simpara">
						For the <span class="strong strong"><strong>TuneD</strong></span> profiles for real-time systems enable <code class="literal">rhel-9</code> repository.
					</p><pre class="screen"># subscription-manager repos --enable=rhel-9-for-x86_64-nfv-beta-rpms</pre><p class="simpara">
						Install it.
					</p><pre class="screen"># dnf install tuned-profiles-realtime tuned-profiles-nfv</pre></li><li class="listitem"><p class="simpara">
						Verify that a <span class="strong strong"><strong>TuneD</strong></span> profile is active and applied:
					</p><pre class="screen">$ tuned-adm active

Current active profile: <span class="emphasis"><em><span class="replaceable replaceable">throughput-performance</span></em></span></pre><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
							The active profile TuneD automatically presets differs based on your machine type and system settings.
						</p></div></rh-alert><pre class="screen">$ tuned-adm verify

Verification succeeded, current system settings match the preset profile.
See tuned log file ('/var/log/tuned/tuned.log') for details.</pre></li></ol></div></section><section class="section" id="listing-available-tuned-profiles_getting-started-with-tuned"><div class="titlepage"><div><div><h3 class="title">1.14. Listing available TuneD profiles</h3></div></div></div><p class="_abstract _abstract">
				This procedure lists all <span class="strong strong"><strong>TuneD</strong></span> profiles that are currently available on your system.
			</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						To list all available <span class="strong strong"><strong>TuneD</strong></span> profiles on your system, use:
					</p><pre class="screen white-space-pre white-space-pre">$ <span class="strong strong"><strong>tuned-adm list</strong></span>

Available profiles:
- accelerator-performance - Throughput performance based tuning with disabled higher latency STOP states
- balanced                - General non-specialized TuneD profile
- desktop                 - Optimize for the desktop use-case
- latency-performance     - Optimize for deterministic performance at the cost of increased power consumption
- network-latency         - Optimize for deterministic performance at the cost of increased power consumption, focused on low latency network performance
- network-throughput      - Optimize for streaming network throughput, generally only necessary on older CPUs or 40G+ networks
- powersave               - Optimize for low power consumption
- throughput-performance  - Broadly applicable tuning that provides excellent performance across a variety of common server workloads
- virtual-guest           - Optimize for running inside a virtual guest
- virtual-host            - Optimize for running KVM guests
Current active profile: <span class="emphasis"><em><span class="replaceable replaceable">balanced</span></em></span></pre></li><li class="listitem"><p class="simpara">
						To display only the currently active profile, use:
					</p><pre class="screen">$ <span class="strong strong"><strong>tuned-adm active</strong></span>

Current active profile: <span class="emphasis"><em><span class="replaceable replaceable">throughput-performance</span></em></span></pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">tuned-adm(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="setting-a-tuned-profile_getting-started-with-tuned"><div class="titlepage"><div><div><h3 class="title">1.15. Setting a TuneD profile</h3></div></div></div><p class="_abstract _abstract">
				This procedure activates a selected <span class="strong strong"><strong>TuneD</strong></span> profile on your system.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						The <code class="literal">TuneD</code> service is running. See <a class="link" href="#installing-and-enabling-tuned_getting-started-with-tuned" title="1.13. Installing and enabling TuneD">Installing and Enabling TuneD</a> for details.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Optional: You can let <span class="strong strong"><strong>TuneD</strong></span> recommend the most suitable profile for your system:
					</p><pre class="screen"># tuned-adm recommend

<span class="emphasis"><em><span class="replaceable replaceable">throughput-performance</span></em></span></pre></li><li class="listitem"><p class="simpara">
						Activate a profile:
					</p><pre class="screen"># tuned-adm profile <span class="emphasis"><em><span class="replaceable replaceable">selected-profile</span></em></span></pre><p class="simpara">
						Alternatively, you can activate a combination of multiple profiles:
					</p><pre class="screen"># tuned-adm profile <span class="emphasis"><em><span class="replaceable replaceable">selected-profile1</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">selected-profile2</span></em></span></pre><div class="example" id="idm140280148419296"><p class="title"><strong>Example 1.3. A virtual machine optimized for low power consumption</strong></p><div class="example-contents"><p>
							The following example optimizes the system to run in a virtual machine with the best performance and concurrently tunes it for low power consumption, while the low power consumption is the priority:
						</p><pre class="screen"># tuned-adm profile virtual-guest powersave</pre></div></div></li><li class="listitem"><p class="simpara">
						View the current active <span class="strong strong"><strong>TuneD</strong></span> profile on your system:
					</p><pre class="screen"># tuned-adm active

Current active profile: <span class="emphasis"><em><span class="replaceable replaceable">selected-profile</span></em></span></pre></li><li class="listitem"><p class="simpara">
						Reboot the system:
					</p><pre class="screen"># reboot</pre></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Verify that the <span class="strong strong"><strong>TuneD</strong></span> profile is active and applied:
					</p><pre class="screen">$ tuned-adm verify

Verification succeeded, current system settings match the preset profile.
See tuned log file ('/var/log/tuned/tuned.log') for details.</pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">tuned-adm(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="using-the-tuned-d-bus-interface_getting-started-with-tuned"><div class="titlepage"><div><div><h3 class="title">1.16. Using the TuneD D-Bus interface</h3></div></div></div><p class="_abstract _abstract">
				You can directly communicate with TuneD at runtime through the TuneD D-Bus interface to control a variety of TuneD services.
			</p><p>
				You can use the <code class="literal">busctl</code> or <code class="literal">dbus-send</code> commands to access the D-Bus API.
			</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					Although you can use either the <code class="literal">busctl</code> or <code class="literal">dbus-send</code> command, the <code class="literal">busctl</code> command is a part of <code class="literal">systemd</code> and, therefore, present on most hosts already.
				</p></div></rh-alert><section class="section" id="using-the-tuned-d-bus-interface-to-show-available-tuned-d-bus-api-methods_using-the-tuned-d-bus-interface"><div class="titlepage"><div><div><h4 class="title">1.16.1. Using the TuneD D-Bus interface to show available TuneD D-Bus API methods</h4></div></div></div><p class="_abstract _abstract">
					You can see the D-Bus API methods available to use with TuneD by using the TuneD D-Bus interface.
				</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							The TuneD service is running. See <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-tuned_monitoring-and-managing-system-status-and-performance#installing-and-enabling-tuned_getting-started-with-tuned">Installing and Enabling TuneD</a> for details.
						</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							To see the available TuneD API methods, run:
						</p><pre class="screen">$ busctl introspect com.redhat.tuned /Tuned com.redhat.tuned.control</pre><p class="simpara">
							The output should look similar to the following:
						</p><pre class="literallayout">NAME                       	TYPE  	SIGNATURE RESULT/VALUE FLAGS
.active_profile            	method	-     	  s            -
.auto_profile              	method	-     	  (bs)         -
.disable                   	method	-      	  b            -
.get_all_plugins           	method	-     	  a{sa{ss}}    -
.get_plugin_documentation  	method	s     	  s            -
.get_plugin_hints          	method	s     	  a{ss}        -
.instance_acquire_devices  	method	ss    	  (bs)         -
.is_running                	method	-     	  b            -
.log_capture_finish        	method	s     	  s            -
.log_capture_start         	method	ii    	  s            -
.post_loaded_profile       	method	-     	  s            -
.profile_info              	method	s     	  (bsss)       -
.profile_mode              	method	-     	  (ss)         -
.profiles                  	method	-     	  as           -
.profiles2                 	method	-     	  a(ss)        -
.recommend_profile         	method	-     	  s            -
.register_socket_signal_path    method	s     	  b            -
.reload                    	method	-     	  b            -
.start                     	method	-     	  b            -
.stop                      	method	-     	  b            -
.switch_profile            	method	s     	  (bs)         -
.verify_profile            	method	-     	  b            -
.verify_profile_ignore_missing  method	-     	  b            -
.profile_changed           	signal	sbs   	  -            -</pre><p class="simpara">
							You can find descriptions of the different available methods in the <a class="link" href="https://github.com/redhat-performance/tuned/blob/master/com.redhat.tuned.policy">TuneD upstream repository</a>.
						</p></li></ul></div></section><section class="section" id="using-the-tuned-d-bus-interface-to-change-the-active-tuned-profile_using-the-tuned-d-bus-interface"><div class="titlepage"><div><div><h4 class="title">1.16.2. Using the TuneD D-Bus interface to change the active TuneD profile</h4></div></div></div><p class="_abstract _abstract">
					You can replace the active TuneD profile with your desired TuneD profile by using the TuneD D-Bus interface.
				</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							The TuneD service is running. See <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-tuned_monitoring-and-managing-system-status-and-performance#installing-and-enabling-tuned_getting-started-with-tuned">Installing and Enabling TuneD</a> for details.
						</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							To change the active TuneD profile, run:
						</p><pre class="literallayout">$ busctl call com.redhat.tuned /Tuned com.redhat.tuned.control switch_profile s <span class="emphasis"><em>profile</em></span>
(bs) true "OK"</pre><p class="simpara">
							Replace <span class="emphasis"><em>profile</em></span> with the name of your desired profile.
						</p></li></ul></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							To view the current active TuneD profile, run:
						</p><pre class="literallayout">$ busctl call com.redhat.tuned /Tuned com.redhat.tuned.control active_profile
s "<span class="emphasis"><em>profile</em></span>"</pre></li></ul></div></section></section><section class="section" id="disabling-tuned_getting-started-with-tuned"><div class="titlepage"><div><div><h3 class="title">1.17. Disabling TuneD</h3></div></div></div><p class="_abstract _abstract">
				This procedure disables <span class="strong strong"><strong>TuneD</strong></span> and resets all affected system settings to their original state before <span class="strong strong"><strong>TuneD</strong></span> modified them.
			</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						To disable all tunings temporarily:
					</p><pre class="screen"># tuned-adm off</pre><p class="simpara">
						The tunings are applied again after the <code class="literal">TuneD</code> service restarts.
					</p></li><li class="listitem"><p class="simpara">
						Alternatively, to stop and disable the <code class="literal">TuneD</code> service permanently:
					</p><pre class="screen"># systemctl disable --now tuned</pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">tuned-adm(8)</code> man page on your system
					</li></ul></div></section></section><section class="chapter" id="customizing-tuned-profiles_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 2. Customizing TuneD profiles</h2></div></div></div><p class="_abstract _abstract">
			You can create or modify <span class="strong strong"><strong>TuneD</strong></span> profiles to optimize system performance for your intended use case.
		</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
					Install and enable <span class="strong strong"><strong>TuneD</strong></span> as described in <a class="link" href="#installing-and-enabling-tuned_getting-started-with-tuned" title="1.13. Installing and enabling TuneD">Installing and Enabling TuneD</a> for details.
				</li></ul></div><section class="section" id="tuned-profiles_customizing-tuned-profiles"><div class="titlepage"><div><div><h3 class="title">2.1. TuneD profiles</h3></div></div></div><p class="_abstract _abstract">
				A detailed analysis of a system can be very time-consuming. <span class="strong strong"><strong>TuneD</strong></span> provides a number of predefined profiles for typical use cases. You can also create, modify, and delete profiles.
			</p><p>
				The profiles provided with <span class="strong strong"><strong>TuneD</strong></span> are divided into the following categories:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Power-saving profiles
					</li><li class="listitem">
						Performance-boosting profiles
					</li></ul></div><p>
				The performance-boosting profiles include profiles that focus on the following aspects:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Low latency for storage and network
					</li><li class="listitem">
						High throughput for storage and network
					</li><li class="listitem">
						Virtual machine performance
					</li><li class="listitem">
						Virtualization host performance
					</li></ul></div><h5 id="syntax_of_profile_configuration_2">Syntax of profile configuration</h5><p>
				The <code class="literal">tuned.conf</code> file can contain one <code class="literal">[main]</code> section and other sections for configuring plug-in instances. However, all sections are optional.
			</p><p>
				Lines starting with the hash sign (<code class="literal">#</code>) are comments.
			</p><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">tuned.conf(5)</code> man page on your system
					</li></ul></div></section><section class="section" id="the-default-tuned-profile_customizing-tuned-profiles"><div class="titlepage"><div><div><h3 class="title">2.2. The default TuneD profile</h3></div></div></div><p class="_abstract _abstract">
				During the installation, the best profile for your system is selected automatically. Currently, the default profile is selected according to the following customizable rules:
			</p><rh-table><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 29%; " class="col_1"><!--Empty--><col style="width: 29%; " class="col_2"><!--Empty--><col style="width: 43%; " class="col_3"><!--Empty--></colgroup><thead><tr><th align="left" valign="top" id="idm140280148905584" scope="col">Environment</th><th align="left" valign="top" id="idm140280149435088" scope="col">Default profile</th><th align="left" valign="top" id="idm140280149434000" scope="col">Goal</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm140280148905584"> <p>
								Compute nodes
							</p>
							 </td><td align="left" valign="top" headers="idm140280149435088"> <p>
								<code class="literal">throughput-performance</code>
							</p>
							 </td><td align="left" valign="top" headers="idm140280149434000"> <p>
								The best throughput performance
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm140280148905584"> <p>
								Virtual machines
							</p>
							 </td><td align="left" valign="top" headers="idm140280149435088"> <p>
								<code class="literal">virtual-guest</code>
							</p>
							 </td><td align="left" valign="top" headers="idm140280149434000"> <p>
								The best performance. If you are not interested in the best performance, you can change it to the <code class="literal">balanced</code> or <code class="literal">powersave</code> profile.
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm140280148905584"> <p>
								Other cases
							</p>
							 </td><td align="left" valign="top" headers="idm140280149435088"> <p>
								<code class="literal">balanced</code>
							</p>
							 </td><td align="left" valign="top" headers="idm140280149434000"> <p>
								Balanced performance and power consumption
							</p>
							 </td></tr></tbody></table></rh-table><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">tuned.conf(5)</code> man page on your system
					</li></ul></div></section><section class="section" id="merged-tuned-profiles_customizing-tuned-profiles"><div class="titlepage"><div><div><h3 class="title">2.3. Merged TuneD profiles</h3></div></div></div><p class="_abstract _abstract">
				As an experimental feature, it is possible to select more profiles at once. <span class="strong strong"><strong>TuneD</strong></span> will try to merge them during the load.
			</p><p>
				If there are conflicts, the settings from the last specified profile takes precedence.
			</p><div class="example" id="idm140280159482160"><p class="title"><strong>Example 2.1. Low power consumption in a virtual guest</strong></p><div class="example-contents"><p>
					The following example optimizes the system to run in a virtual machine for the best performance and concurrently tunes it for low power consumption, while the low power consumption is the priority:
				</p><pre class="screen"># tuned-adm profile virtual-guest powersave</pre></div></div><rh-alert class="admonition warning" state="danger"><div class="admonition_header" slot="header">Warning</div><div><p>
					Merging is done automatically without checking whether the resulting combination of parameters makes sense. Consequently, the feature might tune some parameters the opposite way, which might be counterproductive: for example, setting the disk for high throughput by using the <code class="literal">throughput-performance</code> profile and concurrently setting the disk spindown to the low value by the <code class="literal">spindown-disk</code> profile.
				</p></div></rh-alert><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">tuned-adm</code> and <code class="literal">tuned.conf(5)</code> man pages on your system
					</li></ul></div></section><section class="section" id="the-location-of-tuned-profiles_customizing-tuned-profiles"><div class="titlepage"><div><div><h3 class="title">2.4. The location of TuneD profiles</h3></div></div></div><p class="_abstract _abstract">
				<span class="strong strong"><strong>TuneD</strong></span> stores profiles in the following directories:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal filename">/usr/lib/tuned/</code></span></dt><dd>
							Distribution-specific profiles are stored in the directory. Each profile has its own directory. The profile consists of the main configuration file called <code class="literal">tuned.conf</code>, and optionally other files, for example helper scripts.
						</dd><dt><span class="term"><code class="literal filename">/etc/tuned/</code></span></dt><dd>
							If you need to customize a profile, copy the profile directory into the directory, which is used for custom profiles. If there are two profiles of the same name, the custom profile located in <code class="literal filename">/etc/tuned/</code> is used.
						</dd></dl></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">tuned.conf(5)</code> man page on your system
					</li></ul></div></section><section class="section" id="inheritance-between-tuned-profiles_customizing-tuned-profiles"><div class="titlepage"><div><div><h3 class="title">2.5. Inheritance between TuneD profiles</h3></div></div></div><p class="_abstract _abstract">
				<span class="strong strong"><strong>TuneD</strong></span> profiles can be based on other profiles and modify only certain aspects of their parent profile.
			</p><p>
				The <code class="literal">[main]</code> section of <span class="strong strong"><strong>TuneD</strong></span> profiles recognizes the <code class="literal option">include</code> option:
			</p><pre class="screen">[main]
include=<span class="emphasis"><em><span class="replaceable replaceable">parent</span></em></span></pre><p>
				All settings from the <span class="emphasis"><em><span class="replaceable replaceable">parent</span></em></span> profile are loaded in this <span class="emphasis"><em>child</em></span> profile. In the following sections, the <span class="emphasis"><em>child</em></span> profile can override certain settings inherited from the <span class="emphasis"><em><span class="replaceable replaceable">parent</span></em></span> profile or add new settings not present in the <span class="emphasis"><em><span class="replaceable replaceable">parent</span></em></span> profile.
			</p><p>
				You can create your own <span class="emphasis"><em>child</em></span> profile in the <code class="literal filename">/etc/tuned/</code> directory based on a pre-installed profile in <code class="literal filename">/usr/lib/tuned/</code> with only some parameters adjusted.
			</p><p>
				If the <span class="emphasis"><em><span class="replaceable replaceable">parent</span></em></span> profile is updated, such as after a <span class="strong strong"><strong>TuneD</strong></span> upgrade, the changes are reflected in the <span class="emphasis"><em>child</em></span> profile.
			</p><div class="example" id="idm140280153160048"><p class="title"><strong>Example 2.2. A power-saving profile based on balanced</strong></p><div class="example-contents"><p>
					The following is an example of a custom profile that extends the <code class="literal">balanced</code> profile and sets Aggressive Link Power Management (ALPM) for all devices to the maximum powersaving.
				</p><pre class="screen">[main]
include=balanced

[scsi_host]
alpm=min_power</pre></div></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">tuned.conf(5)</code> man page on your system
					</li></ul></div></section><section class="section" id="static-and-dynamic-tuning-in-tuned_customizing-tuned-profiles"><div class="titlepage"><div><div><h3 class="title">2.6. Static and dynamic tuning in TuneD</h3></div></div></div><p class="_abstract _abstract">
				Understanding the difference between the two categories of system tuning that <span class="strong strong"><strong>TuneD</strong></span> applies, <span class="emphasis"><em>static</em></span> and <span class="emphasis"><em>dynamic</em></span>, is important when determining which one to use for a given situation or purpose.
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">Static tuning</span></dt><dd>
							Mainly consists of the application of predefined <code class="literal">sysctl</code> and <code class="literal">sysfs</code> settings and one-shot activation of several configuration tools such as <code class="literal">ethtool</code>.
						</dd><dt><span class="term">Dynamic tuning</span></dt><dd><p class="simpara">
							Watches how various system components are used throughout the uptime of your system. <span class="strong strong"><strong>TuneD</strong></span> adjusts system settings dynamically based on that monitoring information.
						</p><p class="simpara">
							For example, the hard drive is used heavily during startup and login, but is barely used later when the user might mainly work with applications such as web browsers or email clients. Similarly, the CPU and network devices are used differently at different times. <span class="strong strong"><strong>TuneD</strong></span> monitors the activity of these components and reacts to the changes in their use.
						</p><p class="simpara">
							By default, dynamic tuning is disabled. To enable it, edit the <code class="literal filename">/etc/tuned/tuned-main.conf</code> file and change the <code class="literal option">dynamic_tuning</code> option to <code class="literal">1</code>. <span class="strong strong"><strong>TuneD</strong></span> then periodically analyzes system statistics and uses them to update your system tuning settings. To configure the time interval in seconds between these updates, use the <code class="literal option">update_interval</code> option.
						</p><p class="simpara">
							Currently implemented dynamic tuning algorithms try to balance the performance and powersave, and are therefore disabled in the performance profiles. Dynamic tuning for individual plug-ins can be enabled or disabled in the <span class="strong strong"><strong>TuneD</strong></span> profiles.
						</p></dd></dl></div><div class="example" id="idm140280143659776"><p class="title"><strong>Example 2.3. Static and dynamic tuning on a workstation</strong></p><div class="example-contents"><p>
					On a typical office workstation, the Ethernet network interface is inactive most of the time. Only a few emails go in and out or some web pages might be loaded.
				</p><p>
					For those kinds of loads, the network interface does not have to run at full speed all the time, as it does by default. <span class="strong strong"><strong>TuneD</strong></span> has a monitoring and tuning plug-in for network devices that can detect this low activity and then automatically lower the speed of that interface, typically resulting in a lower power usage.
				</p><p>
					If the activity on the interface increases for a longer period of time, for example because a DVD image is being downloaded or an email with a large attachment is opened, <span class="strong strong"><strong>TuneD</strong></span> detects this and sets the interface speed to maximum to offer the best performance while the activity level is high.
				</p><p>
					This principle is used for other plug-ins for CPU and disks as well.
				</p></div></div></section><section class="section" id="tuned-plug-ins_customizing-tuned-profiles"><div class="titlepage"><div><div><h3 class="title">2.7. TuneD plug-ins</h3></div></div></div><p class="_abstract _abstract">
				Plug-ins are modules in <span class="strong strong"><strong>TuneD</strong></span> profiles that <span class="strong strong"><strong>TuneD</strong></span> uses to monitor or optimize different devices on the system.
			</p><p>
				<span class="strong strong"><strong>TuneD</strong></span> uses two types of plug-ins:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">Monitoring plug-ins</span></dt><dd><p class="simpara">
							Monitoring plug-ins are used to get information from a running system. The output of the monitoring plug-ins can be used by tuning plug-ins for dynamic tuning.
						</p><p class="simpara">
							Monitoring plug-ins are automatically instantiated whenever their metrics are needed by any of the enabled tuning plug-ins. If two tuning plug-ins require the same data, only one instance of the monitoring plug-in is created and the data is shared.
						</p></dd><dt><span class="term">Tuning plug-ins</span></dt><dd>
							Each tuning plug-in tunes an individual subsystem and takes several parameters that are populated from the TuneD profiles. Each subsystem can have multiple devices, such as multiple CPUs or network cards, that are handled by individual instances of the tuning plug-ins. Specific settings for individual devices are also supported.
						</dd></dl></div><h5 id="syntax_for_plug_ins_in_tuned_profiles">Syntax for plug-ins in TuneD profiles</h5><p>
				Sections describing plug-in instances are formatted in the following way:
			</p><pre class="screen">[<span class="emphasis"><em>NAME</em></span>]
type=<span class="emphasis"><em>TYPE</em></span>
devices=<span class="emphasis"><em>DEVICES</em></span></pre><div class="variablelist"><dl class="variablelist"><dt><span class="term">NAME</span></dt><dd>
							is the name of the plug-in instance as it is used in the logs. It can be an arbitrary string.
						</dd><dt><span class="term">TYPE</span></dt><dd>
							is the type of the tuning plug-in.
						</dd><dt><span class="term">DEVICES</span></dt><dd><p class="simpara">
							is the list of devices that this plug-in instance handles.
						</p><p class="simpara">
							The <code class="literal">devices</code> line can contain a list, a wildcard (<code class="literal">*</code>), and negation (<code class="literal">!</code>). If there is no <code class="literal">devices</code> line, all devices present or later attached on the system of the <span class="emphasis"><em><span class="replaceable replaceable">TYPE</span></em></span> are handled by the plug-in instance. This is same as using the <code class="literal option">devices=*</code> option.
						</p><div class="example" id="idm140280160531840"><p class="title"><strong>Example 2.4. Matching block devices with a plug-in</strong></p><div class="example-contents"><p>
								The following example matches all block devices starting with <code class="literal">sd</code>, such as <code class="literal">sda</code> or <code class="literal">sdb</code>, and does not disable barriers on them:
							</p><pre class="screen">[data_disk]
type=disk
devices=sd*
disable_barriers=false</pre><p>
								The following example matches all block devices except <code class="literal">sda1</code> and <code class="literal">sda2</code>:
							</p><pre class="screen">[data_disk]
type=disk
devices=!sda1, !sda2
disable_barriers=false</pre></div></div></dd></dl></div><p>
				If no instance of a plug-in is specified, the plug-in is not enabled.
			</p><p>
				If the plug-in supports more options, they can be also specified in the plug-in section. If the option is not specified and it was not previously specified in the included plug-in, the default value is used.
			</p><h5 id="short_plug_in_syntax">Short plug-in syntax</h5><p>
				If you do not need custom names for the plug-in instance and there is only one definition of the instance in your configuration file, <span class="strong strong"><strong>TuneD</strong></span> supports the following short syntax:
			</p><pre class="screen">[<span class="emphasis"><em>TYPE</em></span>]
devices=<span class="emphasis"><em>DEVICES</em></span></pre><p>
				In this case, it is possible to omit the <code class="literal">type</code> line. The instance is then referred to with a name, same as the type. The previous example could be then rewritten into:
			</p><div class="example" id="idm140280155091088"><p class="title"><strong>Example 2.5. Matching block devices using the short syntax</strong></p><div class="example-contents"><pre class="screen">[disk]
devices=sdb*
disable_barriers=false</pre></div></div><h5 id="conflicting_plug_in_definitions_in_a_profile">Conflicting plug-in definitions in a profile</h5><p>
				If the same section is specified more than once using the <code class="literal">include</code> option, the settings are merged. If they cannot be merged due to a conflict, the last conflicting definition overrides the previous settings. If you do not know what was previously defined, you can use the <code class="literal option">replace</code> Boolean option and set it to <code class="literal">true</code>. This causes all the previous definitions with the same name to be overwritten and the merge does not happen.
			</p><p>
				You can also disable the plug-in by specifying the <code class="literal option">enabled=false</code> option. This has the same effect as if the instance was never defined. Disabling the plug-in is useful if you are redefining the previous definition from the <code class="literal option">include</code> option and do not want the plug-in to be active in your custom profile.
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">NOTE</span></dt><dd><p class="simpara">
							<span class="strong strong"><strong>TuneD</strong></span> includes the ability to run any shell command as part of enabling or disabling a tuning profile. This enables you to extend <span class="strong strong"><strong>TuneD</strong></span> profiles with functionality that has not been integrated into TuneD yet.
						</p><p class="simpara">
							You can specify arbitrary shell commands using the <code class="literal">script</code> plug-in.
						</p></dd></dl></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">tuned.conf(5)</code> man page on your system
					</li></ul></div></section><section class="section" id="available-tuned-plug-ins_customizing-tuned-profiles"><div class="titlepage"><div><div><h3 class="title">2.8. Available TuneD plug-ins</h3></div></div></div><h5 id="monitoring_plug_ins">Monitoring plug-ins</h5><p>
				Currently, the following monitoring plug-ins are implemented:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">disk</code></span></dt><dd>
							Gets disk load (number of IO operations) per device and measurement interval.
						</dd><dt><span class="term"><code class="literal">net</code></span></dt><dd>
							Gets network load (number of transferred packets) per network card and measurement interval.
						</dd><dt><span class="term"><code class="literal">load</code></span></dt><dd>
							Gets CPU load per CPU and measurement interval.
						</dd></dl></div><h5 id="tuning_plug_ins">Tuning plug-ins</h5><p>
				Currently, the following tuning plug-ins are implemented. Only some of these plug-ins implement dynamic tuning. Options supported by plug-ins are also listed:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">cpu</code></span></dt><dd><p class="simpara">
							Sets the CPU governor to the value specified by the <code class="literal option">governor</code> option and dynamically changes the Power Management Quality of Service (PM QoS) CPU Direct Memory Access (DMA) latency according to the CPU load.
						</p><p class="simpara">
							If the CPU load is lower than the value specified by the <code class="literal option">load_threshold</code> option, the latency is set to the value specified by the <code class="literal option">latency_high</code> option, otherwise it is set to the value specified by <code class="literal option">latency_low</code>.
						</p><p class="simpara">
							You can also force the latency to a specific value and prevent it from dynamically changing further. To do so, set the <code class="literal option">force_latency</code> option to the required latency value.
						</p></dd><dt><span class="term"><code class="literal">eeepc_she</code></span></dt><dd><p class="simpara">
							Dynamically sets the front-side bus (FSB) speed according to the CPU load.
						</p><p class="simpara">
							This feature can be found on some netbooks and is also known as the ASUS Super Hybrid Engine (SHE).
						</p><p class="simpara">
							If the CPU load is lower or equal to the value specified by the <code class="literal option">load_threshold_powersave</code> option, the plug-in sets the FSB speed to the value specified by the <code class="literal option">she_powersave</code> option. If the CPU load is higher or equal to the value specified by the <code class="literal option">load_threshold_normal</code> option, it sets the FSB speed to the value specified by the <code class="literal option">she_normal</code> option.
						</p><p class="simpara">
							Static tuning is not supported and the plug-in is transparently disabled if <span class="strong strong"><strong>TuneD</strong></span> does not detect the hardware support for this feature.
						</p></dd><dt><span class="term"><code class="literal">net</code></span></dt><dd>
							Configures the Wake-on-LAN functionality to the values specified by the <code class="literal option">wake_on_lan</code> option. It uses the same syntax as the <code class="literal">ethtool</code> utility. It also dynamically changes the interface speed according to the interface utilization.
						</dd><dt><span class="term"><code class="literal">sysctl</code></span></dt><dd><p class="simpara">
							Sets various <code class="literal">sysctl</code> settings specified by the plug-in options.
						</p><p class="simpara">
							The syntax is <code class="literal"><span class="emphasis"><em><span class="replaceable replaceable">name</span></em></span>=<span class="emphasis"><em><span class="replaceable replaceable">value</span></em></span></code>, where <span class="emphasis"><em><span class="replaceable replaceable">name</span></em></span> is the same as the name provided by the <code class="literal">sysctl</code> utility.
						</p><p class="simpara">
							Use the <code class="literal">sysctl</code> plug-in if you need to change system settings that are not covered by other plug-ins available in <span class="strong strong"><strong>TuneD</strong></span>. If the settings are covered by some specific plug-ins, prefer these plug-ins.
						</p></dd><dt><span class="term"><code class="literal">usb</code></span></dt><dd><p class="simpara">
							Sets autosuspend timeout of USB devices to the value specified by the <code class="literal option">autosuspend</code> parameter.
						</p><p class="simpara">
							The value <code class="literal">0</code> means that autosuspend is disabled.
						</p></dd><dt><span class="term"><code class="literal">vm</code></span></dt><dd><p class="simpara">
							Enables or disables transparent huge pages depending on the value of the <code class="literal option">transparent_hugepages</code> option.
						</p><p class="simpara">
							Valid values of the <code class="literal option">transparent_hugepages</code> option are:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									"always"
								</li><li class="listitem">
									"never"
								</li><li class="listitem">
									"madvise"
								</li></ul></div></dd><dt><span class="term"><code class="literal">audio</code></span></dt><dd><p class="simpara">
							Sets the autosuspend timeout for audio codecs to the value specified by the <code class="literal option">timeout</code> option.
						</p><p class="simpara">
							Currently, the <code class="literal">snd_hda_intel</code> and <code class="literal">snd_ac97_codec</code> codecs are supported. The value <code class="literal">0</code> means that the autosuspend is disabled. You can also enforce the controller reset by setting the Boolean option <code class="literal option">reset_controller</code> to <code class="literal">true</code>.
						</p></dd><dt><span class="term"><code class="literal">disk</code></span></dt><dd><p class="simpara">
							Sets the disk elevator to the value specified by the <code class="literal option">elevator</code> option.
						</p><p class="simpara">
							It also sets:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									APM to the value specified by the <code class="literal option">apm</code> option
								</li><li class="listitem">
									Scheduler quantum to the value specified by the <code class="literal option">scheduler_quantum</code> option
								</li><li class="listitem">
									Disk spindown timeout to the value specified by the <code class="literal option">spindown</code> option
								</li><li class="listitem">
									Disk readahead to the value specified by the <code class="literal option">readahead</code> parameter
								</li><li class="listitem">
									The current disk readahead to a value multiplied by the constant specified by the <code class="literal option">readahead_multiply</code> option
								</li></ul></div><p class="simpara">
							In addition, this plug-in dynamically changes the advanced power management and spindown timeout setting for the drive according to the current drive utilization. The dynamic tuning can be controlled by the Boolean option <code class="literal option">dynamic</code> and is enabled by default.
						</p></dd><dt><span class="term"><code class="literal">scsi_host</code></span></dt><dd><p class="simpara">
							Tunes options for SCSI hosts.
						</p><p class="simpara">
							It sets Aggressive Link Power Management (ALPM) to the value specified by the <code class="literal option">alpm</code> option.
						</p></dd><dt><span class="term"><code class="literal">mounts</code></span></dt><dd>
							Enables or disables barriers for mounts according to the Boolean value of the <code class="literal option">disable_barriers</code> option.
						</dd><dt><span class="term"><code class="literal">script</code></span></dt><dd><p class="simpara">
							Executes an external script or binary when the profile is loaded or unloaded. You can choose an arbitrary executable.
						</p><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
								The <code class="literal">script</code> plug-in is provided mainly for compatibility with earlier releases. Prefer other <span class="strong strong"><strong>TuneD</strong></span> plug-ins if they cover the required functionality.
							</p></div></rh-alert><p class="simpara">
							<span class="strong strong"><strong>TuneD</strong></span> calls the executable with one of the following arguments:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									<code class="literal">start</code> when loading the profile
								</li><li class="listitem">
									<code class="literal">stop</code> when unloading the profile
								</li></ul></div><p class="simpara">
							You need to correctly implement the <code class="literal">stop</code> action in your executable and revert all settings that you changed during the <code class="literal">start</code> action. Otherwise, the roll-back step after changing your <span class="strong strong"><strong>TuneD</strong></span> profile will not work.
						</p><p class="simpara">
							Bash scripts can import the <code class="literal filename">/usr/lib/tuned/functions</code> Bash library and use the functions defined there. Use these functions only for functionality that is not natively provided by <span class="strong strong"><strong>TuneD</strong></span>. If a function name starts with an underscore, such as <code class="literal">_wifi_set_power_level</code>, consider the function private and do not use it in your scripts, because it might change in the future.
						</p><p class="simpara">
							Specify the path to the executable using the <code class="literal">script</code> parameter in the plug-in configuration.
						</p><div class="example" id="idm140280155386608"><p class="title"><strong>Example 2.6. Running a Bash script from a profile</strong></p><div class="example-contents"><p>
								To run a Bash script named <code class="literal">script.sh</code> that is located in the profile directory, use:
							</p><pre class="screen">[script]
script=${i:PROFILE_DIR}/script.sh</pre></div></div></dd><dt><span class="term"><code class="literal">sysfs</code></span></dt><dd><p class="simpara">
							Sets various <code class="literal">sysfs</code> settings specified by the plug-in options.
						</p><p class="simpara">
							The syntax is <code class="literal"><span class="emphasis"><em><span class="replaceable replaceable">name</span></em></span>=<span class="emphasis"><em><span class="replaceable replaceable">value</span></em></span></code>, where <span class="emphasis"><em><span class="replaceable replaceable">name</span></em></span> is the <code class="literal">sysfs</code> path to use.
						</p><p class="simpara">
							Use this plugin in case you need to change some settings that are not covered by other plug-ins. Prefer specific plug-ins if they cover the required settings.
						</p></dd><dt><span class="term"><code class="literal">video</code></span></dt><dd><p class="simpara">
							Sets various powersave levels on video cards. Currently, only the Radeon cards are supported.
						</p><p class="simpara">
							The powersave level can be specified by using the <code class="literal option">radeon_powersave</code> option. Supported values are:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									<code class="literal">default</code>
								</li><li class="listitem">
									<code class="literal">auto</code>
								</li><li class="listitem">
									<code class="literal">low</code>
								</li><li class="listitem">
									<code class="literal">mid</code>
								</li><li class="listitem">
									<code class="literal">high</code>
								</li><li class="listitem">
									<code class="literal">dynpm</code>
								</li><li class="listitem">
									<code class="literal">dpm-battery</code>
								</li><li class="listitem">
									<code class="literal">dpm-balanced</code>
								</li><li class="listitem">
									<code class="literal">dpm-perfomance</code>
								</li></ul></div><p class="simpara">
							For details, see <a class="link" href="https://www.x.org/wiki/RadeonFeature/#KMS_Power_Management_Options">www.x.org</a>. Note that this plug-in is experimental and the option might change in future releases.
						</p></dd><dt><span class="term"><code class="literal">bootloader</code></span></dt><dd><p class="simpara">
							Adds options to the kernel command line. This plug-in supports only the GRUB 2 boot loader.
						</p><p class="simpara">
							Customized non-standard location of the GRUB 2 configuration file can be specified by the <code class="literal option">grub2_cfg_file</code> option.
						</p><p class="simpara">
							The kernel options are added to the current GRUB configuration and its templates. The system needs to be rebooted for the kernel options to take effect.
						</p><p class="simpara">
							Switching to another profile or manually stopping the <code class="literal">TuneD</code> service removes the additional options. If you shut down or reboot the system, the kernel options persist in the <code class="literal filename">grub.cfg</code> file.
						</p><p class="simpara">
							The kernel options can be specified by the following syntax:
						</p><pre class="screen">cmdline=<span class="emphasis"><em><span class="replaceable replaceable">arg1</span></em></span> <span class="emphasis"><em><span class="replaceable replaceable">arg2</span></em></span> ... <span class="emphasis"><em><span class="replaceable replaceable">argN</span></em></span></pre><div class="example" id="idm140280137455712"><p class="title"><strong>Example 2.7. Modifying the kernel command line</strong></p><div class="example-contents"><p>
								For example, to add the <code class="literal option">quiet</code> kernel option to a <span class="strong strong"><strong>TuneD</strong></span> profile, include the following lines in the <code class="literal filename">tuned.conf</code> file:
							</p><pre class="screen">[bootloader]
cmdline=quiet</pre><p>
								The following is an example of a custom profile that adds the <code class="literal option">isolcpus=2</code> option to the kernel command line:
							</p><pre class="screen">[bootloader]
cmdline=isolcpus=2</pre></div></div></dd><dt><span class="term"><code class="literal">service</code></span></dt><dd><p class="simpara">
							Handles various <code class="literal">sysvinit</code>, <code class="literal">sysv-rc</code>, <code class="literal">openrc</code>, and <code class="literal">systemd</code> services specified by the plug-in options.
						</p><p class="simpara">
							The syntax is <code class="literal">service.<span class="emphasis"><em>service_name</em></span>=<span class="emphasis"><em>command</em></span>[,file:<span class="emphasis"><em>file</em></span>]</code>.
						</p><p class="simpara">
							Supported service-handling commands are:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									<code class="literal">start</code>
								</li><li class="listitem">
									<code class="literal">stop</code>
								</li><li class="listitem">
									<code class="literal">enable</code>
								</li><li class="listitem">
									<code class="literal">disable</code>
								</li></ul></div><p class="simpara">
							Separate multiple commands using either a comma (<code class="literal">,</code>) or a semicolon (<code class="literal">;</code>). If the directives conflict, the <code class="literal">service</code> plugin uses the last listed one.
						</p><p class="simpara">
							Use the optional <code class="literal">file:<span class="emphasis"><em>file</em></span></code> directive to install an overlay configuration file, <code class="literal"><span class="emphasis"><em>file</em></span></code>, for <code class="literal">systemd</code> only. Other init systems ignore this directive. The <code class="literal">service</code> plugin copies overlay configuration files to <code class="literal">/etc/systemd/system/<span class="emphasis"><em>service_name</em></span>.service.d/</code> directories. Once profiles are unloaded, the <code class="literal">service</code> plugin removes these directories if they are empty.
						</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
								The <code class="literal">service</code> plugin only operates on the current runlevel with non-<code class="literal">systemd</code> init systems.
							</p></div></rh-alert><div class="example" id="idm140280161031456"><p class="title"><strong>Example 2.8. Starting and enabling the sendmail <code class="literal">sendmail</code> service with an overlay file</strong></p><div class="example-contents"><pre class="screen">[service]
service.sendmail=start,enable,file:${i:PROFILE_DIR}/tuned-sendmail.conf</pre><p>
								The internal variable <code class="literal">${i:PROFILE_DIR}</code> points to the directory the plugin loads the profile from.
							</p></div></div></dd><dt><span class="term"><code class="literal">scheduler</code></span></dt><dd>
							Offers a variety of options for the tuning of scheduling priorities, CPU core isolation, and process, thread, and IRQ affinities.
						</dd></dl></div><p>
				For specifics of the different options available, see <a class="link" href="#functionalities-of-the-scheduler-tuned-plug-in_customizing-tuned-profiles" title="2.9. Functionalities of the scheduler TuneD plugin">Functionalities of the <code class="literal">scheduler</code> TuneD plug-in</a>.
			</p></section><section class="section" id="functionalities-of-the-scheduler-tuned-plug-in_customizing-tuned-profiles"><div class="titlepage"><div><div><h3 class="title">2.9. Functionalities of the <code class="literal">scheduler</code> TuneD plugin</h3></div></div></div><p>
				Use the <code class="literal">scheduler</code> <span class="strong strong"><strong>TuneD</strong></span> plugin to control and tune scheduling priorities, CPU core isolation, and process, thread, and IRQ afinities.
			</p><div class="formalpara"><p class="title"><strong>CPU isolation</strong></p><p>
					To prevent processes, threads, and IRQs from using certain CPUs, use the <code class="literal option">isolated_cores</code> option. It changes process and thread affinities, IRQ affinities, and sets the <code class="literal">default_smp_affinity</code> parameter for IRQs.
				</p></div><p>
				The CPU affinity mask is adjusted for all processes and threads matching the <code class="literal option">ps_whitelist</code> option, subject to success of the <code class="literal">sched_setaffinity()</code> system call. The default setting of the <code class="literal option">ps_whitelist</code> regular expression is <code class="literal">.*</code> to match all processes and thread names. To exclude certain processes and threads, use the <code class="literal option">ps_blacklist</code> option. The value of this option is also interpreted as a regular expression. Process and thread names are matched against that expression. Profile rollback enables all matching processes and threads to run on all CPUs, and restores the IRQ settings prior to the profile application.
			</p><p>
				Multiple regular expressions separated by <code class="literal">;</code> for the <code class="literal option">ps_whitelist</code> and <code class="literal option">ps_blacklist</code> options are supported. Escaped semicolon <code class="literal">\;</code> is taken literally.
			</p><div class="example" id="idm140280151825456"><p class="title"><strong>Example 2.9. Isolate CPUs 2-4</strong></p><div class="example-contents"><p>
					The following configuration isolates CPUs 2-4. Processes and threads that match the <code class="literal">ps_blacklist</code> regular expression can use any CPUs regardless of the isolation:
				</p><pre class="screen">[scheduler]
isolated_cores=2-4
ps_blacklist=.*pmd.*;.*PMD.*;^DPDK;.*qemu-kvm.*</pre></div></div><div class="formalpara"><p class="title"><strong>IRQ SMP affinity</strong></p><p>
					The <code class="literal">/proc/irq/default_smp_affinity</code> file contains a bitmask representing the default target CPU cores on a system for all inactive interrupt request (IRQ) sources. Once an IRQ is activated or allocated, the value in the <code class="literal">/proc/irq/default_smp_affinity</code> file determines the IRQ’s affinity bitmask.
				</p></div><p>
				The <code class="literal">default_irq_smp_affinity</code> parameter controls what <span class="strong strong"><strong>TuneD</strong></span> writes to the <code class="literal">/proc/irq/default_smp_affinity</code> file. The <code class="literal">default_irq_smp_affinity</code> parameter supports the following values and behaviors:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">calc</code></span></dt><dd><p class="simpara">
							Calculates the content of the <code class="literal">/proc/irq/default_smp_affinity</code> file from the <code class="literal">isolated_cores</code> parameter. An inversion of the <code class="literal">isolated_cores</code> parameter calculates the non-isolated cores.
						</p><p class="simpara">
							The intersection of the non-isolated cores and the previous content of the <code class="literal">/proc/irq/default_smp_affinity</code> file is then written to the <code class="literal">/proc/irq/default_smp_affinity</code> file.
						</p><p class="simpara">
							This is the default behavior if the <code class="literal">default_irq_smp_affinity</code> parameter is omitted.
						</p></dd><dt><span class="term"><code class="literal">ignore</code></span></dt><dd>
							<span class="strong strong"><strong>TuneD</strong></span> does not modify the <code class="literal">/proc/irq/default_smp_affinity</code> file.
						</dd><dt><span class="term">A CPU list</span></dt><dd><p class="simpara">
							Takes the form of a single number such as <code class="literal">1</code>, a comma separated list such as <code class="literal">1,3</code>, or a range such as <code class="literal">3-5</code>.
						</p><p class="simpara">
							Unpacks the CPU list and writes it directly to the <code class="literal">/proc/irq/default_smp_affinity</code> file.
						</p></dd></dl></div><div class="example" id="idm140280148669888"><p class="title"><strong>Example 2.10. Setting the default IRQ smp affinity using an explicit CPU list</strong></p><div class="example-contents"><p>
					The following example uses an explicit CPU list to set the default IRQ SMP affinity to CPUs 0 and 2:
				</p><pre class="screen">[scheduler]
isolated_cores=1,3
default_irq_smp_affinity=0,2</pre></div></div><div class="formalpara"><p class="title"><strong>Scheduling policy</strong></p><p>
					To adjust scheduling policy, priority and affinity for a group of processes or threads, use the following syntax:
				</p></div><pre class="screen">group.<span class="emphasis"><em>groupname</em></span>=<span class="emphasis"><em>rule_prio</em></span>:<span class="emphasis"><em>sched</em></span>:<span class="emphasis"><em>prio</em></span>:<span class="emphasis"><em>affinity</em></span>:<span class="emphasis"><em>regex</em></span></pre><p>
				where <code class="literal"><span class="emphasis"><em>rule_prio</em></span></code> defines internal <span class="strong strong"><strong>TuneD</strong></span> priority of the rule. Rules are sorted based on priority. This is needed for inheritance to be able to reorder previously defined rules. Equal <code class="literal"><span class="emphasis"><em>rule_prio</em></span></code> rules should be processed in the order they were defined. However, this is Python interpreter dependent. To disable an inherited rule for <code class="literal"><span class="emphasis"><em>groupname</em></span></code>, use:
			</p><pre class="screen">group.<span class="emphasis"><em>groupname</em></span>=</pre><p>
				<code class="literal"><span class="emphasis"><em>sched</em></span></code> must be one of the following:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">f</code></span></dt><dd>
							for first in, first out (FIFO)
						</dd><dt><span class="term"><code class="literal">b</code></span></dt><dd>
							for batch
						</dd><dt><span class="term"><code class="literal">r</code></span></dt><dd>
							for round robin
						</dd><dt><span class="term"><code class="literal">o</code></span></dt><dd>
							for other
						</dd><dt><span class="term"><code class="literal">*</code></span></dt><dd>
							for do not change
						</dd></dl></div><p>
				<code class="literal"><span class="emphasis"><em>affinity</em></span></code> is CPU affinity in hexadecimal. Use <code class="literal">*</code> for no change.
			</p><p>
				<code class="literal"><span class="emphasis"><em>prio</em></span></code> is scheduling priority (see <code class="literal">chrt -m</code>).
			</p><p>
				<code class="literal"><span class="emphasis"><em>regex</em></span></code> is Python regular expression. It is matched against the output of the <code class="literal">ps -eo cmd</code> command.
			</p><p>
				Any given process name can match more than one group. In such cases, the last matching <code class="literal"><span class="emphasis"><em>regex</em></span></code> determines the priority and scheduling policy.
			</p><div class="example" id="idm140280149235248"><p class="title"><strong>Example 2.11. Setting scheduling policies and priorities</strong></p><div class="example-contents"><p>
					The following example sets the scheduling policy and priorities to kernel threads and watchdog:
				</p><pre class="screen">[scheduler]
group.kthreads=0:*:1:*:\[.*\]$
group.watchdog=0:f:99:*:\[watchdog.*\]</pre></div></div><p>
				The <code class="literal">scheduler</code> plugin uses a <code class="literal">perf</code> event loop to identify newly created processes. By default, it listens to <code class="literal">perf.RECORD_COMM</code> and <code class="literal">perf.RECORD_EXIT</code> events.
			</p><p>
				Setting the <code class="literal">perf_process_fork</code> parameter to <code class="literal">true</code> tells the plug-in to also listen to <code class="literal">perf.RECORD_FORK</code> events, meaning that child processes created by the <code class="literal">fork()</code> system call are processed.
			</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					Processing <code class="literal">perf</code> events can pose a significant CPU overhead.
				</p></div></rh-alert><p>
				The CPU overhead of the scheduler plugin can be mitigated by using the scheduler <code class="literal option">runtime</code> option and setting it to <code class="literal">0</code>. This completely disables the dynamic scheduler functionality and the perf events are not monitored and acted upon. The disadvantage of this is that the process and thread tuning will be done only at profile application.
			</p><div class="example" id="idm140280139485440"><p class="title"><strong>Example 2.12. Disabling the dynamic scheduler functionality</strong></p><div class="example-contents"><p>
					The following example disables the dynamic scheduler functionality while also isolating CPUs 1 and 3:
				</p><pre class="screen">[scheduler]
runtime=0
isolated_cores=1,3</pre></div></div><p>
				The <code class="literal">mmapped</code> buffer is used for <code class="literal">perf</code> events. Under heavy loads, this buffer might overflow and as a result the plugin might start missing events and not processing some newly created processes. In such cases, use the <code class="literal">perf_mmap_pages</code> parameter to increase the buffer size. The value of the <code class="literal">perf_mmap_pages</code> parameter must be a power of 2. If the <code class="literal">perf_mmap_pages</code> parameter is not manually set, a default value of 128 is used.
			</p><div class="formalpara"><p class="title"><strong>Confinement using <code class="literal">cgroups</code></strong></p><p>
					The <code class="literal">scheduler</code> plugin supports process and thread confinement using <code class="literal">cgroups</code> v1.
				</p></div><p>
				The <code class="literal option">cgroup_mount_point</code> option specifies the path to mount the cgroup file system, or, where <span class="strong strong"><strong>TuneD</strong></span> expects it to be mounted. If it is unset, <code class="literal">/sys/fs/cgroup/cpuset</code> is expected.
			</p><p>
				If the <code class="literal option">cgroup_groups_init</code> option is set to <code class="literal">1</code>, <span class="strong strong"><strong>TuneD</strong></span> creates and removes all <code class="literal">cgroups</code> defined with the <code class="literal">cgroup*</code> options. This is the default behavior. If the <code class="literal option">cgroup_mount_point</code> option is set to <code class="literal">0</code>, the <code class="literal">cgroups</code> must be preset by other means.
			</p><p>
				If the <code class="literal option">cgroup_mount_point_init</code> option is set to <code class="literal">1</code>, <span class="strong strong"><strong>TuneD</strong></span> creates and removes the cgroup mount point. It implies <code class="literal">cgroup_groups_init = 1</code>. If the <code class="literal option">cgroup_mount_point_init</code> option is set to <code class="literal">0</code>, you must preset the <code class="literal">cgroups</code> mount point by other means. This is the default behavior.
			</p><p>
				The <code class="literal option">cgroup_for_isolated_cores</code> option is the <code class="literal">cgroup</code> name for the <code class="literal option">isolated_cores</code> option functionality. For example, if a system has 4 CPUs, <code class="literal">isolated_cores=1</code> means that <span class="strong strong"><strong>Tuned</strong></span> moves all processes and threads to CPUs 0, 2, and 3. The <code class="literal">scheduler</code> plug-in isolates the specified core by writing the calculated CPU affinity to the <code class="literal">cpuset.cpus</code> control file of the specified cgroup and moves all the matching processes and threads to this group. If this option is unset, classic cpuset affinity using <code class="literal">sched_setaffinity()</code> sets the CPU affinity.
			</p><p>
				The <code class="literal option">cgroup.<span class="emphasis"><em>cgroup_name</em></span></code> option defines affinities for arbitrary <code class="literal">cgroups</code>. You can even use hierarchic cgroups, but you must specify the hierarchy in the correct order. <span class="strong strong"><strong>TuneD</strong></span> does not do any sanity checks here, with the exception that it forces the <code class="literal">cgroup</code> to be in the location specified by the <code class="literal option">cgroup_mount_point</code> option.
			</p><p>
				The syntax of the scheduler option starting with <code class="literal">group.</code> has been augmented to use <code class="literal">cgroup.<span class="emphasis"><em>cgroup_name</em></span></code> instead of the hexadecimal <code class="literal"><span class="emphasis"><em>affinity</em></span></code>. The matching processes are moved to the <code class="literal">cgroup</code> <code class="literal"><span class="emphasis"><em>cgroup_name</em></span></code>. You can also use cgroups not defined by the <code class="literal option">cgroup.</code> option as described above. For example, <code class="literal">cgroups</code> not managed by <span class="strong strong"><strong>TuneD</strong></span>.
			</p><p>
				All <code class="literal">cgroup</code> names are sanitized by replacing all periods (<code class="literal">.</code>) with slashes (<code class="literal">/</code>). This prevents the plugin from writing outside the location specified by the <code class="literal option">cgroup_mount_point</code> option.
			</p><div class="example" id="idm140280139587216"><p class="title"><strong>Example 2.13. Using <code class="literal">cgroups</code> v1 with the <code class="literal">scheduler</code> plug-in</strong></p><div class="example-contents"><p>
					The following example creates 2 <code class="literal">cgroups</code>, <code class="literal">group1</code> and <code class="literal">group2</code>. It sets the cgroup <code class="literal">group1</code> affinity to CPU 2 and the <code class="literal">cgroup</code> <code class="literal">group2</code> to CPUs 0 and 2. Given a 4 CPU setup, the <code class="literal option">isolated_cores=1</code> option moves all processes and threads to CPU cores 0, 2, and 3. Processes and threads specified by the <code class="literal option">ps_blacklist</code> regular expression are not moved.
				</p><pre class="screen">[scheduler]
cgroup_mount_point=/sys/fs/cgroup/cpuset
cgroup_mount_point_init=1
cgroup_groups_init=1
cgroup_for_isolated_cores=group
cgroup.group1=2
cgroup.group2=0,2

group.ksoftirqd=0:f:2:cgroup.group1:ksoftirqd.*
ps_blacklist=ksoftirqd.*;rcuc.*;rcub.*;ktimersoftd.*
isolated_cores=1</pre></div></div><p>
				The <code class="literal option">cgroup_ps_blacklist</code> option excludes processes belonging to the specified <code class="literal">cgroups</code>. The regular expression specified by this option is matched against <code class="literal">cgroup</code> hierarchies from <code class="literal">/proc/<span class="emphasis"><em>PID</em></span>/cgroups</code>. Commas (<code class="literal">,</code>) separate <code class="literal">cgroups</code> v1 hierarchies from <code class="literal">/proc/<span class="emphasis"><em>PID</em></span>/cgroups</code> before regular expression matching. The following is an example of content the regular expression is matched against:
			</p><pre class="screen">10:hugetlb:/,9:perf_event:/,8:blkio:/</pre><p>
				Multiple regular expressions can be separated by semicolons (<code class="literal">;</code>). The semicolon represents a logical 'or' operator.
			</p><div class="example" id="idm140280146511376"><p class="title"><strong>Example 2.14. Excluding processes from the scheduler using cgroups</strong></p><div class="example-contents"><p>
					In the following example, the <code class="literal">scheduler</code> plug-in moves all processes away from core 1, except for processes which belong to cgroup <code class="literal">/daemons</code>. The <code class="literal">\b</code> string is a regular expression metacharacter that matches a word boundary.
				</p><pre class="screen">[scheduler]
isolated_cores=1
cgroup_ps_blacklist=:/daemons\b</pre><p>
					In the following example, the <code class="literal">scheduler</code> plugin excludes all processes which belong to a cgroup with a hierarchy-ID of 8 and controller-list <code class="literal">blkio</code>.
				</p><pre class="screen">[scheduler]
isolated_cores=1
cgroup_ps_blacklist=\b8:blkio:</pre></div></div><p>
				Recent kernels moved some <code class="literal">sched_</code> and <code class="literal">numa_balancing_</code> kernel run-time parameters from the <code class="literal">/proc/sys/kernel</code> directory managed by the <code class="literal">sysctl</code> utility, to <code class="literal">debugfs</code>, typically mounted under the <code class="literal">/sys/kernel/debug</code> directory. <span class="strong strong"><strong>TuneD</strong></span> provides an abstraction mechanism for the following parameters via the <code class="literal">scheduler</code> plugin where, based on the kernel used, <span class="strong strong"><strong>TuneD</strong></span> writes the specified value to the correct location:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						<code class="literal option">sched_min_granularity_ns</code>
					</li><li class="listitem">
						<code class="literal option">sched_latency_ns</code>,
					</li><li class="listitem">
						<code class="literal option">sched_wakeup_granularity_ns</code>
					</li><li class="listitem">
						<code class="literal option">sched_tunable_scaling</code>,
					</li><li class="listitem">
						<code class="literal option">sched_migration_cost_ns</code>
					</li><li class="listitem">
						<code class="literal option">sched_nr_migrate</code>
					</li><li class="listitem">
						<code class="literal option">numa_balancing_scan_delay_ms</code>
					</li><li class="listitem">
						<code class="literal option">numa_balancing_scan_period_min_ms</code>
					</li><li class="listitem">
						<code class="literal option">numa_balancing_scan_period_max_ms</code>
					</li><li class="listitem"><p class="simpara">
						<code class="literal option">numa_balancing_scan_size_mb</code>
					</p><div class="example" id="idm140280149974544"><p class="title"><strong>Example 2.15. Set tasks' "cache hot" value for migration decisions.</strong></p><div class="example-contents"><p>
							On the old kernels, setting the following parameter meant that <code class="literal">sysctl</code> wrote a value of <code class="literal">500000</code> to the <code class="literal">/proc/sys/kernel/sched_migration_cost_ns</code> file:
						</p><pre class="screen">[sysctl]
kernel.sched_migration_cost_ns=500000</pre><p>
							This is, on more recent kernels, equivalent to setting the following parameter via the <code class="literal">scheduler</code> plugin:
						</p><pre class="screen">[scheduler]
sched_migration_cost_ns=500000</pre><p>
							Meaning <span class="strong strong"><strong>TuneD</strong></span> writes a value of <code class="literal">500000</code> to the <code class="literal">/sys/kernel/debug/sched/migration_cost_ns</code> file.
						</p></div></div></li></ul></div></section><section class="section" id="variables-in-tuned-profiles_customizing-tuned-profiles"><div class="titlepage"><div><div><h3 class="title">2.10. Variables in TuneD profiles</h3></div></div></div><p class="_abstract _abstract">
				Variables expand at run time when a <span class="strong strong"><strong>TuneD</strong></span> profile is activated.
			</p><p>
				Using <span class="strong strong"><strong>TuneD</strong></span> variables reduces the amount of necessary typing in <span class="strong strong"><strong>TuneD</strong></span> profiles.
			</p><p>
				There are no predefined variables in <span class="strong strong"><strong>TuneD</strong></span> profiles. You can define your own variables by creating the <code class="literal">[variables]</code> section in a profile and using the following syntax:
			</p><pre class="screen">[variables]

<span class="emphasis"><em><span class="replaceable replaceable">variable_name</span></em></span>=<span class="emphasis"><em><span class="replaceable replaceable">value</span></em></span></pre><p>
				To expand the value of a variable in a profile, use the following syntax:
			</p><pre class="screen">${<span class="emphasis"><em><span class="replaceable replaceable">variable_name</span></em></span>}</pre><div class="example" id="idm140280139713920"><p class="title"><strong>Example 2.16. Isolating CPU cores using variables</strong></p><div class="example-contents"><p>
					In the following example, the <code class="literal">${isolated_cores}</code> variable expands to <code class="literal">1,2</code>; hence the kernel boots with the <code class="literal option">isolcpus=1,2</code> option:
				</p><pre class="screen">[variables]
isolated_cores=1,2

[bootloader]
cmdline=isolcpus=${isolated_cores}</pre><p>
					The variables can be specified in a separate file. For example, you can add the following lines to <code class="literal filename">tuned.conf</code>:
				</p><pre class="screen">[variables]
include=/etc/tuned/<span class="emphasis"><em><span class="replaceable replaceable">my-variables.conf</span></em></span>

[bootloader]
cmdline=isolcpus=${isolated_cores}</pre><p>
					If you add the <code class="literal option">isolated_cores=1,2</code> option to the <code class="literal filename">/etc/tuned/my-variables.conf</code> file, the kernel boots with the <code class="literal option">isolcpus=1,2</code> option.
				</p></div></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">tuned.conf(5)</code> man page on your system
					</li></ul></div></section><section class="section" id="built-in-functions-in-tuned-profiles_customizing-tuned-profiles"><div class="titlepage"><div><div><h3 class="title">2.11. Built-in functions in TuneD profiles</h3></div></div></div><p class="_abstract _abstract">
				Built-in functions expand at run time when a <span class="strong strong"><strong>TuneD</strong></span> profile is activated.
			</p><p>
				You can:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Use various built-in functions together with <span class="strong strong"><strong>TuneD</strong></span> variables
					</li><li class="listitem">
						Create custom functions in Python and add them to <span class="strong strong"><strong>TuneD</strong></span> in the form of plug-ins
					</li></ul></div><p>
				To call a function, use the following syntax:
			</p><pre class="screen">${f:<span class="emphasis"><em><span class="replaceable replaceable">function_name</span></em></span>:<span class="emphasis"><em><span class="replaceable replaceable">argument_1</span></em></span>:<span class="emphasis"><em><span class="replaceable replaceable">argument_2</span></em></span>}</pre><p>
				To expand the directory path where the profile and the <code class="literal">tuned.conf</code> file are located, use the <code class="literal">PROFILE_DIR</code> function, which requires special syntax:
			</p><pre class="screen">${i:PROFILE_DIR}</pre><div class="example" id="idm140280158002080"><p class="title"><strong>Example 2.17. Isolating CPU cores using variables and built-in functions</strong></p><div class="example-contents"><p>
					In the following example, the <code class="literal">${non_isolated_cores}</code> variable expands to <code class="literal">0,3-5</code>, and the <code class="literal">cpulist_invert</code> built-in function is called with the <code class="literal">0,3-5</code> argument:
				</p><pre class="screen">[variables]
non_isolated_cores=0,3-5

[bootloader]
cmdline=isolcpus=${f:cpulist_invert:${non_isolated_cores}}</pre><p>
					The <code class="literal">cpulist_invert</code> function inverts the list of CPUs. For a 6-CPU machine, the inversion is <code class="literal">1,2</code>, and the kernel boots with the <code class="literal option">isolcpus=1,2</code> command-line option.
				</p></div></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">tuned.conf(5)</code> man page on your system
					</li></ul></div></section><section class="section" id="built-in-functions-available-in-tuned-profiles_customizing-tuned-profiles"><div class="titlepage"><div><div><h3 class="title">2.12. Built-in functions available in TuneD profiles</h3></div></div></div><p class="_abstract _abstract">
				The following built-in functions are available in all <span class="strong strong"><strong>TuneD</strong></span> profiles:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">PROFILE_DIR</code></span></dt><dd>
							Returns the directory path where the profile and the <code class="literal">tuned.conf</code> file are located.
						</dd><dt><span class="term"><code class="literal">exec</code></span></dt><dd>
							Executes a process and returns its output.
						</dd><dt><span class="term"><code class="literal">assertion</code></span></dt><dd>
							Compares two arguments. If they <span class="emphasis"><em>do not match</em></span>, the function logs text from the first argument and aborts profile loading.
						</dd><dt><span class="term"><code class="literal">assertion_non_equal</code></span></dt><dd>
							Compares two arguments. If they <span class="emphasis"><em>match</em></span>, the function logs text from the first argument and aborts profile loading.
						</dd><dt><span class="term"><code class="literal">kb2s</code></span></dt><dd>
							Converts kilobytes to disk sectors.
						</dd><dt><span class="term"><code class="literal">s2kb</code></span></dt><dd>
							Converts disk sectors to kilobytes.
						</dd><dt><span class="term"><code class="literal">strip</code></span></dt><dd>
							Creates a string from all passed arguments and deletes both leading and trailing white space.
						</dd><dt><span class="term"><code class="literal">virt_check</code></span></dt><dd><p class="simpara">
							Checks whether <span class="strong strong"><strong>TuneD</strong></span> is running inside a virtual machine (VM) or on bare metal:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									Inside a VM, the function returns the first argument.
								</li><li class="listitem">
									On bare metal, the function returns the second argument, even in case of an error.
								</li></ul></div></dd><dt><span class="term"><code class="literal">cpulist_invert</code></span></dt><dd>
							Inverts a list of CPUs to make its complement. For example, on a system with 4 CPUs, numbered from 0 to 3, the inversion of the list <code class="literal">0,2,3</code> is <code class="literal">1</code>.
						</dd><dt><span class="term"><code class="literal">cpulist2hex</code></span></dt><dd>
							Converts a CPU list to a hexadecimal CPU mask.
						</dd><dt><span class="term"><code class="literal">cpulist2hex_invert</code></span></dt><dd>
							Converts a CPU list to a hexadecimal CPU mask and inverts it.
						</dd><dt><span class="term"><code class="literal">hex2cpulist</code></span></dt><dd>
							Converts a hexadecimal CPU mask to a CPU list.
						</dd><dt><span class="term"><code class="literal">cpulist_online</code></span></dt><dd>
							Checks whether the CPUs from the list are online. Returns the list containing only online CPUs.
						</dd><dt><span class="term"><code class="literal">cpulist_present</code></span></dt><dd>
							Checks whether the CPUs from the list are present. Returns the list containing only present CPUs.
						</dd><dt><span class="term"><code class="literal">cpulist_unpack</code></span></dt><dd>
							Unpacks a CPU list in the form of <code class="literal">1-3,4</code> to <code class="literal">1,2,3,4</code>.
						</dd><dt><span class="term"><code class="literal">cpulist_pack</code></span></dt><dd>
							Packs a CPU list in the form of <code class="literal">1,2,3,5</code> to <code class="literal">1-3,5</code>.
						</dd></dl></div></section><section class="section" id="creating-new-tuned-profiles_customizing-tuned-profiles"><div class="titlepage"><div><div><h3 class="title">2.13. Creating new TuneD profiles</h3></div></div></div><p class="_abstract _abstract">
				This procedure creates a new <span class="strong strong"><strong>TuneD</strong></span> profile with custom performance rules.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						The <code class="literal">TuneD</code> service is running. See <a class="link" href="#installing-and-enabling-tuned_getting-started-with-tuned" title="1.13. Installing and enabling TuneD">Installing and Enabling TuneD</a> for details.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						In the <code class="literal filename">/etc/tuned/</code> directory, create a new directory named the same as the profile that you want to create:
					</p><pre class="screen"># mkdir /etc/tuned/<span class="emphasis"><em><span class="replaceable replaceable">my-profile</span></em></span></pre></li><li class="listitem"><p class="simpara">
						In the new directory, create a file named <code class="literal filename">tuned.conf</code>. Add a <code class="literal">[main]</code> section and plug-in definitions in it, according to your requirements.
					</p><p class="simpara">
						For example, see the configuration of the <code class="literal">balanced</code> profile:
					</p><pre class="screen">[main]
summary=General non-specialized TuneD profile

[cpu]
governor=conservative
energy_perf_bias=normal

[audio]
timeout=10

[video]
radeon_powersave=dpm-balanced, auto

[scsi_host]
alpm=medium_power</pre></li><li class="listitem"><p class="simpara">
						To activate the profile, use:
					</p><pre class="screen"># tuned-adm profile <span class="emphasis"><em><span class="replaceable replaceable">my-profile</span></em></span></pre></li><li class="listitem"><p class="simpara">
						Verify that the <span class="strong strong"><strong>TuneD</strong></span> profile is active and the system settings are applied:
					</p><pre class="screen">$ tuned-adm active

Current active profile: <span class="emphasis"><em><span class="replaceable replaceable">my-profile</span></em></span></pre><pre class="screen">$ tuned-adm verify

Verification succeeded, current system settings match the preset profile.
See tuned log file ('/var/log/tuned/tuned.log') for details.</pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">tuned.conf(5)</code> man page on your system
					</li></ul></div></section><section class="section" id="modifying-existing-tuned-profiles_customizing-tuned-profiles"><div class="titlepage"><div><div><h3 class="title">2.14. Modifying existing TuneD profiles</h3></div></div></div><p class="_abstract _abstract">
				This procedure creates a modified child profile based on an existing <span class="strong strong"><strong>TuneD</strong></span> profile.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						The <code class="literal">TuneD</code> service is running. See <a class="link" href="#installing-and-enabling-tuned_getting-started-with-tuned" title="1.13. Installing and enabling TuneD">Installing and Enabling TuneD</a> for details.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						In the <code class="literal filename">/etc/tuned/</code> directory, create a new directory named the same as the profile that you want to create:
					</p><pre class="screen"># mkdir /etc/tuned/<span class="emphasis"><em><span class="replaceable replaceable">modified-profile</span></em></span></pre></li><li class="listitem"><p class="simpara">
						In the new directory, create a file named <code class="literal filename">tuned.conf</code>, and set the <code class="literal">[main]</code> section as follows:
					</p><pre class="screen">[main]
include=<span class="emphasis"><em><span class="replaceable replaceable">parent-profile</span></em></span></pre><p class="simpara">
						Replace <span class="emphasis"><em><span class="replaceable replaceable">parent-profile</span></em></span> with the name of the profile you are modifying.
					</p></li><li class="listitem"><p class="simpara">
						Include your profile modifications.
					</p><div class="example" id="idm140280161404224"><p class="title"><strong>Example 2.18. Lowering swappiness in the throughput-performance profile</strong></p><div class="example-contents"><p>
							To use the settings from the <code class="literal">throughput-performance</code> profile and change the value of <code class="literal">vm.swappiness</code> to 5, instead of the default 10, use:
						</p><pre class="screen">[main]
include=throughput-performance

[sysctl]
vm.swappiness=5</pre></div></div></li><li class="listitem"><p class="simpara">
						To activate the profile, use:
					</p><pre class="screen"># tuned-adm profile <span class="emphasis"><em><span class="replaceable replaceable">modified-profile</span></em></span></pre></li><li class="listitem"><p class="simpara">
						Verify that the <span class="strong strong"><strong>TuneD</strong></span> profile is active and the system settings are applied:
					</p><pre class="screen">$ tuned-adm active

Current active profile: <span class="emphasis"><em><span class="replaceable replaceable">my-profile</span></em></span></pre><pre class="screen">$ tuned-adm verify

Verification succeeded, current system settings match the preset profile.
See tuned log file ('/var/log/tuned/tuned.log') for details.</pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">tuned.conf(5)</code> man page on your system
					</li></ul></div></section><section class="section" id="setting-the-disk-scheduler-using-tuned_customizing-tuned-profiles"><div class="titlepage"><div><div><h3 class="title">2.15. Setting the disk scheduler using TuneD</h3></div></div></div><p class="_abstract _abstract">
				This procedure creates and enables a <span class="strong strong"><strong>TuneD</strong></span> profile that sets a given disk scheduler for selected block devices. The setting persists across system reboots.
			</p><p>
				In the following commands and configuration, replace:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						<span class="emphasis"><em>device</em></span> with the name of the block device, for example <code class="literal">sdf</code>
					</li><li class="listitem">
						<span class="emphasis"><em>selected-scheduler</em></span> with the disk scheduler that you want to set for the device, for example <code class="literal">bfq</code>
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						The <code class="literal">TuneD</code> service is installed and enabled. For details, see <a class="link" href="#installing-and-enabling-tuned_getting-started-with-tuned" title="1.13. Installing and enabling TuneD">Installing and enabling TuneD</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Optional: Select an existing <span class="strong strong"><strong>TuneD</strong></span> profile on which your profile will be based. For a list of available profiles, see <a class="link" href="#tuned-profiles-distributed-with-rhel_getting-started-with-tuned" title="1.6. TuneD profiles distributed with RHEL">TuneD profiles distributed with RHEL</a>.
					</p><p class="simpara">
						To see which profile is currently active, use:
					</p><pre class="screen">$ tuned-adm active</pre></li><li class="listitem"><p class="simpara">
						Create a new directory to hold your <span class="strong strong"><strong>TuneD</strong></span> profile:
					</p><pre class="screen"># mkdir /etc/tuned/<span class="emphasis"><em>my-profile</em></span></pre></li><li class="listitem"><p class="simpara">
						Find the system unique identifier of the selected block device:
					</p><pre class="screen">$ udevadm info --query=property --name=/dev/<span class="emphasis"><em>device</em></span> | grep -E '(WWN|SERIAL)'

ID_WWN=<span class="emphasis"><em>0x5002538d00000000_</em></span>
ID_SERIAL=<span class="emphasis"><em>Generic-_SD_MMC_20120501030900000-0:0</em></span>
ID_SERIAL_SHORT=<span class="emphasis"><em>20120501030900000</em></span></pre><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
							The command in the this example will return all values identified as a World Wide Name (WWN) or serial number associated with the specified block device. Although it is preferred to use a WWN, the WWN is not always available for a given device and any values returned by the example command are acceptable to use as the <span class="emphasis"><em>device system unique ID</em></span>.
						</p></div></rh-alert></li><li class="listitem"><p class="simpara">
						Create the <code class="literal">/etc/tuned/<span class="emphasis"><em>my-profile</em></span>/tuned.conf</code> configuration file. In the file, set the following options:
					</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
								Optional: Include an existing profile:
							</p><pre class="screen">[main]
include=<span class="emphasis"><em>existing-profile</em></span></pre></li><li class="listitem"><p class="simpara">
								Set the selected disk scheduler for the device that matches the WWN identifier:
							</p><pre class="screen">[disk]
devices_udev_regex=<span class="emphasis"><em>IDNAME</em></span>=<span class="emphasis"><em>device system unique id</em></span>
elevator=<span class="emphasis"><em>selected-scheduler</em></span></pre><p class="simpara">
								Here:
							</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
										Replace <span class="emphasis"><em>IDNAME</em></span> with the name of the identifier being used (for example, <code class="literal">ID_WWN</code>).
									</li><li class="listitem"><p class="simpara">
										Replace <span class="emphasis"><em>device system unique id</em></span> with the value of the chosen identifier (for example, <code class="literal">0x5002538d00000000</code>).
									</p><p class="simpara">
										To match multiple devices in the <code class="literal">devices_udev_regex</code> option, enclose the identifiers in parentheses and separate them with vertical bars:
									</p><pre class="screen">devices_udev_regex=(ID_WWN=<span class="emphasis"><em>0x5002538d00000000</em></span>)|(ID_WWN=<span class="emphasis"><em>0x1234567800000000</em></span>)</pre></li></ul></div></li></ol></div></li><li class="listitem"><p class="simpara">
						Enable your profile:
					</p><pre class="screen"># tuned-adm profile <span class="emphasis"><em>my-profile</em></span></pre></li></ol></div><div class="orderedlist"><p class="title"><strong>Verification</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Verify that the TuneD profile is active and applied:
					</p><pre class="screen">$ tuned-adm active

Current active profile: <span class="emphasis"><em>my-profile</em></span></pre><pre class="screen">$ tuned-adm verify

Verification succeeded, current system settings match the preset profile.
See TuneD log file ('/var/log/tuned/tuned.log') for details.</pre></li><li class="listitem"><p class="simpara">
						Read the contents of the <code class="literal">/sys/block/<span class="emphasis"><em>device</em></span>/queue/scheduler</code> file:
					</p><pre class="screen"># cat /sys/block/<span class="emphasis"><em>device</em></span>/queue/scheduler

[mq-deadline] kyber bfq none</pre><p class="simpara">
						In the file name, replace <span class="emphasis"><em>device</em></span> with the block device name, for example <code class="literal">sdc</code>.
					</p><p class="simpara">
						The active scheduler is listed in square brackets (<code class="literal">[]</code>).
					</p></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="#customizing-tuned-profiles_monitoring-and-managing-system-status-and-performance" title="Chapter 2. Customizing TuneD profiles">Customizing TuneD profiles</a>.
					</li></ul></div></section></section><section class="chapter" id="reviewing-a-system-using-tuna-interface_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 3. Reviewing a system by using the tuna interface</h2></div></div></div><p class="_abstract _abstract">
			The <code class="literal">tuna</code> tool reduces the complexity of performing tuning tasks. Use <code class="literal">tuna</code> to adjust scheduler tunables, tune thread priority, IRQ handlers, and to isolate CPU cores and sockets. By using the <code class="literal">tuna</code> tool, you can perform the following operations:
		</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
					List the CPUs on a system.
				</li><li class="listitem">
					List the interrupt requests (IRQs) currently running on a system.
				</li><li class="listitem">
					Change policy and priority information about threads.
				</li><li class="listitem">
					Display the current policies and priorities of a system.
				</li></ul></div><section class="section" id="installing-tuna-tool_reviewing-a-system-using-tuna-interface"><div class="titlepage"><div><div><h3 class="title">3.1. Installing the tuna tool</h3></div></div></div><p class="_abstract _abstract">
				The <code class="literal">tuna</code> tool is designed to be used on a running system. This allows application-specific measurement tools to see and analyze system performance immediately after changes have been made.
			</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Install the <code class="literal">tuna</code> tool:
					</p><pre class="literallayout"># <span class="strong strong"><strong>dnf install tuna</strong></span></pre></li></ul></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Display the available <code class="literal">tuna</code> CLI options:
					</p><pre class="literallayout"># <span class="strong strong"><strong>tuna -h</strong></span></pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">tuna(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="viewing-the-system-status-using-tuna-tool_reviewing-a-system-using-tuna-interface"><div class="titlepage"><div><div><h3 class="title">3.2. Viewing the system status by using the tuna tool</h3></div></div></div><p class="_abstract _abstract">
				You can use the <code class="literal">tuna</code> command-line interface (CLI) tool to view the system status.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						The <code class="literal">tuna</code> tool is installed. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/reviewing-a-system-using-tuna-interface_monitoring-and-managing-system-status-and-performance#installing-tuna-tool_reviewing-a-system-using-tuna-interface">Installing the tuna tool</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						View the current policies and priorities:
					</p><pre class="literallayout"># <span class="strong strong"><strong>tuna show_threads</strong></span>
pid   SCHED_ rtpri affinity             cmd
1      OTHER     0      0,1            init
2       FIFO    99        0     migration/0
3      OTHER     0        0     ksoftirqd/0
4       FIFO    99        0      watchdog/0</pre><p class="simpara">
						Alternatively, to view a specific thread corresponding to a PID or matching a command name, enter:
					</p><pre class="literallayout"># <span class="strong strong"><strong>tuna show_threads -t pid_or_cmd_list</strong></span></pre><p class="simpara">
						The <span class="emphasis"><em>pid_or_cmd_list</em></span> argument is a list of comma-separated PIDs or command-name patterns.
					</p></li><li class="listitem"><p class="simpara">
						Depending on you scenario, perform one of the following actions:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								To tune CPUs by using the <code class="literal">tuna</code> CLI, complete the steps in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/reviewing-a-system-using-tuna-interface_monitoring-and-managing-system-status-and-performance#tuning-cpus-using-tuna-tool_reviewing-a-system-using-tuna-interface">Tuning CPUs by using the tuna tool</a>.
							</li><li class="listitem">
								To tune the IRQs by using the <code class="literal">tuna</code> tool, complete the steps in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/reviewing-a-system-using-tuna-interface_monitoring-and-managing-system-status-and-performance#tuning-irqs-using-tuna-tool_reviewing-a-system-using-tuna-interface">Tuning IRQs by using the tuna tool</a>.
							</li></ul></div></li><li class="listitem"><p class="simpara">
						Save the changed configuration:
					</p><pre class="literallayout"># <span class="strong strong"><strong>tuna save filename</strong></span></pre><p class="simpara">
						This command saves only currently running kernel threads. Processes that are not running are not saved.
					</p></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">tuna(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="tuning-cpus-using-tuna-tool_reviewing-a-system-using-tuna-interface"><div class="titlepage"><div><div><h3 class="title">3.3. Tuning CPUs by using the tuna tool</h3></div></div></div><p class="_abstract _abstract">
				The <code class="literal">tuna</code> tool commands can target individual CPUs. By using the <code class="literal">tuna</code> tool, you can perform the following actions:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">Isolate CPUs</code></span></dt><dd>
							All tasks running on the specified CPU move to the next available CPU. Isolating a CPU makes this CPU unavailable by removing it from the affinity mask of all threads.
						</dd><dt><span class="term"><code class="literal">Include CPUs</code></span></dt><dd>
							Allows tasks to run on the specified CPU.
						</dd><dt><span class="term"><code class="literal">Restore CPUs</code></span></dt><dd>
							Restores the specified CPU to its previous configuration.
						</dd></dl></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						The <code class="literal">tuna</code> tool is installed. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/reviewing-a-system-using-tuna-interface_monitoring-and-managing-system-status-and-performance#installing-tuna-tool_reviewing-a-system-using-tuna-interface">Installing the tuna tool</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						List all CPUs and specify the list of CPUs to be affected by the command:
					</p><pre class="literallayout"># <span class="strong strong"><strong>ps ax | awk 'BEGIN { ORS="," }{ print $1 }'</strong></span>
PID,1,2,3,4,5,6,8,10,11,12,13,14,15,16,17,19</pre></li><li class="listitem"><p class="simpara">
						Display the thread list in the <code class="literal">tuna</code> interface:
					</p><pre class="literallayout"># <span class="strong strong"><strong>tuna show_threads -t 'thread_list from above cmd'</strong></span></pre></li><li class="listitem"><p class="simpara">
						Specify the list of CPUs to be affected by a command:
					</p><pre class="literallayout"># *tuna [<span class="emphasis"><em>command</em></span>] --cpus <span class="emphasis"><em>cpu_list</em></span> *</pre><p class="simpara">
						The <span class="emphasis"><em>cpu_list</em></span> argument is a list of comma-separated CPU numbers, for example, <code class="literal">--cpus <span class="emphasis"><em>0,2</em></span></code>.
					</p><p class="simpara">
						To add a specific CPU to the current <span class="emphasis"><em>cpu_list</em></span>, use, for example, <code class="literal">--cpus +0</code>.
					</p></li><li class="listitem"><p class="simpara">
						Depending on your scenario, perform one of the following actions:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								To isolate a CPU, enter:
							</p><pre class="literallayout"># <span class="strong strong"><strong>tuna isolate --cpus cpu_list</strong></span></pre></li><li class="listitem"><p class="simpara">
								To include a CPU, enter:
							</p><pre class="literallayout"># <span class="strong strong"><strong>tuna include --cpus cpu_list</strong></span></pre></li></ul></div></li><li class="listitem"><p class="simpara">
						To use a system with four or more processors, make all <code class="literal">ssh</code> threads run on CPU <span class="emphasis"><em>0</em></span> and <span class="emphasis"><em>1</em></span> and all <code class="literal">http</code> threads on CPU <span class="emphasis"><em>2</em></span> and <span class="emphasis"><em>3</em></span>:
					</p><pre class="literallayout"># <span class="strong strong"><strong>tuna move --cpus 0,1 -t ssh</strong></span>*
# <span class="strong strong"><strong>tuna move --cpus 2,3 -t http\</strong></span>*</pre></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Display the current configuration and verify that the changes were applied:
					</p><pre class="literallayout white-space-pre"># <span class="strong strong"><strong>tuna show_threads -t ssh</strong></span>*

pid   SCHED_  rtpri  affinity   voluntary   nonvoluntary   cmd
855   OTHER   0      0,1        23           15            sshd

# <span class="strong strong"><strong>tuna show_threads -t http\</strong></span>*
pid   SCHED_  rtpri  affinity   voluntary   nonvoluntary   cmd
855   OTHER   0       2,3        23           15           http</pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">/proc/cpuinfo</code> file
					</li><li class="listitem">
						<code class="literal">tuna(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="tuning-irqs-using-tuna-tool_reviewing-a-system-using-tuna-interface"><div class="titlepage"><div><div><h3 class="title">3.4. Tuning IRQs by using the tuna tool</h3></div></div></div><p class="_abstract _abstract">
				The <code class="literal">/proc/interrupts</code> file records the number of interrupts per IRQ, the type of interrupt, and the name of the device that is located at that IRQ.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						The <code class="literal">tuna</code> tool is installed. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/reviewing-a-system-using-tuna-interface_monitoring-and-managing-system-status-and-performance#installing-tuna-tool_reviewing-a-system-using-tuna-interface">Installing tuna tool</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						View the current IRQs and their affinity:
					</p><pre class="literallayout"># <span class="strong strong"><strong>tuna show_irqs</strong></span>
# users            affinity
0 timer                   0
1 i8042                   0
7 parport0                0</pre></li><li class="listitem"><p class="simpara">
						Specify the list of IRQs to be affected by a command:
					</p><pre class="literallayout"># <span class="strong strong"><strong>tuna [<span class="emphasis"><em>command</em></span>] --irqs <span class="emphasis"><em>irq_list</em></span> --cpus <span class="emphasis"><em>cpu_list</em></span></strong></span></pre><p class="simpara">
						The <span class="emphasis"><em>irq_list</em></span> argument is a list of comma-separated IRQ numbers or user-name patterns.
					</p><p class="simpara">
						Replace [<span class="emphasis"><em>command</em></span>] with, for example, <code class="literal">--spread</code>.
					</p></li><li class="listitem"><p class="simpara">
						Move an interrupt to a specified CPU:
					</p><pre class="literallayout"># <span class="strong strong"><strong>tuna show_irqs --irqs <span class="emphasis"><em>128</em></span></strong></span>
users            affinity
128 iwlwifi           0,1,2,3

# <span class="strong strong"><strong>tuna move --irqs <span class="emphasis"><em>128</em></span> --cpus 3</strong></span></pre><p class="simpara">
						Replace <span class="emphasis"><em>128</em></span> with the irq_list argument and <span class="emphasis"><em>3</em></span> with the cpu_list argument.
					</p><p class="simpara">
						The <span class="emphasis"><em>cpu_list</em></span> argument is a list of comma-separated CPU numbers, for example, <code class="literal">--cpus <span class="emphasis"><em>0,2</em></span></code>. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/reviewing-a-system-using-tuna-interface_monitoring-and-managing-system-status-and-performance#tuning-cpus-using-tuna-tool_reviewing-a-system-using-tuna-interface">Tuning CPUs by using the tuna tool</a>.
					</p></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Compare the state of the selected IRQs before and after moving any interrupt to a specified CPU:
					</p><pre class="literallayout"># <span class="strong strong"><strong>tuna show_irqs --irqs <span class="emphasis"><em>128</em></span></strong></span>
     users            affinity
 128 iwlwifi                 3</pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">/procs/interrupts</code> file
					</li><li class="listitem">
						<code class="literal">tuna(8)</code> man page on your system
					</li></ul></div></section></section><section class="chapter" id="monitoring-performance-by-using-the-metrics-rhel-system-role_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 4. Configuring performance monitoring with PCP by using RHEL system roles</h2></div></div></div><p class="_abstract _abstract">
			Performance Co-Pilot (PCP) is a system performance analysis toolkit. You can use it to record and analyze performance data from many components on a Red Hat Enterprise Linux system.
		</p><p>
			You can use the <code class="literal">metrics</code> RHEL system role to automate the installation and configuration of PCP, and the role can configure Grafana to visualize PCP metrics.
		</p><section class="section" id="configuring-performance-co-pilot-by-using-the-metrics-rhel-system-role_monitoring-performance-by-using-the-metrics-rhel-system-role"><div class="titlepage"><div><div><h3 class="title">4.1. Configuring Performance Co-Pilot by using the <code class="literal">metrics</code> RHEL system role</h3></div></div></div><p>
				You can use Performance Co-Pilot (PCP) to monitor many metrics, such as CPU utilization and memory usage. For example, this can help to identify resource and performance bottlenecks. By using the <code class="literal">metrics</code> RHEL system role, you can remotely configure PCP on multiple hosts to record metrics.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles">You have prepared the control node and the managed nodes</a>
					</li><li class="listitem">
						You are logged in to the control node as a user who can run playbooks on the managed nodes.
					</li><li class="listitem">
						The account you use to connect to the managed nodes has <code class="literal">sudo</code> permissions on them.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Create a playbook file, for example <code class="literal">~/playbook.yml</code>, with the following content:
					</p><pre class="programlisting language-yaml">---
- name: Monitoring performance metrics
  hosts: managed-node-01.example.com
  tasks:
    - name: Configure Performance Co-Pilot
      ansible.builtin.include_role:
        name: rhel-system-roles.metrics
      vars:
        metrics_retention_days: 14
        metrics_manage_firewall: true
        metrics_manage_selinux: true</pre><p class="simpara">
						The settings specified in the example playbook include the following:
					</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">metrics_retention_days: <span class="emphasis"><em>&lt;number&gt;</em></span></code></span></dt><dd>
									Sets the number of days after which the <code class="literal">pmlogger_daily</code> systemd timer removes old PCP archives.
								</dd><dt><span class="term"><code class="literal">metrics_manage_firewall: <span class="emphasis"><em>&lt;true|false&gt;</em></span></code></span></dt><dd>
									Defines whether the role should open the required ports in the <code class="literal">firewalld</code> service. If you want to remotely access PCP on the managed nodes, set this variable to <code class="literal">true</code>.
								</dd></dl></div><p class="simpara">
						For details about all variables used in the playbook, see the <code class="literal">/usr/share/ansible/roles/rhel-system-roles.metrics/README.md</code> file on the control node.
					</p></li><li class="listitem"><p class="simpara">
						Validate the playbook syntax:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-playbook --syntax-check ~/playbook.yml</strong></span></pre><p class="simpara">
						Note that this command only validates the syntax and does not protect against a wrong but valid configuration.
					</p></li><li class="listitem"><p class="simpara">
						Run the playbook:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-playbook ~/playbook.yml</strong></span></pre></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Query a metric, for example:
					</p><pre class="literallayout"># <span class="strong strong"><strong>ansible managed-node-01.example.com -m command -a 'pminfo -f kernel.all.load'</strong></span></pre></li></ul></div><div class="itemizedlist"><p class="title"><strong>Next step</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Optional: <a class="link" href="#setting-up-grafana-by-using-the-metrics-rhel-system-role-to-monitor-multiple-hosts-with-performance-co-pilot_monitoring-performance-by-using-the-metrics-rhel-system-role" title="4.3. Setting up Grafana by using the metrics RHEL system role to monitor multiple hosts with Performance Co-Pilot">Configure Grafana to monitor PCP hosts and visualize metrics</a>.
					</li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">/usr/share/ansible/roles/rhel-system-roles.metrics/README.md</code> file
					</li><li class="listitem">
						<code class="literal">/usr/share/doc/rhel-system-roles/metrics/</code> directory
					</li></ul></div></section><section class="section" id="configuring-performance-co-pilot-with-authentication-by-using-the-metrics-rhel-system-role_monitoring-performance-by-using-the-metrics-rhel-system-role"><div class="titlepage"><div><div><h3 class="title">4.2. Configuring Performance Co-Pilot with authentication by using the <code class="literal">metrics</code> RHEL system role</h3></div></div></div><p>
				You can enable authentication in Performance Co-Pilot (PCP) so that the <code class="literal">pmcd</code> service and Performance Metrics Domain Agents (PDMAs) can determine whether the user running the monitoring tools is allowed to perform an action. Authenticated users have access to metrics with sensitive information. Additionally, certain agents require authentication. For example, the <code class="literal">bpftrace</code> agent uses authentication to identify whether a user is allowed to load <code class="literal">bpftrace</code> scripts into the kernel to generate metrics.
			</p><p>
				By using the <code class="literal">metrics</code> RHEL system role, you can remotely configure PCP with authentication on multiple hosts.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles">You have prepared the control node and the managed nodes</a>
					</li><li class="listitem">
						You are logged in to the control node as a user who can run playbooks on the managed nodes.
					</li><li class="listitem">
						The account you use to connect to the managed nodes has <code class="literal">sudo</code> permissions on them.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Store your sensitive variables in an encrypted file:
					</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
								Create the vault:
							</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-vault create vault.yml</strong></span>
New Vault password: <span class="emphasis"><em>&lt;vault_password&gt;</em></span>
Confirm New Vault password: <span class="emphasis"><em>&lt;vault_password&gt;</em></span></pre></li><li class="listitem"><p class="simpara">
								After the <code class="literal">ansible-vault create</code> command opens an editor, enter the sensitive data in the <code class="literal"><span class="emphasis"><em>&lt;key&gt;</em></span>: <span class="emphasis"><em>&lt;value&gt;</em></span></code> format:
							</p><pre class="programlisting language-ini">metrics_usr: <span class="emphasis"><em>&lt;username&gt;</em></span>
metrics_pwd: <span class="emphasis"><em>&lt;password&gt;</em></span></pre></li><li class="listitem">
								Save the changes, and close the editor. Ansible encrypts the data in the vault.
							</li></ol></div></li><li class="listitem"><p class="simpara">
						Create a playbook file, for example <code class="literal">~/playbook.yml</code>, with the following content:
					</p><pre class="programlisting language-yaml">---
- name: Monitoring performance metrics
  hosts: managed-node-01.example.com
  tasks:
    - name: Configure Performance Co-Pilot
      ansible.builtin.include_role:
        name: rhel-system-roles.metrics
      vars:
        metrics_retention_days: 14
        metrics_manage_firewall: true
        metrics_manage_selinux: true
	metrics_username: "{{ metrics_usr }}"
        metrics_password: "{{ metrics_pwd }}"</pre><p class="simpara">
						The settings specified in the example playbook include the following:
					</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">metrics_retention_days: <span class="emphasis"><em>&lt;number&gt;</em></span></code></span></dt><dd>
									Sets the number of days after which the <code class="literal">pmlogger_daily</code> systemd timer removes old PCP archives.
								</dd><dt><span class="term"><code class="literal">metrics_manage_firewall: <span class="emphasis"><em>&lt;true|false&gt;</em></span></code></span></dt><dd>
									Defines whether the role should open the required ports in the <code class="literal">firewalld</code> service. If you want to remotely access PCP on the managed nodes, set this variable to <code class="literal">true</code>.
								</dd><dt><span class="term"><code class="literal">metrics_username: <span class="emphasis"><em>&lt;username&gt;</em></span></code></span></dt><dd>
									The role creates this user locally on the managed node, adds the credentials to the <code class="literal">/etc/pcp/passwd.db</code> Simple Authentication and Security Layer (SASL) database, and configures authentication in PCP. Additionally, if you set <code class="literal">metrics_from_bpftrace: true</code> in the playbook, PCP uses this account to register <code class="literal">bpftrace</code> scripts.
								</dd></dl></div><p class="simpara">
						For details about all variables used in the playbook, see the <code class="literal">/usr/share/ansible/roles/rhel-system-roles.metrics/README.md</code> file on the control node.
					</p></li><li class="listitem"><p class="simpara">
						Validate the playbook syntax:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-playbook --ask-vault-pass --syntax-check ~/playbook.yml</strong></span></pre><p class="simpara">
						Note that this command only validates the syntax and does not protect against a wrong but valid configuration.
					</p></li><li class="listitem"><p class="simpara">
						Run the playbook:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-playbook --ask-vault-pass ~/playbook.yml</strong></span></pre></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						On a host with the <code class="literal">pcp</code> package installed, query a metric that requires authentication:
					</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
								Query the metrics by using the credentials that you used in the playbook:
							</p><pre class="literallayout"># <span class="strong strong"><strong>pminfo -fmdt -h pcp://managed-node-01.example.com?username=<span class="emphasis"><em>&lt;user&gt;</em></span> proc.fd.count</strong></span>
Password: <span class="emphasis"><em>&lt;password&gt;</em></span>

proc.fd.count
    inst [844 or "000844 /var/lib/pcp/pmdas/proc/pmdaproc"] value 5</pre><p class="simpara">
								If the command succeeds, it returns the value of the <code class="literal">proc.fd.count</code> metric.
							</p></li><li class="listitem"><p class="simpara">
								Run the command again, but omit the username to verify that the command fails for unauthenticated users:
							</p><pre class="literallayout"># <span class="strong strong"><strong>pminfo -fmdt -h pcp://managed-node-01.example.com proc.fd.count</strong></span>

proc.fd.count
Error: No permission to perform requested operation</pre></li></ol></div></li></ul></div><div class="itemizedlist"><p class="title"><strong>Next step</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Optional: <a class="link" href="#setting-up-grafana-by-using-the-metrics-rhel-system-role-to-monitor-multiple-hosts-with-performance-co-pilot_monitoring-performance-by-using-the-metrics-rhel-system-role" title="4.3. Setting up Grafana by using the metrics RHEL system role to monitor multiple hosts with Performance Co-Pilot">Configure Grafana to monitor PCP hosts and visualize metrics</a>.
					</li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">/usr/share/ansible/roles/rhel-system-roles.metrics/README.md</code> file
					</li><li class="listitem">
						<code class="literal">/usr/share/doc/rhel-system-roles/metrics/</code> directory
					</li><li class="listitem">
						<a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/ansible-vault_automating-system-administration-by-using-rhel-system-roles">Ansible vault</a>
					</li></ul></div></section><section class="section" id="setting-up-grafana-by-using-the-metrics-rhel-system-role-to-monitor-multiple-hosts-with-performance-co-pilot_monitoring-performance-by-using-the-metrics-rhel-system-role"><div class="titlepage"><div><div><h3 class="title">4.3. Setting up Grafana by using the <code class="literal">metrics</code> RHEL system role to monitor multiple hosts with Performance Co-Pilot</h3></div></div></div><p>
				If you have already configured Performance Co-Pilot (PCP) on multiple hosts, you can use an instance of Grafana to visualize the metrics for these hosts. You can display the live data and, if the PCP data is stored in a Redis database, also past data.
			</p><p>
				By using the <code class="literal">metrics</code> RHEL system role, you can automate the process of setting up Grafana, the PCP plug-in, the optional Redis database, and the configuration of the data sources.
			</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					If you use the <code class="literal">metrics</code> role to install Grafana on a host, the role also installs automatically PCP on this host.
				</p></div></rh-alert><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles">You have prepared the control node and the managed nodes</a>
					</li><li class="listitem">
						You are logged in to the control node as a user who can run playbooks on the managed nodes.
					</li><li class="listitem">
						The account you use to connect to the managed nodes has <code class="literal">sudo</code> permissions on them.
					</li><li class="listitem">
						<a class="link" href="#configuring-performance-co-pilot-by-using-the-metrics-rhel-system-role_monitoring-performance-by-using-the-metrics-rhel-system-role" title="4.1. Configuring Performance Co-Pilot by using the metrics RHEL system role">PCP is configured for remote access on the hosts you want to monitor</a>.
					</li><li class="listitem">
						The host on which you want to install Grafana can access port 44321 on the PCP nodes you plan to monitor.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Store your sensitive variables in an encrypted file:
					</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
								Create the vault:
							</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-vault create vault.yml</strong></span>
New Vault password: <span class="emphasis"><em>&lt;vault_password&gt;</em></span>
Confirm New Vault password: <span class="emphasis"><em>&lt;vault_password&gt;</em></span></pre></li><li class="listitem"><p class="simpara">
								After the <code class="literal">ansible-vault create</code> command opens an editor, enter the sensitive data in the <code class="literal"><span class="emphasis"><em>&lt;key&gt;</em></span>: <span class="emphasis"><em>&lt;value&gt;</em></span></code> format:
							</p><pre class="programlisting language-ini">grafana_admin_pwd: <span class="emphasis"><em>&lt;password&gt;</em></span></pre></li><li class="listitem">
								Save the changes, and close the editor. Ansible encrypts the data in the vault.
							</li></ol></div></li><li class="listitem"><p class="simpara">
						Create a playbook file, for example <code class="literal">~/playbook.yml</code>, with the following content:
					</p><pre class="programlisting language-yaml">---
- name: Monitoring performance metrics
  hosts: managed-node-01.example.com
  vars_files:
    - vault.yml
  tasks:
    - name: Set up Grafana to monitor multiple hosts
      ansible.builtin.include_role:
        name: rhel-system-roles.metrics
      vars:
        metrics_graph_service: true
        metrics_query_service: true
        metrics_monitored_hosts:
          - <span class="emphasis"><em>&lt;pcp_host_1.example.com&gt;</em></span>
          - <span class="emphasis"><em>&lt;pcp_host_2.example.com&gt;</em></span>
        metrics_manage_firewall: true
        metrics_manage_selinux: true

    - name: Set Grafana admin password
      ansible.builtin.shell:
        cmd: grafana-cli admin reset-admin-password "{{ grafana_admin_pwd }}"</pre><p class="simpara">
						The settings specified in the example playbook include the following:
					</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">metrics_graph_service: true</code></span></dt><dd>
									Installs Grafana and the PCP plug-in. Additionally, the role adds the <code class="literal">PCP Vector</code>, <code class="literal">PCP Redis</code>, and <code class="literal">PCP bpftrace</code> data sources to Grafana.
								</dd><dt><span class="term"><code class="literal">metrics_query_service: <span class="emphasis"><em>&lt;true|false&gt;</em></span></code></span></dt><dd>
									Defines whether the role should install and configure Redis for centralized metric recording. If enabled, data collected from PCP clients is stored in Redis and, as a result, you can also display historical data instead of only live data.
								</dd><dt><span class="term"><code class="literal">metrics_monitored_hosts: <span class="emphasis"><em>&lt;list_of_hosts&gt;</em></span></code></span></dt><dd>
									Defines the list of hosts to monitor. In Grafana, you can then display the data of these hosts and, additionally, the host that runs Grafana.
								</dd><dt><span class="term"><code class="literal">metrics_manage_firewall: <span class="emphasis"><em>&lt;true|false&gt;</em></span></code></span></dt><dd>
									Defines whether the role should open the required ports in the <code class="literal">firewalld</code> service. If you set this variable to <code class="literal">true</code>, you can, for example, access Grafana remotely.
								</dd></dl></div><p class="simpara">
						For details about all variables used in the playbook, see the <code class="literal">/usr/share/ansible/roles/rhel-system-roles.metrics/README.md</code> file on the control node.
					</p></li><li class="listitem"><p class="simpara">
						Validate the playbook syntax:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-playbook --ask-vault-pass --syntax-check ~/playbook.yml</strong></span></pre><p class="simpara">
						Note that this command only validates the syntax and does not protect against a wrong but valid configuration.
					</p></li><li class="listitem"><p class="simpara">
						Run the playbook:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>ansible-playbook --ask-vault-pass ~/playbook.yml</strong></span></pre></li></ol></div><div class="orderedlist"><p class="title"><strong>Verification</strong></p><ol class="orderedlist" type="1"><li class="listitem">
						Open <code class="literal">http://<span class="emphasis"><em>&lt;grafana_server_IP_or_hostname&gt;</em></span>:3000</code> in your browser, and log in as the <code class="literal">admin</code> user with the password you set in the procedure.
					</li><li class="listitem"><p class="simpara">
						Display monitoring data:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								To display live data:
							</p><div class="orderedlist"><ol class="orderedlist" type="i"><li class="listitem">
										Click <span class="guimenu">Menu</span> → <span class="guisubmenu">Apps</span> → <span class="guisubmenu">Performance Co-Pilot</span> → <span class="guimenuitem">PCP Vector Checklist</span>
									</li><li class="listitem">
										By default, the graphs display metrics from the host that runs Grafana. To switch to a different host, enter the hostname in the <code class="literal">hostspec</code> field and press <kbd class="keycap">Enter</kbd>.
									</li></ol></div></li><li class="listitem">
								To display historical data stored in a Redis database: <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance#creating-panel-and-alerts-in-pcp-redis-data-source_setting-up-graphical-representation-of-pcp-metrics">Create a panel with a PCP Redis data source</a>. This requires that you set <code class="literal">metrics_query_service: true</code> in the playbook.
							</li></ul></div></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">/usr/share/ansible/roles/rhel-system-roles.metrics/README.md</code> file
					</li><li class="listitem">
						<code class="literal">/usr/share/doc/rhel-system-roles/metrics/</code> directory
					</li><li class="listitem">
						<a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/ansible-vault_automating-system-administration-by-using-rhel-system-roles">Ansible vault</a>
					</li></ul></div></section><section class="section" id="configuring-web-hooks-in-performance-co-pilot-by-using-the-metrics-rhel-system-role_monitoring-performance-by-using-the-metrics-rhel-system-role"><div class="titlepage"><div><div><h3 class="title">4.4. Configuring web hooks in Performance Co-Pilot by using the <code class="literal">metrics</code> RHEL system role</h3></div></div></div><p>
				The Performance Co-Pilot (PCP) suite contains the performance metrics inference engine (PMIE) service. This service evaluates performance rules in real time. For example, you can use the default rules to detect excessive swap activities.
			</p><p>
				You can configure a host as a central PCP management site that collects the monitoring data from multiple PCP nodes. If a rule matches, this central host sends a notification to a web hook to notify other services. For example, the web hook can trigger Event-Driven Ansible to run on Ansible Automation Platform template or playbook on the host that had caused the event.
			</p><p>
				By using the <code class="literal">metrics</code> RHEL system role, you can automate the configuration of a central PCP management host that notifies a web hook.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles">You have prepared the control node and the managed nodes</a>
					</li><li class="listitem">
						You are logged in to the control node as a user who can run playbooks on the managed nodes.
					</li><li class="listitem">
						The account you use to connect to the managed nodes has <code class="literal">sudo</code> permissions on them.
					</li><li class="listitem">
						<a class="link" href="#configuring-performance-co-pilot-by-using-the-metrics-rhel-system-role_monitoring-performance-by-using-the-metrics-rhel-system-role" title="4.1. Configuring Performance Co-Pilot by using the metrics RHEL system role">PCP is configured for remote access on the hosts you want to monitor</a>.
					</li><li class="listitem">
						The host on which you want to configure PMIE can access port 44321 on the PCP nodes you plan to monitor.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Create a playbook file, for example <code class="literal">~/playbook.yml</code>, with the following content:
					</p><pre class="programlisting language-yaml">---
- name: Monitoring performance metrics
  hosts: managed-node-01.example.com
  tasks:
    - name: Configure PMIE web hooks
      ansible.builtin.include_role:
        name: redhat.rhel_system_roles.metrics
      vars:
        metrics_manage_firewall: true
        metrics_retention_days: 7
        metrics_monitored_hosts:
          - pcp-node-01.example.com
          - pcp-node-02.example.com
        metrics_webhook_endpoint: "https://&lt;webserver&gt;:&lt;port&gt;/&lt;endpoint&gt;"</pre><p class="simpara">
						The settings specified in the example playbook include the following:
					</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">metrics_retention_days: <span class="emphasis"><em>&lt;number&gt;</em></span></code></span></dt><dd>
									Sets the number of days after which the <code class="literal">pmlogger_daily</code> systemd timer removes old PCP archives.
								</dd><dt><span class="term"><code class="literal">metrics_manage_firewall: <span class="emphasis"><em>&lt;true|false&gt;</em></span></code></span></dt><dd>
									Defines whether the role should open the required ports in the <code class="literal">firewalld</code> service. If you want to remotely access PCP on the managed nodes, set this variable to <code class="literal">true</code>.
								</dd><dt><span class="term"><code class="literal">metrics_monitored_hosts: <span class="emphasis"><em>&lt;list_of_hosts&gt;</em></span></code></span></dt><dd>
									Specifies the hosts to observe.
								</dd><dt><span class="term"><code class="literal">metrics_webhook_endpoint: <span class="emphasis"><em>&lt;URL&gt;</em></span></code></span></dt><dd>
									Sets the web hook endpoint to which the performance metrics inference engine (PMIE) sends notifications about detected performance issues. By default, these issues are logged to the local system only.
								</dd></dl></div><p class="simpara">
						For details about all variables used in the playbook, see the <code class="literal">/usr/share/ansible/roles/rhel-system-roles.metrics/README.md</code> file on the control node.
					</p></li><li class="listitem"><p class="simpara">
						Validate the playbook syntax:
					</p><pre class="literallayout">$ ansible-playbook --syntax-check ~/playbook.yml</pre><p class="simpara">
						Note that this command only validates the syntax and does not protect against a wrong but valid configuration.
					</p></li><li class="listitem"><p class="simpara">
						Run the playbook:
					</p><pre class="literallayout">$ ansible-playbook ~/playbook.yml</pre></li></ol></div><div class="orderedlist"><p class="title"><strong>Verification</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Check the configuration summary on <code class="literal">managed-node-node-01.example.com</code>:
					</p><pre class="literallayout"># <span class="strong strong"><strong>ansible managed-node-01.example.com -m command -a 'pcp summary'</strong></span>
Performance Co-Pilot configuration on managed-node-01.example.com:

 platform: Linux managed-node-node-01.example.com 5.14.0-427.el9.x86_64 #1 SMP PREEMPT_DYNAMIC Fri Feb 23 01:51:18 EST 2024 x86_64
 hardware: 8 cpus, 1 disk, 1 node, 1773MB RAM
 timezone: CEST-2
 services: pmcd pmproxy
 pmcd: Version 6.2.0-1, 12 agents, 6 clients
 pmda: root pmcd proc pmproxy xfs linux nfsclient mmv kvm jbd2
       dm openmetrics
 pmlogger: primary logger: /var/log/pcp/pmlogger/managed-node-node-01.example.com/20240510.16.25
           pcp-node-01.example.com: /var/log/pmlogger/pcp-node-01.example.com/20240510.16.25
           pcp-node-02.example.com: /var/log/pmlogger/pcp-node-02.example.com/20240510.16.25
 pmie: primary engine: /var/log/pcp/pmie/managed-node-node-01.example.com/pmie.log
       pcp-node-01.example.com: : /var/log/pcp/pmie/pcp-node-01.example.com/pmie.log
       pcp-node-02.example.com: : /var/log/pcp/pmie/pcp-node-02.example.com/pmie.log</pre><p class="simpara">
						The last three lines confirm that PMIE is configured to monitor three systems.
					</p></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">/usr/share/ansible/roles/rhel-system-roles.metrics/README.md</code> file
					</li><li class="listitem">
						<code class="literal">/usr/share/doc/rhel-system-roles/metrics/</code> directory
					</li><li class="listitem">
						<a class="link" href="https://www.redhat.com/en/blog/automate-performance-management-performance-co-pilot">Automate performance management with Performance Co-Pilot using Event-Driven Ansible</a> blog post
					</li></ul></div></section></section><section class="chapter" id="setting-up-pcp_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 5. Setting up PCP</h2></div></div></div><p class="_abstract _abstract">
			Performance Co-Pilot (PCP) is a suite of tools, services, and libraries for monitoring, visualizing, storing, and analyzing system-level performance measurements.
		</p><section class="section" id="overview-of-pcp_setting-up-pcp"><div class="titlepage"><div><div><h3 class="title">5.1. Overview of PCP</h3></div></div></div><p class="_abstract _abstract">
				You can add performance metrics using Python, Perl, C++, and C interfaces. Analysis tools can use the Python, C++, C client APIs directly, and rich web applications can explore all available performance data using a JSON interface.
			</p><p>
				You can analyze data patterns by comparing live results with archived data.
			</p><p>
				Features of PCP:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Light-weight distributed architecture, which is useful during the centralized analysis of complex systems.
					</li><li class="listitem">
						It allows the monitoring and management of real-time data.
					</li><li class="listitem">
						It allows logging and retrieval of historical data.
					</li></ul></div><p>
				PCP has the following components:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						The Performance Metric Collector Daemon (<code class="literal">pmcd</code>) collects performance data from the installed Performance Metric Domain Agents (<code class="literal">pmda</code>). <span class="strong strong"><strong>PMDAs</strong></span> can be individually loaded or unloaded on the system and are controlled by the <span class="strong strong"><strong>PMCD</strong></span> on the same host.
					</li><li class="listitem">
						Various client tools, such as <code class="literal">pminfo</code> or <code class="literal">pmstat</code>, can retrieve, display, archive, and process this data on the same host or over the network.
					</li><li class="listitem">
						The <code class="literal">pcp</code> package provides the command-line tools and underlying functionality.
					</li><li class="listitem">
						The <code class="literal">pcp-gui</code> package provides the graphical application. Install the <code class="literal">pcp-gui</code> package by executing the <code class="literal">dnf install pcp-gui</code> command. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/monitoring-performance-with-performance-co-pilot_monitoring-and-managing-system-status-and-performance#visually-tracing-pcp-log-archives-with-pcp-charts_monitoring-performance-with-performance-co-pilot">Visually tracing PCP log archives with the PCP Charts application</a>.
					</li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">pcp(1)</code> man page on your system
					</li><li class="listitem">
						<code class="literal">/usr/share/doc/pcp-doc/</code> directory
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index#system-services-distributed-with-pcp_setting-up-pcp">System services and tools distributed with PCP</a>
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/articles/1145953">Index of Performance Co-Pilot (PCP) articles, solutions, tutorials, and white papers fromon Red Hat Customer Portal</a>
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/articles/2372811">Side-by-side comparison of PCP tools with legacy tools Red Hat Knowledgebase article</a>
					</li><li class="listitem">
						<a class="link" href="http://pcp.io/documentation.html">PCP upstream documentation</a>
					</li></ul></div></section><section class="section" id="installing-and-enabling-pcp_setting-up-pcp"><div class="titlepage"><div><div><h3 class="title">5.2. Installing and enabling PCP</h3></div></div></div><p class="_abstract _abstract">
				To begin using PCP, install all the required packages and enable the PCP monitoring services.
			</p><p>
				This procedure describes how to install PCP using the <code class="literal">pcp</code> package. If you want to automate the PCP installation, install it using the <code class="literal">pcp-zeroconf</code> package. For more information about installing PCP by using <code class="literal">pcp-zeroconf</code>, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index#setting-up-pcp-with-pcp-zeroconf_setting-up-graphical-representation-of-pcp-metrics">Setting up PCP with pcp-zeroconf</a>.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Install the <code class="literal">pcp</code> package:
					</p><pre class="screen"># dnf install pcp</pre></li><li class="listitem"><p class="simpara">
						Enable and start the <code class="literal">pmcd</code> service on the host machine:
					</p><pre class="screen"># systemctl enable pmcd

# systemctl start pmcd</pre></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Verify if the <code class="literal">pmcd</code> process is running on the host:
					</p><pre class="screen"># pcp

Performance Co-Pilot configuration on workstation:

platform: Linux workstation 4.18.0-80.el8.x86_64 #1 SMP Wed Mar 13 12:02:46 UTC 2019 x86_64
hardware: 12 cpus, 2 disks, 1 node, 36023MB RAM
timezone: CEST-2
services: pmcd
pmcd: Version 4.3.0-1, 8 agents
pmda: root pmcd proc xfs linux mmv kvm jbd2</pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">pmcd(1)</code> man page on your system
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index#system-services-distributed-with-pcp_setting-up-pcp">System services and tools distributed with PCP</a>
					</li></ul></div></section><section class="section" id="deploying-a-minimal-pcp-setup_setting-up-pcp"><div class="titlepage"><div><div><h3 class="title">5.3. Deploying a minimal PCP setup</h3></div></div></div><p class="_abstract _abstract">
				The minimal PCP setup collects performance statistics on Red Hat Enterprise Linux. The setup involves adding the minimum number of packages on a production system needed to gather data for further analysis.
			</p><p>
				You can analyze the resulting <code class="literal">tar.gz</code> file and the archive of the <code class="literal">pmlogger</code> output using various PCP tools and compare them with other sources of performance information.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						PCP is installed. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#installing-and-enabling-pcp_setting-up-pcp">Installing and enabling PCP</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Update the <code class="literal">pmlogger</code> configuration:
					</p><pre class="screen"># pmlogconf -r /var/lib/pcp/config/pmlogger/config.default</pre></li><li class="listitem"><p class="simpara">
						Start the <code class="literal">pmcd</code> and <code class="literal">pmlogger</code> services:
					</p><pre class="screen"># systemctl start pmcd.service

# systemctl start pmlogger.service</pre></li><li class="listitem">
						Execute the required operations to record the performance data.
					</li><li class="listitem"><p class="simpara">
						Stop the <code class="literal">pmcd</code> and <code class="literal">pmlogger</code> services:
					</p><pre class="screen"># systemctl stop pmcd.service

# systemctl stop pmlogger.service</pre></li><li class="listitem"><p class="simpara">
						Save the output and save it to a <code class="literal">tar.gz</code> file named based on the host name and the current date and time:
					</p><pre class="screen"># cd /var/log/pcp/pmlogger/

# tar -czf $(hostname).$(date +%F-%Hh%M).pcp.tar.gz $(hostname)</pre><p class="simpara">
						Extract this file and analyze the data using PCP tools.
					</p></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">pmlogconf(1)</code>, <code class="literal">pmlogger(1)</code>, and <code class="literal">pmcd(1)</code> man pages on your system
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#system-services-distributed-with-pcp_setting-up-pcp">System services and tools distributed with PCP</a>
					</li></ul></div></section><section class="section" id="system-services-distributed-with-pcp_setting-up-pcp"><div class="titlepage"><div><div><h3 class="title">5.4. System services and tools distributed with PCP</h3></div></div></div><p class="_abstract _abstract">
				Performance Co-Pilot (PCP) includes various system services and tools you can use for measuring performance. The basic package <code class="literal">pcp</code> includes the system services and basic tools. Additional tools are provided with the <code class="literal">pcp-system-tools</code>, <code class="literal">pcp-gui</code>, and <code class="literal">pcp-devel</code> packages.
			</p><div class="variablelist"><p class="title"><strong>Roles of system services distributed with PCP</strong></p><dl class="variablelist"><dt><span class="term"><code class="literal">pmcd</code></span></dt><dd>
							The Performance Metric Collector Daemon (PMCD).
						</dd><dt><span class="term"><code class="literal">pmie</code></span></dt><dd>
							The Performance Metrics Inference Engine.
						</dd><dt><span class="term"><code class="literal">pmlogger</code></span></dt><dd>
							The performance metrics logger.
						</dd><dt><span class="term"><code class="literal">pmproxy</code></span></dt><dd>
							The realtime and historical performance metrics proxy, time series query and REST API service.
						</dd></dl></div><div class="variablelist"><p class="title"><strong>Tools distributed with base PCP package</strong></p><dl class="variablelist"><dt><span class="term"><code class="literal">pcp</code></span></dt><dd>
							Displays the current status of a Performance Co-Pilot installation.
						</dd><dt><span class="term"><code class="literal">pcp-vmstat</code></span></dt><dd>
							Provides a high-level system performance overview every 5 seconds. Displays information about processes, memory, paging, block IO, traps, and CPU activity.
						</dd><dt><span class="term"><code class="literal">pmconfig</code></span></dt><dd>
							Displays the values of configuration parameters.
						</dd><dt><span class="term"><code class="literal">pmdiff</code></span></dt><dd>
							Compares the average values for every metric in either one or two archives, in a given time window, for changes that are likely to be of interest when searching for performance regressions.
						</dd><dt><span class="term"><code class="literal">pmdumplog</code></span></dt><dd>
							Displays control, metadata, index, and state information from a Performance Co-Pilot archive file.
						</dd><dt><span class="term"><code class="literal">pmfind</code></span></dt><dd>
							Finds PCP services on the network.
						</dd><dt><span class="term"><code class="literal">pmie</code></span></dt><dd>
							An inference engine that periodically evaluates a set of arithmetic, logical, and rule expressions. The metrics are collected either from a live system, or from a Performance Co-Pilot archive file.
						</dd><dt><span class="term"><code class="literal">pmieconf</code></span></dt><dd>
							Displays or sets configurable <code class="literal">pmie</code> variables.
						</dd><dt><span class="term"><code class="literal">pmiectl</code></span></dt><dd>
							Manages non-primary instances of <code class="literal">pmie</code>.
						</dd><dt><span class="term"><code class="literal">pminfo</code></span></dt><dd>
							Displays information about performance metrics. The metrics are collected either from a live system, or from a Performance Co-Pilot archive file.
						</dd><dt><span class="term"><code class="literal">pmlc</code></span></dt><dd>
							Interactively configures active <code class="literal">pmlogger</code> instances.
						</dd><dt><span class="term"><code class="literal">pmlogcheck</code></span></dt><dd>
							Identifies invalid data in a Performance Co-Pilot archive file.
						</dd><dt><span class="term"><code class="literal">pmlogconf</code></span></dt><dd>
							Creates and modifies a <code class="literal">pmlogger</code> configuration file.
						</dd><dt><span class="term"><code class="literal">pmlogctl</code></span></dt><dd>
							Manages non-primary instances of <code class="literal">pmlogger</code>.
						</dd><dt><span class="term"><code class="literal">pmloglabel</code></span></dt><dd>
							Verifies, modifies, or repairs the label of a Performance Co-Pilot archive file.
						</dd><dt><span class="term"><code class="literal">pmlogredact</code></span></dt><dd>
							Removes sensitive information from PCP archives.
						</dd><dt><span class="term"><code class="literal">pmlogsummary</code></span></dt><dd>
							Calculates statistical information about performance metrics stored in a Performance Co-Pilot archive file.
						</dd><dt><span class="term"><code class="literal">pmprobe</code></span></dt><dd>
							Determines the availability of performance metrics.
						</dd><dt><span class="term"><code class="literal">pmsocks</code></span></dt><dd>
							Allows access to a Performance Co-Pilot hosts through a firewall.
						</dd><dt><span class="term"><code class="literal">pmstat</code></span></dt><dd>
							Periodically displays a brief summary of system performance.
						</dd><dt><span class="term"><code class="literal">pmstore</code></span></dt><dd>
							Modifies the values of performance metrics.
						</dd><dt><span class="term"><code class="literal">pmtrace</code></span></dt><dd>
							Provides a command line interface to the trace PMDA.
						</dd><dt><span class="term"><code class="literal">pmval</code></span></dt><dd>
							Displays the current value of a performance metric.
						</dd></dl></div><div class="variablelist"><p class="title"><strong>Tools distributed with the separately installed <code class="literal">pcp-system-tools</code> package</strong></p><dl class="variablelist"><dt><span class="term"><code class="literal">pcp-atop</code></span></dt><dd>
							Shows the system-level occupation of the most critical hardware resources from the performance point of view: CPU, memory, disk, and network.
						</dd><dt><span class="term"><code class="literal">pcp-atopsar</code></span></dt><dd>
							Generates a system-level activity report over a variety of system resource utilization. The report is generated from a raw logfile previously recorded using <code class="literal">pmlogger</code> or the <code class="literal">-w</code> option of <code class="literal">pcp-atop</code>.
						</dd><dt><span class="term"><code class="literal">pcp-buddyinfo</code></span></dt><dd>
							Reports statistics for the buddy algorithm.
						</dd><dt><span class="term"><code class="literal">pcp-dmcache</code></span></dt><dd>
							Displays information about configured Device Mapper Cache targets, such as: device IOPs, cache and metadata device utilization, as well as hit and miss rates and ratios for both reads and writes for each cache device.
						</dd><dt><span class="term"><code class="literal">pcp-dstat</code></span></dt><dd>
							Displays metrics of one system at a time. To display metrics of multiple systems, use <code class="literal">--host</code> option.
						</dd><dt><span class="term"><code class="literal">pcp-free</code></span></dt><dd>
							Reports on free and used memory in a system.
						</dd><dt><span class="term"><code class="literal">pcp-htop</code></span></dt><dd>
							Displays all processes running on a system along with their command line arguments in a manner similar to the <code class="literal">top</code> command, but allows you to scroll vertically and horizontally as well as interact using a mouse. You can also view processes in a tree format and select and act on multiple processes at once.
						</dd><dt><span class="term"><code class="literal">pcp-ipcs</code></span></dt><dd>
							Displays information about the inter-process communication (IPC) facilities that the calling process has read access for.
						</dd><dt><span class="term"><code class="literal">pcp-meminfo</code></span></dt><dd>
							Reports statistics for the kernel system memory.
						</dd><dt><span class="term"><code class="literal">pcp-mpstat</code></span></dt><dd>
							Reports CPU and interrupt-related statistics.
						</dd><dt><span class="term"><code class="literal">pcp-netstat</code></span></dt><dd>
							Reports statistics for network protocols and network interfaces.
						</dd><dt><span class="term"><code class="literal">pcp-numastat</code></span></dt><dd>
							Displays NUMA allocation statistics from the kernel memory allocator.
						</dd><dt><span class="term"><code class="literal">pcp-pidstat</code></span></dt><dd>
							Displays information about individual tasks or processes running on the system, such as CPU percentage, memory and stack usage, scheduling, and priority. Reports live data for the local host by default.
						</dd><dt><span class="term"><code class="literal">pcp-shping</code></span></dt><dd>
							Samples and reports on the shell-ping service metrics exported by the <code class="literal">pmdashping</code> Performance Metrics Domain Agent (PMDA).
						</dd><dt><span class="term"><code class="literal">pcp-slabinfo</code></span></dt><dd>
							Reports statistics for the kernel slab allocator.
						</dd><dt><span class="term"><code class="literal">pcp-ss</code></span></dt><dd>
							Displays socket statistics collected by the <code class="literal">pmdasockets</code> PMDA.
						</dd><dt><span class="term"><code class="literal">pcp-tapestat</code></span></dt><dd>
							Reports I/O statistics for tape devices.
						</dd><dt><span class="term"><code class="literal">pcp-uptime</code></span></dt><dd>
							Displays how long the system has been running, how many users are currently logged on, and the system load averages for the past 1, 5, and 15 minutes.
						</dd><dt><span class="term"><code class="literal">pcp-zoneinfo</code></span></dt><dd>
							Reports statistics related to Non-Uniform Memory Access (NUMA) nodes.
						</dd><dt><span class="term"><code class="literal">pcp-verify</code></span></dt><dd>
							Inspects various aspects of a Performance Co-Pilot collector installation and reports on whether it is configured correctly for certain modes of operation.
						</dd><dt><span class="term"><code class="literal">pmiostat</code></span></dt><dd>
							Reports I/O statistics for SCSI devices (by default) or device-mapper devices (with the <code class="literal">-x</code> device-mapper option).
						</dd><dt><span class="term"><code class="literal">pmrep</code></span></dt><dd>
							Reports on selected, easily customizable, performance metrics values.
						</dd></dl></div><div class="variablelist"><p class="title"><strong>Tools distributed with the separately installed <code class="literal">pcp-gui</code> package</strong></p><dl class="variablelist"><dt><span class="term"><code class="literal">pmchart</code></span></dt><dd>
							Plots performance metrics values available through the facilities of the Performance Co-Pilot.
						</dd><dt><span class="term"><code class="literal">pmdumptext</code></span></dt><dd>
							Outputs the values of performance metrics collected live or from a Performance Co-Pilot archive.
						</dd></dl></div><div class="variablelist"><p class="title"><strong>Tools distributed with the separately installed <code class="literal">pcp-devel</code> package</strong></p><dl class="variablelist"><dt><span class="term"><code class="literal">pmclient</code></span></dt><dd>
							Displays high-level system performance metrics by using the Performance Metrics Application Programming Interface (PMAPI).
						</dd><dt><span class="term"><code class="literal">pmdbg</code></span></dt><dd>
							Displays available Performance Co-Pilot debug control flags and their values.
						</dd><dt><span class="term"><code class="literal">pmerr</code></span></dt><dd>
							Displays available Performance Co-Pilot error codes and their corresponding error messages.
						</dd></dl></div><div class="variablelist"><p class="title"><strong>Tool distributed with the separately installed <code class="literal">pcp-geolocate</code> package</strong></p><dl class="variablelist"><dt><span class="term"><code class="literal">pcp-geolocate</code></span></dt><dd>
							Discovers collector system geographical labels and reports the latitude and longitude for the local PCP collector host in JSON format.
						</dd></dl></div></section><section class="section" id="pcp-deployment-architectures_setting-up-pcp"><div class="titlepage"><div><div><h3 class="title">5.5. PCP deployment architectures</h3></div></div></div><p class="_abstract _abstract">
				Performance Co-Pilot (PCP) supports multiple deployment architectures, based on the scale of the PCP deployment, and offers many options to accomplish advanced setups.
			</p><p>
				Available scaling deployment setup variants based on the recommended deployment set up by Red Hat, sizing factors, and configuration options include:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">Localhost</code></span></dt><dd><p class="simpara">
							Each service runs locally on the monitored machine. When you start a service without any configuration changes, this is the default deployment. Scaling beyond the individual node is not possible in this case.
						</p><p class="simpara">
							By default, the deployment setup for Redis is standalone, localhost. However, Redis can optionally perform in a highly-available and highly scalable clustered fashion, where data is shared across multiple hosts. Another viable option is to deploy a Redis cluster in the cloud, or to utilize a managed Redis cluster from a cloud vendor.
						</p></dd><dt><span class="term"><code class="literal">Decentralized</code></span></dt><dd><p class="simpara">
							The only difference between localhost and decentralized setup is the centralized Redis service. In this model, the host executes <code class="literal">pmlogger</code> service on each monitored host and retrieves metrics from a local <code class="literal">pmcd</code> instance. A local <code class="literal">pmproxy</code> service then exports the performance metrics to a central Redis instance.
						</p><div class="figure" id="idm140280153089744"><p class="title"><strong>Figure 5.1. Decentralized logging</strong></p><div class="figure-contents"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/8e69aa84f8186f3fa2ee8f1787c2dc17/173_RHEL_instaling_PCP_0721_decentralized.png" alt="Decentralized logging"></div></div></div></dd><dt><span class="term"><code class="literal">Centralized logging - pmlogger farm</code></span></dt><dd><p class="simpara">
							When the resource usage on the monitored hosts is constrained, another deployment option is a <code class="literal">pmlogger</code> farm, which is also known as centralized logging. In this setup, a single logger host executes multiple <code class="literal">pmlogger</code> processes, and each is configured to retrieve performance metrics from a different remote <code class="literal">pmcd</code> host. The centralized logger host is also configured to execute the <code class="literal">pmproxy</code> service, which discovers the resulting PCP archives logs and loads the metric data into a Redis instance.
						</p><div class="figure" id="idm140280133379776"><p class="title"><strong>Figure 5.2. Centralized logging - pmlogger farm</strong></p><div class="figure-contents"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/6a30238925dab26408092ae39258801e/173_RHEL_instaling_PCP_0721_centralized.png" alt="Centralized logging - pmlogger farm"></div></div></div></dd><dt><span class="term"><code class="literal">Federated - multiple pmlogger farms</code></span></dt><dd><p class="simpara">
							For large scale deployments, Red Hat recommends to deploy multiple <code class="literal">pmlogger</code> farms in a federated fashion. For example, one <code class="literal">pmlogger</code> farm per rack or data center. Each <code class="literal">pmlogger</code> farm loads the metrics into a central Redis instance.
						</p><div class="figure" id="idm140280158647136"><p class="title"><strong>Figure 5.3. Federated - multiple pmlogger farms</strong></p><div class="figure-contents"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/0184fc52d4cf8596c8a0927914cab33c/173_RHEL_instaling_PCP_0721_federated.png" alt="Federated - multiple pmlogger farms"></div></div></div></dd></dl></div><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					By default, the deployment setup for Redis is standalone, localhost. However, Redis can optionally perform in a highly-available and highly scalable clustered fashion, where data is shared across multiple hosts. Another viable option is to deploy a Redis cluster in the cloud, or to utilize a managed Redis cluster from a cloud vendor.
				</p></div></rh-alert><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">pcp(1)</code>, <code class="literal">pmlogger(1)</code>, <code class="literal">pmproxy(1)</code>, and <code class="literal">pmcd(1)</code> man pages on your system
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index#recommended-deployment-architecture_setting-up-pcp">Recommended deployment architecture</a>
					</li></ul></div></section><section class="section" id="recommended-deployment-architecture_setting-up-pcp"><div class="titlepage"><div><div><h3 class="title">5.6. Recommended deployment architecture</h3></div></div></div><p class="_abstract _abstract">
				The following table describes the recommended deployment architectures based on the number of monitored hosts.
			</p><rh-table id="idm140280153819360"><table class="gt-4-cols lt-7-rows"><caption>Table 5.1. Recommended deployment architecture</caption><colgroup><col style="width: 25%; " class="col_1"><!--Empty--><col style="width: 25%; " class="col_2"><!--Empty--><col style="width: 25%; " class="col_3"><!--Empty--><col style="width: 25%; " class="col_4"><!--Empty--></colgroup><thead><tr><th align="left" valign="top" id="idm140280150578208" scope="col">Number of hosts (N)</th><th align="left" valign="top" id="idm140280150577120" scope="col">1-10</th><th align="left" valign="top" id="idm140280150576032" scope="col">10-100</th><th align="left" valign="top" id="idm140280150574944" scope="col">100-1000</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm140280150578208"> <p>
								<code class="literal">pmcd</code> servers
							</p>
							 </td><td align="left" valign="top" headers="idm140280150577120"> <p>
								N
							</p>
							 </td><td align="left" valign="top" headers="idm140280150576032"> <p>
								N
							</p>
							 </td><td align="left" valign="top" headers="idm140280150574944"> <p>
								N
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm140280150578208"> <p>
								<code class="literal">pmlogger</code> servers
							</p>
							 </td><td align="left" valign="top" headers="idm140280150577120"> <p>
								1 to N
							</p>
							 </td><td align="left" valign="top" headers="idm140280150576032"> <p>
								N/10 to N
							</p>
							 </td><td align="left" valign="top" headers="idm140280150574944"> <p>
								N/100 to N
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm140280150578208"> <p>
								<code class="literal">pmproxy</code> servers
							</p>
							 </td><td align="left" valign="top" headers="idm140280150577120"> <p>
								1 to N
							</p>
							 </td><td align="left" valign="top" headers="idm140280150576032"> <p>
								1 to N
							</p>
							 </td><td align="left" valign="top" headers="idm140280150574944"> <p>
								N/100 to N
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm140280150578208"> <p>
								Redis servers
							</p>
							 </td><td align="left" valign="top" headers="idm140280150577120"> <p>
								1 to N
							</p>
							 </td><td align="left" valign="top" headers="idm140280150576032"> <p>
								1 to N/10
							</p>
							 </td><td align="left" valign="top" headers="idm140280150574944"> <p>
								N/100 to N/10
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm140280150578208"> <p>
								Redis cluster
							</p>
							 </td><td align="left" valign="top" headers="idm140280150577120"> <p>
								No
							</p>
							 </td><td align="left" valign="top" headers="idm140280150576032"> <p>
								Maybe
							</p>
							 </td><td align="left" valign="top" headers="idm140280150574944"> <p>
								Yes
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm140280150578208"> <p>
								Recommended deployment setup
							</p>
							 </td><td align="left" valign="top" headers="idm140280150577120"> <p>
								Localhost, Decentralized, or Centralized logging
							</p>
							 </td><td align="left" valign="top" headers="idm140280150576032"> <p>
								Decentralized, Centralized logging, or Federated
							</p>
							 </td><td align="left" valign="top" headers="idm140280150574944"> <p>
								Decentralized or Federated
							</p>
							 </td></tr></tbody></table></rh-table></section><section class="section" id="sizing-factors_setting-up-pcp"><div class="titlepage"><div><div><h3 class="title">5.7. Sizing factors</h3></div></div></div><p class="_abstract _abstract">
				The following are the sizing factors required for scaling:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">Remote system size</code></span></dt><dd>
							The number of CPUs, disks, network interfaces, and other hardware resources affects the amount of data collected by each <code class="literal">pmlogger</code> on the centralized logging host.
						</dd><dt><span class="term"><code class="literal">Logged Metrics</code></span></dt><dd>
							The number and types of logged metrics play an important role. In particular, the <code class="literal">per-process proc.*</code> metrics require a large amount of disk space, for example, with the standard <code class="literal">pcp-zeroconf</code> setup, 10s logging interval, 11 MB without proc metrics versus 155 MB with proc metrics - a factor of 10 times more. Additionally, the number of instances for each metric, for example the number of CPUs, block devices, and network interfaces also impacts the required storage capacity.
						</dd><dt><span class="term"><code class="literal">Logging Interval</code></span></dt><dd>
							The interval how often metrics are logged, affects the storage requirements. The expected daily PCP archive file sizes are written to the <code class="literal">pmlogger.log</code> file for each <code class="literal">pmlogger</code> instance. These values are uncompressed estimates. Since PCP archives compress very well, approximately 10:1, the actual long term disk space requirements can be determined for a particular site.
						</dd><dt><span class="term"><code class="literal">pmlogrewrite</code></span></dt><dd>
							After every PCP upgrade, the <code class="literal">pmlogrewrite</code> tool is executed and rewrites old archives if there were changes in the metric metadata from the previous version and the new version of PCP. This process duration scales linear with the number of archives stored.
						</dd></dl></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">pmlogrewrite(1)</code> and <code class="literal">pmlogger(1)</code> man pages on your system
					</li></ul></div></section><section class="section" id="configuration-options-for-pcp-scaling_setting-up-pcp"><div class="titlepage"><div><div><h3 class="title">5.8. Configuration options for PCP scaling</h3></div></div></div><p class="_abstract _abstract">
				The following are the configuration options, which are required for scaling:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">sysctl and rlimit settings</code></span></dt><dd>
							When archive discovery is enabled, <code class="literal">pmproxy</code> requires four descriptors for every <code class="literal">pmlogger</code> that it is monitoring or log-tailing, along with the additional file descriptors for the service logs and <code class="literal">pmproxy</code> client sockets, if any. Each <code class="literal">pmlogger</code> process uses about 20 file descriptors for the remote <code class="literal">pmcd</code> socket, archive files, service logs, and others. In total, this can exceed the default 1024 soft limit on a system running around 200 <code class="literal">pmlogger</code> processes. The <code class="literal">pmproxy</code> service in <code class="literal">pcp-5.3.0</code> and later automatically increases the soft limit to the hard limit. On earlier versions of PCP, tuning is required if a high number of <code class="literal">pmlogger</code> processes are to be deployed, and this can be accomplished by increasing the soft or hard limits for <code class="literal">pmlogger</code>. For more information, see <a class="link" href="https://access.redhat.com/solutions/1346533">How to set limits (ulimit) for services run by systemd</a>.
						</dd><dt><span class="term"><code class="literal">Local Archives</code></span></dt><dd>
							The <code class="literal">pmlogger</code> service stores metrics of local and remote <code class="literal">pmcds</code> in the <code class="literal">/var/log/pcp/pmlogger/</code> directory. To control the logging interval of the local system, update the <code class="literal">/etc/pcp/pmlogger/control.d/<span class="emphasis"><em>configfile</em></span></code> file and add <code class="literal">-t <span class="emphasis"><em>X</em></span></code> in the arguments, where <span class="emphasis"><em>X</em></span> is the logging interval in seconds. To configure which metrics should be logged, execute <code class="literal">pmlogconf /var/lib/pcp/config/pmlogger/config.<span class="emphasis"><em>clienthostname</em></span></code>. This command deploys a configuration file with a default set of metrics, which can optionally be further customized. To specify retention settings, that is when to purge old PCP archives, update the <code class="literal">/etc/sysconfig/pmlogger_timers</code> file and specify <code class="literal">PMLOGGER_DAILY_PARAMS="-E -k <span class="emphasis"><em>X</em></span>"</code>, where <span class="emphasis"><em>X</em></span> is the amount of days to keep PCP archives.
						</dd><dt><span class="term"><code class="literal">Redis</code></span></dt><dd><p class="simpara">
							The <code class="literal">pmproxy</code> service sends logged metrics from <code class="literal">pmlogger</code> to a Redis instance. The following are the available two options to specify the retention settings in the <code class="literal">/etc/pcp/pmproxy/pmproxy.conf</code> configuration file:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									<code class="literal">stream.expire</code> specifies the duration when stale metrics should be removed, that is metrics which were not updated in a specified amount of time in seconds.
								</li><li class="listitem">
									<code class="literal">stream.maxlen</code> specifies the maximum number of metric values for one metric per host. This setting should be the retention time divided by the logging interval, for example 20160 for 14 days of retention and 60s logging interval (60*60*24*14/60)
								</li></ul></div></dd></dl></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">pmproxy(1)</code>, <code class="literal">pmlogger(1)</code>, and <code class="literal">sysctl(8)</code> man pages on your system
					</li></ul></div></section><section class="section" id="example-analyzing-the-centralized-logging-deployment_setting-up-pcp"><div class="titlepage"><div><div><h3 class="title">5.9. Example: Analyzing the centralized logging deployment</h3></div></div></div><p class="_abstract _abstract">
				The following results were gathered on a centralized logging setup, also known as pmlogger farm deployment, with a default <code class="literal">pcp-zeroconf 5.3.0</code> installation, where each remote host is an identical container instance running <code class="literal">pmcd</code> on a server with 64 CPU cores, 376 GB RAM, and one disk attached.
			</p><p>
				The logging interval is 10s, proc metrics of remote nodes are not included, and the memory values refer to the Resident Set Size (RSS) value.
			</p><rh-table id="idm140280139551008"><table class="lt-4-cols lt-7-rows"><caption>Table 5.2. Detailed utilization statistics for 10s logging interval</caption><colgroup><col style="width: 33%; " class="col_1"><!--Empty--><col style="width: 33%; " class="col_2"><!--Empty--><col style="width: 33%; " class="col_3"><!--Empty--></colgroup><thead><tr><th align="left" valign="top" id="idm140280161850736" scope="col">Number of Hosts</th><th align="left" valign="top" id="idm140280161849648" scope="col">10</th><th align="left" valign="top" id="idm140280161848560" scope="col">50</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm140280161850736"> <p>
								PCP Archives Storage per Day
							</p>
							 </td><td align="left" valign="top" headers="idm140280161849648"> <p>
								91 MB
							</p>
							 </td><td align="left" valign="top" headers="idm140280161848560"> <p>
								522 MB
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm140280161850736"> <p>
								<code class="literal">pmlogger</code> Memory
							</p>
							 </td><td align="left" valign="top" headers="idm140280161849648"> <p>
								160 MB
							</p>
							 </td><td align="left" valign="top" headers="idm140280161848560"> <p>
								580 MB
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm140280161850736"> <p>
								<code class="literal">pmlogger</code> Network per Day (In)
							</p>
							 </td><td align="left" valign="top" headers="idm140280161849648"> <p>
								2 MB
							</p>
							 </td><td align="left" valign="top" headers="idm140280161848560"> <p>
								9 MB
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm140280161850736"> <p>
								<code class="literal">pmproxy</code> Memory
							</p>
							 </td><td align="left" valign="top" headers="idm140280161849648"> <p>
								1.4 GB
							</p>
							 </td><td align="left" valign="top" headers="idm140280161848560"> <p>
								6.3 GB
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm140280161850736"> <p>
								Redis Memory per Day
							</p>
							 </td><td align="left" valign="top" headers="idm140280161849648"> <p>
								2.6 GB
							</p>
							 </td><td align="left" valign="top" headers="idm140280161848560"> <p>
								12 GB
							</p>
							 </td></tr></tbody></table></rh-table><rh-table id="idm140280148158976"><table class="gt-4-cols lt-7-rows"><caption>Table 5.3. Used resources depending on monitored hosts for 60s logging interval</caption><colgroup><col style="width: 25%; " class="col_1"><!--Empty--><col style="width: 25%; " class="col_2"><!--Empty--><col style="width: 25%; " class="col_3"><!--Empty--><col style="width: 25%; " class="col_4"><!--Empty--></colgroup><thead><tr><th align="left" valign="top" id="idm140280159714928" scope="col">Number of Hosts</th><th align="left" valign="top" id="idm140280159713840" scope="col">10</th><th align="left" valign="top" id="idm140280159712752" scope="col">50</th><th align="left" valign="top" id="idm140280159711664" scope="col">100</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm140280159714928"> <p>
								PCP Archives Storage per Day
							</p>
							 </td><td align="left" valign="top" headers="idm140280159713840"> <p>
								20 MB
							</p>
							 </td><td align="left" valign="top" headers="idm140280159712752"> <p>
								120 MB
							</p>
							 </td><td align="left" valign="top" headers="idm140280159711664"> <p>
								271 MB
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm140280159714928"> <p>
								<code class="literal">pmlogger</code> Memory
							</p>
							 </td><td align="left" valign="top" headers="idm140280159713840"> <p>
								104 MB
							</p>
							 </td><td align="left" valign="top" headers="idm140280159712752"> <p>
								524 MB
							</p>
							 </td><td align="left" valign="top" headers="idm140280159711664"> <p>
								1049 MB
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm140280159714928"> <p>
								<code class="literal">pmlogger</code> Network per Day (In)
							</p>
							 </td><td align="left" valign="top" headers="idm140280159713840"> <p>
								0.38 MB
							</p>
							 </td><td align="left" valign="top" headers="idm140280159712752"> <p>
								1.75 MB
							</p>
							 </td><td align="left" valign="top" headers="idm140280159711664"> <p>
								3.48 MB
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm140280159714928"> <p>
								<code class="literal">pmproxy</code> Memory
							</p>
							 </td><td align="left" valign="top" headers="idm140280159713840"> <p>
								2.67 GB
							</p>
							 </td><td align="left" valign="top" headers="idm140280159712752"> <p>
								5.5GB
							</p>
							 </td><td align="left" valign="top" headers="idm140280159711664"> <p>
								9 GB
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm140280159714928"> <p>
								Redis Memory per Day
							</p>
							 </td><td align="left" valign="top" headers="idm140280159713840"> <p>
								0.54 GB
							</p>
							 </td><td align="left" valign="top" headers="idm140280159712752"> <p>
								2.65 GB
							</p>
							 </td><td align="left" valign="top" headers="idm140280159711664"> <p>
								5.3 GB
							</p>
							 </td></tr></tbody></table></rh-table><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					The <code class="literal">pmproxy</code> queues Redis requests and employs Redis pipelining to speed up Redis queries. This can result in high memory usage. For troubleshooting this issue, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index#troubleshooting-high-memory-usage_setting-up-pcp">Troubleshooting high memory usage</a>.
				</p></div></rh-alert></section><section class="section" id="example-analyzing-the-federated-setup-deployment_setting-up-pcp"><div class="titlepage"><div><div><h3 class="title">5.10. Example: Analyzing the federated setup deployment</h3></div></div></div><p class="_abstract _abstract">
				The following results were observed on a federated setup, also known as multiple <code class="literal">pmlogger</code> farms, consisting of three centralized logging (<code class="literal">pmlogger</code> farm) setups, where each <code class="literal">pmlogger</code> farm was monitoring 100 remote hosts, that is 300 hosts in total.
			</p><p>
				This setup of the <code class="literal">pmlogger</code> farms is identical to the configuration mentioned in the
			</p><p>
				<a class="link" href="#example-analyzing-the-centralized-logging-deployment_setting-up-pcp" title="5.9. Example: Analyzing the centralized logging deployment">Example: Analyzing the centralized logging deployment</a> for 60s logging interval, except that the Redis servers were operating in cluster mode.
			</p><rh-table id="idm140280153889888"><table class="gt-4-cols lt-7-rows"><caption>Table 5.4. Used resources depending on federated hosts for 60s logging interval</caption><colgroup><col style="width: 20%; " class="col_1"><!--Empty--><col style="width: 20%; " class="col_2"><!--Empty--><col style="width: 20%; " class="col_3"><!--Empty--><col style="width: 20%; " class="col_4"><!--Empty--><col style="width: 20%; " class="col_5"><!--Empty--></colgroup><thead><tr><th align="left" valign="top" id="idm140280142321680" scope="col">PCP Archives Storage per Day</th><th align="left" valign="top" id="idm140280142320576" scope="col"><code class="literal">pmlogger</code> Memory</th><th align="left" valign="top" id="idm140280142319168" scope="col">Network per Day (In/Out)</th><th align="left" valign="top" id="idm140280142318064" scope="col"><code class="literal">pmproxy</code> Memory</th><th align="left" valign="top" id="idm140280142316656" scope="col">Redis Memory per Day</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm140280142321680"> <p>
								277 MB
							</p>
							 </td><td align="left" valign="top" headers="idm140280142320576"> <p>
								1058 MB
							</p>
							 </td><td align="left" valign="top" headers="idm140280142319168"> <p>
								15.6 MB / 12.3 MB
							</p>
							 </td><td align="left" valign="top" headers="idm140280142318064"> <p>
								6-8 GB
							</p>
							 </td><td align="left" valign="top" headers="idm140280142316656"> <p>
								5.5 GB
							</p>
							 </td></tr></tbody></table></rh-table><p>
				Here, all values are per host. The network bandwidth is higher due to the inter-node communication of the Redis cluster.
			</p></section><section class="section" id="establishing-secure-pcp-connections_setting-up-pcp"><div class="titlepage"><div><div><h3 class="title">5.11. Establishing secure PCP connections</h3></div></div></div><p class="_abstract _abstract">
				You can configure PCP collector and monitoring components to participate in secure PCP protocol exchanges.
			</p><section class="section" id="secure-pcp-connections_establishing-secure-pcp-connections"><div class="titlepage"><div><div><h4 class="title">5.11.1. Secure PCP connections</h4></div></div></div><p>
					You can establish secure connections between Performance Co-Pilot (PCP) collector and monitoring components. PCP collector components are the parts of PCP that collect and extract performance data from different sources. PCP monitor components are the parts of PCP that display data collected from hosts or archives that have the PCP collector components installed. Establishing secure connections between these components helps prevent unauthorized parties from accessing or modifying the data being collected and monitored.
				</p><p>
					All connections with the Performance Metrics Collector Daemon (<code class="literal">pmcd</code>) are made using the TCP/IP based PCP protocol. Protocol proxying and the PCP REST APIs are served by the <code class="literal">pmproxy</code> daemon - the REST API can be accessed over HTTPS, ensuring a secure connection.
				</p><p>
					Both the <code class="literal">pmcd</code> and <code class="literal">pmproxy</code> daemons are capable of simultaneous TLS and non-TLS communications on a single port. The default port for <code class="literal">pmcd</code> is 44321 and 44322 for <code class="literal">pmproxy</code>. This means that you do not have to choose between TLS or non-TLS communications for your PCP collector systems and can use both at the same time.
				</p></section><section class="section" id="configuring-secure-connections-for-pcp-collector-components_establishing-secure-pcp-connections"><div class="titlepage"><div><div><h4 class="title">5.11.2. Configuring secure connections for PCP collector components</h4></div></div></div><p>
					All PCP collector systems must have valid certificates in order to participate in secure PCP protocol exchanges.
				</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
						the <code class="literal">pmproxy</code> daemon operates as both a client and a server from the perspective of TLS.
					</p></div></rh-alert><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							PCP is installed. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#installing-and-enabling-pcp_setting-up-pcp">Installing and enabling PCP</a>.
						</li><li class="listitem"><p class="simpara">
							The private client key is stored in the <code class="literal">/etc/pcp/tls/client.key</code> file. If you use a different path, adapt the corresponding steps of the procedure.
						</p><p class="simpara">
							For details about creating a private key and certificate signing request (CSR), as well as how to request a certificate from a certificate authority (CA), see your CA’s documentation.
						</p></li><li class="listitem">
							The TLS client certificate is stored in the <code class="literal">/etc/pcp/tls/client.crt</code> file. If you use a different path, adapt the corresponding steps of the procedure.
						</li><li class="listitem">
							The CA certificate is stored in the <code class="literal">/etc/pcp/tls/ca.crt</code> file. If you use a different path, adapt the corresponding steps of the procedure. Additionally, for the <code class="literal">pmproxy</code> daemon:
						</li><li class="listitem">
							The private server key is stored in the <code class="literal">/etc/pcp/tls/server.key</code> file. If you use a different path, adapt the corresponding steps of the procedure
						</li><li class="listitem">
							The TLS server certificate is stored in the <code class="literal">/etc/pcp/tls/server.crt</code> file. If you use a different path, adapt the corresponding steps of the procedure.
						</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Update the PCP TLS configuration file on the collector systems to use the CA issued certificates to establish a secure connection:
						</p><pre class="screen"># cat &gt; /etc/pcp/tls.conf &lt;&lt; END
tls-ca-cert-file = /etc/pcp/tls/ca.crt
tls-key-file = /etc/pcp/tls/server.key
tls-cert-file = /etc/pcp/tls/server.crt
tls-client-key-file = /etc/pcp/tls/client.key
tls-client-cert-file = /etc/pcp/tls/client.crt
END</pre></li><li class="listitem"><p class="simpara">
							Restart the PCP collector infrastructure:
						</p><pre class="screen"># systemctl restart pmcd.service
# systemctl restart pmproxy.service</pre></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							Verify the TLS configuration:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem"><p class="simpara">
									On the <code class="literal">pmcd</code> service:
								</p><pre class="screen"># grep 'Info:' /var/log/pcp/pmcd/pmcd.log
[Tue Feb 07 11:47:33] pmcd(6558) Info: OpenSSL 3.0.7 setup</pre></li><li class="listitem"><p class="simpara">
									On the <code class="literal">pmproxy</code> service:
								</p><pre class="screen"># grep 'Info:' /var/log/pcp/pmproxy/pmproxy.log
[Tue Feb 07 11:44:13] pmproxy(6014) Info: OpenSSL 3.0.7 setup</pre></li></ul></div></li></ul></div></section><section class="section" id="configuring-secure-connections-for-pcp-monitoring-components_establishing-secure-pcp-connections"><div class="titlepage"><div><div><h4 class="title">5.11.3. Configuring secure connections for PCP monitoring components</h4></div></div></div><p>
					Configure your PCP monitoring components to participate in secure PCP protocol exchanges.
				</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							PCP is installed. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#installing-and-enabling-pcp_setting-up-pcp">Installing and enabling PCP</a>.
						</li><li class="listitem"><p class="simpara">
							The private client key is stored in the <code class="literal">~/.pcp/tls/client.key</code> file. If you use a different path, adapt the corresponding steps of the procedure.
						</p><p class="simpara">
							For details about creating a private key and certificate signing request (CSR), as well as how to request a certificate from a certificate authority (CA), see your CA’s documentation.
						</p></li><li class="listitem">
							The TLS client certificate is stored in the <code class="literal">~/.pcp/tls/client.crt</code> file. If you use a different path, adapt the corresponding steps of the procedure.
						</li><li class="listitem">
							The CA certificate is stored in the <code class="literal">/etc/pcp/tls/ca.crt</code> file. If you use a different path, adapt the corresponding steps of the procedure.
						</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Create a TLS configuration file with the following information:
						</p><pre class="screen">$ home=<code class="literal">echo ~</code>
$ cat &gt; ~/.pcp/tls.conf &lt;&lt; END
tls-ca-cert-file = /etc/pcp/tls/ca.crt
tls-key-file = $home/.pcp/tls/client.key
tls-cert-file = $home/.pcp/tls/client.crt
END</pre></li><li class="listitem"><p class="simpara">
							Establish the secure connection:
						</p><pre class="screen">$ export PCP_SECURE_SOCKETS=enforce
$ export PCP_TLSCONF_PATH=~/.pcp/tls.conf</pre></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							Verify the secure connection is configured:
						</p><pre class="screen">$ pminfo --fetch --host pcps://localhost kernel.all.load

kernel.all.load
    inst [1 or "1 minute"] value 1.26
    inst [5 or "5 minute"] value 1.29
    inst [15 or "15 minute"] value 1.28</pre></li></ul></div></section></section><section class="section" id="troubleshooting-high-memory-usage_setting-up-pcp"><div class="titlepage"><div><div><h3 class="title">5.12. Troubleshooting high memory usage</h3></div></div></div><p class="_abstract _abstract">
				The following scenarios can result in high memory usage:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						The <code class="literal">pmproxy</code> process is busy processing new PCP archives and does not have spare CPU cycles to process Redis requests and responses.
					</li><li class="listitem">
						The Redis node or cluster is overloaded and cannot process incoming requests on time.
					</li></ul></div><p>
				The <code class="literal">pmproxy</code> service daemon uses Redis streams and supports the configuration parameters, which are PCP tuning parameters and affects Redis memory usage and key retention. The <code class="literal">/etc/pcp/pmproxy/pmproxy.conf</code> file lists the available configuration options for <code class="literal">pmproxy</code> and the associated APIs.
			</p><p>
				The following procedure describes how to troubleshoot high memory usage issue.
			</p><div class="orderedlist"><p class="title"><strong>Prerequisites</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Install the <code class="literal">pcp-pmda-redis</code> package:
					</p><pre class="screen"># dnf install pcp-pmda-redis</pre></li><li class="listitem"><p class="simpara">
						Install the redis PMDA:
					</p><pre class="screen"># cd /var/lib/pcp/pmdas/redis &amp;&amp; ./Install</pre></li></ol></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						To troubleshoot high memory usage, execute the following command and observe the <code class="literal">inflight</code> column:
					</p><pre class="literallayout">$ pmrep :pmproxy
         backlog  inflight  reqs/s  resp/s   wait req err  resp err  changed  throttled
          byte     count   count/s  count/s  s/s  count/s   count/s  count/s   count/s
14:59:08   0         0       N/A       N/A   N/A    N/A      N/A      N/A        N/A
14:59:09   0         0    2268.9    2268.9    28     0        0       2.0        4.0
14:59:10   0         0       0.0       0.0     0     0        0       0.0        0.0
14:59:11   0         0       0.0       0.0     0     0        0       0.0        0.0</pre><p class="simpara">
						This column shows how many Redis requests are in-flight, which means they are queued or sent, and no reply was received so far.
					</p><p class="simpara">
						A high number indicates one of the following conditions:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
								The <code class="literal">pmproxy</code> process is busy processing new PCP archives and does not have spare CPU cycles to process Redis requests and responses.
							</li><li class="listitem">
								The Redis node or cluster is overloaded and cannot process incoming requests on time.
							</li></ul></div></li><li class="listitem"><p class="simpara">
						To troubleshoot the high memory usage issue, reduce the number of <code class="literal">pmlogger</code> processes for this farm, and add another pmlogger farm. Use the federated - multiple pmlogger farms setup.
					</p><p class="simpara">
						If the Redis node is using 100% CPU for an extended amount of time, move it to a host with better performance or use a clustered Redis setup instead.
					</p></li><li class="listitem"><p class="simpara">
						To view the <code class="literal">pmproxy.redis.*</code> metrics, use the following command:
					</p><pre class="screen">$ pminfo -ftd pmproxy.redis
pmproxy.redis.responses.wait [wait time for responses]
    Data Type: 64-bit unsigned int  InDom: PM_INDOM_NULL 0xffffffff
    Semantics: counter  Units: microsec
    value 546028367374
pmproxy.redis.responses.error [number of error responses]
    Data Type: 64-bit unsigned int  InDom: PM_INDOM_NULL 0xffffffff
    Semantics: counter  Units: count
    value 1164
[...]
pmproxy.redis.requests.inflight.bytes [bytes allocated for inflight requests]
    Data Type: 64-bit int  InDom: PM_INDOM_NULL 0xffffffff
    Semantics: discrete  Units: byte
    value 0

pmproxy.redis.requests.inflight.total [inflight requests]
    Data Type: 64-bit unsigned int  InDom: PM_INDOM_NULL 0xffffffff
    Semantics: discrete  Units: count
    value 0
[...]</pre><p class="simpara">
						To view how many Redis requests are inflight, see the <code class="literal">pmproxy.redis.requests.inflight.total</code> metric and <code class="literal">pmproxy.redis.requests.inflight.bytes</code> metric to view how many bytes are occupied by all current inflight Redis requests.
					</p><p class="simpara">
						In general, the redis request queue would be zero but can build up based on the usage of large pmlogger farms, which limits scalability and can cause high latency for <code class="literal">pmproxy</code> clients.
					</p></li><li class="listitem"><p class="simpara">
						Use the <code class="literal">pminfo</code> command to view information about performance metrics. For example, to view the <code class="literal">redis.*</code> metrics, use the following command:
					</p><pre class="screen">$ pminfo -ftd redis
redis.redis_build_id [Build ID]
    Data Type: string  InDom: 24.0 0x6000000
    Semantics: discrete  Units: count
    inst [0 or "localhost:6379"] value "87e335e57cffa755"
redis.total_commands_processed [Total number of commands processed by the server]
    Data Type: 64-bit unsigned int  InDom: 24.0 0x6000000
    Semantics: counter  Units: count
    inst [0 or "localhost:6379"] value 595627069
[...]

redis.used_memory_peak [Peak memory consumed by Redis (in bytes)]
    Data Type: 32-bit unsigned int  InDom: 24.0 0x6000000
    Semantics: instant  Units: count
    inst [0 or "localhost:6379"] value 572234920
[...]</pre><p class="simpara">
						To view the peak memory usage, see the <code class="literal">redis.used_memory_peak</code> metric.
					</p></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">pmdaredis(1)</code>, <code class="literal">pmproxy(1)</code>, and <code class="literal">pminfo(1)</code> man pages on your system
					</li><li class="listitem">
						<a class="link" href="#pcp-deployment-architectures_setting-up-pcp" title="5.5. PCP deployment architectures">PCP deployment architectures</a>
					</li></ul></div></section></section><section class="chapter" id="logging-performance-data-with-pmlogger_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 6. Logging performance data with pmlogger</h2></div></div></div><p class="_abstract _abstract">
			With the PCP tool you can log the performance metric values and replay them later. This allows you to perform a retrospective performance analysis.
		</p><p>
			Using the <code class="literal">pmlogger</code> tool, you can:
		</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
					Create the archived logs of selected metrics on the system
				</li><li class="listitem">
					Specify which metrics are recorded on the system and how often
				</li></ul></div><section class="section" id="modifying-the-pmlogger-configuration-file-with-pmlogconf_logging-performance-data-with-pmlogger"><div class="titlepage"><div><div><h3 class="title">6.1. Modifying the pmlogger configuration file with pmlogconf</h3></div></div></div><p class="_abstract _abstract">
				When the <code class="literal">pmlogger</code> service is running, PCP logs a default set of metrics on the host.
			</p><p>
				Use the <code class="literal">pmlogconf</code> utility to check the default configuration. If the <code class="literal">pmlogger</code> configuration file does not exist, <code class="literal">pmlogconf</code> creates it with a default metric values.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						PCP is installed. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#installing-and-enabling-pcp_setting-up-pcp">Installing and enabling PCP</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Create or modify the <code class="literal">pmlogger</code> configuration file:
					</p><pre class="screen"># pmlogconf -r /var/lib/pcp/config/pmlogger/config.default</pre></li><li class="listitem">
						Follow <code class="literal">pmlogconf</code> prompts to enable or disable groups of related performance metrics and to control the logging interval for each enabled group.
					</li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">pmlogconf(1)</code> and <code class="literal">pmlogger(1)</code> man pages on your system
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#system-services-distributed-with-pcp_setting-up-pcp">System services and tools distributed with PCP</a>
					</li></ul></div></section><section class="section" id="editing-the-pmlogger-configuration-file-manually_logging-performance-data-with-pmlogger"><div class="titlepage"><div><div><h3 class="title">6.2. Editing the pmlogger configuration file manually</h3></div></div></div><p class="_abstract _abstract">
				To create a tailored logging configuration with specific metrics and given intervals, edit the <code class="literal">pmlogger</code> configuration file manually. The default <code class="literal">pmlogger</code> configuration file is <code class="literal">/var/lib/pcp/config/pmlogger/config.default</code>. The configuration file specifies which metrics are logged by the primary logging instance.
			</p><p>
				In manual configuration, you can:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Record metrics which are not listed in the automatic configuration.
					</li><li class="listitem">
						Choose custom logging frequencies.
					</li><li class="listitem">
						Add <span class="strong strong"><strong>PMDA</strong></span> with the application metrics.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						PCP is installed. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#installing-and-enabling-pcp_setting-up-pcp">Installing and enabling PCP</a>.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Open and edit the <code class="literal">/var/lib/pcp/config/pmlogger/config.default</code> file to add specific metrics:
					</p><pre class="screen"># It is safe to make additions from here on ...
#

log mandatory on every 5 seconds {
    xfs.write
    xfs.write_bytes
    xfs.read
    xfs.read_bytes
}

log mandatory on every 10 seconds {
    xfs.allocs
    xfs.block_map
    xfs.transactions
    xfs.log

}

[access]
disallow * : all;
allow localhost : enquire;</pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">pmlogger(1)</code> man page on your system
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#system-services-distributed-with-pcp_setting-up-pcp">System services and tools distributed with PCP</a>
					</li></ul></div></section><section class="section" id="enabling-the-pmlogger-service_logging-performance-data-with-pmlogger"><div class="titlepage"><div><div><h3 class="title">6.3. Enabling the pmlogger service</h3></div></div></div><p class="_abstract _abstract">
				The <code class="literal">pmlogger</code> service must be started and enabled to log the metric values on the local machine.
			</p><p>
				This procedure describes how to enable the <code class="literal">pmlogger</code> service.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						PCP is installed. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#installing-and-enabling-pcp_setting-up-pcp">Installing and enabling PCP</a>.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Start and enable the <code class="literal">pmlogger</code> service:
					</p><pre class="screen"># systemctl start pmlogger

# systemctl enable pmlogger</pre></li></ul></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Verify if the <code class="literal">pmlogger</code> service is enabled:
					</p><pre class="screen"># pcp

Performance Co-Pilot configuration on workstation:

platform: Linux workstation 4.18.0-80.el8.x86_64 #1 SMP Wed Mar 13 12:02:46 UTC 2019 x86_64
hardware: 12 cpus, 2 disks, 1 node, 36023MB RAM
timezone: CEST-2
services: pmcd
pmcd: Version 4.3.0-1, 8 agents, 1 client
pmda: root pmcd proc xfs linux mmv kvm jbd2
pmlogger: primary logger: /var/log/pcp/pmlogger/workstation/20190827.15.54</pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">pmlogger(1)</code> man page on your system
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#system-services-distributed-with-pcp_setting-up-pcp">System services and tools distributed with PCP</a>
					</li><li class="listitem">
						<code class="literal">/var/lib/pcp/config/pmlogger/config.default</code> file
					</li></ul></div></section><section class="section" id="setting-up-a-client-system-for-metrics-collection_logging-performance-data-with-pmlogger"><div class="titlepage"><div><div><h3 class="title">6.4. Setting up a client system for metrics collection</h3></div></div></div><p class="_abstract _abstract">
				This procedure describes how to set up a client system so that a central server can collect metrics from clients running PCP.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						PCP is installed. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#installing-and-enabling-pcp_setting-up-pcp">Installing and enabling PCP</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Install the <code class="literal">pcp-system-tools</code> package:
					</p><pre class="screen"># dnf install pcp-system-tools</pre></li><li class="listitem"><p class="simpara">
						Configure an IP address for <code class="literal">pmcd</code>:
					</p><pre class="screen"># echo "-i <span class="emphasis"><em>192.168.4.62</em></span>" &gt;&gt;/etc/pcp/pmcd/pmcd.options</pre><p class="simpara">
						Replace <span class="emphasis"><em>192.168.4.62</em></span> with the IP address, the client should listen on.
					</p><p class="simpara">
						By default, <code class="literal">pmcd</code> is listening on the localhost.
					</p></li><li class="listitem"><p class="simpara">
						Configure the firewall to add the public <code class="literal">zone</code> permanently:
					</p><pre class="screen"># firewall-cmd --permanent --zone=public --add-port=44321/tcp
success

# firewall-cmd --reload
success</pre></li><li class="listitem"><p class="simpara">
						Set an SELinux boolean:
					</p><pre class="screen"># setsebool -P pcp_bind_all_unreserved_ports on</pre></li><li class="listitem"><p class="simpara">
						Enable the <code class="literal">pmcd</code> and <code class="literal">pmlogger</code> services:
					</p><pre class="screen"># systemctl enable pmcd pmlogger
# systemctl restart pmcd pmlogger</pre></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Verify if the <code class="literal">pmcd</code> is correctly listening on the configured IP address:
					</p><pre class="literallayout white-space-pre"># ss -tlp | grep 44321
LISTEN   0   5     127.0.0.1:44321   0.0.0.0:*   users:(("pmcd",pid=151595,fd=6))
LISTEN   0   5  <span class="emphasis"><em>192.168.4.62:44321</em></span>   0.0.0.0:*   users:(("pmcd",pid=151595,fd=0))
LISTEN   0   5         [::1]:44321      [::]:*   users:(("pmcd",pid=151595,fd=7))</pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">pmlogger(1)</code>, <code class="literal">firewall-cmd(1)</code>, <code class="literal">ss(8)</code>, and <code class="literal">setsebool(8)</code> man pages on your system
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#system-services-distributed-with-pcp_setting-up-pcp">System services and tools distributed with PCP</a>
					</li><li class="listitem">
						<code class="literal">/var/lib/pcp/config/pmlogger/config.default</code> file
					</li></ul></div></section><section class="section" id="setting-up-the-central-server-to-collect-data_logging-performance-data-with-pmlogger"><div class="titlepage"><div><div><h3 class="title">6.5. Setting up a central server to collect data</h3></div></div></div><p class="_abstract _abstract">
				This procedure describes how to create a central server to collect metrics from clients running PCP.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						PCP is installed. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#installing-and-enabling-pcp_setting-up-pcp">Installing and enabling PCP</a>.
					</li><li class="listitem">
						Client is configured for metrics collection. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/logging-performance-data-with-pmlogger_monitoring-and-managing-system-status-and-performance#setting-up-a-client-system-for-metrics-collection_logging-performance-data-with-pmlogger">Setting up a client system for metrics collection</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Install the <code class="literal">pcp-system-tools</code> package:
					</p><pre class="screen"># dnf install pcp-system-tools</pre></li><li class="listitem"><p class="simpara">
						Create the <code class="literal">/etc/pcp/pmlogger/control.d/remote</code> file with the following content:
					</p><pre class="literallayout white-space-pre"># DO NOT REMOVE OR EDIT THE FOLLOWING LINE
$version=1.1

<span class="emphasis"><em>192.168.4.13</em></span> n n PCP_ARCHIVE_DIR/rhel7u4a -r -T24h10m -c config.rhel7u4a
<span class="emphasis"><em>192.168.4.14</em></span> n n PCP_ARCHIVE_DIR/rhel6u10a -r -T24h10m -c config.rhel6u10a
<span class="emphasis"><em>192.168.4.62</em></span> n n PCP_ARCHIVE_DIR/rhel8u1a -r -T24h10m -c config.rhel8u1a
<span class="emphasis"><em>192.168.4.69</em></span> n n PCP_ARCHIVE_DIR/rhel9u3a -r -T24h10m -c config.rhel9u3a</pre><p class="simpara">
						Replace <span class="emphasis"><em>192.168.4.13</em></span>, <span class="emphasis"><em>192.168.4.14</em></span>, <span class="emphasis"><em>192.168.4.62</em></span> and <span class="emphasis"><em>192.168.4.69</em></span> with the client IP addresses.
					</p></li><li class="listitem"><p class="simpara">
						Enable the <code class="literal">pmcd</code> and <code class="literal">pmlogger</code> services:
					</p><pre class="screen"># systemctl enable pmcd pmlogger
# systemctl restart pmcd pmlogger</pre></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Ensure that you can access the latest archive file from each directory:
					</p><pre class="screen"># for i in /var/log/pcp/pmlogger/rhel*/*.0; do pmdumplog -L $i; done
Log Label (Log Format Version 2)
Performance metrics from host rhel6u10a.local
  commencing Mon Nov 25 21:55:04.851 2019
  ending     Mon Nov 25 22:06:04.874 2019
Archive timezone: JST-9
PID for pmlogger: 24002
Log Label (Log Format Version 2)
Performance metrics from host rhel7u4a
  commencing Tue Nov 26 06:49:24.954 2019
  ending     Tue Nov 26 07:06:24.979 2019
Archive timezone: CET-1
PID for pmlogger: 10941
[..]</pre><p class="simpara">
						The archive files from the <code class="literal">/var/log/pcp/pmlogger/</code> directory can be used for further analysis and graphing.
					</p></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">pmlogger(1)</code> man page on your system
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#system-services-distributed-with-pcp_setting-up-pcp">System services and tools distributed with PCP</a>
					</li><li class="listitem">
						<code class="literal">/var/lib/pcp/config/pmlogger/config.default</code> file
					</li></ul></div></section><section class="section" id="systemd-units-and-pmlogger_logging-performance-data-with-pmlogger"><div class="titlepage"><div><div><h3 class="title">6.6. <code class="literal">Systemd</code> units and <code class="literal">pmlogger</code></h3></div></div></div><p>
				When you deploy the <code class="literal">pmlogger</code> service, either as a single host monitoring itself or a <code class="literal">pmlogger</code> farm with a single host collecting metrics from several remote hosts, there are several associated <code class="literal">systemd</code> service and timer units that are automatically deployed. These services and timers provide routine checks to ensure that your <code class="literal">pmlogger</code> instances are running, restart any missing instances, and perform archive management such as file compression.
			</p><p>
				The checking and housekeeping services typically deployed by <code class="literal">pmlogger</code> are:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">pmlogger_daily.service</code></span></dt><dd>
							Runs daily, soon after midnight by default, to aggregate, compress, and rotate one or more sets of PCP archives. Also culls archives older than the limit, 2 weeks by default. Triggered by the <code class="literal">pmlogger_daily.timer</code> unit, which is required by the <code class="literal">pmlogger.service</code> unit.
						</dd><dt><span class="term"><code class="literal">pmlogger_check</code></span></dt><dd>
							Performs half-hourly checks that <code class="literal">pmlogger</code> instances are running. Restarts any missing instances and performs any required compression tasks. Triggered by the <code class="literal">pmlogger_check.timer</code> unit, which is required by the <code class="literal">pmlogger.service</code> unit.
						</dd><dt><span class="term"><code class="literal">pmlogger_farm_check</code></span></dt><dd>
							Checks the status of all configured <code class="literal">pmlogger</code> instances. Restarts any missing instances. Migrates all non–primary instances to the <code class="literal">pmlogger_farm</code> service. Triggered by the <code class="literal">pmlogger_farm_check.timer</code>, which is required by the <code class="literal">pmlogger_farm.service</code> unit that is itself required by the <code class="literal">pmlogger.service</code> unit.
						</dd></dl></div><p>
				These services are managed through a series of positive dependencies, meaning that they are all enabled upon activating the primary <code class="literal">pmlogger</code> instance. Note that while <code class="literal">pmlogger_daily.service</code> is disabled by default, <code class="literal">pmlogger_daily.timer</code> being active via the dependency with <code class="literal">pmlogger.service</code> will trigger <code class="literal">pmlogger_daily.service</code> to run.
			</p><p>
				<code class="literal">pmlogger_daily</code> is also integrated with <code class="literal">pmlogrewrite</code> for automatically rewriting archives before merging. This helps to ensure metadata consistency amid changing production environments and PMDAs. For example, if <code class="literal">pmcd</code> on one monitored host is updated during the logging interval, the semantics for some metrics on the host might be updated, thus making the new archives incompatible with the previously recorded archives from that host. For more information see the <a class="link" href="https://man7.org/linux/man-pages/man1/pmlogrewrite.1.html"><code class="literal">pmlogrewrite(1)</code></a> man page.
			</p><div class="formalpara"><p class="title"><strong>Managing <code class="literal">systemd</code> services triggered by <code class="literal">pmlogger</code></strong></p><p>
					You can create an automated custom archive management system for data collected by your <code class="literal">pmlogger</code> instances. This is done using control files. These control files are:
				</p></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						For the primary <code class="literal">pmlogger</code> instance:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
								<code class="literal">etc/pcp/pmlogger/control</code>
							</li><li class="listitem">
								<code class="literal">/etc/pcp/pmlogger/control.d/local</code>
							</li></ul></div></li><li class="listitem"><p class="simpara">
						For the remote hosts:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem"><p class="simpara">
								<code class="literal">/etc/pcp/pmlogger/control.d/remote</code>
							</p><p class="simpara">
								Replace <span class="emphasis"><em>remote</em></span> with your desired file name.
							</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">NOTE</span></dt><dd>
											The primary <code class="literal">pmlogger</code> instance must be running on the same host as the <code class="literal">pmcd</code> it connects to. You do not need to have a primary instance and you might not need it in your configuration if one central host is collecting data on several <code class="literal">pmlogger</code> instances connected to <code class="literal">pmcd</code> instances running on remote host
										</dd></dl></div></li></ul></div></li></ul></div><p>
				The file should contain one line for each host to be logged. The default format of the primary logger instance that is automatically created looks similar to:
			</p><pre class="screen"># === LOGGER CONTROL SPECIFICATIONS ===
#
#Host   	 P?  S?    directory   		 args

# local primary logger
LOCALHOSTNAME    y   n    PCP_ARCHIVE_DIR/LOCALHOSTNAME    -r -T24h10m -c config.default -v 100Mb</pre><p>
				The fields are:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">Host</code></span></dt><dd>
							The name of the host to be logged
						</dd><dt><span class="term"><code class="literal">P?</code></span></dt><dd>
							Stands for “Primary?” This field indicates if the host is the primary logger instance, <code class="literal">y</code>, or not, <code class="literal">n</code>. There can only be one primary logger across all the files in your configuration and it must be running on the same host as the <code class="literal">pmcd</code> it connects to.
						</dd><dt><span class="term"><code class="literal">S?</code></span></dt><dd>
							Stands for “Socks?” This field indicates if this logger instance needs to use the <code class="literal">SOCKS</code> protocol to connect to <code class="literal">pmcd</code> through a firewall, <code class="literal">y</code>, or not, <code class="literal">n</code>.
						</dd><dt><span class="term"><code class="literal">directory</code></span></dt><dd>
							All archives associated with this line are created in this directory.
						</dd><dt><span class="term"><code class="literal">args</code></span></dt><dd><p class="simpara">
							Arguments passed to <code class="literal">pmlogger</code>.
						</p><p class="simpara">
							The default values for the <code class="literal">args</code> field are:
						</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">-r</code></span></dt><dd>
										Report the archive sizes and growth rate.
									</dd><dt><span class="term"><code class="literal">T24h10m</code></span></dt><dd>
										Specifies when to end logging for each day. This is typically the time when <code class="literal">pmlogger_daily.service</code> runs. The default value of <code class="literal">24h10m</code> indicates that logging should end 24 hours and 10 minutes after it begins, at the latest.
									</dd><dt><span class="term"><code class="literal">-c config.default</code></span></dt><dd>
										Specifies which configuration file to use. This essentially defines what metrics to record.
									</dd><dt><span class="term"><code class="literal">-v 100Mb</code></span></dt><dd>
										Specifies the size at which point one data volume is filled and another is created. After it switches to the new archive, the previously recorded one will be compressed by either <code class="literal">pmlogger_daily</code> or <code class="literal">pmlogger_check</code>.
									</dd></dl></div></dd></dl></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">pmlogger(1)</code> and <code class="literal">pmlogrewrite(1)</code> man pages on your system
					</li><li class="listitem">
						<code class="literal">pmlogger_daily(1)</code>, <code class="literal">pmlogger_check(1)</code>, and <code class="literal">pmlogger.control(5)</code> man pages on your system
					</li></ul></div></section><section class="section" id="replaying-the-pcp-log-archives_logging-performance-data-with-pmlogger"><div class="titlepage"><div><div><h3 class="title">6.7. Replaying the PCP log archives with pmrep</h3></div></div></div><p class="_abstract _abstract">
				After recording the metric data, you can replay the PCP log archives. To export the logs to text files and import them into spreadsheets, use PCP utilities such as <code class="literal">pcp2csv</code>, <code class="literal">pcp2xml</code>, <code class="literal">pmrep</code> or <code class="literal">pmlogsummary</code>.
			</p><p>
				Using the <code class="literal">pmrep</code> tool, you can:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						View the log files
					</li><li class="listitem">
						Parse the selected PCP log archive and export the values into an ASCII table
					</li><li class="listitem">
						Extract the entire archive log or only select metric values from the log by specifying individual metrics on the command line
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						PCP is installed. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#installing-and-enabling-pcp_setting-up-pcp">Installing and enabling PCP</a>.
					</li><li class="listitem">
						The <code class="literal">pmlogger</code> service is enabled. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/logging-performance-data-with-pmlogger_monitoring-and-managing-system-status-and-performance#enabling-the-pmlogger-service_logging-performance-data-with-pmlogger">Enabling the pmlogger service</a>.
					</li><li class="listitem"><p class="simpara">
						Install the <code class="literal">pcp-gui</code> package:
					</p><pre class="screen"># dnf install pcp-gui</pre></li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Display the data on the metric:
					</p><pre class="screen">$ pmrep --start @3:00am --archive 20211128 --interval 5seconds --samples 10 --output csv disk.dev.write
Time,"disk.dev.write-sda","disk.dev.write-sdb"
2021-11-28 03:00:00,,
2021-11-28 03:00:05,4.000,5.200
2021-11-28 03:00:10,1.600,7.600
2021-11-28 03:00:15,0.800,7.100
2021-11-28 03:00:20,16.600,8.400
2021-11-28 03:00:25,21.400,7.200
2021-11-28 03:00:30,21.200,6.800
2021-11-28 03:00:35,21.000,27.600
2021-11-28 03:00:40,12.400,33.800
2021-11-28 03:00:45,9.800,20.600</pre><p class="simpara">
						The mentioned example displays the data on the <code class="literal">disk.dev.write</code> metric collected in an archive at a <span class="emphasis"><em>5 second</em></span> interval in comma-separated-value format.
					</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
							Replace <code class="literal">20211128</code> in this example with a filename containing the <code class="literal">pmlogger</code> archive you want to display data for.
						</p></div></rh-alert></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">pmlogger(1)</code>, <code class="literal">pmrep(1)</code>, and <code class="literal">pmlogsummary(1)</code> man pages on your system
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#system-services-distributed-with-pcp_setting-up-pcp">System services and tools distributed with PCP</a>
					</li></ul></div></section><section class="section" id="enabling-pcp-version-3-archives_logging-performance-data-with-pmlogger"><div class="titlepage"><div><div><h3 class="title">6.8. Enabling PCP version 3 archives</h3></div></div></div><p>
				Performance Co-Pilot (PCP) archives store historical values of PCP metrics recorded from a single host and support retrospective performance analysis. PCP archives contain all the important metric data and metadata needed for offline or offsite analysis. These archives can be read by most PCP client tools or dumped raw by the <code class="literal">pmdumplog</code> tool.
			</p><p>
				From PCP 6.0, version 3 archives are supported in addition to version 2 archives. Version 2 archives remain the default and will continue to receive long-term support for backwards compatibility purposes in addition to version 3 archives receiving long-term support from RHEL 9.2 and on.
			</p><p>
				Using PCP version 3 archives offers the following benefits over version 2:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Support for instance domain change-deltas
					</li><li class="listitem">
						Y2038-safe timestamps
					</li><li class="listitem">
						Nanosecond-precision timestamps
					</li><li class="listitem">
						Arbitrary timezones support
					</li><li class="listitem">
						64-bit file offsets used for individual volumes larger than 2GB
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						PCP is installed. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#installing-and-enabling-pcp_setting-up-pcp">Installing and enabling PCP</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Open the <code class="literal">/etc/pcp.conf</code> file in a text editor of your choice and set the PCP archive version:
					</p><pre class="screen">PCP_ARCHIVE_VERSION=3</pre></li><li class="listitem"><p class="simpara">
						Restart the <code class="literal">pmlogger</code> service to apply your configuration changes:
					</p><pre class="screen"># systemctl restart pmlogger.service</pre></li><li class="listitem">
						Create a new PCP archive log using your new configuration. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/logging-performance-data-with-pmlogger_monitoring-and-managing-system-status-and-performance">Logging performance data with pmlogger</a>.
					</li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Verify the version of the archive created with your new configuration:
					</p><pre class="screen"># pmloglabel -l /var/log/pcp/pmlogger/<span class="emphasis"><em>20230208</em></span>
Log Label (Log Format Version 3)
Performance metrics from host <span class="emphasis"><em>host1</em></span>
        commencing Wed Feb   08 00:11:09.396 2023
        ending           Thu  Feb   07 00:13:54.347 2023</pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">logarchive(5)</code> and <code class="literal">pmlogger(1)</code> man pages on your system
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/logging-performance-data-with-pmlogger_monitoring-and-managing-system-status-and-performance">Logging performance data with pmlogger</a>
					</li></ul></div></section></section><section class="chapter" id="monitoring-performance-with-performance-co-pilot_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 7. Monitoring performance with Performance Co-Pilot</h2></div></div></div><p class="_abstract _abstract">
			Performance Co-Pilot (PCP) is a suite of tools, services, and libraries for monitoring, visualizing, storing, and analyzing system-level performance measurements.
		</p><p>
			As a system administrator, you can monitor the system’s performance using the PCP application in Red Hat Enterprise Linux 9.
		</p><section class="section" id="monitoring-postfix-with-pmda-postfix_monitoring-performance-with-performance-co-pilot"><div class="titlepage"><div><div><h3 class="title">7.1. Monitoring postfix with pmda-postfix</h3></div></div></div><p class="_abstract _abstract">
				This procedure describes how to monitor performance metrics of the <code class="literal">postfix</code> mail server with <code class="literal">pmda-postfix</code>. It helps to check how many emails are received per second.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						PCP is installed. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#installing-and-enabling-pcp_setting-up-pcp">Installing and enabling PCP</a>.
					</li><li class="listitem">
						The <code class="literal">pmlogger</code> service is enabled. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/logging-performance-data-with-pmlogger_monitoring-and-managing-system-status-and-performance#enabling-the-pmlogger-service_logging-performance-data-with-pmlogger">Enabling the pmlogger service</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Install the following packages:
					</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
								Install the <code class="literal">pcp-system-tools</code>:
							</p><pre class="screen"># dnf install pcp-system-tools</pre></li><li class="listitem"><p class="simpara">
								Install the <code class="literal">pmda-postfix</code> package to monitor <code class="literal">postfix</code>:
							</p><pre class="screen"># dnf install pcp-pmda-postfix postfix</pre></li><li class="listitem"><p class="simpara">
								Install the logging daemon:
							</p><pre class="screen"># dnf install rsyslog</pre></li><li class="listitem"><p class="simpara">
								Install the mail client for testing:
							</p><pre class="screen"># dnf install mutt</pre></li></ol></div></li><li class="listitem"><p class="simpara">
						Enable the <code class="literal">postfix</code> and <code class="literal">rsyslog</code> services:
					</p><pre class="screen"># systemctl enable postfix rsyslog
# systemctl restart postfix rsyslog</pre></li><li class="listitem"><p class="simpara">
						Enable the SELinux boolean, so that <code class="literal">pmda-postfix</code> can access the required log files:
					</p><pre class="screen"># setsebool -P pcp_read_generic_logs=on</pre></li><li class="listitem"><p class="simpara">
						Install the <code class="literal">PMDA</code>:
					</p><pre class="screen"># cd /var/lib/pcp/pmdas/postfix/

# ./Install

Updating the Performance Metrics Name Space (PMNS) ...
Terminate PMDA if already installed ...
Updating the PMCD control file, and notifying PMCD ...
Waiting for pmcd to terminate ...
Starting pmcd ...
Check postfix metrics have appeared ... 7 metrics and 58 values</pre></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Verify the <code class="literal">pmda-postfix</code> operation:
					</p><pre class="screen">echo testmail | mutt root</pre></li><li class="listitem"><p class="simpara">
						Verify the available metrics:
					</p><pre class="screen"># pminfo postfix

postfix.received
postfix.sent
postfix.queues.incoming
postfix.queues.maildrop
postfix.queues.hold
postfix.queues.deferred
postfix.queues.active</pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">rsyslogd(8)</code>, <code class="literal">postfix(1)</code>, and <code class="literal">setsebool(8)</code> man pages on your system
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#system-services-distributed-with-pcp_setting-up-pcp">System services and tools distributed with PCP</a>
					</li></ul></div></section><section class="section" id="visually-tracing-pcp-log-archives-with-pcp-charts_monitoring-performance-with-performance-co-pilot"><div class="titlepage"><div><div><h3 class="title">7.2. Visually tracing PCP log archives with the PCP Charts application</h3></div></div></div><p class="_abstract _abstract">
				After recording metric data, you can replay the PCP log archives as graphs. The metrics are sourced from one or more live hosts with alternative options to use metric data from PCP log archives as a source of historical data. To customize the <span class="strong strong"><strong>PCP Charts</strong></span> application interface to display the data from the performance metrics, you can use line plot, bar graphs, or utilization graphs.
			</p><p>
				Using the <span class="strong strong"><strong>PCP Charts</strong></span> application, you can:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Replay the data in the <span class="strong strong"><strong>PCP Charts</strong></span> application application and use graphs to visualize the retrospective data alongside live data of the system.
					</li><li class="listitem">
						Plot performance metric values into graphs.
					</li><li class="listitem">
						Display multiple charts simultaneously.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						PCP is installed. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#installing-and-enabling-pcp_setting-up-pcp">Installing and enabling PCP</a>.
					</li><li class="listitem">
						Logged performance data with the <code class="literal">pmlogger</code>. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/logging-performance-data-with-pmlogger_monitoring-and-managing-system-status-and-performance">Logging performance data with pmlogger</a>.
					</li><li class="listitem"><p class="simpara">
						Install the <code class="literal">pcp-gui</code> package:
					</p><pre class="screen"># dnf install pcp-gui</pre></li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Launch the <span class="strong strong"><strong>PCP Charts</strong></span> application from the command line:
					</p><pre class="screen"># pmchart</pre><div class="figure" id="idm140280153202064"><p class="title"><strong>Figure 7.1. PCP Charts application</strong></p><div class="figure-contents"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/804544b6996d4a37ca90b153dab642ea/pmchart_started.png" alt="pmchart started"></div></div></div><p class="simpara">
						The <code class="literal">pmtime</code> server settings are located at the bottom. The <span class="strong strong"><strong>start</strong></span> and <span class="strong strong"><strong>pause</strong></span> button allows you to control:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								The interval in which PCP polls the metric data
							</li><li class="listitem">
								The date and time for the metrics of historical data
							</li></ul></div></li><li class="listitem">
						Click <span class="strong strong"><strong>File</strong></span> and then <span class="strong strong"><strong>New Chart</strong></span> to select metric from both the local machine and remote machines by specifying their host name or address. Advanced configuration options include the ability to manually set the axis values for the chart, and to manually choose the color of the plots.
					</li><li class="listitem"><p class="simpara">
						Record the views created in the <span class="strong strong"><strong>PCP Charts</strong></span> application:
					</p><p class="simpara">
						Following are the options to take images or record the views created in the <span class="strong strong"><strong>PCP Charts</strong></span> application:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								Click <span class="strong strong"><strong>File</strong></span> and then <span class="strong strong"><strong>Export</strong></span> to save an image of the current view.
							</li><li class="listitem">
								Click <span class="strong strong"><strong>Record</strong></span> and then <span class="strong strong"><strong>Start</strong></span> to start a recording. Click <span class="strong strong"><strong>Record</strong></span> and then <span class="strong strong"><strong>Stop</strong></span> to stop the recording. After stopping the recording, the recorded metrics are archived to be viewed later.
							</li></ul></div></li><li class="listitem"><p class="simpara">
						Optional: In the <span class="strong strong"><strong>PCP Charts</strong></span> application, the main configuration file, known as the <span class="strong strong"><strong>view</strong></span>, allows the metadata associated with one or more charts to be saved. This metadata describes all chart aspects, including the metrics used and the chart columns. Save the custom <span class="strong strong"><strong>view</strong></span> configuration by clicking <span class="strong strong"><strong>File</strong></span> and then <span class="strong strong"><strong>Save View</strong></span>, and load the <span class="strong strong"><strong>view</strong></span> configuration later.
					</p><p class="simpara">
						The following example of the <span class="strong strong"><strong>PCP Charts</strong></span> application view configuration file describes a stacking chart graph showing the total number of bytes read and written to the given XFS file system <code class="literal">loop1</code>:
					</p><pre class="screen">#kmchart
version 1

chart title "Filesystem Throughput /loop1" style stacking antialiasing off
    plot legend "Read rate"   metric xfs.read_bytes   instance  "loop1"
    plot legend "Write rate"  metric xfs.write_bytes  instance  "loop1"</pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">pmchart(1)</code> and <code class="literal">pmtime(1)</code> man pages on your system
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#system-services-distributed-with-pcp_setting-up-pcp">System services and tools distributed with PCP</a>
					</li></ul></div></section><section class="section" id="collecting-data-from-sql-server-using-pcp_monitoring-performance-with-performance-co-pilot"><div class="titlepage"><div><div><h3 class="title">7.3. Collecting data from SQL server using PCP</h3></div></div></div><p class="_abstract _abstract">
				The SQL Server agent is available in Performance Co-Pilot (PCP), which helps you to monitor and analyze database performance issues.
			</p><p>
				This procedure describes how to collect data for Microsoft SQL Server via <code class="literal">pcp</code> on your system.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have installed Microsoft SQL Server for Red Hat Enterprise Linux and established a 'trusted' connection to an SQL server.
					</li><li class="listitem">
						You have installed the Microsoft ODBC driver for SQL Server for Red Hat Enterprise Linux.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Install PCP:
					</p><pre class="screen"># dnf install pcp-zeroconf</pre></li><li class="listitem"><p class="simpara">
						Install packages required for the <code class="literal">pyodbc</code> driver:
					</p><pre class="screen"># dnf install python3-pyodbc</pre></li><li class="listitem"><p class="simpara">
						Install the <code class="literal">mssql</code> agent:
					</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
								Install the Microsoft SQL Server domain agent for PCP:
							</p><pre class="screen"># dnf install pcp-pmda-mssql</pre></li><li class="listitem"><p class="simpara">
								Edit the <code class="literal">/etc/pcp/mssql/mssql.conf</code> file to configure the SQL server account’s username and password for the <code class="literal">mssql</code> agent. Ensure that the account you configure has access rights to performance data.
							</p><pre class="screen">username: <span class="emphasis"><em>user_name</em></span>
password: <span class="emphasis"><em>user_password</em></span></pre><p class="simpara">
								Replace <span class="emphasis"><em>user_name</em></span> with the SQL Server account and <span class="emphasis"><em>user_password</em></span> with the SQL Server user password for this account.
							</p></li></ol></div></li><li class="listitem"><p class="simpara">
						Install the agent:
					</p><pre class="screen"># cd /var/lib/pcp/pmdas/mssql
# ./Install
Updating the Performance Metrics Name Space (PMNS) ...
Terminate PMDA if already installed ...
Updating the PMCD control file, and notifying PMCD ...
Check mssql metrics have appeared ... 168 metrics and 598 values
[...]</pre></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Using the <code class="literal">pcp</code> command, verify if the SQL Server PMDA (<code class="literal">mssql</code>) is loaded and running:
					</p><pre class="screen">$ pcp
Performance Co-Pilot configuration on rhel.local:

platform: Linux rhel.local 4.18.0-167.el8.x86_64 #1 SMP Sun Dec 15 01:24:23 UTC 2019 x86_64
 hardware: 2 cpus, 1 disk, 1 node, 2770MB RAM
 timezone: PDT+7
 services: pmcd pmproxy
     pmcd: Version 5.0.2-1, 12 agents, 4 clients
     pmda: root pmcd proc pmproxy xfs linux nfsclient mmv kvm mssql
           jbd2 dm
 pmlogger: primary logger: /var/log/pcp/pmlogger/rhel.local/20200326.16.31
     pmie: primary engine: /var/log/pcp/pmie/rhel.local/pmie.log</pre></li><li class="listitem"><p class="simpara">
						View the complete list of metrics that PCP can collect from the SQL Server:
					</p><pre class="screen"># pminfo mssql</pre></li><li class="listitem"><p class="simpara">
						After viewing the list of metrics, you can report the rate of transactions. For example, to report on the overall transaction count per second, over a five second time window:
					</p><pre class="screen"># pmval -t 1 -T 5 mssql.databases.transactions</pre></li><li class="listitem">
						View the graphical chart of these metrics on your system by using the <code class="literal">pmchart</code> command. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/monitoring-performance-with-performance-co-pilot_monitoring-and-managing-system-status-and-performance#visually-tracing-pcp-log-archives-with-pcp-charts_monitoring-performance-with-performance-co-pilot">Visually tracing PCP log archives with the PCP Charts application</a>.
					</li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">pcp(1)</code>, <code class="literal">pminfo(1)</code>, <code class="literal">pmval(1)</code>, <code class="literal">pmchart(1)</code>, and <code class="literal">pmdamssql(1)</code> man pages on your system
					</li><li class="listitem">
						<a class="link" href="https://www.redhat.com/en/blog/performance-co-pilot-microsoft-sql-server-rhel-82">Performance Co-Pilot for Microsoft SQL Server with RHEL 8.2 Red Hat Developers Blog post</a>
					</li></ul></div></section><section class="section" id="proc_generating-pcp-archives-from-sadc-archives_monitoring-performance-with-performance-co-pilot"><div class="titlepage"><div><div><h3 class="title">7.4. Generating PCP archives from sadc archives</h3></div></div></div><p class="_abstract _abstract">
				You can use the <code class="literal">sadf</code> tool provided by the <code class="literal">sysstat</code> package to generate PCP archives from native <code class="literal">sadc</code> archives.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						A <code class="literal">sadc</code> archive has been created:
					</p><pre class="screen"># /usr/lib64/sa/sadc 1 5 -</pre><p class="simpara">
						In this example, <code class="literal">sadc</code> is sampling system data 1 time in a 5 second interval. The outfile is specified as <code class="literal">-</code> which results in <code class="literal">sadc</code> writing the data to the standard system activity daily data file. This file is named saDD and is located in the /var/log/sa directory by default.
					</p></li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Generate a PCP archive from a <code class="literal">sadc</code> archive:
					</p><pre class="screen"># sadf -l -O pcparchive=/tmp/recording -2</pre><p class="simpara">
						In this example, using the <code class="literal">-2</code> option results in <code class="literal">sadf</code> generating a PCP archive from a <code class="literal">sadc</code> archive recorded 2 days ago.
					</p></li></ul></div><div class="formalpara"><p class="title"><strong>Verification</strong></p><p>
					You can use PCP commands to inspect and analyze the PCP archive generated from a <code class="literal">sadc</code> archive as you would a native PCP archive. For example:
				</p></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						To show a list of metrics in the PCP archive generated from an <code class="literal">sadc</code> archive archive, run:
					</p><pre class="screen">$ pminfo --archive /tmp/recording
Disk.dev.avactive
Disk.dev.read
Disk.dev.write
Disk.dev.blkread
[...]</pre></li><li class="listitem"><p class="simpara">
						To show the timespace of the archive and hostname of the PCP archive, run:
					</p><pre class="screen">$ pmdumplog --label /tmp/recording
Log Label (Log Format Version 2)
Performance metrics from host shard
        commencing Tue Jul 20 00:10:30.642477 2021
        ending     Wed Jul 21 00:10:30.222176 2021</pre></li><li class="listitem"><p class="simpara">
						To plot performance metrics values into graphs, run:
					</p><pre class="screen">$ pmchart --archive /tmp/recording</pre></li></ul></div></section></section><section class="chapter" id="performance-analysis-of-xfs-with-pcp_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 8. Performance analysis of XFS with PCP</h2></div></div></div><p class="_abstract _abstract">
			The XFS PMDA ships as part of the <code class="literal">pcp</code> package and is enabled by default during the installation. It is used to gather performance metric data of XFS file systems in Performance Co-Pilot (PCP).
		</p><p>
			You can use PCP to analyze XFS file system’s performance.
		</p><section class="section" id="installing-xfs-pmda-manually_performance-analysis-of-xfs-with-pcp"><div class="titlepage"><div><div><h3 class="title">8.1. Installing XFS PMDA manually</h3></div></div></div><p class="_abstract _abstract">
				If the XFS PMDA is not listed in the <code class="literal">pcp</code> configuration output, install the PMDA agent manually.
			</p><p>
				This procedure describes how to manually install the PMDA agent.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						PCP is installed. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#installing-and-enabling-pcp_setting-up-pcp">Installing and enabling PCP</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Navigate to the xfs directory:
					</p><pre class="screen"># cd /var/lib/pcp/pmdas/xfs/</pre></li><li class="listitem"><p class="simpara">
						Install the XFS PMDA manually:
					</p><pre class="screen">xfs]# ./Install
Updating the Performance Metrics Name Space (PMNS) ...
Terminate PMDA if already installed ...
Updating the PMCD control file, and notifying PMCD ...
Check xfs metrics have appeared ... 387 metrics and 387 values</pre></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Verify that the <code class="literal">pmcd</code> process is running on the host and the XFS PMDA is listed as enabled in the configuration:
					</p><pre class="screen"># pcp

Performance Co-Pilot configuration on workstation:

platform: Linux workstation 4.18.0-80.el8.x86_64 #1 SMP Wed Mar 13 12:02:46 UTC 2019 x86_64
hardware: 12 cpus, 2 disks, 1 node, 36023MB RAM
timezone: CEST-2
services: pmcd
pmcd: Version 4.3.0-1, 8 agents
pmda: root pmcd proc xfs linux mmv kvm jbd2</pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">pmcd(1)</code> man page on your system
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#system-services-distributed-with-pcp_setting-up-pcp">System services and tools distributed with PCP</a>
					</li></ul></div></section><section class="section" id="examining-xfs-performance-metrics-with-pminfo_performance-analysis-of-xfs-with-pcp"><div class="titlepage"><div><div><h3 class="title">8.2. Examining XFS performance metrics with pminfo</h3></div></div></div><p class="_abstract _abstract">
				PCP enables XFS PMDA to allow the reporting of certain XFS metrics per each of the mounted XFS file systems. This makes it easier to pinpoint specific mounted file system issues and evaluate performance.
			</p><p>
				The <code class="literal">pminfo</code> command provides per-device XFS metrics for each mounted XFS file system.
			</p><p>
				This procedure displays a list of all available metrics provided by the XFS PMDA.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						PCP is installed. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#installing-and-enabling-pcp_setting-up-pcp">Installing and enabling PCP</a>.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Display the list of all available metrics provided by the XFS PMDA:
					</p><pre class="screen"># pminfo xfs</pre></li><li class="listitem"><p class="simpara">
						Display information for the individual metrics. The following examples examine specific XFS <code class="literal">read</code> and <code class="literal">write</code> metrics using the <code class="literal">pminfo</code> tool:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem"><p class="simpara">
								Display a short description of the <code class="literal">xfs.write_bytes</code> metric:
							</p><pre class="screen"># pminfo --oneline xfs.write_bytes

xfs.write_bytes [number of bytes written in XFS file system write operations]</pre></li><li class="listitem"><p class="simpara">
								Display a long description of the <code class="literal">xfs.read_bytes</code> metric:
							</p><pre class="screen"># pminfo --helptext xfs.read_bytes

xfs.read_bytes
Help:
This is the number of bytes read via read(2) system calls to files in
XFS file systems. It can be used in conjunction with the read_calls
count to calculate the average size of the read operations to file in
XFS file systems.</pre></li><li class="listitem"><p class="simpara">
								Obtain the current performance value of the <code class="literal">xfs.read_bytes</code> metric:
							</p><pre class="screen"># pminfo --fetch xfs.read_bytes

xfs.read_bytes
    value 4891346238</pre></li><li class="listitem"><p class="simpara">
								Obtain per-device XFS metrics with <code class="literal">pminfo</code>:
							</p><pre class="screen"># pminfo --fetch --oneline xfs.perdev.read xfs.perdev.write

xfs.perdev.read [number of XFS file system read operations]
inst [0 or "loop1"] value 0
inst [0 or "loop2"] value 0

xfs.perdev.write [number of XFS file system write operations]
inst [0 or "loop1"] value 86
inst [0 or "loop2"] value 0</pre></li></ul></div></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">pminfo(1)</code> man page on your system
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/performance-analysis-of-xfs-with-pcp_monitoring-and-managing-system-status-and-performance#pcp-metric-groups-for-xfs_performance-analysis-of-xfs-with-pcp">PCP metric groups for XFS</a>
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/performance-analysis-of-xfs-with-pcp_monitoring-and-managing-system-status-and-performance#per-device-pcp-metric-groups-for-xfs_performance-analysis-of-xfs-with-pcp">Per-device PCP metric groups for XFS</a>
					</li></ul></div></section><section class="section" id="resetting-xfs-performance-metrics-with-pmstore_performance-analysis-of-xfs-with-pcp"><div class="titlepage"><div><div><h3 class="title">8.3. Resetting XFS performance metrics with pmstore</h3></div></div></div><p class="_abstract _abstract">
				With PCP, you can modify the values of certain metrics, especially if the metric acts as a control variable, such as the <code class="literal">xfs.control.reset</code> metric. To modify a metric value, use the <code class="literal">pmstore</code> tool.
			</p><p>
				This procedure describes how to reset XFS metrics using the <code class="literal">pmstore</code> tool.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						PCP is installed. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#installing-and-enabling-pcp_setting-up-pcp">Installing and enabling PCP</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Display the value of a metric:
					</p><pre class="screen">$ pminfo -f xfs.write

xfs.write
    value 325262</pre></li><li class="listitem"><p class="simpara">
						Reset all the XFS metrics:
					</p><pre class="screen"># pmstore xfs.control.reset 1

xfs.control.reset old value=0 new value=1</pre></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						View the information after resetting the metric:
					</p><pre class="screen">$ pminfo --fetch xfs.write

xfs.write
    value 0</pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">pmstore(1)</code> and <code class="literal">pminfo(1)</code> man pages on your system
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#system-services-distributed-with-pcp_setting-up-pcp">System services and tools distributed with PCP</a>
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/performance-analysis-of-xfs-with-pcp_monitoring-and-managing-system-status-and-performance#pcp-metric-groups-for-xfs_performance-analysis-of-xfs-with-pcp">PCP metric groups for XFS</a>
					</li></ul></div></section><section class="section" id="pcp-metric-groups-for-xfs_performance-analysis-of-xfs-with-pcp"><div class="titlepage"><div><div><h3 class="title">8.4. PCP metric groups for XFS</h3></div></div></div><p class="_abstract _abstract">
				The following table describes the available PCP metric groups for XFS.
			</p><rh-table id="idm140280144977840"><table class="lt-4-cols lt-7-rows"><caption>Table 8.1. Metric groups for XFS</caption><colgroup><col style="width: 50%; " class="col_1"><!--Empty--><col style="width: 50%; " class="col_2"><!--Empty--></colgroup><tbody><tr><td align="left" valign="top"> <p>
								Metric Group
							</p>
							 </td><td align="left" valign="top"> <p>
								Metrics provided
							</p>
							 </td></tr><tr><td align="left" valign="top"> <p>
								<code class="literal">xfs.*</code>
							</p>
							 </td><td align="left" valign="top"> <p>
								General XFS metrics including the read and write operation counts, read and write byte counts. Along with counters for the number of times inodes are flushed, clustered and number of failure to cluster.
							</p>
							 </td></tr><tr><td align="left" valign="top"> <p>
								<code class="literal">xfs.allocs.*</code>
							</p>
							 <p>
								<code class="literal">xfs.alloc_btree.*</code>
							</p>
							 </td><td align="left" valign="top"> <p>
								Range of metrics regarding the allocation of objects in the file system, these include number of extent and block creations/frees. Allocation tree lookup and compares along with extend record creation and deletion from the btree.
							</p>
							 </td></tr><tr><td align="left" valign="top"> <p>
								<code class="literal">xfs.block_map.*</code>
							</p>
							 <p>
								<code class="literal">xfs.bmap_btree.*</code>
							</p>
							 </td><td align="left" valign="top"> <p>
								Metrics include the number of block map read/write and block deletions, extent list operations for insertion, deletions and lookups. Also operations counters for compares, lookups, insertions and deletion operations from the blockmap.
							</p>
							 </td></tr><tr><td align="left" valign="top"> <p>
								<code class="literal">xfs.dir_ops.*</code>
							</p>
							 </td><td align="left" valign="top"> <p>
								Counters for directory operations on XFS file systems for creation, entry deletions, count of “getdent” operations.
							</p>
							 </td></tr><tr><td align="left" valign="top"> <p>
								<code class="literal">xfs.transactions.*</code>
							</p>
							 </td><td align="left" valign="top"> <p>
								Counters for the number of meta-data transactions, these include the count for the number of synchronous and asynchronous transactions along with the number of empty transactions.
							</p>
							 </td></tr><tr><td align="left" valign="top"> <p>
								<code class="literal">xfs.inode_ops.*</code>
							</p>
							 </td><td align="left" valign="top"> <p>
								Counters for the number of times that the operating system looked for an XFS inode in the inode cache with different outcomes. These count cache hits, cache misses, and so on.
							</p>
							 </td></tr><tr><td align="left" valign="top"> <p>
								<code class="literal">xfs.log.*</code>
							</p>
							 <p>
								<code class="literal">xfs.log_tail.*</code>
							</p>
							 </td><td align="left" valign="top"> <p>
								Counters for the number of log buffer writes over XFS file sytems includes the number of blocks written to disk. Metrics also for the number of log flushes and pinning.
							</p>
							 </td></tr><tr><td align="left" valign="top"> <p>
								<code class="literal">xfs.xstrat.*</code>
							</p>
							 </td><td align="left" valign="top"> <p>
								Counts for the number of bytes of file data flushed out by the XFS flush deamon along with counters for number of buffers flushed to contiguous and non-contiguous space on disk.
							</p>
							 </td></tr><tr><td align="left" valign="top"> <p>
								<code class="literal">xfs.attr.*</code>
							</p>
							 </td><td align="left" valign="top"> <p>
								Counts for the number of attribute get, set, remove and list operations over all XFS file systems.
							</p>
							 </td></tr><tr><td align="left" valign="top"> <p>
								<code class="literal">xfs.quota.*</code>
							</p>
							 </td><td align="left" valign="top"> <p>
								Metrics for quota operation over XFS file systems, these include counters for number of quota reclaims, quota cache misses, cache hits and quota data reclaims.
							</p>
							 </td></tr><tr><td align="left" valign="top"> <p>
								<code class="literal">xfs.buffer.*</code>
							</p>
							 </td><td align="left" valign="top"> <p>
								Range of metrics regarding XFS buffer objects. Counters include the number of requested buffer calls, successful buffer locks, waited buffer locks, miss_locks, miss_retries and buffer hits when looking up pages.
							</p>
							 </td></tr><tr><td align="left" valign="top"> <p>
								<code class="literal">xfs.btree.*</code>
							</p>
							 </td><td align="left" valign="top"> <p>
								Metrics regarding the operations of the XFS btree.
							</p>
							 </td></tr><tr><td align="left" valign="top"> <p>
								<code class="literal">xfs.control.reset</code>
							</p>
							 </td><td align="left" valign="top"> <p>
								Configuration metrics which are used to reset the metric counters for the XFS stats. Control metrics are toggled by means of the pmstore tool.
							</p>
							 </td></tr></tbody></table></rh-table></section><section class="section" id="per-device-pcp-metric-groups-for-xfs_performance-analysis-of-xfs-with-pcp"><div class="titlepage"><div><div><h3 class="title">8.5. Per-device PCP metric groups for XFS</h3></div></div></div><p class="_abstract _abstract">
				The following table describes the available per-device PCP metric group for XFS.
			</p><rh-table id="idm140280140070240"><table class="lt-4-cols lt-7-rows"><caption>Table 8.2. Per-device PCP metric groups for XFS</caption><colgroup><col style="width: 50%; " class="col_1"><!--Empty--><col style="width: 50%; " class="col_2"><!--Empty--></colgroup><tbody><tr><td align="left" valign="top"> <p>
								Metric Group
							</p>
							 </td><td align="left" valign="top"> <p>
								Metrics provided
							</p>
							 </td></tr><tr><td align="left" valign="top"> <p>
								<code class="literal">xfs.perdev.*</code>
							</p>
							 </td><td align="left" valign="top"> <p>
								General XFS metrics including the read and write operation counts, read and write byte counts. Along with counters for the number of times inodes are flushed, clustered and number of failure to cluster.
							</p>
							 </td></tr><tr><td align="left" valign="top"> <p>
								<code class="literal">xfs.perdev.allocs.*</code>
							</p>
							 <p>
								<code class="literal">xfs.perdev.alloc_btree.*</code>
							</p>
							 </td><td align="left" valign="top"> <p>
								Range of metrics regarding the allocation of objects in the file system, these include number of extent and block creations/frees. Allocation tree lookup and compares along with extend record creation and deletion from the btree.
							</p>
							 </td></tr><tr><td align="left" valign="top"> <p>
								<code class="literal">xfs.perdev.block_map.*</code>
							</p>
							 <p>
								<code class="literal">xfs.perdev.bmap_btree.*</code>
							</p>
							 </td><td align="left" valign="top"> <p>
								Metrics include the number of block map read/write and block deletions, extent list operations for insertion, deletions and lookups. Also operations counters for compares, lookups, insertions and deletion operations from the blockmap.
							</p>
							 </td></tr><tr><td align="left" valign="top"> <p>
								<code class="literal">xfs.perdev.dir_ops.*</code>
							</p>
							 </td><td align="left" valign="top"> <p>
								Counters for directory operations of XFS file systems for creation, entry deletions, count of “getdent” operations.
							</p>
							 </td></tr><tr><td align="left" valign="top"> <p>
								<code class="literal">xfs.perdev.transactions.*</code>
							</p>
							 </td><td align="left" valign="top"> <p>
								Counters for the number of meta-data transactions, these include the count for the number of synchronous and asynchronous transactions along with the number of empty transactions.
							</p>
							 </td></tr><tr><td align="left" valign="top"> <p>
								<code class="literal">xfs.perdev.inode_ops.*</code>
							</p>
							 </td><td align="left" valign="top"> <p>
								Counters for the number of times that the operating system looked for an XFS inode in the inode cache with different outcomes. These count cache hits, cache misses, and so on.
							</p>
							 </td></tr><tr><td align="left" valign="top"> <p>
								<code class="literal">xfs.perdev.log.*</code>
							</p>
							 <p>
								<code class="literal">xfs.perdev.log_tail.*</code>
							</p>
							 </td><td align="left" valign="top"> <p>
								Counters for the number of log buffer writes over XFS filesytems includes the number of blocks written to disk. Metrics also for the number of log flushes and pinning.
							</p>
							 </td></tr><tr><td align="left" valign="top"> <p>
								<code class="literal">xfs.perdev.xstrat.*</code>
							</p>
							 </td><td align="left" valign="top"> <p>
								Counts for the number of bytes of file data flushed out by the XFS flush deamon along with counters for number of buffers flushed to contiguous and non-contiguous space on disk.
							</p>
							 </td></tr><tr><td align="left" valign="top"> <p>
								<code class="literal">xfs.perdev.attr.*</code>
							</p>
							 </td><td align="left" valign="top"> <p>
								Counts for the number of attribute get, set, remove and list operations over all XFS file systems.
							</p>
							 </td></tr><tr><td align="left" valign="top"> <p>
								<code class="literal">xfs.perdev.quota.*</code>
							</p>
							 </td><td align="left" valign="top"> <p>
								Metrics for quota operation over XFS file systems, these include counters for number of quota reclaims, quota cache misses, cache hits and quota data reclaims.
							</p>
							 </td></tr><tr><td align="left" valign="top"> <p>
								<code class="literal">xfs.perdev.buffer.*</code>
							</p>
							 </td><td align="left" valign="top"> <p>
								Range of metrics regarding XFS buffer objects. Counters include the number of requested buffer calls, successful buffer locks, waited buffer locks, miss_locks, miss_retries and buffer hits when looking up pages.
							</p>
							 </td></tr><tr><td align="left" valign="top"> <p>
								<code class="literal">xfs.perdev.btree.*</code>
							</p>
							 </td><td align="left" valign="top"> <p>
								Metrics regarding the operations of the XFS btree.
							</p>
							 </td></tr></tbody></table></rh-table></section></section><section class="chapter" id="setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 9. Setting up graphical representation of PCP metrics</h2></div></div></div><p class="_abstract _abstract">
			Using a combination of <code class="literal">pcp</code>, <code class="literal">grafana</code>, <code class="literal">pcp redis</code>, <code class="literal">pcp bpftrace</code>, and <code class="literal">pcp vector</code> provides graphical representation of the live data or data collected by Performance Co-Pilot (PCP).
		</p><section class="section" id="setting-up-pcp-with-pcp-zeroconf_setting-up-graphical-representation-of-pcp-metrics"><div class="titlepage"><div><div><h3 class="title">9.1. Setting up PCP with pcp-zeroconf</h3></div></div></div><p class="_abstract _abstract">
				This procedure describes how to set up PCP on a system with the <code class="literal">pcp-zeroconf</code> package. Once the <code class="literal">pcp-zeroconf</code> package is installed, the system records the default set of metrics into archived files.
			</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Install the <code class="literal">pcp-zeroconf</code> package:
					</p><pre class="screen"># dnf install pcp-zeroconf</pre></li></ul></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Ensure that the <code class="literal">pmlogger</code> service is active, and starts archiving the metrics:
					</p><pre class="literallayout white-space-pre"># pcp | grep pmlogger
 pmlogger: primary logger: /var/log/pcp/pmlogger/<span class="emphasis"><em>localhost.localdomain/20200401.00.12</em></span></pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">pmlogger</code> man page on your system
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index#monitoring-performance-with-performance-co-pilot_monitoring-and-managing-system-status-and-performance">Monitoring performance with Performance Co-Pilot</a>
					</li></ul></div></section><section class="section" id="setting-up-a-grafana-server_setting-up-graphical-representation-of-pcp-metrics"><div class="titlepage"><div><div><h3 class="title">9.2. Setting up a Grafana server</h3></div></div></div><p class="_abstract _abstract">
				Grafana generates graphs that are accessible from a browser. The Grafana server is a back-end server for the Grafana dashboard. It listens, by default, on all interfaces, and provides web services accessed through the web browser. The <code class="literal">grafana-pcp</code> plugin interacts with the <code class="literal">pmproxy</code> daemon in the backend.
			</p><p>
				This procedure describes how to set up a Grafana server.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						PCP is configured. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance#setting-up-pcp-with-pcp-zeroconf_setting-up-graphical-representation-of-pcp-metrics">Setting up PCP with pcp-zeroconf</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Install the following packages:
					</p><pre class="screen"># dnf install grafana grafana-pcp</pre></li><li class="listitem"><p class="simpara">
						Restart and enable the following service:
					</p><pre class="screen"># systemctl restart grafana-server
# systemctl enable grafana-server</pre></li><li class="listitem"><p class="simpara">
						Open the server’s firewall for network traffic to the Grafana service.
					</p><pre class="screen"># firewall-cmd --permanent --add-service=grafana
success

# firewall-cmd --reload
success</pre></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Ensure that the Grafana server is listening and responding to requests:
					</p><pre class="screen"># ss -ntlp | grep 3000
LISTEN  0  128  *:3000  *:*  users:(("grafana-server",pid=19522,fd=7))</pre></li><li class="listitem"><p class="simpara">
						Ensure that the <code class="literal">grafana-pcp</code> plugin is installed:
					</p><pre class="screen"># grafana-cli plugins ls | grep performancecopilot-pcp-app

performancecopilot-pcp-app @ 5.1.1</pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">pmproxy(1)</code> and <code class="literal">grafana-server(1)</code> man pages on your system
					</li></ul></div></section><section class="section" id="accessing-the-grafana-web-ui_setting-up-graphical-representation-of-pcp-metrics"><div class="titlepage"><div><div><h3 class="title">9.3. Accessing the Grafana web UI</h3></div></div></div><p class="_abstract _abstract">
				This procedure describes how to access the Grafana web interface.
			</p><p>
				Using the Grafana web interface, you can:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Add PCP Redis, PCP bpftrace, and PCP Vector data sources
					</li><li class="listitem">
						Create dashboard
					</li><li class="listitem">
						View an overview of any useful metrics
					</li><li class="listitem">
						Create alerts in PCP Redis.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						PCP is configured. For more information, see <a class="link" href="#setting-up-pcp-with-pcp-zeroconf_setting-up-graphical-representation-of-pcp-metrics" title="9.1. Setting up PCP with pcp-zeroconf">Setting up PCP with pcp-zeroconf</a>.
					</li><li class="listitem">
						The Grafana server is configured. For more information, see <a class="link" href="#setting-up-a-grafana-server_setting-up-graphical-representation-of-pcp-metrics" title="9.2. Setting up a Grafana server">Setting up a Grafana server</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem">
						On the client system, open <code class="literal">http://<span class="emphasis"><em>&lt;grafana_server_IP_address_or_hostname&gt;</em></span>:3000</code> in your browser.
					</li><li class="listitem"><p class="simpara">
						For the first login, enter <span class="strong strong"><strong>admin</strong></span> in both the <span class="strong strong"><strong>Email or username</strong></span> and <span class="strong strong"><strong>Password</strong></span> field.
					</p><p class="simpara">
						Grafana prompts to set a <span class="strong strong"><strong>New password</strong></span> to create a secured account.
					</p></li><li class="listitem">
						In the menu, navigate to <span class="strong strong"><strong>Administration</strong></span> and then click <span class="strong strong"><strong>Plugins</strong></span>.
					</li><li class="listitem">
						In the <span class="strong strong"><strong>Plugins</strong></span> tab, type <code class="literal">performance co-pilot</code> in the <span class="strong strong"><strong>Search Grafana plugins</strong></span> text box and then click <span class="strong strong"><strong>Performance Co-Pilot</strong></span> (PCP) plugin.
					</li><li class="listitem">
						In the <span class="strong strong"><strong>Plugins / Performance Co-Pilot</strong></span> pane, click <span class="guibutton">Enable</span>.
					</li><li class="listitem"><p class="simpara">
						Click the Grafana icon  
						<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/a025b5a74873fcc2faa26c2441a34c43/grafana-home-page-whirl-icon.png" alt="grafana home page whirl icon"></span>
						  . The Grafana <span class="strong strong"><strong>Home</strong></span> page is displayed.
					</p><div class="figure" id="idm140280147165632"><p class="title"><strong>Figure 9.1. Home Dashboard</strong></p><div class="figure-contents"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/bf19e85b8f020e04a0450cff1108b4e3/grafana-home-dashboard1.png" alt="grafana home dashboard1"></div></div></div><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
							The top right corner of the screen has a settings (gear) icon  
							<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/3ba1a1723dd2484923c87992667e6de4/grafana-gear-icon1.png" alt="grafana gear icon1"></span>
							   that controls the general <span class="strong strong"><strong>Dashboard settings</strong></span>.
						</p></div></rh-alert></li><li class="listitem"><p class="simpara">
						In the Grafana <span class="strong strong"><strong>Home</strong></span> page, click <span class="strong strong"><strong>Add your first data source</strong></span> to add PCP Redis, PCP bpftrace, and PCP Vector data sources. For more information about adding data source, see:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								To add pcp redis data source, view default dashboard, create a panel, and an alert rule, see <a class="link" href="#creating-panel-and-alerts-in-pcp-redis-data-source_setting-up-graphical-representation-of-pcp-metrics" title="9.6. Creating panels and alerts in PCP Redis data source">Creating panels and alert in PCP Redis data source</a>.
							</li><li class="listitem">
								To add pcp bpftrace data source and view the default dashboard, see <a class="link" href="#viewing-the-pcp-bpftrace-system-analysis-dashboard_setting-up-graphical-representation-of-pcp-metrics" title="9.10. Viewing the PCP bpftrace System Analysis dashboard">Viewing the PCP bpftrace System Analysis dashboard</a>.
							</li><li class="listitem">
								To add pcp vector data source, view the default dashboard, and to view the vector checklist, see <a class="link" href="#viewing-the-pcp-vector-checklist_setting-up-graphical-representation-of-pcp-metrics" title="9.12. Viewing the PCP Vector Checklist">Viewing the PCP Vector Checklist</a>.
							</li></ul></div></li><li class="listitem">
						Optional: From the menu, hover over the <span class="strong strong"><strong>admin</strong></span> profile icon  
						<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/fb429591107dc7a2751707e864b36b6f/grafana-logout-option-icon.png" alt="grafana logout option icon"></span>
						   to update your <span class="strong strong"><strong>Profile</strong></span>, view <span class="strong strong"><strong>Notification history</strong></span>, <span class="strong strong"><strong>Change password</strong></span>, or to <span class="strong strong"><strong>Sign out</strong></span>.
					</li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">grafana-cli(1)</code> and <code class="literal">grafana-server(1)</code> man pages on your system
					</li></ul></div></section><section class="section" id="configuring-secure-connections-for-grafana_setting-up-graphical-representation-of-pcp-metrics"><div class="titlepage"><div><div><h3 class="title">9.4. Configuring secure connections for Grafana</h3></div></div></div><p>
				You can establish secure connections between Grafana and Performance Co-Pilot (PCP) components. Establishing secure connections between these components helps prevent unauthorized parties from accessing or modifying the data being collected and monitored.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						PCP is installed. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#installing-and-enabling-pcp_setting-up-pcp">Installing and enabling PCP</a>.
					</li><li class="listitem">
						The Grafana server is configured. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance#setting-up-a-grafana-server_setting-up-graphical-representation-of-pcp-metrics">Setting up a Grafana server</a>.
					</li><li class="listitem"><p class="simpara">
						The private client key is stored in the <code class="literal">/etc/grafana/grafana.key</code> file. If you use a different path, modify the path in the corresponding steps of the procedure.
					</p><p class="simpara">
						For details about creating a private key and certificate signing request (CSR), as well as how to request a certificate from a certificate authority (CA), see your CA’s documentation.
					</p></li><li class="listitem">
						The TLS client certificate is stored in the <code class="literal">/etc/grafana/grafana.crt</code> file. If you use a different path, modify the path in the corresponding steps of the procedure.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						As a root user, open the <code class="literal">/etc/grafana/grafana.ini</code> file and adjust the following options in the <code class="literal">[server]</code> section to reflect the following:
					</p><pre class="screen">protocol = https
cert_key = /etc/grafana/grafana.key
cert_file = /etc/grafana/grafana.crt</pre></li><li class="listitem"><p class="simpara">
						Ensure grafana can access the certificates:
					</p><pre class="screen"># su grafana -s /bin/bash -c \
  'ls -1 /etc/grafana/grafana.crt /etc/grafana/grafana.key'
/etc/grafana/grafana.crt
/etc/grafana/grafana.key</pre></li><li class="listitem"><p class="simpara">
						Restart and enable the Grafana service to apply the configuration changes:
					</p><pre class="screen"># systemctl restart grafana-server
# systemctl enable grafana-server</pre></li></ol></div><div class="orderedlist"><p class="title"><strong>Verification</strong></p><ol class="orderedlist" type="1"><li class="listitem">
						On the client system, open a browser and access the Grafana server machine on port 3000, using the <span class="emphasis"><em>https://192.0.2.0:3000</em></span> link. Replace 192.0.2.0 with your machine IP.
					</li><li class="listitem"><p class="simpara">
						Confirm the lock icon  
						<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/e35cc95bbc36bfbb39b356d56c9fa2a3/lock_icon.png" alt="lock icon"></span>
						   is displayed beside the address bar.
					</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
							If the protocol is set to <code class="literal">http</code> and an HTTPS connection is attempted, you will receive a <code class="literal">ERR_SSL_PROTOCOL_ERROR</code> error. If the protocol is set to <code class="literal">https</code> and an HTTP connection is attempted, the Grafana server responds with a “Client sent an HTTP request to an HTTPS server” message.
						</p></div></rh-alert></li></ol></div></section><section class="section" id="configuring-pcp-redis_setting-up-graphical-representation-of-pcp-metrics"><div class="titlepage"><div><div><h3 class="title">9.5. Configuring PCP Redis</h3></div></div></div><p class="_abstract _abstract">
				Use the PCP Redis data source to:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						View data archives
					</li><li class="listitem">
						Query time series using pmseries language
					</li><li class="listitem">
						Analyze data across multiple hosts
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						PCP is configured. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance#setting-up-pcp-with-pcp-zeroconf_setting-up-graphical-representation-of-pcp-metrics">Setting up PCP with pcp-zeroconf</a>.
					</li><li class="listitem">
						The Grafana server is configured. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance#setting-up-a-grafana-server_setting-up-graphical-representation-of-pcp-metrics">Setting up a Grafana server</a>.
					</li><li class="listitem">
						Mail transfer agent, for example, <code class="literal">sendmail</code> or <code class="literal">postfix</code> is installed and configured.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Install the <code class="literal">redis</code> package:
					</p><pre class="screen"># dnf install redis</pre></li><li class="listitem"><p class="simpara">
						Start and enable the following services:
					</p><pre class="screen"># systemctl start pmproxy redis
# systemctl enable pmproxy redis</pre></li><li class="listitem"><p class="simpara">
						Restart the Grafana server:
					</p><pre class="screen"># systemctl restart grafana-server</pre></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Ensure that the <code class="literal">pmproxy</code> and <code class="literal">redis</code> are working:
					</p><pre class="screen"># pmseries disk.dev.read
2eb3e58d8f1e231361fb15cf1aa26fe534b4d9df</pre><p class="simpara">
						This command does not return any data if the <code class="literal">redis</code> package is not installed.
					</p></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">pmseries(1)</code> man page on your system
					</li></ul></div></section><section class="section" id="creating-panel-and-alerts-in-pcp-redis-data-source_setting-up-graphical-representation-of-pcp-metrics"><div class="titlepage"><div><div><h3 class="title">9.6. Creating panels and alerts in PCP Redis data source</h3></div></div></div><p class="_abstract _abstract">
				After adding the PCP Redis data source, you can view the dashboard with an overview of useful metrics, add a query to visualize the load graph, and create alerts that help you to view the system issues after they occur.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						The PCP Redis is configured. For more information, see <a class="link" href="#configuring-pcp-redis_setting-up-graphical-representation-of-pcp-metrics" title="9.5. Configuring PCP Redis">Configuring PCP Redis</a>.
					</li><li class="listitem">
						The Grafana server is accessible. For more information, see <a class="link" href="#accessing-the-grafana-web-ui_setting-up-graphical-representation-of-pcp-metrics" title="9.3. Accessing the Grafana web UI">Accessing the Grafana web UI</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem">
						Log into the Grafana web UI.
					</li><li class="listitem">
						In the Grafana <span class="strong strong"><strong>Home</strong></span> page, click <span class="strong strong"><strong>Add your first data source</strong></span>.
					</li><li class="listitem">
						In the <span class="strong strong"><strong>Add data source</strong></span> pane, type <code class="literal">redis</code> in the <span class="strong strong"><strong>Filter by name or type</strong></span> text box and then click <span class="strong strong"><strong>PCP Redis</strong></span>.
					</li><li class="listitem"><p class="simpara">
						In the <span class="strong strong"><strong>Data Sources / PCP Redis</strong></span> pane, perform the following:
					</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem">
								Add <code class="literal">http://localhost:44322</code> in the <span class="strong strong"><strong>URL</strong></span> field and then click <span class="guibutton">Save &amp; Test</span>.
							</li><li class="listitem">
								Click <span class="guimenu">Dashboards tab</span> → <span class="guisubmenu">Import</span> → <span class="guimenuitem">PCP Redis: Host Overview</span> to see a dashboard with an overview of any useful metrics.
							</li><li class="listitem"><p class="simpara">
								Optional: In the drop-down menu next to the clock icon  
								<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/aad623ee40b87d8742467494b5efb798/grafana-clock-icon.png" alt="grafana clock icon"></span>
								  , you can set the timeline of the displayed metrics either by setting the absolute time range or by selecting a predefined range. You can also use the zoom out icon  
								<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/17baf4f1be1024c49bcc7039de10977e/grafana-zoom-out-icon.png" alt="grafana zoom out icon"></span>
								   to modify the displayed time range.
							</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
									The time frame displayed by default might not be aligned with the time frame covered by the archive files created by the <code class="literal">pmlogger</code> service.
								</p></div></rh-alert><div class="figure" id="idm140280147402448"><p class="title"><strong>Figure 9.2. PCP Redis: Host Overview</strong></p><div class="figure-contents"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/a65ab7967b9ce306fd522737f3eb7324/pcp-redis-host-overview1.png" alt="pcp redis host overview1"></div></div></div></li></ol></div></li><li class="listitem"><p class="simpara">
						Add a new panel:
					</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem">
								From the plus sign  
								<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/4bef4168e28b542ff381b4cf2e80a0ca/grafana-plus-sign1.png" alt="grafana plus sign1"></span>
								   drop-down menu, select <span class="strong strong"><strong>New dashboard</strong></span>.
							</li><li class="listitem">
								From the <span class="strong strong"><strong>Add</strong></span>   <span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/176d40372fa3d6f6e415514ac0e8db22/grafana-add-drop-down.png" alt="grafana add drop down"></span>
								   drop-down menu, select <span class="strong strong"><strong>Visualization</strong></span>.
							</li><li class="listitem">
								In the <span class="strong strong"><strong>Query</strong></span> tab, select the <span class="strong strong"><strong>pcp-redis-datasource</strong></span> as the <span class="strong strong"><strong>Data source</strong></span>.
							</li><li class="listitem">
								In the text field below <span class="strong strong"><strong>A</strong></span>, enter metric, for example, <code class="literal">kernel.all.load</code> to visualize the kernel load graph.
							</li><li class="listitem">
								Optional: From the <span class="strong strong"><strong>Time series</strong></span> drop-down menu on the right, select another format of visualization, for example, <span class="strong strong"><strong>Bar chart</strong></span>, <span class="strong strong"><strong>Table</strong></span>, or <span class="strong strong"><strong>Heatmap</strong></span>.
							</li><li class="listitem">
								Optional: Add <span class="strong strong"><strong>Panel title</strong></span> and <span class="strong strong"><strong>Description</strong></span>, and update other options.
							</li><li class="listitem">
								Click <span class="guibutton">Save</span> to apply changes and save the dashboard. Add <span class="strong strong"><strong>Title</strong></span>.
							</li><li class="listitem"><p class="simpara">
								Click <span class="guibutton">Apply</span> to apply changes and go back to the dashboard.
							</p><div class="figure" id="idm140280130725072"><p class="title"><strong>Figure 9.3. PCP Redis query panel</strong></p><div class="figure-contents"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/fb3c3f442d7a30ad1870192b27e646b9/pcp-redis-query.png" alt="pcp redis query"></div></div></div></li></ol></div></li><li class="listitem"><p class="simpara">
						Create an alert rule:
					</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem">
								In the <span class="strong strong"><strong>PCP Redis query panel</strong></span>, click <span class="strong strong"><strong>Alert</strong></span>   <span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/27faa831b9bb3c08a33a610ea23926df/grafana-alert.png" alt="grafana alert"></span>
								   and then click <span class="strong strong"><strong>New alert rule</strong></span>.
							</li><li class="listitem">
								Enter alert rule name.
							</li><li class="listitem">
								Define query and alert condition.
							</li><li class="listitem">
								Set evaluation behavior.
							</li><li class="listitem">
								Optional: Add annotations.
							</li><li class="listitem">
								Add labels and notifications.
							</li><li class="listitem">
								Click <span class="guibutton">Save rule an exit</span> to apply changes in alert rules.
							</li><li class="listitem"><p class="simpara">
								Click <span class="guibutton">Apply</span> to apply changes and go back to the dashboard.
							</p><div class="figure" id="idm140280148325984"><p class="title"><strong>Figure 9.4. Creating alerts in the PCP Redis panel</strong></p><div class="figure-contents"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/05755c9f85d5eb517bbe54bed543b40c/pcp-redis-alert1.png" alt="pcp redis alert1"></div></div></div><p class="simpara">
								To add a notification channel for the created alert rule to receive an alert notification from Grafana, see <a class="link" href="#adding-notification-channels-for-alerts_setting-up-graphical-representation-of-pcp-metrics" title="9.7. Adding notification channels for alerts">Adding notification channels for alerts</a>.
							</p></li></ol></div></li></ol></div></section><section class="section" id="adding-notification-channels-for-alerts_setting-up-graphical-representation-of-pcp-metrics"><div class="titlepage"><div><div><h3 class="title">9.7. Adding notification channels for alerts</h3></div></div></div><p class="_abstract _abstract">
				By adding notification channels, you can receive an alert notification from Grafana whenever the alert rule conditions are met and the system needs further monitoring.
			</p><p>
				You can receive these alerts after selecting any one type from the supported list of notifiers, which includes:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Alertmanager
					</li><li class="listitem">
						Cisco Webex Teams
					</li><li class="listitem">
						DingDing
					</li><li class="listitem">
						Discord
					</li><li class="listitem">
						Email
					</li><li class="listitem">
						Google Chat
					</li><li class="listitem">
						Kafka REST Proxy
					</li><li class="listitem">
						LINE
					</li><li class="listitem">
						Microsoft Teams
					</li><li class="listitem">
						OpsGenie
					</li><li class="listitem">
						PagerDuty
					</li><li class="listitem">
						Pushover
					</li><li class="listitem">
						Sensu Go
					</li><li class="listitem">
						Slack
					</li><li class="listitem">
						Telegram
					</li><li class="listitem">
						Threema Gateway
					</li><li class="listitem">
						VictorOps
					</li><li class="listitem">
						WeCom
					</li><li class="listitem">
						Webhook
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						The Grafana server is accessible. For more information, see <a class="link" href="#accessing-the-grafana-web-ui_setting-up-graphical-representation-of-pcp-metrics" title="9.3. Accessing the Grafana web UI">Accessing the Grafana web UI</a>.
					</li><li class="listitem">
						An alert rule is created. For more information, see <a class="link" href="#creating-panel-and-alerts-in-pcp-redis-data-source_setting-up-graphical-representation-of-pcp-metrics" title="9.6. Creating panels and alerts in PCP Redis data source">Creating panels and alert in PCP Redis data source</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Configure SMTP and add a valid sender’s email address in the <code class="literal">/etc/grafana/grafana.ini</code> file:
					</p><pre class="screen">[smtp]
enabled = true
from_address = <span class="emphasis"><em>&lt;sender_email_address&gt;</em></span></pre></li><li class="listitem"><p class="simpara">
						Restart the Grafana server.
					</p><pre class="screen"># systemctl restart grafana-server.service</pre></li><li class="listitem"><p class="simpara">
						From the menu, select <span class="guimenu">Alerting</span> → <span class="guisubmenu">Contact points</span> → <span class="guimenuitem">+ Add contact point</span>.
					</p><div class="figure" id="idm140280147955840"><p class="title"><strong>Figure 9.5. Alerting in Grafana</strong></p><div class="figure-contents"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/3a62289eefc2075c37e590702f80a9f3/grafana-alerting-panel.png" alt="grafana alerting panel"></div></div></div></li><li class="listitem"><p class="simpara">
						In the <span class="strong strong"><strong>Create contact point</strong></span> details view, perform the following:
					</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem">
								Enter your name in the <span class="strong strong"><strong>Name</strong></span> text box.
							</li><li class="listitem">
								Select the <span class="strong strong"><strong>Integration</strong></span> type, for example, Email and enter the email address or multiple email addresses.
							</li><li class="listitem">
								Optional: Configure <span class="strong strong"><strong>Optional Email settings</strong></span> and <span class="strong strong"><strong>Notification settings</strong></span>.
							</li></ol></div></li><li class="listitem">
						Click <span class="guibutton">Save contact point</span>.
					</li><li class="listitem"><p class="simpara">
						Select a notification channel in the alert rule:
					</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem">
								From the <span class="strong strong"><strong>Alerting</strong></span> menu, select <span class="strong strong"><strong>Notification policies</strong></span>.
							</li><li class="listitem">
								Click the three dots icon  
								<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/4ace5574078c2572f3c088e45d5e27d5/grafana-3-dots.png" alt="grafana 3 dots"></span>
								   on the far right of <span class="strong strong"><strong>Default policy</strong></span> and select <span class="strong strong"><strong>Edit</strong></span>.
							</li><li class="listitem">
								Choose the <span class="strong strong"><strong>Contact point</strong></span> you have just created and click <span class="strong strong"><strong>Update default policy</strong></span>.
							</li><li class="listitem">
								Optional: Configure a nested policy in addition to the default policy.
							</li><li class="listitem">
								Optional: Configure <span class="strong strong"><strong>Mute Timings</strong></span>.
							</li></ol></div></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="https://grafana.com/docs/grafana/v10.0/alerting/alerting-rules/create-notification-policy/">Upstream Grafana documentation for alert notification policies</a>
					</li></ul></div></section><section class="section" id="setting-up-authentication-between-pcp-components_setting-up-graphical-representation-of-pcp-metrics"><div class="titlepage"><div><div><h3 class="title">9.8. Setting up authentication between PCP components</h3></div></div></div><p class="_abstract _abstract">
				You can setup authentication using the <code class="literal">scram-sha-256</code> authentication mechanism, which is supported by PCP through the Simple Authentication Security Layer (SASL) framework.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Install the <code class="literal">sasl</code> framework for the <code class="literal">scram-sha-256</code> authentication mechanism:
					</p><pre class="screen"># dnf install cyrus-sasl-scram cyrus-sasl-lib</pre></li><li class="listitem"><p class="simpara">
						Specify the supported authentication mechanism and the user database path in the <code class="literal">pmcd.conf</code> file:
					</p><pre class="screen"># vi /etc/sasl2/pmcd.conf

mech_list: scram-sha-256

sasldb_path: /etc/pcp/passwd.db</pre></li><li class="listitem"><p class="simpara">
						Create a new user:
					</p><pre class="screen"># useradd -r <span class="emphasis"><em>metrics</em></span></pre><p class="simpara">
						Replace <span class="emphasis"><em>metrics</em></span> by your user name.
					</p></li><li class="listitem"><p class="simpara">
						Add the created user in the user database:
					</p><pre class="screen"># saslpasswd2 -a pmcd <span class="emphasis"><em>metrics</em></span>

Password:
Again (for verification):</pre><p class="simpara">
						To add the created user, you are required to enter the <span class="emphasis"><em>metrics</em></span> account password.
					</p></li><li class="listitem"><p class="simpara">
						Set the permissions of the user database:
					</p><pre class="screen"># chown root:pcp /etc/pcp/passwd.db
# chmod 640 /etc/pcp/passwd.db</pre></li><li class="listitem"><p class="simpara">
						Restart the <code class="literal">pmcd</code> service:
					</p><pre class="screen"># systemctl restart pmcd</pre></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Verify the <code class="literal">sasl</code> configuration:
					</p><pre class="literallayout white-space-pre"># pminfo -f -h "pcp://127.0.0.1?username=<span class="emphasis"><em>metrics</em></span>" disk.dev.read
Password:
disk.dev.read
inst [0 or "sda"] value 19540</pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">saslauthd(8)</code>, <code class="literal">pminfo(1)</code>, and <code class="literal">sha256</code> man pages on your system
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/solutions/5041891">How can I setup authentication between PCP components, like PMDAs and pmcd in RHEL 8.2?</a> (Red Hat Knowledgebase)
					</li></ul></div></section><section class="section" id="installing-pcp-bpftrace_setting-up-graphical-representation-of-pcp-metrics"><div class="titlepage"><div><div><h3 class="title">9.9. Installing PCP bpftrace</h3></div></div></div><p class="_abstract _abstract">
				Install the PCP <code class="literal">bpftrace</code> agent to introspect a system and to gather metrics from the kernel and user-space tracepoints.
			</p><p>
				The <code class="literal">bpftrace</code> agent uses bpftrace scripts to gather the metrics. The <code class="literal">bpftrace</code> scripts use the enhanced Berkeley Packet Filter (<code class="literal">eBPF</code>).
			</p><p>
				This procedure describes how to install a <code class="literal">pcp bpftrace</code>.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						PCP is configured. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance#setting-up-pcp-with-pcp-zeroconf_setting-up-graphical-representation-of-pcp-metrics">Setting up PCP with pcp-zeroconf</a>.
					</li><li class="listitem">
						The Grafana server is configured. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance#setting-up-a-grafana-server_setting-up-graphical-representation-of-pcp-metrics">Setting up a Grafana server</a>.
					</li><li class="listitem">
						The <code class="literal">scram-sha-256</code> authentication mechanism is configured. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance#setting-up-authentication-between-pcp-components_setting-up-graphical-representation-of-pcp-metrics">Setting up authentication between PCP components</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Install the <code class="literal">pcp-pmda-bpftrace</code> package:
					</p><pre class="screen"># dnf install pcp-pmda-bpftrace</pre></li><li class="listitem"><p class="simpara">
						Edit the <code class="literal">bpftrace.conf</code> file and add the user that you have created in <a class="link" href="#setting-up-authentication-between-pcp-components_setting-up-graphical-representation-of-pcp-metrics" title="9.8. Setting up authentication between PCP components">Setting up authentication between PCP components</a>:
					</p><pre class="screen"># vi /var/lib/pcp/pmdas/bpftrace/bpftrace.conf

[dynamic_scripts]
enabled = true
auth_enabled = true
allowed_users = root,<span class="emphasis"><em>metrics</em></span></pre><p class="simpara">
						Replace <span class="emphasis"><em>metrics</em></span> by your user name.
					</p></li><li class="listitem"><p class="simpara">
						Install <code class="literal">bpftrace</code> PMDA:
					</p><pre class="screen"># cd /var/lib/pcp/pmdas/bpftrace/
# ./Install
Updating the Performance Metrics Name Space (PMNS) ...
Terminate PMDA if already installed ...
Updating the PMCD control file, and notifying PMCD ...
Check bpftrace metrics have appeared ... 7 metrics and 6 values</pre><p class="simpara">
						The <code class="literal">pmda-bpftrace</code> is now installed, and can only be used after authenticating your user. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance#viewing-the-pcp-bpftrace-system-analysis-dashboard_setting-up-graphical-representation-of-pcp-metrics">Viewing the PCP bpftrace System Analysis dashboard</a>.
					</p></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">pmdabpftrace(1)</code> and <code class="literal">bpftrace</code> man pages on your system
					</li></ul></div></section><section class="section" id="viewing-the-pcp-bpftrace-system-analysis-dashboard_setting-up-graphical-representation-of-pcp-metrics"><div class="titlepage"><div><div><h3 class="title">9.10. Viewing the PCP bpftrace System Analysis dashboard</h3></div></div></div><p class="_abstract _abstract">
				Using the PCP bpftrace data source, you can access the live data from sources which are not available as normal data from the <code class="literal">pmlogger</code> or archives
			</p><p>
				In the PCP bpftrace data source, you can view the dashboard with an overview of useful metrics.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						The PCP bpftrace is installed. For more information, see <a class="link" href="#installing-pcp-bpftrace_setting-up-graphical-representation-of-pcp-metrics" title="9.9. Installing PCP bpftrace">Installing PCP bpftrace</a>.
					</li><li class="listitem">
						The Grafana server is accessible. For more information, see <a class="link" href="#accessing-the-grafana-web-ui_setting-up-graphical-representation-of-pcp-metrics" title="9.3. Accessing the Grafana web UI">Accessing the Grafana web UI</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem">
						Log into the Grafana web UI.
					</li><li class="listitem">
						In the menu, navigate to <span class="guimenu">Connections</span> → <span class="guisubmenu">Data sources</span> → <span class="guimenuitem">+ Add new data source</span>.
					</li><li class="listitem">
						In the <span class="strong strong"><strong>Add data source</strong></span> pane, type bpftrace in the <span class="strong strong"><strong>Filter by name or type</strong></span> text box and then click <span class="strong strong"><strong>PCP bpftrace</strong></span>.
					</li><li class="listitem"><p class="simpara">
						In the <span class="strong strong"><strong>Data Sources / pcp-bpftrace-datasource</strong></span> pane, perform the following:
					</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem">
								Add <code class="literal">http://localhost:44322</code> in the <span class="strong strong"><strong>URL</strong></span> field.
							</li><li class="listitem">
								Toggle the <span class="strong strong"><strong>Basic Auth</strong></span> option and add the created user credentials in the <span class="strong strong"><strong>User</strong></span> and <span class="strong strong"><strong>Password</strong></span> field.
							</li><li class="listitem"><p class="simpara">
								Click <span class="guibutton">Save &amp; Test</span>.
							</p><div class="figure" id="idm140280149813488"><p class="title"><strong>Figure 9.6. Adding PCP bpftrace in the data source</strong></p><div class="figure-contents"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/9df0f37edb579f894d76bff2821315b2/pcp-bpftrace.png" alt="pcp bpftrace"></div></div></div></li><li class="listitem"><p class="simpara">
								Click <span class="guimenu">Dashboards tab</span> → <span class="guisubmenu">Import</span> → <span class="guimenuitem">PCP bpftrace: System Analysis</span> to see a dashboard with an overview of any useful metrics.
							</p><div class="figure" id="idm140280150479328"><p class="title"><strong>Figure 9.7. PCP bpftrace: System Analysis</strong></p><div class="figure-contents"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/8b57d67ce674ef329aad1a0443df11a1/pcp-bpftrace-system-analysis1.png" alt="pcp bpftrace system analysis1"></div></div></div></li></ol></div></li></ol></div></section><section class="section" id="installing-pcp-vector_setting-up-graphical-representation-of-pcp-metrics"><div class="titlepage"><div><div><h3 class="title">9.11. Installing PCP Vector</h3></div></div></div><p class="_abstract _abstract">
				This procedure describes how to install a <code class="literal">pcp vector</code>.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						PCP is configured. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance#setting-up-pcp-with-pcp-zeroconf_setting-up-graphical-representation-of-pcp-metrics">Setting up PCP with pcp-zeroconf</a>.
					</li><li class="listitem">
						The Grafana server is configured. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance#setting-up-a-grafana-server_setting-up-graphical-representation-of-pcp-metrics">Setting up a Grafana server</a>.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Install the <code class="literal">bcc</code> PMDA:
					</p><pre class="screen"># cd /var/lib/pcp/pmdas/bcc
# ./Install
[Wed Apr  1 00:27:48] pmdabcc(22341) Info: Initializing, currently in 'notready' state.
[Wed Apr  1 00:27:48] pmdabcc(22341) Info: Enabled modules:
[Wed Apr  1 00:27:48] pmdabcc(22341) Info: ['biolatency', 'sysfork',
[...]
Updating the Performance Metrics Name Space (PMNS) ...
Terminate PMDA if already installed ...
Updating the PMCD control file, and notifying PMCD ...
Check bcc metrics have appeared ... 1 warnings, 1 metrics and 0 values</pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">pmdabcc(1)</code> man page on your system
					</li></ul></div></section><section class="section" id="viewing-the-pcp-vector-checklist_setting-up-graphical-representation-of-pcp-metrics"><div class="titlepage"><div><div><h3 class="title">9.12. Viewing the PCP Vector Checklist</h3></div></div></div><p class="_abstract _abstract">
				The PCP Vector data source displays live metrics and uses the <code class="literal">pcp</code> metrics. It analyzes data for individual hosts.
			</p><p>
				After adding the PCP Vector data source, you can view the dashboard with an overview of useful metrics and view the related troubleshooting or reference links in the checklist.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						The PCP Vector is installed. For more information, see <a class="link" href="#installing-pcp-vector_setting-up-graphical-representation-of-pcp-metrics" title="9.11. Installing PCP Vector">Installing PCP Vector</a>.
					</li><li class="listitem">
						The Grafana server is accessible. For more information, see <a class="link" href="#accessing-the-grafana-web-ui_setting-up-graphical-representation-of-pcp-metrics" title="9.3. Accessing the Grafana web UI">Accessing the Grafana web UI</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem">
						Log into the Grafana web UI.
					</li><li class="listitem">
						In the menu, navigate to <span class="guimenu">Connections</span> → <span class="guisubmenu">Data sources</span> → <span class="guimenuitem">+ Add new data source</span>.
					</li><li class="listitem">
						In the <span class="strong strong"><strong>Add data source</strong></span> pane, type vector in the <span class="strong strong"><strong>Filter by name or type</strong></span> text box and then click <span class="strong strong"><strong>PCP Vector</strong></span>.
					</li><li class="listitem"><p class="simpara">
						In the <span class="strong strong"><strong>Data Sources / pcp-vector-datasource</strong></span> pane, perform the following:
					</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem">
								Add <code class="literal">http://localhost:44322</code> in the <span class="strong strong"><strong>URL</strong></span> field and then click <span class="guibutton">Save &amp; Test</span>.
							</li><li class="listitem"><p class="simpara">
								Click <span class="guimenu">Dashboards tab</span> → <span class="guisubmenu">Import</span> → <span class="guimenuitem">PCP Vector: Host Overview</span> to see a dashboard with an overview of any useful metrics.
							</p><div class="figure" id="idm140280138903248"><p class="title"><strong>Figure 9.8. PCP Vector: Host Overview</strong></p><div class="figure-contents"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/4d178ed3d910ced56dc97c587729c2a6/pcp-vector-host-overview1.png" alt="pcp vector host overview1"></div></div></div></li></ol></div></li><li class="listitem"><p class="simpara">
						In the menu, navigate to <span class="guimenu">Apps</span> → <span class="guisubmenu">Performance Co-Pilot</span> → <span class="guimenuitem">PCP Vector Checklist</span>.
					</p><p class="simpara">
						In the PCP checklist, click the question mark icon  
						<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/aeafb42a73abe35a996fbef332985497/pcp-vector-checklist-troubleshooting-doc.png" alt="pcp vector checklist troubleshooting doc"></span>
						   for help or the warning icon  
						<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/d5171f39042726c86cc66894ed34a88a/pcp-vector-checklist-warning.png" alt="pcp vector checklist warning"></span>
						   to view the related troubleshooting or reference links.
					</p><div class="figure" id="idm140280150238608"><p class="title"><strong>Figure 9.9. Performance Co-Pilot / PCP Vector Checklist</strong></p><div class="figure-contents"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/8767f919ee35f25eb3aaf26dd10a1931/pcp-vector-checklist1.png" alt="pcp vector checklist1"></div></div></div></li></ol></div></section><section class="section" id="using-heatmaps-in-grafana_setting-up-graphical-representation-of-pcp-metrics"><div class="titlepage"><div><div><h3 class="title">9.13. Using heatmaps in Grafana</h3></div></div></div><p>
				You can use heatmaps in Grafana to view histograms of your data over time, identify trends and patterns in your data, and see how they change over time. Each column within a heatmap represents a single histogram with different colored cells representing the different densities of observation of a given value within that histogram.
			</p><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
					This specific workflow is for the heatmaps in Grafana version 10 and later on RHEL9.
				</p></div></rh-alert><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						PCP Redis is configured. For more information see <a class="link" href="#configuring-pcp-redis_setting-up-graphical-representation-of-pcp-metrics" title="9.5. Configuring PCP Redis">Configuring PCP Redis</a>.
					</li><li class="listitem">
						The Grafana server is accessible. For more information see <a class="link" href="#accessing-the-grafana-web-ui_setting-up-graphical-representation-of-pcp-metrics" title="9.3. Accessing the Grafana web UI">Accessing the Grafana Web UI</a>.
					</li><li class="listitem">
						The PCP Redis data source is configured. For more information see <a class="link" href="#creating-panel-and-alerts-in-pcp-redis-data-source_setting-up-graphical-representation-of-pcp-metrics" title="9.6. Creating panels and alerts in PCP Redis data source">Creating panels and alerts in PCP Redis data source</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem">
						In the menu, select <span class="guimenu">Dashboards</span> → <span class="guisubmenu">New Dashboard</span> → <span class="guimenuitem">+ Add visualization</span>.
					</li><li class="listitem">
						In the <span class="strong strong"><strong>Select data source</strong></span> pane, select <span class="strong strong"><strong>pcp-redis-datasource</strong></span>.
					</li><li class="listitem">
						In the <span class="strong strong"><strong>Query</strong></span> tab, in the text field below <span class="strong strong"><strong>A</strong></span>, enter a metric, for example, <code class="literal">kernel.all.load</code> to visualize the kernel load graph.
					</li><li class="listitem">
						From the <span class="strong strong"><strong>Time series</strong></span> drop-down menu on the right, select <span class="strong strong"><strong>Heatmap</strong></span>.
					</li><li class="listitem">
						Optional: In the <span class="strong strong"><strong>Panel Options</strong></span> dropdown menu, add a <span class="strong strong"><strong>Panel Title</strong></span> and <span class="strong strong"><strong>Description</strong></span>.
					</li><li class="listitem"><p class="simpara">
						In the <span class="strong strong"><strong>Heatmap</strong></span> dropdown menu, under the <span class="strong strong"><strong>Calculate from data</strong></span> setting, click <span class="strong strong"><strong>Yes</strong></span>.
					</p><div class="formalpara"><p class="title"><strong>Heatmap</strong></p><p>
							<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/ac37e49e146f7139fe58971516c38f99/grafana_heatmap.png" alt="A configured Grafana heatmap"></span>

						</p></div></li><li class="listitem">
						Optional: In the <span class="strong strong"><strong>Colors</strong></span> dropdown menu, change the <span class="strong strong"><strong>Scheme</strong></span> from the default <span class="strong strong"><strong>Orange</strong></span> and select the number of steps (color shades).
					</li><li class="listitem"><p class="simpara">
						Optional: In the <span class="strong strong"><strong>Tooltip</strong></span> dropdown menu, click the toggle to display a cell’s position within its specific histogram when hovering your cursor over a cell in the heatmap. For example:
					</p><div class="formalpara"><p class="title"><strong>Show histogram (Y Axis) cell display</strong></p><p>
							<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/3f6341feaf365f49731bd763dd4442ff/grafana_histogram.png" alt="A cell’s specific position within its histogram"></span>

						</p></div></li></ol></div></section><section class="section" id="troubleshooting-grafana-issues_setting-up-graphical-representation-of-pcp-metrics"><div class="titlepage"><div><div><h3 class="title">9.14. Troubleshooting Grafana issues</h3></div></div></div><p class="_abstract _abstract">
				It is sometimes neccesary to troubleshoot Grafana issues, such as, Grafana does not display any data, the dashboard is black, or similar issues.
			</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Verify that the <code class="literal">pmlogger</code> service is up and running by executing the following command:
					</p><pre class="screen">$ systemctl status pmlogger</pre></li><li class="listitem"><p class="simpara">
						Verify if files were created or modified to the disk by executing the following command:
					</p><pre class="literallayout">$ ls /var/log/pcp/pmlogger/$(hostname)/ -rlt
total 4024
-rw-r--r--. 1 pcp pcp   45996 Oct 13  2019 20191013.20.07.meta.xz
-rw-r--r--. 1 pcp pcp     412 Oct 13  2019 20191013.20.07.index
-rw-r--r--. 1 pcp pcp   32188 Oct 13  2019 20191013.20.07.0.xz
-rw-r--r--. 1 pcp pcp   44756 Oct 13  2019 20191013.20.30-00.meta.xz
[..]</pre></li><li class="listitem"><p class="simpara">
						Verify that the <code class="literal">pmproxy</code> service is running by executing the following command:
					</p><pre class="screen">$ systemctl status pmproxy</pre></li><li class="listitem"><p class="simpara">
						Verify that <code class="literal">pmproxy</code> is running, time series support is enabled, and a connection to Redis is established by viewing the <code class="literal">/var/log/pcp/pmproxy/pmproxy.log</code> file and ensure that it contains the following text:
					</p><pre class="screen">pmproxy(1716) Info: Redis slots, command keys, schema version setup</pre><p class="simpara">
						Here, <span class="strong strong"><strong>1716</strong></span> is the PID of pmproxy, which will be different for every invocation of <code class="literal">pmproxy</code>.
					</p></li><li class="listitem"><p class="simpara">
						Verify if the Redis database contains any keys by executing the following command:
					</p><pre class="screen">$ redis-cli dbsize
(integer) 34837</pre></li><li class="listitem"><p class="simpara">
						Verify if any PCP metrics are in the Redis database and <code class="literal">pmproxy</code> is able to access them by executing the following commands:
					</p><pre class="literallayout">$ pmseries disk.dev.read
2eb3e58d8f1e231361fb15cf1aa26fe534b4d9df

$ pmseries "disk.dev.read[count:10]"
2eb3e58d8f1e231361fb15cf1aa26fe534b4d9df
    [Mon Jul 26 12:21:10.085468000 2021] 117971 70e83e88d4e1857a3a31605c6d1333755f2dd17c
    [Mon Jul 26 12:21:00.087401000 2021] 117758 70e83e88d4e1857a3a31605c6d1333755f2dd17c
    [Mon Jul 26 12:20:50.085738000 2021] 116688 70e83e88d4e1857a3a31605c6d1333755f2dd17c
[...]</pre><pre class="literallayout">$ redis-cli --scan --pattern "*$(pmseries 'disk.dev.read')"

pcp:metric.name:series:2eb3e58d8f1e231361fb15cf1aa26fe534b4d9df
pcp:values:series:2eb3e58d8f1e231361fb15cf1aa26fe534b4d9df
pcp:desc:series:2eb3e58d8f1e231361fb15cf1aa26fe534b4d9df
pcp:labelvalue:series:2eb3e58d8f1e231361fb15cf1aa26fe534b4d9df
pcp:instances:series:2eb3e58d8f1e231361fb15cf1aa26fe534b4d9df
pcp:labelflags:series:2eb3e58d8f1e231361fb15cf1aa26fe534b4d9df</pre></li><li class="listitem"><p class="simpara">
						Verify if there are any errors in the Grafana logs by executing the following command:
					</p><pre class="literallayout">$ journalctl -e -u grafana-server
-- Logs begin at Mon 2021-07-26 11:55:10 IST, end at Mon 2021-07-26 12:30:15 IST. --
Jul 26 11:55:17 localhost.localdomain systemd[1]: Starting Grafana instance...
Jul 26 11:55:17 localhost.localdomain grafana-server[1171]: t=2021-07-26T11:55:17+0530 lvl=info msg="Starting Grafana" logger=server version=7.3.6 c&gt;
Jul 26 11:55:17 localhost.localdomain grafana-server[1171]: t=2021-07-26T11:55:17+0530 lvl=info msg="Config loaded from" logger=settings file=/usr/s&gt;
Jul 26 11:55:17 localhost.localdomain grafana-server[1171]: t=2021-07-26T11:55:17+0530 lvl=info msg="Config loaded from" logger=settings file=/etc/g&gt;
[...]</pre></li></ul></div></section></section><section class="chapter" id="using-the-web-console-for-selecting-performance-profiles_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 10. Optimizing the system performance using the web console</h2></div></div></div><p class="_abstract _abstract">
			Learn how to set a performance profile in the RHEL web console to optimize the performance of the system for a selected task.
		</p><section class="section" id="performance-tuning-options-in-the-web-console_optimizing-the-system-performance-using-the-web-console"><div class="titlepage"><div><div><h3 class="title">10.1. Performance tuning options in the web console</h3></div></div></div><p class="_abstract _abstract">
				Red Hat Enterprise Linux 9 provides several performance profiles that optimize the system for the following tasks:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Systems using the desktop
					</li><li class="listitem">
						Throughput performance
					</li><li class="listitem">
						Latency performance
					</li><li class="listitem">
						Network performance
					</li><li class="listitem">
						Low power consumption
					</li><li class="listitem">
						Virtual machines
					</li></ul></div><p>
				The <code class="literal">TuneD</code> service optimizes system options to match the selected profile.
			</p><p>
				In the web console, you can set which performance profile your system uses.
			</p><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-tuned_monitoring-and-managing-system-status-and-performance">Getting started with TuneD</a>
					</li></ul></div></section><section class="section" id="setting-a-performance-profile-in-the-web-console_optimizing-the-system-performance-using-the-web-console"><div class="titlepage"><div><div><h3 class="title">10.2. Setting a performance profile in the web console</h3></div></div></div><p class="_abstract _abstract">
				Depending on the task you want to perform, you can use the web console to optimize system performance by setting a suitable performance profile.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						You have installed the RHEL 9 web console.
					</p><p class="simpara">
						For instructions, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console">Installing and enabling the web console</a>.
					</p></li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Log in to the RHEL 9 web console.
					</p><p class="simpara">
						For details, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#logging-in-to-the-web-console_getting-started-with-the-rhel-9-web-console">Logging in to the web console</a>.
					</p></li><li class="listitem">
						Click <span class="strong strong"><strong>Overview</strong></span>.
					</li><li class="listitem"><p class="simpara">
						In the <span class="strong strong"><strong>Configuration</strong></span> section, click the current performance profile.
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/6657171b9c582eae939d7b0d427f1cab/cockpit-performance-profile-pf4.png" alt="Image displaying the Overview pane of the cockpit interface."></span>

					</p></li><li class="listitem"><p class="simpara">
						In the <span class="strong strong"><strong>Change Performance Profile</strong></span> dialog box, set the required profile.
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/44d16f8526acc4d5468e8ad42cdd52ab/cockpit-performance-profile-change-pf4.png" alt="Image displaying the Change performance profile dialog box."></span>

					</p></li><li class="listitem">
						Click <span class="guibutton">Change Profile</span>.
					</li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						The <span class="strong strong"><strong>Overview</strong></span> tab now shows the selected performance profile in the <span class="strong strong"><strong>Configuration</strong></span> section.
					</li></ul></div></section><section class="section" id="monitoring-performance-using-the-web-console_optimizing-the-system-performance-using-the-web-console"><div class="titlepage"><div><div><h3 class="title">10.3. Monitoring performance on the local system by using the web console</h3></div></div></div><p>
				Red Hat Enterprise Linux web console uses the Utilization Saturation and Errors (USE) Method for troubleshooting. The new performance metrics page has a historical view of your data organized chronologically with the newest data at the top.
			</p><p>
				In the <span class="strong strong"><strong>Metrics and history</strong></span> page, you can view events, errors, and graphical representation for resource utilization and saturation.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						You have installed the RHEL 9 web console.
					</p><p class="simpara">
						For instructions, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console">Installing and enabling the web console</a>.
					</p></li><li class="listitem">
						The <code class="literal">cockpit-pcp</code> package, which enables collecting the performance metrics, is installed.
					</li><li class="listitem"><p class="simpara">
						The Performance Co-Pilot (PCP) service is enabled:
					</p><pre class="screen"># <span class="strong strong"><strong>systemctl enable --now pmlogger.service pmproxy.service</strong></span></pre></li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Log in to the RHEL 9 web console.
					</p><p class="simpara">
						For details, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#logging-in-to-the-web-console_getting-started-with-the-rhel-9-web-console">Logging in to the web console</a>.
					</p></li><li class="listitem">
						Click <span class="strong strong"><strong>Overview</strong></span>.
					</li><li class="listitem"><p class="simpara">
						In the <span class="strong strong"><strong>Usage</strong></span> section, click <span class="strong strong"><strong>View metrics and history</strong></span>.
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/6657171b9c582eae939d7b0d427f1cab/cockpit-performance-profile-pf4.png" alt="Image displaying the Overview pane of the cockpit interface."></span>

					</p><p class="simpara">
						The <span class="strong strong"><strong>Metrics and history</strong></span> section opens:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								The current system configuration and usage:
								<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/b947ab3a7147c086e7c837d0abb496de/webconsole-view-details.png" alt="Image displaying the current system configuration and usage"></span>

							</li><li class="listitem">
								The performance metrics in a graphical form over a user-specified time interval:
								<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/2f82ace99e1cb1ddc0598f2a2b301402/webconsole-performance-metrics.png" alt="Image displaying the performance metrics of the CPU"></span>

							</li></ul></div></li></ol></div></section><section class="section" id="proc_enabling-performance-metrics-export-with-pcp-from-the-web-console_optimizing-the-system-performance-using-the-web-console"><div class="titlepage"><div><div><h3 class="title">10.4. Monitoring performance on several systems by using the web console and Grafana</h3></div></div></div><p>
				Grafana enables you to collect data from several systems at once and review a graphical representation of their collected Performance Co-Pilot (PCP) metrics. You can set up performance metrics monitoring and export for several systems in the web console interface.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						You have installed the RHEL 9 web console.
					</p><p class="simpara">
						For instructions, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console">Installing and enabling the web console</a>.
					</p></li><li class="listitem">
						You have installed the <code class="literal">cockpit-pcp</code> package.
					</li><li class="listitem"><p class="simpara">
						You have enabled the PCP service:
					</p><pre class="screen"># <span class="strong strong"><strong>systemctl enable --now pmlogger.service pmproxy.service</strong></span></pre></li><li class="listitem">
						You have set up the Grafana dashboard. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance#setting-up-a-grafana-server_setting-up-graphical-representation-of-pcp-metrics">Setting up a grafana-server</a>.
					</li><li class="listitem"><p class="simpara">
						You have installed the <code class="literal">redis</code> package.
					</p><p class="simpara">
						Alternatively, you can install the package from the web console interface later in the procedure.
					</p></li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Log in to the RHEL 9 web console.
					</p><p class="simpara">
						For details, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#logging-in-to-the-web-console_getting-started-with-the-rhel-9-web-console">Logging in to the web console</a>.
					</p></li><li class="listitem">
						In the <span class="strong strong"><strong>Overview</strong></span> page, click <span class="strong strong"><strong>View metrics and history</strong></span> in the <span class="strong strong"><strong>Usage</strong></span> table.
					</li><li class="listitem">
						Click the <span class="guibutton">Metrics settings</span> button.
					</li><li class="listitem"><p class="simpara">
						Move the <span class="strong strong"><strong>Export to network</strong></span> slider to active position.
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/55761d5cf5f7a430b868dc184530bffa/cockpit-export-to-network-slider.png" alt="Metrics settings"></span>

					</p><p class="simpara">
						If you do not have the <code class="literal">redis</code> package installed, the web console prompts you to install it.
					</p></li><li class="listitem">
						To open the <code class="literal">pmproxy</code> service, select a zone from a drop-down list and click the <span class="guibutton">Add pmproxy</span> button.
					</li><li class="listitem">
						Click <span class="strong strong"><strong>Save</strong></span>.
					</li></ol></div><div class="orderedlist"><p class="title"><strong>Verification</strong></p><ol class="orderedlist" type="1"><li class="listitem">
						Click <span class="strong strong"><strong>Networking</strong></span>.
					</li><li class="listitem">
						In the <span class="strong strong"><strong>Firewall</strong></span> table, click the <span class="guibutton">Edit rules and zones</span> button.
					</li><li class="listitem">
						Search for <code class="literal">pmproxy</code> in your selected zone.
					</li></ol></div><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
					Repeat this procedure on all the systems you want to watch.
				</p></div></rh-alert><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance#setting-up-pcp-with-pcp-zeroconf_setting-up-graphical-representation-of-pcp-metrics">Setting up graphical representation of PCP metrics</a>
					</li></ul></div></section></section><section class="chapter" id="setting-the-disk-scheduler_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 11. Setting the disk scheduler</h2></div></div></div><p class="_abstract _abstract">
			The disk scheduler is responsible for ordering the I/O requests submitted to a storage device.
		</p><p>
			You can configure the scheduler in several different ways:
		</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
					Set the scheduler using <span class="strong strong"><strong>TuneD</strong></span>, as described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-the-disk-scheduler_monitoring-and-managing-system-status-and-performance#setting-the-disk-scheduler-using-tuned_setting-the-disk-scheduler">Setting the disk scheduler using TuneD</a>
				</li><li class="listitem">
					Set the scheduler using <code class="literal">udev</code>, as described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-the-disk-scheduler_monitoring-and-managing-system-status-and-performance#setting-the-disk-scheduler-using-udev-rules_setting-the-disk-scheduler">Setting the disk scheduler using udev rules</a>
				</li><li class="listitem">
					Temporarily change the scheduler on a running system, as described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-the-disk-scheduler_monitoring-and-managing-system-status-and-performance#temporarily-setting-a-scheduler-for-a-specific-disk_setting-the-disk-scheduler">Temporarily setting a scheduler for a specific disk</a>
				</li></ul></div><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
				In Red Hat Enterprise Linux 9, block devices support only multi-queue scheduling. This enables the block layer performance to scale well with fast solid-state drives (SSDs) and multi-core systems.
			</p><p>
				The traditional, single-queue schedulers, which were available in Red Hat Enterprise Linux 7 and earlier versions, have been removed.
			</p></div></rh-alert><section class="section" id="available-disk-schedulers_setting-the-disk-scheduler"><div class="titlepage"><div><div><h3 class="title">11.1. Available disk schedulers</h3></div></div></div><p class="_abstract _abstract">
				The following multi-queue disk schedulers are supported in Red Hat Enterprise Linux 9:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">none</code></span></dt><dd>
							Implements a first-in first-out (FIFO) scheduling algorithm. It merges requests at the generic block layer through a simple last-hit cache.
						</dd><dt><span class="term"><code class="literal">mq-deadline</code></span></dt><dd><p class="simpara">
							Attempts to provide a guaranteed latency for requests from the point at which requests reach the scheduler.
						</p><p class="simpara">
							The <code class="literal">mq-deadline</code> scheduler sorts queued I/O requests into a read or write batch and then schedules them for execution in increasing logical block addressing (LBA) order. By default, read batches take precedence over write batches, because applications are more likely to block on read I/O operations. After <code class="literal">mq-deadline</code> processes a batch, it checks how long write operations have been starved of processor time and schedules the next read or write batch as appropriate.
						</p><p class="simpara">
							This scheduler is suitable for most use cases, but particularly those in which the write operations are mostly asynchronous.
						</p></dd><dt><span class="term"><code class="literal">bfq</code></span></dt><dd><p class="simpara">
							Targets desktop systems and interactive tasks.
						</p><p class="simpara">
							The <code class="literal">bfq</code> scheduler ensures that a single application is never using all of the bandwidth. In effect, the storage device is always as responsive as if it was idle. In its default configuration, <code class="literal">bfq</code> focuses on delivering the lowest latency rather than achieving the maximum throughput.
						</p><p class="simpara">
							<code class="literal">bfq</code> is based on <code class="literal">cfq</code> code. It does not grant the disk to each process for a fixed time slice but assigns a <span class="emphasis"><em>budget</em></span> measured in number of sectors to the process.
						</p><p class="simpara">
							This scheduler is suitable while copying large files and the system does not become unresponsive in this case.
						</p></dd><dt><span class="term"><code class="literal">kyber</code></span></dt><dd><p class="simpara">
							The scheduler tunes itself to achieve a latency goal by calculating the latencies of every I/O request submitted to the block I/O layer. You can configure the target latencies for read, in the case of cache-misses, and synchronous write requests.
						</p><p class="simpara">
							This scheduler is suitable for fast devices, for example NVMe, SSD, or other low latency devices.
						</p></dd></dl></div></section><section class="section" id="different-disk-schedulers-for-different-use-cases_setting-the-disk-scheduler"><div class="titlepage"><div><div><h3 class="title">11.2. Different disk schedulers for different use cases</h3></div></div></div><p class="_abstract _abstract">
				Depending on the task that your system performs, the following disk schedulers are recommended as a baseline prior to any analysis and tuning tasks:
			</p><rh-table id="idm140280143512464"><table class="lt-4-cols lt-7-rows"><caption>Table 11.1. Disk schedulers for different use cases</caption><colgroup><col style="width: 50%; " class="col_1"><!--Empty--><col style="width: 50%; " class="col_2"><!--Empty--></colgroup><thead><tr><th align="left" valign="top" id="idm140280150191504" scope="col">Use case</th><th align="left" valign="top" id="idm140280150190416" scope="col">Disk scheduler</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm140280150191504"> <p>
								Traditional HDD with a SCSI interface
							</p>
							 </td><td align="left" valign="top" headers="idm140280150190416"> <p>
								Use <code class="literal">mq-deadline</code> or <code class="literal">bfq</code>.
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm140280150191504"> <p>
								High-performance SSD or a CPU-bound system with fast storage
							</p>
							 </td><td align="left" valign="top" headers="idm140280150190416"> <p>
								Use <code class="literal">none</code>, especially when running enterprise applications. Alternatively, use <code class="literal">kyber</code>.
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm140280150191504"> <p>
								Desktop or interactive tasks
							</p>
							 </td><td align="left" valign="top" headers="idm140280150190416"> <p>
								Use <code class="literal">bfq</code>.
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm140280150191504"> <p>
								Virtual guest
							</p>
							 </td><td align="left" valign="top" headers="idm140280150190416"> <p>
								Use <code class="literal">mq-deadline</code>. With a host bus adapter (HBA) driver that is multi-queue capable, use <code class="literal">none</code>.
							</p>
							 </td></tr></tbody></table></rh-table></section><section class="section" id="the-default-disk-scheduler_setting-the-disk-scheduler"><div class="titlepage"><div><div><h3 class="title">11.3. The default disk scheduler</h3></div></div></div><p class="_abstract _abstract">
				Block devices use the default disk scheduler unless you specify another scheduler.
			</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					For <code class="literal">non-volatile Memory Express (NVMe)</code> block devices specifically, the default scheduler is <code class="literal">none</code> and Red Hat recommends not changing this.
				</p></div></rh-alert><p>
				The kernel selects a default disk scheduler based on the type of device. The automatically selected scheduler is typically the optimal setting. If you require a different scheduler, Red Hat recommends to use <code class="literal">udev</code> rules or the <span class="strong strong"><strong>TuneD</strong></span> application to configure it. Match the selected devices and switch the scheduler only for those devices.
			</p></section><section class="section" id="determining-the-active-disk-scheduler_setting-the-disk-scheduler"><div class="titlepage"><div><div><h3 class="title">11.4. Determining the active disk scheduler</h3></div></div></div><p class="_abstract _abstract">
				This procedure determines which disk scheduler is currently active on a given block device.
			</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Read the content of the <code class="literal">/sys/block/<span class="emphasis"><em>device</em></span>/queue/scheduler</code> file:
					</p><pre class="screen"># cat /sys/block/<span class="emphasis"><em>device</em></span>/queue/scheduler

[mq-deadline] kyber bfq none</pre><p class="simpara">
						In the file name, replace <span class="emphasis"><em>device</em></span> with the block device name, for example <code class="literal">sdc</code>.
					</p><p class="simpara">
						The active scheduler is listed in square brackets (<code class="literal">[ ]</code>).
					</p></li></ul></div></section><section class="section" id="setting-the-disk-scheduler-using-tuned_setting-the-disk-scheduler"><div class="titlepage"><div><div><h3 class="title">11.5. Setting the disk scheduler using TuneD</h3></div></div></div><p class="_abstract _abstract">
				This procedure creates and enables a <span class="strong strong"><strong>TuneD</strong></span> profile that sets a given disk scheduler for selected block devices. The setting persists across system reboots.
			</p><p>
				In the following commands and configuration, replace:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						<span class="emphasis"><em>device</em></span> with the name of the block device, for example <code class="literal">sdf</code>
					</li><li class="listitem">
						<span class="emphasis"><em>selected-scheduler</em></span> with the disk scheduler that you want to set for the device, for example <code class="literal">bfq</code>
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						The <code class="literal">TuneD</code> service is installed and enabled. For details, see <a class="link" href="#installing-and-enabling-tuned_getting-started-with-tuned" title="1.13. Installing and enabling TuneD">Installing and enabling TuneD</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Optional: Select an existing <span class="strong strong"><strong>TuneD</strong></span> profile on which your profile will be based. For a list of available profiles, see <a class="link" href="#tuned-profiles-distributed-with-rhel_getting-started-with-tuned" title="1.6. TuneD profiles distributed with RHEL">TuneD profiles distributed with RHEL</a>.
					</p><p class="simpara">
						To see which profile is currently active, use:
					</p><pre class="screen">$ tuned-adm active</pre></li><li class="listitem"><p class="simpara">
						Create a new directory to hold your <span class="strong strong"><strong>TuneD</strong></span> profile:
					</p><pre class="screen"># mkdir /etc/tuned/<span class="emphasis"><em>my-profile</em></span></pre></li><li class="listitem"><p class="simpara">
						Find the system unique identifier of the selected block device:
					</p><pre class="screen">$ udevadm info --query=property --name=/dev/<span class="emphasis"><em>device</em></span> | grep -E '(WWN|SERIAL)'

ID_WWN=<span class="emphasis"><em>0x5002538d00000000_</em></span>
ID_SERIAL=<span class="emphasis"><em>Generic-_SD_MMC_20120501030900000-0:0</em></span>
ID_SERIAL_SHORT=<span class="emphasis"><em>20120501030900000</em></span></pre><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
							The command in the this example will return all values identified as a World Wide Name (WWN) or serial number associated with the specified block device. Although it is preferred to use a WWN, the WWN is not always available for a given device and any values returned by the example command are acceptable to use as the <span class="emphasis"><em>device system unique ID</em></span>.
						</p></div></rh-alert></li><li class="listitem"><p class="simpara">
						Create the <code class="literal">/etc/tuned/<span class="emphasis"><em>my-profile</em></span>/tuned.conf</code> configuration file. In the file, set the following options:
					</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
								Optional: Include an existing profile:
							</p><pre class="screen">[main]
include=<span class="emphasis"><em>existing-profile</em></span></pre></li><li class="listitem"><p class="simpara">
								Set the selected disk scheduler for the device that matches the WWN identifier:
							</p><pre class="screen">[disk]
devices_udev_regex=<span class="emphasis"><em>IDNAME</em></span>=<span class="emphasis"><em>device system unique id</em></span>
elevator=<span class="emphasis"><em>selected-scheduler</em></span></pre><p class="simpara">
								Here:
							</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
										Replace <span class="emphasis"><em>IDNAME</em></span> with the name of the identifier being used (for example, <code class="literal">ID_WWN</code>).
									</li><li class="listitem"><p class="simpara">
										Replace <span class="emphasis"><em>device system unique id</em></span> with the value of the chosen identifier (for example, <code class="literal">0x5002538d00000000</code>).
									</p><p class="simpara">
										To match multiple devices in the <code class="literal">devices_udev_regex</code> option, enclose the identifiers in parentheses and separate them with vertical bars:
									</p><pre class="screen">devices_udev_regex=(ID_WWN=<span class="emphasis"><em>0x5002538d00000000</em></span>)|(ID_WWN=<span class="emphasis"><em>0x1234567800000000</em></span>)</pre></li></ul></div></li></ol></div></li><li class="listitem"><p class="simpara">
						Enable your profile:
					</p><pre class="screen"># tuned-adm profile <span class="emphasis"><em>my-profile</em></span></pre></li></ol></div><div class="orderedlist"><p class="title"><strong>Verification</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Verify that the TuneD profile is active and applied:
					</p><pre class="screen">$ tuned-adm active

Current active profile: <span class="emphasis"><em>my-profile</em></span></pre><pre class="screen">$ tuned-adm verify

Verification succeeded, current system settings match the preset profile.
See TuneD log file ('/var/log/tuned/tuned.log') for details.</pre></li><li class="listitem"><p class="simpara">
						Read the contents of the <code class="literal">/sys/block/<span class="emphasis"><em>device</em></span>/queue/scheduler</code> file:
					</p><pre class="screen"># cat /sys/block/<span class="emphasis"><em>device</em></span>/queue/scheduler

[mq-deadline] kyber bfq none</pre><p class="simpara">
						In the file name, replace <span class="emphasis"><em>device</em></span> with the block device name, for example <code class="literal">sdc</code>.
					</p><p class="simpara">
						The active scheduler is listed in square brackets (<code class="literal">[]</code>).
					</p></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="#customizing-tuned-profiles_monitoring-and-managing-system-status-and-performance" title="Chapter 2. Customizing TuneD profiles">Customizing TuneD profiles</a>.
					</li></ul></div></section><section class="section" id="setting-the-disk-scheduler-using-udev-rules_setting-the-disk-scheduler"><div class="titlepage"><div><div><h3 class="title">11.6. Setting the disk scheduler using udev rules</h3></div></div></div><p class="_abstract _abstract">
				This procedure sets a given disk scheduler for specific block devices using <code class="literal">udev</code> rules. The setting persists across system reboots.
			</p><p>
				In the following commands and configuration, replace:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						<span class="emphasis"><em>device</em></span> with the name of the block device, for example <code class="literal">sdf</code>
					</li><li class="listitem">
						<span class="emphasis"><em>selected-scheduler</em></span> with the disk scheduler that you want to set for the device, for example <code class="literal">bfq</code>
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Find the system unique identifier of the block device:
					</p><pre class="screen">$ udevadm info --name=/dev/<span class="emphasis"><em>device</em></span> | grep -E '(WWN|SERIAL)'
E: ID_WWN=<span class="emphasis"><em>0x5002538d00000000</em></span>
E: ID_SERIAL=<span class="emphasis"><em>Generic-_SD_MMC_20120501030900000-0:0</em></span>
E: ID_SERIAL_SHORT=<span class="emphasis"><em>20120501030900000</em></span></pre><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
							The command in the this example will return all values identified as a World Wide Name (WWN) or serial number associated with the specified block device. Although it is preferred to use a WWN, the WWN is not always available for a given device and any values returned by the example command are acceptable to use as the <span class="emphasis"><em>device system unique ID</em></span>.
						</p></div></rh-alert></li><li class="listitem"><p class="simpara">
						Configure the <code class="literal">udev</code> rule. Create the <code class="literal">/etc/udev/rules.d/99-scheduler.rules</code> file with the following content:
					</p><pre class="screen">ACTION=="add|change", SUBSYSTEM=="block", ENV{<span class="emphasis"><em>IDNAME</em></span>}=="<span class="emphasis"><em>device system unique id</em></span>", ATTR{queue/scheduler}="<span class="emphasis"><em>selected-scheduler</em></span>"</pre><p class="simpara">
						Here:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								Replace <span class="emphasis"><em>IDNAME</em></span> with the name of the identifier being used (for example, <code class="literal">ID_WWN</code>).
							</li><li class="listitem">
								Replace <span class="emphasis"><em>device system unique id</em></span> with the value of the chosen identifier (for example, <code class="literal">0x5002538d00000000</code>).
							</li></ul></div></li><li class="listitem"><p class="simpara">
						Reload <code class="literal">udev</code> rules:
					</p><pre class="screen"># udevadm control --reload-rules</pre></li><li class="listitem"><p class="simpara">
						Apply the scheduler configuration:
					</p><pre class="screen"># udevadm trigger --type=devices --action=change</pre></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Verify the active scheduler:
					</p><pre class="screen"># cat /sys/block/<span class="emphasis"><em>device</em></span>/queue/scheduler</pre></li></ul></div></section><section class="section" id="temporarily-setting-a-scheduler-for-a-specific-disk_setting-the-disk-scheduler"><div class="titlepage"><div><div><h3 class="title">11.7. Temporarily setting a scheduler for a specific disk</h3></div></div></div><p class="_abstract _abstract">
				This procedure sets a given disk scheduler for specific block devices. The setting does not persist across system reboots.
			</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Write the name of the selected scheduler to the <code class="literal">/sys/block/<span class="emphasis"><em>device</em></span>/queue/scheduler</code> file:
					</p><pre class="screen"># echo <span class="emphasis"><em>selected-scheduler</em></span> &gt; /sys/block/<span class="emphasis"><em>device</em></span>/queue/scheduler</pre><p class="simpara">
						In the file name, replace <span class="emphasis"><em>device</em></span> with the block device name, for example <code class="literal">sdc</code>.
					</p></li></ul></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Verify that the scheduler is active on the device:
					</p><pre class="screen"># cat /sys/block/<span class="emphasis"><em>device</em></span>/queue/scheduler</pre></li></ul></div></section></section><section class="chapter" id="assembly_tuning-the-performance-of-a-samba-server_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 12. Tuning the performance of a Samba server</h2></div></div></div><p class="_abstract _abstract">
			Learn what settings can improve the performance of Samba in certain situations, and which settings can have a negative performance impact.
		</p><p>
			Parts of this section were adopted from the <a class="link" href="https://wiki.samba.org/index.php/Performance_Tuning">Performance Tuning</a> documentation published in the Samba Wiki. License: <a class="link" href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>. Authors and contributors: See the <a class="link" href="https://wiki.samba.org/index.php?title=Performance_Tuning&amp;action=history">history</a> tab on the Wiki page.
		</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
					Samba is set up as a file or print server
				</li></ul></div><section class="section" id="proc_setting-the-smb-protocol-version_assembly_tuning-the-performance-of-a-samba-server"><div class="titlepage"><div><div><h3 class="title">12.1. Setting the SMB protocol version</h3></div></div></div><p class="_abstract _abstract">
				Each new SMB version adds features and improves the performance of the protocol. The recent Windows and Windows Server operating systems always supports the latest protocol version. If Samba also uses the latest protocol version, Windows clients connecting to Samba benefit from the performance improvements. In Samba, the default value of the server max protocol is set to the latest supported stable SMB protocol version.
			</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					To always have the latest stable SMB protocol version enabled, do not set the <code class="literal">server max protocol</code> parameter. If you set the parameter manually, you will need to modify the setting with each new version of the SMB protocol, to have the latest protocol version enabled.
				</p></div></rh-alert><p>
				The following procedure explains how to use the default value in the <code class="literal">server max protocol</code> parameter.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem">
						Remove the <code class="literal">server max protocol</code> parameter from the <code class="literal">[global]</code> section in the <code class="literal filename">/etc/samba/smb.conf</code> file.
					</li><li class="listitem"><p class="simpara">
						Reload the Samba configuration
					</p><pre class="literallayout"># <span class="strong strong"><strong>smbcontrol all reload-config</strong></span></pre></li></ol></div></section><section class="section" id="proc_tuning-shares-with-directories-that-contain-a-large-number-of-files_assembly_tuning-the-performance-of-a-samba-server"><div class="titlepage"><div><div><h3 class="title">12.2. Tuning shares with directories that contain a large number of files</h3></div></div></div><p class="_abstract _abstract">
				Linux supports case-sensitive file names. For this reason, Samba needs to scan directories for uppercase and lowercase file names when searching or accessing a file. You can configure a share to create new files only in lowercase or uppercase, which improves the performance.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						Samba is configured as a file server
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Rename all files on the share to lowercase.
					</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
							Using the settings in this procedure, files with names other than in lowercase will no longer be displayed.
						</p></div></rh-alert></li><li class="listitem"><p class="simpara">
						Set the following parameters in the share’s section:
					</p><pre class="literallayout">case sensitive = true
default case = lower
preserve case = no
short preserve case = no</pre><p class="simpara">
						For details about the parameters, see their descriptions in the <code class="literal">smb.conf(5)</code> man page on your system.
					</p></li><li class="listitem"><p class="simpara">
						Verify the <code class="literal filename">/etc/samba/smb.conf</code> file:
					</p><pre class="literallayout"># <span class="strong strong"><strong>testparm</strong></span></pre></li><li class="listitem"><p class="simpara">
						Reload the Samba configuration:
					</p><pre class="literallayout"># <span class="strong strong"><strong>smbcontrol all reload-config</strong></span></pre></li></ol></div><p>
				After you applied these settings, the names of all newly created files on this share use lowercase. Because of these settings, Samba no longer needs to scan the directory for uppercase and lowercase, which improves the performance.
			</p></section><section class="section" id="con_settings-that-can-have-a-negative-performance-impact_assembly_tuning-the-performance-of-a-samba-server"><div class="titlepage"><div><div><h3 class="title">12.3. Settings that can have a negative performance impact</h3></div></div></div><p class="_abstract _abstract">
				By default, the kernel in Red Hat Enterprise Linux is tuned for high network performance. For example, the kernel uses an auto-tuning mechanism for buffer sizes. Setting the <code class="literal">socket options</code> parameter in the <code class="literal filename">/etc/samba/smb.conf</code> file overrides these kernel settings. As a result, setting this parameter decreases the Samba network performance in most cases.
			</p><p>
				To use the optimized settings from the Kernel, remove the <code class="literal">socket options</code> parameter from the <code class="literal">[global]</code> section in the <code class="literal filename">/etc/samba/smb.conf</code>.
			</p></section></section><section class="chapter" id="optimizing-virtual-machine-performance-in-rhel_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 13. Optimizing virtual machine performance</h2></div></div></div><p>
			Virtual machines (VMs) always experience some degree of performance deterioration in comparison to the host. The following sections explain the reasons for this deterioration and provide instructions on how to minimize the performance impact of virtualization in RHEL 9, so that your hardware infrastructure resources can be used as efficiently as possible.
		</p><section class="section" id="what-influences-virtual-machine-performance_optimizing-virtual-machine-performance-in-rhel"><div class="titlepage"><div><div><h3 class="title">13.1. What influences virtual machine performance</h3></div></div></div><p>
				VMs are run as user-space processes on the host. The hypervisor therefore needs to convert the host’s system resources so that the VMs can use them. As a consequence, a portion of the resources is consumed by the conversion, and the VM therefore cannot achieve the same performance efficiency as the host.
			</p><h5 id="the_impact_of_virtualization_on_system_performance">The impact of virtualization on system performance</h5><p>
				More specific reasons for VM performance loss include:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Virtual CPUs (vCPUs) are implemented as threads on the host, handled by the Linux scheduler.
					</li><li class="listitem">
						VMs do not automatically inherit optimization features, such as NUMA or huge pages, from the host kernel.
					</li><li class="listitem">
						Disk and network I/O settings of the host might have a significant performance impact on the VM.
					</li><li class="listitem">
						Network traffic typically travels to a VM through a software-based bridge.
					</li><li class="listitem">
						Depending on the host devices and their models, there might be significant overhead due to emulation of particular hardware.
					</li></ul></div><p>
				The severity of the virtualization impact on the VM performance is influenced by a variety factors, which include:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						The number of concurrently running VMs.
					</li><li class="listitem">
						The amount of virtual devices used by each VM.
					</li><li class="listitem">
						The device types used by the VMs.
					</li></ul></div><h5 id="reducing_vm_performance_loss">Reducing VM performance loss</h5><p>
				RHEL 9 provides a number of features you can use to reduce the negative performance effects of virtualization. Notably:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						<a class="link" href="#optimizing-virtual-machine-performance-using-tuned_optimizing-virtual-machine-performance-in-rhel" title="13.2. Optimizing virtual machine performance by using TuneD">The <code class="literal">TuneD</code> service</a> can automatically optimize the resource distribution and performance of your VMs.
					</li><li class="listitem">
						<a class="link" href="#optimizing-virtual-machine-i-o-performance_optimizing-virtual-machine-performance-in-rhel" title="13.5. Optimizing virtual machine I/O performance">Block I/O tuning</a> can improve the performances of the VM’s block devices, such as disks.
					</li><li class="listitem">
						<a class="link" href="#optimizing-virtual-machine-cpu-performance_optimizing-virtual-machine-performance-in-rhel" title="13.6. Optimizing virtual machine CPU performance">NUMA tuning</a> can increase vCPU performance.
					</li><li class="listitem">
						<a class="link" href="#optimizing-virtual-machine-network-performance_optimizing-virtual-machine-performance-in-rhel" title="13.7. Optimizing virtual machine network performance">Virtual networking</a> can be optimized in various ways.
					</li></ul></div><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
					Tuning VM performance can have negative effects on other virtualization functions. For example, it can make migrating the modified VM more difficult.
				</p></div></rh-alert></section><section class="section" id="optimizing-virtual-machine-performance-using-tuned_optimizing-virtual-machine-performance-in-rhel"><div class="titlepage"><div><div><h3 class="title">13.2. Optimizing virtual machine performance by using TuneD</h3></div></div></div><p>
				The <code class="literal">TuneD</code> utility is a tuning profile delivery mechanism that adapts RHEL for certain workload characteristics, such as requirements for CPU-intensive tasks or storage-network throughput responsiveness. It provides a number of tuning profiles that are pre-configured to enhance performance and reduce power consumption in a number of specific use cases. You can edit these profiles or create new profiles to create performance solutions tailored to your environment, including virtualized environments.
			</p><p>
				To optimize RHEL 9 for virtualization, use the following profiles:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						For RHEL 9 virtual machines, use the <span class="strong strong"><strong>virtual-guest</strong></span> profile. It is based on the generally applicable <code class="literal"><span class="emphasis"><em>throughput-performance</em></span></code> profile, but also decreases the swappiness of virtual memory.
					</li><li class="listitem">
						For RHEL 9 virtualization hosts, use the <span class="strong strong"><strong>virtual-host</strong></span> profile. This enables more aggressive writeback of dirty memory pages, which benefits the host performance.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						The <code class="literal">TuneD</code> service is <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-tuned_monitoring-and-managing-system-status-and-performance#installing-and-enabling-tuned_getting-started-with-tuned">installed and enabled</a>.
					</li></ul></div><div class="formalpara"><p class="title"><strong>Procedure</strong></p><p>
					To enable a specific <code class="literal">TuneD</code> profile:
				</p></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						List the available <code class="literal">TuneD</code> profiles.
					</p><pre class="screen"># <span class="strong strong"><strong>tuned-adm list</strong></span>

Available profiles:
- balanced             - General non-specialized TuneD profile
- desktop              - Optimize for the desktop use-case
[...]
- virtual-guest        - Optimize for running inside a virtual guest
- virtual-host         - Optimize for running KVM guests
Current active profile: <span class="emphasis"><em>balanced</em></span></pre></li><li class="listitem"><p class="simpara">
						Optional: Create a new <code class="literal">TuneD</code> profile or edit an existing <code class="literal">TuneD</code> profile.
					</p><p class="simpara">
						For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/customizing-tuned-profiles_monitoring-and-managing-system-status-and-performance">Customizing TuneD profiles</a>.
					</p></li><li class="listitem"><p class="simpara">
						Activate a <code class="literal">TuneD</code> profile.
					</p><pre class="screen"># <span class="strong strong"><strong>tuned-adm profile <span class="emphasis"><em>selected-profile</em></span></strong></span></pre><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								To optimize a virtualization host, use the <span class="emphasis"><em>virtual-host</em></span> profile.
							</p><pre class="screen"># <span class="strong strong"><strong>tuned-adm profile virtual-host</strong></span></pre></li><li class="listitem"><p class="simpara">
								On a RHEL guest operating system, use the <span class="emphasis"><em>virtual-guest</em></span> profile.
							</p><pre class="screen"># <span class="strong strong"><strong>tuned-adm profile virtual-guest</strong></span></pre></li></ul></div></li></ol></div><div class="orderedlist"><p class="title"><strong>Verification</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Display the active profile for <code class="literal">TuneD</code>.
					</p><pre class="screen"># <span class="strong strong"><strong>tuned-adm active</strong></span>
Current active profile: virtual-host</pre></li><li class="listitem"><p class="simpara">
						Ensure that the <code class="literal">TuneD</code> profile settings have been applied on your system.
					</p><pre class="screen"># <span class="strong strong"><strong>tuned-adm verify</strong></span>
Verification succeeded, current system settings match the preset profile. See tuned log file ('/var/log/tuned/tuned.log') for details.</pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/">Monitoring and managing system status and performance</a>
					</li></ul></div></section><section class="section" id="assembly_optimizing-libvirt-daemons_optimizing-virtual-machine-performance-in-rhel"><div class="titlepage"><div><div><h3 class="title">13.3. Optimizing libvirt daemons</h3></div></div></div><p>
				The <code class="literal">libvirt</code> virtualization suite works as a management layer for the RHEL hypervisor, and your <code class="literal">libvirt</code> configuration significantly impacts your virtualization host. Notably, RHEL 9 contains two different types of <code class="literal">libvirt</code> daemons, monolithic or modular, and which type of daemons you use affects how granularly you can configure individual virtualization drivers.
			</p><section class="section" id="con_types-of-libvirt-daemons_assembly_optimizing-libvirt-daemons"><div class="titlepage"><div><div><h4 class="title">13.3.1. Types of libvirt daemons</h4></div></div></div><p>
					RHEL 9 supports the following <code class="literal">libvirt</code> daemon types:
				</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">Monolithic libvirt</span></dt><dd><p class="simpara">
								The traditional <code class="literal">libvirt</code> daemon, <code class="literal">libvirtd</code>, controls a wide variety of virtualization drivers, by using a single configuration file - <code class="literal">/etc/libvirt/libvirtd.conf</code>.
							</p><p class="simpara">
								As such, <code class="literal">libvirtd</code> allows for centralized hypervisor configuration, but may use system resources inefficiently. Therefore, <code class="literal">libvirtd</code> will become unsupported in a future major release of RHEL.
							</p><p class="simpara">
								However, if you updated to RHEL 9 from RHEL 8, your host still uses <code class="literal">libvirtd</code> by default.
							</p></dd><dt><span class="term">Modular libvirt</span></dt><dd><p class="simpara">
								Newly introduced in RHEL 9, modular <code class="literal">libvirt</code> provides a specific daemon for each virtualization driver. These include the following:
							</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
										<span class="strong strong"><strong>virtqemud</strong></span> - A primary daemon for hypervisor management
									</li><li class="listitem">
										<span class="strong strong"><strong>virtinterfaced</strong></span> - A secondary daemon for host NIC management
									</li><li class="listitem">
										<span class="strong strong"><strong>virtnetworkd</strong></span> - A secondary daemon for virtual network management
									</li><li class="listitem">
										<span class="strong strong"><strong>virtnodedevd</strong></span> - A secondary daemon for host physical device management
									</li><li class="listitem">
										<span class="strong strong"><strong>virtnwfilterd</strong></span> - A secondary daemon for host firewall management
									</li><li class="listitem">
										<span class="strong strong"><strong>virtsecretd</strong></span> - A secondary daemon for host secret management
									</li><li class="listitem">
										<span class="strong strong"><strong>virtstoraged</strong></span> - A secondary daemon for storage management
									</li></ul></div><p class="simpara">
								Each of the daemons has a separate configuration file - for example <code class="literal">/etc/libvirt/virtqemud.conf</code>. As such, modular <code class="literal">libvirt</code> daemons provide better options for fine-tuning <code class="literal">libvirt</code> resource management.
							</p><p class="simpara">
								If you performed a fresh install of RHEL 9, modular <code class="literal">libvirt</code> is configured by default.
							</p></dd></dl></div><div class="itemizedlist"><p class="title"><strong>Next steps</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							If your RHEL 9 uses <code class="literal">libvirtd</code>, Red Hat recommends switching to modular daemons. For instructions, see <a class="link" href="#proc_enabling-modular-libvirt-daemons_assembly_optimizing-libvirt-daemons" title="13.3.2. Enabling modular libvirt daemons">Enabling modular libvirt daemons</a>.
						</li></ul></div></section><section class="section" id="proc_enabling-modular-libvirt-daemons_assembly_optimizing-libvirt-daemons"><div class="titlepage"><div><div><h4 class="title">13.3.2. Enabling modular libvirt daemons</h4></div></div></div><p>
					In RHEL 9, the <code class="literal">libvirt</code> library uses modular daemons that handle individual virtualization driver sets on your host. For example, the <code class="literal">virtqemud</code> daemon handles QEMU drivers.
				</p><p>
					If you performed a fresh install of a RHEL 9 host, your hypervisor uses modular <code class="literal">libvirt</code> daemons by default. However, if you upgraded your host from RHEL 8 to RHEL 9, your hypervisor uses the monolithic <code class="literal">libvirtd</code> daemon, which is the default in RHEL 8.
				</p><p>
					If that is the case, Red Hat recommends enabling the modular <code class="literal">libvirt</code> daemons instead, because they provide better options for fine-tuning <code class="literal">libvirt</code> resource management. In addition, <code class="literal">libvirtd</code> will become unsupported in a future major release of RHEL.
				</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							Your hypervisor is using the monolithic <code class="literal">libvirtd</code> service.
						</p><pre class="screen"># <span class="strong strong"><strong>systemctl is-active libvirtd.service</strong></span>
active</pre><p class="simpara">
							If this command displays <code class="literal">active</code>, you are using <code class="literal">libvirtd</code>.
						</p></li><li class="listitem">
							Your virtual machines are shut down.
						</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Stop <code class="literal">libvirtd</code> and its sockets.
						</p><pre class="screen">$ <span class="strong strong"><strong>systemctl stop libvirtd.service</strong></span>
$ <span class="strong strong"><strong>systemctl stop libvirtd{,-ro,-admin,-tcp,-tls}.socket</strong></span></pre></li><li class="listitem"><p class="simpara">
							Disable <code class="literal">libvirtd</code> to prevent it from starting on boot.
						</p><pre class="screen">$ <span class="strong strong"><strong>systemctl disable libvirtd.service</strong></span>
$ <span class="strong strong"><strong>systemctl disable libvirtd{,-ro,-admin,-tcp,-tls}.socket</strong></span></pre></li><li class="listitem"><p class="simpara">
							Enable the modular <code class="literal">libvirt</code> daemons.
						</p><pre class="screen"># <span class="strong strong"><strong>for drv in qemu interface network nodedev nwfilter secret storage; do systemctl unmask virt${drv}d.service; systemctl unmask virt${drv}d{,-ro,-admin}.socket; systemctl enable virt${drv}d.service; systemctl enable virt${drv}d{,-ro,-admin}.socket; done</strong></span></pre></li><li class="listitem"><p class="simpara">
							Start the sockets for the modular daemons.
						</p><pre class="screen"># <span class="strong strong"><strong>for drv in qemu network nodedev nwfilter secret storage; do systemctl start virt${drv}d{,-ro,-admin}.socket; done</strong></span></pre></li><li class="listitem"><p class="simpara">
							Optional: If you require connecting to your host from remote hosts, enable and start the virtualization proxy daemon.
						</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
									Check whether the <code class="literal">libvirtd-tls.socket</code> service is enabled on your system.
								</p><pre class="screen"># <span class="strong strong"><strong>grep listen_tls /etc/libvirt/libvirtd.conf</strong></span>

listen_tls = 0</pre></li><li class="listitem"><p class="simpara">
									If <code class="literal">libvirtd-tls.socket</code> is not enabled (<code class="literal">listen_tls = 0</code>), activate <code class="literal">virtproxyd</code> as follows:
								</p><pre class="screen"># <span class="strong strong"><strong>systemctl unmask virtproxyd.service</strong></span>
# <span class="strong strong"><strong>systemctl unmask virtproxyd{,-ro,-admin}.socket</strong></span>
# <span class="strong strong"><strong>systemctl enable virtproxyd.service</strong></span>
# <span class="strong strong"><strong>systemctl enable virtproxyd{,-ro,-admin}.socket</strong></span>
# <span class="strong strong"><strong>systemctl start virtproxyd{,-ro,-admin}.socket</strong></span></pre></li><li class="listitem"><p class="simpara">
									If <code class="literal">libvirtd-tls.socket</code> is enabled (<code class="literal">listen_tls = 1</code>), activate <code class="literal">virtproxyd</code> as follows:
								</p><pre class="screen"># <span class="strong strong"><strong>systemctl unmask virtproxyd.service</strong></span>
# <span class="strong strong"><strong>systemctl unmask virtproxyd{,-ro,-admin,-tls}.socket</strong></span>
# <span class="strong strong"><strong>systemctl enable virtproxyd.service</strong></span>
# <span class="strong strong"><strong>systemctl enable virtproxyd{,-ro,-admin,-tls}.socket</strong></span>
# <span class="strong strong"><strong>systemctl start virtproxyd{,-ro,-admin,-tls}.socket</strong></span></pre><p class="simpara">
									To enable the TLS socket of <code class="literal">virtproxyd</code>, your host must have TLS certificates configured to work with <code class="literal">libvirt</code>. For more information, see the <a class="link" href="https://libvirt.org/kbase/tlscerts.html">Upstream libvirt documentation</a>.
								</p></li></ol></div></li></ol></div><div class="orderedlist"><p class="title"><strong>Verification</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Activate the enabled virtualization daemons.
						</p><pre class="screen"># <span class="strong strong"><strong>virsh uri</strong></span>
qemu:///system</pre></li><li class="listitem"><p class="simpara">
							Verify that your host is using the <code class="literal">virtqemud</code> modular daemon.
						</p><pre class="screen"># <span class="strong strong"><strong>systemctl is-active virtqemud.service</strong></span>
active</pre><p class="simpara">
							If the status is <code class="literal">active</code>, you have successfully enabled modular <code class="literal">libvirt</code> daemons.
						</p></li></ol></div></section></section><section class="section" id="configuring-virtual-machine-ram_optimizing-virtual-machine-performance-in-rhel"><div class="titlepage"><div><div><h3 class="title">13.4. Configuring virtual machine memory</h3></div></div></div><p>
				To improve the performance of a virtual machine (VM), you can assign additional host RAM to the VM. Similarly, you can decrease the amount of memory allocated to a VM so the host memory can be allocated to other VMs or tasks.
			</p><p>
				To perform these actions, you can use <a class="link" href="#adding-and-removing-virtual-machine-ram-using-the-web-console_configuring-virtual-machine-ram" title="13.4.1. Adding and removing virtual machine memory by using the web console">the web console</a> or <a class="link" href="#adding-and-removing-virtual-machine-ram-using-the-command-line-interface_configuring-virtual-machine-ram" title="13.4.2. Adding and removing virtual machine memory by using the command-line interface">the command-line interface</a>.
			</p><section class="section" id="adding-and-removing-virtual-machine-ram-using-the-web-console_configuring-virtual-machine-ram"><div class="titlepage"><div><div><h4 class="title">13.4.1. Adding and removing virtual machine memory by using the web console</h4></div></div></div><p>
					To improve the performance of a virtual machine (VM) or to free up the host resources it is using, you can use the web console to adjust amount of memory allocated to the VM.
				</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							You have installed the RHEL 9 web console.
						</p><p class="simpara">
							For instructions, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console">Installing and enabling the web console</a>.
						</p></li><li class="listitem"><p class="simpara">
							The guest OS is running the memory balloon drivers. To verify this is the case:
						</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
									Ensure the VM’s configuration includes the <code class="literal">memballoon</code> device:
								</p><pre class="screen"># <span class="strong strong"><strong>virsh dumpxml <span class="emphasis"><em>testguest</em></span> | grep memballoon</strong></span>
&lt;memballoon model='virtio'&gt;
    &lt;/memballoon&gt;</pre><p class="simpara">
									If this commands displays any output and the model is not set to <code class="literal">none</code>, the <code class="literal">memballoon</code> device is present.
								</p></li><li class="listitem"><p class="simpara">
									Ensure the balloon drivers are running in the guest OS.
								</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
											In Windows guests, the drivers are installed as a part of the <code class="literal">virtio-win</code> driver package. For instructions, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/installing-and-managing-windows-virtual-machines-on-rhel_configuring-and-managing-virtualization#installing-kvm-paravirtualized-drivers-for-rhel-virtual-machines_optimizing-windows-virtual-machines-on-rhel">Installing paravirtualized KVM drivers for Windows virtual machines</a>.
										</li><li class="listitem">
											In Linux guests, the drivers are generally included by default and activate when the <code class="literal">memballoon</code> device is present.
										</li></ul></div></li></ol></div></li><li class="listitem">
							The web console VM plug-in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/managing-virtual-machines-in-the-web-console_configuring-and-managing-virtualization">is installed on your system</a>.
						</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Optional: Obtain the information about the maximum memory and currently used memory for a VM. This will serve as a baseline for your changes, and also for verification.
						</p><pre class="screen"># <span class="strong strong"><strong>virsh dominfo <span class="emphasis"><em>testguest</em></span></strong></span>
Max memory:     2097152 KiB
Used memory:    2097152 KiB</pre></li></ol></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Log in to the RHEL 9 web console.
						</p><p class="simpara">
							For details, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#logging-in-to-the-web-console_getting-started-with-the-rhel-9-web-console">Logging in to the web console</a>.
						</p></li><li class="listitem"><p class="simpara">
							In the <span class="guimenu">Virtual Machines</span> interface, click the VM whose information you want to see.
						</p><p class="simpara">
							A new page opens with an Overview section with basic information about the selected VM and a Console section to access the VM’s graphical interface.
						</p></li><li class="listitem"><p class="simpara">
							Click <span class="guibutton">edit</span> next to the <code class="literal">Memory</code> line in the Overview pane.
						</p><p class="simpara">
							The <code class="literal">Memory Adjustment</code> dialog appears.
						</p><div class="informalfigure"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/839e2ecc24d24759503df5eeb06e6888/virt-cockpit-memory.png" width="540" alt="Image displaying the VM memory adjustment dialog box."></div></div></li><li class="listitem"><p class="simpara">
							Configure the virtual memory for the selected VM.
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									<span class="strong strong"><strong>Maximum allocation</strong></span> - Sets the maximum amount of host memory that the VM can use for its processes. You can specify the maximum memory when creating the VM or increase it later. You can specify memory as multiples of MiB or GiB.
								</p><p class="simpara">
									Adjusting maximum memory allocation is only possible on a shut-off VM.
								</p></li><li class="listitem"><p class="simpara">
									<span class="strong strong"><strong>Current allocation</strong></span> - Sets the actual amount of memory allocated to the VM. This value can be less than the Maximum allocation but cannot exceed it. You can adjust the value to regulate the memory available to the VM for its processes. You can specify memory as multiples of MiB or GiB.
								</p><p class="simpara">
									If you do not specify this value, the default allocation is the <span class="strong strong"><strong>Maximum allocation</strong></span> value.
								</p></li></ul></div></li><li class="listitem"><p class="simpara">
							Click <span class="guibutton">Save</span>.
						</p><p class="simpara">
							The memory allocation of the VM is adjusted.
						</p></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/optimizing-virtual-machine-performance-in-rhel_configuring-and-managing-virtualization#adding-and-removing-virtual-machine-ram-using-the-command-line-interface_configuring-virtual-machine-ram">Adding and removing virtual machine memory by using the command-line interface</a>
						</li><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/optimizing-virtual-machine-performance-in-rhel_configuring-and-managing-virtualization#optimizing-virtual-machine-cpu-performance_optimizing-virtual-machine-performance-in-rhel">Optimizing virtual machine CPU performance</a>
						</li></ul></div></section><section class="section" id="adding-and-removing-virtual-machine-ram-using-the-command-line-interface_configuring-virtual-machine-ram"><div class="titlepage"><div><div><h4 class="title">13.4.2. Adding and removing virtual machine memory by using the command-line interface</h4></div></div></div><p>
					To improve the performance of a virtual machine (VM) or to free up the host resources it is using, you can use the CLI to adjust amount of memory allocated to the VM.
				</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							The guest OS is running the memory balloon drivers. To verify this is the case:
						</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
									Ensure the VM’s configuration includes the <code class="literal">memballoon</code> device:
								</p><pre class="screen"># <span class="strong strong"><strong>virsh dumpxml <span class="emphasis"><em>testguest</em></span> | grep memballoon</strong></span>
&lt;memballoon model='virtio'&gt;
    &lt;/memballoon&gt;</pre><p class="simpara">
									If this commands displays any output and the model is not set to <code class="literal">none</code>, the <code class="literal">memballoon</code> device is present.
								</p></li><li class="listitem"><p class="simpara">
									Ensure the ballon drivers are running in the guest OS.
								</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
											In Windows guests, the drivers are installed as a part of the <code class="literal">virtio-win</code> driver package. For instructions, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/installing-and-managing-windows-virtual-machines-on-rhel_configuring-and-managing-virtualization#installing-kvm-paravirtualized-drivers-for-rhel-virtual-machines_optimizing-windows-virtual-machines-on-rhel">Installing paravirtualized KVM drivers for Windows virtual machines</a>.
										</li><li class="listitem">
											In Linux guests, the drivers are generally included by default and activate when the <code class="literal">memballoon</code> device is present.
										</li></ul></div></li></ol></div></li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Optional: Obtain the information about the maximum memory and currently used memory for a VM. This will serve as a baseline for your changes, and also for verification.
						</p><pre class="screen"># <span class="strong strong"><strong>virsh dominfo <span class="emphasis"><em>testguest</em></span></strong></span>
Max memory:     2097152 KiB
Used memory:    2097152 KiB</pre></li><li class="listitem"><p class="simpara">
							Adjust the maximum memory allocated to a VM. Increasing this value improves the performance potential of the VM, and reducing the value lowers the performance footprint the VM has on your host. Note that this change can only be performed on a shut-off VM, so adjusting a running VM requires a reboot to take effect.
						</p><p class="simpara">
							For example, to change the maximum memory that the <span class="emphasis"><em>testguest</em></span> VM can use to 4096 MiB:
						</p><pre class="screen"># <span class="strong strong"><strong>virt-xml <span class="emphasis"><em>testguest</em></span> --edit --memory memory=4096,currentMemory=4096</strong></span>
Domain 'testguest' defined successfully.
Changes will take effect after the domain is fully powered off.</pre><p class="simpara">
							To increase the maximum memory of a running VM, you can attach a memory device to the VM. This is also referred to as <span class="strong strong"><strong>memory hot plug</strong></span>. For details, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/managing-virtual-devices_configuring-and-managing-virtualization#attaching-devices-to-virtual-machines_assembly_managing-virtual-devices-using-the-cli">Attaching devices to virtual machines</a>.
						</p><rh-alert class="admonition warning" state="danger"><div class="admonition_header" slot="header">Warning</div><div><p>
								Removing memory devices from a running VM (also referred as a memory hot unplug) is not supported, and highly discouraged by Red Hat.
							</p></div></rh-alert></li><li class="listitem"><p class="simpara">
							Optional: You can also adjust the memory currently used by the VM, up to the maximum allocation. This regulates the memory load that the VM has on the host until the next reboot, without changing the maximum VM allocation.
						</p><pre class="screen"># <span class="strong strong"><strong>virsh setmem <span class="emphasis"><em>testguest</em></span> --current 2048</strong></span></pre></li></ol></div><div class="orderedlist"><p class="title"><strong>Verification</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Confirm that the memory used by the VM has been updated:
						</p><pre class="screen"># <span class="strong strong"><strong>virsh dominfo <span class="emphasis"><em>testguest</em></span></strong></span>
Max memory:     4194304 KiB
Used memory:    2097152 KiB</pre></li><li class="listitem"><p class="simpara">
							Optional: If you adjusted the current VM memory, you can obtain the memory balloon statistics of the VM to evaluate how effectively it regulates its memory use.
						</p><pre class="screen"> # <span class="strong strong"><strong>virsh domstats --balloon <span class="emphasis"><em>testguest</em></span></strong></span>
Domain: 'testguest'
  balloon.current=365624
  balloon.maximum=4194304
  balloon.swap_in=0
  balloon.swap_out=0
  balloon.major_fault=306
  balloon.minor_fault=156117
  balloon.unused=3834448
  balloon.available=4035008
  balloon.usable=3746340
  balloon.last-update=1587971682
  balloon.disk_caches=75444
  balloon.hugetlb_pgalloc=0
  balloon.hugetlb_pgfail=0
  balloon.rss=1005456</pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/optimizing-virtual-machine-performance-in-rhel_configuring-and-managing-virtualization#adding-and-removing-virtual-machine-ram-using-the-web-console_configuring-virtual-machine-ram">Adding and removing virtual machine memory by using the web console</a>
						</li><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/optimizing-virtual-machine-performance-in-rhel_configuring-and-managing-virtualization#optimizing-virtual-machine-cpu-performance_optimizing-virtual-machine-performance-in-rhel">Optimizing virtual machine CPU performance</a>
						</li></ul></div></section><section class="section" id="adding-and-removing-virtual-machine-memory-by-using-virtio-mem_configuring-virtual-machine-ram"><div class="titlepage"><div><div><h4 class="title">13.4.3. Adding and removing virtual machine memory by using virtio-mem</h4></div></div></div><p>
					RHEL 9 provides the <code class="literal">virtio-mem</code> paravirtualized memory device. This device makes it possible to dynamically add or remove host memory in virtual machines (VMs). For example, you can use <code class="literal">virtio-mem</code> to move memory resources between running VMs or to resize VM memory in cloud setups based on your current requirements.
				</p><section class="section" id="overview-of-virtio-mem_adding-and-removing-virtual-machine-memory-by-using-virtio-mem"><div class="titlepage"><div><div><h5 class="title">13.4.3.1. Overview of virtio-mem</h5></div></div></div><p>
						<code class="literal">virtio-mem</code> is a paravirtualized memory device that can be used to dynamically add or remove host memory in virtual machines (VMs). For example, you can use this device to move memory resources between running VMs or to resize VM memory in cloud setups based on your current requirements.
					</p><p>
						By using <code class="literal">virtio-mem</code>, you can increase the memory of a VM beyond its initial size, and shrink it back to its original size, in units that can have the size of 4 to several hundred mebibytes (MiBs). Note, however, that <code class="literal">virtio-mem</code> also relies on a specific guest operating system configuration, especially to reliably unplug memory.
					</p><div class="formalpara"><p class="title"><strong>virtio-mem feature limitations</strong></p><p>
							<code class="literal">virtio-mem</code> is currently not compatible with the following features:
						</p></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								Using memory locking for real-time applications on the host
							</li><li class="listitem">
								Using encrypted virtualization on the host
							</li><li class="listitem">
								Combining <code class="literal">virtio-mem</code> with <code class="literal">memballoon</code> inflation and deflation on the host
							</li><li class="listitem">
								Unloading or reloading the <code class="literal">virtio_mem</code> driver in a VM
							</li><li class="listitem">
								Using vhost-user devices, with the exception of <code class="literal">virtiofs</code>
							</li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
								<a class="link" href="#configuring-memory-onlining-in-virtual-machines_adding-and-removing-virtual-machine-memory-by-using-virtio-mem" title="13.4.3.2. Configuring memory onlining in virtual machines">Configuring memory onlining in virtual machines</a>
							</li><li class="listitem">
								<a class="link" href="#attaching-a-virtio-mem-device-to-virtual-machines_adding-and-removing-virtual-machine-memory-by-using-virtio-mem" title="13.4.3.3. Attaching a virtio-mem device to virtual machines">Attaching a virtio-mem device to virtual machines</a>
							</li></ul></div></section><section class="section" id="configuring-memory-onlining-in-virtual-machines_adding-and-removing-virtual-machine-memory-by-using-virtio-mem"><div class="titlepage"><div><div><h5 class="title">13.4.3.2. Configuring memory onlining in virtual machines</h5></div></div></div><p>
						Before using <code class="literal">virtio-mem</code> to attach memory to a running virtual machine (also known as memory hot-plugging), you must configure the virtual machine (VM) operating system to automatically set the hot-plugged memory to an online state. Otherwise, the guest operating system is not able to use the additional memory. You can choose from one of the following configurations for memory onlining:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								<code class="literal">online_movable</code>
							</li><li class="listitem">
								<code class="literal">online_kernel</code>
							</li><li class="listitem">
								<code class="literal">auto-movable</code>
							</li></ul></div><p>
						To learn about differences between these configurations, see: <a class="link" href="#comparison-of-memory-onlining-configurations_adding-and-removing-virtual-machine-memory-by-using-virtio-mem" title="13.4.3.4. Comparison of memory onlining configurations">Comparison of memory onlining configurations</a>
					</p><p>
						Memory onlining is configured with udev rules by default in RHEL. However, when using <code class="literal">virtio-mem</code>, it is recommended to configure memory onlining directly in the kernel.
					</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
								The host uses the Intel 64, AMD64, or ARM 64 CPU architecture.
							</li><li class="listitem">
								The host uses RHEL 9.4 or later as the operating system.
							</li><li class="listitem"><p class="simpara">
								VMs running on the host use one of the following operating system versions:
							</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem"><p class="simpara">
										RHEL 8.10
									</p><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
											Unplugging memory from a running VM is disabled by default in RHEL 8.10 VMs.
										</p></div></rh-alert></li><li class="listitem">
										RHEL 9
									</li></ul></div></li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								To set memory onlining to use the <code class="literal">online_movable</code> configuration in the VM:
							</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
										Set the <code class="literal">memhp_default_state</code> kernel command line parameter to <code class="literal">online_movable</code>:
									</p><pre class="screen"># <span class="strong strong"><strong>grubby --update-kernel=ALL --remove-args=memhp_default_state --args=memhp_default_state=online_movable</strong></span></pre></li><li class="listitem">
										Reboot the VM.
									</li></ol></div></li><li class="listitem"><p class="simpara">
								To set memory onlining to use the <code class="literal">online_kernel</code> configuration in the VM:
							</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
										Set the <code class="literal">memhp_default_state</code> kernel command line parameter to <code class="literal">online_kernel</code>:
									</p><pre class="screen"># <span class="strong strong"><strong>grubby --update-kernel=ALL --remove-args=memhp_default_state --args=memhp_default_state=online_kernel</strong></span></pre></li><li class="listitem">
										Reboot the VM.
									</li></ol></div></li><li class="listitem"><p class="simpara">
								To use the <code class="literal">auto-movable</code> memory onlining policy in the VM:
							</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
										Set the <code class="literal">memhp_default_state</code> kernel command line parameter to <code class="literal">online</code>:
									</p><pre class="screen"># <span class="strong strong"><strong>grubby --update-kernel=ALL --remove-args=memhp_default_state --args=memhp_default_state=online</strong></span></pre></li><li class="listitem"><p class="simpara">
										Set the <code class="literal">memory_hotplug.online_policy</code> kernel command line parameter to <code class="literal">auto-movable</code>:
									</p><pre class="screen"># <span class="strong strong"><strong>grubby --update-kernel=ALL --remove-args="memory_hotplug.online_policy" --args=memory_hotplug.online_policy=auto-movable</strong></span></pre></li><li class="listitem"><p class="simpara">
										Optional: To further tune the <code class="literal">auto-movable</code> onlining policy, change the <code class="literal">memory_hotplug.auto_movable_ratio</code> and <code class="literal">memory_hotplug.auto_movable_numa_aware</code> parameters:
									</p><pre class="screen"># <span class="strong strong"><strong>grubby --update-kernel=ALL --remove-args="memory_hotplug.auto_movable_ratio" --args=memory_hotplug.auto_movable_ratio=<span class="emphasis"><em>&lt;percentage&gt;</em></span></strong></span>

# <span class="strong strong"><strong>grubby --update-kernel=ALL --remove-args="memory_hotplug.memory_auto_movable_numa_aware" --args=memory_hotplug.auto_movable_numa_aware=<span class="emphasis"><em>&lt;y/n&gt;</em></span></strong></span></pre><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
												The <code class="literal">memory_hotplug.auto_movable_ratio parameter</code> sets the maximum ratio of memory only available for movable allocations compared to memory available for any allocations. The ratio is expressed in percents and the default value is: <span class="emphasis"><em>301</em></span> (%), which is a 3:1 ratio.
											</li><li class="listitem"><p class="simpara">
												The <code class="literal">memory_hotplug.auto_movable_numa_aware</code> parameter controls whether the <code class="literal">memory_hotplug.auto_movable_ratio</code> parameter applies to memory across all available NUMA nodes or only for memory within a single NUMA node. The default value is: <span class="emphasis"><em>y</em></span> (yes)
											</p><p class="simpara">
												For example, if the maximum ratio is set to 301% and the <code class="literal">memory_hotplug.auto_movable_numa_aware</code> is set to <span class="emphasis"><em>y</em></span> (yes), than the 3:1 ratio is applied even within the NUMA node with the attached <code class="literal">virtio-mem</code> device. If the parameter is set to <span class="emphasis"><em>n</em></span> (no), the maximum 3:1 ratio is applied only for all the NUMA nodes as a whole.
											</p><p class="simpara">
												Additionally, if the ratio is not exceeded, the newly hot-plugged memory will be available only for movable allocations. Otherwise, the newly hot-plugged memory will be available for both movable and unmovable allocations.
											</p></li></ul></div></li><li class="listitem">
										Reboot the VM.
									</li></ol></div></li></ul></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								To see if the <code class="literal">online_movable</code> configuration has been set correctly, check the current value of the <code class="literal">memhp_default_state</code> kernel parameter:
							</p><pre class="screen"># <span class="strong strong"><strong>cat /sys/devices/system/memory/auto_online_blocks</strong></span>

online_movable</pre></li><li class="listitem"><p class="simpara">
								To see if the <code class="literal">online_kernel</code> configuration has been set correctly, check the current value of the <code class="literal">memhp_default_state</code> kernel parameter:
							</p><pre class="screen"># <span class="strong strong"><strong>cat /sys/devices/system/memory/auto_online_blocks</strong></span>

online_kernel</pre></li><li class="listitem"><p class="simpara">
								To see if the <code class="literal">auto-movable</code> configuration has been set correctly, check the following kernel parameters:
							</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem"><p class="simpara">
										<code class="literal">memhp_default_state</code>:
									</p><pre class="screen"># <span class="strong strong"><strong>cat /sys/devices/system/memory/auto_online_blocks</strong></span>

online</pre></li><li class="listitem"><p class="simpara">
										<code class="literal">memory_hotplug.online_policy</code>:
									</p><pre class="screen"># <span class="strong strong"><strong>cat /sys/module/memory_hotplug/parameters/online_policy</strong></span>

auto-movable</pre></li><li class="listitem"><p class="simpara">
										<code class="literal">memory_hotplug.auto_movable_ratio</code>:
									</p><pre class="screen"># <span class="strong strong"><strong>cat /sys/module/memory_hotplug/parameters/auto_movable_ratio</strong></span>

301</pre></li><li class="listitem"><p class="simpara">
										<code class="literal">memory_hotplug.auto_movable_numa_aware</code>:
									</p><pre class="screen"># <span class="strong strong"><strong>cat /sys/module/memory_hotplug/parameters/auto_movable_numa_aware</strong></span>

y</pre></li></ul></div></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
								<a class="link" href="#overview-of-virtio-mem_adding-and-removing-virtual-machine-memory-by-using-virtio-mem" title="13.4.3.1. Overview of virtio-mem">Overview of virtio-mem</a>
							</li><li class="listitem">
								<a class="link" href="#attaching-a-virtio-mem-device-to-virtual-machines_adding-and-removing-virtual-machine-memory-by-using-virtio-mem" title="13.4.3.3. Attaching a virtio-mem device to virtual machines">Attaching a virtio-mem device to virtual machines</a>
							</li><li class="listitem">
								<a class="link" href="https://www.kernel.org/doc/html/latest/admin-guide/mm/memory-hotplug.html#configuring-memory-hot-un-plug">Configuring Memory Hot(Un)Plug</a>
							</li></ul></div></section><section class="section" id="attaching-a-virtio-mem-device-to-virtual-machines_adding-and-removing-virtual-machine-memory-by-using-virtio-mem"><div class="titlepage"><div><div><h5 class="title">13.4.3.3. Attaching a virtio-mem device to virtual machines</h5></div></div></div><p>
						To attach additional memory to a running virtual machine (also known as memory hot-plugging) and afterwards be able to resize the hot-plugged memory, you can use a <code class="literal">virtio-mem</code> device. Specifically, you can use libvirt XML configuration files and <code class="literal">virsh</code> commands to define and attach <code class="literal">virtio-mem</code> devices to virtual machines (VMs).
					</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
								The host uses the Intel 64, AMD64, or ARM 64 CPU architecture.
							</li><li class="listitem">
								The host uses RHEL 9.4 or later as the operating system.
							</li><li class="listitem"><p class="simpara">
								VMs running on the host use one of the following operating system versions:
							</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem"><p class="simpara">
										RHEL 8.10
									</p><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
											Unplugging memory from a running VM is disabled by default in RHEL 8.10 VMs.
										</p></div></rh-alert></li><li class="listitem">
										RHEL 9
									</li></ul></div></li><li class="listitem">
								The VM has memory onlining configured. For instructions, see: <a class="link" href="#configuring-memory-onlining-in-virtual-machines_adding-and-removing-virtual-machine-memory-by-using-virtio-mem" title="13.4.3.2. Configuring memory onlining in virtual machines">Configuring memory onlining in virtual machines</a>
							</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
								Ensure the XML configuration of the target VM includes the <code class="literal">maxMemory</code> parameter:
							</p><pre class="screen"># <span class="strong strong"><strong>virsh edit testguest1</strong></span>

&lt;domain type='kvm'&gt;
  &lt;name&gt;testguest1&lt;/name&gt;
  ...
  <span class="strong strong"><strong>&lt;maxMemory unit='GiB'&gt;128&lt;/maxMemory&gt;</strong></span>
  ...
&lt;/domain&gt;</pre><p class="simpara">
								In this example, the XML configuration of the <code class="literal">testguest1</code> VM defines a <code class="literal">maxMemory</code> parameter with a 128 gibibyte (GiB) size. The <code class="literal">maxMemory</code> size specifies the maximum memory the VM can use, which includes both initial and hot-plugged memory.
							</p></li><li class="listitem"><p class="simpara">
								Create and open an XML file to define <code class="literal">virtio-mem</code> devices on the host, for example:
							</p><pre class="screen"># <span class="strong strong"><strong>vim virtio-mem-device.xml</strong></span></pre></li><li class="listitem"><p class="simpara">
								Add XML definitions of <code class="literal">virtio-mem</code> devices to the file and save it:
							</p><pre class="programlisting language-xml">&lt;memory model='virtio-mem'&gt;
        &lt;target&gt;
                &lt;size unit='GiB'&gt;48&lt;/size&gt;
                &lt;node&gt;0&lt;/node&gt;
                &lt;block unit='MiB'&gt;2&lt;/block&gt;
                &lt;requested unit='GiB'&gt;16&lt;/requested&gt;
                &lt;current unit='GiB'&gt;16&lt;/current&gt;
        &lt;/target&gt;
        &lt;alias name='ua-virtiomem0'/&gt;
        &lt;address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x0'/&gt;
&lt;/memory&gt;
&lt;memory model='virtio-mem'&gt;
        &lt;target&gt;
                &lt;size unit='GiB'&gt;48&lt;/size&gt;
                &lt;node&gt;1&lt;/node&gt;
                &lt;block unit='MiB'&gt;2&lt;/block&gt;
                &lt;requested unit='GiB'&gt;0&lt;/requested&gt;
                &lt;current unit='GiB'&gt;0&lt;/current&gt;
        &lt;/target&gt;
        &lt;alias name='ua-virtiomem1'/&gt;
        &lt;address type='pci' domain='0x0000' bus='0x00' slot='0x04' function='0x0'/&gt;
&lt;/memory&gt;</pre><p class="simpara">
								In this example, two <code class="literal">virtio-mem</code> devices are defined with the following parameters:
							</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
										<code class="literal">size</code>: This is the maximum size of the device. In the example, it is 48 GiB. The <code class="literal">size</code> must be a multiple of the <code class="literal">block</code> size.
									</li><li class="listitem">
										<code class="literal">node</code>: This is the assigned vNUMA node for the <code class="literal">virtio-mem</code> device.
									</li><li class="listitem">
										<code class="literal">block</code>: This is the block size of the device. It must be at least the size of the Transparent Huge Page (THP), which is 2 MiB on Intel 64 and AMD64 CPU architecture. On ARM64 architecture, the size of THP can be 2 MiB or 512 MiB depending on the base page size. The 2 MiB block size on Intel 64 or AMD64 architecture is usually a good default choice. When using <code class="literal">virtio-mem</code> with <span class="emphasis"><em>Virtual Function I/O (VFIO)</em></span> or <span class="emphasis"><em>mediated devices (mdev)</em></span>, the total number of blocks across all <code class="literal">virtio-mem</code> devices must not be larger than 32768, otherwise the plugging of RAM might fail.
									</li><li class="listitem">
										<code class="literal">requested</code>: This is the amount of memory you attach to the VM with the <code class="literal">virtio-mem</code> device. However, it is just a request towards the VM and it might not be resolved successfully, for example if the VM is not properly configured. The <code class="literal">requested</code> size must be a multiple of the <code class="literal">block</code> size and cannot exceed the maximum defined <code class="literal">size</code>.
									</li><li class="listitem">
										<code class="literal">current</code>: This represents the current size the <code class="literal">virtio-mem</code> device provides to the VM. The <code class="literal">current</code> size can differ from the <code class="literal">requested</code> size, for example when requests cannot be completed or when rebooting the VM.
									</li><li class="listitem"><p class="simpara">
										<code class="literal">alias</code>: This is an optional user-defined alias that you can use to specify the intended <code class="literal">virtio-mem</code> device, for example when editing the device with libvirt commands. All user-defined aliases in libvirt must start with the <span class="emphasis"><em>"ua-"</em></span> prefix.
									</p><p class="simpara">
										Apart from these specific parameters, <code class="literal">libvirt</code> handles the <code class="literal">virtio-mem</code> device like any other PCI device.
									</p></li></ul></div></li><li class="listitem"><p class="simpara">
								Use the XML file to attach the defined <code class="literal">virtio-mem</code> devices to a VM. For example, to permanently attach the two devices defined in the <code class="literal">virtio-mem-device.xml</code> to the running <code class="literal">testguest1</code> VM:
							</p><pre class="screen"># <span class="strong strong"><strong>virsh attach-device testguest1 virtio-mem-device.xml --live --config</strong></span></pre><p class="simpara">
								The <code class="literal">--live</code> option attaches the device to a running VM only, without persistence between boots. The <code class="literal">--config</code> option makes the configuration changes persistent. You can also attach the device to a shutdown VM without the <code class="literal">--live</code> option.
							</p></li><li class="listitem"><p class="simpara">
								Optional: To dynamically change the <code class="literal">requested</code> size of a <code class="literal">virtio-mem</code> device attached to a running VM, use the <code class="literal">virsh update-memory-device</code> command:
							</p><pre class="screen"># <span class="strong strong"><strong>virsh update-memory-device testguest1 --alias ua-virtiomem0 --requested-size 4GiB</strong></span></pre><p class="simpara">
								In this example:
							</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
										<code class="literal">testguest1</code> is the VM you want to update.
									</li><li class="listitem">
										<code class="literal">--alias ua-virtiomem0</code> is the <code class="literal">virtio-mem</code> device specified by a previously defined alias.
									</li><li class="listitem"><p class="simpara">
										<code class="literal">--requested-size 4GiB</code> changes the <code class="literal">requested</code> size of the <code class="literal">virtio-mem</code> device to 4 GiB.
									</p><rh-alert class="admonition warning" state="danger"><div class="admonition_header" slot="header">Warning</div><div><p>
											Unplugging memory from a running VM by reducing the <code class="literal">requested</code> size might be unreliable. Whether this process succeeds depends on various factors, such as the memory onlining policy that is used.
										</p><p>
											In some cases, the guest operating system cannot complete the request successfully, because changing the amount of hot-plugged memory is not possible at that time.
										</p><p>
											Additionally, unplugging memory from a running VM is disabled by default in RHEL 8.10 VMs.
										</p></div></rh-alert></li></ul></div></li><li class="listitem"><p class="simpara">
								Optional: To unplug a <code class="literal">virtio-mem</code> device from a shut-down VM, use the <code class="literal">virsh detach-device</code> command:
							</p><pre class="screen"># <span class="strong strong"><strong>virsh detach-device testguest1 virtio-mem-device.xml</strong></span></pre></li><li class="listitem"><p class="simpara">
								Optional: To unplug a <code class="literal">virtio-mem</code> device from a running VM:
							</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
										Change the <code class="literal">requested</code> size of the <code class="literal">virtio-mem</code> device to 0, otherwise the attempt to unplug a <code class="literal">virtio-mem</code> device from a running VM will fail.
									</p><pre class="screen"># <span class="strong strong"><strong>virsh update-memory-device testguest1 --alias ua-virtiomem0 --requested-size 0</strong></span></pre></li><li class="listitem"><p class="simpara">
										Unplug a <code class="literal">virtio-mem</code> device from the running VM:
									</p><pre class="screen"># <span class="strong strong"><strong>virsh detach-device testguest1 virtio-mem-device.xml --config</strong></span></pre></li></ol></div></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								In the VM, check the available RAM and see if the total amount now includes the hot-plugged memory:
							</p><pre class="screen"># <span class="strong strong"><strong>free -h</strong></span>

        total    used    free   shared  buff/cache   available
Mem:    31Gi     5.5Gi   14Gi   1.3Gi   11Gi         23Gi
Swap:   8.0Gi    0B      8.0Gi</pre><pre class="screen"># <span class="strong strong"><strong>numactl -H</strong></span>

available: 1 nodes (0)
node 0 cpus: 0 1 2 3 4 5 6 7
node 0 size: 29564 MB
node 0 free: 13351 MB
node distances:
node   0
  0:  10</pre></li><li class="listitem"><p class="simpara">
								The current amount of plugged-in RAM can be also viewed on the host by displaying the XML configuration of the running VM:
							</p><pre class="screen"># <span class="strong strong"><strong>virsh dumpxml testguest1</strong></span>

&lt;domain type='kvm'&gt;
  &lt;name&gt;testguest1&lt;/name&gt;
  ...
  <span class="strong strong"><strong>&lt;currentMemory unit='GiB'&gt;31&lt;/currentMemory&gt;</strong></span>
  ...
  &lt;memory model='virtio-mem'&gt;
      &lt;target&gt;
        &lt;size unit='GiB'&gt;48&lt;/size&gt;
        &lt;node&gt;0&lt;/node&gt;
        &lt;block unit='MiB'&gt;2&lt;/block&gt;
        &lt;requested unit='GiB'&gt;16&lt;/requested&gt;
        <span class="strong strong"><strong>&lt;current unit='GiB'&gt;16&lt;/current&gt;</strong></span>
      &lt;/target&gt;
      &lt;alias name='ua-virtiomem0'/&gt;
      &lt;address type='pci' domain='0x0000' bus='0x08' slot='0x00' function='0x0'/&gt;
  ...
&lt;/domain&gt;</pre><p class="simpara">
								In this example:
							</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
										<code class="literal">&lt;currentMemory unit='GiB'&gt;31&lt;/currentMemory&gt;</code> represents the total RAM available in the VM from all sources.
									</li><li class="listitem">
										<code class="literal">&lt;current unit='GiB'&gt;16&lt;/current&gt;</code> represents the current size of the plugged-in RAM provided by the <code class="literal">virtio-mem</code> device.
									</li></ul></div></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
								<a class="link" href="#overview-of-virtio-mem_adding-and-removing-virtual-machine-memory-by-using-virtio-mem" title="13.4.3.1. Overview of virtio-mem">Overview of virtio-mem</a>
							</li><li class="listitem">
								<a class="link" href="#configuring-memory-onlining-in-virtual-machines_adding-and-removing-virtual-machine-memory-by-using-virtio-mem" title="13.4.3.2. Configuring memory onlining in virtual machines">Configuring memory onlining in virtual machines</a>
							</li></ul></div></section><section class="section" id="comparison-of-memory-onlining-configurations_adding-and-removing-virtual-machine-memory-by-using-virtio-mem"><div class="titlepage"><div><div><h5 class="title">13.4.3.4. Comparison of memory onlining configurations</h5></div></div></div><p>
						When attaching memory to a running RHEL virtual machine (also known as memory hot-plugging), you must set the hot-plugged memory to an online state in the virtual machine (VM) operating system. Otherwise, the system will not be able to use the memory.
					</p><p>
						The following table summarizes the main considerations when choosing between the available memory onlining configurations.
					</p><rh-table id="idm140280133393392"><table class="gt-4-cols lt-7-rows"><caption>Table 13.1. Comparison of memory onlining configurations</caption><colgroup><col style="width: 20%; " class="col_1"><!--Empty--><col style="width: 20%; " class="col_2"><!--Empty--><col style="width: 20%; " class="col_3"><!--Empty--><col style="width: 20%; " class="col_4"><!--Empty--><col style="width: 20%; " class="col_5"><!--Empty--></colgroup><thead><tr><th align="left" valign="top" id="idm140280134453664" scope="col">Configuration name</th><th align="left" valign="top" id="idm140280134452576" scope="col">Unplugging memory from a VM</th><th align="left" valign="top" id="idm140280134451520" scope="col">A risk of creating a memory zone imbalance</th><th align="left" valign="top" id="idm140280134450400" scope="col">A potential use case</th><th align="left" valign="top" id="idm140280134449312" scope="col">Memory requirements of the intended workload</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm140280134453664"> <p>
										<code class="literal">online_movable</code>
									</p>
									 </td><td align="left" valign="top" headers="idm140280134452576"> <p>
										Hot-plugged memory can be reliably unplugged.
									</p>
									 </td><td align="left" valign="top" headers="idm140280134451520"> <p>
										Yes
									</p>
									 </td><td align="left" valign="top" headers="idm140280134450400"> <p>
										Hot-plugging a comparatively small amount of memory
									</p>
									 </td><td align="left" valign="top" headers="idm140280134449312"> <p>
										Mostly user-space memory
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm140280134453664"> <p>
										<code class="literal">auto-movable</code>
									</p>
									 </td><td align="left" valign="top" headers="idm140280134452576"> <p>
										Movable portions of hot-plugged memory can be reliably unplugged.
									</p>
									 </td><td align="left" valign="top" headers="idm140280134451520"> <p>
										Minimal
									</p>
									 </td><td align="left" valign="top" headers="idm140280134450400"> <p>
										Hot-plugging a large amount of memory
									</p>
									 </td><td align="left" valign="top" headers="idm140280134449312"> <p>
										Mostly user-space memory
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm140280134453664"> <p>
										<code class="literal">online_kernel</code>
									</p>
									 </td><td align="left" valign="top" headers="idm140280134452576"> <p>
										Hot-plugged memory cannot be reliably unplugged.
									</p>
									 </td><td align="left" valign="top" headers="idm140280134451520"> <p>
										No
									</p>
									 </td><td align="left" valign="top" headers="idm140280134450400"> <p>
										Unreliable memory unplugging is acceptable.
									</p>
									 </td><td align="left" valign="top" headers="idm140280134449312"> <p>
										User-space or kernel-space memory
									</p>
									 </td></tr></tbody></table></rh-table><p>
						A <span class="emphasis"><em>zone imbalance</em></span> is a lack of available memory pages in one of the Linux memory zones. A <span class="emphasis"><em>zone imbalance</em></span> can negatively impact the system performance. For example, the kernel might crash if it runs out of free memory for unmovable allocations. Usually, movable allocations contain mostly user-space memory pages and unmovable allocations contain mostly kernel-space memory pages.
					</p><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
								<a class="link" href="https://www.kernel.org/doc/html/latest/admin-guide/mm/memory-hotplug.html#onlining-and-offlining-memory-blocks">Onlining and Offlining Memory Blocks</a>
							</li><li class="listitem">
								<a class="link" href="https://www.kernel.org/doc/html/latest/admin-guide/mm/memory-hotplug.html#zone-movable">Zone Imbalances</a>
							</li><li class="listitem">
								<a class="link" href="#configuring-memory-onlining-in-virtual-machines_adding-and-removing-virtual-machine-memory-by-using-virtio-mem" title="13.4.3.2. Configuring memory onlining in virtual machines">Configuring memory onlining in virtual machines</a>
							</li></ul></div></section></section><section class="section _additional-resources" id="additional_resources"><div class="titlepage"><div><div><h4 class="title">13.4.4. Additional resources</h4></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Attaching devices to virtual machines <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/managing-virtual-devices_configuring-and-managing-virtualization#attaching-devices-to-virtual-machines_assembly_managing-virtual-devices-using-the-cli">Attaching devices to virtual machines</a>.
						</li></ul></div></section></section><section class="section" id="optimizing-virtual-machine-i-o-performance_optimizing-virtual-machine-performance-in-rhel"><div class="titlepage"><div><div><h3 class="title">13.5. Optimizing virtual machine I/O performance</h3></div></div></div><p>
				The input and output (I/O) capabilities of a virtual machine (VM) can significantly limit the VM’s overall efficiency. To address this, you can optimize a VM’s I/O by configuring block I/O parameters.
			</p><section class="section" id="tuning-block-i-o-in-virtual-machines_optimizing-virtual-machine-i-o-performance"><div class="titlepage"><div><div><h4 class="title">13.5.1. Tuning block I/O in virtual machines</h4></div></div></div><p>
					When multiple block devices are being used by one or more VMs, it might be important to adjust the I/O priority of specific virtual devices by modifying their <span class="emphasis"><em>I/O weights</em></span>.
				</p><p>
					Increasing the I/O weight of a device increases its priority for I/O bandwidth, and therefore provides it with more host resources. Similarly, reducing a device’s weight makes it consume less host resources.
				</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
						Each device’s <code class="literal">weight</code> value must be within the <code class="literal">100</code> to <code class="literal">1000</code> range. Alternatively, the value can be <code class="literal">0</code>, which removes that device from per-device listings.
					</p></div></rh-alert><div class="formalpara"><p class="title"><strong>Procedure</strong></p><p>
						To display and set a VM’s block I/O parameters:
					</p></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Display the current <code class="literal">&lt;blkio&gt;</code> parameters for a VM:
						</p><p class="simpara">
							<code class="literal"># <span class="strong strong"><strong>virsh dumpxml <span class="emphasis"><em>VM-name</em></span></strong></span></code>
						</p><pre class="programlisting language-xml">&lt;domain&gt;
  [...]
  &lt;blkiotune&gt;
    &lt;weight&gt;800&lt;/weight&gt;
    &lt;device&gt;
      &lt;path&gt;/dev/sda&lt;/path&gt;
      &lt;weight&gt;1000&lt;/weight&gt;
    &lt;/device&gt;
    &lt;device&gt;
      &lt;path&gt;/dev/sdb&lt;/path&gt;
      &lt;weight&gt;500&lt;/weight&gt;
    &lt;/device&gt;
  &lt;/blkiotune&gt;
  [...]
&lt;/domain&gt;</pre></li><li class="listitem"><p class="simpara">
							Edit the I/O weight of a specified device:
						</p><pre class="screen"># <span class="strong strong"><strong>virsh blkiotune <span class="emphasis"><em>VM-name</em></span> --device-weights <span class="emphasis"><em>device</em></span>, <span class="emphasis"><em>I/O-weight</em></span></strong></span></pre><p class="simpara">
							For example, the following changes the weight of the <span class="emphasis"><em>/dev/sda</em></span> device in the <span class="emphasis"><em>testguest1</em></span> VM to 500.
						</p><pre class="screen"># <span class="strong strong"><strong>virsh blkiotune testguest1 --device-weights /dev/sda, 500</strong></span></pre></li></ol></div></section><section class="section" id="disk-i-o-throttling-in-virtual-machines_optimizing-virtual-machine-i-o-performance"><div class="titlepage"><div><div><h4 class="title">13.5.2. Disk I/O throttling in virtual machines</h4></div></div></div><p>
					When several VMs are running simultaneously, they can interfere with system performance by using excessive disk I/O. Disk I/O throttling in KVM virtualization provides the ability to set a limit on disk I/O requests sent from the VMs to the host machine. This can prevent a VM from over-utilizing shared resources and impacting the performance of other VMs.
				</p><p>
					To enable disk I/O throttling, set a limit on disk I/O requests sent from each block device attached to VMs to the host machine.
				</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Use the <code class="literal">virsh domblklist</code> command to list the names of all the disk devices on a specified VM.
						</p><pre class="screen"># <span class="strong strong"><strong>virsh domblklist rollin-coal</strong></span>
Target     Source
------------------------------------------------
vda        /var/lib/libvirt/images/rollin-coal.qcow2
sda        -
sdb        /home/horridly-demanding-processes.iso</pre></li><li class="listitem"><p class="simpara">
							Find the host block device where the virtual disk that you want to throttle is mounted.
						</p><p class="simpara">
							For example, if you want to throttle the <code class="literal">sdb</code> virtual disk from the previous step, the following output shows that the disk is mounted on the <code class="literal">/dev/nvme0n1p3</code> partition.
						</p><pre class="screen">$ <span class="strong strong"><strong>lsblk</strong></span>
NAME                                          MAJ:MIN RM   SIZE RO TYPE  MOUNTPOINT
zram0                                         252:0    0     4G  0 disk  [SWAP]
nvme0n1                                       259:0    0 238.5G  0 disk
├─nvme0n1p1                                   259:1    0   600M  0 part  /boot/efi
├─nvme0n1p2                                   259:2    0     1G  0 part  /boot
└─nvme0n1p3                                   259:3    0 236.9G  0 part
  └─luks-a1123911-6f37-463c-b4eb-fxzy1ac12fea 253:0    0 236.9G  0 crypt /home</pre></li><li class="listitem"><p class="simpara">
							Set I/O limits for the block device by using the <code class="literal">virsh blkiotune</code> command.
						</p><pre class="screen"># <span class="strong strong"><strong>virsh blkiotune <span class="emphasis"><em>VM-name</em></span> --parameter <span class="emphasis"><em>device</em></span>,<span class="emphasis"><em>limit</em></span></strong></span></pre><p class="simpara">
							The following example throttles the <code class="literal">sdb</code> disk on the <code class="literal">rollin-coal</code> VM to 1000 read and write I/O operations per second and to 50 MB per second read and write throughput.
						</p><pre class="screen"># <span class="strong strong"><strong>virsh blkiotune rollin-coal --device-read-iops-sec /dev/nvme0n1p3,1000 --device-write-iops-sec /dev/nvme0n1p3,1000 --device-write-bytes-sec /dev/nvme0n1p3,52428800 --device-read-bytes-sec /dev/nvme0n1p3,52428800</strong></span></pre></li></ol></div><div class="itemizedlist"><p class="title"><strong>Additional information</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							Disk I/O throttling can be useful in various situations, for example when VMs belonging to different customers are running on the same host, or when quality of service guarantees are given for different VMs. Disk I/O throttling can also be used to simulate slower disks.
						</li><li class="listitem">
							I/O throttling can be applied independently to each block device attached to a VM and supports limits on throughput and I/O operations.
						</li><li class="listitem">
							Red Hat does not support using the <code class="literal">virsh blkdeviotune</code> command to configure I/O throttling in VMs. For more information about unsupported features when using RHEL 9 as a VM host, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/configuring_and_managing_virtualization/index#unsupported-features-in-rhel-9-virtualization_feature-support-and-limitations-in-rhel-9-virtualization">Unsupported features in RHEL 9 virtualization</a>.
						</li></ul></div></section><section class="section" id="configuring-multi-queue-virtio-scsi_optimizing-virtual-machine-i-o-performance"><div class="titlepage"><div><div><h4 class="title">13.5.3. Enabling multi-queue virtio-scsi</h4></div></div></div><p>
					When using <code class="literal">virtio-scsi</code> storage devices in your virtual machines (VMs), the <span class="emphasis"><em>multi-queue virtio-scsi</em></span> feature provides improved storage performance and scalability. It enables each virtual CPU (vCPU) to have a separate queue and interrupt to use without affecting other vCPUs.
				</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							To enable multi-queue virtio-scsi support for a specific VM, add the following to the VM’s XML configuration, where <span class="emphasis"><em>N</em></span> is the total number of vCPU queues:
						</p><pre class="programlisting language-xml">&lt;controller type='scsi' index='0' model='virtio-scsi'&gt;
   &lt;driver queues='N' /&gt;
&lt;/controller&gt;</pre></li></ul></div></section></section><section class="section" id="optimizing-virtual-machine-cpu-performance_optimizing-virtual-machine-performance-in-rhel"><div class="titlepage"><div><div><h3 class="title">13.6. Optimizing virtual machine CPU performance</h3></div></div></div><p>
				Much like physical CPUs in host machines, vCPUs are critical to virtual machine (VM) performance. As a result, optimizing vCPUs can have a significant impact on the resource efficiency of your VMs. To optimize your vCPU:
			</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
						Adjust how many host CPUs are assigned to the VM. You can do this using <a class="link" href="#adding-and-removing-virtual-cpus-using-the-command-line-interface_optimizing-virtual-machine-cpu-performance" title="13.6.1. Adding and removing virtual CPUs by using the command-line interface">the CLI</a> or <a class="link" href="#managing-virtual-cpus-using-the-web-console_optimizing-virtual-machine-cpu-performance" title="13.6.2. Managing virtual CPUs by using the web console">the web console</a>.
					</li><li class="listitem"><p class="simpara">
						Ensure that the vCPU model is aligned with the CPU model of the host. For example, to set the <span class="emphasis"><em>testguest1</em></span> VM to use the CPU model of the host:
					</p><pre class="screen"># <span class="strong strong"><strong>virt-xml testguest1 --edit --cpu host-model</strong></span></pre><p class="simpara">
						On an ARM 64 system, use <code class="literal">--cpu host-passthrough</code>.
					</p></li><li class="listitem">
						<a class="link" href="#proc_managing-ksm_optimizing-virtual-machine-cpu-performance" title="13.6.5. Enabling and disabling kernel same-page merging">Manage kernel same-page merging (KSM)</a>.
					</li><li class="listitem"><p class="simpara">
						If your host machine uses Non-Uniform Memory Access (NUMA), you can also <span class="strong strong"><strong>configure NUMA</strong></span> for its VMs. This maps the host’s CPU and memory processes onto the CPU and memory processes of the VM as closely as possible. In effect, NUMA tuning provides the vCPU with a more streamlined access to the system memory allocated to the VM, which can improve the vCPU processing effectiveness.
					</p><p class="simpara">
						For details, see <a class="link" href="#configuring-numa-in-a-virtual-machine_optimizing-virtual-machine-cpu-performance" title="13.6.3. Configuring NUMA in a virtual machine">Configuring NUMA in a virtual machine</a> and <a class="link" href="#sample-vcpu-performance-tuning-scenario_optimizing-virtual-machine-cpu-performance" title="13.6.4. Sample vCPU performance tuning scenario">Sample vCPU performance tuning scenario</a>.
					</p></li></ol></div><section class="section" id="adding-and-removing-virtual-cpus-using-the-command-line-interface_optimizing-virtual-machine-cpu-performance"><div class="titlepage"><div><div><h4 class="title">13.6.1. Adding and removing virtual CPUs by using the command-line interface</h4></div></div></div><p>
					To increase or optimize the CPU performance of a virtual machine (VM), you can add or remove virtual CPUs (vCPUs) assigned to the VM.
				</p><p>
					When performed on a running VM, this is also referred to as vCPU hot plugging and hot unplugging. However, note that vCPU hot unplug is not supported in RHEL 9, and Red Hat highly discourages its use.
				</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							Optional: View the current state of the vCPUs in the targeted VM. For example, to display the number of vCPUs on the <span class="emphasis"><em>testguest</em></span> VM:
						</p><pre class="screen"># <span class="strong strong"><strong>virsh vcpucount <span class="emphasis"><em>testguest</em></span></strong></span>
maximum      config         4
maximum      live           2
current      config         2
current      live           1</pre><p class="simpara">
							This output indicates that <span class="emphasis"><em>testguest</em></span> is currently using 1 vCPU, and 1 more vCPu can be hot plugged to it to increase the VM’s performance. However, after reboot, the number of vCPUs <span class="emphasis"><em>testguest</em></span> uses will change to 2, and it will be possible to hot plug 2 more vCPUs.
						</p></li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Adjust the maximum number of vCPUs that can be attached to a VM, which takes effect on the VM’s next boot.
						</p><p class="simpara">
							For example, to increase the maximum vCPU count for the <span class="emphasis"><em>testguest</em></span> VM to 8:
						</p><pre class="screen"># <span class="strong strong"><strong>virsh setvcpus testguest 8 --maximum --config</strong></span></pre><p class="simpara">
							Note that the maximum may be limited by the CPU topology, host hardware, the hypervisor, and other factors.
						</p></li><li class="listitem"><p class="simpara">
							Adjust the current number of vCPUs attached to a VM, up to the maximum configured in the previous step. For example:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									To increase the number of vCPUs attached to the running <span class="emphasis"><em>testguest</em></span> VM to 4:
								</p><pre class="screen"># <span class="strong strong"><strong>virsh setvcpus testguest 4 --live</strong></span></pre><p class="simpara">
									This increases the VM’s performance and host load footprint of <span class="emphasis"><em>testguest</em></span> until the VM’s next boot.
								</p></li><li class="listitem"><p class="simpara">
									To permanently decrease the number of vCPUs attached to the <span class="emphasis"><em>testguest</em></span> VM to 1:
								</p><pre class="screen"># <span class="strong strong"><strong>virsh setvcpus testguest 1 --config</strong></span></pre><p class="simpara">
									This decreases the VM’s performance and host load footprint of <span class="emphasis"><em>testguest</em></span> after the VM’s next boot. However, if needed, additional vCPUs can be hot plugged to the VM to temporarily increase its performance.
								</p></li></ul></div></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							Confirm that the current state of vCPU for the VM reflects your changes.
						</p><pre class="screen"># <span class="strong strong"><strong>virsh vcpucount <span class="emphasis"><em>testguest</em></span></strong></span>
maximum      config         8
maximum      live           4
current      config         1
current      live           4</pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/optimizing-virtual-machine-performance-in-rhel_configuring-and-managing-virtualization#managing-virtual-cpus-using-the-web-console_optimizing-virtual-machine-cpu-performance">Managing virtual CPUs by using the web console</a>
						</li></ul></div></section><section class="section" id="managing-virtual-cpus-using-the-web-console_optimizing-virtual-machine-cpu-performance"><div class="titlepage"><div><div><h4 class="title">13.6.2. Managing virtual CPUs by using the web console</h4></div></div></div><p>
					By using the RHEL 9 web console, you can review and configure virtual CPUs used by virtual machines (VMs) to which the web console is connected.
				</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							You have installed the RHEL 9 web console.
						</p><p class="simpara">
							For instructions, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console">Installing and enabling the web console</a>.
						</p></li><li class="listitem">
							The web console VM plug-in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/managing-virtual-machines-in-the-web-console_configuring-and-managing-virtualization">is installed on your system</a>.
						</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Log in to the RHEL 9 web console.
						</p><p class="simpara">
							For details, see <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#logging-in-to-the-web-console_getting-started-with-the-rhel-9-web-console">Logging in to the web console</a>.
						</p></li><li class="listitem"><p class="simpara">
							In the <span class="guimenu">Virtual Machines</span> interface, click the VM whose information you want to see.
						</p><p class="simpara">
							A new page opens with an Overview section with basic information about the selected VM and a Console section to access the VM’s graphical interface.
						</p></li><li class="listitem"><p class="simpara">
							Click <span class="guibutton">edit</span> next to the number of vCPUs in the Overview pane.
						</p><p class="simpara">
							The vCPU details dialog appears.
						</p><div class="informalfigure"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/822593b143a5fe3f23f61dc63a892afb/virt-cockpit-configure-vCPUs.png" width="540" alt="Image displaying the VM CPU details dialog box."></div></div></li></ol></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Configure the virtual CPUs for the selected VM.
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									<span class="strong strong"><strong>vCPU Count</strong></span> - The number of vCPUs currently in use.
								</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
										The vCPU count cannot be greater than the vCPU Maximum.
									</p></div></rh-alert></li><li class="listitem">
									<span class="strong strong"><strong>vCPU Maximum</strong></span> - The maximum number of virtual CPUs that can be configured for the VM. If this value is higher than the <span class="strong strong"><strong>vCPU Count</strong></span>, additional vCPUs can be attached to the VM.
								</li><li class="listitem">
									<span class="strong strong"><strong>Sockets</strong></span> - The number of sockets to expose to the VM.
								</li><li class="listitem">
									<span class="strong strong"><strong>Cores per socket</strong></span> - The number of cores for each socket to expose to the VM.
								</li><li class="listitem"><p class="simpara">
									<span class="strong strong"><strong>Threads per core</strong></span> - The number of threads for each core to expose to the VM.
								</p><p class="simpara">
									Note that the <span class="strong strong"><strong>Sockets</strong></span>, <span class="strong strong"><strong>Cores per socket</strong></span>, and <span class="strong strong"><strong>Threads per core</strong></span> options adjust the CPU topology of the VM. This may be beneficial for vCPU performance and may impact the functionality of certain software in the guest OS. If a different setting is not required by your deployment, keep the default values.
								</p></li></ul></div></li><li class="listitem"><p class="simpara">
							Click <span class="guibutton">Apply</span>.
						</p><p class="simpara">
							The virtual CPUs for the VM are configured.
						</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
								Changes to virtual CPU settings only take effect after the VM is restarted.
							</p></div></rh-alert></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/optimizing-virtual-machine-performance-in-rhel_configuring-and-managing-virtualization#adding-and-removing-virtual-cpus-using-the-command-line-interface_optimizing-virtual-machine-cpu-performance">Adding and removing virtual CPUs by using the command-line interface</a>
						</li></ul></div></section><section class="section" id="configuring-numa-in-a-virtual-machine_optimizing-virtual-machine-cpu-performance"><div class="titlepage"><div><div><h4 class="title">13.6.3. Configuring NUMA in a virtual machine</h4></div></div></div><p>
					The following methods can be used to configure Non-Uniform Memory Access (NUMA) settings of a virtual machine (VM) on a RHEL 9 host.
				</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							The host is a NUMA-compatible machine. To detect whether this is the case, use the <code class="literal">virsh nodeinfo</code> command and see the <code class="literal">NUMA cell(s)</code> line:
						</p><pre class="screen"># <span class="strong strong"><strong>virsh nodeinfo</strong></span>
CPU model:           x86_64
CPU(s):              48
CPU frequency:       1200 MHz
CPU socket(s):       1
Core(s) per socket:  12
Thread(s) per core:  2
NUMA cell(s):        <span class="strong strong"><strong>2</strong></span>
Memory size:         67012964 KiB</pre><p class="simpara">
							If the value of the line is 2 or greater, the host is NUMA-compatible.
						</p></li></ul></div><div class="formalpara"><p class="title"><strong>Procedure</strong></p><p>
						For ease of use, you can set up a VM’s NUMA configuration by using automated utilities and services. However, manual NUMA setup is more likely to yield a significant performance improvement.
					</p></div><p>
					<span class="strong strong"><strong>Automatic methods</strong></span>
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							Set the VM’s NUMA policy to <code class="literal">Preferred</code>. For example, to do so for the <span class="emphasis"><em>testguest5</em></span> VM:
						</p><pre class="screen"># <span class="strong strong"><strong>virt-xml testguest5 --edit --vcpus placement=auto</strong></span>
# <span class="strong strong"><strong>virt-xml testguest5 --edit --numatune mode=preferred</strong></span></pre></li><li class="listitem"><p class="simpara">
							Enable automatic NUMA balancing on the host:
						</p><pre class="screen"># <span class="strong strong"><strong>echo 1 &gt; /proc/sys/kernel/numa_balancing</strong></span></pre></li><li class="listitem"><p class="simpara">
							Start the <code class="literal">numad</code> service to automatically align the VM CPU with memory resources.
						</p><pre class="screen"># <span class="strong strong"><strong>systemctl start numad</strong></span></pre></li></ul></div><p>
					<span class="strong strong"><strong>Manual methods</strong></span>
				</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Pin specific vCPU threads to a specific host CPU or range of CPUs. This is also possible on non-NUMA hosts and VMs, and is recommended as a safe method of vCPU performance improvement.
						</p><p class="simpara">
							For example, the following commands pin vCPU threads 0 to 5 of the <span class="emphasis"><em>testguest6</em></span> VM to host CPUs 1, 3, 5, 7, 9, and 11, respectively:
						</p><pre class="screen"># <span class="strong strong"><strong>virsh vcpupin testguest6 0 1</strong></span>
# <span class="strong strong"><strong>virsh vcpupin testguest6 1 3</strong></span>
# <span class="strong strong"><strong>virsh vcpupin testguest6 2 5</strong></span>
# <span class="strong strong"><strong>virsh vcpupin testguest6 3 7</strong></span>
# <span class="strong strong"><strong>virsh vcpupin testguest6 4 9</strong></span>
# <span class="strong strong"><strong>virsh vcpupin testguest6 5 11</strong></span></pre><p class="simpara">
							Afterwards, you can verify whether this was successful:
						</p><pre class="screen"># <span class="strong strong"><strong>virsh vcpupin testguest6</strong></span>
VCPU   CPU Affinity
----------------------
0      1
1      3
2      5
3      7
4      9
5      11</pre></li><li class="listitem"><p class="simpara">
							After pinning vCPU threads, you can also pin QEMU process threads associated with a specified VM to a specific host CPU or range of CPUs. For example, the following commands pin the QEMU process thread of <span class="emphasis"><em>testguest6</em></span> to CPUs 13 and 15, and verify this was successful:
						</p><pre class="screen"># <span class="strong strong"><strong>virsh emulatorpin testguest6 13,15</strong></span>
# <span class="strong strong"><strong>virsh emulatorpin testguest6</strong></span>
emulator: CPU Affinity
----------------------------------
       *: 13,15</pre></li><li class="listitem"><p class="simpara">
							Finally, you can also specify which host NUMA nodes will be assigned specifically to a certain VM. This can improve the host memory usage by the VM’s vCPU. For example, the following commands set <span class="emphasis"><em>testguest6</em></span> to use host NUMA nodes 3 to 5, and verify this was successful:
						</p><pre class="screen"># <span class="strong strong"><strong>virsh numatune testguest6 --nodeset 3-5</strong></span>
# <span class="strong strong"><strong>virsh numatune testguest6</strong></span></pre></li></ol></div><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
						For best performance results, it is recommended to use all of the manual tuning methods listed above
					</p></div></rh-alert><div class="itemizedlist"><p class="title"><strong>Known issues</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/assembly_feature-support-and-limitations-in-rhel-9-virtualization_configuring-and-managing-virtualization#how-virtualization-on-ibm-z-differs-from-amd64-and-intel64_feature-support-and-limitations-in-rhel-9-virtualization">NUMA tuning currently cannot be performed on IBM Z hosts</a>.
						</li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/optimizing-virtual-machine-performance-in-rhel_configuring-and-managing-virtualization#sample-vcpu-performance-tuning-scenario_optimizing-virtual-machine-cpu-performance">Sample vCPU performance tuning scenario</a>
						</li><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/optimizing-virtual-machine-performance-in-rhel_configuring-and-managing-virtualization#virtual-machine-performance-monitoring-tools_optimizing-virtual-machine-performance-in-rhel">View the current NUMA configuration of your system</a> using the <code class="literal">numastat</code> utility
						</li></ul></div></section><section class="section" id="sample-vcpu-performance-tuning-scenario_optimizing-virtual-machine-cpu-performance"><div class="titlepage"><div><div><h4 class="title">13.6.4. Sample vCPU performance tuning scenario</h4></div></div></div><p>
					To obtain the best vCPU performance possible, Red Hat recommends by using manual <code class="literal">vcpupin</code>, <code class="literal">emulatorpin</code>, and <code class="literal">numatune</code> settings together, for example like in the following scenario.
				</p><div class="itemizedlist"><p class="title"><strong>Starting scenario</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							Your host has the following hardware specifics:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
									2 NUMA nodes
								</li><li class="listitem">
									3 CPU cores on each node
								</li><li class="listitem">
									2 threads on each core
								</li></ul></div><p class="simpara">
							The output of <code class="literal">virsh nodeinfo</code> of such a machine would look similar to:
						</p><pre class="screen"># <span class="strong strong"><strong>virsh nodeinfo</strong></span>
CPU model:           x86_64
CPU(s):              12
CPU frequency:       3661 MHz
CPU socket(s):       2
Core(s) per socket:  3
Thread(s) per core:  2
NUMA cell(s):        2
Memory size:         31248692 KiB</pre></li><li class="listitem"><p class="simpara">
							You intend to modify an existing VM to have 8 vCPUs, which means that it will not fit in a single NUMA node.
						</p><p class="simpara">
							Therefore, you should distribute 4 vCPUs on each NUMA node and make the vCPU topology resemble the host topology as closely as possible. This means that vCPUs that run as sibling threads of a given physical CPU should be pinned to host threads on the same core. For details, see the <span class="emphasis"><em>Solution</em></span> below:
						</p></li></ul></div><div class="orderedlist"><p class="title"><strong>Solution</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Obtain the information about the host topology:
						</p><pre class="screen"># <span class="strong strong"><strong>virsh capabilities</strong></span></pre><p class="simpara">
							The output should include a section that looks similar to the following:
						</p><pre class="programlisting language-xml">&lt;topology&gt;
  &lt;cells num="2"&gt;
    &lt;cell id="0"&gt;
      &lt;memory unit="KiB"&gt;15624346&lt;/memory&gt;
      &lt;pages unit="KiB" size="4"&gt;3906086&lt;/pages&gt;
      &lt;pages unit="KiB" size="2048"&gt;0&lt;/pages&gt;
      &lt;pages unit="KiB" size="1048576"&gt;0&lt;/pages&gt;
      &lt;distances&gt;
        &lt;sibling id="0" value="10" /&gt;
        &lt;sibling id="1" value="21" /&gt;
      &lt;/distances&gt;
      &lt;cpus num="6"&gt;
        &lt;cpu id="0" socket_id="0" core_id="0" siblings="0,3" /&gt;
        &lt;cpu id="1" socket_id="0" core_id="1" siblings="1,4" /&gt;
        &lt;cpu id="2" socket_id="0" core_id="2" siblings="2,5" /&gt;
        &lt;cpu id="3" socket_id="0" core_id="0" siblings="0,3" /&gt;
        &lt;cpu id="4" socket_id="0" core_id="1" siblings="1,4" /&gt;
        &lt;cpu id="5" socket_id="0" core_id="2" siblings="2,5" /&gt;
      &lt;/cpus&gt;
    &lt;/cell&gt;
    &lt;cell id="1"&gt;
      &lt;memory unit="KiB"&gt;15624346&lt;/memory&gt;
      &lt;pages unit="KiB" size="4"&gt;3906086&lt;/pages&gt;
      &lt;pages unit="KiB" size="2048"&gt;0&lt;/pages&gt;
      &lt;pages unit="KiB" size="1048576"&gt;0&lt;/pages&gt;
      &lt;distances&gt;
        &lt;sibling id="0" value="21" /&gt;
        &lt;sibling id="1" value="10" /&gt;
      &lt;/distances&gt;
      &lt;cpus num="6"&gt;
        &lt;cpu id="6" socket_id="1" core_id="3" siblings="6,9" /&gt;
        &lt;cpu id="7" socket_id="1" core_id="4" siblings="7,10" /&gt;
        &lt;cpu id="8" socket_id="1" core_id="5" siblings="8,11" /&gt;
        &lt;cpu id="9" socket_id="1" core_id="3" siblings="6,9" /&gt;
        &lt;cpu id="10" socket_id="1" core_id="4" siblings="7,10" /&gt;
        &lt;cpu id="11" socket_id="1" core_id="5" siblings="8,11" /&gt;
      &lt;/cpus&gt;
    &lt;/cell&gt;
  &lt;/cells&gt;
&lt;/topology&gt;</pre></li><li class="listitem">
							Optional: Test the performance of the VM by using <a class="link" href="#virtual-machine-performance-monitoring-tools_optimizing-virtual-machine-performance-in-rhel" title="13.8. Virtual machine performance monitoring tools">the applicable tools and utilities</a>.
						</li><li class="listitem"><p class="simpara">
							Set up and mount 1 GiB huge pages on the host:
						</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
								1 GiB huge pages might not be available on some architectures and configurations, such as ARM 64 hosts.
							</p></div></rh-alert><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
									Add the following line to the host’s kernel command line:
								</p><pre class="screen">default_hugepagesz=1G hugepagesz=1G</pre></li><li class="listitem"><p class="simpara">
									Create the <code class="literal">/etc/systemd/system/hugetlb-gigantic-pages.service</code> file with the following content:
								</p><pre class="screen">[Unit]
Description=HugeTLB Gigantic Pages Reservation
DefaultDependencies=no
Before=dev-hugepages.mount
ConditionPathExists=/sys/devices/system/node
ConditionKernelCommandLine=hugepagesz=1G

[Service]
Type=oneshot
RemainAfterExit=yes
ExecStart=/etc/systemd/hugetlb-reserve-pages.sh

[Install]
WantedBy=sysinit.target</pre></li><li class="listitem"><p class="simpara">
									Create the <code class="literal">/etc/systemd/hugetlb-reserve-pages.sh</code> file with the following content:
								</p><pre class="screen">#!/bin/sh

nodes_path=/sys/devices/system/node/
if [ ! -d $nodes_path ]; then
	echo "ERROR: $nodes_path does not exist"
	exit 1
fi

reserve_pages()
{
	echo $1 &gt; $nodes_path/$2/hugepages/hugepages-1048576kB/nr_hugepages
}

reserve_pages 4 node1
reserve_pages 4 node2</pre><p class="simpara">
									This reserves four 1GiB huge pages from <span class="emphasis"><em>node1</em></span> and four 1GiB huge pages from <span class="emphasis"><em>node2</em></span>.
								</p></li><li class="listitem"><p class="simpara">
									Make the script created in the previous step executable:
								</p><pre class="screen"># <span class="strong strong"><strong>chmod +x /etc/systemd/hugetlb-reserve-pages.sh</strong></span></pre></li><li class="listitem"><p class="simpara">
									Enable huge page reservation on boot:
								</p><pre class="screen"># <span class="strong strong"><strong>systemctl enable hugetlb-gigantic-pages</strong></span></pre></li></ol></div></li><li class="listitem"><p class="simpara">
							Use the <code class="literal">virsh edit</code> command to edit the XML configuration of the VM you wish to optimize, in this example <span class="emphasis"><em>super-VM</em></span>:
						</p><pre class="screen"># <span class="strong strong"><strong>virsh edit super-vm</strong></span></pre></li><li class="listitem"><p class="simpara">
							Adjust the XML configuration of the VM in the following way:
						</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem">
									Set the VM to use 8 static vCPUs. Use the <code class="literal">&lt;vcpu/&gt;</code> element to do this.
								</li><li class="listitem"><p class="simpara">
									Pin each of the vCPU threads to the corresponding host CPU threads that it mirrors in the topology. To do so, use the <code class="literal">&lt;vcpupin/&gt;</code> elements in the <code class="literal">&lt;cputune&gt;</code> section.
								</p><p class="simpara">
									Note that, as shown by the <code class="literal">virsh capabilities</code> utility above, host CPU threads are not ordered sequentially in their respective cores. In addition, the vCPU threads should be pinned to the highest available set of host cores on the same NUMA node. For a table illustration, see the <span class="strong strong"><strong>Sample topology</strong></span> section below.
								</p><p class="simpara">
									The XML configuration for steps a. and b. can look similar to:
								</p><pre class="programlisting language-xml">&lt;cputune&gt;
  &lt;vcpupin vcpu='0' cpuset='1'/&gt;
  &lt;vcpupin vcpu='1' cpuset='4'/&gt;
  &lt;vcpupin vcpu='2' cpuset='2'/&gt;
  &lt;vcpupin vcpu='3' cpuset='5'/&gt;
  &lt;vcpupin vcpu='4' cpuset='7'/&gt;
  &lt;vcpupin vcpu='5' cpuset='10'/&gt;
  &lt;vcpupin vcpu='6' cpuset='8'/&gt;
  &lt;vcpupin vcpu='7' cpuset='11'/&gt;
  &lt;emulatorpin cpuset='6,9'/&gt;
&lt;/cputune&gt;</pre></li><li class="listitem"><p class="simpara">
									Set the VM to use 1 GiB huge pages:
								</p><pre class="programlisting language-xml">&lt;memoryBacking&gt;
  &lt;hugepages&gt;
    &lt;page size='1' unit='GiB'/&gt;
  &lt;/hugepages&gt;
&lt;/memoryBacking&gt;</pre></li><li class="listitem"><p class="simpara">
									Configure the VM’s NUMA nodes to use memory from the corresponding NUMA nodes on the host. To do so, use the <code class="literal">&lt;memnode/&gt;</code> elements in the <code class="literal">&lt;numatune/&gt;</code> section:
								</p><pre class="programlisting language-xml">&lt;numatune&gt;
  &lt;memory mode="preferred" nodeset="1"/&gt;
  &lt;memnode cellid="0" mode="strict" nodeset="0"/&gt;
  &lt;memnode cellid="1" mode="strict" nodeset="1"/&gt;
&lt;/numatune&gt;</pre></li><li class="listitem"><p class="simpara">
									Ensure the CPU mode is set to <code class="literal">host-passthrough</code>, and that the CPU uses cache in <code class="literal">passthrough</code> mode:
								</p><pre class="programlisting language-xml">&lt;cpu mode="host-passthrough"&gt;
  &lt;topology sockets="2" cores="2" threads="2"/&gt;
  &lt;cache mode="passthrough"/&gt;</pre><p class="simpara">
									On an ARM 64 system, omit the <code class="literal">&lt;cache mode="passthrough"/&gt;</code> line.
								</p></li></ol></div></li></ol></div><div class="orderedlist"><p class="title"><strong>Verification</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Confirm that the resulting XML configuration of the VM includes a section similar to the following:
						</p><pre class="programlisting language-xml">[...]
  &lt;memoryBacking&gt;
    &lt;hugepages&gt;
      &lt;page size='1' unit='GiB'/&gt;
    &lt;/hugepages&gt;
  &lt;/memoryBacking&gt;
  &lt;vcpu placement='static'&gt;8&lt;/vcpu&gt;
  &lt;cputune&gt;
    &lt;vcpupin vcpu='0' cpuset='1'/&gt;
    &lt;vcpupin vcpu='1' cpuset='4'/&gt;
    &lt;vcpupin vcpu='2' cpuset='2'/&gt;
    &lt;vcpupin vcpu='3' cpuset='5'/&gt;
    &lt;vcpupin vcpu='4' cpuset='7'/&gt;
    &lt;vcpupin vcpu='5' cpuset='10'/&gt;
    &lt;vcpupin vcpu='6' cpuset='8'/&gt;
    &lt;vcpupin vcpu='7' cpuset='11'/&gt;
    &lt;emulatorpin cpuset='6,9'/&gt;
  &lt;/cputune&gt;
  &lt;numatune&gt;
    &lt;memory mode="preferred" nodeset="1"/&gt;
    &lt;memnode cellid="0" mode="strict" nodeset="0"/&gt;
    &lt;memnode cellid="1" mode="strict" nodeset="1"/&gt;
  &lt;/numatune&gt;
  &lt;cpu mode="host-passthrough"&gt;
    &lt;topology sockets="2" cores="2" threads="2"/&gt;
    &lt;cache mode="passthrough"/&gt;
    &lt;numa&gt;
      &lt;cell id="0" cpus="0-3" memory="2" unit="GiB"&gt;
        &lt;distances&gt;
          &lt;sibling id="0" value="10"/&gt;
          &lt;sibling id="1" value="21"/&gt;
        &lt;/distances&gt;
      &lt;/cell&gt;
      &lt;cell id="1" cpus="4-7" memory="2" unit="GiB"&gt;
        &lt;distances&gt;
          &lt;sibling id="0" value="21"/&gt;
          &lt;sibling id="1" value="10"/&gt;
        &lt;/distances&gt;
      &lt;/cell&gt;
    &lt;/numa&gt;
  &lt;/cpu&gt;
&lt;/domain&gt;</pre></li><li class="listitem">
							Optional: Test the performance of the VM by using <a class="link" href="#virtual-machine-performance-monitoring-tools_optimizing-virtual-machine-performance-in-rhel" title="13.8. Virtual machine performance monitoring tools">the applicable tools and utilities</a> to evaluate the impact of the VM’s optimization.
						</li></ol></div><div class="itemizedlist"><p class="title"><strong>Sample topology</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							The following tables illustrate the connections between the vCPUs and the host CPUs they should be pinned to:
						</p><rh-table id="idm140280139896848"><table class="gt-8-cols lt-7-rows"><caption>Table 13.2. Host topology</caption><colgroup><col style="width: 7%; " class="col_1"><!--Empty--><col style="width: 7%; " class="col_2"><!--Empty--><col style="width: 7%; " class="col_3"><!--Empty--><col style="width: 7%; " class="col_4"><!--Empty--><col style="width: 7%; " class="col_5"><!--Empty--><col style="width: 7%; " class="col_6"><!--Empty--><col style="width: 7%; " class="col_7"><!--Empty--><col style="width: 7%; " class="col_8"><!--Empty--><col style="width: 7%; " class="col_9"><!--Empty--><col style="width: 7%; " class="col_10"><!--Empty--><col style="width: 7%; " class="col_11"><!--Empty--><col style="width: 7%; " class="col_12"><!--Empty--><col style="width: 7%; " class="col_13"><!--Empty--><col style="width: 7%; " class="col_14"><!--Empty--><col style="width: 7%; " class="col_15"><!--Empty--></colgroup><tbody><tr><td colspan="3" align="center" valign="top"> <p>
											<span class="strong strong"><strong>CPU threads</strong></span>
										</p>
										 </td><td align="left" valign="top"> <p>
											0
										</p>
										 </td><td align="left" valign="top"> <p>
											3
										</p>
										 </td><td align="left" valign="top"> <p>
											1
										</p>
										 </td><td align="left" valign="top"> <p>
											4
										</p>
										 </td><td align="left" valign="top"> <p>
											2
										</p>
										 </td><td align="left" valign="top"> <p>
											5
										</p>
										 </td><td align="left" valign="top"> <p>
											6
										</p>
										 </td><td align="left" valign="top"> <p>
											9
										</p>
										 </td><td align="left" valign="top"> <p>
											7
										</p>
										 </td><td align="left" valign="top"> <p>
											10
										</p>
										 </td><td align="left" valign="top"> <p>
											8
										</p>
										 </td><td align="left" valign="top"> <p>
											11
										</p>
										 </td></tr><tr><td colspan="3" align="center" valign="top"> <p>
											<span class="strong strong"><strong>Cores</strong></span>
										</p>
										 </td><td colspan="2" align="center" valign="top"> <p>
											0
										</p>
										 </td><td colspan="2" align="center" valign="top"> <p>
											1
										</p>
										 </td><td colspan="2" align="center" valign="top"> <p>
											2
										</p>
										 </td><td colspan="2" align="center" valign="top"> <p>
											3
										</p>
										 </td><td colspan="2" align="center" valign="top"> <p>
											4
										</p>
										 </td><td colspan="2" align="center" valign="top"> <p>
											5
										</p>
										 </td></tr><tr><td colspan="3" align="center" valign="top"> <p>
											<span class="strong strong"><strong>Sockets</strong></span>
										</p>
										 </td><td colspan="6" align="center" valign="top"> <p>
											0
										</p>
										 </td><td colspan="6" align="center" valign="top"> <p>
											1
										</p>
										 </td></tr><tr><td colspan="3" align="center" valign="top"> <p>
											<span class="strong strong"><strong>NUMA nodes</strong></span>
										</p>
										 </td><td colspan="6" align="center" valign="top"> <p>
											0
										</p>
										 </td><td colspan="6" align="center" valign="top"> <p>
											1
										</p>
										 </td></tr></tbody></table></rh-table><rh-table id="idm140280131378592"><table class="gt-8-cols lt-7-rows"><caption>Table 13.3. VM topology</caption><colgroup><col style="width: 9%; " class="col_1"><!--Empty--><col style="width: 9%; " class="col_2"><!--Empty--><col style="width: 9%; " class="col_3"><!--Empty--><col style="width: 9%; " class="col_4"><!--Empty--><col style="width: 9%; " class="col_5"><!--Empty--><col style="width: 9%; " class="col_6"><!--Empty--><col style="width: 9%; " class="col_7"><!--Empty--><col style="width: 9%; " class="col_8"><!--Empty--><col style="width: 9%; " class="col_9"><!--Empty--><col style="width: 9%; " class="col_10"><!--Empty--><col style="width: 9%; " class="col_11"><!--Empty--></colgroup><tbody><tr><td colspan="3" align="center" valign="top"> <p>
											<span class="strong strong"><strong>vCPU threads</strong></span>
										</p>
										 </td><td align="left" valign="top"> <p>
											0
										</p>
										 </td><td align="left" valign="top"> <p>
											1
										</p>
										 </td><td align="left" valign="top"> <p>
											2
										</p>
										 </td><td align="left" valign="top"> <p>
											3
										</p>
										 </td><td align="left" valign="top"> <p>
											4
										</p>
										 </td><td align="left" valign="top"> <p>
											5
										</p>
										 </td><td align="left" valign="top"> <p>
											6
										</p>
										 </td><td align="left" valign="top"> <p>
											7
										</p>
										 </td></tr><tr><td colspan="3" align="center" valign="top"> <p>
											<span class="strong strong"><strong>Cores</strong></span>
										</p>
										 </td><td colspan="2" align="center" valign="top"> <p>
											0
										</p>
										 </td><td colspan="2" align="center" valign="top"> <p>
											1
										</p>
										 </td><td colspan="2" align="center" valign="top"> <p>
											2
										</p>
										 </td><td colspan="2" align="center" valign="top"> <p>
											3
										</p>
										 </td></tr><tr><td colspan="3" align="center" valign="top"> <p>
											<span class="strong strong"><strong>Sockets</strong></span>
										</p>
										 </td><td colspan="4" align="center" valign="top"> <p>
											0
										</p>
										 </td><td colspan="4" align="center" valign="top"> <p>
											1
										</p>
										 </td></tr><tr><td colspan="3" align="center" valign="top"> <p>
											<span class="strong strong"><strong>NUMA nodes</strong></span>
										</p>
										 </td><td colspan="4" align="center" valign="top"> <p>
											0
										</p>
										 </td><td colspan="4" align="center" valign="top"> <p>
											1
										</p>
										 </td></tr></tbody></table></rh-table><rh-table id="idm140280132257584"><table class="gt-8-cols lt-7-rows"><caption>Table 13.4. Combined host and VM topology</caption><colgroup><col style="width: 7%; " class="col_1"><!--Empty--><col style="width: 7%; " class="col_2"><!--Empty--><col style="width: 7%; " class="col_3"><!--Empty--><col style="width: 7%; " class="col_4"><!--Empty--><col style="width: 7%; " class="col_5"><!--Empty--><col style="width: 7%; " class="col_6"><!--Empty--><col style="width: 7%; " class="col_7"><!--Empty--><col style="width: 7%; " class="col_8"><!--Empty--><col style="width: 7%; " class="col_9"><!--Empty--><col style="width: 7%; " class="col_10"><!--Empty--><col style="width: 7%; " class="col_11"><!--Empty--><col style="width: 7%; " class="col_12"><!--Empty--><col style="width: 7%; " class="col_13"><!--Empty--><col style="width: 7%; " class="col_14"><!--Empty--><col style="width: 7%; " class="col_15"><!--Empty--></colgroup><tbody><tr><td colspan="3" align="center" valign="top"> <p>
											<span class="strong strong"><strong>vCPU threads</strong></span>
										</p>
										 </td><td colspan="2" align="center" valign="top"> </td><td align="left" valign="top"> <p>
											0
										</p>
										 </td><td align="left" valign="top"> <p>
											1
										</p>
										 </td><td align="left" valign="top"> <p>
											2
										</p>
										 </td><td align="left" valign="top"> <p>
											3
										</p>
										 </td><td colspan="2" align="center" valign="top"> </td><td align="left" valign="top"> <p>
											4
										</p>
										 </td><td align="left" valign="top"> <p>
											5
										</p>
										 </td><td align="left" valign="top"> <p>
											6
										</p>
										 </td><td align="left" valign="top"> <p>
											7
										</p>
										 </td></tr><tr><td colspan="3" align="center" valign="top"> <p>
											<span class="strong strong"><strong>Host CPU threads</strong></span>
										</p>
										 </td><td align="left" valign="top"> <p>
											0
										</p>
										 </td><td align="left" valign="top"> <p>
											3
										</p>
										 </td><td align="left" valign="top"> <p>
											1
										</p>
										 </td><td align="left" valign="top"> <p>
											4
										</p>
										 </td><td align="left" valign="top"> <p>
											2
										</p>
										 </td><td align="left" valign="top"> <p>
											5
										</p>
										 </td><td align="left" valign="top"> <p>
											6
										</p>
										 </td><td align="left" valign="top"> <p>
											9
										</p>
										 </td><td align="left" valign="top"> <p>
											7
										</p>
										 </td><td align="left" valign="top"> <p>
											10
										</p>
										 </td><td align="left" valign="top"> <p>
											8
										</p>
										 </td><td align="left" valign="top"> <p>
											11
										</p>
										 </td></tr><tr><td colspan="3" align="center" valign="top"> <p>
											<span class="strong strong"><strong>Cores</strong></span>
										</p>
										 </td><td colspan="2" align="center" valign="top"> <p>
											0
										</p>
										 </td><td colspan="2" align="center" valign="top"> <p>
											1
										</p>
										 </td><td colspan="2" align="center" valign="top"> <p>
											2
										</p>
										 </td><td colspan="2" align="center" valign="top"> <p>
											3
										</p>
										 </td><td colspan="2" align="center" valign="top"> <p>
											4
										</p>
										 </td><td colspan="2" align="center" valign="top"> <p>
											5
										</p>
										 </td></tr><tr><td colspan="3" align="center" valign="top"> <p>
											<span class="strong strong"><strong>Sockets</strong></span>
										</p>
										 </td><td colspan="6" align="center" valign="top"> <p>
											0
										</p>
										 </td><td colspan="6" align="center" valign="top"> <p>
											1
										</p>
										 </td></tr><tr><td colspan="3" align="center" valign="top"> <p>
											<span class="strong strong"><strong>NUMA nodes</strong></span>
										</p>
										 </td><td colspan="6" align="center" valign="top"> <p>
											0
										</p>
										 </td><td colspan="6" align="center" valign="top"> <p>
											1
										</p>
										 </td></tr></tbody></table></rh-table><p class="simpara">
							In this scenario, there are 2 NUMA nodes and 8 vCPUs. Therefore, 4 vCPU threads should be pinned to each node.
						</p><p class="simpara">
							In addition, Red Hat recommends leaving at least a single CPU thread available on each node for host system operations.
						</p><p class="simpara">
							Because in this example, each NUMA node houses 3 cores, each with 2 host CPU threads, the set for node 0 translates as follows:
						</p><pre class="programlisting language-xml">&lt;vcpupin vcpu='0' cpuset='1'/&gt;
&lt;vcpupin vcpu='1' cpuset='4'/&gt;
&lt;vcpupin vcpu='2' cpuset='2'/&gt;
&lt;vcpupin vcpu='3' cpuset='5'/&gt;</pre></li></ul></div></section><section class="section" id="proc_managing-ksm_optimizing-virtual-machine-cpu-performance"><div class="titlepage"><div><div><h4 class="title">13.6.5. Enabling and disabling kernel same-page merging</h4></div></div></div><p>
					Kernel Same-Page Merging (KSM) improves memory density by sharing identical memory pages between virtual machines (VMs). Therefore, enabling KSM might improve memory efficiency of your VM deployment.
				</p><p>
					However, enabling KSM also increases CPU utilization, and might negatively affect overall performance depending on the workload.
				</p><p>
					In RHEL 9 and later, KSM is disabled by default. To enable KSM and test its impact on your VM performance, see the following instructions.
				</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							Root access to your host system.
						</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Enable KSM:
						</p><rh-alert class="admonition warning" state="danger"><div class="admonition_header" slot="header">Warning</div><div><p>
								Enabling KSM increases CPU utilization and affects overall CPU performance.
							</p></div></rh-alert><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
									Install the <code class="literal">ksmtuned</code> service:
								</p><pre class="screen"># <span class="strong strong"><strong>{PackageManagerCommand} install ksmtuned</strong></span></pre></li><li class="listitem"><p class="simpara">
									Start the service:
								</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
											To enable KSM for a single session, use the <code class="literal">systemctl</code> utility to start the <code class="literal">ksm</code> and <code class="literal">ksmtuned</code> services.
										</p><pre class="screen"># <span class="strong strong"><strong>systemctl start ksm</strong></span>
# <span class="strong strong"><strong>systemctl start ksmtuned</strong></span></pre></li><li class="listitem"><p class="simpara">
											To enable KSM persistently, use the <code class="literal">systemctl</code> utility to enable the <code class="literal">ksm</code> and <code class="literal">ksmtuned</code> services.
										</p><pre class="screen"># <span class="strong strong"><strong>systemctl enable ksm</strong></span>
Created symlink /etc/systemd/system/multi-user.target.wants/ksm.service → /usr/lib/systemd/system/ksm.service

# <span class="strong strong"><strong>systemctl enable ksmtuned</strong></span>
Created symlink /etc/systemd/system/multi-user.target.wants/ksmtuned.service → /usr/lib/systemd/system/ksmtuned.service</pre></li></ul></div></li></ol></div></li><li class="listitem">
							Monitor the performance and resource consumption of VMs on your host to evaluate the benefits of activating KSM. Specifically, ensure that the additional CPU usage by KSM does not offset the memory improvements and does not cause additional performance issues. In latency-sensitive workloads, also pay attention to cross-NUMA page merges.
						</li><li class="listitem"><p class="simpara">
							Optional: If KSM has not improved your VM performance, disable it:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									To disable KSM for a single session, use the <code class="literal">systemctl</code> utility to stop <code class="literal">ksm</code> and <code class="literal">ksmtuned</code> services.
								</p><pre class="screen"># <span class="strong strong"><strong>systemctl stop ksm</strong></span>
# <span class="strong strong"><strong>systemctl stop ksmtuned</strong></span></pre></li><li class="listitem"><p class="simpara">
									To disable KSM persistently, use the <code class="literal">systemctl</code> utility to disable <code class="literal">ksm</code> and <code class="literal">ksmtuned</code> services.
								</p><pre class="screen"># <span class="strong strong"><strong>systemctl disable ksm</strong></span>
Removed /etc/systemd/system/multi-user.target.wants/ksm.service.
# <span class="strong strong"><strong>systemctl disable ksmtuned</strong></span>
Removed /etc/systemd/system/multi-user.target.wants/ksmtuned.service.</pre></li></ul></div></li></ol></div><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
						Memory pages shared between VMs before deactivating KSM will remain shared. To stop sharing, delete all the <code class="literal">PageKSM</code> pages in the system by using the following command:
					</p><pre class="screen"># <span class="strong strong"><strong>echo 2 &gt; /sys/kernel/mm/ksm/run</strong></span></pre><p>
						However, this command increases memory usage, and might cause performance problems on your host or your VMs.
					</p></div></rh-alert></section></section><section class="section" id="optimizing-virtual-machine-network-performance_optimizing-virtual-machine-performance-in-rhel"><div class="titlepage"><div><div><h3 class="title">13.7. Optimizing virtual machine network performance</h3></div></div></div><p>
				Due to the virtual nature of a VM’s network interface card (NIC), the VM loses a portion of its allocated host network bandwidth, which can reduce the overall workload efficiency of the VM. The following tips can minimize the negative impact of virtualization on the virtual NIC (vNIC) throughput.
			</p><div class="formalpara"><p class="title"><strong>Procedure</strong></p><p>
					Use any of the following methods and observe if it has a beneficial effect on your VM network performance:
				</p></div><div class="variablelist"><dl class="variablelist"><dt><span class="term">Enable the vhost_net module</span></dt><dd><p class="simpara">
							On the host, ensure the <code class="literal">vhost_net</code> kernel feature is enabled:
						</p><pre class="screen"># <span class="strong strong"><strong>lsmod | grep vhost</strong></span>
vhost_net              32768  1
vhost                  53248  1 vhost_net
tap                    24576  1 vhost_net
tun                    57344  6 vhost_net</pre><p class="simpara">
							If the output of this command is blank, enable the <code class="literal">vhost_net</code> kernel module:
						</p><pre class="screen"># <span class="strong strong"><strong>modprobe vhost_net</strong></span></pre></dd><dt><span class="term">Set up multi-queue virtio-net</span></dt><dd><p class="simpara">
							To set up the <span class="emphasis"><em>multi-queue virtio-net</em></span> feature for a VM, use the <code class="literal">virsh edit</code> command to edit to the XML configuration of the VM. In the XML, add the following to the <code class="literal">&lt;devices&gt;</code> section, and replace <code class="literal">N</code> with the number of vCPUs in the VM, up to 16:
						</p><pre class="screen">&lt;interface type='network'&gt;
      &lt;source network='default'/&gt;
      &lt;model type='virtio'/&gt;
      &lt;driver name='vhost' queues='N'/&gt;
&lt;/interface&gt;</pre><p class="simpara">
							If the VM is running, restart it for the changes to take effect.
						</p></dd><dt><span class="term">Batching network packets</span></dt><dd><p class="simpara">
							In Linux VM configurations with a long transmission path, batching packets before submitting them to the kernel may improve cache utilization. To set up packet batching, use the following command on the host, and replace <span class="emphasis"><em>tap0</em></span> with the name of the network interface that the VMs use:
						</p><pre class="screen"># <span class="strong strong"><strong>ethtool -C <span class="emphasis"><em>tap0</em></span> rx-frames 64</strong></span></pre></dd><dt><span class="term">SR-IOV</span></dt><dd>
							If your host NIC supports SR-IOV, use SR-IOV device assignment for your vNICs. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/managing-virtual-devices_configuring-and-managing-virtualization#managing-sr-iov-devices_managing-virtual-devices">Managing SR-IOV devices</a>.
						</dd></dl></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/configuring-virtual-machine-network-connections_configuring-and-managing-virtualization#understanding-virtual-networking-overview_configuring-virtual-machine-network-connections">Understanding virtual networking</a>
					</li></ul></div></section><section class="section" id="virtual-machine-performance-monitoring-tools_optimizing-virtual-machine-performance-in-rhel"><div class="titlepage"><div><div><h3 class="title">13.8. Virtual machine performance monitoring tools</h3></div></div></div><p>
				To identify what consumes the most VM resources and which aspect of VM performance needs optimization, performance diagnostic tools, both general and VM-specific, can be used.
			</p><div class="formalpara"><p class="title"><strong>Default OS performance monitoring tools</strong></p><p>
					For standard performance evaluation, you can use the utilities provided by default by your host and guest operating systems:
				</p></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						On your RHEL 9 host, as root, use the <code class="literal">top</code> utility or the <span class="strong strong"><strong>system monitor</strong></span> application, and look for <code class="literal">qemu</code> and <code class="literal">virt</code> in the output. This shows how much host system resources your VMs are consuming.
					</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
								If the monitoring tool displays that any of the <code class="literal">qemu</code> or <code class="literal">virt</code> processes consume a large portion of the host CPU or memory capacity, use the <code class="literal">perf</code> utility to investigate. For details, see below.
							</li><li class="listitem">
								In addition, if a <code class="literal">vhost_net</code> thread process, named for example <span class="emphasis"><em>vhost_net-1234</em></span>, is displayed as consuming an excessive amount of host CPU capacity, consider using <a class="link" href="#optimizing-virtual-machine-network-performance_optimizing-virtual-machine-performance-in-rhel" title="13.7. Optimizing virtual machine network performance">virtual network optimization features</a>, such as <code class="literal">multi-queue virtio-net</code>.
							</li></ul></div></li><li class="listitem"><p class="simpara">
						On the guest operating system, use performance utilities and applications available on the system to evaluate which processes consume the most system resources.
					</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
								On Linux systems, you can use the <code class="literal">top</code> utility.
							</li><li class="listitem">
								On Windows systems, you can use the <span class="strong strong"><strong>Task Manager</strong></span> application.
							</li></ul></div></li></ul></div><div class="formalpara"><p class="title"><strong>perf kvm</strong></p><p>
					You can use the <code class="literal">perf</code> utility to collect and analyze virtualization-specific statistics about the performance of your RHEL 9 host. To do so:
				</p></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						On the host, install the <span class="emphasis"><em>perf</em></span> package:
					</p><pre class="screen"># <span class="strong strong"><strong>dnf install perf</strong></span></pre></li><li class="listitem"><p class="simpara">
						Use one of the <code class="literal">perf kvm stat</code> commands to display perf statistics for your virtualization host:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								For real-time monitoring of your hypervisor, use the <code class="literal">perf kvm stat live</code> command.
							</li><li class="listitem">
								To log the perf data of your hypervisor over a period of time, activate the logging by using the <code class="literal">perf kvm stat record</code> command. After the command is canceled or interrupted, the data is saved in the <code class="literal">perf.data.guest</code> file, which can be analyzed by using the <code class="literal">perf kvm stat report</code> command.
							</li></ul></div></li><li class="listitem"><p class="simpara">
						Analyze the <code class="literal">perf</code> output for types of <code class="literal">VM-EXIT</code> events and their distribution. For example, the <code class="literal">PAUSE_INSTRUCTION</code> events should be infrequent, but in the following output, the high occurrence of this event suggests that the host CPUs are not handling the running vCPUs well. In such a scenario, consider shutting down some of your active VMs, removing vCPUs from these VMs, or <a class="link" href="#optimizing-virtual-machine-cpu-performance_optimizing-virtual-machine-performance-in-rhel" title="13.6. Optimizing virtual machine CPU performance">tuning the performance of the vCPUs</a>.
					</p><pre class="screen"># <span class="strong strong"><strong>perf kvm stat report</strong></span>

Analyze events for all VMs, all VCPUs:


             VM-EXIT    Samples  Samples%     Time%    Min Time    Max Time         Avg time

  EXTERNAL_INTERRUPT     365634    31.59%    18.04%      0.42us  58780.59us    204.08us ( +-   0.99% )
           MSR_WRITE     293428    25.35%     0.13%      0.59us  17873.02us      1.80us ( +-   4.63% )
    PREEMPTION_TIMER     276162    23.86%     0.23%      0.51us  21396.03us      3.38us ( +-   5.19% )
   PAUSE_INSTRUCTION     189375    16.36%    11.75%      0.72us  29655.25us    256.77us ( +-   0.70% )
                 HLT      20440     1.77%    69.83%      0.62us  79319.41us  14134.56us ( +-   0.79% )
              VMCALL      12426     1.07%     0.03%      1.02us   5416.25us      8.77us ( +-   7.36% )
       EXCEPTION_NMI         27     0.00%     0.00%      0.69us      1.34us      0.98us ( +-   3.50% )
       EPT_MISCONFIG          5     0.00%     0.00%      5.15us     10.85us      7.88us ( +-  11.67% )

Total Samples:1157497, Total events handled time:413728274.66us.</pre><p class="simpara">
						Other event types that can signal problems in the output of <code class="literal">perf kvm stat</code> include:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								<code class="literal">INSN_EMULATION</code> - suggests suboptimal <a class="link" href="#optimizing-virtual-machine-i-o-performance_optimizing-virtual-machine-performance-in-rhel" title="13.5. Optimizing virtual machine I/O performance">VM I/O configuration</a>.
							</li></ul></div></li></ol></div><p>
				For more information about using <code class="literal">perf</code> to monitor virtualization performance, see the <code class="literal">perf-kvm</code> man page on your system.
			</p><div class="formalpara"><p class="title"><strong>numastat</strong></p><p>
					To see the current NUMA configuration of your system, you can use the <code class="literal">numastat</code> utility, which is provided by installing the <span class="strong strong"><strong>numactl</strong></span> package.
				</p></div><p>
				The following shows a host with 4 running VMs, each obtaining memory from multiple NUMA nodes. This is not optimal for vCPU performance, and <a class="link" href="#configuring-numa-in-a-virtual-machine_optimizing-virtual-machine-cpu-performance" title="13.6.3. Configuring NUMA in a virtual machine">warrants adjusting</a>:
			</p><pre class="screen"># <span class="strong strong"><strong>numastat -c qemu-kvm</strong></span>

Per-node process memory usage (in MBs)
PID              Node 0 Node 1 Node 2 Node 3 Node 4 Node 5 Node 6 Node 7 Total
---------------  ------ ------ ------ ------ ------ ------ ------ ------ -----
51722 (qemu-kvm)     68     16    357   6936      2      3    147    598  8128
51747 (qemu-kvm)    245     11      5     18   5172   2532      1     92  8076
53736 (qemu-kvm)     62    432   1661    506   4851    136     22    445  8116
53773 (qemu-kvm)   1393      3      1      2     12      0      0   6702  8114
---------------  ------ ------ ------ ------ ------ ------ ------ ------ -----
Total              1769    463   2024   7462  10037   2672    169   7837 32434</pre><p>
				In contrast, the following shows memory being provided to each VM by a single node, which is significantly more efficient.
			</p><pre class="screen"># <span class="strong strong"><strong>numastat -c qemu-kvm</strong></span>

Per-node process memory usage (in MBs)
PID              Node 0 Node 1 Node 2 Node 3 Node 4 Node 5 Node 6 Node 7 Total
---------------  ------ ------ ------ ------ ------ ------ ------ ------ -----
51747 (qemu-kvm)      0      0      7      0   8072      0      1      0  8080
53736 (qemu-kvm)      0      0      7      0      0      0   8113      0  8120
53773 (qemu-kvm)      0      0      7      0      0      0      1   8110  8118
59065 (qemu-kvm)      0      0   8050      0      0      0      0      0  8051
---------------  ------ ------ ------ ------ ------ ------ ------ ------ -----
Total                 0      0   8072      0   8072      0   8114   8110 32368</pre></section><section class="section _additional-resources" id="related-information-optimizing-virtual-machine-performance-in-rhel"><div class="titlepage"><div><div><h3 class="title">13.9. Additional resources</h3></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/configuring_and_managing_virtualization/index#optimizing-windows-virtual-machines-on-rhel_installing-and-managing-windows-virtual-machines-on-rhel">Optimizing Windows virtual machines</a>
					</li></ul></div></section></section><section class="chapter" id="importance-of-power-management_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 14. Importance of power management</h2></div></div></div><p class="_abstract _abstract">
			Reducing the overall power consumption of computer systems helps to save cost. Effectively optimizing energy consumption of each system component includes studying different tasks that your system performs, and configuring each component to ensure that its performance is correct for that job. Lowering the power consumption of a specific component or of the system as a whole leads to lower heat and performance.
		</p><p>
			Proper power management results in:
		</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
					heat reduction for servers and computing centers
				</li><li class="listitem">
					reduced secondary costs, including cooling, space, cables, generators, and uninterruptible power supplies (UPS)
				</li><li class="listitem">
					extended battery life for laptops
				</li><li class="listitem">
					lower carbon dioxide output
				</li><li class="listitem">
					meeting government regulations or legal requirements regarding Green IT, for example, Energy Star
				</li><li class="listitem">
					meeting company guidelines for new systems
				</li></ul></div><p>
			This section describes the information regarding power management of your Red Hat Enterprise Linux systems.
		</p><section class="section" id="power-management-basics_importance-of-power-management"><div class="titlepage"><div><div><h3 class="title">14.1. Power management basics</h3></div></div></div><p class="_abstract _abstract">
				Effective power management is built on the following principles:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">An idle CPU should only wake up when needed</code></span></dt><dd><p class="simpara">
							Since Red Hat Enterprise Linux 6, the kernel runs <code class="literal">tickless</code>, which means the previous periodic timer interrupts have been replaced with on-demand interrupts. Therefore, idle CPUs are allowed to remain idle until a new task is queued for processing, and CPUs that have entered lower power states can remain in these states longer. However, benefits from this feature can be offset if your system has applications that create unnecessary timer events. Polling events, such as checks for volume changes or mouse movement, are examples of such events.
						</p><p class="simpara">
							Red Hat Enterprise Linux includes tools using which you can identify and audit applications on the basis of their CPU usage. For more information see, <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index#audit-and-analysis-overview_importance-of-power-management">Audit and analysis overview</a> and <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index#tools-for-auditing_importance-of-power-management">Tools for auditing</a>.
						</p></dd><dt><span class="term"><code class="literal">Unused hardware and devices should be disabled completely</code></span></dt><dd>
							This is true for devices that have moving parts, for example, hard disks. In addition to this, some applications may leave an unused but enabled device "open"; when this occurs, the kernel assumes that the device is in use, which can prevent the device from going into a power saving state.
						</dd><dt><span class="term"><code class="literal">Low activity should translate to low wattage</code></span></dt><dd><p class="simpara">
							In many cases, however, this depends on modern hardware and correct BIOS configuration or UEFI on modern systems, including non-x86 architectures. Make sure that you are using the latest official firmware for your systems and that in the power management or device configuration sections of the BIOS the power management features are enabled. Some features to look for include:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									Collaborative Processor Performance Controls (CPPC) support for ARM64
								</li><li class="listitem">
									PowerNV support for IBM Power Systems
								</li><li class="listitem">
									SpeedStep
								</li><li class="listitem">
									PowerNow!
								</li><li class="listitem">
									Cool’n’Quiet
								</li><li class="listitem">
									ACPI (C-state)
								</li><li class="listitem"><p class="simpara">
									Smart
								</p><p class="simpara">
									If your hardware has support for these features and they are enabled in the BIOS, Red Hat Enterprise Linux uses them by default.
								</p></li></ul></div></dd><dt><span class="term"><code class="literal">Different forms of CPU states and their effects</code></span></dt><dd><p class="simpara">
							Modern CPUs together with Advanced Configuration and Power Interface (ACPI) provide different power states. The three different states are:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									Sleep (C-states)
								</li><li class="listitem">
									Frequency and voltage (P-states)
								</li><li class="listitem"><p class="simpara">
									Heat output (T-states or thermal states)
								</p><p class="simpara">
									A CPU running on the lowest sleep state, consumes the least amount of watts, but it also takes considerably more time to wake it up from that state when needed. In very rare cases this can lead to the CPU having to wake up immediately every time it just went to sleep. This situation results in an effectively permanently busy CPU and loses some of the potential power saving if another state had been used.
								</p></li></ul></div></dd><dt><span class="term"><code class="literal">A turned off machine uses the least amount of power</code></span></dt><dd>
							One of the best ways to save power is to turn off systems. For example, your company can develop a corporate culture focused on "green IT" awareness with a guideline to turn off machines during lunch break or when going home. You also might consolidate several physical servers into one bigger server and virtualize them using the virtualization technology, which is shipped with Red Hat Enterprise Linux.
						</dd></dl></div></section><section class="section" id="audit-and-analysis-overview_importance-of-power-management"><div class="titlepage"><div><div><h3 class="title">14.2. Audit and analysis overview</h3></div></div></div><p class="_abstract _abstract">
				The detailed manual audit, analysis, and tuning of a single system is usually the exception because the time and cost spent to do so typically outweighs the benefits gained from these last pieces of system tuning.
			</p><p>
				However, performing these tasks once for a large number of nearly identical systems where you can reuse the same settings for all systems can be very useful. For example, consider the deployment of thousands of desktop systems, or an HPC cluster where the machines are nearly identical. Another reason to do auditing and analysis is to provide a basis for comparison against which you can identify regressions or changes in system behavior in the future. The results of this analysis can be very helpful in cases where hardware, BIOS, or software updates happen regularly and you want to avoid any surprises with regard to power consumption. Generally, a thorough audit and analysis gives you a much better idea of what is really happening on a particular system.
			</p><p>
				Auditing and analyzing a system with regard to power consumption is relatively hard, even with the most modern systems available. Most systems do not provide the necessary means to measure power use via software. Exceptions exist though:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						iLO management console of Hewlett Packard server systems has a power management module that you can access through the web.
					</li><li class="listitem">
						IBM provides a similar solution in their BladeCenter power management module.
					</li><li class="listitem">
						On some Dell systems, the IT Assistant offers power monitoring capabilities as well.
					</li></ul></div><p>
				Other vendors are likely to offer similar capabilities for their server platforms, but as can be seen there is no single solution available that is supported by all vendors. Direct measurements of power consumption are often only necessary to maximize savings as far as possible.
			</p></section><section class="section" id="tools-for-auditing_importance-of-power-management"><div class="titlepage"><div><div><h3 class="title">14.3. Tools for auditing</h3></div></div></div><p class="_abstract _abstract">
				Red Hat Enterprise Linux 8 offers tools using which you can perform system auditing and analysis. Most of them can be used as supplementary sources of information in case you want to verify what you have discovered already or in case you need more in-depth information about certain parts.
			</p><p>
				Many of these tools are used for performance tuning as well, which include:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">PowerTOP</code></span></dt><dd>
							It identifies specific components of kernel and user-space applications that frequently wake up the CPU. Use the <code class="literal">powertop</code> command as root to start the <span class="strong strong"><strong>PowerTop</strong></span> tool and <code class="literal">powertop --calibrate</code> to calibrate the power estimation engine. For more information about PowerTop, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index#managing-power-consumption-with-powertop_monitoring-and-managing-system-status-and-performance">Managing power consumption with PowerTOP</a>.
						</dd><dt><span class="term"><code class="literal">Diskdevstat and netdevstat</code></span></dt><dd><p class="simpara">
							They are SystemTap tools that collect detailed information about the disk activity and network activity of all applications running on a system. Using the collected statistics by these tools, you can identify applications that waste power with many small I/O operations rather than fewer, larger operations. Using the <code class="literal">dnf install tuned-utils-systemtap kernel-debuginfo</code> command as root, install the <code class="literal">diskdevstat</code> and <code class="literal">netdevstat</code> tool.
						</p><p class="simpara">
							To view the detailed information about the disk and network activity, use:
						</p><pre class="literallayout white-space-pre"># diskdevstat

PID   UID   DEV   WRITE_CNT   WRITE_MIN   WRITE_MAX   WRITE_AVG   READ_CNT   READ_MIN   READ_MAX   READ_AVG   COMMAND

3575  1000  dm-2   59          0.000      0.365        0.006        5         0.000        0.000      0.000      mozStorage #5
3575  1000  dm-2    7          0.000      0.000        0.000        0         0.000        0.000      0.000      localStorage DB
[...]


# netdevstat

PID   UID   DEV       XMIT_CNT   XMIT_MIN   XMIT_MAX   XMIT_AVG   RECV_CNT   RECV_MIN   RECV_MAX   RECV_AVG   COMMAND
3572  991  enp0s31f6    40       0.000      0.882       0.108        0         0.000       0.000       0.000     openvpn
3575  1000 enp0s31f6    27       0.000      1.363       0.160        0         0.000       0.000       0.000     Socket Thread
[...]</pre><p class="simpara">
							With these commands, you can specify three parameters: <code class="literal">update_interval</code>, <code class="literal">total_duration</code>, and <code class="literal">display_histogram</code>.
						</p></dd><dt><span class="term"><code class="literal">TuneD</code></span></dt><dd>
							It is a profile-based system tuning tool that uses the <code class="literal">udev</code> device manager to monitor connected devices, and enables both static and dynamic tuning of system settings. You can use the <code class="literal">tuned-adm recommend</code> command to determine which profile Red Hat recommends as the most suitable for a particular product. For more information about TuneD, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index#getting-started-with-tuned_monitoring-and-managing-system-status-and-performance">Getting started with TuneD</a> and <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index#customizing-tuned-profiles_monitoring-and-managing-system-status-and-performance">Customizing TuneD profiles</a>. Using the <code class="literal">powertop2tuned utility</code>, you can create custom TuneD profiles from <code class="literal">PowerTOP</code> suggestions. For information about the <code class="literal">powertop2tuned</code> utility, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index#optimizing-power-consumption_managing-power-consumption-with-powertop">Optimizing power consumption</a>.
						</dd><dt><span class="term"><code class="literal">Virtual memory statistics (vmstat)</code></span></dt><dd><p class="simpara">
							It is provided by the <code class="literal">procps-ng</code> package. Using this tool, you can view the detailed information about processes, memory, paging, block I/O, traps, and CPU activity.
						</p><p class="simpara">
							To view this information, use:
						</p><pre class="literallayout white-space-pre">$ vmstat
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
r  b  swpd  free    buff   cache   si   so  bi   bo   in  cs  us  sy id  wa  st
1  0   0   5805576 380856 4852848   0    0  119  73  814  640  2   2 96   0   0</pre><p class="simpara">
							Using the <code class="literal">vmstat -a</code> command, you can display active and inactive memory. For more information about other <code class="literal">vmstat</code> options, see the <code class="literal">vmstat</code> man page on your system.
						</p></dd><dt><span class="term"><code class="literal">iostat</code></span></dt><dd><p class="simpara">
							It is provided by the <code class="literal">sysstat</code> package. This tool is similar to <code class="literal">vmstat</code>, but only for monitoring I/O on block devices. It also provides more verbose output and statistics.
						</p><p class="simpara">
							To monitor the system I/O, use:
						</p><pre class="literallayout white-space-pre">$ iostat
avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           2.05    0.46    1.55    0.26    0.00   95.67

Device     tps     kB_read/s    kB_wrtn/s    kB_read    kB_wrtn
nvme0n1    53.54     899.48     616.99      3445229     2363196
dm-0       42.84     753.72     238.71      2886921      914296
dm-1        0.03       0.60       0.00         2292           0
dm-2       24.15     143.12     379.80       548193     1454712</pre></dd><dt><span class="term"><code class="literal">blktrace</code></span></dt><dd><p class="simpara">
							It provides detailed information about how time is spent in the I/O subsystem.
						</p><p class="simpara">
							To view this information in human readable format, use:
						</p><pre class="literallayout white-space-pre"># blktrace -d /dev/dm-0 -o - | blkparse -i -

253,0   1    1   0.000000000  17694  Q   W 76423384 + 8 [kworker/u16:1]
253,0   2    1   0.001926913     0   C   W 76423384 + 8 [0]
[...]</pre><p class="simpara">
							Here, The first column, <span class="strong strong"><strong>253,0</strong></span> is the device major and minor tuple. The second column, <span class="strong strong"><strong>1</strong></span>, gives information about the CPU, followed by columns for timestamps and PID of the process issuing the IO process.
						</p><p class="simpara">
							The sixth column, <span class="strong strong"><strong>Q</strong></span>, shows the event type, the 7th column, <span class="strong strong"><strong>W</strong></span> for write operation, the 8th column, <span class="strong strong"><strong>76423384</strong></span>, is the block number, and the <span class="strong strong"><strong>+ 8</strong></span> is the number of requested blocks.
						</p><p class="simpara">
							The last field, <span class="strong strong"><strong>[kworker/u16:1]</strong></span>, is the process name.
						</p><p class="simpara">
							By default, the <code class="literal">blktrace</code> command runs forever until the process is explicitly killed. Use the <code class="literal">-w</code> option to specify the run-time duration.
						</p></dd><dt><span class="term"><code class="literal">turbostat</code></span></dt><dd><p class="simpara">
							It is provided by the <code class="literal">kernel-tools</code> package. It reports on processor topology, frequency, idle power-state statistics, temperature, and power usage on x86-64 processors.
						</p><p class="simpara">
							To view this summary, use:
						</p><pre class="literallayout white-space-pre"># turbostat

CPUID(0): GenuineIntel 0x16 CPUID levels; 0x80000008 xlevels; family:model:stepping 0x6:8e:a (6:142:10)
CPUID(1): SSE3 MONITOR SMX EIST TM2 TSC MSR ACPI-TM HT TM
CPUID(6): APERF, TURBO, DTS, PTM, HWP, HWPnotify, HWPwindow, HWPepp, No-HWPpkg, EPB
[...]</pre><p class="simpara">
							By default, <code class="literal">turbostat</code> prints a summary of counter results for the entire screen, followed by counter results every 5 seconds. Specify a different period between counter results with the <code class="literal">-i</code> option, for example, execute <code class="literal">turbostat -i 10</code> to print results every 10 seconds instead.
						</p><p class="simpara">
							<span class="strong strong"><strong>Turbostat</strong></span> is also useful for identifying servers that are inefficient in terms of power usage or idle time. It also helps to identify the rate of system management interrupts (SMIs) occurring on the system. It can also be used to verify the effects of power management tuning.
						</p></dd><dt><span class="term"><code class="literal">cpupower</code></span></dt><dd><p class="simpara">
							IT is a collection of tools to examine and tune power saving related features of processors. Use the <code class="literal">cpupower</code> command with the <code class="literal">frequency-info</code>, <code class="literal">frequency-set</code>, <code class="literal">idle-info</code>, <code class="literal">idle-set</code>, <code class="literal">set</code>, <code class="literal">info</code>, and <code class="literal">monitor</code> options to display and set processor related values.
						</p><p class="simpara">
							For example, to view available cpufreq governors, use:
						</p><pre class="literallayout white-space-pre">$ cpupower frequency-info --governors
analyzing CPU 0:
  available cpufreq governors: performance powersave</pre><p class="simpara">
							For more information about <code class="literal">cpupower</code>, see Viewing CPU related information.
						</p></dd><dt><span class="term"><code class="literal">GNOME Power Manager</code></span></dt><dd>
							It is a daemon that is installed as part of the GNOME desktop environment. GNOME Power Manager notifies you of changes in your system’s power status; for example, a change from battery to AC power. It also reports battery status, and warns you when battery power is low.
						</dd></dl></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">powertop(1)</code>, <code class="literal">diskdevstat(8)</code>, <code class="literal">netdevstat(8)</code>, <code class="literal">tuned(8)</code>, <code class="literal">vmstat(8)</code>, <code class="literal">iostat(1)</code>, <code class="literal">blktrace(8)</code>, <code class="literal">blkparse(8)</code>, and <code class="literal">turbostat(8)</code> man pages on your system
					</li><li class="listitem">
						<code class="literal">cpupower(1)</code>, <code class="literal">cpupower-set(1)</code>, <code class="literal">cpupower-info(1)</code>, <code class="literal">cpupower-idle(1)</code>, <code class="literal">cpupower-frequency-set(1)</code>, <code class="literal">cpupower-frequency-info(1)</code>, and <code class="literal">cpupower-monitor(1)</code> man pages on your system
					</li></ul></div></section></section><section class="chapter" id="managing-power-consumption-with-powertop_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 15. Managing power consumption with PowerTOP</h2></div></div></div><p>
			As a system administrator, you can use the <span class="strong strong"><strong><span class="application application">PowerTOP</span></strong></span> tool to analyze and manage power consumption.
		</p><section class="section" id="the-purpose-of-powertop_managing-power-consumption-with-powertop"><div class="titlepage"><div><div><h3 class="title">15.1. The purpose of PowerTOP</h3></div></div></div><p>
				<span class="strong strong"><strong><span class="application application">PowerTOP</span></strong></span> is a program that diagnoses issues related to power consumption and provides suggestions on how to extend battery lifetime.
			</p><p>
				The <span class="strong strong"><strong><span class="application application">PowerTOP</span></strong></span> tool can provide an estimate of the total power usage of the system and also individual power usage for each process, device, kernel worker, timer, and interrupt handler. The tool can also identify specific components of kernel and user-space applications that frequently wake up the CPU.
			</p><p>
				Red Hat Enterprise Linux 9 uses version 2.x of <span class="strong strong"><strong><span class="application application">PowerTOP</span></strong></span>.
			</p></section><section class="section" id="using-powertop_managing-power-consumption-with-powertop"><div class="titlepage"><div><div><h3 class="title">15.2. Using PowerTOP</h3></div></div></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						To be able to use <span class="strong strong"><strong><span class="application application">PowerTOP</span></strong></span>, make sure that the <code class="literal package">powertop</code> package has been installed on your system:
					</p><pre class="screen"># dnf install powertop</pre></li></ul></div><section class="section" id="starting-powertop_using-powertop"><div class="titlepage"><div><div><h4 class="title">15.2.1. Starting PowerTOP</h4></div></div></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							To run <span class="strong strong"><strong><span class="application application">PowerTOP</span></strong></span>, use the following command:
						</p><pre class="literallayout"># <span class="strong strong"><strong>powertop</strong></span></pre></li></ul></div><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
						Laptops should run on battery power when running the <code class="literal package">powertop</code> command.
					</p></div></rh-alert></section><section class="section" id="calibrating-powertop_using-powertop"><div class="titlepage"><div><div><h4 class="title">15.2.2. Calibrating PowerTOP</h4></div></div></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							On a laptop, you can calibrate the power estimation engine by running the following command:
						</p><pre class="literallayout"># <span class="strong strong"><strong>powertop --calibrate</strong></span></pre></li><li class="listitem"><p class="simpara">
							Let the calibration finish without interacting with the machine during the process.
						</p><p class="simpara">
							Calibration takes time because the process performs various tests, cycles through brightness levels and switches devices on and off.
						</p></li><li class="listitem"><p class="simpara">
							When the calibration process is completed, <span class="strong strong"><strong><span class="application application">PowerTOP</span></strong></span> starts as normal. Let it run for approximately an hour to collect data.
						</p><p class="simpara">
							When enough data is collected, power estimation figures will be displayed in the first column of the output table.
						</p></li></ol></div><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
						Note that <code class="literal command">powertop --calibrate</code> can only be used on laptops.
					</p></div></rh-alert></section><section class="section" id="setting-the-measuring-interval_using-powertop"><div class="titlepage"><div><div><h4 class="title">15.2.3. Setting the measuring interval</h4></div></div></div><p>
					By default, <span class="strong strong"><strong><span class="application application">PowerTOP</span></strong></span> takes measurements in 20 seconds intervals.
				</p><p>
					If you want to change this measuring frequency, use the following procedure:
				</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							Run the <code class="literal command">powertop</code> command with the <code class="literal option">--time</code> option:
						</p><pre class="literallayout"># <span class="strong strong"><strong>powertop --time=<span class="emphasis"><em><span class="replaceable replaceable">time in seconds</span></em></span></strong></span></pre></li></ul></div></section><section class="section _additional-resources" id="related-information-using-powertop"><div class="titlepage"><div><div><h4 class="title">15.2.4. Additional resources</h4></div></div></div><p>
					For more details on how to use <span class="strong strong"><strong><span class="application application">PowerTOP</span></strong></span>, see the <code class="literal">powertop</code> man page on your system
				</p></section></section><section class="section" id="powertop-statistics_managing-power-consumption-with-powertop"><div class="titlepage"><div><div><h3 class="title">15.3. PowerTOP statistics</h3></div></div></div><p>
				While it runs, <span class="strong strong"><strong><span class="application application">PowerTOP</span></strong></span> gathers statistics from the system.
			</p><p>
				<span class="strong strong"><strong><span class="application application">PowerTOP</span></strong></span>'s output provides multiple tabs:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						<code class="literal">Overview</code>
					</li><li class="listitem">
						<code class="literal">Idle stats</code>
					</li><li class="listitem">
						<code class="literal">Frequency stats</code>
					</li><li class="listitem">
						<code class="literal">Device stats</code>
					</li><li class="listitem">
						<code class="literal">Tunables</code>
					</li><li class="listitem">
						<code class="literal">WakeUp</code>
					</li></ul></div><p>
				You can use the <code class="literal">Tab</code> and <code class="literal">Shift+Tab</code> keys to cycle through these tabs.
			</p><section class="section" id="overview-tab_managing-power-consumption-with-powertop"><div class="titlepage"><div><div><h4 class="title">15.3.1. The Overview tab</h4></div></div></div><p>
					In the <code class="literal">Overview</code> tab, you can view a list of the components that either send wakeups to the CPU most frequently or consume the most power. The items within the <code class="literal">Overview</code> tab, including processes, interrupts, devices, and other resources, are sorted according to their utilization.
				</p><p>
					The adjacent columns within the <code class="literal">Overview</code> tab provide the following pieces of information:
				</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">Usage</span></dt><dd>
								Power estimation of how the resource is being used.
							</dd><dt><span class="term">Events/s</span></dt><dd>
								Wakeups per second. The number of wakeups per second indicates how efficiently the services or the devices and drivers of the kernel are performing. Less wakeups means that less power is consumed. Components are ordered by how much further their power usage can be optimized.
							</dd><dt><span class="term">Category</span></dt><dd>
								Classification of the component; such as process, device, or timer.
							</dd><dt><span class="term">Description</span></dt><dd>
								Description of the component.
							</dd></dl></div><p>
					If properly calibrated, a power consumption estimation for every listed item in the first column is shown as well.
				</p><p>
					Apart from this, the <code class="literal">Overview</code> tab includes the line with summary statistics such as:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Total power consumption
						</li><li class="listitem">
							Remaining battery life (only if applicable)
						</li><li class="listitem">
							Summary of total wakeups per second, GPU operations per second, and virtual file system operations per second
						</li></ul></div></section><section class="section" id="idle-stats-tab_managing-power-consumption-with-powertop"><div class="titlepage"><div><div><h4 class="title">15.3.2. The Idle stats tab</h4></div></div></div><p>
					The <code class="literal">Idle stats</code> tab shows usage of C-states for all processors and cores, while the <code class="literal">Frequency stats</code> tab shows usage of P-states including the Turbo mode, if applicable, for all processors and cores. The duration of C- or P-states is an indication of how well the CPU usage has been optimized. The longer the CPU stays in the higher C- or P-states (for example C4 is higher than C3), the better the CPU usage optimization is. Ideally, residency is 90% or more in the highest C- or P-state when the system is idle.
				</p></section><section class="section" id="device-stats-tab_managing-power-consumption-with-powertop"><div class="titlepage"><div><div><h4 class="title">15.3.3. The Device stats tab</h4></div></div></div><p>
					The <code class="literal">Device stats</code> tab provides similar information to the <code class="literal">Overview</code> tab but only for devices.
				</p></section><section class="section" id="tunables-tab_managing-power-consumption-with-powertop"><div class="titlepage"><div><div><h4 class="title">15.3.4. The Tunables tab</h4></div></div></div><p>
					The <code class="literal">Tunables</code> tab contains <span class="strong strong"><strong><span class="application application">PowerTOP</span></strong></span>'s suggestions for optimizing the system for lower power consumption.
				</p><p>
					Use the <code class="literal">up</code> and <code class="literal">down</code> keys to move through suggestions, and the <code class="literal">enter</code> key to toggle the suggestion on or off.
				</p></section><section class="section" id="wakeup-tab_managing-power-consumption-with-powertop"><div class="titlepage"><div><div><h4 class="title">15.3.5. The WakeUp tab</h4></div></div></div><p>
					The <code class="literal">WakeUp</code> tab displays the device wakeup settings available for users to change as and when required.
				</p><p>
					Use the <code class="literal">up</code> and <code class="literal">down</code> keys to move through the available settings, and the <code class="literal">enter</code> key to enable or disable a setting.
				</p><div class="figure" id="idm140280139869856"><p class="title"><strong>Figure 15.1. PowerTOP output</strong></p><div class="figure-contents"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/99b231a090ded326ccc3823ca0f7f134/powertop2-14.png" alt="powertop2 14"></div></div></div><div class="_additional-resources _additional-resources"><p class="title"><strong>Additional resources</strong></p><p>
						For more details on <span class="strong strong"><strong><span class="application application">PowerTOP</span></strong></span>, see <a class="link" href="https://01.org/powertop/">PowerTOP’s home page</a>.
					</p></div></section></section><section class="section" id="con_why-powertop-does-not-display-frequency-stats-values-in-some-instances_managing-power-consumption-with-powertop"><div class="titlepage"><div><div><h3 class="title">15.4. Why Powertop does not display Frequency stats values in some instances</h3></div></div></div><p class="_abstract _abstract">
				While using the Intel P-State driver, PowerTOP only displays values in the <code class="literal">Frequency Stats</code> tab if the driver is in passive mode. But, even in this case, the values may be incomplete.
			</p><p>
				In total, there are three possible modes of the Intel P-State driver:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Active mode with Hardware P-States (HWP)
					</li><li class="listitem">
						Active mode without HWP
					</li><li class="listitem">
						Passive mode
					</li></ul></div><p>
				Switching to the ACPI CPUfreq driver results in complete information being displayed by PowerTOP. However, it is recommended to keep your system on the default settings.
			</p><p>
				To see what driver is loaded and in what mode, run:
			</p><pre class="literallayout"># <span class="strong strong"><strong>cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_driver</strong></span></pre><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						<code class="literal">intel_pstate</code> is returned if the Intel P-State driver is loaded and in active mode.
					</li><li class="listitem">
						<code class="literal">intel_cpufreq</code> is returned if the Intel P-State driver is loaded and in passive mode.
					</li><li class="listitem">
						<code class="literal">acpi-cpufreq</code> is returned if the ACPI CPUfreq driver is loaded.
					</li></ul></div><p>
				While using the Intel P-State driver, add the following argument to the kernel boot command line to force the driver to run in passive mode:
			</p><pre class="screen">intel_pstate=passive</pre><p>
				To disable the Intel P-State driver and use, instead, the ACPI CPUfreq driver, add the following argument to the kernel boot command line:
			</p><pre class="screen">intel_pstate=disable</pre></section><section class="section" id="generating-an-html-output_managing-power-consumption-with-powertop"><div class="titlepage"><div><div><h3 class="title">15.5. Generating an HTML output</h3></div></div></div><p>
				Apart from the <code class="literal command">powertop’s</code> output in terminal, you can also generate an HTML report.
			</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Run the <code class="literal command">powertop</code> command with the <code class="literal option">--html</code> option:
					</p><pre class="literallayout"># <span class="strong strong"><strong>powertop --html=htmlfile.html</strong></span></pre><p class="simpara">
						Replace the <code class="literal">htmlfile.html</code> parameter with the required name for the output file.
					</p></li></ul></div></section><section class="section" id="optimizing-power-consumption_managing-power-consumption-with-powertop"><div class="titlepage"><div><div><h3 class="title">15.6. Optimizing power consumption</h3></div></div></div><p>
				To optimize power consumption, you can use either the <code class="literal">powertop</code> service or the <code class="literal">powertop2tuned</code> utility.
			</p><section class="section" id="optimizing-power-consumption-using-the-powertop-service_optimizing-power-consumption"><div class="titlepage"><div><div><h4 class="title">15.6.1. Optimizing power consumption using the powertop service</h4></div></div></div><p>
					You can use the <code class="literal">powertop</code> service to automatically enable all <span class="strong strong"><strong><span class="application application">PowerTOP</span></strong></span>'s suggestions from the <code class="literal">Tunables</code> tab on the boot:
				</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							Enable the <code class="literal">powertop</code> service:
						</p><pre class="literallayout"># <span class="strong strong"><strong>systemctl enable powertop</strong></span></pre></li></ul></div></section><section class="section" id="powertop2tuned-utility_optimizing-power-consumption"><div class="titlepage"><div><div><h4 class="title">15.6.2. The powertop2tuned utility</h4></div></div></div><p>
					The <code class="literal">powertop2tuned</code> utility allows you to create custom <span class="strong strong"><strong><span class="application application">TuneD</span></strong></span> profiles from <span class="strong strong"><strong><span class="application application">PowerTOP</span></strong></span> suggestions.
				</p><p>
					By default, <code class="literal">powertop2tuned</code> creates profiles in the <code class="literal filename">/etc/tuned/</code> directory, and bases the custom profile on the currently selected <span class="strong strong"><strong><span class="application application">TuneD</span></strong></span> profile. For safety reasons, all <span class="strong strong"><strong><span class="application application">PowerTOP</span></strong></span> tunings are initially disabled in the new profile.
				</p><p>
					To enable the tunings, you can:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Uncomment them in the <code class="literal filename">/etc/tuned/profile_name/tuned.conf file</code>.
						</li><li class="listitem"><p class="simpara">
							Use the <code class="literal option">--enable</code> or <code class="literal option">-e</code> option to generate a new profile that enables most of the tunings suggested by <span class="strong strong"><strong><span class="application application">PowerTOP</span></strong></span>.
						</p><p class="simpara">
							Certain potentially problematic tunings, such as the USB autosuspend, are disabled by default and need to be uncommented manually.
						</p></li></ul></div></section><section class="section" id="optimizing-power-consumption-with-powertop2tuned_optimizing-power-consumption"><div class="titlepage"><div><div><h4 class="title">15.6.3. Optimizing power consumption using the powertop2tuned utility</h4></div></div></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							The <code class="literal">powertop2tuned</code> utility is installed on the system:
						</p><pre class="literallayout"># <span class="strong strong"><strong>dnf install tuned-utils</strong></span></pre></li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Create a custom profile:
						</p><pre class="literallayout"># <span class="strong strong"><strong>powertop2tuned new_profile_name</strong></span></pre></li><li class="listitem"><p class="simpara">
							Activate the new profile:
						</p><pre class="literallayout"># <span class="strong strong"><strong>tuned-adm profile new_profile_name</strong></span></pre></li></ol></div><div class="itemizedlist"><p class="title"><strong>Additional information</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							For a complete list of options that <code class="literal">powertop2tuned</code> supports, use:
						</p><pre class="literallayout">$ <span class="strong strong"><strong>powertop2tuned --help</strong></span></pre></li></ul></div></section><section class="section" id="con_comparison-of-powertop-service-and-powertop2tuned_optimizing-power-consumption"><div class="titlepage"><div><div><h4 class="title">15.6.4. Comparison of powertop.service and powertop2tuned</h4></div></div></div><p>
					Optimizing power consumption with <code class="literal">powertop2tuned</code> is preferred over <code class="literal">powertop.service</code> for the following reasons:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							The <code class="literal">powertop2tuned</code> utility represents integration of <span class="strong strong"><strong><span class="application application">PowerTOP</span></strong></span> into <span class="strong strong"><strong><span class="application application">TuneD</span></strong></span>, which enables to benefit of advantages of both tools.
						</li><li class="listitem">
							The <code class="literal">powertop2tuned</code> utility allows for fine-grained control of enabled tuning.
						</li><li class="listitem">
							With <code class="literal">powertop2tuned</code>, potentially dangerous tuning are not automatically enabled.
						</li><li class="listitem">
							With <code class="literal">powertop2tuned</code>, rollback is possible without reboot.
						</li></ul></div></section></section></section><section class="chapter" id="getting-started-with-perf_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 16. Getting started with perf</h2></div></div></div><p class="_abstract _abstract">
			As a system administrator, you can use the <code class="literal">perf</code> tool to collect and analyze performance data of your system.
		</p><section class="section" id="introduction-to-perf_getting-started-with-perf"><div class="titlepage"><div><div><h3 class="title">16.1. Introduction to perf</h3></div></div></div><p class="_abstract _abstract">
				The <code class="literal">perf</code> user-space tool interfaces with the kernel-based subsystem <span class="emphasis"><em>Performance Counters for Linux</em></span> (PCL). <code class="literal">perf</code> is a powerful tool that uses the Performance Monitoring Unit (PMU) to measure, record, and monitor a variety of hardware and software events. <code class="literal">perf</code> also supports tracepoints, kprobes, and uprobes.
			</p></section><section class="section" id="installing-perf_getting-started-with-perf"><div class="titlepage"><div><div><h3 class="title">16.2. Installing perf</h3></div></div></div><p class="_abstract _abstract">
				This procedure installs the <code class="literal">perf</code> user-space tool.
			</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Install the <code class="literal">perf</code> tool:
					</p><pre class="screen"># dnf install perf</pre></li></ul></div></section><section class="section" id="common-perf-commands_getting-started-with-perf"><div class="titlepage"><div><div><h3 class="title">16.3. Common perf commands</h3></div></div></div><div class="variablelist _abstract"><dl class="variablelist _abstract"><dt><span class="term"><code class="literal command">perf stat</code> </span></dt><dd>
							This command provides overall statistics for common performance events, including instructions executed and clock cycles consumed. Options allow for selection of events other than the default measurement events.
						</dd><dt><span class="term"><code class="literal command">perf record</code> </span></dt><dd>
							This command records performance data into a file, <code class="literal">perf.data</code>, which can be later analyzed using the <code class="literal">perf report</code> command.
						</dd><dt><span class="term"><code class="literal command">perf report</code> </span></dt><dd>
							This command reads and displays the performance data from the <code class="literal">perf.data</code> file created by <code class="literal">perf record</code>.
						</dd><dt><span class="term"><code class="literal command">perf list</code> </span></dt><dd>
							This command lists the events available on a particular machine. These events will vary based on performance monitoring hardware and software configuration of the system.
						</dd><dt><span class="term"><code class="literal command">perf top</code> </span></dt><dd>
							This command performs a similar function to the <code class="literal">top</code> utility. It generates and displays a performance counter profile in realtime.
						</dd><dt><span class="term"><code class="literal command">perf trace</code> </span></dt><dd>
							This command performs a similar function to the <code class="literal">strace</code> tool. It monitors the system calls used by a specified thread or process and all signals received by that application.
						</dd><dt><span class="term"><code class="literal command">perf help</code> </span></dt><dd>
							This command displays a complete list of <code class="literal">perf</code> commands.
						</dd></dl></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						Add the <code class="literal">--help</code> option to a subcommand to open the man page.
					</li></ul></div></section></section><section class="chapter" id="profiling-cpu-usage-in-real-time-with-top_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 17. Profiling CPU usage in real time with perf top</h2></div></div></div><p class="_abstract _abstract">
			You can use the <code class="literal command">perf top</code> command to measure CPU usage of different functions in real time.
		</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
					You have the <code class="literal">perf</code> user space tool installed as described in <a class="link" href="#installing-perf_getting-started-with-perf" title="16.2. Installing perf">Installing perf</a>.
				</li></ul></div><section class="section" id="the-purpose-of-perf-top_profiling-cpu-usage-in-real-time-with-top"><div class="titlepage"><div><div><h3 class="title">17.1. The purpose of perf top</h3></div></div></div><p class="_abstract _abstract">
				The <code class="literal command">perf top</code> command is used for real time system profiling and functions similarly to the <code class="literal">top</code> utility. However, where the <code class="literal">top</code> utility generally shows you how much CPU time a given process or thread is using, <code class="literal command">perf top</code> shows you how much CPU time each specific function uses. In its default state, <code class="literal command">perf top</code> tells you about functions being used across all CPUs in both the user-space and the kernel-space. To use <code class="literal command">perf top</code> you need root access.
			</p></section><section class="section" id="profiling-cpu-usage-with-perf-top_profiling-cpu-usage-in-real-time-with-top"><div class="titlepage"><div><div><h3 class="title">17.2. Profiling CPU usage with perf top</h3></div></div></div><p class="_abstract _abstract">
				This procedure activates <code class="literal">perf top</code> and profiles CPU usage in real time.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have the <code class="literal">perf</code> user space tool installed as described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf">Installing perf</a>.
					</li><li class="listitem">
						You have root access
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Start the <code class="literal">perf top</code> monitoring interface:
					</p><pre class="screen"># perf top</pre><p class="simpara">
						The monitoring interface looks similar to the following:
					</p><pre class="screen">Samples: 8K of event 'cycles', 2000 Hz, Event count (approx.): 4579432780 lost: 0/0 drop: 0/0
Overhead  Shared Object       Symbol
   2.20%  [kernel]            [k] do_syscall_64
   2.17%  [kernel]            [k] module_get_kallsym
   1.49%  [kernel]            [k] copy_user_enhanced_fast_string
   1.37%  libpthread-2.29.so  [.] <span class="emphasis"><em>pthread_mutex_lock 1.31% [unknown] [.] 0000000000000000 1.07% [kernel] [k] psi_task_change 1.04% [kernel] [k] switch_mm_irqs_off 0.94% [kernel] [k] </em></span>fget
   0.74%  [kernel]            [k] entry_SYSCALL_64
   0.69%  [kernel]            [k] syscall_return_via_sysret
   0.69%  libxul.so           [.] 0x000000000113f9b0
   0.67%  [kernel]            [k] kallsyms_expand_symbol.constprop.0
   0.65%  firefox             [.] moz_xmalloc
   0.65%  libpthread-2.29.so  [.] __pthread_mutex_unlock_usercnt
   0.60%  firefox             [.] free
   0.60%  libxul.so           [.] 0x000000000241d1cd
   0.60%  [kernel]            [k] do_sys_poll
   0.58%  [kernel]            [k] menu_select
   0.56%  [kernel]            [k] _raw_spin_lock_irqsave
   0.55%  perf                [.] 0x00000000002ae0f3</pre><p class="simpara">
						In this example, the kernel function <code class="literal">do_syscall_64</code> is using the most CPU time.
					</p></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">perf-top(1)</code> man page on your system
					</li></ul></div></section><section class="section" id="interpretation-of-perf-top-output_profiling-cpu-usage-in-real-time-with-top"><div class="titlepage"><div><div><h3 class="title">17.3. Interpretation of perf top output</h3></div></div></div><p class="_abstract _abstract">
				The <code class="literal">perf top</code> monitoring interface displays the data in several columns:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">The "Overhead" column </span></dt><dd>
							Displays the percent of CPU a given function is using.
						</dd><dt><span class="term">The "Shared Object" column </span></dt><dd>
							Displays name of the program or library which is using the function.
						</dd><dt><span class="term">The "Symbol" column </span></dt><dd>
							Displays the function name or symbol. Functions executed in the kernel-space are identified by <code class="literal">[k]</code> and functions executed in the user-space are identified by <code class="literal">[.]</code>.
						</dd></dl></div></section><section class="section" id="why-perf-displays-some-function-names-as-raw-function-addresses_profiling-cpu-usage-in-real-time-with-top"><div class="titlepage"><div><div><h3 class="title">17.4. Why perf displays some function names as raw function addresses</h3></div></div></div><p class="_abstract _abstract">
				For kernel functions, <code class="literal">perf</code> uses the information from the <code class="literal">/proc/kallsyms</code> file to map the samples to their respective function names or symbols. For functions executed in the user space, however, you might see raw function addresses because the binary is stripped.
			</p><p>
				The <code class="literal literal">debuginfo</code> package of the executable must be installed or, if the executable is a locally developed application, the application must be compiled with debugging information turned on (the <code class="literal option">-g</code> option in GCC) to display the function names or symbols in such a situation.
			</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					It is not necessary to re-run the <code class="literal command">perf record</code> command after installing the <code class="literal literal">debuginfo</code> associated with an executable. Simply re-run the <code class="literal command">perf report</code> command.
				</p></div></rh-alert><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional Resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/developing_c_and_cpp_applications_in_rhel_9/debugging-applications_developing-applications#enabling-debugging-with-debugging-information_debugging-applications">Enabling debugging with debugging information</a>
					</li></ul></div></section><section class="section" id="enabling-debug-and-source-repositories_profiling-cpu-usage-in-real-time-with-top"><div class="titlepage"><div><div><h3 class="title">17.5. Enabling debug and source repositories</h3></div></div></div><p class="_abstract _abstract">
				A standard installation of Red Hat Enterprise Linux does not enable the debug and source repositories. These repositories contain information needed to debug the system components and measure their performance.
			</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Enable the source and debug information package channels:
					</p><pre class="screen"># subscription-manager repos --enable rhel-9-for-$(uname -i)-baseos-debug-rpms
# subscription-manager repos --enable rhel-9-for-$(uname -i)-baseos-source-rpms
# subscription-manager repos --enable rhel-9-for-$(uname -i)-appstream-debug-rpms
# subscription-manager repos --enable rhel-9-for-$(uname -i)-appstream-source-rpms</pre><p class="simpara">
						The <code class="literal">$(uname -i)</code> part is automatically replaced with a matching value for architecture of your system:
					</p><rh-table><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 50%; " class="col_1"><!--Empty--><col style="width: 50%; " class="col_2"><!--Empty--></colgroup><thead><tr><th align="left" valign="top" id="idm140280133060912" scope="col">Architecture name</th><th align="left" valign="top" id="idm140280133059824" scope="col">Value</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm140280133060912"> <p>
										64-bit Intel and AMD
									</p>
									 </td><td align="left" valign="top" headers="idm140280133059824"> <p>
										x86_64
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm140280133060912"> <p>
										64-bit ARM
									</p>
									 </td><td align="left" valign="top" headers="idm140280133059824"> <p>
										aarch64
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm140280133060912"> <p>
										IBM POWER
									</p>
									 </td><td align="left" valign="top" headers="idm140280133059824"> <p>
										ppc64le
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm140280133060912"> <p>
										64-bit IBM Z
									</p>
									 </td><td align="left" valign="top" headers="idm140280133059824"> <p>
										s390x
									</p>
									 </td></tr></tbody></table></rh-table></li></ul></div></section><section class="section" id="getting-debuginfo-packages-for-an-application-or-library-using-gdb_profiling-cpu-usage-in-real-time-with-top"><div class="titlepage"><div><div><h3 class="title">17.6. Getting debuginfo packages for an application or library using GDB</h3></div></div></div><p class="_abstract _abstract">
				Debugging information is required to debug code. For code that is installed from a package, the GNU Debugger (GDB) automatically recognizes missing debug information, resolves the package name and provides concrete advice on how to get the package.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						The application or library you want to debug must be installed on the system.
					</li><li class="listitem">
						GDB and the <code class="literal command">debuginfo-install</code> tool must be installed on the system. For details, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/developing_c_and_cpp_applications_in_rhel_9/setting-up-a-development-workstation_developing-applications#setting-up-to-debug-applications_setting-up-a-development-workstation">Setting up to debug applications</a>.
					</li><li class="listitem">
						Repositories providing <code class="literal">debuginfo</code> and <code class="literal">debugsource</code> packages must be configured and enabled on the system. For details, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/developing_c_and_cpp_applications_in_rhel_9/index#enabling-debug-and-source-repositories_setting-up-a-development-workstation">Enabling debug and source repositories</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Start GDB attached to the application or library you want to debug. GDB automatically recognizes missing debugging information and suggests a command to run.
					</p><pre class="screen">$ gdb -q /bin/ls
Reading symbols from /bin/ls...Reading symbols from .gnu_debugdata for /usr/bin/ls...(no debugging symbols found)...done.
(no debugging symbols found)...done.
Missing separate debuginfos, use: dnf <span class="emphasis"><em>debuginfo-install coreutils-8.30-6.el8.x86_64</em></span>
(gdb)</pre></li><li class="listitem"><p class="simpara">
						Exit GDB: type <kbd class="keycap">q</kbd> and confirm with <kbd class="keycap">Enter</kbd>.
					</p><pre class="screen">(gdb) q</pre></li><li class="listitem"><p class="simpara">
						Run the command suggested by GDB to install the required <code class="literal">debuginfo</code> packages:
					</p><pre class="screen"># dnf debuginfo-install coreutils-8.30-6.el8.x86_64</pre><p class="simpara">
						The <code class="literal">dnf</code> package management tool provides a summary of the changes, asks for confirmation and once you confirm, downloads and installs all the necessary files.
					</p></li><li class="listitem">
						In case GDB is not able to suggest the <code class="literal">debuginfo</code> package, follow the procedure described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/developing_c_and_cpp_applications_in_rhel_9/debugging-applications_developing-applications#getting-debuginfo-packages-for-an-application-or-library-manually_enabling-debugging-with-debugging-information">Getting debuginfo packages for an application or library manually</a>.
					</li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/solutions/9907">How can I download or install debuginfo packages for RHEL systems?</a> (Red Hat Knowledgebase)
					</li></ul></div></section></section><section class="chapter" id="counting-events-during-process-execution-with-perf-stat_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 18. Counting events during process execution with perf stat</h2></div></div></div><p class="_abstract _abstract">
			You can use the <code class="literal command">perf stat</code> command to count hardware and software events during process execution.
		</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
					You have the <code class="literal">perf</code> user space tool installed as described in <a class="link" href="#installing-perf_getting-started-with-perf" title="16.2. Installing perf">Installing perf</a>.
				</li></ul></div><section class="section" id="the-purpose-of-perf-stat_counting-events-during-process-execution-with-perf-stat"><div class="titlepage"><div><div><h3 class="title">18.1. The purpose of perf stat</h3></div></div></div><p class="_abstract _abstract">
				The <code class="literal command">perf stat</code> command executes a specified command, keeps a running count of hardware and software event occurrences during the commands execution, and generates statistics of these counts. If you do not specify any events, then <code class="literal command">perf stat</code> counts a set of common hardware and software events.
			</p></section><section class="section" id="counting-events-with-perf-stat_counting-events-during-process-execution-with-perf-stat"><div class="titlepage"><div><div><h3 class="title">18.2. Counting events with perf stat</h3></div></div></div><p class="_abstract _abstract">
				You can use <code class="literal">perf stat</code> to count hardware and software event occurrences during command execution and generate statistics of these counts. By default, <code class="literal">perf stat</code> operates in per-thread mode.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have the <code class="literal">perf</code> user space tool installed as described in <a class="link" href="#installing-perf_getting-started-with-perf" title="16.2. Installing perf">Installing perf</a>.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Count the events.
					</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem"><p class="simpara">
								Running the <code class="literal command">perf stat</code> command without root access will only count events occurring in the user space:
							</p><pre class="screen">$ perf stat ls</pre><div class="example" id="idm140280183700800"><p class="title"><strong>Example 18.1. Output of perf stat ran without root access</strong></p><div class="example-contents"><pre class="screen">Desktop  Documents  Downloads  Music  Pictures  Public  Templates  Videos

 Performance counter stats for 'ls':

              1.28 msec task-clock:u               #    0.165 CPUs utilized
                 0      context-switches:u         #    0.000 M/sec
                 0      cpu-migrations:u           #    0.000 K/sec
               104      page-faults:u              #    0.081 M/sec
         1,054,302      cycles:u                   #    0.823 GHz
         1,136,989      instructions:u             #    1.08  insn per cycle
           228,531      branches:u                 #  178.447 M/sec
            11,331      branch-misses:u            #    4.96% of all branches

       0.007754312 seconds time elapsed

       0.000000000 seconds user
       0.007717000 seconds sys</pre></div></div><p class="simpara">
								As you can see in the previous example, when <code class="literal">perf stat</code> runs without root access the event names are followed by <code class="literal">:u</code>, indicating that these events were counted only in the user-space.
							</p></li><li class="listitem"><p class="simpara">
								To count both user-space and kernel-space events, you must have root access when running <code class="literal command">perf stat</code>:
							</p><pre class="screen"># perf stat ls</pre><div class="example" id="idm140280183694768"><p class="title"><strong>Example 18.2. Output of perf stat ran with root access</strong></p><div class="example-contents"><pre class="screen">Desktop  Documents  Downloads  Music  Pictures  Public  Templates  Videos

 Performance counter stats for 'ls':

              3.09 msec task-clock                #    0.119 CPUs utilized
                18      context-switches          #    0.006 M/sec
                 3      cpu-migrations            #    0.969 K/sec
               108      page-faults               #    0.035 M/sec
         6,576,004      cycles                    #    2.125 GHz
         5,694,223      instructions              #    0.87  insn per cycle
         1,092,372      branches                  #  352.960 M/sec
            31,515      branch-misses             #    2.89% of all branches

       0.026020043 seconds time elapsed

       0.000000000 seconds user
       0.014061000 seconds sys</pre></div></div><div class="itemizedlist"><ul class="itemizedlist" type="square"><li class="listitem"><p class="simpara">
										By default, <code class="literal">perf stat</code> operates in per-thread mode. To change to CPU-wide event counting, pass the <code class="literal">-a</code> option to <code class="literal">perf stat</code>. To count CPU-wide events, you need root access:
									</p><pre class="screen"># perf stat -a ls</pre></li></ul></div></li></ul></div></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">perf-stat(1)</code> man page on your system
					</li></ul></div></section><section class="section" id="interpretation-of-perf-stat-output_counting-events-during-process-execution-with-perf-stat"><div class="titlepage"><div><div><h3 class="title">18.3. Interpretation of perf stat output</h3></div></div></div><p class="_abstract _abstract">
				<code class="literal">perf stat</code> executes a specified command and counts event occurrences during the commands execution and displays statistics of these counts in three columns:
			</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
						The number of occurrences counted for a given event
					</li><li class="listitem">
						The name of the event that was counted
					</li><li class="listitem"><p class="simpara">
						When related metrics are available, a ratio or percentage is displayed after the hash sign (<code class="literal">#</code>) in the right-most column.
					</p><p class="simpara">
						For example, when running in default mode, <code class="literal">perf stat</code> counts both cycles and instructions and, therefore, calculates and displays instructions per cycle in the right-most column. You can see similar behavior with regard to branch-misses as a percent of all branches since both events are counted by default.
					</p></li></ol></div></section><section class="section" id="attaching-perf-stat-to-a-running-process_counting-events-during-process-execution-with-perf-stat"><div class="titlepage"><div><div><h3 class="title">18.4. Attaching perf stat to a running process</h3></div></div></div><p class="_abstract _abstract">
				You can attach <code class="literal">perf stat</code> to a running process. This will instruct <code class="literal">perf stat</code> to count event occurrences only in the specified processes during the execution of a command.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have the <code class="literal">perf</code> user space tool installed as described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf">Installing perf</a>.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Attach <code class="literal">perf stat</code> to a running process:
					</p><pre class="screen">$ perf stat -p <span class="emphasis"><em>ID1,ID2</em></span> sleep <span class="emphasis"><em>seconds</em></span></pre><p class="simpara">
						The previous example counts events in the processes with the IDs of <code class="literal"><span class="emphasis"><em>ID1</em></span></code> and <code class="literal"><span class="emphasis"><em>ID2</em></span></code> for a time period of <code class="literal"><span class="emphasis"><em>seconds</em></span></code> seconds as dictated by using the <code class="literal">sleep</code> command.
					</p></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">perf-stat(1)</code> man page on your system
					</li></ul></div></section></section><section class="chapter" id="recording-and-analyzing-performance-profiles-with-perf_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 19. Recording and analyzing performance profiles with perf</h2></div></div></div><p class="_abstract _abstract">
			The <code class="literal">perf</code> tool allows you to record performance data and analyze it at a later time.
		</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
					You have the <code class="literal">perf</code> user space tool installed as described in <a class="link" href="#installing-perf_getting-started-with-perf" title="16.2. Installing perf">Installing perf</a>.
				</li></ul></div><section class="section" id="the-purpose-of-perf-record_recording-and-analyzing-performance-profiles-with-perf"><div class="titlepage"><div><div><h3 class="title">19.1. The purpose of perf record</h3></div></div></div><p class="_abstract _abstract">
				The <code class="literal command">perf record</code> command samples performance data and stores it in a file, <code class="literal file">perf.data</code>, which can be read and visualized with other <code class="literal">perf</code> commands. <code class="literal file">perf.data</code> is generated in the current directory and can be accessed at a later time, possibly on a different machine.
			</p><p>
				If you do not specify a command for <code class="literal command">perf record</code> to record during, it will record until you manually stop the process by pressing <code class="literal">Ctrl+C</code>. You can attach <code class="literal command">perf record</code> to specific processes by passing the <code class="literal option">-p</code> option followed by one or more process IDs. You can run <code class="literal command">perf record</code> without root access, however, doing so will only sample performance data in the user space. In the default mode, <code class="literal command">perf record</code> uses CPU cycles as the sampling event and operates in per-thread mode with inherit mode enabled.
			</p></section><section class="section" id="recording-a-performance-profile-without-root-access_recording-and-analyzing-performance-profiles-with-perf"><div class="titlepage"><div><div><h3 class="title">19.2. Recording a performance profile without root access</h3></div></div></div><p class="_abstract _abstract">
				You can use <code class="literal">perf record</code> without root access to sample and record performance data in the user-space only.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have the <code class="literal">perf</code> user space tool installed as described in <a class="link" href="#installing-perf_getting-started-with-perf" title="16.2. Installing perf">Installing perf</a>.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Sample and record the performance data:
					</p><pre class="screen">$ perf record <span class="emphasis"><em>command</em></span></pre><p class="simpara">
						Replace <code class="literal"><span class="emphasis"><em>command</em></span></code> with the command you want to sample data during. If you do not specify a command, then <code class="literal">perf record</code> will sample data until you manually stop it by pressing <kbd class="keycap">Ctrl</kbd>+<kbd class="keycap">C</kbd>.
					</p></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">perf-record(1)</code> man page on your system
					</li></ul></div></section><section class="section" id="recording-a-performance-profile-with-root-access_recording-and-analyzing-performance-profiles-with-perf"><div class="titlepage"><div><div><h3 class="title">19.3. Recording a performance profile with root access</h3></div></div></div><p class="_abstract _abstract">
				You can use <code class="literal">perf record</code> with root access to sample and record performance data in both the user-space and the kernel-space simultaneously.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have the <code class="literal">perf</code> user space tool installed as described in <a class="link" href="#installing-perf_getting-started-with-perf" title="16.2. Installing perf">Installing perf</a>.
					</li><li class="listitem">
						You have root access.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Sample and record the performance data:
					</p><pre class="screen"># perf record <span class="emphasis"><em>command</em></span></pre><p class="simpara">
						Replace <code class="literal"><span class="emphasis"><em>command</em></span></code> with the command you want to sample data during. If you do not specify a command, then <code class="literal">perf record</code> will sample data until you manually stop it by pressing <kbd class="keycap">Ctrl</kbd>+<kbd class="keycap">C</kbd>.
					</p></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">perf-record(1)</code> man page on your system
					</li></ul></div></section><section class="section" id="recording-a-performance-profile-in-per-cpu-mode_recording-and-analyzing-performance-profiles-with-perf"><div class="titlepage"><div><div><h3 class="title">19.4. Recording a performance profile in per-CPU mode</h3></div></div></div><p class="_abstract _abstract">
				You can use <code class="literal">perf record</code> in per-CPU mode to sample and record performance data in both and user-space and the kernel-space simultaneously across all threads on a monitored CPU. By default, per-CPU mode monitors all online CPUs.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have the <code class="literal">perf</code> user space tool installed as described in <a class="link" href="#installing-perf_getting-started-with-perf" title="16.2. Installing perf">Installing perf</a>.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Sample and record the performance data:
					</p><pre class="screen"># perf record -a <span class="emphasis"><em>command</em></span></pre><p class="simpara">
						Replace <code class="literal"><span class="emphasis"><em>command</em></span></code> with the command you want to sample data during. If you do not specify a command, then <code class="literal">perf record</code> will sample data until you manually stop it by pressing <kbd class="keycap">Ctrl</kbd>+<kbd class="keycap">C</kbd>.
					</p></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">perf-record(1)</code> man page on your system
					</li></ul></div></section><section class="section" id="capturing-call-graph-data-with-perf-record_recording-and-analyzing-performance-profiles-with-perf"><div class="titlepage"><div><div><h3 class="title">19.5. Capturing call graph data with perf record</h3></div></div></div><p class="_abstract _abstract">
				You can configure the <code class="literal">perf record</code> tool so that it records which function is calling other functions in the performance profile. This helps to identify a bottleneck if several processes are calling the same function.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have the <code class="literal">perf</code> user space tool installed as described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf">Installing perf</a>.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Sample and record performance data with the <code class="literal">--call-graph</code> option:
					</p><pre class="screen">$ perf record --call-graph <span class="emphasis"><em>method</em></span> <span class="emphasis"><em>command</em></span></pre><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
								Replace <code class="literal"><span class="emphasis"><em>command</em></span></code> with the command you want to sample data during. If you do not specify a command, then <code class="literal">perf record</code> will sample data until you manually stop it by pressing <kbd class="keycap">Ctrl</kbd>+<kbd class="keycap">C</kbd>.
							</li><li class="listitem"><p class="simpara">
								Replace <span class="emphasis"><em>method</em></span> with one of the following unwinding methods:
							</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">fp</code></span></dt><dd>
											Uses the frame pointer method. Depending on compiler optimization, such as with binaries built with the GCC option <code class="literal option">--fomit-frame-pointer</code>, this may not be able to unwind the stack.
										</dd><dt><span class="term"><code class="literal">dwarf</code></span></dt><dd>
											Uses DWARF Call Frame Information to unwind the stack.
										</dd><dt><span class="term"><code class="literal">lbr</code></span></dt><dd>
											Uses the last branch record hardware on Intel processors.
										</dd></dl></div></li></ul></div></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">perf-record(1)</code> man page on your system
					</li></ul></div></section><section class="section" id="analyzing-perf-data-with-perf-report_recording-and-analyzing-performance-profiles-with-perf"><div class="titlepage"><div><div><h3 class="title">19.6. Analyzing perf.data with perf report</h3></div></div></div><p class="_abstract _abstract">
				You can use <code class="literal">perf report</code> to display and analyze a <code class="literal file">perf.data</code> file.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have the <code class="literal">perf</code> user space tool installed as described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf">Installing perf</a>.
					</li><li class="listitem">
						There is a <code class="literal file">perf.data</code> file in the current directory.
					</li><li class="listitem">
						If the <code class="literal file">perf.data</code> file was created with root access, you need to run <code class="literal">perf report</code> with root access too.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Display the contents of the <code class="literal file">perf.data</code> file for further analysis:
					</p><pre class="screen"># perf report</pre><p class="simpara">
						This command displays output similar to the following:
					</p><pre class="screen">Samples: 2K of event 'cycles', Event count (approx.): 235462960
Overhead  Command          Shared Object                     Symbol
   2.36%  kswapd0          [kernel.kallsyms]                 [k] page_vma_mapped_walk
   2.13%  sssd_kcm         libc-2.28.so                      [.] <span class="emphasis"><em>memset_avx2_erms 2.13% perf [kernel.kallsyms] [k] smp_call_function_single 1.53% gnome-shell libc-2.28.so [.] </em></span>strcmp_avx2
   1.17%  gnome-shell      libglib-2.0.so.0.5600.4           [.] g_hash_table_lookup
   0.93%  Xorg             libc-2.28.so                      [.] <span class="emphasis"><em>memmove_avx_unaligned_erms 0.89% gnome-shell libgobject-2.0.so.0.5600.4 [.] g_object_unref 0.87% kswapd0 [kernel.kallsyms] [k] page_referenced_one 0.86% gnome-shell libc-2.28.so [.] </em></span>memmove_avx_unaligned_erms
   0.83%  Xorg             [kernel.kallsyms]                 [k] alloc_vmap_area
   0.63%  gnome-shell      libglib-2.0.so.0.5600.4           [.] g_slice_alloc
   0.53%  gnome-shell      libgirepository-1.0.so.1.0.0      [.] g_base_info_unref
   0.53%  gnome-shell      ld-2.28.so                        [.] _dl_find_dso_for_object
   0.49%  kswapd0          [kernel.kallsyms]                 [k] vma_interval_tree_iter_next
   0.48%  gnome-shell      libpthread-2.28.so                [.] <span class="emphasis"><em>pthread_getspecific 0.47% gnome-shell libgirepository-1.0.so.1.0.0 [.] 0x0000000000013b1d 0.45% gnome-shell libglib-2.0.so.0.5600.4 [.] g_slice_free1 0.45% gnome-shell libgobject-2.0.so.0.5600.4 [.] g_type_check_instance_is_fundamentally_a 0.44% gnome-shell libc-2.28.so [.] malloc 0.41% swapper [kernel.kallsyms] [k] apic_timer_interrupt 0.40% gnome-shell ld-2.28.so [.] _dl_lookup_symbol_x 0.39% kswapd0 [kernel.kallsyms] [k] </em></span>raw_callee_save___pv_queued_spin_unlock</pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">perf-report(1)</code> man page on your system
					</li></ul></div></section><section class="section" id="interpretation-of-perf-report-output_recording-and-analyzing-performance-profiles-with-perf"><div class="titlepage"><div><div><h3 class="title">19.7. Interpretation of perf report output</h3></div></div></div><p class="_abstract _abstract">
				The table displayed by running the <code class="literal command">perf report</code> command sorts the data into several columns:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">The 'Overhead' column</span></dt><dd>
							Indicates what percentage of overall samples were collected in that particular function.
						</dd><dt><span class="term">The 'Command' column</span></dt><dd>
							Tells you which process the samples were collected from.
						</dd><dt><span class="term">The 'Shared Object' column</span></dt><dd>
							Displays the name of the ELF image where the samples come from (the name [kernel.kallsyms] is used when the samples come from the kernel).
						</dd><dt><span class="term">The 'Symbol' column</span></dt><dd>
							Displays the function name or symbol.
						</dd></dl></div><p>
				In default mode, the functions are sorted in descending order with those with the highest overhead displayed first.
			</p></section><section class="section" id="generating-a-perf-data-file-that-is-readable-on-a-different-device_recording-and-analyzing-performance-profiles-with-perf"><div class="titlepage"><div><div><h3 class="title">19.8. Generating a perf.data file that is readable on a different device</h3></div></div></div><p class="_abstract _abstract">
				You can use the <code class="literal">perf</code> tool to record performance data into a <code class="literal">perf.data</code> file to be analyzed on a different device.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have the <code class="literal">perf</code> user space tool installed as described in <a class="link" href="#installing-perf_getting-started-with-perf" title="16.2. Installing perf">Installing perf</a>.
					</li><li class="listitem">
						The kernel <code class="literal">debuginfo</code> package is installed. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/developing_c_and_cpp_applications_in_rhel_8/index#getting-debuginfo-packages-for-an-application-or-library-using-gdb_enabling-debugging-with-debugging-information">Getting debuginfo packages for an application or library using GDB.</a>
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Capture performance data you are interested in investigating further:
					</p><pre class="screen"># perf record -a --call-graph fp sleep <span class="emphasis"><em>seconds</em></span></pre><p class="simpara">
						This example would generate a <code class="literal">perf.data</code> over the entire system for a period of <code class="literal"><span class="emphasis"><em>seconds</em></span></code> seconds as dictated by the use of the <code class="literal">sleep</code> command. It would also capture call graph data using the frame pointer method.
					</p></li><li class="listitem"><p class="simpara">
						Generate an archive file containing debug symbols of the recorded data:
					</p><pre class="screen"># perf archive</pre></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Verify that the archive file has been generated in your current active directory:
					</p><pre class="screen"># ls perf.data*</pre><p class="simpara">
						The output will display every file in your current directory that begins with <code class="literal">perf.data</code>. The archive file will be named either:
					</p><pre class="screen">perf.data.tar.gz</pre><p class="simpara">
						or
					</p><pre class="screen">perf.data.tar.bz2</pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="#recording-and-analyzing-performance-profiles-with-perf_monitoring-and-managing-system-status-and-performance" title="Chapter 19. Recording and analyzing performance profiles with perf">Recording and analyzing performance profiles with perf</a>
					</li><li class="listitem">
						<a class="link" href="#capturing-call-graph-data-with-perf-record_recording-and-analyzing-performance-profiles-with-perf" title="19.5. Capturing call graph data with perf record">Capturing call graph data with perf record</a>
					</li></ul></div></section><section class="section" id="analyzing-a-perf-data-file-that-was-created-on-a-different-device_recording-and-analyzing-performance-profiles-with-perf"><div class="titlepage"><div><div><h3 class="title">19.9. Analyzing a perf.data file that was created on a different device</h3></div></div></div><p class="_abstract _abstract">
				You can use the <code class="literal">perf</code> tool to analyze a <code class="literal">perf.data</code> file that was generated on a different device.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have the <code class="literal">perf</code> user space tool installed as described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf">Installing perf</a>.
					</li><li class="listitem">
						A <code class="literal">perf.data</code> file and associated archive file generated on a different device are present on the current device being used.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem">
						Copy both the <code class="literal">perf.data</code> file and the archive file into your current active directory.
					</li><li class="listitem"><p class="simpara">
						Extract the archive file into <code class="literal">~/.debug</code>:
					</p><pre class="screen"># mkdir -p ~/.debug
# tar xf <span class="emphasis"><em>perf.data.tar.bz2</em></span> -C ~/.debug</pre><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
							The archive file might also be named <code class="literal"><span class="emphasis"><em>perf.data.tar.gz</em></span></code>.
						</p></div></rh-alert></li><li class="listitem"><p class="simpara">
						Open the <code class="literal">perf.data</code> file for further analysis:
					</p><pre class="screen"># perf report</pre></li></ol></div></section><section class="section" id="why-perf-displays-some-function-names-as-raw-function-addresses_recording-and-analyzing-performance-profiles-with-perf"><div class="titlepage"><div><div><h3 class="title">19.10. Why perf displays some function names as raw function addresses</h3></div></div></div><p class="_abstract _abstract">
				For kernel functions, <code class="literal">perf</code> uses the information from the <code class="literal">/proc/kallsyms</code> file to map the samples to their respective function names or symbols. For functions executed in the user space, however, you might see raw function addresses because the binary is stripped.
			</p><p>
				The <code class="literal literal">debuginfo</code> package of the executable must be installed or, if the executable is a locally developed application, the application must be compiled with debugging information turned on (the <code class="literal option">-g</code> option in GCC) to display the function names or symbols in such a situation.
			</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					It is not necessary to re-run the <code class="literal command">perf record</code> command after installing the <code class="literal literal">debuginfo</code> associated with an executable. Simply re-run the <code class="literal command">perf report</code> command.
				</p></div></rh-alert><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional Resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/developing_c_and_cpp_applications_in_rhel_9/debugging-applications_developing-applications#enabling-debugging-with-debugging-information_debugging-applications">Enabling debugging with debugging information</a>
					</li></ul></div></section><section class="section" id="enabling-debug-and-source-repositories_recording-and-analyzing-performance-profiles-with-perf"><div class="titlepage"><div><div><h3 class="title">19.11. Enabling debug and source repositories</h3></div></div></div><p class="_abstract _abstract">
				A standard installation of Red Hat Enterprise Linux does not enable the debug and source repositories. These repositories contain information needed to debug the system components and measure their performance.
			</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Enable the source and debug information package channels:
					</p><pre class="screen"># subscription-manager repos --enable rhel-9-for-$(uname -i)-baseos-debug-rpms
# subscription-manager repos --enable rhel-9-for-$(uname -i)-baseos-source-rpms
# subscription-manager repos --enable rhel-9-for-$(uname -i)-appstream-debug-rpms
# subscription-manager repos --enable rhel-9-for-$(uname -i)-appstream-source-rpms</pre><p class="simpara">
						The <code class="literal">$(uname -i)</code> part is automatically replaced with a matching value for architecture of your system:
					</p><rh-table><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 50%; " class="col_1"><!--Empty--><col style="width: 50%; " class="col_2"><!--Empty--></colgroup><thead><tr><th align="left" valign="top" id="idm140280134419776" scope="col">Architecture name</th><th align="left" valign="top" id="idm140280134418688" scope="col">Value</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm140280134419776"> <p>
										64-bit Intel and AMD
									</p>
									 </td><td align="left" valign="top" headers="idm140280134418688"> <p>
										x86_64
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm140280134419776"> <p>
										64-bit ARM
									</p>
									 </td><td align="left" valign="top" headers="idm140280134418688"> <p>
										aarch64
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm140280134419776"> <p>
										IBM POWER
									</p>
									 </td><td align="left" valign="top" headers="idm140280134418688"> <p>
										ppc64le
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm140280134419776"> <p>
										64-bit IBM Z
									</p>
									 </td><td align="left" valign="top" headers="idm140280134418688"> <p>
										s390x
									</p>
									 </td></tr></tbody></table></rh-table></li></ul></div></section><section class="section" id="getting-debuginfo-packages-for-an-application-or-library-using-gdb_recording-and-analyzing-performance-profiles-with-perf"><div class="titlepage"><div><div><h3 class="title">19.12. Getting debuginfo packages for an application or library using GDB</h3></div></div></div><p class="_abstract _abstract">
				Debugging information is required to debug code. For code that is installed from a package, the GNU Debugger (GDB) automatically recognizes missing debug information, resolves the package name and provides concrete advice on how to get the package.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						The application or library you want to debug must be installed on the system.
					</li><li class="listitem">
						GDB and the <code class="literal command">debuginfo-install</code> tool must be installed on the system. For details, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/developing_c_and_cpp_applications_in_rhel_9/setting-up-a-development-workstation_developing-applications#setting-up-to-debug-applications_setting-up-a-development-workstation">Setting up to debug applications</a>.
					</li><li class="listitem">
						Repositories providing <code class="literal">debuginfo</code> and <code class="literal">debugsource</code> packages must be configured and enabled on the system. For details, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/developing_c_and_cpp_applications_in_rhel_9/index#enabling-debug-and-source-repositories_setting-up-a-development-workstation">Enabling debug and source repositories</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Start GDB attached to the application or library you want to debug. GDB automatically recognizes missing debugging information and suggests a command to run.
					</p><pre class="screen">$ gdb -q /bin/ls
Reading symbols from /bin/ls...Reading symbols from .gnu_debugdata for /usr/bin/ls...(no debugging symbols found)...done.
(no debugging symbols found)...done.
Missing separate debuginfos, use: dnf <span class="emphasis"><em>debuginfo-install coreutils-8.30-6.el8.x86_64</em></span>
(gdb)</pre></li><li class="listitem"><p class="simpara">
						Exit GDB: type <kbd class="keycap">q</kbd> and confirm with <kbd class="keycap">Enter</kbd>.
					</p><pre class="screen">(gdb) q</pre></li><li class="listitem"><p class="simpara">
						Run the command suggested by GDB to install the required <code class="literal">debuginfo</code> packages:
					</p><pre class="screen"># dnf debuginfo-install coreutils-8.30-6.el8.x86_64</pre><p class="simpara">
						The <code class="literal">dnf</code> package management tool provides a summary of the changes, asks for confirmation and once you confirm, downloads and installs all the necessary files.
					</p></li><li class="listitem">
						In case GDB is not able to suggest the <code class="literal">debuginfo</code> package, follow the procedure described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/developing_c_and_cpp_applications_in_rhel_9/debugging-applications_developing-applications#getting-debuginfo-packages-for-an-application-or-library-manually_enabling-debugging-with-debugging-information">Getting debuginfo packages for an application or library manually</a>.
					</li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/solutions/9907">How can I download or install debuginfo packages for RHEL systems?</a> (Red Hat Knowledgebase)
					</li></ul></div></section></section><section class="chapter" id="investigating-busy-cpus-with-perf_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 20. Investigating busy CPUs with perf</h2></div></div></div><p class="_abstract _abstract">
			When investigating performance issues on a system, you can use the <code class="literal">perf</code> tool to identify and monitor the busiest CPUs in order to focus your efforts.
		</p><section class="section" id="displaying-which-cpu-events-were-counted-on-with-perf-stat_investigating-busy-cpus-with-perf"><div class="titlepage"><div><div><h3 class="title">20.1. Displaying which CPU events were counted on with perf stat</h3></div></div></div><p class="_abstract _abstract">
				You can use <code class="literal">perf stat</code> to display which CPU events were counted on by disabling CPU count aggregation. You must count events in system-wide mode by using the <code class="literal">-a</code> flag in order to use this functionality.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have the <code class="literal">perf</code> user space tool installed as described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf">Installing perf</a>.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Count the events with CPU count aggregation disabled:
					</p><pre class="screen"># perf stat -a -A sleep <span class="emphasis"><em>seconds</em></span></pre><p class="simpara">
						The previous example displays counts of a default set of common hardware and software events recorded over a time period of <code class="literal"><span class="emphasis"><em>seconds</em></span></code> seconds, as dictated by using the <code class="literal">sleep</code> command, over each individual CPU in ascending order, starting with <code class="literal">CPU0</code>. As such, it may be useful to specify an event such as cycles:
					</p><pre class="screen"># perf stat -a -A -e cycles sleep <span class="emphasis"><em>seconds</em></span></pre></li></ul></div></section><section class="section" id="displaying-which-cpu-samples-were-taken-on-with-perf-report_investigating-busy-cpus-with-perf"><div class="titlepage"><div><div><h3 class="title">20.2. Displaying which CPU samples were taken on with perf report</h3></div></div></div><p class="_abstract _abstract">
				The <code class="literal">perf record</code> command samples performance data and stores this data in a <code class="literal">perf.data</code> file which can be read with the <code class="literal">perf report</code> command. The <code class="literal">perf record</code> command always records which CPU samples were taken on. You can configure <code class="literal">perf report</code> to display this information.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have the <code class="literal">perf</code> user space tool installed as described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf">Installing perf</a>.
					</li><li class="listitem">
						There is a <code class="literal">perf.data</code> file created with <code class="literal">perf record</code> in the current directory. If the <code class="literal">perf.data</code> file was created with root access, you need to run <code class="literal">perf report</code> with root access too.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Display the contents of the <code class="literal">perf.data</code> file for further analysis while sorting by CPU:
					</p><pre class="screen"># perf report --sort cpu</pre><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem"><p class="simpara">
								You can sort by CPU and command to display more detailed information about where CPU time is being spent:
							</p><pre class="screen"># perf report --sort cpu,comm</pre><p class="simpara">
								This example will list commands from all monitored CPUs by total overhead in descending order of overhead usage and identify the CPU the command was executed on.
							</p></li></ul></div></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/recording-and-analyzing-performance-profiles-with-perf_monitoring-and-managing-system-status-and-performance">Recording and analyzing performance profiles with perf</a>
					</li></ul></div></section><section class="section" id="displaying-specific-cpus-during-profiling-with-perf-top_investigating-busy-cpus-with-perf"><div class="titlepage"><div><div><h3 class="title">20.3. Displaying specific CPUs during profiling with perf top</h3></div></div></div><p class="_abstract _abstract">
				You can configure <code class="literal">perf top</code> to display specific CPUs and their relative usage while profiling your system in real time.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have the <code class="literal">perf</code> user space tool installed as described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf">Installing perf</a>.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Start the <code class="literal">perf top</code> interface while sorting by CPU:
					</p><pre class="screen"># perf top --sort cpu</pre><p class="simpara">
						This example will list CPUs and their respective overhead in descending order of overhead usage in real time.
					</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem"><p class="simpara">
								You can sort by CPU and command for more detailed information of where CPU time is being spent:
							</p><pre class="screen"># perf top --sort cpu,comm</pre><p class="simpara">
								This example will list commands by total overhead in descending order of overhead usage and identify the CPU the command was executed on in real time.
							</p></li></ul></div></li></ul></div></section><section class="section" id="monitoring-specific-cpus-with-perf-record-and-perf-report_investigating-busy-cpus-with-perf"><div class="titlepage"><div><div><h3 class="title">20.4. Monitoring specific CPUs with perf record and perf report</h3></div></div></div><p class="_abstract _abstract">
				You can configure <code class="literal">perf record</code> to only sample specific CPUs of interest and analyze the generated <code class="literal">perf.data</code> file with <code class="literal">perf report</code> for further analysis.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have the <code class="literal">perf</code> user space tool installed as described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf">Installing perf</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Sample and record the performance data in the specific CPU’s, generating a <code class="literal">perf.data</code> file:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
								Using a comma separated list of CPUs:
							</p><pre class="screen"># perf record -C <span class="emphasis"><em>0,1</em></span> sleep <span class="emphasis"><em>seconds</em></span></pre><p class="simpara">
								The previous example samples and records data in CPUs 0 and 1 for a period of <code class="literal"><span class="emphasis"><em>seconds</em></span></code> seconds as dictated by the use of the <code class="literal">sleep</code> command.
							</p></li><li class="listitem"><p class="simpara">
								Using a range of CPUs:
							</p><pre class="screen"># perf record -C <span class="emphasis"><em>0-2</em></span> sleep <span class="emphasis"><em>seconds</em></span></pre><p class="simpara">
								The previous example samples and records data in all CPUs from CPU 0 to 2 for a period of <code class="literal"><span class="emphasis"><em>seconds</em></span></code> seconds as dictated by the use of the <code class="literal">sleep</code> command.
							</p></li></ul></div></li><li class="listitem"><p class="simpara">
						Display the contents of the <code class="literal">perf.data</code> file for further analysis:
					</p><pre class="screen"># perf report</pre><p class="simpara">
						This example will display the contents of <code class="literal">perf.data</code>. If you are monitoring several CPUs and want to know which CPU data was sampled on, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/investigating-busy-cpus-with-perf_monitoring-and-managing-system-status-and-performance#displaying-which-cpu-samples-were-taken-on-with-perf-report_investigating-busy-cpus-with-perf">Displaying which CPU samples were taken on with perf report</a>.
					</p></li></ol></div></section></section><section class="chapter" id="monitoring-application-performance-with-perf_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 21. Monitoring application performance with perf</h2></div></div></div><p class="_abstract _abstract">
			You can use the <code class="literal">perf</code> tool to monitor and analyze application performance.
		</p><section class="section" id="attaching-perf-record-to-a-running-process_monitoring-application-performance-with-perf"><div class="titlepage"><div><div><h3 class="title">21.1. Attaching perf record to a running process</h3></div></div></div><p class="_abstract _abstract">
				You can attach <code class="literal">perf record</code> to a running process. This will instruct <code class="literal">perf record</code> to only sample and record performance data in the specified processes.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have the <code class="literal">perf</code> user space tool installed as described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf">Installing perf</a>.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Attach <code class="literal">perf record</code> to a running process:
					</p><pre class="screen">$ perf record -p <span class="emphasis"><em>ID1,ID2</em></span> sleep <span class="emphasis"><em>seconds</em></span></pre><p class="simpara">
						The previous example samples and records performance data of the processes with the process ID’s <code class="literal"><span class="emphasis"><em>ID1</em></span></code> and <code class="literal"><span class="emphasis"><em>ID2</em></span></code> for a time period of <code class="literal"><span class="emphasis"><em>seconds</em></span></code> seconds as dictated by using the <code class="literal">sleep</code> command. You can also configure <code class="literal">perf</code> to record events in specific threads:
					</p><pre class="screen">$ perf record -t <span class="emphasis"><em>ID1,ID2</em></span> sleep <span class="emphasis"><em>seconds</em></span></pre><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
							When using the <code class="literal">-t</code> flag and stipulating thread ID’s, <code class="literal">perf</code> disables inheritance by default. You can enable inheritance by adding the <code class="literal">--inherit</code> option.
						</p></div></rh-alert></li></ul></div></section><section class="section" id="capturing-call-graph-data-with-perf-record_monitoring-application-performance-with-perf"><div class="titlepage"><div><div><h3 class="title">21.2. Capturing call graph data with perf record</h3></div></div></div><p class="_abstract _abstract">
				You can configure the <code class="literal">perf record</code> tool so that it records which function is calling other functions in the performance profile. This helps to identify a bottleneck if several processes are calling the same function.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have the <code class="literal">perf</code> user space tool installed as described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf">Installing perf</a>.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Sample and record performance data with the <code class="literal">--call-graph</code> option:
					</p><pre class="screen">$ perf record --call-graph <span class="emphasis"><em>method</em></span> <span class="emphasis"><em>command</em></span></pre><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
								Replace <code class="literal"><span class="emphasis"><em>command</em></span></code> with the command you want to sample data during. If you do not specify a command, then <code class="literal">perf record</code> will sample data until you manually stop it by pressing <kbd class="keycap">Ctrl</kbd>+<kbd class="keycap">C</kbd>.
							</li><li class="listitem"><p class="simpara">
								Replace <span class="emphasis"><em>method</em></span> with one of the following unwinding methods:
							</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">fp</code></span></dt><dd>
											Uses the frame pointer method. Depending on compiler optimization, such as with binaries built with the GCC option <code class="literal option">--fomit-frame-pointer</code>, this may not be able to unwind the stack.
										</dd><dt><span class="term"><code class="literal">dwarf</code></span></dt><dd>
											Uses DWARF Call Frame Information to unwind the stack.
										</dd><dt><span class="term"><code class="literal">lbr</code></span></dt><dd>
											Uses the last branch record hardware on Intel processors.
										</dd></dl></div></li></ul></div></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">perf-record(1)</code> man page on your system
					</li></ul></div></section><section class="section" id="analyzing-perf-data-with-perf-report_monitoring-application-performance-with-perf"><div class="titlepage"><div><div><h3 class="title">21.3. Analyzing perf.data with perf report</h3></div></div></div><p class="_abstract _abstract">
				You can use <code class="literal">perf report</code> to display and analyze a <code class="literal file">perf.data</code> file.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have the <code class="literal">perf</code> user space tool installed as described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf">Installing perf</a>.
					</li><li class="listitem">
						There is a <code class="literal file">perf.data</code> file in the current directory.
					</li><li class="listitem">
						If the <code class="literal file">perf.data</code> file was created with root access, you need to run <code class="literal">perf report</code> with root access too.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Display the contents of the <code class="literal file">perf.data</code> file for further analysis:
					</p><pre class="screen"># perf report</pre><p class="simpara">
						This command displays output similar to the following:
					</p><pre class="screen">Samples: 2K of event 'cycles', Event count (approx.): 235462960
Overhead  Command          Shared Object                     Symbol
   2.36%  kswapd0          [kernel.kallsyms]                 [k] page_vma_mapped_walk
   2.13%  sssd_kcm         libc-2.28.so                      [.] <span class="emphasis"><em>memset_avx2_erms 2.13% perf [kernel.kallsyms] [k] smp_call_function_single 1.53% gnome-shell libc-2.28.so [.] </em></span>strcmp_avx2
   1.17%  gnome-shell      libglib-2.0.so.0.5600.4           [.] g_hash_table_lookup
   0.93%  Xorg             libc-2.28.so                      [.] <span class="emphasis"><em>memmove_avx_unaligned_erms 0.89% gnome-shell libgobject-2.0.so.0.5600.4 [.] g_object_unref 0.87% kswapd0 [kernel.kallsyms] [k] page_referenced_one 0.86% gnome-shell libc-2.28.so [.] </em></span>memmove_avx_unaligned_erms
   0.83%  Xorg             [kernel.kallsyms]                 [k] alloc_vmap_area
   0.63%  gnome-shell      libglib-2.0.so.0.5600.4           [.] g_slice_alloc
   0.53%  gnome-shell      libgirepository-1.0.so.1.0.0      [.] g_base_info_unref
   0.53%  gnome-shell      ld-2.28.so                        [.] _dl_find_dso_for_object
   0.49%  kswapd0          [kernel.kallsyms]                 [k] vma_interval_tree_iter_next
   0.48%  gnome-shell      libpthread-2.28.so                [.] <span class="emphasis"><em>pthread_getspecific 0.47% gnome-shell libgirepository-1.0.so.1.0.0 [.] 0x0000000000013b1d 0.45% gnome-shell libglib-2.0.so.0.5600.4 [.] g_slice_free1 0.45% gnome-shell libgobject-2.0.so.0.5600.4 [.] g_type_check_instance_is_fundamentally_a 0.44% gnome-shell libc-2.28.so [.] malloc 0.41% swapper [kernel.kallsyms] [k] apic_timer_interrupt 0.40% gnome-shell ld-2.28.so [.] _dl_lookup_symbol_x 0.39% kswapd0 [kernel.kallsyms] [k] </em></span>raw_callee_save___pv_queued_spin_unlock</pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">perf-report(1)</code> man page on your system
					</li></ul></div></section></section><section class="chapter" id="creating-uprobes-with-perf_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 22. Creating uprobes with perf</h2></div></div></div><section class="section" id="proc_creating-uprobes-at-the-fucntion-level-with-perf_assembly_creating-uprobes-with-perf"><div class="titlepage"><div><div><h3 class="title">22.1. Creating uprobes at the function level with perf</h3></div></div></div><p class="_abstract _abstract">
				You can use the <code class="literal">perf</code> tool to create dynamic tracepoints at arbitrary points in a process or application. These tracepoints can then be used in conjunction with other <code class="literal">perf</code> tools such as <code class="literal">perf stat</code> and <code class="literal">perf record</code> to better understand the process or applications behavior.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have the <code class="literal">perf</code> user space tool installed as described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf">Installing perf</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Create the uprobe in the process or application you are interested in monitoring at a location of interest within the process or application:
					</p><pre class="literallayout"># perf probe -x <span class="emphasis"><em>/path/to/executable</em></span> -a <span class="emphasis"><em>function</em></span>
Added new event:
  <span class="emphasis"><em>probe_executable:function</em></span>   (on <span class="emphasis"><em>function</em></span> in <span class="emphasis"><em>/path/to/executable</em></span>)

You can now use it in all perf tools, such as:

        perf record -e <span class="emphasis"><em>probe_executable:function</em></span> -aR sleep 1</pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">perf-probe</code> man page on your system
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/recording-and-analyzing-performance-profiles-with-perf_monitoring-and-managing-system-status-and-performance">Recording and analyzing performance profiles with perf</a>
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/counting-events-during-process-execution-with-perf-stat_monitoring-and-managing-system-status-and-performance">Counting events during process execution with perf stat</a>
					</li></ul></div></section><section class="section" id="proc_creating-uprobes-on-lines-within-a-function-with-perf_assembly_creating-uprobes-with-perf"><div class="titlepage"><div><div><h3 class="title">22.2. Creating uprobes on lines within a function with perf</h3></div></div></div><p class="_abstract _abstract">
				These tracepoints can then be used in conjunction with other <code class="literal">perf</code> tools such as <code class="literal">perf stat</code> and <code class="literal">perf record</code> to better understand the process or applications behavior.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have the <code class="literal">perf</code> user space tool installed as described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf">Installing perf</a>.
					</li><li class="listitem"><p class="simpara">
						You have gotten the debugging symbols for your executable:
					</p><pre class="literallayout"># objdump -t <span class="emphasis"><em>./your_executable</em></span> | head</pre><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
							To do this, the <code class="literal">debuginfo</code> package of the executable must be installed or, if the executable is a locally developed application, the application must be compiled with debugging information, the <code class="literal">-g</code> option in GCC.
						</p></div></rh-alert></li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						View the function lines where you can place a uprobe:
					</p><pre class="literallayout">$ perf probe -x <span class="emphasis"><em>./your_executable</em></span> -L main</pre><p class="simpara">
						Output of this command looks similar to:
					</p><pre class="literallayout">&lt;main@/home/<span class="emphasis"><em>user</em></span>/<span class="emphasis"><em>my_executable</em></span>:0&gt;
              0  int main(int argc, const char **argv)
              1  {
                        int err;
                        const char *cmd;
                        char sbuf[STRERR_BUFSIZE];

                        /* libsubcmd init */
              7         exec_cmd_init("perf", PREFIX, PERF_EXEC_PATH, EXEC_PATH_ENVIRONMENT);
              8         pager_init(PERF_PAGER_ENVIRONMENT);</pre></li><li class="listitem"><p class="simpara">
						Create the uprobe for the desired function line:
					</p><pre class="literallayout"># perf probe -x ./<span class="emphasis"><em>my_executable</em></span> main:8
Added new event:
          probe_my_executable:main_L8   (on main:8 in /home/user/my_executable)

        You can now use it in all perf tools, such as:

                perf record -e probe_my_executable:main_L8 -aR sleep 1</pre></li></ol></div></section><section class="section" id="ref_perf-script-output-of-a-perf-data-file-generated-over-uprobes_assembly_creating-uprobes-with-perf"><div class="titlepage"><div><div><h3 class="title">22.3. Perf script output of data recorded over uprobes</h3></div></div></div><p class="_abstract _abstract">
				A common method to analyze data collected using uprobes is using the <code class="literal">perf script</code> command to read a <code class="literal">perf.data</code> file and display a detailed trace of the recorded workload.
			</p><p>
				In the perf script example output:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						A uprobe is added to the function <span class="strong strong"><strong>isprime()</strong></span> in a program called <span class="strong strong"><strong>my_prog</strong></span>
					</li><li class="listitem">
						<span class="strong strong"><strong>a</strong></span> is a function argument added to the uprobe. Alternatively, <span class="strong strong"><strong>a</strong></span> could be an arbitrary variable visible in the code scope of where you add your uprobe:
					</li></ul></div><pre class="screen"># perf script
    my_prog  1367 [007] 10802159.906593: probe_my_prog:isprime: (400551) a=2
    my_prog  1367 [007] 10802159.906623: probe_my_prog:isprime: (400551) a=3
    my_prog  1367 [007] 10802159.906625: probe_my_prog:isprime: (400551) a=4
    my_prog  1367 [007] 10802159.906627: probe_my_prog:isprime: (400551) a=5
    my_prog  1367 [007] 10802159.906629: probe_my_prog:isprime: (400551) a=6
    my_prog  1367 [007] 10802159.906631: probe_my_prog:isprime: (400551) a=7
    my_prog  1367 [007] 10802159.906633: probe_my_prog:isprime: (400551) a=13
    my_prog  1367 [007] 10802159.906635: probe_my_prog:isprime: (400551) a=17
    my_prog  1367 [007] 10802159.906637: probe_my_prog:isprime: (400551) a=19</pre></section></section><section class="chapter" id="profiling-memory-accesses-with-perf-mem_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 23. Profiling memory accesses with perf mem</h2></div></div></div><p class="_abstract _abstract">
			You can use the <code class="literal">perf mem</code> command to sample memory accesses on your system.
		</p><section class="section" id="the-purpose-of-perf-mem_profiling-memory-accesses-with-perf-mem"><div class="titlepage"><div><div><h3 class="title">23.1. The purpose of perf mem</h3></div></div></div><p class="_abstract _abstract">
				The <code class="literal">mem</code> subcommand of the <code class="literal">perf</code> tool enables the sampling of memory accesses (loads and stores). The <code class="literal">perf mem</code> command provides information about memory latency, types of memory accesses, functions causing cache hits and misses, and, by recording the data symbol, the memory locations where these hits and misses occur.
			</p></section><section class="section" id="sampling-memory-access-with-perf-mem_profiling-memory-accesses-with-perf-mem"><div class="titlepage"><div><div><h3 class="title">23.2. Sampling memory access with perf mem</h3></div></div></div><p class="_abstract _abstract">
				This procedure describes how to use the <code class="literal">perf mem</code> command to sample memory accesses on your system. The command takes the same options as <code class="literal">perf record</code> and <code class="literal">perf report</code> as well as some options exclusive to the <code class="literal">mem</code> subcommand. The recorded data is stored in a <code class="literal">perf.data</code> file in the current directory for later analysis.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have the <code class="literal">perf</code> user space tool installed as described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf">Installing perf</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Sample the memory accesses:
					</p><pre class="screen"># perf mem record -a sleep <span class="emphasis"><em>seconds</em></span></pre><p class="simpara">
						This example samples memory accesses across all CPUs for a period of <span class="emphasis"><em>seconds</em></span> seconds as dictated by the <code class="literal">sleep</code> command. You can replace the <code class="literal">sleep</code> command for any command during which you want to sample memory access data. By default, <code class="literal">perf mem</code> samples both memory loads and stores. You can select only one memory operation by using the <code class="literal">-t</code> option and specifying either "load" or "store" between <code class="literal">perf mem</code> and <code class="literal">record</code>. For loads, information over the memory hierarchy level, TLB memory accesses, bus snoops, and memory locks is captured.
					</p></li><li class="listitem"><p class="simpara">
						Open the <code class="literal">perf.data</code> file for analysis:
					</p><pre class="screen"># perf mem report</pre><p class="simpara">
						If you have used the example commands, the output is:
					</p><pre class="screen">Available samples
35k cpu/mem-loads,ldlat=30/P
54k cpu/mem-stores/P</pre><p class="simpara">
						The <code class="literal">cpu/mem-loads,ldlat=30/P</code> line denotes data collected over memory loads and the <code class="literal">cpu/mem-stores/P</code> line denotes data collected over memory stores. Highlight the category of interest and press <kbd class="keycap">Enter</kbd> to view the data:
					</p><pre class="literallayout">Samples: 35K of event 'cpu/mem-loads,ldlat=30/P', Event count (approx.): 4067062
Overhead       Samples  Local Weight  Memory access             Symbol                                                                 Shared Object                 Data Symbol                                                     Data Object                            Snoop         TLB access              Locked
   0.07%            29  98            L1 or L1 hit              [.] 0x000000000000a255                                                 libspeexdsp.so.1.5.0          [.] 0x00007f697a3cd0f0                                          anon                                   None          L1 or L2 hit            No
   0.06%            26  97            L1 or L1 hit              [.] 0x000000000000a255                                                 libspeexdsp.so.1.5.0          [.] 0x00007f697a3cd0f0                                          anon                                   None          L1 or L2 hit            No
   0.06%            25  96            L1 or L1 hit              [.] 0x000000000000a255                                                 libspeexdsp.so.1.5.0          [.] 0x00007f697a3cd0f0                                          anon                                   None          L1 or L2 hit            No
   0.06%             1  2325          Uncached or N/A hit       [k] pci_azx_readl                                                      [kernel.kallsyms]             [k] 0xffffb092c06e9084                                          [kernel.kallsyms]                      None          L1 or L2 hit            No
   0.06%             1  2247          Uncached or N/A hit       [k] pci_azx_readl                                                      [kernel.kallsyms]             [k] 0xffffb092c06e8164                                          [kernel.kallsyms]                      None          L1 or L2 hit            No
   0.05%             1  2166          L1 or L1 hit              [.] 0x00000000038140d6                                                 libxul.so                     [.] 0x00007ffd7b84b4a8                                          [stack]                                None          L1 or L2 hit            No
   0.05%             1  2117          Uncached or N/A hit       [k] check_for_unclaimed_mmio                                           [kernel.kallsyms]             [k] 0xffffb092c1842300                                          [kernel.kallsyms]                      None          L1 or L2 hit            No
   0.05%            22  95            L1 or L1 hit              [.] 0x000000000000a255                                                 libspeexdsp.so.1.5.0          [.] 0x00007f697a3cd0f0                                          anon                                   None          L1 or L2 hit            No
   0.05%             1  1898          L1 or L1 hit              [.] 0x0000000002a30e07                                                 libxul.so                     [.] 0x00007f610422e0e0                                          anon                                   None          L1 or L2 hit            No
   0.05%             1  1878          Uncached or N/A hit       [k] pci_azx_readl                                                      [kernel.kallsyms]             [k] 0xffffb092c06e8164                                          [kernel.kallsyms]                      None          L2 miss                 No
   0.04%            18  94            L1 or L1 hit              [.] 0x000000000000a255                                                 libspeexdsp.so.1.5.0          [.] 0x00007f697a3cd0f0                                          anon                                   None          L1 or L2 hit            No
   0.04%             1  1593          Local RAM or RAM hit      [.] 0x00000000026f907d                                                 libxul.so                     [.] 0x00007f3336d50a80                                          anon                                   Hit           L2 miss                 No
   0.03%             1  1399          L1 or L1 hit              [.] 0x00000000037cb5f1                                                 libxul.so                     [.] 0x00007fbe81ef5d78                                          libxul.so                              None          L1 or L2 hit            No
   0.03%             1  1229          LFB or LFB hit            [.] 0x0000000002962aad                                                 libxul.so                     [.] 0x00007fb6f1be2b28                                          anon                                   None          L2 miss                 No
   0.03%             1  1202          LFB or LFB hit            [.] __pthread_mutex_lock                                               libpthread-2.29.so            [.] 0x00007fb75583ef20                                          anon                                   None          L1 or L2 hit            No
   0.03%             1  1193          Uncached or N/A hit       [k] pci_azx_readl                                                      [kernel.kallsyms]             [k] 0xffffb092c06e9164                                          [kernel.kallsyms]                      None          L2 miss                 No
   0.03%             1  1191          L1 or L1 hit              [k] azx_get_delay_from_lpib                                            [kernel.kallsyms]             [k] 0xffffb092ca7efcf0                                          [kernel.kallsyms]                      None          L1 or L2 hit            No</pre><p class="simpara">
						Alternatively, you can sort your results to investigate different aspects of interest when displaying the data. For example, to sort data over memory loads by type of memory accesses occurring during the sampling period in descending order of overhead they account for:
					</p><pre class="screen"># perf mem -t load report --sort=mem</pre><p class="simpara">
						For example, the output can be:
					</p><pre class="screen">Samples: 35K of event 'cpu/mem-loads,ldlat=30/P', Event count (approx.): 40670
Overhead       Samples  Memory access
  31.53%          9725  LFB or LFB hit
  29.70%         12201  L1 or L1 hit
  23.03%          9725  L3 or L3 hit
  12.91%          2316  Local RAM or RAM hit
   2.37%           743  L2 or L2 hit
   0.34%             9  Uncached or N/A hit
   0.10%            69  I/O or N/A hit
   0.02%           825  L3 miss</pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">perf-mem(1)</code> man page on your system
					</li></ul></div></section><section class="section" id="interpretation-of-perf-mem-report-output_profiling-memory-accesses-with-perf-mem"><div class="titlepage"><div><div><h3 class="title">23.3. Interpretation of perf mem report output</h3></div></div></div><p class="_abstract _abstract">
				The table displayed by running the <code class="literal command">perf mem report</code> command without any modifiers sorts the data into several columns:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">The 'Overhead' column</span></dt><dd>
							Indicates percentage of overall samples collected in that particular function.
						</dd><dt><span class="term">The 'Samples' column</span></dt><dd>
							Displays the number of samples accounted for by that row.
						</dd><dt><span class="term">The 'Local Weight' column</span></dt><dd>
							Displays the access latency in processor core cycles.
						</dd><dt><span class="term">The 'Memory Access' column</span></dt><dd>
							Displays the type of memory access that occurred.
						</dd><dt><span class="term">The 'Symbol' column</span></dt><dd>
							Displays the function name or symbol.
						</dd><dt><span class="term">The 'Shared Object' column</span></dt><dd>
							Displays the name of the ELF image where the samples come from (the name [kernel.kallsyms] is used when the samples come from the kernel).
						</dd><dt><span class="term">The 'Data Symbol' column</span></dt><dd>
							Displays the address of the memory location that row was targeting.
						</dd></dl></div><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
					Oftentimes, due to dynamic allocation of memory or stack memory being accessed, the 'Data Symbol' column will display a raw address.
				</p></div></rh-alert><div class="variablelist"><dl class="variablelist"><dt><span class="term">The "Snoop" column</span></dt><dd>
							Displays bus transactions.
						</dd><dt><span class="term">The 'TLB Access' column</span></dt><dd>
							Displays TLB memory accesses.
						</dd><dt><span class="term">The 'Locked' column</span></dt><dd>
							Indicates if a function was or was not memory locked.
						</dd></dl></div><p>
				In default mode, the functions are sorted in descending order with those with the highest overhead displayed first.
			</p></section></section><section class="chapter" id="detecting-false-sharing_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 24. Detecting false sharing</h2></div></div></div><p class="_abstract _abstract">
			False sharing occurs when a processor core on a Symmetric Multi Processing (SMP) system modifies data items on the same cache line that is in use by other processors to access other data items that are not being shared between the processors.
		</p><p>
			This initial modification requires that the other processors using the cache line invalidate their copy and request an updated one despite the processors not needing, or even necessarily having access to, an updated version of the modified data item.
		</p><p>
			You can use the <code class="literal">perf c2c</code> command to detect false sharing.
		</p><section class="section" id="the-purpose-of-perf-c2c_detecting-false-sharing"><div class="titlepage"><div><div><h3 class="title">24.1. The purpose of perf c2c</h3></div></div></div><p class="_abstract _abstract">
				The <code class="literal">c2c</code> subcommand of the <code class="literal">perf</code> tool enables Shared Data Cache-to-Cache (C2C) analysis. You can use the <code class="literal">perf c2c</code> command to inspect cache-line contention to detect both true and false sharing.
			</p><p>
				Cache-line contention occurs when a processor core on a Symmetric Multi Processing (SMP) system modifies data items on the same cache line that is in use by other processors. All other processors using this cache-line must then invalidate their copy and request an updated one. This can lead to degraded performance.
			</p><p>
				The <code class="literal">perf c2c</code> command provides the following information:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Cache lines where contention has been detected
					</li><li class="listitem">
						Processes reading and writing the data
					</li><li class="listitem">
						Instructions causing the contention
					</li><li class="listitem">
						The Non-Uniform Memory Access (NUMA) nodes involved in the contention
					</li></ul></div></section><section class="section" id="detecting-cache-line-contention-with-perf-c2c_detecting-false-sharing"><div class="titlepage"><div><div><h3 class="title">24.2. Detecting cache-line contention with perf c2c</h3></div></div></div><p class="_abstract _abstract">
				Use the <code class="literal">perf c2c</code> command to detect cache-line contention in a system.
			</p><p>
				The <code class="literal">perf c2c</code> command supports the same options as <code class="literal">perf record</code> as well as some options exclusive to the <code class="literal">c2c</code> subcommand. The recorded data is stored in a <code class="literal">perf.data</code> file in the current directory for later analysis.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						The <code class="literal">perf</code> user space tool is installed. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf">installing perf</a>.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Use <code class="literal">perf c2c</code> to detect cache-line contention:
					</p><pre class="screen"># perf c2c record -a <span class="emphasis"><em>sleep</em></span> <span class="emphasis"><em>seconds</em></span></pre><p class="simpara">
						This example samples and records cache-line contention data across all CPU’s for a period of <code class="literal"><span class="emphasis"><em>seconds</em></span></code> as dictated by the <code class="literal">sleep</code> command. You can replace the <code class="literal">sleep</code> command with any command you want to collect cache-line contention data over.
					</p></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">perf-c2c(1)</code> man page on your system
					</li></ul></div></section><section class="section" id="visualizing-a-perf-data-file-recorded-with-perf-c2c-record_detecting-false-sharing"><div class="titlepage"><div><div><h3 class="title">24.3. Visualizing a perf.data file recorded with perf c2c record</h3></div></div></div><p class="_abstract _abstract">
				This procedure describes how to visualize the <code class="literal">perf.data</code> file, which is recorded using the <code class="literal">perf c2c</code> command.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						The <code class="literal">perf</code> user space tool is installed. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf">Installing perf</a>.
					</li><li class="listitem">
						A <code class="literal">perf.data</code> file recorded using the <code class="literal">perf c2c</code> command is available in the current directory. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/detecting-false-sharing_monitoring-and-managing-system-status-and-performance#detecting-cache-line-contention-with-perf-c2c_detecting-false-sharing">Detecting cache-line contention with perf c2c</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Open the <code class="literal">perf.data</code> file for further analysis:
					</p><pre class="screen"># perf c2c report --stdio</pre><p class="simpara">
						This command visualizes the <code class="literal">perf.data</code> file into several graphs within the terminal:
					</p><pre class="literallayout">=================================================
           Trace Event Information
=================================================
 Total records                     :     329219
 Locked Load/Store Operations      :      14654
 Load Operations                   :      69679
 Loads - uncacheable               :          0
 Loads - IO                        :          0
 Loads - Miss                      :       3972
 Loads - no mapping                :          0
 Load Fill Buffer Hit              :      11958
 Load L1D hit                      :      17235
 Load L2D hit                      :         21
 Load LLC hit                      :      14219
 Load Local HITM                   :       3402
 Load Remote HITM                  :      12757
 Load Remote HIT                   :       5295
 Load Local DRAM                   :        976
 Load Remote DRAM                  :       3246
 Load MESI State Exclusive         :       4222
 Load MESI State Shared            :          0
 Load LLC Misses                   :      22274
 LLC Misses to Local DRAM          :        4.4%
 LLC Misses to Remote DRAM         :       14.6%
 LLC Misses to Remote cache (HIT)  :       23.8%
 LLC Misses to Remote cache (HITM) :       57.3%
 Store Operations                  :     259539
 Store - uncacheable               :          0
 Store - no mapping                :         11
 Store L1D Hit                     :     256696
 Store L1D Miss                    :       2832
 No Page Map Rejects               :       2376
 Unable to parse data source       :          1

=================================================
   Global Shared Cache Line Event Information
=================================================
 Total Shared Cache Lines          :         55
 Load HITs on shared lines         :      55454
 Fill Buffer Hits on shared lines  :      10635
 L1D hits on shared lines          :      16415
 L2D hits on shared lines          :          0
 LLC hits on shared lines          :       8501
 Locked Access on shared lines     :      14351
 Store HITs on shared lines        :     109953
 Store L1D hits on shared lines    :     109449
 Total Merged records              :     126112

=================================================
                 c2c details
=================================================
 Events                            : cpu/mem-loads,ldlat=30/P
	                                    : cpu/mem-stores/P
 Cachelines sort on                : Remote HITMs
 Cacheline data groupping          : offset,pid,iaddr

=================================================
	   Shared Data Cache Line Table
=================================================
#
#                              Total      Rmt  ----- LLC Load Hitm -----  ---- Store Reference ----  --- Load Dram ----      LLC    Total  ----- Core Load Hit -----  -- LLC Load Hit --
# Index           Cacheline  records     Hitm    Total      Lcl      Rmt    Total    L1Hit   L1Miss       Lcl       Rmt  Ld Miss    Loads       FB       L1       L2       Llc       Rmt
# .....  ..................  .......  .......  .......  .......  .......  .......  .......  .......  ........  ........  .......  .......  .......  .......  .......  ........  ........
#
      0            0x602180   149904   77.09%    12103     2269     9834   109504   109036      468       727      2657    13747    40400     5355    16154        0      2875       529
      1            0x602100    12128   22.20%     3951     1119     2832        0        0        0        65       200     3749    12128     5096      108        0      2056       652
      2  0xffff883ffb6a7e80      260    0.09%       15        3       12      161      161        0         1         1       15       99       25       50        0         6         1
      3  0xffffffff81aec000      157    0.07%        9        0        9        1        0        1         0         7       20      156       50       59        0        27         4
      4  0xffffffff81e3f540      179    0.06%        9        1        8      117       97       20         0        10       25       62       11        1        0        24         7

=================================================
      Shared Cache Line Distribution Pareto
=================================================
#
#        ----- HITM -----  -- Store Refs --        Data address                               ---------- cycles ----------       cpu                                     Shared
#   Num      Rmt      Lcl   L1 Hit  L1 Miss              Offset      Pid        Code address  rmt hitm  lcl hitm      load       cnt               Symbol                Object                  Source:Line  Node{cpu list}
# .....  .......  .......  .......  .......  ..................  .......  ..................  ........  ........  ........  ........  ...................  ....................  ...........................  ....
#
  -------------------------------------------------------------
      0     9834     2269   109036      468            0x602180
  -------------------------------------------------------------
          65.51%   55.88%   75.20%    0.00%                 0x0    14604            0x400b4f     27161     26039     26017         9  [.] read_write_func  no_false_sharing.exe  false_sharing_example.c:144   0{0-1,4}  1{24-25,120}  2{48,54}  3{169}
	   0.41%    0.35%    0.00%    0.00%                 0x0    14604            0x400b56     18088     12601     26671         9  [.] read_write_func  no_false_sharing.exe  false_sharing_example.c:145   0{0-1,4}  1{24-25,120}  2{48,54}  3{169}
	   0.00%    0.00%   24.80%  100.00%                 0x0    14604            0x400b61         0         0         0         9  [.] read_write_func  no_false_sharing.exe  false_sharing_example.c:145   0{0-1,4}  1{24-25,120}  2{48,54}  3{169}
	   7.50%    9.92%    0.00%    0.00%                0x20    14604            0x400ba7      2470      1729      1897         2  [.] read_write_func  no_false_sharing.exe  false_sharing_example.c:154   1{122}  2{144}
	  17.61%   20.89%    0.00%    0.00%                0x28    14604            0x400bc1      2294      1575      1649         2  [.] read_write_func  no_false_sharing.exe  false_sharing_example.c:158   2{53}  3{170}
	   8.97%   12.96%    0.00%    0.00%                0x30    14604            0x400bdb      2325      1897      1828         2  [.] read_write_func  no_false_sharing.exe  false_sharing_example.c:162   0{96}  3{171}

  -------------------------------------------------------------
      1     2832     1119        0        0            0x602100
  -------------------------------------------------------------
	  29.13%   36.19%    0.00%    0.00%                0x20    14604            0x400bb3      1964      1230      1788         2  [.] read_write_func  no_false_sharing.exe  false_sharing_example.c:155   1{122}  2{144}
	  43.68%   34.41%    0.00%    0.00%                0x28    14604            0x400bcd      2274      1566      1793         2  [.] read_write_func  no_false_sharing.exe  false_sharing_example.c:159   2{53}  3{170}
	  27.19%   29.40%    0.00%    0.00%                0x30    14604            0x400be7      2045      1247      2011         2  [.] read_write_func  no_false_sharing.exe  false_sharing_example.c:163   0{96}  3{171}</pre></li></ol></div></section><section class="section" id="interpretation-of-perf-c2c-report-output_detecting-false-sharing"><div class="titlepage"><div><div><h3 class="title">24.4. Interpretation of perf c2c report output</h3></div></div></div><p class="_abstract _abstract">
				The visualization displayed by running the <code class="literal">perf c2c report --stdio</code> command sorts the data into several tables:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">Trace Events Information</code></span></dt><dd>
							This table provides a high level summary of all the load and store samples, which are collected by the <code class="literal">perf c2c record</code> command.
						</dd><dt><span class="term"><code class="literal">Global Shared Cache Line Event Information</code></span></dt><dd>
							This table provides statistics over the shared cache lines.
						</dd><dt><span class="term"><code class="literal">c2c Details</code></span></dt><dd>
							This table provides information about what events were sampled and how the <code class="literal">perf c2c report</code> data is organized within the visualization.
						</dd><dt><span class="term"><code class="literal">Shared Data Cache Line Table</code></span></dt><dd>
							This table provides a one line summary for the hottest cache lines where false sharing is detected and is sorted in descending order by the amount of remote <span class="strong strong"><strong>Hitm</strong></span> detected per cache line by default.
						</dd><dt><span class="term"><code class="literal">Shared Cache Line Distribution Pareto</code></span></dt><dd><p class="simpara">
							This tables provides a variety of information about each cache line experiencing contention:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									The cache lines are numbered in the <span class="strong strong"><strong>NUM</strong></span> column, starting at <code class="literal">0</code>.
								</li><li class="listitem">
									The virtual address of each cache line is contained in the <span class="strong strong"><strong>Data address Offset</strong></span> column and followed subsequently by the offset into the cache line where different accesses occurred.
								</li><li class="listitem">
									The <span class="strong strong"><strong>Pid</strong></span> column contains the process ID.
								</li><li class="listitem">
									The <span class="strong strong"><strong>Code Address</strong></span> column contains the instruction pointer code address.
								</li><li class="listitem">
									The columns under the <span class="strong strong"><strong>cycles</strong></span> label show average load latencies.
								</li><li class="listitem">
									The <span class="strong strong"><strong>cpu cnt</strong></span> column displays how many different CPUs samples came from (essentially, how many different CPUs were waiting for the data indexed at that given location).
								</li><li class="listitem">
									The <span class="strong strong"><strong>Symbol</strong></span> column displays the function name or symbol.
								</li><li class="listitem">
									The <span class="strong strong"><strong>Shared Object</strong></span> column displays the name of the ELF image where the samples come from (the name [<code class="literal">kernel.kallsyms</code>] is used when the samples come from the kernel).
								</li><li class="listitem">
									The <span class="strong strong"><strong>Source:Line</strong></span> column displays the source file and line number.
								</li><li class="listitem">
									The <span class="strong strong"><strong>Node{cpu list}</strong></span> column displays which specific CPUs samples came from for each node.
								</li></ul></div></dd></dl></div></section><section class="section" id="detecting-false-sharing-with-perf-c2c_detecting-false-sharing"><div class="titlepage"><div><div><h3 class="title">24.5. Detecting false sharing with perf c2c</h3></div></div></div><p class="_abstract _abstract">
				This procedure describes how to detect false sharing using the <code class="literal">perf c2c</code> command.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						The <code class="literal">perf</code> user space tool is installed. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf">installing perf</a>.
					</li><li class="listitem">
						A <code class="literal">perf.data</code> file recorded using the <code class="literal">perf c2c</code> command is available in the current directory. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/detecting-false-sharing_monitoring-and-managing-system-status-and-performance#detecting-cache-line-contention-with-perf-c2c_detecting-false-sharing">Detecting cache-line contention with perf c2c</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Open the <code class="literal">perf.data</code> file for further analysis:
					</p><pre class="screen"># perf c2c report --stdio</pre><p class="simpara">
						This opens the <code class="literal">perf.data</code> file in the terminal.
					</p></li><li class="listitem"><p class="simpara">
						In the "Trace Event Information" table, locate the row containing the values for <span class="strong strong"><strong>LLC Misses to Remote Cache (HITM)</strong></span>:
					</p><p class="simpara">
						The percentage in the value column of the <span class="strong strong"><strong>LLC Misses to Remote Cache (HITM)</strong></span> row represents the percentage of LLC misses that were occurring across NUMA nodes in modified cache-lines and is a key indicator false sharing has occurred.
					</p><pre class="literallayout">=================================================
            Trace Event Information
=================================================
  Total records                     :     329219
  Locked Load/Store Operations      :      14654
  Load Operations                   :      69679
  Loads - uncacheable               :          0
  Loads - IO                        :          0
  Loads - Miss                      :       3972
  Loads - no mapping                :          0
  Load Fill Buffer Hit              :      11958
  Load L1D hit                      :      17235
  Load L2D hit                      :         21
  Load LLC hit                      :      14219
  Load Local HITM                   :       3402
  Load Remote HITM                  :      12757
  Load Remote HIT                   :       5295
  Load Local DRAM                   :        976
  Load Remote DRAM                  :       3246
  Load MESI State Exclusive         :       4222
  Load MESI State Shared            :          0
  Load LLC Misses                   :      22274
  LLC Misses to Local DRAM          :        4.4%
  LLC Misses to Remote DRAM         :       14.6%
  LLC Misses to Remote cache (HIT)  :       23.8%
  <span class="strong strong"><strong>LLC Misses to Remote cache (HITM) : 57.3%</strong></span>
  Store Operations                  :     259539
  Store - uncacheable               :          0
  Store - no mapping                :         11
  Store L1D Hit                     :     256696
  Store L1D Miss                    :       2832
  No Page Map Rejects               :       2376
  Unable to parse data source       :          1</pre></li><li class="listitem"><p class="simpara">
						Inspect the <span class="strong strong"><strong>Rmt</strong></span> column of the <span class="strong strong"><strong>LLC Load Hitm</strong></span> field of the <span class="strong strong"><strong>Shared Data Cache Line Table</strong></span>:
					</p><pre class="literallayout">  =================================================
             Shared Data Cache Line Table
  =================================================
  #
  #                              Total      Rmt  <span class="strong strong"><strong>----- LLC Load Hitm -----</strong></span>  ---- Store Reference ----  --- Load Dram ----      LLC    Total  ----- Core Load Hit -----  -- LLC Load Hit --
  # Index           Cacheline  records     Hitm    Total      Lcl      <span class="strong strong"><strong>Rmt</strong></span>    Total    L1Hit   L1Miss       Lcl       Rmt  Ld Miss    Loads       FB       L1       L2       Llc       Rmt
  # .....  ..................  .......  .......  .......  .......  .......  .......  .......  .......  ........  ........  .......  .......  .......  .......  .......  ........  ........
  #
        0            0x602180   149904   77.09%    12103     2269     9834   109504   109036      468       727      2657    13747    40400     5355    16154        0      2875       529
        1            0x602100    12128   22.20%     3951     1119     2832        0        0        0        65       200     3749    12128     5096      108        0      2056       652
        2  0xffff883ffb6a7e80      260    0.09%       15        3       12      161      161        0         1         1       15       99       25       50        0         6         1
        3  0xffffffff81aec000      157    0.07%        9        0        9        1        0        1         0         7       20      156       50       59        0        27         4
        4  0xffffffff81e3f540      179    0.06%        9        1        8      117       97       20         0        10       25       62       11        1        0        24         7</pre><p class="simpara">
						This table is sorted in descending order by the amount of remote <span class="strong strong"><strong>Hitm</strong></span> detected per cache line. A high number in the <span class="strong strong"><strong>Rmt</strong></span> column of the <span class="strong strong"><strong>LLC Load Hitm</strong></span> section indicates false sharing and requires further inspection of the cache line on which it occurred to debug the false sharing activity.
					</p></li></ol></div></section></section><section class="chapter" id="getting-started-with-flamegraphs_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 25. Getting started with flamegraphs</h2></div></div></div><p class="_abstract _abstract">
			As a system administrator, you can use <code class="literal">flamegraphs</code> to create visualizations of system performance data recorded with the <code class="literal">perf</code> tool. As a software developer, you can use <code class="literal">flamegraphs</code> to create visualizations of application performance data recorded with the <code class="literal">perf</code> tool.
		</p><p>
			Sampling stack traces is a common technique for profiling CPU performance with the <code class="literal">perf</code> tool. Unfortunately, the results of profiling stack traces with <code class="literal">perf</code> can be extremely verbose and labor-intensive to analyze. <code class="literal">flamegraphs</code> are visualizations created from data recorded with <code class="literal">perf</code> to make identifying hot code-paths faster and easier.
		</p><section class="section" id="installing-flamegraphs_getting-started-with-flamegraphs"><div class="titlepage"><div><div><h3 class="title">25.1. Installing flamegraphs</h3></div></div></div><p class="_abstract _abstract">
				To begin using <code class="literal">flamegraphs</code>, install the required package.
			</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Install the <code class="literal">flamegraphs</code> package:
					</p><pre class="screen"># dnf install js-d3-flame-graph</pre></li></ul></div></section><section class="section" id="creating-flamegraphs-over-the-entire-system_getting-started-with-flamegraphs"><div class="titlepage"><div><div><h3 class="title">25.2. Creating flamegraphs over the entire system</h3></div></div></div><p class="_abstract _abstract">
				This procedure describes how to visualize performance data recorded over an entire system using <code class="literal">flamegraphs</code>.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						<code class="literal">flamegraphs</code> are installed as described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-flamegraphs_monitoring-and-managing-system-status-and-performance#installing-flamegraphs_getting-started-with-flamegraphs">installing flamegraphs</a>.
					</li><li class="listitem">
						The <code class="literal">perf</code> tool is installed as described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf">installing perf</a>.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Record the data and create the visualization:
					</p><pre class="screen"># perf script flamegraph -a -F 99 sleep 60</pre><p class="simpara">
						This command samples and records performance data over the entire system for 60 seconds, as stipulated by use of the <code class="literal">sleep</code> command, and then constructs the visualization which will be stored in the current active directory as <code class="literal">flamegraph.html</code>. The command samples call-graph data by default and takes the same arguments as the <code class="literal">perf</code> tool, in this particular case:
					</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">-a</code></span></dt><dd>
									Stipulates to record data over the entire system.
								</dd><dt><span class="term"><code class="literal">-F</code></span></dt><dd>
									To set the sampling frequency per second.
								</dd></dl></div></li></ul></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						For analysis, view the generated visualization:
					</p><pre class="screen"># xdg-open flamegraph.html</pre><p class="simpara">
						This command opens the visualization in the default browser:
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/a28282f7a290a148d48eb29b3a17d046/flamegraph_allcpus.png" alt="flamegraph allcpus"></span>

					</p></li></ul></div></section><section class="section" id="creating-flamegraphs-over-specific-processes_getting-started-with-flamegraphs"><div class="titlepage"><div><div><h3 class="title">25.3. Creating flamegraphs over specific processes</h3></div></div></div><p class="_abstract _abstract">
				You can use <code class="literal">flamegraphs</code> to visualize performance data recorded over specific running processes.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						<code class="literal">flamegraphs</code> are installed as described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-flamegraphs_monitoring-and-managing-system-status-and-performance#installing-flamegraphs_getting-started-with-flamegraphs">installing flamegraphs</a>.
					</li><li class="listitem">
						The <code class="literal">perf</code> tool is installed as described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf">installing perf</a>.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Record the data and create the visualization:
					</p><pre class="screen"># perf script flamegraph -a -F 99 -p <code class="literal"><span class="emphasis"><em>ID1,ID2</em></span></code> sleep 60</pre><p class="simpara">
						This command samples and records performance data of the processes with the process ID’s <code class="literal"><span class="emphasis"><em>ID1</em></span></code> and <code class="literal"><span class="emphasis"><em>ID2</em></span></code> for 60 seconds, as stipulated by use of the <code class="literal">sleep</code> command, and then constructs the visualization which will be stored in the current active directory as <code class="literal">flamegraph.html</code>. The command samples call-graph data by default and takes the same arguments as the <code class="literal">perf</code> tool, in this particular case:
					</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">-a</code></span></dt><dd>
									Stipulates to record data over the entire system.
								</dd><dt><span class="term"><code class="literal">-F</code></span></dt><dd>
									To set the sampling frequency per second.
								</dd><dt><span class="term"><code class="literal">-p</code></span></dt><dd>
									To stipulate specific process ID’s to sample and record data over.
								</dd></dl></div></li></ul></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						For analysis, view the generated visualization:
					</p><pre class="screen"># xdg-open flamegraph.html</pre><p class="simpara">
						This command opens the visualization in the default browser:
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/003d80d4f9d85ea8e33c627a40a2f333/flamegraph.png" alt="flamegraph"></span>

					</p></li></ul></div></section><section class="section" id="interpreting-flamegraphs_getting-started-with-flamegraphs"><div class="titlepage"><div><div><h3 class="title">25.4. Interpreting flamegraphs</h3></div></div></div><p class="_abstract _abstract">
				Each box in the flamegraph represents a different function in the stack. The y-axis shows the depth of the stack with the topmost box in each stack being the function that was actually on-CPU and everything below it being ancestry. The x-axis displays the population of the sampled call-graph data.
			</p><p>
				The children of a stack in a given row are displayed based on the number of samples taken of each respective function in descending order along the x-axis; the x-axis does not represent the passing of time. The wider an individual box is, the more frequent it was on-CPU or part of an on-CPU ancestry at the time the data was being sampled.
			</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						To reveal the names of functions which may have not been displayed previously and further investigate the data click on a box within the flamegraph to zoom into the stack at that given location:
					</p><p class="simpara">
						<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/0ea4b6a35abc82847a9eb7bb25bf1d6e/zoomed-in-flamegraph.png" alt="zoomed in flamegraph"></span>

					</p></li><li class="listitem">
						To return to the default view of the flamegraph, click <span class="guibutton">Reset Zoom</span>.
					</li></ul></div><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
					Boxes representing user-space functions may be labeled as <span class="strong strong"><strong>Unknown</strong></span> in <code class="literal">flamegraphs</code> because the binary of the function is stripped. The <code class="literal">debuginfo</code> package of the executable must be installed or, if the executable is a locally developed application, the application must be compiled with debugging information. Use the <code class="literal">-g</code> option in GCC, to display the function names or symbols in such a situation.
				</p><p>
					<span class="inlinemediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/003d80d4f9d85ea8e33c627a40a2f333/flamegraph.png" alt="flamegraph"></span>

				</p></div></rh-alert><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index#why-perf-displays-some-function-names-as-raw-function-addresses_profiling-cpu-usage-in-real-time-with-top">Why perf displays some function names as raw functions addresses</a>
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/developing_c_and_cpp_applications_in_rhel_9/debugging-applications_developing-applications#enabling-debugging-with-debugging-information_debugging-applications">Enabling debugging with debugging information</a>
					</li></ul></div></section></section><section class="chapter" id="creating-custom-circular-buffers-to-collect-specific-data-with-perf_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 26. Monitoring processes for performance bottlenecks using perf circular buffers</h2></div></div></div><p class="_abstract _abstract">
			You can create circular buffers that take event-specific snapshots of data with the <code class="literal">perf</code> tool in order to monitor performance bottlenecks in specific processes or parts of applications running on your system. In such cases, <code class="literal">perf</code> only writes data to a <code class="literal">perf.data</code> file for later analysis if a specified event is detected.
		</p><section class="section" id="circular-buffers-and-event-specific-snapshots_assembly_creating-custom-circular-buffers-to-collect-specific-data-with-perf"><div class="titlepage"><div><div><h3 class="title">26.1. Circular buffers and event-specific snapshots with perf</h3></div></div></div><p class="_abstract _abstract">
				When investigating performance issues in a process or application with <code class="literal">perf</code>, it may not be affordable or appropriate to record data for hours preceding a specific event of interest occurring. In such cases, you can use <code class="literal">perf record</code> to create custom circular buffers that take snapshots after specific events.
			</p><p>
				The <code class="literal option">--overwrite</code> option makes <code class="literal">perf record</code> store all data in an overwritable circular buffer. When the buffer gets full, <code class="literal">perf record</code> automatically overwrites the oldest records which, therefore, never get written to a <code class="literal file">perf.data</code> file.
			</p><p>
				Using the <code class="literal option">--overwrite</code> and <code class="literal option">--switch-output-event</code> options together configures a circular buffer that records and dumps data continuously until it detects the <code class="literal option">--switch-output-event</code> trigger event. The trigger event signals to <code class="literal">perf record</code> that something of interest to the user has occurred and to write the data in the circular buffer to a <code class="literal file">perf.data</code> file. This collects specific data you are interested in while simultaneously reducing the overhead of the running <code class="literal">perf</code> process by not writing data you do not want to a <code class="literal">perf.data</code> file.
			</p></section><section class="section" id="using-perf-to-create-custom-circular-buffers-that-perform-event-specific-snapshots_assembly_creating-custom-circular-buffers-to-collect-specific-data-with-perf"><div class="titlepage"><div><div><h3 class="title">26.2. Collecting specific data to monitor for performance bottlenecks using perf circular buffers</h3></div></div></div><p class="_abstract _abstract">
				With the <code class="literal">perf</code> tool, you can create circular buffers that are triggered by events you specify in order to only collect data you are interested in. To create circular buffers that collect event-specific data, use the <code class="literal">--overwrite</code> and <code class="literal">--switch-output-event</code> options for <code class="literal">perf</code>.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have the <code class="literal">perf</code> user space tool installed as described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf">Installing perf</a>.
					</li><li class="listitem"><p class="simpara">
						You have placed a uprobe in the process or application you are interested in monitoring at a location of interest within the process or application:
					</p><pre class="screen"># perf probe -x <span class="emphasis"><em>/path/to/executable</em></span> -a <span class="emphasis"><em>function</em></span>
Added new event:
  <span class="emphasis"><em>probe_executable:function</em></span>   (on <span class="emphasis"><em>function</em></span> in <span class="emphasis"><em>/path/to/executable</em></span>)

You can now use it in all perf tools, such as:

        perf record -e <span class="emphasis"><em>probe_executable:function</em></span> -aR sleep 1</pre></li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Create the circular buffer with the uprobe as the trigger event:
					</p><pre class="screen"># perf record --overwrite -e cycles --switch-output-event <span class="emphasis"><em>probe_executable:function</em></span> ./executable
[ perf record: dump data: Woken up 1 times ]
[ perf record: Dump perf.data.2021021012231959 ]
[ perf record: dump data: Woken up 1 times ]
[ perf record: Dump perf.data.2021021012232008 ]
^C[ perf record: dump data: Woken up 1 times ]
[ perf record: Dump perf.data.2021021012232082 ]
[ perf record: Captured and wrote 5.621 MB perf.data.&lt;timestamp&gt; ]</pre><p class="simpara">
						This example initiates the executable and collects cpu cycles, specified after the <code class="literal">-e</code> option, until <code class="literal">perf</code> detects the uprobe, the trigger event specified after the <code class="literal">--switch-output-event</code> option. At that point, <code class="literal">perf</code> takes a snapshot of all the data in the circular buffer and stores it in a unique <code class="literal">perf.data</code> file identified by timestamp. This example produced a total of 2 snapshots, the last <code class="literal">perf.data</code> file was forced by pressing <kbd class="keycap">Ctrl</kbd>+<kbd class="keycap">c</kbd>.
					</p></li></ul></div></section></section><section class="chapter" id="turning-tracepoints-on-and-off-without-stopping-or-restarting-perf_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 27. Adding and removing tracepoints from a running perf collector without stopping or restarting perf</h2></div></div></div><p class="_abstract _abstract">
			By using the control pipe interface to enable and disable different tracepoints in a running <code class="literal">perf</code> collector, you can dynamically adjust what data you are collecting without having to stop or restart <code class="literal">perf</code>. This ensures you do not lose performance data that would have otherwise been recorded during the stopping or restarting process.
		</p><section class="section" id="adding-tracepoints-to-a-running-perf-collector-without-stopping-or-restarting-perf_turning-tracepoints-on-and-off-without-stopping-or-restarting-perf"><div class="titlepage"><div><div><h3 class="title">27.1. Adding tracepoints to a running perf collector without stopping or restarting perf</h3></div></div></div><p class="_abstract _abstract">
				Add tracepoints to a running <code class="literal">perf</code> collector using the control pipe interface to adjust the data you are recording without having to stop <code class="literal">perf</code> and losing performance data.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have the <code class="literal">perf</code> user space tool installed as described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf">Installing perf</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Configure the control pipe interface:
					</p><pre class="screen"># mkfifo control ack perf.pipe</pre></li><li class="listitem"><p class="simpara">
						Run <code class="literal">perf record</code> with the control file setup and events you are interested in enabling:
					</p><pre class="screen"># perf record --control=fifo:control,ack -D -1 --no-buffering -e '<span class="emphasis"><em>sched:*</em></span>' -o - &gt; perf.pipe</pre><p class="simpara">
						In this example, declaring <code class="literal">'sched:*'</code> after the <code class="literal">-e</code> option starts <code class="literal">perf record</code> with scheduler events.
					</p></li><li class="listitem"><p class="simpara">
						In a second terminal, start the read side of the control pipe:
					</p><pre class="screen"># cat perf.pipe | perf --no-pager script -i -</pre><p class="simpara">
						Starting the read side of the control pipe triggers the following message in the first terminal:
					</p><pre class="screen">Events disabled</pre></li><li class="listitem"><p class="simpara">
						In a third terminal, enable a tracepoint using the control file:
					</p><pre class="screen"># echo 'enable <span class="emphasis"><em>sched:sched_process_fork</em></span>' &gt; control</pre><p class="simpara">
						This command triggers <code class="literal">perf</code> to scan the current event list in the control file for the declared event. If the event is present, the tracepoint is enabled and the following message appears in the first terminal:
					</p><pre class="screen">event sched:sched_process_fork enabled</pre><p class="simpara">
						Once the tracepoint is enabled, the second terminal displays the output from <code class="literal">perf</code> detecting the tracepoint:
					</p><pre class="screen">bash 33349 [034] 149587.674295: sched:sched_process_fork: comm=bash pid=33349 child_comm=bash child_pid=34056</pre></li></ol></div></section><section class="section" id="removing-tracepoints-from-a-running-perf-collector-without-stopping-or-restarting-perf_turning-tracepoints-on-and-off-without-stopping-or-restarting-perf"><div class="titlepage"><div><div><h3 class="title">27.2. Removing tracepoints from a running perf collector without stopping or restarting perf</h3></div></div></div><p class="_abstract _abstract">
				Remove tracepoints from a running <code class="literal">perf</code> collector using the control pipe interface to reduce the scope of data you are collecting without having to stop <code class="literal">perf</code> and losing performance data.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have the <code class="literal">perf</code> user space tool installed as described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf">Installing perf</a>.
					</li><li class="listitem">
						You have added tracepoints to a running <code class="literal">perf</code> collector via the control pipe interface. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/turning-tracepoints-on-and-off-without-stopping-or-restarting-perf_monitoring-and-managing-system-status-and-performance#adding-tracepoints-to-a-running-perf-collector-without-stopping-or-restarting-perf_turning-tracepoints-on-and-off-without-stopping-or-restarting-perf">Adding tracepoints to a running perf collector without stopping or restarting perf</a>.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Remove the tracepoint:
					</p><pre class="screen"># echo 'disable <span class="emphasis"><em>sched:sched_process_fork</em></span>' &gt; control</pre><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
							This example assumes you have previously loaded scheduler events into the control file and enabled the tracepoint <code class="literal">sched:sched_process_fork</code>.
						</p></div></rh-alert><p class="simpara">
						This command triggers <code class="literal">perf</code> to scan the current event list in the control file for the declared event. If the event is present, the tracepoint is disabled and the following message appears in the terminal used to configure the control pipe:
					</p><pre class="screen">event sched:sched_process_fork disabled</pre></li></ul></div></section></section><section class="chapter" id="profiling-memory-allocation-with-numastat_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 28. Profiling memory allocation with numastat</h2></div></div></div><p class="_abstract _abstract">
			With the <code class="literal">numastat</code> tool, you can display statistics over memory allocations in a system.
		</p><p>
			The <code class="literal">numastat</code> tool displays data for each NUMA node separately. You can use this information to investigate memory performance of your system or the effectiveness of different memory policies on your system.
		</p><section class="section" id="default-numastat-statistics_profiling-memory-allocation-with-numastat"><div class="titlepage"><div><div><h3 class="title">28.1. Default numastat statistics</h3></div></div></div><p class="_abstract _abstract">
				By default, the <code class="literal">numastat</code> tool displays statistics over these categories of data for each NUMA node:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">numa_hit</code></span></dt><dd>
							The number of pages that were successfully allocated to this node.
						</dd><dt><span class="term"><code class="literal">numa_miss</code></span></dt><dd>
							The number of pages that were allocated on this node because of low memory on the intended node. Each <code class="literal">numa_miss</code> event has a corresponding <code class="literal">numa_foreign</code> event on another node.
						</dd><dt><span class="term"><code class="literal">numa_foreign</code></span></dt><dd>
							The number of pages initially intended for this node that were allocated to another node instead. Each <code class="literal">numa_foreign</code> event has a corresponding <code class="literal">numa_miss</code> event on another node.
						</dd><dt><span class="term"><code class="literal">interleave_hit</code></span></dt><dd>
							The number of interleave policy pages successfully allocated to this node.
						</dd><dt><span class="term"><code class="literal">local_node</code></span></dt><dd>
							The number of pages successfully allocated on this node by a process on this node.
						</dd><dt><span class="term"><code class="literal">other_node</code></span></dt><dd>
							The number of pages allocated on this node by a process on another node.
						</dd></dl></div><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					High <code class="literal">numa_hit</code> values and low <code class="literal">numa_miss</code> values (relative to each other) indicate optimal performance.
				</p></div></rh-alert></section><section class="section" id="viewing-memory-allocation-with-numastat_profiling-memory-allocation-with-numastat"><div class="titlepage"><div><div><h3 class="title">28.2. Viewing memory allocation with numastat</h3></div></div></div><p class="_abstract _abstract">
				You can view the memory allocation of the system by using the <code class="literal">numastat</code> tool.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Install the <code class="literal">numactl</code> package:
					</p><pre class="screen"># dnf install numactl</pre></li></ul></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						View the memory allocation of your system:
					</p><pre class="screen">$ numastat
                             node0         node1
numa_hit                  76557759      92126519
numa_miss                 30772308      30827638
numa_foreign              30827638      30772308
interleave_hit              106507        103832
local_node                76502227      92086995
other_node                30827840      30867162</pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">numastat(8)</code> man page on your system
					</li></ul></div></section></section><section class="chapter" id="configuring-an-operating-system-to-optimize-cpu-utilization_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 29. Configuring an operating system to optimize CPU utilization</h2></div></div></div><p class="_abstract _abstract">
			You can configure the operating system to optimize CPU utilization across their workloads.
		</p><section class="section" id="tools-for-monitoring-and-diagnosing-processor-issues_configuring-an-operating-system-to-optimize-cpu-utilization"><div class="titlepage"><div><div><h3 class="title">29.1. Tools for monitoring and diagnosing processor issues</h3></div></div></div><p class="_abstract _abstract">
				The following are the tools available in Red Hat Enterprise Linux 9 to monitor and diagnose processor-related performance issues:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						<code class="literal">turbostat</code> tool prints counter results at specified intervals to help administrators identify unexpected behavior in servers, such as excessive power usage, failure to enter deep sleep states, or system management interrupts (SMIs) being created unnecessarily.
					</li><li class="listitem">
						<code class="literal">numactl</code> utility provides a number of options to manage processor and memory affinity. The <code class="literal">numactl</code> package includes the <code class="literal">libnuma</code> library which offers a simple programming interface to the NUMA policy supported by the kernel, and can be used for more fine-grained tuning than the <code class="literal">numactl</code> application.
					</li><li class="listitem">
						<code class="literal">numastat</code> tool displays per-NUMA node memory statistics for the operating system and its processes, and shows administrators whether the process memory is spread throughout a system or is centralized on specific nodes. This tool is provided by the <code class="literal">numactl</code> package.
					</li><li class="listitem">
						<code class="literal">numad</code> is an automatic NUMA affinity management daemon. It monitors NUMA topology and resource usage within a system in order to dynamically improve NUMA resource allocation and management.
					</li><li class="listitem">
						<code class="literal">/proc/interrupts</code> file displays the interrupt request (IRQ) number, the number of similar interrupt requests handled by each processor in the system, the type of interrupt sent, and a comma-separated list of devices that respond to the listed interrupt request.
					</li><li class="listitem"><p class="simpara">
						<code class="literal">pqos</code> utility is available in the <code class="literal">intel-cmt-cat</code> package. It monitors CPU cache and memory bandwidth on recent Intel processors. It monitors:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
								The instructions per cycle (IPC).
							</li><li class="listitem">
								The count of last level cache MISSES.
							</li><li class="listitem">
								The size in kilobytes that the program executing in a given CPU occupies in the LLC.
							</li><li class="listitem">
								The bandwidth to local memory (MBL).
							</li><li class="listitem">
								The bandwidth to remote memory (MBR).
							</li></ul></div></li><li class="listitem">
						<code class="literal">x86_energy_perf_policy</code> tool allows administrators to define the relative importance of performance and energy efficiency. This information can then be used to influence processors that support this feature when they select options that trade off between performance and energy efficiency.
					</li><li class="listitem">
						<code class="literal">taskset</code> tool is provided by the <code class="literal">util-linux</code> package. It allows administrators to retrieve and set the processor affinity of a running process, or launch a process with a specified processor affinity.
					</li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">turbostat(8)</code>, <code class="literal">numactl(8)</code>, <code class="literal">numastat(8)</code>, <code class="literal">numa(7)</code>, <code class="literal">numad(8)</code>, <code class="literal">pqos(8)</code>, <code class="literal">x86_energy_perf_policy(8)</code>, and <code class="literal">taskset(1)</code> man pages on your system
					</li></ul></div></section><section class="section" id="types-of-system-topology_configuring-an-operating-system-to-optimize-cpu-utilization"><div class="titlepage"><div><div><h3 class="title">29.2. Types of system topology</h3></div></div></div><p class="_abstract _abstract">
				In modern computing, the idea of a CPU is a misleading one, as most modern systems have multiple processors. The topology of the system is the way these processors are connected to each other and to other system resources. This can affect system and application performance, and the tuning considerations for a system.
			</p><p>
				The following are the two primary types of topology used in modern computing:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">Symmetric Multi-Processor (SMP) topology</code></span></dt><dd>
							SMP topology allows all processors to access memory in the same amount of time. However, because shared and equal memory access inherently forces serialized memory accesses from all the CPUs, SMP system scaling constraints are now generally viewed as unacceptable. For this reason, practically all modern server systems are NUMA machines.
						</dd><dt><span class="term"><code class="literal">Non-Uniform Memory Access (NUMA) topology</code></span></dt><dd><p class="simpara">
							NUMA topology was developed more recently than SMP topology. In a NUMA system, multiple processors are physically grouped on a socket. Each socket has a dedicated area of memory and processors that have local access to that memory, these are referred to collectively as a node. Processors on the same node have high speed access to that node’s memory bank, and slower access to memory banks not on their node.
						</p><p class="simpara">
							Therefore, there is a performance penalty when accessing non-local memory. Thus, performance sensitive applications on a system with NUMA topology should access memory that is on the same node as the processor executing the application, and should avoid accessing remote memory wherever possible.
						</p><p class="simpara">
							Multi-threaded applications that are sensitive to performance may benefit from being configured to execute on a specific NUMA node rather than a specific processor. Whether this is suitable depends on your system and the requirements of your application. If multiple application threads access the same cached data, then configuring those threads to execute on the same processor may be suitable. However, if multiple threads that access and cache different data execute on the same processor, each thread may evict cached data accessed by a previous thread. This means that each thread 'misses' the cache and wastes execution time fetching data from memory and replacing it in the cache. Use the <code class="literal">perf</code> tool to check for an excessive number of cache misses.
						</p></dd></dl></div><section class="section" id="displaying-system-topologies_configuring-an-operating-system-to-optimize-cpu-utilization"><div class="titlepage"><div><div><h4 class="title">29.2.1. Displaying system topologies</h4></div></div></div><p class="_abstract _abstract">
					There are a number of commands that help understand the topology of a system. This procedure describes how to determine the system topology.
				</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							To display an overview of your system topology:
						</p><pre class="screen">$ numactl --hardware
available: 4 nodes (0-3)
node 0 cpus: 0 4 8 12 16 20 24 28 32 36
node 0 size: 65415 MB
node 0 free: 43971 MB
[...]</pre></li><li class="listitem"><p class="simpara">
							To gather the information about the CPU architecture, such as the number of CPUs, threads, cores, sockets, and NUMA nodes:
						</p><pre class="screen">$ lscpu
Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                40
On-line CPU(s) list:   0-39
Thread(s) per core:    1
Core(s) per socket:    10
Socket(s):             4
NUMA node(s):          4
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 47
Model name:            Intel(R) Xeon(R) CPU E7- 4870  @ 2.40GHz
Stepping:              2
CPU MHz:               2394.204
BogoMIPS:              4787.85
Virtualization:        VT-x
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              30720K
NUMA node0 CPU(s):     0,4,8,12,16,20,24,28,32,36
NUMA node1 CPU(s):     2,6,10,14,18,22,26,30,34,38
NUMA node2 CPU(s):     1,5,9,13,17,21,25,29,33,37
NUMA node3 CPU(s):     3,7,11,15,19,23,27,31,35,39</pre></li><li class="listitem"><p class="simpara">
							To view a graphical representation of your system:
						</p><pre class="screen"># dnf install hwloc-gui
# lstopo</pre><div class="figure" id="idm140280133768240"><p class="title"><strong>Figure 29.1. The <code class="literal">lstopo</code> output</strong></p><div class="figure-contents"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/7ddd66e302a97d0b710e23e0af9d6524/lstopo.png" alt="lstopo"></div></div></div></li><li class="listitem"><p class="simpara">
							To view the detailed textual output:
						</p><pre class="screen"># dnf install hwloc
# lstopo-no-graphics
Machine (15GB)
  Package L#0 + L3 L#0 (8192KB)
    L2 L#0 (256KB) + L1d L#0 (32KB) + L1i L#0 (32KB) + Core L#0
        PU L#0 (P#0)
        PU L#1 (P#4)
       HostBridge L#0
    PCI 8086:5917
        GPU L#0 "renderD128"
        GPU L#1 "controlD64"
        GPU L#2 "card0"
    PCIBridge
        PCI 8086:24fd
          Net L#3 "wlp61s0"
    PCIBridge
        PCI 8086:f1a6
    PCI 8086:15d7
        Net L#4 "enp0s31f6"</pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<code class="literal">numactl(8)</code>, <code class="literal">lscpu(1)</code>, and <code class="literal">lstopo(1)</code> man pages on your system
						</li></ul></div></section></section><section class="section" id="configuring-kernel-tick-time_configuring-an-operating-system-to-optimize-cpu-utilization"><div class="titlepage"><div><div><h3 class="title">29.3. Configuring kernel tick time</h3></div></div></div><p class="_abstract _abstract">
				By default, Red Hat Enterprise Linux 9 uses a tickless kernel, which does not interrupt idle CPUs in order to reduce power usage and allow new processors to take advantage of deep sleep states.
			</p><p>
				Red Hat Enterprise Linux 9 also offers a dynamic tickless option, which is useful for latency-sensitive workloads, such as high performance computing or realtime computing. By default, the dynamic tickless option is disabled. Red Hat recommends using the <code class="literal">cpu-partitioning</code> <span class="strong strong"><strong>TuneD</strong></span> profile to enable the dynamic tickless option for cores specified as <code class="literal">isolated_cores</code>.
			</p><p>
				This procedure describes how to manually persistently enable dynamic tickless behavior.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						To enable dynamic tickless behavior in certain cores, specify those cores on the kernel command line with the <code class="literal">nohz_full</code> parameter. On a 16 core system, enable the <code class="literal">nohz_full=1-15</code> kernel option:
					</p><pre class="screen"># grubby --update-kernel=ALL --args="nohz_full=1-15"</pre><p class="simpara">
						This enables dynamic tickless behavior on cores <code class="literal">1</code> through <code class="literal">15</code>, moving all timekeeping to the only unspecified core (core <code class="literal">0</code>).
					</p></li><li class="listitem"><p class="simpara">
						When the system boots, manually move the <code class="literal">rcu</code> threads to the non-latency-sensitive core, in this case core <code class="literal">0</code>:
					</p><pre class="screen"># for i in `pgrep rcu[^c]` ; do taskset -pc 0 $i ; done</pre></li><li class="listitem">
						Optional: Use the <code class="literal">isolcpus</code> parameter on the kernel command line to isolate certain cores from user-space tasks.
					</li><li class="listitem"><p class="simpara">
						Optional: Set the CPU affinity for the kernel’s <code class="literal">write-back bdi-flush</code> threads to the housekeeping core:
					</p><pre class="screen">echo 1 &gt; /sys/bus/workqueue/devices/writeback/cpumask</pre></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Once the system is rebooted, verify if <code class="literal">dynticks</code> are enabled:
					</p><pre class="screen"># journalctl -xe | grep dynticks
Mar 15 18:34:54 rhel-server kernel: NO_HZ: Full dynticks CPUs: 1-15.</pre></li><li class="listitem"><p class="simpara">
						Verify that the dynamic tickless configuration is working correctly:
					</p><pre class="screen"># perf stat -C 1 -e irq_vectors:local_timer_entry taskset -c 1 sleep 3</pre><p class="simpara">
						This command measures ticks on CPU 1 while telling CPU 1 to sleep for 3 seconds.
					</p></li><li class="listitem"><p class="simpara">
						The default kernel timer configuration shows around 3100 ticks on a regular CPU:
					</p><pre class="screen"># perf stat -C 0 -e irq_vectors:local_timer_entry taskset -c 0 sleep 3

 Performance counter stats for 'CPU(s) 0':

             3,107      irq_vectors:local_timer_entry

       3.001342790 seconds time elapsed</pre></li><li class="listitem"><p class="simpara">
						With the dynamic tickless kernel configured, you should see around 4 ticks instead:
					</p><pre class="screen"># perf stat -C 1 -e irq_vectors:local_timer_entry taskset -c 1 sleep 3

 Performance counter stats for 'CPU(s) 1':

                 4      irq_vectors:local_timer_entry

       3.001544078 seconds time elapsed</pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">perf(1)</code> and <code class="literal">cpuset(7)</code> man pages on your system
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/solutions/2273531">All about nohz_full kernel parameter Red Hat Knowledgebase article</a> (Red Hat Knowledgebase)
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/solutions/3875421">How to verify the list of "isolated" and "nohz_full" CPU information from sysfs? Red Hat Knowledgebase article</a> (Red Hat Knowledgebase)
					</li></ul></div></section><section class="section" id="overview-of-an-interrupt-request_configuring-an-operating-system-to-optimize-cpu-utilization"><div class="titlepage"><div><div><h3 class="title">29.4. Overview of an interrupt request</h3></div></div></div><p class="_abstract _abstract">
				An interrupt request or IRQ is a signal for immediate attention sent from a piece of hardware to a processor. Each device in a system is assigned one or more IRQ numbers which allow it to send unique interrupts. When interrupts are enabled, a processor that receives an interrupt request immediately pauses execution of the current application thread in order to address the interrupt request.
			</p><p>
				Because interrupt halts normal operation, high interrupt rates can severely degrade system performance. It is possible to reduce the amount of time taken by interrupts by configuring interrupt affinity or by sending a number of lower priority interrupts in a batch (coalescing a number of interrupts).
			</p><p>
				Interrupt requests have an associated affinity property, <code class="literal">smp_affinity</code>, which defines the processors that handle the interrupt request. To improve application performance, assign interrupt affinity and process affinity to the same processor, or processors on the same core. This allows the specified interrupt and application threads to share cache lines.
			</p><p>
				On systems that support interrupt steering, modifying the <code class="literal">smp_affinity</code> property of an interrupt request sets up the hardware so that the decision to service an interrupt with a particular processor is made at the hardware level with no intervention from the kernel.
			</p><section class="section" id="balancing-interrupts-manually_configuring-an-operating-system-to-optimize-cpu-utilization"><div class="titlepage"><div><div><h4 class="title">29.4.1. Balancing interrupts manually</h4></div></div></div><p class="_abstract _abstract">
					If your BIOS exports its NUMA topology, the <code class="literal">irqbalance</code> service can automatically serve interrupt requests on the node that is local to the hardware requesting service.
				</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem">
							Check which devices correspond to the interrupt requests that you want to configure.
						</li><li class="listitem"><p class="simpara">
							Find the hardware specification for your platform. Check if the chipset on your system supports distributing interrupts.
						</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem">
									If it does, you can configure interrupt delivery as described in the following steps. Additionally, check which algorithm your chipset uses to balance interrupts. Some BIOSes have options to configure interrupt delivery.
								</li><li class="listitem">
									If it does not, your chipset always routes all interrupts to a single, static CPU. You cannot configure which CPU is used.
								</li></ol></div></li><li class="listitem"><p class="simpara">
							Check which Advanced Programmable Interrupt Controller (APIC) mode is in use on your system:
						</p><pre class="screen">$ journalctl --dmesg | grep APIC</pre><p class="simpara">
							Here,
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									If your system uses a mode other than <code class="literal">flat</code>, you can see a line similar to <code class="literal">Setting APIC routing to physical flat</code>.
								</li><li class="listitem"><p class="simpara">
									If you can see no such message, your system uses <code class="literal">flat</code> mode.
								</p><p class="simpara">
									If your system uses <code class="literal">x2apic</code> mode, you can disable it by adding the <code class="literal">nox2apic</code> option to the kernel command line in the <code class="literal">bootloader</code> configuration.
								</p><p class="simpara">
									Only non-physical flat mode (<code class="literal">flat</code>) supports distributing interrupts to multiple CPUs. This mode is available only for systems that have up to <code class="literal">8</code> CPUs.
								</p></li></ul></div></li><li class="listitem">
							Calculate the <code class="literal">smp_affinity mask</code>. For more information about how to calculate the <code class="literal">smp_affinity mask</code>, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/configuring-an-operating-system-to-optimize-cpu-utilization_monitoring-and-managing-system-status-and-performance#setting-the-smp_affinity-mask_configuring-an-operating-system-to-optimize-cpu-utilization">Setting the smp_affinity mask</a>.
						</li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<code class="literal">journalctl(1)</code> and <code class="literal">taskset(1)</code> man pages on your system
						</li></ul></div></section><section class="section" id="setting-the-smp_affinity-mask_configuring-an-operating-system-to-optimize-cpu-utilization"><div class="titlepage"><div><div><h4 class="title">29.4.2. Setting the smp_affinity mask</h4></div></div></div><p class="_abstract _abstract">
					The <code class="literal">smp_affinity</code> value is stored as a hexadecimal bit mask representing all processors in the system. Each bit configures a different CPU. The least significant bit is CPU 0.
				</p><p>
					The default value of the mask is <code class="literal">f</code>, which means that an interrupt request can be handled on any processor in the system. Setting this value to 1 means that only processor 0 can handle the interrupt.
				</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							In binary, use the value 1 for CPUs that handle the interrupts. For example, to set CPU 0 and CPU 7 to handle interrupts, use <code class="literal">0000000010000001</code> as the binary code:
						</p><rh-table id="idm140280130434080"><table class="gt-8-cols lt-7-rows"><caption>Table 29.1. Binary Bits for CPUs</caption><colgroup><col style="width: 17%; " class="col_1"><!--Empty--><col style="width: 5%; " class="col_2"><!--Empty--><col style="width: 5%; " class="col_3"><!--Empty--><col style="width: 5%; " class="col_4"><!--Empty--><col style="width: 5%; " class="col_5"><!--Empty--><col style="width: 5%; " class="col_6"><!--Empty--><col style="width: 5%; " class="col_7"><!--Empty--><col style="width: 5%; " class="col_8"><!--Empty--><col style="width: 5%; " class="col_9"><!--Empty--><col style="width: 5%; " class="col_10"><!--Empty--><col style="width: 5%; " class="col_11"><!--Empty--><col style="width: 5%; " class="col_12"><!--Empty--><col style="width: 5%; " class="col_13"><!--Empty--><col style="width: 5%; " class="col_14"><!--Empty--><col style="width: 5%; " class="col_15"><!--Empty--><col style="width: 5%; " class="col_16"><!--Empty--><col style="width: 5%; " class="col_17"><!--Empty--></colgroup><tbody><tr><td align="left" valign="top"> <p>
											CPU
										</p>
										 </td><td align="left" valign="top"> <p>
											15
										</p>
										 </td><td align="left" valign="top"> <p>
											14
										</p>
										 </td><td align="left" valign="top"> <p>
											13
										</p>
										 </td><td align="left" valign="top"> <p>
											12
										</p>
										 </td><td align="left" valign="top"> <p>
											11
										</p>
										 </td><td align="left" valign="top"> <p>
											10
										</p>
										 </td><td align="left" valign="top"> <p>
											9
										</p>
										 </td><td align="left" valign="top"> <p>
											8
										</p>
										 </td><td align="left" valign="top"> <p>
											7
										</p>
										 </td><td align="left" valign="top"> <p>
											6
										</p>
										 </td><td align="left" valign="top"> <p>
											5
										</p>
										 </td><td align="left" valign="top"> <p>
											4
										</p>
										 </td><td align="left" valign="top"> <p>
											3
										</p>
										 </td><td align="left" valign="top"> <p>
											2
										</p>
										 </td><td align="left" valign="top"> <p>
											1
										</p>
										 </td><td align="left" valign="top"> <p>
											0
										</p>
										 </td></tr><tr><td align="left" valign="top"> <p>
											Binary
										</p>
										 </td><td align="left" valign="top"> <p>
											0
										</p>
										 </td><td align="left" valign="top"> <p>
											0
										</p>
										 </td><td align="left" valign="top"> <p>
											0
										</p>
										 </td><td align="left" valign="top"> <p>
											0
										</p>
										 </td><td align="left" valign="top"> <p>
											0
										</p>
										 </td><td align="left" valign="top"> <p>
											0
										</p>
										 </td><td align="left" valign="top"> <p>
											0
										</p>
										 </td><td align="left" valign="top"> <p>
											0
										</p>
										 </td><td align="left" valign="top"> <p>
											1
										</p>
										 </td><td align="left" valign="top"> <p>
											0
										</p>
										 </td><td align="left" valign="top"> <p>
											0
										</p>
										 </td><td align="left" valign="top"> <p>
											0
										</p>
										 </td><td align="left" valign="top"> <p>
											0
										</p>
										 </td><td align="left" valign="top"> <p>
											0
										</p>
										 </td><td align="left" valign="top"> <p>
											0
										</p>
										 </td><td align="left" valign="top"> <p>
											1
										</p>
										 </td></tr></tbody></table></rh-table></li><li class="listitem"><p class="simpara">
							Convert the binary code to hexadecimal:
						</p><p class="simpara">
							For example, to convert the binary code using Python:
						</p><pre class="screen">&gt;&gt;&gt; hex(int('0000000010000001', 2))

'0x81'</pre><p class="simpara">
							On systems with more than 32 processors, you must delimit the <code class="literal">smp_affinity</code> values for discrete 32 bit groups. For example, if you want only the first 32 processors of a 64 processor system to service an interrupt request, use <code class="literal">0xffffffff,00000000</code>.
						</p></li><li class="listitem"><p class="simpara">
							The interrupt affinity value for a particular interrupt request is stored in the associated <code class="literal">/proc/irq/irq_number/smp_affinity</code> file. Set the <code class="literal">smp_affinity</code> mask in this file:
						</p><pre class="screen"># echo mask &gt; /proc/irq/irq_number/smp_affinity</pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<code class="literal">journalctl(1)</code>, <code class="literal">irqbalance(1)</code>, and <code class="literal">taskset(1)</code> man pages on your system
						</li></ul></div></section></section></section><section class="chapter" id="tuning-scheduling-policy_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 30. Tuning scheduling policy</h2></div></div></div><p class="_abstract _abstract">
			In Red Hat Enterprise Linux, the smallest unit of process execution is called a thread. The system scheduler determines which processor runs a thread, and for how long the thread runs. However, because the scheduler’s primary concern is to keep the system busy, it may not schedule threads optimally for application performance.
		</p><p>
			For example, say an application on a NUMA system is running on Node A when a processor on Node B becomes available. To keep the processor on Node B busy, the scheduler moves one of the application’s threads to Node B. However, the application thread still requires access to memory on Node A. But, this memory will take longer to access because the thread is now running on Node B and Node A memory is no longer local to the thread. Thus, it may take longer for the thread to finish running on Node B than it would have taken to wait for a processor on Node A to become available, and then to execute the thread on the original node with local memory access.
		</p><section class="section" id="con_categories-of-scheduling-policies_tuning-scheduling-policy"><div class="titlepage"><div><div><h3 class="title">30.1. Categories of scheduling policies</h3></div></div></div><p class="_abstract _abstract">
				Performance sensitive applications often benefit from the designer or administrator determining where threads are run. The Linux scheduler implements a number of scheduling policies which determine where and for how long a thread runs.
			</p><p>
				The following are the two major categories of scheduling policies:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">Normal policies</code></span></dt><dd>
							Normal threads are used for tasks of normal priority.
						</dd><dt><span class="term"><code class="literal">Realtime policies</code></span></dt><dd><p class="simpara">
							Realtime policies are used for time-sensitive tasks that must complete without interruptions. Realtime threads are not subject to time slicing. This means the thread runs until they block, exit, voluntarily yield, or are preempted by a higher priority thread.
						</p><p class="simpara">
							The lowest priority realtime thread is scheduled before any thread with a normal policy. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/tuning-scheduling-policy_monitoring-and-managing-system-status-and-performance#static-priority-scheduling-with-SCHED_FIFO_tuning-scheduling-policy">Static priority scheduling with SCHED_FIFO</a> and <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/tuning-scheduling-policy_monitoring-and-managing-system-status-and-performance#round-robin-priority-scheduling-with-sched_rr_tuning-scheduling-policy">Round robin priority scheduling with SCHED_RR</a>.
						</p></dd></dl></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">sched(7)</code>, <code class="literal">sched_setaffinity(2)</code>, <code class="literal">sched_getaffinity(2)</code>, <code class="literal">sched_setscheduler(2)</code>, and <code class="literal">sched_getscheduler(2)</code> man pages on your system
					</li></ul></div></section><section class="section" id="static-priority-scheduling-with-SCHED_FIFO_tuning-scheduling-policy"><div class="titlepage"><div><div><h3 class="title">30.2. Static priority scheduling with SCHED_FIFO</h3></div></div></div><p class="_abstract _abstract">
				The <code class="literal">SCHED_FIFO</code>, also called static priority scheduling, is a realtime policy that defines a fixed priority for each thread. This policy allows administrators to improve event response time and reduce latency. It is recommended to not execute this policy for an extended period of time for time sensitive tasks.
			</p><p>
				When <code class="literal">SCHED_FIFO</code> is in use, the scheduler scans the list of all the <code class="literal">SCHED_FIFO</code> threads in order of priority and schedules the highest priority thread that is ready to run. The priority level of a <code class="literal">SCHED_FIFO</code> thread can be any integer from <code class="literal">1</code> to <code class="literal">99</code>, where <code class="literal">99</code> is treated as the highest priority. Red Hat recommends starting with a lower number and increasing priority only when you identify latency issues.
			</p><rh-alert class="admonition warning" state="danger"><div class="admonition_header" slot="header">Warning</div><div><p>
					Because realtime threads are not subject to time slicing, Red Hat does not recommend setting a priority as 99. This keeps your process at the same priority level as migration and watchdog threads; if your thread goes into a computational loop and these threads are blocked, they will not be able to run. Systems with a single processor will eventually hang in this situation.
				</p></div></rh-alert><p>
				Administrators can limit <code class="literal">SCHED_FIFO</code> bandwidth to prevent realtime application programmers from initiating realtime tasks that monopolize the processor.
			</p><p>
				The following are some of the parameters used in this policy:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">/proc/sys/kernel/sched_rt_period_us</code></span></dt><dd>
							This parameter defines the time period, in microseconds, that is considered to be one hundred percent of the processor bandwidth. The default value is <code class="literal">1000000 μs</code>, or <code class="literal">1 second</code>.
						</dd><dt><span class="term"><code class="literal">/proc/sys/kernel/sched_rt_runtime_us</code></span></dt><dd>
							This parameter defines the time period, in microseconds, that is devoted to running real-time threads. The default value is <code class="literal">950000 μs</code>, or <code class="literal">0.95 seconds</code>.
						</dd></dl></div></section><section class="section" id="round-robin-priority-scheduling-with-sched_rr_tuning-scheduling-policy"><div class="titlepage"><div><div><h3 class="title">30.3. Round robin priority scheduling with SCHED_RR</h3></div></div></div><p class="_abstract _abstract">
				The <code class="literal">SCHED_RR</code> is a round-robin variant of the <code class="literal">SCHED_FIFO</code>. This policy is useful when multiple threads need to run at the same priority level.
			</p><p>
				Like <code class="literal">SCHED_FIFO</code>, <code class="literal">SCHED_RR</code> is a realtime policy that defines a fixed priority for each thread. The scheduler scans the list of all SCHED_RR threads in order of priority and schedules the highest priority thread that is ready to run. However, unlike <code class="literal">SCHED_FIFO</code>, threads that have the same priority are scheduled in a round-robin style within a certain time slice.
			</p><p>
				You can set the value of this time slice in milliseconds with the <code class="literal">sched_rr_timeslice_ms</code> kernel parameter in the <code class="literal">/proc/sys/kernel/sched_rr_timeslice_ms</code> file. The lowest value is <code class="literal">1 millisecond</code>.
			</p></section><section class="section" id="normal-scheduling-with-sched_other_tuning-scheduling-policy"><div class="titlepage"><div><div><h3 class="title">30.4. Normal scheduling with SCHED_OTHER</h3></div></div></div><p class="_abstract _abstract">
				The <code class="literal">SCHED_OTHER</code> is the default scheduling policy in Red Hat Enterprise Linux 9. This policy uses the Completely Fair Scheduler (CFS) to allow fair processor access to all threads scheduled with this policy. This policy is most useful when there are a large number of threads or when data throughput is a priority, as it allows more efficient scheduling of threads over time.
			</p><p>
				When this policy is in use, the scheduler creates a dynamic priority list based partly on the niceness value of each process thread. Administrators can change the niceness value of a process, but cannot change the scheduler’s dynamic priority list directly.
			</p></section><section class="section" id="setting-scheduler-policies_tuning-scheduling-policy"><div class="titlepage"><div><div><h3 class="title">30.5. Setting scheduler policies</h3></div></div></div><p class="_abstract _abstract">
				Check and adjust scheduler policies and priorities by using the <code class="literal">chrt</code> command line tool. It can start new processes with the desired properties, or change the properties of a running process. It can also be used for setting the policy at runtime.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						View the process ID (PID) of the active processes:
					</p><pre class="screen"># ps</pre><p class="simpara">
						Use the <code class="literal">--pid</code> or <code class="literal">-p</code> option with the <code class="literal">ps</code> command to view the details of the particular PID.
					</p></li><li class="listitem"><p class="simpara">
						Check the scheduling policy, PID, and priority of a particular process:
					</p><pre class="screen"># chrt -p <span class="emphasis"><em>468</em></span>
pid <span class="emphasis"><em>468</em></span>'s current scheduling policy: <span class="emphasis"><em>SCHED_FIFO</em></span>
pid <span class="emphasis"><em>468</em></span>'s current scheduling priority: <span class="emphasis"><em>85</em></span>

# chrt -p <span class="emphasis"><em>476</em></span>
pid <span class="emphasis"><em>476</em></span>'s current scheduling policy: <span class="emphasis"><em>SCHED_OTHER</em></span>
pid <span class="emphasis"><em>476</em></span>'s current scheduling priority: <span class="emphasis"><em>0</em></span></pre><p class="simpara">
						Here, <span class="emphasis"><em>468</em></span> and <span class="emphasis"><em>476</em></span> are PID of a process.
					</p></li><li class="listitem"><p class="simpara">
						Set the scheduling policy of a process:
					</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
								For example, to set the process with PID <span class="emphasis"><em>1000</em></span> to <span class="emphasis"><em>SCHED_FIFO</em></span>, with a priority of <span class="emphasis"><em>50</em></span>:
							</p><pre class="screen"># chrt -f -p <span class="emphasis"><em>50 1000</em></span></pre></li><li class="listitem"><p class="simpara">
								For example, to set the process with PID <span class="emphasis"><em>1000</em></span> to <span class="emphasis"><em>SCHED_OTHER</em></span>, with a priority of <span class="emphasis"><em>0</em></span>:
							</p><pre class="screen"># chrt -o -p <span class="emphasis"><em>0 1000</em></span></pre></li><li class="listitem"><p class="simpara">
								For example, to set the process with PID <span class="emphasis"><em>1000</em></span> to <span class="emphasis"><em>SCHED_RR</em></span>, with a priority of <span class="emphasis"><em>10</em></span>:
							</p><pre class="screen"># chrt -r -p <span class="emphasis"><em>10 1000</em></span></pre></li><li class="listitem"><p class="simpara">
								To start a new application with a particular policy and priority, specify the name of the application:
							</p><pre class="screen"># chrt -f <span class="emphasis"><em>36 /bin/my-app</em></span></pre></li></ol></div></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">chrt(1)</code> man page on your system
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/tuning-scheduling-policy_monitoring-and-managing-system-status-and-performance#policy-options-for-the-chrt-command_tuning-scheduling-policy">Policy Options for the chrt command</a>
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/tuning-scheduling-policy_monitoring-and-managing-system-status-and-performance#changing-the-priority-of-service-during-the-boot-process_tuning-scheduling-policy">Changing the priority of services during the boot process</a>
					</li></ul></div></section><section class="section" id="policy-options-for-the-chrt-command_tuning-scheduling-policy"><div class="titlepage"><div><div><h3 class="title">30.6. Policy options for the chrt command</h3></div></div></div><p class="_abstract _abstract">
				Using the <code class="literal">chrt</code> command, you can view and set the scheduling policy of a process.
			</p><p>
				The following table describes the appropriate policy options, which can be used to set the scheduling policy of a process.
			</p><rh-table id="idm140280131368304"><table class="lt-4-cols lt-7-rows"><caption>Table 30.1. Policy Options for the chrt Command</caption><colgroup><col style="width: 33%; " class="col_1"><!--Empty--><col style="width: 33%; " class="col_2"><!--Empty--><col style="width: 33%; " class="col_3"><!--Empty--></colgroup><thead><tr><th align="left" valign="top" id="idm140280131362528" scope="col">Short option</th><th align="left" valign="top" id="idm140280131361440" scope="col">Long option</th><th align="left" valign="top" id="idm140280131360352" scope="col">Description</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm140280131362528"> <p>
								<code class="literal">-f</code>
							</p>
							 </td><td align="left" valign="top" headers="idm140280131361440"> <p>
								<code class="literal">--fifo</code>
							</p>
							 </td><td align="left" valign="top" headers="idm140280131360352"> <p>
								Set schedule to <code class="literal">SCHED_FIFO</code>
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm140280131362528"> <p>
								<code class="literal">-o</code>
							</p>
							 </td><td align="left" valign="top" headers="idm140280131361440"> <p>
								<code class="literal">--other</code>
							</p>
							 </td><td align="left" valign="top" headers="idm140280131360352"> <p>
								Set schedule to <code class="literal">SCHED_OTHER</code>
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm140280131362528"> <p>
								<code class="literal">-r</code>
							</p>
							 </td><td align="left" valign="top" headers="idm140280131361440"> <p>
								<code class="literal">--rr</code>
							</p>
							 </td><td align="left" valign="top" headers="idm140280131360352"> <p>
								Set schedule to <code class="literal">SCHED_RR</code>
							</p>
							 </td></tr></tbody></table></rh-table></section><section class="section" id="changing-the-priority-of-service-during-the-boot-process_tuning-scheduling-policy"><div class="titlepage"><div><div><h3 class="title">30.7. Changing the priority of services during the boot process</h3></div></div></div><p class="_abstract _abstract">
				Using the <code class="literal">systemd</code> service, it is possible to set up real-time priorities for services launched during the boot process. The <span class="emphasis"><em>unit configuration directives</em></span> are used to change the priority of a service during the boot process.
			</p><p>
				The boot process priority change is done by using the following directives in the service section:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">CPUSchedulingPolicy=</code></span></dt><dd>
							Sets the CPU scheduling policy for executed processes. It is used to set <code class="literal">other</code>, <code class="literal">fifo</code>, and <code class="literal">rr</code> policies.
						</dd><dt><span class="term"><code class="literal">CPUSchedulingPriority=</code></span></dt><dd>
							Sets the CPU scheduling priority for executed processes. The available priority range depends on the selected CPU scheduling policy. For real-time scheduling policies, an integer between <code class="literal">1</code> (lowest priority) and <code class="literal">99</code> (highest priority) can be used.
						</dd></dl></div><p>
				The following procedure describes how to change the priority of a service, during the boot process, using the <code class="literal">mcelog</code> service.
			</p><div class="orderedlist"><p class="title"><strong>Prerequisites</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Install the TuneD package:
					</p><pre class="screen"># dnf install tuned</pre></li><li class="listitem"><p class="simpara">
						Enable and start the TuneD service:
					</p><pre class="screen"># systemctl enable --now tuned</pre></li></ol></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						View the scheduling priorities of running threads:
					</p><pre class="literallayout"># tuna --show_threads
                      thread       ctxt_switches
    pid SCHED_ rtpri affinity voluntary nonvoluntary             cmd
  1      OTHER     0     0xff      3181          292         systemd
  2      OTHER     0     0xff       254            0        kthreadd
  3      OTHER     0     0xff         2            0          rcu_gp
  4      OTHER     0     0xff         2            0      rcu_par_gp
  6      OTHER     0        0         9            0 kworker/0:0H-kblockd
  7      OTHER     0     0xff      1301            1 kworker/u16:0-events_unbound
  8      OTHER     0     0xff         2            0    mm_percpu_wq
  9      OTHER     0        0       266            0     ksoftirqd/0
[...]</pre></li><li class="listitem"><p class="simpara">
						Create a supplementary <code class="literal">mcelog</code> service configuration directory file and insert the policy name and priority in this file:
					</p><pre class="screen"># cat &lt;&lt; EOF &gt; /etc/systemd/system/mcelog.service.d/priority.conf

[Service]
CPUSchedulingPolicy=<span class="emphasis"><em>fifo</em></span>
CPUSchedulingPriority=<span class="emphasis"><em>20</em></span>
EOF</pre></li><li class="listitem"><p class="simpara">
						Reload the <code class="literal">systemd</code> scripts configuration:
					</p><pre class="screen"># systemctl daemon-reload</pre></li><li class="listitem"><p class="simpara">
						Restart the <code class="literal">mcelog</code> service:
					</p><pre class="screen"># systemctl restart mcelog</pre></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Display the <code class="literal">mcelog</code> priority set by <code class="literal">systemd</code> issue:
					</p><pre class="literallayout"># tuna -t mcelog -P
thread       ctxt_switches
  pid SCHED_ rtpri affinity voluntary nonvoluntary             cmd
826     FIFO    20  0,1,2,3        13            0          mcelog</pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">systemd(1)</code> and <code class="literal">tuna(8)</code> man pages on your system
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/tuning-scheduling-policy_monitoring-and-managing-system-status-and-performance#priority-map_tuning-scheduling-policy">Description of the priority range</a>
					</li></ul></div></section><section class="section" id="priority-map_tuning-scheduling-policy"><div class="titlepage"><div><div><h3 class="title">30.8. Priority map</h3></div></div></div><p class="_abstract _abstract">
				Priorities are defined in groups, with some groups dedicated to certain kernel functions. For real-time scheduling policies, an integer between <code class="literal">1</code> (lowest priority) and <code class="literal">99</code> (highest priority) can be used.
			</p><p>
				The following table describes the priority range, which can be used while setting the scheduling policy of a process.
			</p><rh-table id="idm140280130694608"><table class="lt-4-cols lt-7-rows"><caption>Table 30.2. Description of the priority range</caption><colgroup><col style="width: 33%; " class="col_1"><!--Empty--><col style="width: 33%; " class="col_2"><!--Empty--><col style="width: 33%; " class="col_3"><!--Empty--></colgroup><thead><tr><th align="left" valign="top" id="idm140280130688832" scope="col">Priority</th><th align="left" valign="top" id="idm140280130687744" scope="col">Threads</th><th align="left" valign="top" id="idm140280130686656" scope="col">Description</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm140280130688832"> <p>
								1
							</p>
							 </td><td align="left" valign="top" headers="idm140280130687744"> <p>
								Low priority kernel threads
							</p>
							 </td><td align="left" valign="top" headers="idm140280130686656"> <p>
								This priority is usually reserved for the tasks that need to be just above <code class="literal">SCHED_OTHER</code>.
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm140280130688832"> <p>
								2 - 49
							</p>
							 </td><td align="left" valign="top" headers="idm140280130687744"> <p>
								Available for use
							</p>
							 </td><td align="left" valign="top" headers="idm140280130686656"> <p>
								The range used for typical application priorities.
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm140280130688832"> <p>
								50
							</p>
							 </td><td align="left" valign="top" headers="idm140280130687744"> <p>
								Default hard-IRQ value
							</p>
							 </td><td align="left" valign="top" headers="idm140280130686656"> </td></tr><tr><td align="left" valign="top" headers="idm140280130688832"> <p>
								51 - 98
							</p>
							 </td><td align="left" valign="top" headers="idm140280130687744"> <p>
								High priority threads
							</p>
							 </td><td align="left" valign="top" headers="idm140280130686656"> <p>
								Use this range for threads that execute periodically and must have quick response times. Do not use this range for CPU-bound threads as you will starve interrupts.
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm140280130688832"> <p>
								99
							</p>
							 </td><td align="left" valign="top" headers="idm140280130687744"> <p>
								Watchdogs and migration
							</p>
							 </td><td align="left" valign="top" headers="idm140280130686656"> <p>
								System threads that must run at the highest priority.
							</p>
							 </td></tr></tbody></table></rh-table></section><section class="section" id="tuned-cpu-partitioning-profile_tuning-scheduling-policy"><div class="titlepage"><div><div><h3 class="title">30.9. TuneD cpu-partitioning profile</h3></div></div></div><p class="_abstract _abstract">
				For tuning Red Hat Enterprise Linux 9 for latency-sensitive workloads, Red Hat recommends to use the <code class="literal">cpu-partitioning</code> TuneD profile.
			</p><p>
				Prior to Red Hat Enterprise Linux 9, the low-latency Red Hat documentation described the numerous low-level steps needed to achieve low-latency tuning. In Red Hat Enterprise Linux 9, you can perform low-latency tuning more efficiently by using the <code class="literal">cpu-partitioning</code> TuneD profile. This profile is easily customizable according to the requirements for individual low-latency applications.
			</p><p>
				The following figure is an example to demonstrate how to use the <code class="literal">cpu-partitioning</code> profile. This example uses the CPU and node layout.
			</p><div class="figure" id="cpu-partitioning_tuning-scheduling-policy"><p class="title"><strong>Figure 30.1. Figure cpu-partitioning</strong></p><div class="figure-contents"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/367206bd2d1527d49965f718f51722e3/cpu-partitioning.png" alt="cpu partitioning"></div></div></div><p>
				You can configure the cpu-partitioning profile in the <code class="literal">/etc/tuned/cpu-partitioning-variables.conf</code> file using the following configuration options:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">Isolated CPUs with load balancing</span></dt><dd><p class="simpara">
							In the cpu-partitioning figure, the blocks numbered from 4 to 23, are the default isolated CPUs. The kernel scheduler’s process load balancing is enabled on these CPUs. It is designed for low-latency processes with multiple threads that need the kernel scheduler load balancing.
						</p><p class="simpara">
							You can configure the cpu-partitioning profile in the <code class="literal">/etc/tuned/cpu-partitioning-variables.conf</code> file using the <code class="literal">isolated_cores=cpu-list</code> option, which lists CPUs to isolate that will use the kernel scheduler load balancing.
						</p><p class="simpara">
							The list of isolated CPUs is comma-separated or you can specify a range using a dash, such as <code class="literal">3-5</code>. This option is mandatory. Any CPU missing from this list is automatically considered a housekeeping CPU.
						</p></dd><dt><span class="term">Isolated CPUs without load balancing</span></dt><dd><p class="simpara">
							In the cpu-partitioning figure, the blocks numbered 2 and 3, are the isolated CPUs that do not provide any additional kernel scheduler process load balancing.
						</p><p class="simpara">
							You can configure the cpu-partitioning profile in the <code class="literal">/etc/tuned/cpu-partitioning-variables.conf</code> file using the <code class="literal">no_balance_cores=cpu-list</code> option, which lists CPUs to isolate that will not use the kernel scheduler load balancing.
						</p><p class="simpara">
							Specifying the <code class="literal">no_balance_cores</code> option is optional, however any CPUs in this list must be a subset of the CPUs listed in the <code class="literal">isolated_cores</code> list.
						</p><p class="simpara">
							Application threads using these CPUs need to be pinned individually to each CPU.
						</p></dd><dt><span class="term">Housekeeping CPUs</span></dt><dd>
							Any CPU not isolated in the <code class="literal">cpu-partitioning-variables.conf</code> file is automatically considered a housekeeping CPU. On the housekeeping CPUs, all services, daemons, user processes, movable kernel threads, interrupt handlers, and kernel timers are permitted to execute.
						</dd></dl></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">tuned-profiles-cpu-partitioning(7)</code> man page on your system
					</li></ul></div></section><section class="section" id="using-the-tuned-cpu-partitioning-profile-for-low-latency-tuning_tuning-scheduling-policy"><div class="titlepage"><div><div><h3 class="title">30.10. Using the TuneD cpu-partitioning profile for low-latency tuning</h3></div></div></div><p class="_abstract _abstract">
				This procedure describes how to tune a system for low-latency using the TuneD’s <code class="literal">cpu-partitioning</code> profile. It uses the example of a low-latency application that can use <code class="literal">cpu-partitioning</code> and the CPU layout as mentioned in the <a class="link" href="#cpu-partitioning_tuning-scheduling-policy" title="Figure 30.1. Figure cpu-partitioning">cpu-partitioning</a> figure.
			</p><p>
				The application in this case uses:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						One dedicated reader thread that reads data from the network will be pinned to CPU 2.
					</li><li class="listitem">
						A large number of threads that process this network data will be pinned to CPUs 4-23.
					</li><li class="listitem">
						A dedicated writer thread that writes the processed data to the network will be pinned to CPU 3.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have installed the <code class="literal">cpu-partitioning</code> TuneD profile by using the <code class="literal">dnf install tuned-profiles-cpu-partitioning</code> command as root.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Edit <code class="literal">/etc/tuned/cpu-partitioning-variables.conf</code> file and add the following information:
					</p><pre class="screen"># All isolated CPUs:
isolated_cores=2-23
# Isolated CPUs without the kernel’s scheduler load balancing:
no_balance_cores=2,3</pre></li><li class="listitem"><p class="simpara">
						Set the <code class="literal">cpu-partitioning</code> TuneD profile:
					</p><pre class="screen"># tuned-adm profile cpu-partitioning</pre></li><li class="listitem"><p class="simpara">
						Reboot
					</p><p class="simpara">
						After rebooting, the system is tuned for low-latency, according to the isolation in the cpu-partitioning figure. The application can use taskset to pin the reader and writer threads to CPUs 2 and 3, and the remaining application threads on CPUs 4-23.
					</p></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">tuned-profiles-cpu-partitioning(7)</code> man page on your system
					</li></ul></div></section><section class="section" id="customizing-the-cpu-partitioning-tuned-profile_tuning-scheduling-policy"><div class="titlepage"><div><div><h3 class="title">30.11. Customizing the cpu-partitioning TuneD profile</h3></div></div></div><p class="_abstract _abstract">
				You can extend the TuneD profile to make additional tuning changes.
			</p><p>
				For example, the <code class="literal">cpu-partitioning</code> profile sets the CPUs to use <code class="literal">cstate=1</code>. In order to use the <code class="literal">cpu-partitioning</code> profile but to additionally change the CPU cstate from cstate1 to cstate0, the following procedure describes a new TuneD profile named <span class="emphasis"><em>my_profile</em></span>, which inherits the <code class="literal">cpu-partitioning</code> profile and then sets C state-0.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Create the <code class="literal">/etc/tuned/my_profile</code> directory:
					</p><pre class="screen"># mkdir /etc/tuned/<span class="emphasis"><em>my_profile</em></span></pre></li><li class="listitem"><p class="simpara">
						Create a <code class="literal">tuned.conf</code> file in this directory, and add the following content:
					</p><pre class="screen"># vi /etc/tuned/<span class="emphasis"><em>my_profile</em></span>/tuned.conf
[main]
summary=Customized tuning on top of cpu-partitioning
include=cpu-partitioning
[cpu]
force_latency=cstate.id:0|1</pre></li><li class="listitem"><p class="simpara">
						Use the new profile:
					</p><pre class="screen"># tuned-adm profile <span class="emphasis"><em>my_profile</em></span></pre></li></ol></div><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					In the shared example, a reboot is not required. However, if the changes in the <span class="emphasis"><em>my_profile</em></span> profile require a reboot to take effect, then reboot your machine.
				</p></div></rh-alert><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">tuned-profiles-cpu-partitioning(7)</code> man page on your system
					</li></ul></div></section></section><section class="chapter" id="tuning-the-network-performance_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 31. Tuning the network performance</h2></div></div></div><p>
			Tuning the network settings is a complex process with many factors to consider. For example, this includes the CPU-to-memory architecture, the amount of CPU cores, and more. Red Hat Enterprise Linux uses default settings that are optimized for most scenarios. However, in certain cases, it can be necessary to tune network settings to increase the throughput or latency or to solve problems, such as packet drops.
		</p><section class="section" id="tuning-network-adapter-settings_tuning-the-network-performance"><div class="titlepage"><div><div><h3 class="title">31.1. Tuning network adapter settings</h3></div></div></div><p>
				In high-speed networks with 40 Gbps and faster, certain default values of network adapter-related kernel settings can be a cause of packet drops and performance degradation. Tuning these settings can prevent such problems.
			</p><section class="section" id="increasing-the-ring-buffers-to-reduce-a-high-packet-drop-rate_tuning-network-adapter-settings"><div class="titlepage"><div><div><h4 class="title">31.1.1. Increasing the ring buffer size to reduce a high packet drop rate by using <code class="literal">nmcli</code></h4></div></div></div><p class="_abstract _abstract">
					Increase the size of an Ethernet device’s ring buffers if the packet drop rate causes applications to report a loss of data, timeouts, or other issues.
				</p><p>
					Receive ring buffers are shared between the device driver and network interface controller (NIC). The card assigns a transmit (TX) and receive (RX) ring buffer. As the name implies, the ring buffer is a circular buffer where an overflow overwrites existing data. There are two ways to move data from the NIC to the kernel, hardware interrupts and software interrupts, also called SoftIRQs.
				</p><p>
					The kernel uses the RX ring buffer to store incoming packets until the device driver can process them. The device driver drains the RX ring, typically by using SoftIRQs, which puts the incoming packets into a kernel data structure called an <code class="literal">sk_buff</code> or <code class="literal">skb</code> to begin its journey through the kernel and up to the application that owns the relevant socket.
				</p><p>
					The kernel uses the TX ring buffer to hold outgoing packets which should be sent to the network. These ring buffers reside at the bottom of the stack and are a crucial point at which packet drop can occur, which in turn will adversely affect network performance.
				</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Display the packet drop statistics of the interface:
						</p><pre class="literallayout"># <span class="strong strong"><strong>ethtool -S <span class="emphasis"><em>enp1s0</em></span></strong></span>
    ...
    rx_queue_0_drops: <span class="emphasis"><em>97326</em></span>
    rx_queue_1_drops: <span class="emphasis"><em>63783</em></span>
    ...</pre><p class="simpara">
							Note that the output of the command depends on the network card and the driver.
						</p><p class="simpara">
							High values in <code class="literal">discard</code> or <code class="literal">drop</code> counters indicate that the available buffer fills up faster than the kernel can process the packets. Increasing the ring buffers can help to avoid such loss.
						</p></li><li class="listitem"><p class="simpara">
							Display the maximum ring buffer sizes:
						</p><pre class="literallayout"># <span class="strong strong"><strong>ethtool -g <span class="emphasis"><em>enp1s0</em></span></strong></span>
 Ring parameters for <span class="emphasis"><em>enp1s0</em></span>:
 Pre-set maximums:
 RX:             <span class="emphasis"><em>4096</em></span>
 RX Mini:        <span class="emphasis"><em>0</em></span>
 RX Jumbo:       <span class="emphasis"><em>16320</em></span>
 TX:             <span class="emphasis"><em>4096</em></span>
 Current hardware settings:
 RX:             <span class="emphasis"><em>255</em></span>
 RX Mini:        <span class="emphasis"><em>0</em></span>
 RX Jumbo:       <span class="emphasis"><em>0</em></span>
 TX:             <span class="emphasis"><em>255</em></span></pre><p class="simpara">
							If the values in the <code class="literal">Pre-set maximums</code> section are higher than in the <code class="literal">Current hardware settings</code> section, you can change the settings in the next steps.
						</p></li><li class="listitem"><p class="simpara">
							Identify the NetworkManager connection profile that uses the interface:
						</p><pre class="literallayout"># <span class="strong strong"><strong>nmcli connection show</strong></span>
NAME                UUID                                  TYPE      DEVICE
<span class="emphasis"><em>Example-Connection</em></span>  <span class="emphasis"><em>a5eb6490-cc20-3668-81f8-0314a27f3f75</em></span>  ethernet  <span class="emphasis"><em>enp1s0</em></span></pre></li><li class="listitem"><p class="simpara">
							Update the connection profile, and increase the ring buffers:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									To increase the RX ring buffer, enter:
								</p><pre class="literallayout"># <span class="strong strong"><strong>nmcli connection modify <span class="emphasis"><em>Example-Connection</em></span> ethtool.ring-rx <span class="emphasis"><em>4096</em></span></strong></span></pre></li><li class="listitem"><p class="simpara">
									To increase the TX ring buffer, enter:
								</p><pre class="literallayout"># <span class="strong strong"><strong>nmcli connection modify <span class="emphasis"><em>Example-Connection</em></span> ethtool.ring-tx <span class="emphasis"><em>4096</em></span></strong></span></pre></li></ul></div></li><li class="listitem"><p class="simpara">
							Reload the NetworkManager connection:
						</p><pre class="literallayout"># <span class="strong strong"><strong>nmcli connection up <span class="emphasis"><em>Example-Connection</em></span></strong></span></pre><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
								Depending on the driver your NIC uses, changing in the ring buffer can shortly interrupt the network connection.
							</p></div></rh-alert></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<a class="link" href="https://access.redhat.com/solutions/2073223">ifconfig and ip commands report packet drops</a> (Red Hat Knowledgebase)
						</li><li class="listitem">
							<a class="link" href="https://access.redhat.com/solutions/742043">Should I be concerned about a 0.05% packet drop rate?</a> (Red Hat Knowledgebase)
						</li><li class="listitem">
							<code class="literal">ethtool(8)</code> man page on your system
						</li></ul></div></section><section class="section" id="tuning-the-network-device-backlog-queue-to-avoid-packet-drops_tuning-network-adapter-settings"><div class="titlepage"><div><div><h4 class="title">31.1.2. Tuning the network device backlog queue to avoid packet drops</h4></div></div></div><p>
					When a network card receives packets and before the kernel protocol stack processes them, the kernel stores these packets in backlog queues. The kernel maintains a separate queue for each CPU core.
				</p><p>
					If the backlog queue for a core is full, the kernel drops all further incoming packets that the <code class="literal">netif_receive_skb()</code> kernel function assigns to this queue. If the server contains a 10 Gbps or faster network adapter or multiple 1 Gbps adapters, tune the backlog queue size to avoid this problem.
				</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							A 10 Gbps or faster or multiple 1 Gbps network adapters
						</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Determine whether tuning the backlog queue is needed, display the counters in the <code class="literal">/proc/net/softnet_stat</code> file:
						</p><pre class="literallayout"># <span class="strong strong"><strong>awk '{for (i=1; i&lt;=NF; i++) printf strtonum("0x" $i) (i==NF?"\n":" ")}' /proc/net/softnet_stat | column -t</strong></span>
221951548  0      0  0  0  0  0  0  0  0  0  0  0
192058677  18862  0  0  0  0  0  0  0  0  0  0  1
455324886  0      0  0  0  0  0  0  0  0  0  0  2
...</pre><p class="simpara">
							This <code class="literal">awk</code> command converts the values in <code class="literal">/proc/net/softnet_stat</code> from hexadecimal to decimal format and displays them in table format. Each line represents a CPU core starting with core 0.
						</p><p class="simpara">
							The relevant columns are:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									First column: The total number of received frames
								</li><li class="listitem">
									Second column: The number of dropped frames because of a full backlog queue
								</li><li class="listitem">
									Last column: The CPU core number
								</li></ul></div></li><li class="listitem"><p class="simpara">
							If the values in the second column of the <code class="literal">/proc/net/softnet_stat</code> file increment over time, increase the size of the backlog queue:
						</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
									Display the current backlog queue size:
								</p><pre class="literallayout"># <span class="strong strong"><strong>sysctl net.core.netdev_max_backlog</strong></span>
net.core.netdev_max_backlog = <span class="emphasis"><em>1000</em></span></pre></li><li class="listitem"><p class="simpara">
									Create the <code class="literal">/etc/sysctl.d/10-netdev_max_backlog.conf</code> file with the following content:
								</p><pre class="literallayout"><span class="strong strong"><strong>net.core.netdev_max_backlog = <span class="emphasis"><em>2000</em></span></strong></span></pre><p class="simpara">
									Set the <code class="literal">net.core.netdev_max_backlog</code> parameter to a double of the current value.
								</p></li><li class="listitem"><p class="simpara">
									Load the settings from the <code class="literal">/etc/sysctl.d/10-netdev_max_backlog.conf</code> file:
								</p><pre class="literallayout"># <span class="strong strong"><strong>sysctl -p /etc/sysctl.d/10-netdev_max_backlog.conf</strong></span></pre></li></ol></div></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							Monitor the second column in the <code class="literal">/proc/net/softnet_stat</code> file:
						</p><pre class="literallayout"># <span class="strong strong"><strong>awk '{for (i=1; i&lt;=NF; i++) printf strtonum("0x" $i) (i==NF?"\n":" ")}' /proc/net/softnet_stat | column -t</strong></span></pre><p class="simpara">
							If the values still increase, double the <code class="literal">net.core.netdev_max_backlog</code> value again. Repeat this process until the packet drop counters no longer increase.
						</p></li></ul></div></section><section class="section" id="increasing-the-transmit-queue-length-of-a-nic-to-reduce-the-number-of-transmit-errors_tuning-network-adapter-settings"><div class="titlepage"><div><div><h4 class="title">31.1.3. Increasing the transmit queue length of a NIC to reduce the number of transmit errors</h4></div></div></div><p>
					The kernel stores packets in a transmit queue before transmitting them. The default length (1000 packets) is typically sufficient for 10 Gbps, and often also for 40 Gbps networks. However, in faster networks, or if you encounter an increasing number of transmit errors on an adapter, increase the queue length.
				</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Display the current transmit queue length:
						</p><pre class="literallayout"># <span class="strong strong"><strong>ip -s link show <span class="emphasis"><em>enp1s0</em></span></strong></span>
<span class="emphasis"><em>2</em></span>: <span class="emphasis"><em>enp1s0</em></span>: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span class="emphasis"><em>1500</em></span> qdisc <span class="emphasis"><em>fq_codel</em></span> state <span class="emphasis"><em>UP</em></span> mode <span class="emphasis"><em>DEFAULT</em></span> group <span class="emphasis"><em>default</em></span> qlen <span class="emphasis"><em>1000</em></span>
...</pre><p class="simpara">
							In this example, the transmit queue length (<code class="literal">qlen</code>) of the <code class="literal">enp1s0</code> interface is <code class="literal">1000</code>.
						</p></li><li class="listitem"><p class="simpara">
							Monitor the dropped packets counter of a network interface’s software transmit queue:
						</p><pre class="literallayout"># <span class="strong strong"><strong>tc -s qdisc show dev <span class="emphasis"><em>enp1s0</em></span></strong></span>
qdisc <span class="emphasis"><em>fq_codel</em></span> <span class="emphasis"><em>0</em></span>: <span class="emphasis"><em>root</em></span> refcnt <span class="emphasis"><em>2</em></span> limit <span class="emphasis"><em>10240p</em></span> flows <span class="emphasis"><em>1024</em></span> quantum <span class="emphasis"><em>1514</em></span> target <span class="emphasis"><em>5ms</em></span> interval <span class="emphasis"><em>100ms</em></span> memory_limit <span class="emphasis"><em>32Mb</em></span> ecn drop_batch <span class="emphasis"><em>64</em></span>
 Sent <span class="emphasis"><em>16889923</em></span> bytes <span class="emphasis"><em>426862765</em></span> pkt (dropped <span class="emphasis"><em>191980</em></span>, overlimits <span class="emphasis"><em>0</em></span> requeues <span class="emphasis"><em>2</em></span>)
...</pre></li><li class="listitem"><p class="simpara">
							If you encounter a high or increasing transmit error count, set a higher transmit queue length:
						</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
									Identify the NetworkManager connection profile that uses this interface:
								</p><pre class="literallayout"># <span class="strong strong"><strong>nmcli connection show</strong></span>
NAME                UUID                                  TYPE      DEVICE
<span class="emphasis"><em>Example-Connection</em></span>  <span class="emphasis"><em>a5eb6490-cc20-3668-81f8-0314a27f3f75</em></span>  <span class="emphasis"><em>ethernet</em></span>  <span class="emphasis"><em>enp1s0</em></span></pre></li><li class="listitem"><p class="simpara">
									Update the connection profile, and increase the transmit queue length:
								</p><pre class="literallayout"># <span class="strong strong"><strong>nmcli connection modify <span class="emphasis"><em>Example-Connection</em></span> link.tx-queue-length <span class="emphasis"><em>2000</em></span></strong></span></pre><p class="simpara">
									Set the queue length to double of the current value.
								</p></li><li class="listitem"><p class="simpara">
									Apply the changes:
								</p><pre class="literallayout"># <span class="strong strong"><strong>nmcli connection up <span class="emphasis"><em>Example-Connection</em></span></strong></span></pre></li></ol></div></li></ol></div><div class="orderedlist"><p class="title"><strong>Verification</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Display the transmit queue length:
						</p><pre class="literallayout"># <span class="strong strong"><strong>ip -s link show <span class="emphasis"><em>enp1s0</em></span></strong></span>
<span class="emphasis"><em>2</em></span>: <span class="emphasis"><em>enp1s0</em></span>: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span class="emphasis"><em>1500</em></span> qdisc <span class="emphasis"><em>fq_codel</em></span> state <span class="emphasis"><em>UP</em></span> mode <span class="emphasis"><em>DEFAULT</em></span> group <span class="emphasis"><em>default</em></span> qlen <span class="emphasis"><em>2000</em></span>
...</pre></li><li class="listitem"><p class="simpara">
							Monitor the dropped packets counter:
						</p><pre class="literallayout"># <span class="strong strong"><strong>tc -s qdisc show dev <span class="emphasis"><em>enp1s0</em></span></strong></span></pre><p class="simpara">
							If the <code class="literal">dropped</code> counter still increases, double the transmit queue length again. Repeat this process until the counter no longer increases.
						</p></li></ol></div></section></section><section class="section" id="tuning-irq-balancing_tuning-the-network-performance"><div class="titlepage"><div><div><h3 class="title">31.2. Tuning IRQ balancing</h3></div></div></div><p>
				On multi-core hosts, you can increase the performance by ensuring that Red Hat Enterprise Linux balances interrupt queues (IRQs) to distribute the interrupts across CPU cores.
			</p><section class="section" id="interrupts-and-interrupt-handlers_tuning-irq-balancing"><div class="titlepage"><div><div><h4 class="title">31.2.1. Interrupts and interrupt handlers</h4></div></div></div><p>
					When a network interface controller (NIC) receives incoming data, it copies the data into kernel buffers by using Direct Memory Access (DMA). The NIC then notifies the kernel about this data by triggering a hard interrupt. These interrupts are processed by interrupt handlers which do minimal work, as they have already interrupted another task and the handlers cannot interrupt themselves. Hard interrupts can be costly in terms of CPU usage, especially if they use kernel locks.
				</p><p>
					The hard interrupt handler then leaves the majority of packet reception to a software interrupt request (SoftIRQ) process. The kernel can schedule these processes more fairly.
				</p><div class="example" id="idm140280134656864"><p class="title"><strong>Example 31.1. Displaying hardware interrupts</strong></p><div class="example-contents"><p>
						The kernel stores the interrupt counters in the <code class="literal">/proc/interrupts</code> file. To display the counters for a specific NIC, such as <code class="literal">enp1s0</code>, enter:
					</p><pre class="literallayout"># <span class="strong strong"><strong>egrep "CPU|<span class="emphasis"><em>enp1s0</em></span>" /proc/interrupts</strong></span>
         CPU0     CPU1     CPU2    CPU3    CPU4   CPU5
 <span class="emphasis"><em>105</em></span>:  <span class="emphasis"><em>141606</em></span>        <span class="emphasis"><em>0</em></span>        <span class="emphasis"><em>0</em></span>       <span class="emphasis"><em>0</em></span>       <span class="emphasis"><em>0</em></span>      <span class="emphasis"><em>0</em></span>  <span class="emphasis"><em>IR-PCI-MSI-edge</em></span>      <span class="emphasis"><em>enp1s0-rx-0</em></span>
 <span class="emphasis"><em>106</em></span>:       <span class="emphasis"><em>0</em></span>   <span class="emphasis"><em>141091</em></span>        <span class="emphasis"><em>0</em></span>       <span class="emphasis"><em>0</em></span>       <span class="emphasis"><em>0</em></span>      <span class="emphasis"><em>0</em></span>  <span class="emphasis"><em>IR-PCI-MSI-edge</em></span>      <span class="emphasis"><em>enp1s0-rx-1</em></span>
 <span class="emphasis"><em>107</em></span>:       <span class="emphasis"><em>2</em></span>        <span class="emphasis"><em>0</em></span>   <span class="emphasis"><em>163785</em></span>       <span class="emphasis"><em>0</em></span>       <span class="emphasis"><em>0</em></span>      <span class="emphasis"><em>0</em></span>  <span class="emphasis"><em>IR-PCI-MSI-edge</em></span>      <span class="emphasis"><em>enp1s0-rx-2</em></span>
 <span class="emphasis"><em>108</em></span>:       <span class="emphasis"><em>3</em></span>        <span class="emphasis"><em>0</em></span>        <span class="emphasis"><em>0</em></span>  <span class="emphasis"><em>194370</em></span>       <span class="emphasis"><em>0</em></span>      <span class="emphasis"><em>0</em></span>  <span class="emphasis"><em>IR-PCI-MSI-edge</em></span>      <span class="emphasis"><em>enp1s0-rx-3</em></span>
 <span class="emphasis"><em>109</em></span>:       <span class="emphasis"><em>0</em></span>        <span class="emphasis"><em>0</em></span>        <span class="emphasis"><em>0</em></span>       <span class="emphasis"><em>0</em></span>       <span class="emphasis"><em>0</em></span>      <span class="emphasis"><em>0</em></span>  <span class="emphasis"><em>IR-PCI-MSI-edge</em></span>      <span class="emphasis"><em>enp1s0-tx</em></span></pre><p>
						Each queue has an interrupt vector in the first column assigned to it. The kernel initializes these vectors when the system boots or when a user loads the NIC driver module. Each receive (<code class="literal">RX</code>) and transmit (<code class="literal">TX</code>) queue is assigned a unique vector that informs the interrupt handler which NIC or queue the interrupt is coming from. The columns represent the number of incoming interrupts for every CPU core.
					</p></div></div></section><section class="section" id="software-interrupt-requests_tuning-irq-balancing"><div class="titlepage"><div><div><h4 class="title">31.2.2. Software interrupt requests</h4></div></div></div><p>
					Software interrupt requests (SoftIRQs) clear the receive ring buffers of network adapters. The kernel schedules SoftIRQ routines to run at a time when other tasks will not be interrupted. On Red Hat Enterprise Linux, processes named <code class="literal">ksoftirqd/<span class="emphasis"><em>cpu-number</em></span></code> run these routines and call driver-specific code functions.
				</p><p>
					To monitor the SoftIRQ counters for each CPU core, enter:
				</p><pre class="literallayout"># <span class="strong strong"><strong>watch -n1 'egrep "CPU|NET_RX|NET_TX" /proc/softirqs'</strong></span>
                    CPU0       CPU1	  CPU2       CPU3	CPU4	   CPU5       CPU6	 CPU7
      NET_TX:	   49672      52610	 28175      97288      12633	  19843      18746     220689
      NET_RX:         96       1615        789         46         31	   1735       1315     470798</pre><p>
					The command dynamically updates the output. Press <kbd class="keycap">Ctrl</kbd>+<kbd class="keycap">C</kbd> to interrupt the output.
				</p></section><section class="section" id="napi-polling_tuning-irq-balancing"><div class="titlepage"><div><div><h4 class="title">31.2.3. NAPI Polling</h4></div></div></div><p>
					New API (NAPI) is an extension to the device driver packet processing framework to improve the efficiency of incoming network packets. Hard interrupts are expensive because they usually cause a context switch from the kernel space to the user space and back again, and cannot interrupt themselves. Even with interrupt coalescence, the interrupt handler monopolizes a CPU core completely. With NAPI, the driver can use a polling mode instead of being hard-interrupted by the kernel for every packet that is received.
				</p><p>
					Under normal operation, the kernel issues an initial hard interrupt, followed by a soft interrupt request (SoftIRQ) handler that polls the network card using NAPI routines. To prevent SoftIRQs from monopolizing a CPU core, the polling routine has a budget that determines the CPU time the SoftIRQ can consume. On completion of the SoftIRQ poll routine, the kernel exits the routine and schedules it to run again at a later time to repeat the process of receiving packets from the network card.
				</p></section><section class="section" id="the-irqbalance-service_tuning-irq-balancing"><div class="titlepage"><div><div><h4 class="title">31.2.4. The irqbalance service</h4></div></div></div><p>
					On systems both with and without Non-Uniform Memory Access (NUMA) architecture, the <code class="literal">irqbalance</code> service balances interrupts effectively across CPU cores, based on system conditions. The <code class="literal">irqbalance</code> service runs in the background and monitors the CPU load every 10 seconds. The service moves interrupts to other CPU cores when a CPU’s load is too high. As a result, the system performs well and handles load more efficiently.
				</p><p>
					If <code class="literal">irqbalance</code> is not running, usually the CPU core 0 handles most of the interrupts. Even at moderate load, this CPU core can become busy trying to handle the workload of all the hardware in the system. As a consequence, interrupts or interrupt-based work can be missed or delayed. This can result in low network and storage performance, packet loss, and potentially other issues.
				</p><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
						Disabling <code class="literal">irqbalance</code> can negatively impact the network throughput.
					</p></div></rh-alert><p>
					On systems with only a single CPU core, the <code class="literal">irqbalance</code> service provides no benefit and exits on its own.
				</p><p>
					By default, the <code class="literal">irqbalance</code> service is enabled and running on Red Hat Enterprise Linux. To re-enable the service if you disabled it, enter:
				</p><pre class="literallayout"># <span class="strong strong"><strong>systemctl enable --now irqbalance</strong></span></pre><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<a class="link" href="https://access.redhat.com/solutions/41535">Do we need irqbalance?</a> (Red Hat Knowledgebase)
						</li><li class="listitem">
							<a class="link" href="https://access.redhat.com/solutions/4367191">How should I configure network interface IRQ channels?</a> (Red Hat Knowledgebase)
						</li></ul></div></section><section class="section" id="increasing-the-time-softirqs-can-run-on-the-cpu_tuning-irq-balancing"><div class="titlepage"><div><div><h4 class="title">31.2.5. Increasing the time SoftIRQs can run on the CPU</h4></div></div></div><p>
					If SoftIRQs do not run long enough, the rate of incoming data could exceed the kernel’s capability to drain the buffer fast enough. As a result, the network interface controller (NIC) buffers overflow and packets are lost.
				</p><p>
					If <code class="literal">softirqd</code> processes could not retrieve all packets from interfaces in one NAPI polling cycle, it is an indicator that the SoftIRQs do not have enough CPU time. This could be the case on hosts with fast NICs, such as 10 Gbps and faster. If you increase the values of the <code class="literal">net.core.netdev_budget</code> and <code class="literal">net.core.netdev_budget_usecs</code> kernel parameters, you can control the time and number of packets <code class="literal">softirqd</code> can process in a polling cycle.
				</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							To determine whether tuning the <code class="literal">net.core.netdev_budget</code> parameter is needed, display the counters in the <code class="literal">/proc/net/softnet_stat</code> file:
						</p><pre class="literallayout"># <span class="strong strong"><strong>awk '{for (i=1; i&lt;=NF; i++) printf strtonum("0x" $i) (i==NF?"\n":" ")}' /proc/net/softnet_stat | column -t</strong></span>
221951548  0  0      0  0  0  0  0  0  0  0  0  0
192058677  0  20380  0  0  0  0  0  0  0  0  0  1
455324886  0  0      0  0  0  0  0  0  0  0  0  2
...</pre><p class="simpara">
							This <code class="literal">awk</code> command converts the values in <code class="literal">/proc/net/softnet_stat</code> from hexadecimal to decimal format and displays them in the table format. Each line represents a CPU core starting with core 0.
						</p><p class="simpara">
							The relevant columns are:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									First column: The total number of received frames.
								</li><li class="listitem">
									Third column: The number times <code class="literal">softirqd</code> processes that could not retrieve all packets from interfaces in one NAPI polling cycle.
								</li><li class="listitem">
									Last column: The CPU core number.
								</li></ul></div></li><li class="listitem"><p class="simpara">
							If the counters in the third column of the <code class="literal">/proc/net/softnet_stat</code> file increment over time, tune the system:
						</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
									Display the current values of the <code class="literal">net.core.netdev_budget_usecs</code> and <code class="literal">net.core.netdev_budget</code> parameters:
								</p><pre class="literallayout"># <span class="strong strong"><strong>sysctl net.core.netdev_budget_usecs net.core.netdev_budget</strong></span>
net.core.netdev_budget_usecs = 2000
net.core.netdev_budget = 300</pre><p class="simpara">
									With these settings, <code class="literal">softirqd</code> processes have up to 2000 microseconds to process up to 300 messages from the NIC in one polling cycle. Polling ends based on which condition is met first.
								</p></li><li class="listitem"><p class="simpara">
									Create the <code class="literal">/etc/sysctl.d/10-netdev_budget.conf</code> file with the following content:
								</p><pre class="literallayout"><span class="strong strong"><strong>net.core.netdev_budget = <span class="emphasis"><em>600</em></span></strong></span>
<span class="strong strong"><strong>net.core.netdev_budget_usecs = 4000</strong></span></pre><p class="simpara">
									Set the parameters to a double of their current values.
								</p></li><li class="listitem"><p class="simpara">
									Load the settings from the <code class="literal">/etc/sysctl.d/10-netdev_budget.conf</code> file:
								</p><pre class="literallayout"># <span class="strong strong"><strong>sysctl -p /etc/sysctl.d/10-netdev_budget.conf</strong></span></pre></li></ol></div></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							Monitor the third column in the <code class="literal">/proc/net/softnet_stat</code> file:
						</p><pre class="literallayout"># <span class="strong strong"><strong>awk '{for (i=1; i&lt;=NF; i++) printf strtonum("0x" $i) (i==NF?"\n":" ")}' /proc/net/softnet_stat | column -t</strong></span></pre><p class="simpara">
							If the values still increase, set <code class="literal">net.core.netdev_budget_usecs</code> and <code class="literal">net.core.netdev_budget</code> to higher values. Repeat this process until the counters no longer increase.
						</p></li></ul></div></section></section><section class="section" id="improving-the-network-latency_tuning-the-network-performance"><div class="titlepage"><div><div><h3 class="title">31.3. Improving the network latency</h3></div></div></div><p>
				CPU power management features can cause unwanted delays in time-sensitive application processing. You can disable some or all of these power management features to improve the network latency.
			</p><p>
				For example, if the latency is higher when the server is idle than under heavy load, CPU power management settings could influence the latency.
			</p><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
					Disabling CPU power management features can cause a higher power consumption and heat loss.
				</p></div></rh-alert><section class="section" id="how-the-cpu-power-states-influence-the-network-latency_improving-the-network-latency"><div class="titlepage"><div><div><h4 class="title">31.3.1. How the CPU power states influence the network latency</h4></div></div></div><p>
					The consumption state (C-states) of CPUs optimize and reduce the power consumption of computers. The C-states are numbered, starting at C0. In C0, the processor is fully powered and executing. In C1, the processor is fully powered but not executing. The higher the number of the C-state, the more components the CPU turns off.
				</p><p>
					Whenever a CPU core is idle, the built-in power saving logic steps in and attempts to move the core from the current C-state to a higher one by turning off various processor components. If the CPU core must process data, Red Hat Enterprise Linux (RHEL) sends an interrupt to the processor to wake up the core and set its C-state back to C0.
				</p><p>
					Moving out of deep C-states back to C0 takes time due to turning power back on to various components of the processor. On multi-core systems, it can also happen that many of the cores are simultaneously idle and, therefore, in deeper C-states. If RHEL tries to wake them up at the same time, the kernel can generate a large number of Inter-Processor Interrupts (IPIs) while all cores return from deep C-states. Due to locking that is required while processing interrupts, the system can then stall for some time while handling all the interrupts. This can result in large delays in the application response to events.
				</p><div class="example" id="idm140280132957856"><p class="title"><strong>Example 31.2. Displaying times in C-state per core</strong></p><div class="example-contents"><p>
						The <code class="literal">Idle Stats</code> page in the PowerTOP application displays how much time the CPU cores spend in each C-state:
					</p><pre class="literallayout">           Pkg(HW)  |            Core(HW) |            CPU(OS) 0   CPU(OS) 4
                    |                     | C0 active   2.5%        2.2%
                    |                     | POLL        0.0%    0.0 ms  0.0%    0.1 ms
                    |                     | C1          0.1%    0.2 ms  0.0%    0.1 ms
C2 (pc2)   63.7%    |                     |
C3 (pc3)    0.0%    | C3 (cc3)    0.1%    | C3          0.1%    0.1 ms  0.1%    0.1 ms
C6 (pc6)    0.0%    | C6 (cc6)    8.3%    | C6          5.2%    0.6 ms  6.0%    0.6 ms
C7 (pc7)    0.0%    | C7 (cc7)   76.6%    | C7s         0.0%    0.0 ms  0.0%    0.0 ms
C8 (pc8)    0.0%    |                     | C8          6.3%    0.9 ms  5.8%    0.8 ms
C9 (pc9)    0.0%    |                     | C9          0.4%    3.7 ms  2.2%    2.2 ms
C10 (pc10)  0.0%    |                     |
                    |                     | C10        80.8%    3.7 ms 79.4%    4.4 ms
                    |                     | C1E         0.1%    0.1 ms  0.1%    0.1 ms
...</pre></div></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/managing-power-consumption-with-powertop_monitoring-and-managing-system-status-and-performance">Managing power consumption with PowerTOP</a>
						</li></ul></div></section><section class="section" id="c-state-settings-in-the-efi-firmware_improving-the-network-latency"><div class="titlepage"><div><div><h4 class="title">31.3.2. C-state settings in the EFI firmware</h4></div></div></div><p>
					In most systems with an EFI firmware, you can enable and disable the individual consumption states (C-states). However, on Red Hat Enterprise Linux (RHEL), the idle driver determines whether the kernel uses the settings from the firmware:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							<code class="literal">intel_idle</code>: This is the default driver on hosts with an Intel CPU and ignores the C-state settings from the EFI firmware.
						</li><li class="listitem">
							<code class="literal">acpi_idle</code>: RHEL uses this driver on hosts with CPUs from vendors other than Intel and if <code class="literal">intel_idle</code> is disabled. By default, the <code class="literal">acpi_idle</code> driver uses the C-state settings from the EFI firmware.
						</li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<code class="literal">/usr/share/doc/kernel-doc-<span class="emphasis"><em>&lt;version&gt;</em></span>/Documentation/admin-guide/pm/cpuidle.rst</code> provided by the <code class="literal">kernel-doc</code> package
						</li></ul></div></section><section class="section" id="disabling-c-states-by-using-a-custom-tuned-profile_improving-the-network-latency"><div class="titlepage"><div><div><h4 class="title">31.3.3. Disabling C-states by using a custom TuneD profile</h4></div></div></div><p>
					The TuneD service uses the Power Management Quality of Service (<code class="literal">PMQOS</code>) interface of the kernel to set consumption states (C-states) locking. The kernel idle driver can communicate with this interface to dynamically limit the C-states. This prevents that administrators must hard code a maximum C-state value by using kernel command line parameters.
				</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							The <code class="literal">tuned</code> package is installed.
						</li><li class="listitem">
							The <code class="literal">tuned</code> service is enabled and running.
						</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Display the active profile:
						</p><pre class="literallayout"># <span class="strong strong"><strong>tuned-adm active</strong></span>
Current active profile: <span class="emphasis"><em>network-latency</em></span></pre></li><li class="listitem"><p class="simpara">
							Create a directory for the custom TuneD profile:
						</p><pre class="literallayout"># <span class="strong strong"><strong>mkdir /etc/tuned/<span class="emphasis"><em>network-latency-custom</em></span>/</strong></span></pre></li><li class="listitem"><p class="simpara">
							Create the <code class="literal">/etc/tuned/<span class="emphasis"><em>network-latency-custom</em></span>/tuned.conf</code> file with the following content:
						</p><pre class="literallayout">[main]
include=<span class="emphasis"><em>network-latency</em></span>

[cpu]
force_latency=<span class="emphasis"><em>cstate.id:1|2</em></span></pre><p class="simpara">
							This custom profile inherits all settings from the <code class="literal">network-latency</code> profile. The <code class="literal">force_latency</code> TuneD parameter specifies the latency in microseconds (µs). If the C-state latency is higher than the specified value, the idle driver in Red Hat Enterprise Linux prevents the CPU from moving to a higher C-state. With <code class="literal">force_latency=cstate.id:1|2</code>, TuneD first checks if the <code class="literal">/sys/devices/system/cpu/cpu_&lt;number&gt;_/cpuidle/state_&lt;cstate.id&gt;_/</code> directory exists. In this case, TuneD reads the latency value from the <code class="literal">latency</code> file in this directory. If the directory does not exist, TuneD uses 2 microseconds as a fallback value.
						</p></li><li class="listitem"><p class="simpara">
							Activate the <code class="literal"><span class="emphasis"><em>network-latency-custom</em></span></code> profile:
						</p><pre class="literallayout"># <span class="strong strong"><strong>tuned-adm profile <span class="emphasis"><em>network-latency-custom</em></span></strong></span></pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<a class="link" href="#getting-started-with-tuned_monitoring-and-managing-system-status-and-performance" title="Chapter 1. Getting started with TuneD">Getting started with TuneD</a>
						</li><li class="listitem">
							<a class="link" href="#customizing-tuned-profiles_monitoring-and-managing-system-status-and-performance" title="Chapter 2. Customizing TuneD profiles">Customizing TuneD profiles</a>
						</li></ul></div></section><section class="section" id="disabling-c-states-by-using-a-kernel-command-line-option_improving-the-network-latency"><div class="titlepage"><div><div><h4 class="title">31.3.4. Disabling C-states by using a kernel command line option</h4></div></div></div><p>
					The <code class="literal">processor.max_cstate</code> and <code class="literal">intel_idle.max_cstat</code> kernel command line parameters configure the maximum consumption states (C-state) CPU cores can use. For example, setting the parameters to <code class="literal">1</code> ensures that the CPU will never request a C-state below C1.
				</p><p>
					Use this method to test whether the latency of applications on a host are being affected by C-states. To not hard code a specific state, consider using a more dynamic solution. See <a class="link" href="#disabling-c-states-by-using-a-custom-tuned-profile_improving-the-network-latency" title="31.3.3. Disabling C-states by using a custom TuneD profile">Disabling C-states by using a custom TuneD profile</a>.
				</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							The <code class="literal">tuned</code> service is not running or configured to not update C-state settings.
						</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Display the idle driver the system uses:
						</p><pre class="literallayout"># <span class="strong strong"><strong>cat /sys/devices/system/cpu/cpuidle/current_driver</strong></span>
<span class="emphasis"><em>intel_idle</em></span></pre></li><li class="listitem"><p class="simpara">
							If the host uses the <code class="literal">intel_idle</code> driver, set the <code class="literal">intel_idle.max_cstate</code> kernel parameter to define the highest C-state that CPU cores should be able to use:
						</p><pre class="literallayout"># <span class="strong strong"><strong>grubby --update-kernel=ALL --args="intel_idle.max_cstate=<span class="emphasis"><em>0</em></span>"</strong></span></pre><p class="simpara">
							Setting <code class="literal">intel_idle.max_cstate=0</code> disables the <code class="literal">intel_idle</code> driver. Consequently, the kernel uses the <code class="literal">acpi_idle</code> driver that uses the C-state values set in the EFI firmware. For this reason, also set <code class="literal">processor.max_cstate</code> to override these C-state settings.
						</p></li><li class="listitem"><p class="simpara">
							On every host, independent from the CPU vendor, set the highest C-state that CPU cores should be able to use:
						</p><pre class="literallayout"># <span class="strong strong"><strong>grubby --update-kernel=ALL --args="processor.max_cstate=<span class="emphasis"><em>0</em></span>"</strong></span></pre><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
								If you set <code class="literal">processor.max_cstate=0</code> in addition to <code class="literal">intel_idle.max_cstate=0</code>, the <code class="literal">acpi_idle</code> driver overrides the value of <code class="literal">processor.max_cstate</code> and sets it to <code class="literal">1</code>. As a result, with <code class="literal">processor.max_cstate=0 intel_idle.max_cstate=0</code>, the highest C-state the kernel will use is C1, not C0.
							</p></div></rh-alert></li><li class="listitem"><p class="simpara">
							Restart the host for the changes to take effect:
						</p><pre class="literallayout"># <span class="strong strong"><strong>reboot</strong></span></pre></li></ol></div><div class="orderedlist"><p class="title"><strong>Verification</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Display the maximum C-state:
						</p><pre class="literallayout"># <span class="strong strong"><strong>cat /sys/module/processor/parameters/max_cstate</strong></span>
1</pre></li><li class="listitem"><p class="simpara">
							If the host uses the <code class="literal">intel_idle</code> driver, display the maximum C-state:
						</p><pre class="literallayout"># <span class="strong strong"><strong>cat /sys/module/intel_idle/parameters/max_cstate</strong></span>
0</pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<a class="link" href="https://access.redhat.com/solutions/202743">What are CPU "C-states" and how to disable them if needed?</a> (Red Hat Knowledgebase)
						</li><li class="listitem">
							<code class="literal">/usr/share/doc/kernel-doc-<span class="emphasis"><em>&lt;version&gt;</em></span>/Documentation/admin-guide/pm/cpuidle.rst</code> provided by the <code class="literal">kernel-doc</code> package
						</li></ul></div></section></section><section class="section" id="improving-the-throughput-of-large-amounts-of-contiguous-data-streams_tuning-the-network-performance"><div class="titlepage"><div><div><h3 class="title">31.4. Improving the throughput of large amounts of contiguous data streams</h3></div></div></div><p>
				According to the IEEE 802.3 standard, a default Ethernet frame without Virtual Local Area Network (VLAN) tag has a maximum size of 1518 bytes. Each of these frames includes an 18 bytes header, leaving 1500 bytes for payload. Consequently, for every 1500 bytes of data the server transmits over the network, 18 bytes (1.2%) Ethernet frame header are overhead and transmitted as well. Headers from layer 3 and 4 protocols increase the overhead per packet further.
			</p><p>
				Consider employing jumbo frames to save overhead if hosts on your network often send numerous contiguous data streams, such as backup servers or file servers hosting numerous huge files. Jumbo frames are non-standardized frames that have a larger Maximum Transmission Unit (MTU) than the standard Ethernet payload size of 1500 bytes. For example, if you configure jumbo frames with the maximum allowed MTU of 9000 bytes payload, the overhead of each frame reduces to 0.2%.
			</p><p>
				Depending on the network and services, it can be beneficial to enable jumbo frames only in specific parts of a network, such as the storage backend of a cluster. This avoids packet fragmentation.
			</p><section class="section" id="considerations-before-configuring-jumbo-frames_improving-the-throughput-of-large-amounts-of-contiguous-data-streams"><div class="titlepage"><div><div><h4 class="title">31.4.1. Considerations before configuring jumbo frames</h4></div></div></div><p>
					Depending on your hardware, applications, and services in your network, jumbo frames can have different impacts. Decide carefully whether enabling jumbo frames provides a benefit in your scenario.
				</p><div class="formalpara"><p class="title"><strong>Prerequisites</strong></p><p>
						All network devices on the transmission path must support jumbo frames and use the same Maximum Transmission Unit (MTU) size. In the opposite case, you can face the following problems:
					</p></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Dropped packets.
						</li><li class="listitem">
							Higher latency due to fragmented packets.
						</li><li class="listitem">
							Increased risk of packet loss caused by fragmentation. For example, if a router fragments a single 9000-bytes frame into six 1500-bytes frames, and any of those 1500-byte frames are lost, the whole frame is lost because it cannot be reassembled.
						</li></ul></div><p>
					In the following diagram, all hosts in the three subnets must use the same MTU if a host from network A sends a packet to a host in network C:
				</p><div class="informalfigure"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/2418569b01b0a8c1dce179bfba831708/network-diagram-MTU.png" alt="network diagram MTU"></div></div><div class="itemizedlist"><p class="title"><strong>Benefits of jumbo frames</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							Higher throughput: Each frame contains more user data while the protocol overhead is fixed.
						</li><li class="listitem">
							Lower CPU utilization: Jumbo frames cause fewer interrupts and, therefore, save CPU cycles.
						</li></ul></div><div class="itemizedlist"><p class="title"><strong>Drawbacks of jumbo frames</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							Higher latency: Larger frames delay packets that follow.
						</li><li class="listitem">
							Increased memory buffer usage: Larger frames can fill buffer queue memory more quickly.
						</li></ul></div></section><section class="section" id="configuring-the-mtu-in-an-existing-networkmanager-connection-profile_improving-the-throughput-of-large-amounts-of-contiguous-data-streams"><div class="titlepage"><div><div><h4 class="title">31.4.2. Configuring the MTU in an existing NetworkManager connection profile</h4></div></div></div><p>
					If your network requires a different Maximum Transmission Unit (MTU) than the default, you can configure this setting in the corresponding NetworkManager connection profile.
				</p><p>
					Jumbo frames are network packets with a payload of between 1500 and 9000 bytes. All devices in the same broadcast domain have to support those frames.
				</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							All devices in the broadcast domain use the same MTU.
						</li><li class="listitem">
							You know the MTU of the network.
						</li><li class="listitem">
							You already configured a connection profile for the network with the divergent MTU.
						</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Optional: Display the current MTU:
						</p><pre class="literallayout"># <span class="strong strong"><strong>ip link show</strong></span>
...
3: enp1s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span class="strong strong"><strong>1500</strong></span> qdisc fq_codel state UP mode DEFAULT group default qlen 1000
    link/ether 52:54:00:74:79:56 brd ff:ff:ff:ff:ff:ff
...</pre></li><li class="listitem"><p class="simpara">
							Optional: Display the NetworkManager connection profiles:
						</p><pre class="literallayout"># <span class="strong strong"><strong>nmcli connection show</strong></span>
NAME     UUID                                  TYPE      DEVICE
<span class="emphasis"><em>Example</em></span>  <span class="emphasis"><em>f2f33f29-bb5c-3a07-9069-be72eaec3ecf</em></span>  ethernet  <span class="emphasis"><em>enp1s0</em></span>
...</pre></li><li class="listitem"><p class="simpara">
							Set the MTU in the profile that manages the connection to the network with the divergent MTU:
						</p><pre class="literallayout"># <span class="strong strong"><strong>nmcli connection modify <span class="emphasis"><em>Example</em></span> mtu <span class="emphasis"><em>9000</em></span></strong></span></pre></li><li class="listitem"><p class="simpara">
							Reactivate the connection:
						</p><pre class="literallayout"># <span class="strong strong"><strong>nmcli connection up <span class="emphasis"><em>Example</em></span></strong></span></pre></li></ol></div><div class="orderedlist"><p class="title"><strong>Verification</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Display the MTU setting:
						</p><pre class="literallayout"># <span class="strong strong"><strong>ip link show</strong></span>
...
3: enp1s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span class="strong strong"><strong>9000</strong></span> qdisc fq_codel state UP mode DEFAULT group default qlen 1000
    link/ether 52:54:00:74:79:56 brd ff:ff:ff:ff:ff:ff
...</pre></li><li class="listitem"><p class="simpara">
							Verify that no host on the transmission paths fragments the packets:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									On the receiver side, display the IP reassembly statistics of the kernel:
								</p><pre class="literallayout"># <span class="strong strong"><strong>nstat -az IpReasm</strong></span>*
#kernel
IpReasmTimeout 0 0.0
IpReasmReqds 0 0.0
IpReasmOKs 0 0.0
IpReasmFails 0 0.0</pre><p class="simpara">
									If the counters return <code class="literal">0</code>, packets were not reassembled.
								</p></li><li class="listitem"><p class="simpara">
									On the sender side, transmit an ICMP request with the prohibit-fragmentation-bit:
								</p><pre class="literallayout"># <span class="strong strong"><strong>ping -c1 -Mdo -s <span class="emphasis"><em>8972</em></span> <span class="emphasis"><em>destination_host</em></span></strong></span></pre><p class="simpara">
									If the command succeeds, the packet was not fragmented.
								</p><p class="simpara">
									Calculate the value for the <code class="literal">-s</code> packet size option as follows: MTU size - 8 bytes ICMP header - 20 bytes IPv4 header = packet size
								</p></li></ul></div></li></ol></div></section></section><section class="section" id="tuning-tcp-connections-for-high-throughput_tuning-the-network-performance"><div class="titlepage"><div><div><h3 class="title">31.5. Tuning TCP connections for high throughput</h3></div></div></div><p>
				Tune TCP-related settings on Red Hat Enterprise Linux to increase the throughput, reduce the latency, or prevent problems, such as packet loss.
			</p><section class="section" id="testing-the-tcp-throughput-using-iperf3_tuning-tcp-connections-for-high-throughput"><div class="titlepage"><div><div><h4 class="title">31.5.1. Testing the TCP throughput using iperf3</h4></div></div></div><p>
					The <code class="literal">iperf3</code> utility provides a server and client mode to perform network throughput tests between two hosts.
				</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
						The throughput of applications depends on many factors, such as the buffer sizes that the application uses. Therefore, the results measured with testing utilities, such as <code class="literal">iperf3</code>, can be significantly different from those of applications on a server under production workload.
					</p></div></rh-alert><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							The <code class="literal">iperf3</code> package is installed on both the client and server.
						</li><li class="listitem">
							No other services on either host cause network traffic that substantially affects the test result.
						</li><li class="listitem">
							For 40 Gbps and faster connections, the network card supports Accelerated Receive Flow Steering (ARFS) and the feature is enabled on the interface.
						</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Optional: Display the maximum network speed of the network interface controller (NIC) on both the server and client:
						</p><pre class="literallayout"># <span class="strong strong"><strong>ethtool enp1s0 | grep "Speed"</strong></span>
   Speed: 100000Mb/s</pre></li><li class="listitem"><p class="simpara">
							On the server:
						</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
									Temporarily open the default <code class="literal">iperf3</code> TCP port 5201 in the <code class="literal">firewalld</code> service:
								</p><pre class="literallayout"># <span class="strong strong"><strong>firewall-cmd --add-port=5201/tcp</strong></span>
# <span class="strong strong"><strong>firewall-cmd --reload</strong></span></pre></li><li class="listitem"><p class="simpara">
									Start <code class="literal">iperf3</code> in server mode:
								</p><pre class="literallayout"># <span class="strong strong"><strong>iperf3 --server</strong></span></pre><p class="simpara">
									The service now is waiting for incoming client connections.
								</p></li></ol></div></li><li class="listitem"><p class="simpara">
							On the client:
						</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
									Start measuring the throughput:
								</p><pre class="literallayout"># <span class="strong strong"><strong>iperf3 --time <span class="emphasis"><em>60</em></span> --zerocopy --client <span class="emphasis"><em>192.0.2.1</em></span></strong></span></pre><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
											<code class="literal">--time <span class="emphasis"><em>&lt;seconds&gt;</em></span></code>: Defines the time in seconds when the client stops the transmission.
										</p><p class="simpara">
											Set this parameter to a value that you expect to work and increase it in later measurements. If the server sends packets at a faster rate than the devices on the transmit path or the client can process, packets can be dropped.
										</p></li><li class="listitem">
											<code class="literal">--zerocopy</code>: Enables a zero copy method instead of using the <code class="literal">write()</code> system call. You require this option only if you want to simulate a zero-copy-capable application or to reach 40 Gbps and more on a single stream.
										</li><li class="listitem">
											<code class="literal">--client &lt;server&gt;</code>: Enables the client mode and sets the IP address or name of the server that runs the <code class="literal">iperf3</code> server.
										</li></ul></div></li></ol></div></li><li class="listitem"><p class="simpara">
							Wait until <code class="literal">iperf3</code> completes the test. Both the server and the client display statistics every second and a summary at the end. For example, the following is a summary displayed on a client:
						</p><pre class="literallayout">[ ID] Interval         Transfer    Bitrate         Retr
[  5] 0.00-60.00  sec  101 GBytes   14.4 Gbits/sec   0   sender
[  5] 0.00-60.04  sec  101 GBytes   14.4 Gbits/sec       receiver</pre><p class="simpara">
							In this example, the average bitrate was 14.4 Gbps.
						</p></li><li class="listitem"><p class="simpara">
							On the server:
						</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem">
									Press <kbd class="keycap">Ctrl</kbd>+<kbd class="keycap">C</kbd> to stop the <code class="literal">iperf3</code> server.
								</li><li class="listitem"><p class="simpara">
									Close the TCP port 5201 in <code class="literal">firewalld</code>:
								</p><pre class="literallayout"># <span class="strong strong"><strong>firewall-cmd --remove-port=5201/tcp</strong></span>
# <span class="strong strong"><strong>firewall-cmd --reload</strong></span></pre></li></ol></div></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<code class="literal">iperf3(1)</code> man page on your system
						</li></ul></div></section><section class="section" id="the-system-wide-tcp-socket-buffer-settings_tuning-tcp-connections-for-high-throughput"><div class="titlepage"><div><div><h4 class="title">31.5.2. The system-wide TCP socket buffer settings</h4></div></div></div><p>
					Socket buffers temporarily store data that the kernel has received or should send:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							The read socket buffer holds packets that the kernel has received but which the application has not read yet.
						</li><li class="listitem">
							The write socket buffer holds packets that an application has written to the buffer but which the kernel has not passed to the IP stack and network driver yet.
						</li></ul></div><p>
					If a TCP packet is too large and exceeds the buffer size or packets are sent or received at a too fast rate, the kernel drops any new incoming TCP packet until the data is removed from the buffer. In this case, increasing the socket buffers can prevent packet loss.
				</p><p>
					Both the <code class="literal">net.ipv4.tcp_rmem</code> (read) and <code class="literal">net.ipv4.tcp_wmem</code> (write) socket buffer kernel settings contain three values:
				</p><pre class="literallayout">net.ipv4.tcp_rmem = 4096  131072  6291456
net.ipv4.tcp_wmem = 4096  16384   4194304</pre><p>
					The displayed values are in bytes and Red Hat Enterprise Linux uses them in the following way:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							The first value is the minimum buffer size. New sockets cannot have a smaller size.
						</li><li class="listitem">
							The second value is the default buffer size. If an application sets no buffer size, this is the default value.
						</li><li class="listitem">
							The third value is the maximum size of automatically tuned buffers. Using the <code class="literal">setsockopt()</code> function with the <code class="literal">SO_SNDBUF</code> socket option in an application disables this maximum buffer size.
						</li></ul></div><p>
					Note that the <code class="literal">net.ipv4.tcp_rmem</code> and <code class="literal">net.ipv4.tcp_wmem</code> parameters set the socket sizes for both the IPv4 and IPv6 protocols.
				</p></section><section class="section" id="increasing-the-system-wide-tcp-socket-buffers_tuning-tcp-connections-for-high-throughput"><div class="titlepage"><div><div><h4 class="title">31.5.3. Increasing the system-wide TCP socket buffers</h4></div></div></div><p>
					The system-wide TCP socket buffers temporarily store data that the kernel has received or should send. Both <code class="literal">net.ipv4.tcp_rmem</code> (read) and <code class="literal">net.ipv4.tcp_wmem</code> (write) socket buffer kernel settings each contain three settings: A minimum, default, and maximum value.
				</p><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
						Setting too large buffer sizes wastes memory. Each socket can be set to the size that the application requests, and the kernel doubles this value. For example, if an application requests a 256 KiB socket buffer size and opens 1 million sockets, the system can use up to 512 GB RAM (512 KiB x 1 million) only for the potential socket buffer space.
					</p><p>
						Additionally, a too large value for the maximum buffer size can increase the latency.
					</p></div></rh-alert><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							You encountered a significant rate of dropped TCP packets.
						</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Determine the latency of the connection. For example, ping from the client to server to measure the average Round Trip Time (RTT):
						</p><pre class="literallayout"># <span class="strong strong"><strong>ping -c <span class="emphasis"><em>10</em></span> <span class="emphasis"><em>server.example.com</em></span></strong></span>
...
--- <span class="emphasis"><em>server.example.com</em></span> ping statistics ---
<span class="emphasis"><em>10</em></span> packets transmitted, <span class="emphasis"><em>10</em></span> received, <span class="emphasis"><em>0%</em></span> packet loss, time <span class="emphasis"><em>9014ms</em></span>
rtt min/avg/max/mdev = <span class="emphasis"><em>117.208</em></span>/<span class="strong strong"><strong><span class="emphasis"><em>117.056</em></span></strong></span>/<span class="emphasis"><em>119.333</em></span>/<span class="emphasis"><em>0.616</em></span> ms</pre><p class="simpara">
							In this example, the latency is 117 ms.
						</p></li><li class="listitem"><p class="simpara">
							Use the following formula to calculate the Bandwidth Delay Product (BDP) for the traffic you want to tune:
						</p><pre class="literallayout">connection speed in bytes * latency in ms = BDP in bytes</pre><p class="simpara">
							For example, to calculate the BDP for a 10 Gbps connection that has a 117 ms latency:
						</p><pre class="literallayout">(10 * 1000 * 1000 * 1000 / 8) * 117 = 10683760 bytes</pre></li><li class="listitem"><p class="simpara">
							Create the <code class="literal">/etc/sysctl.d/10-tcp-socket-buffers.conf</code> file and either set the maximum read or write buffer size, or both, based on your requirements:
						</p><pre class="literallayout"><span class="strong strong"><strong>net.ipv4.tcp_rmem = <span class="emphasis"><em>4096</em></span> <span class="emphasis"><em>262144</em></span> <span class="emphasis"><em>21367520</em></span></strong></span>
<span class="strong strong"><strong>net.ipv4.tcp_wmem = <span class="emphasis"><em>4096</em></span> <span class="emphasis"><em>24576</em></span> <span class="emphasis"><em>21367520</em></span></strong></span></pre><p class="simpara">
							Specify the values in bytes. Use the following rule of thumb when you try to identify optimized values for your environment:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									Default buffer size (second value): Increase this value only slightly or set it to <code class="literal">524288</code> (512 KiB) at most. A too high default buffer size can cause buffer collapsing and, consequently, latency spikes.
								</li><li class="listitem">
									Maximum buffer size (third value): A value double to triple of the BDP is often sufficient.
								</li></ul></div></li><li class="listitem"><p class="simpara">
							Load the settings from the <code class="literal">/etc/sysctl.d/10-tcp-socket-buffers.conf</code> file:
						</p><pre class="literallayout"># <span class="strong strong"><strong>sysctl -p /etc/sysctl.d/<span class="emphasis"><em>10-tcp-socket-buffers.conf</em></span></strong></span></pre></li><li class="listitem"><p class="simpara">
							Configure your applications to use a larger socket buffer size. The third value in the <code class="literal">net.ipv4.tcp_rmem</code> and <code class="literal">net.ipv4.tcp_wmem</code> parameters defines the maximum buffer size that the <code class="literal">setsockopt()</code> function in an application can request.
						</p><p class="simpara">
							For further details, see the documentation of the programming language of your application. If you are not the developer of the application, contact the developer.
						</p></li><li class="listitem"><p class="simpara">
							If you have changed the second value in the <code class="literal">net.ipv4.tcp_rmem</code> or <code class="literal">net.ipv4.tcp_wmem</code> parameter, restart the applications to use the new TCP buffer sizes.
						</p><p class="simpara">
							If you have changed only the third value, you do not need to restart the application because auto-tuning applies these settings dynamically.
						</p></li></ol></div><div class="orderedlist"><p class="title"><strong>Verification</strong></p><ol class="orderedlist" type="1"><li class="listitem">
							Optional: <a class="link" href="#testing-the-tcp-throughput-using-iperf3_tuning-tcp-connections-for-high-throughput" title="31.5.1. Testing the TCP throughput using iperf3">Test the TCP throughput using iperf3</a>.
						</li><li class="listitem"><p class="simpara">
							Monitor the packet drop statistics using the same method that you used when you encountered the packet drops.
						</p><p class="simpara">
							If packet drops still occur but at a lower rate, increase the buffer sizes further.
						</p></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<a class="link" href="https://access.redhat.com/solutions/85913">What are the implications of changing socket buffer sizes?</a> (Red Hat Knowledgebase)
						</li><li class="listitem">
							<code class="literal">tcp(7)</code> and <code class="literal">socket(7)</code> man pages on your system
						</li></ul></div></section><section class="section" id="tcp-window-scaling_tuning-tcp-connections-for-high-throughput"><div class="titlepage"><div><div><h4 class="title">31.5.4. TCP Window Scaling</h4></div></div></div><p>
					The TCP Window Scaling feature, which is enabled by default in Red Hat Enterprise Linux, is an extension of the TCP protocol that significantly improves the throughput.
				</p><p>
					For example, on a 1 Gbps connection with 1.5 ms Round Trip Time (RTT):
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							With TCP Window Scaling enabled, approximately 630 Mbps are realistic.
						</li><li class="listitem">
							With TCP Window Scaling disabled, the throughput goes down to 380 Mbps.
						</li></ul></div><p>
					One of the features TCP provides is flow control. With flow control, a sender can send as much data as the receiver can receive, but no more. To achieve this, the receiver advertises a <code class="literal">window</code> value, which is the amount of data a sender can send.
				</p><p>
					TCP originally supported window sizes up to 64 KiB, but at high Bandwidth Delay Products (BDP), this value becomes a restriction because the sender cannot send more than 64 KiB at a time. High-speed connections can transfer much more than 64 KiB of data at a given time. For example, a 10 Gbps link with 1 ms of latency between systems can have more than 1 MiB of data in transit at a given time. It would be inefficient if a host sends only 64 KiB, then pauses until the other host receives that 64 KiB.
				</p><p>
					To remove this bottleneck, the TCP Window Scaling extension allows the TCP window value to be arithmetically shifted left to increase the window size beyond 64 KiB. For example, the largest window value of <code class="literal">65535</code> shifted 7 places to the left, resulting in a window size of almost 8 MiB. This enables transferring much more data at a given time.
				</p><p>
					TCP Window Scaling is negotiated during the three-way TCP handshake that opens every TCP connection. Both sender and receiver must support TCP Window Scaling for the feature to work. If either or both participants do not advertise window scaling ability in their handshake, the connection reverts to using the original 16-bit TCP window size.
				</p><p>
					By default, TCP Window Scaling is enabled in Red Hat Enterprise Linux:
				</p><pre class="literallayout"># <span class="strong strong"><strong>sysctl net.ipv4.tcp_window_scaling</strong></span>
net.ipv4.tcp_window_scaling = 1</pre><p>
					If TCP Window Scaling is disabled (<code class="literal">0</code>) on your server, revert the setting in the same way as you set it.
				</p><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<a class="link" href="https://www.rfc-editor.org/rfc/rfc1323">RFC 1323: TCP Extensions for High Performance</a>
						</li><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_monitoring_and_updating_the_kernel/configuring-kernel-parameters-at-runtime_managing-monitoring-and-updating-the-kernel">Configuring kernel parameters at runtime</a>
						</li></ul></div></section><section class="section" id="how-tcp-sack-reduces-the-packet-drop-rate_tuning-tcp-connections-for-high-throughput"><div class="titlepage"><div><div><h4 class="title">31.5.5. How TCP SACK reduces the packet drop rate</h4></div></div></div><p>
					The TCP Selective Acknowledgment (TCP SACK) feature, which is enabled by default in Red Hat Enterprise Linux (RHEL), is an enhancement of the TCP protocol and increases the efficiency of TCP connections.
				</p><p>
					In TCP transmissions, the receiver sends an ACK packet to the sender for every packet it receives. For example, a client sends the TCP packets 1-10 to the server but the packets number 5 and 6 get lost. Without TCP SACK, the server drops packets 7-10, and the client must retransmit all packets from the point of loss, which is inefficient. With TCP SACK enabled on both hosts, the client must re-transmit only the lost packets 5 and 6.
				</p><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
						Disabling TCP SACK decreases the performance and causes a higher packet drop rate on the receiver side in a TCP connection.
					</p></div></rh-alert><p>
					By default, TCP SACK is enabled in RHEL. To verify:
				</p><pre class="literallayout"># <span class="strong strong"><strong>sysctl net.ipv4.tcp_sack</strong></span>
1</pre><p>
					If TCP SACK is disabled (<code class="literal">0</code>) on your server, revert the setting in the same way as you set it.
				</p><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<a class="link" href="http://tools.ietf.org/html/rfc2018">RFC 2018: TCP Selective Acknowledgment Options</a>
						</li><li class="listitem">
							<a class="link" href="https://access.redhat.com/solutions/742043">Should I be concerned about a 0.05% packet drop rate?</a> (Red Hat Knowledgebase)
						</li><li class="listitem">
							<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_monitoring_and_updating_the_kernel/configuring-kernel-parameters-at-runtime_managing-monitoring-and-updating-the-kernel">Configuring kernel parameters at runtime</a>
						</li></ul></div></section></section><section class="section" id="tuning-udp-connections_tuning-the-network-performance"><div class="titlepage"><div><div><h3 class="title">31.6. Tuning UDP connections</h3></div></div></div><p>
				Before you start tuning Red Hat Enterprise Linux to improve the throughput of UDP traffic, it is important to have the realistic expectations. UDP is a simple protocol. Compared to TCP, UDP does not contain features, such as flow control, congestion control, and data reliability. This makes it difficult to reach reliable communication over UDP with a throughput rate that is close to the maximum speed of the network interface controller (NIC).
			</p><section class="section" id="detecting-packet-drops_tuning-udp-connections"><div class="titlepage"><div><div><h4 class="title">31.6.1. Detecting packet drops</h4></div></div></div><p>
					There are multiple levels in the network stack in which the kernel can drop packets. Red Hat Enterprise Linux provides different utilities to display statistics of these levels. Use them to identify potential problems.
				</p><p>
					Note that you can ignore a very small rate of dropped packets. However, if you encounter a significant rate, consider tuning measures.
				</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
						The kernel drops network packets if the networking stack cannot handle the incoming traffic.
					</p></div></rh-alert><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Identify if the network interface controller (NIC) drops packets:
						</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
									Display the NIC and driver-specific statistics:
								</p><pre class="literallayout"># <span class="strong strong"><strong>ethtool -S <span class="emphasis"><em>enp1s0</em></span></strong></span>
NIC statistics:
     ...
     rx_queue<span class="emphasis"><em>_0</em></span>_drops: 17657
     ...</pre><p class="simpara">
									The naming of the statistics and if they are available depend on the NIC and the driver.
								</p></li><li class="listitem"><p class="simpara">
									Display the interface statistics:
								</p><pre class="literallayout"># <span class="strong strong"><strong>ip -s link show <span class="emphasis"><em>enp1s0</em></span></strong></span>
<span class="emphasis"><em>2: enp1s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000</em></span>
    <span class="emphasis"><em>link/ether 52:54:00:74:79:56 brd ff:ff:ff:ff:ff:ff</em></span>
    RX:   bytes  packets errors dropped  missed   mcast_
    <span class="emphasis"><em>84697611107</em></span> <span class="emphasis"><em>56866482</em></span>      <span class="emphasis"><em>0</em></span>   <span class="emphasis"><em>10904</em></span>       <span class="emphasis"><em>0</em></span>       <span class="emphasis"><em>0</em></span>
    TX:   bytes  packets errors dropped carrier collsns_
     <span class="emphasis"><em>5540028184</em></span>  <span class="emphasis"><em>3722234</em></span>      <span class="emphasis"><em>0</em></span>       <span class="emphasis"><em>0</em></span>       <span class="emphasis"><em>0</em></span>       <span class="emphasis"><em>0</em></span></pre><p class="simpara">
									<code class="literal">RX</code> represents the statistics of received packets and <code class="literal">TX</code> of transmitted packets.
								</p></li></ol></div></li><li class="listitem"><p class="simpara">
							Identify UDP protocol-specific packet drops due to too small socket buffers or slow application processing:
						</p><pre class="literallayout"># <span class="strong strong"><strong>nstat -az UdpSndbufErrors UdpRcvbufErrors</strong></span>
#kernel
UdpSndbufErrors           4    0.0
UdpRcvbufErrors    45716659    0.0</pre><p class="simpara">
							The second column in the output lists the counters.
						</p></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<a class="link" href="https://access.redhat.com/solutions/21301">RHEL network interface dropping packets</a> (Red Hat Knowledgebase)
						</li><li class="listitem">
							<a class="link" href="https://access.redhat.com/solutions/742043">Should I be concerned about a 0.05% packet drop rate?</a> (Red Hat Knowledgebase)
						</li></ul></div></section><section class="section" id="testing-the-udp-throughput-using-iperf3_tuning-udp-connections"><div class="titlepage"><div><div><h4 class="title">31.6.2. Testing the UDP throughput using iperf3</h4></div></div></div><p>
					The <code class="literal">iperf3</code> utility provides a server and client mode to perform network throughput tests between two hosts.
				</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
						The throughput of applications depend on many factors, such as the buffer sizes that the application uses. Therefore, the results measured with testing utilities, such as <code class="literal">iperf3</code>, can significantly be different from those of applications on a server under production workload.
					</p></div></rh-alert><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							The <code class="literal">iperf3</code> package is installed on both the client and server.
						</li><li class="listitem">
							No other services on both hosts cause network traffic that substantially affects the test result.
						</li><li class="listitem">
							Optional: You increased the maximum UDP socket sizes on both the server and the client. For details, see <a class="link" href="#increasing-the-system-wide-udp-socket-buffers_tuning-udp-connections" title="31.6.5. Increasing the system-wide UDP socket buffers">Increasing the system-wide UDP socket buffers</a>.
						</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Optional: Display the maximum network speed of the network interface controller (NIC) on both the server and client:
						</p><pre class="literallayout"># <span class="strong strong"><strong>ethtool enp1s0 | grep "Speed"</strong></span>
   Speed: 10000Mb/s</pre></li><li class="listitem"><p class="simpara">
							On the server:
						</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
									Display the maximum UDP socket read buffer size, and note the value:
								</p><pre class="literallayout"># <span class="strong strong"><strong>sysctl net.core.rmem_max</strong></span>
net.core.rmem_max = <span class="emphasis"><em>16777216</em></span></pre><p class="simpara">
									The displayed value is in bytes.
								</p></li><li class="listitem"><p class="simpara">
									Temporarily open the default <code class="literal">iperf3</code> port 5201 in the <code class="literal">firewalld</code> service:
								</p><pre class="literallayout"># <span class="strong strong"><strong>firewall-cmd --add-port=5201/tcp --add-port=5201/udp</strong></span>
# <span class="strong strong"><strong>firewall-cmd --reload</strong></span></pre><p class="simpara">
									Note that, <code class="literal">iperf3</code> opens only a TCP socket on the server. If a clients wants to use UDP, it first connects to this TCP port, and then the server opens a UDP socket on the same port number for performing the UDP traffic throughput test. For this reason, you must open port 5201 for both the TCP and UDP protocol in the local firewall.
								</p></li><li class="listitem"><p class="simpara">
									Start <code class="literal">iperf3</code> in server mode:
								</p><pre class="literallayout"># <span class="strong strong"><strong>iperf3 --server</strong></span></pre><p class="simpara">
									The service now waits for incoming client connections.
								</p></li></ol></div></li><li class="listitem"><p class="simpara">
							On the client:
						</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
									Display the Maximum Transmission Unit (MTU) of the interface that the client will use for the connection to the server, and note the value:
								</p><pre class="literallayout"># <span class="strong strong"><strong>ip link show enp1s0</strong></span>
<span class="emphasis"><em>2: enp1s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span class="strong strong"><strong>1500</strong></span> qdisc fq_codel state UP mode DEFAULT group default qlen 1000</em></span>
...</pre></li><li class="listitem"><p class="simpara">
									Display the maximum UDP socket write buffer size, and note the value:
								</p><pre class="literallayout"># <span class="strong strong"><strong>sysctl net.core.wmem_max</strong></span>
net.core.wmem_max = <span class="emphasis"><em>16777216</em></span></pre><p class="simpara">
									The displayed value is in bytes.
								</p></li><li class="listitem"><p class="simpara">
									Start measuring the throughput:
								</p><pre class="literallayout"># <span class="strong strong"><strong>iperf3 --udp --time <span class="emphasis"><em>60</em></span> --window <span class="emphasis"><em>16777216</em></span> --length <span class="emphasis"><em>1472</em></span> --bitrate 2G --client <span class="emphasis"><em>192.0.2.1</em></span></strong></span></pre><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
											<code class="literal">--udp</code>: Use the UDP protocol for the test.
										</li><li class="listitem">
											<code class="literal">--time <span class="emphasis"><em>&lt;seconds&gt;</em></span></code>: Defines the time in seconds when the client stops the transmission.
										</li><li class="listitem">
											<code class="literal">--window <span class="emphasis"><em>&lt;size&gt;</em></span></code>: Sets the UDP socket buffer size. Ideally, the sizes are the same on both the client and server. In case that they are different, set this parameter to the value that is smaller: <code class="literal">net.core.wmem_max</code> on the client or <code class="literal">net.core.rmem_max</code> on the server.
										</li><li class="listitem">
											<code class="literal">--length <span class="emphasis"><em>&lt;size&gt;</em></span></code>: Sets the length of the buffer to read and write. Set this option to the largest unfragmented payload. Calculate the ideal value as follows: MTU - IP header (20 bytes for IPv4 and 40 bytes for IPv6) - 8 bytes UDP header.
										</li><li class="listitem"><p class="simpara">
											<code class="literal">--bitrate <span class="emphasis"><em>&lt;rate&gt;</em></span></code>: Limits the bit rate to the specified value in bits per second. You can specify units, such as <code class="literal">2G</code> for 2 Gbps.
										</p><p class="simpara">
											Set this parameter to a value that you expect to work and increase it in later measurements. If the server sends packets at a faster rate than the devices on the transmit path or the client can process them, packets can be dropped.
										</p></li><li class="listitem">
											<code class="literal">--client &lt;server&gt;</code>: Enables the client mode and sets the IP address or name of the server that runs the <code class="literal">iperf3</code> server.
										</li></ul></div></li></ol></div></li><li class="listitem"><p class="simpara">
							Wait until <code class="literal">iperf3</code> completes the test. Both the server and the client display statistics every second and a summary at the end. For example, the following is a summary displayed on a client:
						</p><pre class="literallayout">[ ID] Interval       Transfer      Bitrate         Jitter    Lost/Total Datagrams
[ 5] 0.00-60.00 sec  14.0 GBytes   2.00 Gbits/sec  0.000 ms  0/10190216 (0%) sender
[ 5] 0.00-60.04 sec  14.0 GBytes   2.00 Gbits/sec  0.002 ms  0/10190216 (0%) receiver</pre><p class="simpara">
							In this example, the average bit rate was 2 Gbps, and no packets were lost.
						</p></li><li class="listitem"><p class="simpara">
							On the server:
						</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem">
									Press <kbd class="keycap">Ctrl</kbd>+<kbd class="keycap">C</kbd> to stop the <code class="literal">iperf3</code> server.
								</li><li class="listitem"><p class="simpara">
									Close port 5201 in <code class="literal">firewalld</code>:
								</p><pre class="literallayout"># <span class="strong strong"><strong>firewall-cmd --remove-port=5201/tcp --remove-port=5201/udp</strong></span>
# <span class="strong strong"><strong>firewall-cmd --reload</strong></span></pre></li></ol></div></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<code class="literal">iperf3(1)</code> man page on your system
						</li></ul></div></section><section class="section" id="impact-of-the-mtu-size-on-udp-traffic-throughput_tuning-udp-connections"><div class="titlepage"><div><div><h4 class="title">31.6.3. Impact of the MTU size on UDP traffic throughput</h4></div></div></div><p>
					If your application uses a large UDP message size, using jumbo frames can improve the throughput. According to the IEEE 802.3 standard, a default Ethernet frame without Virtual Local Area Network (VLAN) tag has a maximum size of 1518 bytes. Each of these frames includes an 18 bytes header, leaving 1500 bytes for payload. Consequently, for every 1500 bytes of data the server transmits over the network, 18 bytes (1.2%) are overhead.
				</p><p>
					Jumbo frames are non-standardized frames that have a larger Maximum Transmission Unit (MTU) than the standard Ethernet payload size of 1500 bytes. For example, if you configure jumbo Frames with the maximum allowed MTU of 9000 bytes payload, the overhead of each frame reduces to 0.2%.
				</p><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
						All network devices on the transmission path and the involved broadcast domains must support jumbo frames and use the same MTU. Packet fragmentation and reassembly due to inconsistent MTU settings on the transmission path reduces the network throughput.
					</p></div></rh-alert><p>
					Different connection types have certain MTU limitations:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Ethernet: the MTU is limited to 9000 bytes.
						</li><li class="listitem">
							IP over InfiniBand (IPoIB) in datagram mode: The MTU is limited to 4 bytes less than the InfiniBand MTU.
						</li><li class="listitem">
							In-memory networking commonly supports larger MTUs. For details, see the respective documentation.
						</li></ul></div></section><section class="section" id="impact-of-the-cpu-speed-on-udp-traffic-throughput_tuning-udp-connections"><div class="titlepage"><div><div><h4 class="title">31.6.4. Impact of the CPU speed on UDP traffic throughput</h4></div></div></div><p>
					In bulk transfers, the UDP protocol is much less efficient than TCP, mainly due to the missing packet aggregation in UDP. By default, the Generic Receive Offload (GRO) and Transmit Segmentation Offload (TSO) features are not enabled. Consequently, the CPU frequency can limit the UDP throughput for bulk transfer on high speed links.
				</p><p>
					For example, on a tuned host with a high Maximum Transmission Unit (MTU) and large socket buffers, a 3 GHz CPU can process the traffic of a 10 GBit NIC that sends or receives UDP traffic at full speed. However, you can expect about 1-2 Gbps speed loss for every 100 MHz CPU speed under 3 GHz when you transmit UDP traffic. Also, if a CPU speed of 3 GHz can closely achieve 10 Gbps, the same CPU restricts UDP traffic on a 40 GBit NIC to roughly 20-25 Gbps.
				</p></section><section class="section" id="increasing-the-system-wide-udp-socket-buffers_tuning-udp-connections"><div class="titlepage"><div><div><h4 class="title">31.6.5. Increasing the system-wide UDP socket buffers</h4></div></div></div><p>
					Socket buffers temporarily store data that the kernel has received or should send:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							The read socket buffer holds packets that the kernel has received but which the application has not read yet.
						</li><li class="listitem">
							The write socket buffer holds packets that an application has written to the buffer but which the kernel has not passed to the IP stack and network driver yet.
						</li></ul></div><p>
					If a UDP packet is too large and exceeds the buffer size or packets are sent or received at a too fast rate, the kernel drops any new incoming UDP packet until the data is removed from the buffer. In this case, increasing the socket buffers can prevent packet loss.
				</p><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
						Setting too large buffer sizes wastes memory. Each socket can be set to the size that the application requests, and the kernel doubles this value. For example, if an application requests a 256 KiB socket buffer size and opens 1 million sockets, the system requires 512 GB RAM (512 KiB x 1 million) only for the potential socket buffer space.
					</p></div></rh-alert><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							You encountered a significant rate of dropped UDP packets.
						</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Create the <code class="literal">/etc/sysctl.d/10-udp-socket-buffers.conf</code> file and either set the maximum read or write buffer size, or both, based on your requirements:
						</p><pre class="literallayout"><span class="strong strong"><strong>net.core.rmem_max = <span class="emphasis"><em>16777216</em></span></strong></span>
<span class="strong strong"><strong>net.core.wmem_max = <span class="emphasis"><em>16777216</em></span></strong></span></pre><p class="simpara">
							Specify the values in bytes. The values in this example set the maximum size of buffers to 16 MiB. The default values of both parameters are <code class="literal">212992</code> bytes (208 KiB).
						</p></li><li class="listitem"><p class="simpara">
							Load the settings from the <code class="literal">/etc/sysctl.d/10-udp-socket-buffers.conf</code> file:
						</p><pre class="literallayout"># <span class="strong strong"><strong>sysctl -p /etc/sysctl.d/<span class="emphasis"><em>10-udp-socket-buffers.conf</em></span></strong></span></pre></li><li class="listitem"><p class="simpara">
							Configure your applications to use the larger socket buffer sizes.
						</p><p class="simpara">
							The <code class="literal">net.core.rmem_max</code> and <code class="literal">net.core.wmem_max</code> parameters define the maximum buffer size that the <code class="literal">setsockopt()</code> function in an application can request. Note that, if you configure your application to not use the <code class="literal">setsockopt()</code> function, the kernel uses the values from the <code class="literal">rmem_default</code> and <code class="literal">wmem_default</code> parameters.
						</p><p class="simpara">
							For further details, see the documentation of the programming language of your application. If you are not the developer of the application, contact the developer.
						</p></li><li class="listitem">
							Restart the applications to use the new UDP buffer sizes.
						</li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							Monitor the packet drop statistics using the same method as you used when you encountered the packet drops.
						</p><p class="simpara">
							If packet drops still occur but at a lower rate, increase the buffer sizes further.
						</p></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<a class="link" href="https://access.redhat.com/solutions/85913">What are the implications of changing socket buffer sizes?</a> (Red Hat Knowledgebase)
						</li><li class="listitem">
							<code class="literal">udp(7)</code> and <code class="literal">socket(7)</code> man pages on your system
						</li></ul></div></section></section><section class="section" id="identifying-application-read-socket-buffer-bottlenecks_tuning-the-network-performance"><div class="titlepage"><div><div><h3 class="title">31.7. Identifying application read socket buffer bottlenecks</h3></div></div></div><p>
				If TCP applications do not clear the read socket buffers frequently enough, performance can suffer and packets can be lost. Red Hat Enterprise Linux provides different utilities to identify such problems.
			</p><section class="section" id="identifying-receive-buffer-collapsing-and-pruning_identifying-application-read-socket-buffer-bottlenecks"><div class="titlepage"><div><div><h4 class="title">31.7.1. Identifying receive buffer collapsing and pruning</h4></div></div></div><p>
					When the data in the receive queue exceeds the receive buffer size, the TCP stack tries to free some space by removing unnecessary metadata from the socket buffer. This step is known as collapsing.
				</p><p>
					If collapsing fails to free sufficient space for additional traffic, the kernel prunes new data that arrives. This means that the kernel removes the data from the memory and the packet is lost.
				</p><p>
					To avoid collapsing and pruning operations, monitor whether TCP buffer collapsing and pruning happens on your server and, in this case, tune the TCP buffers.
				</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Use the <code class="literal">nstat</code> utility to query the <code class="literal">TcpExtTCPRcvCollapsed</code> and <code class="literal">TcpExtRcvPruned</code> counters:
						</p><pre class="literallayout"># <span class="strong strong"><strong>nstat -az TcpExtTCPRcvCollapsed TcpExtRcvPruned</strong></span>
#kernel
TcpExtRcvPruned            0         0.0
TcpExtTCPRcvCollapsed      612859    0.0</pre></li><li class="listitem"><p class="simpara">
							Wait some time and re-run the <code class="literal">nstat</code> command:
						</p><pre class="literallayout"># <span class="strong strong"><strong>nstat -az TcpExtTCPRcvCollapsed TcpExtRcvPruned</strong></span>
#kernel
TcpExtRcvPruned            0         0.0
TcpExtTCPRcvCollapsed      620358    0.0</pre></li><li class="listitem"><p class="simpara">
							If the values of the counters have increased compared to the first run, tuning is required:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									If the application uses the <code class="literal">setsockopt(SO_RCVBUF)</code> call, consider removing it. With this call, the application only uses the receive buffer size specified in the call and turns off the socket’s ability to auto-tune its size.
								</li><li class="listitem">
									If the application does not use the <code class="literal">setsockopt(SO_RCVBUF)</code> call, tune the default and maximum values of the TCP read socket buffer.
								</li></ul></div></li><li class="listitem"><p class="simpara">
							Display the receive backlog queue (<code class="literal">Recv-Q</code>):
						</p><pre class="literallayout"># <span class="strong strong"><strong>ss -nti</strong></span>
State   Recv-Q   Send-Q   Local Address:Port   Peer Address:Port   Process
ESTAB   0        0        192.0.2.1:443        192.0.2.125:41574
      :7,7 ... lastrcv:543 ...
ESTAB   78       0        192.0.2.1:443        192.0.2.56:42612
      :7,7 ... lastrcv:658 ...
ESTAB   88       0        192.0.2.1:443        192.0.2.97:40313
      :7,7 ... lastrcv:5764 ...
...</pre></li><li class="listitem"><p class="simpara">
							Run the <code class="literal">ss -nt</code> command multiple times with a few seconds waiting time between each run.
						</p><p class="simpara">
							If the output lists only one case of a high value in the <code class="literal">Recv-Q</code> column, the application was between two receive operations. However, if the values in <code class="literal">Recv-Q</code> stays constant while <code class="literal">lastrcv</code> continually grows, or <code class="literal">Recv-Q</code> continually increases over time, one of the following problems can be the cause:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									The application does not check its socket buffers often enough. Contact the application vendor for details about how you can solve this problem.
								</li><li class="listitem"><p class="simpara">
									The application does not get enough CPU time. To further debug this problem:
								</p><div class="orderedlist"><ol class="orderedlist" type="i"><li class="listitem"><p class="simpara">
											Display on which CPU cores the application runs:
										</p><pre class="literallayout"># <span class="strong strong"><strong>ps -eo pid,tid,psr,pcpu,stat,wchan:20,comm</strong></span>
    PID     TID PSR %CPU STAT WCHAN                COMMAND
...
  44594   44594   5  0.0 Ss   do_select            httpd
  44595   44595   3  0.0 S    skb_wait_for_more_pa httpd
  44596   44596   5  0.0 Sl   pipe_read            httpd
  44597   44597   5  0.0 Sl   pipe_read            httpd
  44602   44602   5  0.0 Sl   pipe_read            httpd
...</pre><p class="simpara">
											The <code class="literal">PSR</code> column displays the CPU cores the process is currently assigned to.
										</p></li><li class="listitem">
											Identify other processes running on the same cores and consider assigning them to other cores.
										</li></ol></div></li></ul></div></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<a class="link" href="#increasing-the-system-wide-tcp-socket-buffers_tuning-tcp-connections-for-high-throughput" title="31.5.3. Increasing the system-wide TCP socket buffers">Increasing the system-wide TCP socket buffers</a>
						</li></ul></div></section></section><section class="section" id="tuning-applications-with-a-large-number-of-incoming-requests_tuning-the-network-performance"><div class="titlepage"><div><div><h3 class="title">31.8. Tuning applications with a large number of incoming requests</h3></div></div></div><p>
				If you run an application that handles a large number of incoming requests, such as web servers, it can be necessary to tune Red Hat Enterprise Linux to optimize the performance.
			</p><section class="section" id="tuning-the-tcp-listen-backlog-to-process-a-high-number-of-tcp-connection-attempts_tuning-applications-with-a-large-number-of-incoming-requests"><div class="titlepage"><div><div><h4 class="title">31.8.1. Tuning the TCP listen backlog to process a high number of TCP connection attempts</h4></div></div></div><p>
					When an application opens a TCP socket in <code class="literal">LISTEN</code> state, the kernel limits the number of accepted client connections this socket can handle. If clients try to establish more connections than the application can process, the new connections get lost or the kernel sends SYN cookies to the client.
				</p><p>
					If the system is under normal workload and too many connections from legitimate clients cause the kernel to send SYN cookies, tune Red Hat Enterprise Linux (RHEL) to avoid them.
				</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							RHEL logs <code class="literal">possible SYN flooding on port <span class="emphasis"><em>&lt;ip_address&gt;</em></span>:<span class="emphasis"><em>&lt;port_number&gt;</em></span></code> error messages in the Systemd journal.
						</li><li class="listitem">
							The high number of connection attempts are from valid sources and not caused by an attack.
						</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							To verify whether tuning is required, display the statistics for the affected port:
						</p><pre class="literallayout"># <span class="strong strong"><strong>ss -ntl '( sport = :<span class="emphasis"><em>443</em></span> )'</strong></span>
State    Recv-Q   Send-Q   Local Address:Port   Peer Address:Port  Process
LISTEN   <span class="emphasis"><em>650</em></span>      <span class="emphasis"><em>500</em></span>      <span class="emphasis"><em>192.0.2.1:443</em></span>        0.0.0.0:*</pre><p class="simpara">
							If the current number of connections in the backlog (<code class="literal">Recv-Q</code>) is larger than the socket backlog (<code class="literal">Send-Q</code>), the listen backlog is still not large enough and tuning is required.
						</p></li><li class="listitem"><p class="simpara">
							Optional: Display the current TCP listen backlog limit:
						</p><pre class="literallayout"># <span class="strong strong"><strong>sysctl net.core.somaxconn</strong></span>
net.core.somaxconn = <span class="emphasis"><em>4096</em></span></pre></li><li class="listitem"><p class="simpara">
							Create the <code class="literal">/etc/sysctl.d/10-socket-backlog-limit.conf</code> file, and set a larger listen backlog limit:
						</p><pre class="literallayout"><span class="strong strong"><strong>net.core.somaxconn = <span class="emphasis"><em>8192</em></span></strong></span></pre><p class="simpara">
							Note that applications can request a larger listen backlog than specified in the <code class="literal">net.core.somaxconn</code> kernel parameter but the kernel limits the application to the number you set in this parameter.
						</p></li><li class="listitem"><p class="simpara">
							Load the setting from the <code class="literal">/etc/sysctl.d/10-socket-backlog-limit.conf</code> file:
						</p><pre class="literallayout"># <span class="strong strong"><strong>sysctl -p /etc/sysctl.d/10-socket-backlog-limit.conf</strong></span></pre></li><li class="listitem"><p class="simpara">
							Reconfigure the application to use the new listen backlog limit:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									If the application provides a config option for the limit, update it. For example, the Apache HTTP Server provides the <code class="literal">ListenBacklog</code> configuration option to set the listen backlog limit for this service.
								</li><li class="listitem">
									If you cannot configure the limit, recompile the application.
								</li></ul></div></li><li class="listitem">
							Restart the application.
						</li></ol></div><div class="orderedlist"><p class="title"><strong>Verification</strong></p><ol class="orderedlist" type="1"><li class="listitem">
							Monitor the Systemd journal for further occurrences of <code class="literal">possible SYN flooding on port <span class="emphasis"><em>&lt;port_number&gt;</em></span></code> error messages.
						</li><li class="listitem"><p class="simpara">
							Monitor the current number of connections in the backlog and compare it with the socket backlog:
						</p><pre class="literallayout"># <span class="strong strong"><strong>ss -ntl '( sport = :<span class="emphasis"><em>443</em></span> )'</strong></span>
State    Recv-Q   Send-Q   Local Address:Port   Peer Address:Port  Process
LISTEN   <span class="emphasis"><em>0</em></span>        <span class="emphasis"><em>500</em></span>      <span class="emphasis"><em>192.0.2.1:443</em></span>        0.0.0.0:*</pre><p class="simpara">
							If the current number of connections in the backlog (<code class="literal">Recv-Q</code>) is larger than the socket backlog (<code class="literal">Send-Q</code>), the listen backlog is not large enough and further tuning is required.
						</p></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<a class="link" href="https://access.redhat.com/articles/1391433">kernel: Possible SYN flooding on port #. Sending cookies</a>
						</li><li class="listitem">
							<a class="link" href="https://access.redhat.com/solutions/3193562">Listening TCP server ignores SYN or ACK for new connection handshake</a> (Red Hat Knowledgebase)
						</li><li class="listitem">
							<code class="literal">listen(2)</code> man page on your system
						</li></ul></div></section></section><section class="section" id="avoiding-listen-queue-lock-contention_tuning-the-network-performance"><div class="titlepage"><div><div><h3 class="title">31.9. Avoiding listen queue lock contention</h3></div></div></div><p>
				Queue lock contention can cause packet drops and higher CPU usage and, consequently, a higher latency. You can avoid queue lock contention on the receive (RX) and transmit (TX) queue by tuning your application and using transmit packet steering.
			</p><section class="section" id="avoiding-rx-queue-lock-contention-the-so_reuseport-and-so_reuseport_bpf-socket-options_avoiding-listen-queue-lock-contention"><div class="titlepage"><div><div><h4 class="title">31.9.1. Avoiding RX queue lock contention: The SO_REUSEPORT and SO_REUSEPORT_BPF socket options</h4></div></div></div><p>
					On a multi-core system, you can improve the performance of multi-threaded network server applications if the application opens the port by using the <code class="literal">SO_REUSEPORT</code> or <code class="literal">SO_REUSEPORT_BPF</code> socket option. If the application does not use one of these socket options, all threads are forced to share a single socket to receive the incoming traffic. Using a single socket causes:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Significant contention on the receive buffer, which can cause packet drops and higher CPU usage.
						</li><li class="listitem">
							A significant increase of CPU usage
						</li><li class="listitem">
							Possibly packet drops
						</li></ul></div><div class="informalfigure"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/4a88b5b3bbe5fb65cf923949642f94e3/lock-contention.png" alt="lock contention"></div></div><p>
					With the <code class="literal">SO_REUSEPORT</code> or <code class="literal">SO_REUSEPORT_BPF</code> socket option, multiple sockets on one host can bind to the same port:
				</p><div class="informalfigure"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/d98510d7449bbab560553bb46e5828fe/so_reuseport.png" alt="so reuseport"></div></div><p>
					Red Hat Enterprise Linux provides a code example of how to use the <code class="literal">SO_REUSEPORT</code> socket options in the kernel sources. To access the code example:
				</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Enable the <code class="literal">rhel-9-for-x86_64-baseos-debug-rpms</code> repository:
						</p><pre class="literallayout"># <span class="strong strong"><strong>subscription-manager repos --enable rhel-9-for-x86_64-baseos-debug-rpms</strong></span></pre></li><li class="listitem"><p class="simpara">
							Install the <code class="literal">kernel-debuginfo-common-x86_64</code> package:
						</p><pre class="literallayout"># <span class="strong strong"><strong>dnf install kernel-debuginfo-common-x86_64</strong></span></pre></li><li class="listitem">
							The code example is now available in the <code class="literal">/usr/src/debug/kernel-<span class="emphasis"><em>&lt;version&gt;</em></span>/linux-&lt;version&gt;/tools/testing/selftests/net/reuseport_bpf_cpu.c</code> file.
						</li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<code class="literal">socket(7)</code> man page on your system
						</li><li class="listitem">
							<code class="literal">/usr/src/debug/kernel-<span class="emphasis"><em>&lt;version&gt;</em></span>/linux-&lt;version&gt;/tools/testing/selftests/net/reuseport_bpf_cpu.c</code>
						</li></ul></div></section><section class="section" id="avoiding-tx-queue-lock-contention-transmit-packet-steering_avoiding-listen-queue-lock-contention"><div class="titlepage"><div><div><h4 class="title">31.9.2. Avoiding TX queue lock contention: Transmit packet steering</h4></div></div></div><p>
					In hosts with a network interface controller (NIC) that supports multiple queues, transmit packet steering (XPS) distributes the processing of outgoing network packets among several queues. This enables multiple CPUs to process the outgoing network traffic and to avoid transmit queue lock contention and, consequently, packet drops.
				</p><p>
					Certain drivers, such as <code class="literal">ixgbe</code>, <code class="literal">i40e</code>, and <code class="literal">mlx5</code> automatically configure XPS. To identify if the driver supports this capability, consult the documentation of your NIC driver. Consult your NIC driver’s documentation to identify if the driver supports this capability. If the driver does not support XPS auto-tuning, you can manually assign CPU cores to the transmit queues.
				</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
						Red Hat Enterprise Linux does not provide an option to permanently assign transmit queues to CPU cores. Use the commands in a script and run it when the system boots.
					</p></div></rh-alert><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							The NIC supports multiple queues.
						</li><li class="listitem">
							The <code class="literal">numactl</code> package is installed.
						</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Display the count of available queues:
						</p><pre class="literallayout"># <span class="strong strong"><strong>ethtool -l <span class="emphasis"><em>enp1s0</em></span></strong></span>
Channel parameters for <span class="emphasis"><em>enp1s0</em></span>:
Pre-set maximums:
RX:		<span class="emphasis"><em>0</em></span>
TX:		<span class="emphasis"><em>0</em></span>
Other:		<span class="emphasis"><em>0</em></span>
Combined:	<span class="emphasis"><em>4</em></span>
Current hardware settings:
RX:		<span class="emphasis"><em>0</em></span>
TX:		<span class="emphasis"><em>0</em></span>
Other:		<span class="emphasis"><em>0</em></span>
Combined:	<span class="emphasis"><em>1</em></span></pre><p class="simpara">
							The <code class="literal">Pre-set maximums</code> section shows the total number of queues and <code class="literal">Current hardware settings</code> the number of queues that are currently assigned to the receive, transmit, other, or combined queues.
						</p></li><li class="listitem"><p class="simpara">
							Optional: If you require queues on specific channels, assign them accordingly. For example, to assign the 4 queues to the <code class="literal">Combined</code> channel, enter:
						</p><pre class="literallayout"># <span class="strong strong"><strong>ethtool -L <span class="emphasis"><em>enp1s0</em></span> combined 4</strong></span></pre></li><li class="listitem"><p class="simpara">
							Display to which Non-Uniform Memory Access (NUMA) node the NIC is assigned:
						</p><pre class="literallayout"># <span class="strong strong"><strong>cat /sys/class/net/<span class="emphasis"><em>enp1s0</em></span>/device/numa_node</strong></span>
0</pre><p class="simpara">
							If the file is not found or the command returns <code class="literal">-1</code>, the host is not a NUMA system.
						</p></li><li class="listitem"><p class="simpara">
							If the host is a NUMA system, display which CPUs are assigned to which NUMA node:
						</p><pre class="literallayout"># <span class="strong strong"><strong>lscpu | grep NUMA</strong></span>
NUMA node(s):       2
NUMA node0 CPU(s):  0-3
NUMA node1 CPU(s):  4-7</pre></li><li class="listitem"><p class="simpara">
							In the example above, the NIC has 4 queues and the NIC is assigned to NUMA node 0. This node uses the CPU cores 0-3. Consequently, map each transmit queue to one of the CPU cores from 0-3:
						</p><pre class="literallayout"># <span class="strong strong"><strong>echo <span class="emphasis"><em>1</em></span> &gt; /sys/class/net/<span class="emphasis"><em>enp1s0</em></span>/queues/tx-<span class="emphasis"><em>0</em></span>/xps_cpus</strong></span>
# <span class="strong strong"><strong>echo <span class="emphasis"><em>2</em></span> &gt; /sys/class/net/<span class="emphasis"><em>enp1s0</em></span>/queues/tx-<span class="emphasis"><em>1</em></span>/xps_cpus</strong></span>
# <span class="strong strong"><strong>echo <span class="emphasis"><em>4</em></span> &gt; /sys/class/net/<span class="emphasis"><em>enp1s0</em></span>/queues/tx-<span class="emphasis"><em>2</em></span>/xps_cpus</strong></span>
# <span class="strong strong"><strong>echo <span class="emphasis"><em>8</em></span> &gt; /sys/class/net/<span class="emphasis"><em>enp1s0</em></span>/queues/tx-<span class="emphasis"><em>3</em></span>/xps_cpus</strong></span></pre><p class="simpara">
							If the number of CPU cores and transmit (TX) queues is the same, use a 1 to 1 mapping to avoid any kind of contention on the TX queue. Otherwise, if you map multiple CPUs on the same TX queue, transmit operations on different CPUs will cause TX queue lock contention and negatively impacts the transmit throughput.
						</p><p class="simpara">
							Note that you must pass the bitmap, containing the CPU’s core numbers, to the queues. Use the following command to calculate the bitmap:
						</p><pre class="literallayout"># <span class="strong strong"><strong>printf %x $((1 &lt;&lt; <span class="emphasis"><em>&lt;core_number&gt;</em></span> ))</strong></span></pre></li></ol></div><div class="orderedlist"><p class="title"><strong>Verification</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Identify the process IDs (PIDs) of services that send traffic:
						</p><pre class="literallayout"># <span class="strong strong"><strong>pidof <span class="emphasis"><em>&lt;process_name&gt;</em></span></strong></span>
<span class="emphasis"><em>12345</em></span> <span class="emphasis"><em>98765</em></span></pre></li><li class="listitem"><p class="simpara">
							Pin the PIDs to cores that use XPS:
						</p><pre class="literallayout"># <span class="strong strong"><strong>numactl -C <span class="emphasis"><em>0-3</em></span> <span class="emphasis"><em>12345</em></span> <span class="emphasis"><em>98765</em></span></strong></span></pre></li><li class="listitem"><p class="simpara">
							Monitor the <code class="literal">requeues</code> counter while the process send traffic:
						</p><pre class="literallayout"># <span class="strong strong"><strong>tc -s qdisc</strong></span>
<span class="emphasis"><em>qdisc fq_codel 0: dev enp10s0u1 root refcnt 2 limit 10240p flows 1024 quantum 1514 target 5ms interval 100ms memory_limit 32Mb ecn drop_batch 64</em></span>
 Sent <span class="emphasis"><em>125728849</em></span> bytes <span class="emphasis"><em>1067587</em></span> pkt (dropped <span class="emphasis"><em>0</em></span>, overlimits <span class="emphasis"><em>0</em></span> requeues <span class="emphasis"><em>30</em></span>)
 backlog <span class="emphasis"><em>0b 0p</em></span> requeues <span class="emphasis"><em>30</em></span>
 ...</pre><p class="simpara">
							If the <code class="literal">requeues</code> counter no longer increases at a significant rate, TX queue lock contention no longer happens.
						</p></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<code class="literal">/usr/share/doc/kernel-doc-_&lt;version&gt;/Documentation/networking/scaling.rst</code>
						</li></ul></div></section><section class="section" id="disabling-the-generic-receive-offload-feature-on-servers-with-high-udp-traffic_avoiding-listen-queue-lock-contention"><div class="titlepage"><div><div><h4 class="title">31.9.3. Disabling the Generic Receive Offload feature on servers with high UDP traffic</h4></div></div></div><p>
					Applications that use high-speed UDP bulk transfer should enable and use UDP Generic Receive Offload (GRO) on the UDP socket. However, you can disable GRO to increase the throughput if the following conditions apply:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							The application does not support GRO and the feature cannot be added.
						</li><li class="listitem"><p class="simpara">
							TCP throughput is not relevant.
						</p><rh-alert class="admonition warning" state="danger"><div class="admonition_header" slot="header">Warning</div><div><p>
								Disabling GRO significantly reduces the receive throughput of TCP traffic. Therefore, do not disable GRO on hosts where TCP performance is relevant.
							</p></div></rh-alert></li></ul></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							The host mainly processes UDP traffic.
						</li><li class="listitem">
							The application does not use GRO.
						</li><li class="listitem">
							The host does not use UDP tunnel protocols, such as VXLAN.
						</li><li class="listitem">
							The host does not run virtual machines (VMs) or containers.
						</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Optional: Display the NetworkManager connection profiles:
						</p><pre class="literallayout"># <span class="strong strong"><strong>nmcli connection show</strong></span>
NAME     UUID                                  TYPE      DEVICE
<span class="emphasis"><em>example</em></span>  <span class="emphasis"><em>f2f33f29-bb5c-3a07-9069-be72eaec3ecf</em></span>  <span class="emphasis"><em>ethernet</em></span>  <span class="emphasis"><em>enp1s0</em></span></pre></li><li class="listitem"><p class="simpara">
							Disable GRO support in the connection profile:
						</p><pre class="literallayout"># <span class="strong strong"><strong>nmcli connection modify <span class="emphasis"><em>example</em></span> ethtool.feature-gro off</strong></span></pre></li><li class="listitem"><p class="simpara">
							Reactivate the connection profile:
						</p><pre class="literallayout"># <span class="strong strong"><strong>nmcli connection up <span class="emphasis"><em>example</em></span></strong></span></pre></li></ol></div><div class="orderedlist"><p class="title"><strong>Verification</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Verify that GRO is disabled:
						</p><pre class="literallayout"># <span class="strong strong"><strong>ethtool -k <span class="emphasis"><em>enp1s0</em></span> | grep generic-receive-offload</strong></span>
generic-receive-offload: off</pre></li><li class="listitem">
							Monitor the throughput on the server. Re-enable GRO in the NetworkManager profile if the setting has negative side effects to other applications on the host.
						</li></ol></div></section></section><section class="section" id="tuning-the-device-driver-and-nic_tuning-the-network-performance"><div class="titlepage"><div><div><h3 class="title">31.10. Tuning the device driver and NIC</h3></div></div></div><p>
				In RHEL, kernel modules provide drivers for network interface controllers (NICs). These modules support parameters to tune and optimize the device driver and the NIC. For example, if the driver supports delaying the generation of receive interrupts, you can reduce the value of the corresponding parameter to avoid running out of receive descriptors.
			</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					Not all modules support custom parameters, and the features depend on the hardware, as well as the driver and firmware version.
				</p></div></rh-alert><section class="section" id="configuring-custom-nic-driver-parameters_tuning-the-device-driver-and-nic"><div class="titlepage"><div><div><h4 class="title">31.10.1. Configuring custom NIC driver parameters</h4></div></div></div><p>
					Many kernel modules support setting parameters to tune the driver and the network interface controller (NIC). You can customize the settings according to the hardware and the driver.
				</p><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
						If you set parameters on a kernel module, RHEL applies these settings to all devices that use this driver.
					</p></div></rh-alert><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							A NIC is installed in the host.
						</li><li class="listitem">
							The kernel module that provides the driver for the NIC supports the required tuning feature.
						</li><li class="listitem">
							You are logged in locally or using a network interface that is different from the one that uses the driver for which you want to change the parameters.
						</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Identify the driver:
						</p><pre class="literallayout"># <span class="strong strong"><strong>ethtool -i <span class="emphasis"><em>enp0s31f6</em></span></strong></span>
driver: <span class="emphasis"><em>e1000e</em></span>
version: ...
firmware-version: ...
...</pre><p class="simpara">
							Note that certain features can require a specific driver and firmware version.
						</p></li><li class="listitem"><p class="simpara">
							Display the available parameters of the kernel module:
						</p><pre class="literallayout"># <span class="strong strong"><strong>modinfo -p <span class="emphasis"><em>e1000e</em></span></strong></span>
...
SmartPowerDownEnable:Enable PHY smart power down (array of int)
parm:RxIntDelay:Receive Interrupt Delay (array of int)</pre><p class="simpara">
							For further details on the parameters, see the kernel module’s documentation. For modules in RHEL, see the documentation in the <code class="literal">/usr/share/doc/kernel-doc-<span class="emphasis"><em>&lt;version&gt;</em></span>/Documentation/networking/device_drivers/</code> directory that is provided by the <code class="literal">kernel-doc</code> package.
						</p></li><li class="listitem"><p class="simpara">
							Create the <code class="literal">/etc/modprobe.d/<span class="emphasis"><em>nic-parameters.conf</em></span></code> file and specify the parameters for the module:
						</p><pre class="literallayout">options <span class="emphasis"><em>&lt;module_name&gt;</em></span> <span class="emphasis"><em>&lt;parameter1&gt;</em></span>=<span class="emphasis"><em>&lt;value&gt;</em></span> <span class="emphasis"><em>&lt;parameter2&gt;</em></span>=<span class="emphasis"><em>&lt;value&gt;</em></span></pre><p class="simpara">
							For example, to enable the port power saving mechanism and set the generation of receive interrupts to 4 units, enter:
						</p><pre class="literallayout"><span class="strong strong"><strong>options <span class="emphasis"><em>e1000e SmartPowerDownEnable=1 RxIntDelay=4</em></span></strong></span></pre></li><li class="listitem"><p class="simpara">
							Unload the module:
						</p><pre class="literallayout"># <span class="strong strong"><strong>modprobe -r <span class="emphasis"><em>e1000e</em></span></strong></span></pre><rh-alert class="admonition warning" state="danger"><div class="admonition_header" slot="header">Warning</div><div><p>
								Unloading a module that an active network interface uses, immediately terminates the connection and you can lock yourself out of the server.
							</p></div></rh-alert></li><li class="listitem"><p class="simpara">
							Load the module:
						</p><pre class="literallayout"># <span class="strong strong"><strong>modprobe <span class="emphasis"><em>e1000e</em></span></strong></span></pre></li><li class="listitem"><p class="simpara">
							Reactivate the network connections:
						</p><pre class="literallayout"># <span class="strong strong"><strong>nmcli connection up <span class="emphasis"><em>&lt;profile_name&gt;</em></span></strong></span></pre></li></ol></div><div class="orderedlist"><p class="title"><strong>Verification</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Display the kernel messages:
						</p><pre class="literallayout"># <span class="strong strong"><strong>dmesg</strong></span>
...
[35309.225765] e1000e 0000:00:1f.6: Transmit Interrupt Delay set to 16
[35309.225769] e1000e 0000:00:1f.6: PHY Smart Power Down Enabled
...</pre><p class="simpara">
							Note that not all modules log parameter settings to the kernel ring buffer.
						</p></li><li class="listitem"><p class="simpara">
							Certain kernel modules create files for each module parameter in the <code class="literal">/sys/module/<span class="emphasis"><em>&lt;driver&gt;</em></span>/parameters/</code> directory. Each of these files contain the current value of this parameter. You can display these files to verify a setting:
						</p><pre class="literallayout"># <span class="strong strong"><strong>cat /sys/module/<span class="emphasis"><em>&lt;driver_name&gt;</em></span>/parameters/<span class="emphasis"><em>&lt;parameter_name&gt;</em></span></strong></span></pre></li></ol></div></section></section><section class="section" id="configuring-network-adapter-offload-settings_tuning-the-network-performance"><div class="titlepage"><div><div><h3 class="title">31.11. Configuring network adapter offload settings</h3></div></div></div><p>
				To reduce CPU load, certain network adapters use offloading features which move the network processing load to the network interface controller (NIC). For example, with Encapsulating Security Payload (ESP) offload, the NIC performs ESP operations to accelerate IPsec connections and reduce CPU load.
			</p><p>
				By default, most offloading features in Red Hat Enterprise Linux are enabled. Only disable them in the following cases:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						Temporarily disable offload features for troubleshooting purposes.
					</li><li class="listitem">
						Permanently disable offload features when a specific feature negatively impacts your host.
					</li></ul></div><p>
				If a performance-related offload feature is not enabled by default in a network driver, you can enable it manually.
			</p><section class="section" id="temporarily-setting-an-offload-feature_configuring-network-adapter-offload-settings"><div class="titlepage"><div><div><h4 class="title">31.11.1. Temporarily setting an offload feature</h4></div></div></div><p>
					If you expect that an offload feature causes problems or reduces the performance of your host, you can attempt to narrow down the cause by temporarily enabling or disabling it, depending on its current state.
				</p><p>
					If you temporarily enable or disable an offload feature, it returns to its previous value on the next reboot.
				</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							The network card supports offload features.
						</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Display the interface’s available offload features and their current state:
						</p><pre class="literallayout"># <span class="strong strong"><strong>ethtool -k <span class="emphasis"><em>enp1s0</em></span></strong></span>
...
<span class="emphasis"><em>esp-hw-offload: on</em></span>
<span class="emphasis"><em>ntuple-filters: off</em></span>
<span class="emphasis"><em>rx-vlan-filter: off [fixed]</em></span>
...</pre><p class="simpara">
							The output depends on the capabilities of the hardware and its driver. Note that you cannot change the state of features that are flagged with <code class="literal">[fixed]</code>.
						</p></li><li class="listitem"><p class="simpara">
							Temporarily disable an offload feature:
						</p><pre class="literallayout"># <span class="strong strong"><strong>ethtool -K <span class="emphasis"><em>&lt;interface&gt;</em></span> <span class="emphasis"><em>&lt;feature&gt;</em></span> <span class="emphasis"><em>[on|off]</em></span></strong></span></pre><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									For example, to temporarily disable IPsec Encapsulating Security Payload (ESP) offload on the <code class="literal">enp10s0u1</code> interface, enter:
								</p><pre class="literallayout"># <span class="strong strong"><strong>ethtool -K <span class="emphasis"><em>enp10s0u1</em></span> <span class="emphasis"><em>esp-hw-offload</em></span> off</strong></span></pre></li><li class="listitem"><p class="simpara">
									For example, to temporarily enable accelerated Receive Flow Steering (aRFS) filtering on the <code class="literal">enp10s0u1</code> interface, enter:
								</p><pre class="literallayout"># <span class="strong strong"><strong>ethtool -K <span class="emphasis"><em>enp10s0u1</em></span> <span class="emphasis"><em>ntuple-filters</em></span> on</strong></span></pre></li></ul></div></li></ol></div><div class="orderedlist"><p class="title"><strong>Verification</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Display the states of the offload features:
						</p><pre class="literallayout"># <span class="strong strong"><strong>ethtool -k <span class="emphasis"><em>enp1s0</em></span></strong></span>
...
<span class="emphasis"><em>esp-hw-offload: off</em></span>
<span class="emphasis"><em>ntuple-filters: on</em></span>
...</pre></li><li class="listitem"><p class="simpara">
							Test whether the problem you encountered before changing the offload feature still exists.
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									If the problem no longer exists after changing a specific offload feature:
								</p><div class="orderedlist"><ol class="orderedlist" type="i"><li class="listitem">
											Contact <a class="link" href="https://access.redhat.com/support">Red Hat Support</a> and report the problem.
										</li><li class="listitem">
											Consider <a class="link" href="#permanently-setting-an-offload-feature_configuring-network-adapter-offload-settings" title="31.11.2. Permanently setting an offload feature">permanently setting the offload feature</a> until a fix is available.
										</li></ol></div></li><li class="listitem"><p class="simpara">
									If the problem still exists after disabling a specific offload feature:
								</p><div class="orderedlist"><ol class="orderedlist" type="i"><li class="listitem">
											Reset the setting to its previous state by using the <code class="literal">ethtool -K <span class="emphasis"><em>&lt;interface&gt;</em></span> <span class="emphasis"><em>&lt;feature&gt;</em></span> <span class="emphasis"><em>[on|off]</em></span></code> command.
										</li><li class="listitem">
											Enable or disable a different offload feature to narrow down the problem.
										</li></ol></div></li></ul></div></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<code class="literal">ethtool(8)</code> man page on your system
						</li></ul></div></section><section class="section" id="permanently-setting-an-offload-feature_configuring-network-adapter-offload-settings"><div class="titlepage"><div><div><h4 class="title">31.11.2. Permanently setting an offload feature</h4></div></div></div><p>
					If you have identified a specific offload feature that limits the performance on your host, you can permanently enable or disable it, depending on its current state.
				</p><p>
					If you permanently enable or disable an offload feature, NetworkManager ensures that the feature still has this state after a reboot.
				</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							You identified a specific offload feature to limit the performance on your host.
						</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Identify the connection profile that uses the network interface on which you want to change the state of the offload feature:
						</p><pre class="literallayout"># <span class="strong strong"><strong>nmcli connection show</strong></span>
NAME     UUID                                  TYPE      DEVICE
<span class="emphasis"><em>Example</em></span>  <span class="emphasis"><em>a5eb6490-cc20-3668-81f8-0314a27f3f75</em></span>  ethernet  <span class="emphasis"><em>enp1ss0</em></span>
...</pre></li><li class="listitem"><p class="simpara">
							Permanently change the state of the offload feature:
						</p><pre class="literallayout"># <span class="strong strong"><strong>nmcli connection modify <span class="emphasis"><em>&lt;connection_name&gt;</em></span> <span class="emphasis"><em>&lt;feature&gt;</em></span> <span class="emphasis"><em>[on|off]</em></span></strong></span></pre><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									For example, to permanently disable IPsec Encapsulating Security Payload (ESP) offload in the <code class="literal">Example</code> connection profile, enter:
								</p><pre class="literallayout"># <span class="strong strong"><strong>nmcli connection modify <span class="emphasis"><em>Example</em></span> <span class="emphasis"><em>ethtool.feature-esp-hw-offload</em></span> off</strong></span></pre></li><li class="listitem"><p class="simpara">
									For example, to permanently enable accelerated Receive Flow Steering (aRFS) filtering in the <code class="literal">Example</code> connection profile, enter:
								</p><pre class="literallayout"># <span class="strong strong"><strong>nmcli connection modify <span class="emphasis"><em>Example</em></span> <span class="emphasis"><em>ethtool.feature-ntuple</em></span> on</strong></span></pre></li></ul></div></li><li class="listitem"><p class="simpara">
							Reactivate the connection profile:
						</p><pre class="literallayout"># <span class="strong strong"><strong>nmcli connection up <span class="emphasis"><em>Example</em></span></strong></span></pre></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							Display the output states of the offload features:
						</p><pre class="literallayout"># <span class="strong strong"><strong>ethtool -k <span class="emphasis"><em>enp1s0</em></span></strong></span>
...
<span class="emphasis"><em>esp-hw-offload: off</em></span>
<span class="emphasis"><em>ntuple-filters: on</em></span>
...</pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<code class="literal">nm-settings-nmcli(5)</code> man page on your system
						</li></ul></div></section></section><section class="section" id="tuning-interrupt-coalescence-settings_tuning-the-network-performance"><div class="titlepage"><div><div><h3 class="title">31.12. Tuning interrupt coalescence settings</h3></div></div></div><p>
				Interrupt coalescence is a mechanism for reducing the number of interrupts generated by a network card. Generally, fewer interrupts can enhance the latency and overall performance of your network.
			</p><p>
				Tuning the interrupt coalescence settings involves adjusting the parameters that control:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						The number of packets that are combined into a single interrupt.
					</li><li class="listitem">
						The delay before generating an interrupt.
					</li></ul></div><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
					The optimal coalescence settings depend on the specific network conditions and hardware in use. Therefore, it might take several attempts to find the settings that work best for your environment and needs.
				</p></div></rh-alert><section class="section" id="optimizing-rhel-for-latency-or-throughput-sensitive-services_tuning-interrupt-coalescence-settings"><div class="titlepage"><div><div><h4 class="title">31.12.1. Optimizing RHEL for latency or throughput-sensitive services</h4></div></div></div><p>
					The goal of coalesce tuning is to minimize the number of interrupts required for a given workload. In high-throughput situations, the goal is to have as few interrupts as possible while maintaining a high data rate. In low-latency situations, more interrupts can be used to handle traffic quickly.
				</p><p>
					You can adjust the settings on your network card to increase or decrease the number of packets that are combined into a single interrupt. As a result, you can achieve improved throughput or latency for your traffic.
				</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Identify the network interface that is experiencing the bottleneck:
						</p><pre class="literallayout"># <span class="strong strong"><strong>ethtool -S <span class="emphasis"><em>enp1s0</em></span></strong></span>
NIC statistics:
     rx_packets: 1234
     tx_packets: 5678
     rx_bytes: 12345678
     tx_bytes: 87654321
     rx_errors: 0
     tx_errors: 0
     rx_missed: 0
     tx_dropped: 0
     coalesced_pkts: 0
     coalesced_events: 0
     coalesced_aborts: 0</pre><p class="simpara">
							Identify the packet counters containing "drop", "discard", or "error" in their name. These particular statistics measure the actual packet loss at the network interface card (NIC) packet buffer, which can be caused by NIC coalescence.
						</p></li><li class="listitem"><p class="simpara">
							Monitor values of packet counters you identified in the previous step.
						</p><p class="simpara">
							Compare them to the expected values for your network to determine whether any particular interface experiences a bottleneck. Some common signs of a network bottleneck include, but are not limited to:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									Many errors on a network interface
								</li><li class="listitem">
									High packet loss
								</li><li class="listitem"><p class="simpara">
									Heavy usage of the network interface
								</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
										Other important factors are for example CPU usage, memory usage, and disk I/O when identifying a network bottleneck.
									</p></div></rh-alert></li></ul></div></li><li class="listitem"><p class="simpara">
							View the current coalescence settings:
						</p><pre class="literallayout"># <span class="strong strong"><strong>ethtool enp1s0</strong></span>
Settings for enp1s0:
        Supported ports: [ TP ]
        Supported link modes:   10baseT/Half 10baseT/Full
                                100baseT/Half 100baseT/Full
                                1000baseT/Full
        Supported pause frame use: No
        Supports auto-negotiation: Yes
        Advertised link modes:  10baseT/Half 10baseT/Full
                                100baseT/Half 100baseT/Full
                                1000baseT/Full
        Advertised pause frame use: No
        Advertised auto-negotiation: Yes
        Speed: 1000Mb/s
        Duplex: Full
        Port: Twisted Pair
        PHYAD: 0
        Transceiver: internal
        Auto-negotiation: on
        MDI-X: Unknown
        Supports Wake-on: g
        Wake-on: g
        Current message level: 0x00000033 (51)
                               drv probe link
        Link detected: yes</pre><p class="simpara">
							In this output, monitor the <code class="literal">Speed</code> and <code class="literal">Duplex</code> fields. These fields display information about the network interface operation and whether it is running at its expected values.
						</p></li><li class="listitem"><p class="simpara">
							Check the current interrupt coalescence settings:
						</p><pre class="literallayout"># <span class="strong strong"><strong>ethtool -c enp1s0</strong></span>
Coalesce parameters for enp1s0:
        Adaptive RX: off
        Adaptive TX: off
        RX usecs: 100
        RX frames: 8
        RX usecs irq: 100
        RX frames irq: 8
        TX usecs: 100
        TX frames: 8
        TX usecs irq: 100
        TX frames irq: 8</pre><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									The <code class="literal">usecs</code> values refer to the number of microseconds that the receiver or transmitter waits before generating an interrupt.
								</li><li class="listitem">
									The <code class="literal">frames</code> values refer to the number of frames that the receiver or transmitter waits before generating an interrupt.
								</li><li class="listitem"><p class="simpara">
									The <code class="literal">irq</code> values are used to configure the interrupt moderation when the network interface is already handling an interrupt.
								</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
										Not all network interface cards support reporting and changing all values from the example output.
									</p></div></rh-alert></li><li class="listitem">
									The <code class="literal">Adaptive RX/TX</code> value represents the adaptive interrupt coalescence mechanism, which adjusts the interrupt coalescence settings dynamically. Based on the packet conditions, the NIC driver auto-calculates coalesce values when <code class="literal">Adaptive RX/TX</code> are enabled (the algorithm differs for every NIC driver).
								</li></ul></div></li><li class="listitem"><p class="simpara">
							Modify the coalescence settings as needed. For example:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									While <code class="literal">ethtool.coalesce-adaptive-rx</code> is disabled, configure <code class="literal">ethtool.coalesce-rx-usecs</code> to set the delay before generating an interrupt to 100 microseconds for the RX packets:
								</p><pre class="literallayout"># <span class="strong strong"><strong>nmcli connection modify enp1s0 ethtool.coalesce-rx-usecs <span class="emphasis"><em>100</em></span></strong></span></pre></li><li class="listitem"><p class="simpara">
									Enable <code class="literal">ethtool.coalesce-adaptive-rx</code> while <code class="literal">ethtool.coalesce-rx-usecs</code> is set to its default value:
								</p><pre class="literallayout"># <span class="strong strong"><strong>nmcli connection modify enp1s0 ethtool.coalesce-adaptive-rx on</strong></span></pre><p class="simpara">
									Modify the Adaptive-RX setting as follows:
								</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
											Users concerned with low latency (sub-50us) should not enable <code class="literal">Adaptive-RX</code>.
										</li><li class="listitem">
											Users concerned with throughput can probably enable <code class="literal">Adaptive-RX</code> with no harm. If they do not want to use the adaptive interrupt coalescence mechanism, they can try setting large values like 100us, or 250us to <code class="literal">ethtool.coalesce-rx-usecs</code>.
										</li><li class="listitem">
											Users unsure about their needs should not modify this setting until an issue occurs.
										</li></ul></div></li></ul></div></li><li class="listitem"><p class="simpara">
							Re-activate the connection:
						</p><pre class="literallayout"># <span class="strong strong"><strong>nmcli connection up enp1s0</strong></span></pre></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							Monitor the network performance and check for dropped packets:
						</p><pre class="literallayout"># <span class="strong strong"><strong>ethtool -S enp1s0</strong></span>
NIC statistics:
     rx_packets: 1234
     tx_packets: 5678
     rx_bytes: 12345678
     tx_bytes: 87654321
     rx_errors: 0
     tx_errors: 0
     rx_missed: 0
     tx_dropped: 0
     coalesced_pkts: 12
     coalesced_events: 34
     coalesced_aborts: 56
...</pre><p class="simpara">
							The value of the <code class="literal">rx_errors</code>, <code class="literal">rx_dropped</code>, <code class="literal">tx_errors</code>, and <code class="literal">tx_dropped</code> fields should be 0 or close to it (up to few hundreds, depending on the network traffic and system resources). A high value in these fields indicates a network problem. Your counters can have different names. Closely monitor packet counters containing "drop", "discard", or "error" in their name.
						</p><p class="simpara">
							The value of the <code class="literal">rx_packets</code>, <code class="literal">tx_packets</code>, <code class="literal">rx_bytes</code>, and <code class="literal">tx_bytes</code> should increase over time. If the values do not increase, there might be a network problem. The packet counters can have different names, depending on your NIC driver.
						</p><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
								The <code class="literal">ethtool</code> command output can vary depending on the NIC and driver in use.
							</p></div></rh-alert><p class="simpara">
							Users with focus on extremely low latency can use application-level metrics or the kernel packet time-stamping API for their monitoring purposes.
						</p></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
							<a class="link" href="https://access.redhat.com/articles/1162133">Initial investigation for any performance issue</a>
						</li><li class="listitem">
							<a class="link" href="https://access.redhat.com/solutions/108513">What are the kernel parameters available for network tuning?</a> (Red Hat Knowledgebase)
						</li><li class="listitem">
							<a class="link" href="https://access.redhat.com/solutions/2127401">How to make NIC ethtool settings persistent (apply automatically at boot)</a> (Red Hat Knowledgebase)
						</li><li class="listitem">
							<a class="link" href="https://www.kernel.org/doc/html/latest/networking/timestamping.html">Timestamping</a>
						</li></ul></div></section></section><section class="section" id="benefits-of-tcp-timestamps_tuning-the-network-performance"><div class="titlepage"><div><div><h3 class="title">31.13. Benefits of TCP Timestamps</h3></div></div></div><p>
				TCP Timestamps are optional information in the TCP header and an extension of the TCP protocol. By default, TCP Timestamps are enabled in Red Hat Enterprise Linux, and the kernel uses TCP Timestamps to better estimate the round trip time (RTT) in TCP connections. This results in more accurate TCP window and buffer calculations.
			</p><p>
				Additionally, TCP Timestamps provide an alternative method to determine the age and order of a segment, and protect against wrapped sequence numbers. TCP packet headers record the sequence number in a 32-bit field. On a 10 Gbps connection, the value of this field can wrap after 1.7 seconds. Without TCP Timestamps, the receiver could not determine whether a segment with a wrapped sequence number is a new segment or an old duplicate. With TCP Timestamps, however, the receiver can make the correct choice to receive or discard the segment. Therefore, enabling TCP Timestamps on systems with fast network interfaces is essential.
			</p><p>
				The <code class="literal">net.ipv4.tcp_timestamps</code> kernel parameter can have one of the following values:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						<code class="literal">0</code>: TCP Timestamps are disabled.
					</li><li class="listitem">
						<code class="literal">1</code>: TCP Timestamps are enabled (default).
					</li><li class="listitem"><p class="simpara">
						<code class="literal">2</code>: TCP Timestamps are enabled but without random offsets.
					</p><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
							Without random offsets for each connection, it is possible to approximately determine the host’s uptime and fingerprint and use this information in attacks.
						</p></div></rh-alert></li></ul></div><p>
				By default, TCP Timestamps are enabled in Red Hat Enterprise Linux and use random offsets for each connection instead of only storing the current time:
			</p><pre class="literallayout"># <span class="strong strong"><strong>sysctl net.ipv4.tcp_timestamps</strong></span>
net.ipv4.tcp_timestamps = 1</pre><p>
				If the <code class="literal">net.ipv4.tcp_timestamps</code> parameter has a different value than the default (<code class="literal">1</code>), revert the setting in the same way as you set it.
			</p><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="https://www.rfc-editor.org/rfc/rfc1323">RFC 1323: TCP Extensions for High Performance</a>
					</li></ul></div></section><section class="section" id="ref_flow-control-in-ethernet-networks_tuning-the-network-performance"><div class="titlepage"><div><div><h3 class="title">31.14. Flow control for Ethernet networks</h3></div></div></div><p>
				On an Ethernet link, continuous data transmission between a network interface and a switch port can lead to full buffer capacity. Full buffer capacity results in network congestion. In this case, when the sender transmits data at a higher rate than the processing capacity of the receiver, packet loss can occur due to the lower data processing capacity of a network interface on the other end of the link which is a switch port.
			</p><p>
				The flow control mechanism manages data transmission across the Ethernet link where each sender and receiver has different sending and receiving capacities. To avoid packet loss, the Ethernet flow control mechanism temporarily suspends the packet transmission to manage a higher transmission rate from a switch port. Note that routers do not forward pause frames beyond a switch port.
			</p><p>
				When receive (RX) buffers become full, a receiver sends pause frames to the transmitter. The transmitter then stops data transmission for a short sub-second time frame, while continuing to buffer incoming data during this pause period. This duration provides enough time for the receiver to empty its interface buffers and prevent buffer overflow.
			</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					Either end of the Ethernet link can send pause frames to another end. If the receive buffers of a network interface are full, the network interface will send pause frames to the switch port. Similarly, when the receive buffers of a switch port are full, the switch port sends pause frames to the network interface.
				</p></div></rh-alert><p>
				By default, most of the network drivers in Red Hat Enterprise Linux have pause frame support enabled. To display the current settings of a network interface, enter:
			</p><pre class="screen"># <span class="strong strong"><strong>ethtool --show-pause <span class="emphasis"><em>enp1s0</em></span></strong></span>
Pause parameters for enp1s0:
...
RX:     on
TX:     on
...</pre><p>
				Verify with your switch vendor to confirm if your switch supports pause frames.
			</p><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">ethtool(8)</code> man page on your system
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/solutions/68817">What is network link flow control and how does it work in Red Hat Enterprise Linux?</a> (Red Hat Knowledgebase)
					</li></ul></div></section></section><section class="chapter" id="factors-affecting-i-o-and-file-system-performance_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 32. Factors affecting I/O and file system performance</h2></div></div></div><p class="_abstract _abstract">
			The appropriate settings for storage and file system performance are highly dependent on the storage purpose.
		</p><p>
			I/O and file system performance can be affected by any of the following factors:
		</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
					Data write or read patterns
				</li><li class="listitem">
					Sequential or random
				</li><li class="listitem">
					Buffered or Direct IO
				</li><li class="listitem">
					Data alignment with underlying geometry
				</li><li class="listitem">
					Block size
				</li><li class="listitem">
					File system size
				</li><li class="listitem">
					Journal size and location
				</li><li class="listitem">
					Recording access times
				</li><li class="listitem">
					Ensuring data reliability
				</li><li class="listitem">
					Pre-fetching data
				</li><li class="listitem">
					Pre-allocating disk space
				</li><li class="listitem">
					File fragmentation
				</li><li class="listitem">
					Resource contention
				</li></ul></div><section class="section" id="tools-for-monitoring-and-diagnosing-i-o-and-file-system-issues_factors-affecting-i-o-and-file-system-performance"><div class="titlepage"><div><div><h3 class="title">32.1. Tools for monitoring and diagnosing I/O and file system issues</h3></div></div></div><p class="_abstract _abstract">
				The following tools are available in Red Hat Enterprise Linux 9 for monitoring system performance and diagnosing performance problems related to I/O, file systems, and their configuration:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						<code class="literal">vmstat</code> tool reports on processes, memory, paging, block I/O, interrupts, and CPU activity across the entire system. It can help administrators determine whether the I/O subsystem is responsible for any performance issues. If analysis with <code class="literal">vmstat</code> shows that the I/O subsystem is responsible for reduced performance, administrators can use the <code class="literal">iostat</code> tool to determine the responsible I/O device.
					</li><li class="listitem">
						<code class="literal">iostat</code> reports on I/O device load in your system. It is provided by the <code class="literal">sysstat</code> package.
					</li><li class="listitem">
						<code class="literal">blktrace</code> provides detailed information about how time is spent in the I/O subsystem. The companion utility <code class="literal">blkparse</code> reads the raw output from <code class="literal">blktrace</code> and produces a human readable summary of input and output operations recorded by <code class="literal">blktrace</code>.
					</li><li class="listitem"><p class="simpara">
						<code class="literal">btt</code> analyzes <code class="literal">blktrace</code> output and displays the amount of time that data spends in each area of the I/O stack, making it easier to spot bottlenecks in the I/O subsystem. This utility is provided as part of the <code class="literal">blktrace</code> package. Some of the important events tracked by the <code class="literal">blktrace</code> mechanism and analyzed by <code class="literal">btt</code> are:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
								Queuing of the I/O event (<code class="literal">Q</code>)
							</li><li class="listitem">
								Dispatch of the I/O to the driver event (<code class="literal">D</code>)
							</li><li class="listitem">
								Completion of I/O event (<code class="literal">C</code>)
							</li></ul></div></li><li class="listitem">
						<code class="literal">iowatcher</code> can use the <code class="literal">blktrace</code> output to graph I/O over time. It focuses on the Logical Block Address (LBA) of disk I/O, throughput in megabytes per second, the number of seeks per second, and I/O operations per second. This can help to identify when you are hitting the operations-per-second limit of a device.
					</li><li class="listitem"><p class="simpara">
						BPF Compiler Collection (BCC) is a library, which facilitates the creation of the extended Berkeley Packet Filter (<code class="literal">eBPF</code>) programs. The <code class="literal">eBPF</code> programs are triggered on events, such as disk I/O, TCP connections, and process creations. The BCC tools are installed in the <code class="literal">/usr/share/bcc/tools/</code> directory. The following <code class="literal">bcc-tools</code> helps to analyze performance:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
								<code class="literal">biolatency</code> summarizes the latency in block device I/O (disk I/O) in histogram. This allows the distribution to be studied, including two modes for device cache hits and for cache misses, and latency outliers.
							</li><li class="listitem">
								<code class="literal">biosnoop</code> is a basic block I/O tracing tool for displaying each I/O event along with the issuing process ID, and the I/O latency. Using this tool, you can investigate disk I/O performance issues.
							</li><li class="listitem">
								<code class="literal">biotop</code> is used for block i/o operations in the kernel.
							</li><li class="listitem">
								<code class="literal">filelife</code> tool traces the <code class="literal">stat()</code> syscalls.
							</li><li class="listitem">
								<code class="literal">fileslower</code> traces slow synchronous file reads and writes.
							</li><li class="listitem">
								<code class="literal">filetop</code> displays file reads and writes by process.
							</li><li class="listitem"><p class="simpara">
								<code class="literal">ext4slower</code>, <code class="literal">nfsslower</code>, and <code class="literal">xfsslower</code> are tools that show file system operations slower than a certain threshold, which defaults to <code class="literal">10ms</code>.
							</p><p class="simpara">
								For more information, see the <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_monitoring_and_updating_the_kernel/analyzing-system-performance-with-bpf-compiler_collection_managing-monitoring-and-updating-the-kernel">Analyzing system performance with BPF Compiler Collection</a>.
							</p></li></ul></div></li><li class="listitem">
						<code class="literal">bpftace</code> is a tracing language for <code class="literal">eBPF</code> used for analyzing performance issues. It also provides trace utilities like BCC for system observation, which is useful for investigating I/O performance issues.
					</li><li class="listitem"><p class="simpara">
						The following <code class="literal">SystemTap</code> scripts may be useful in diagnosing storage or file system performance problems:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
								<code class="literal">disktop.stp</code>: Checks the status of reading or writing disk every 5 seconds and outputs the top ten entries during that period.
							</li><li class="listitem">
								<code class="literal">iotime.stp</code>: Prints the amount of time spent on read and write operations, and the number of bytes read and written.
							</li><li class="listitem">
								<code class="literal">traceio.stp</code>: Prints the top ten executable based on cumulative I/O traffic observed, every second.
							</li><li class="listitem">
								<code class="literal">traceio2.stp</code>: Prints the executable name and process identifier as reads and writes to the specified device occur.
							</li><li class="listitem">
								<code class="literal">Inodewatch.stp</code>: Prints the executable name and process identifier each time a read or write occurs to the specified inode on the specified major or minor device.
							</li><li class="listitem">
								<code class="literal">inodewatch2.stp</code>: Prints the executable name, process identifier, and attributes each time the attributes are changed on the specified inode on the specified major or minor device.
							</li></ul></div></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">vmstat(8)</code>, <code class="literal">iostat(1)</code>, <code class="literal">blktrace(8)</code>, <code class="literal">blkparse(1)</code>, <code class="literal">btt(1)</code>, <code class="literal">bpftrace</code>, and <code class="literal">iowatcher(1)</code> man pages on your system
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index#configuring-an-operating-system-to-optimize-memory-access_monitoring-and-managing-system-status-and-performance">Analyzing system performance with BPF Compiler Collection</a>
					</li></ul></div></section><section class="section" id="available-tuning-options-for-formatting-a-file-system_factors-affecting-i-o-and-file-system-performance"><div class="titlepage"><div><div><h3 class="title">32.2. Available tuning options for formatting a file system</h3></div></div></div><p class="_abstract _abstract">
				Some file system configuration decisions cannot be changed after the device is formatted.
			</p><p>
				The following are the options available before formatting a storage device:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">Size</code></span></dt><dd>
							Create an appropriately-sized file system for your workload. Smaller file systems require less time and memory for file system checks. However, if a file system is too small, its performance suffers from high fragmentation.
						</dd><dt><span class="term"><code class="literal">Block size</code></span></dt><dd><p class="simpara">
							The block is the unit of work for the file system. The block size determines how much data can be stored in a single block, and therefore the smallest amount of data that is written or read at one time.
						</p><p class="simpara">
							The default block size is appropriate for most use cases. However, your file system performs better and stores data more efficiently if the block size or the size of multiple blocks is the same as or slightly larger than the amount of data that is typically read or written at one time. A small file still uses an entire block. Files can be spread across multiple blocks, but this can create additional runtime overhead.
						</p><p class="simpara">
							Additionally, some file systems are limited to a certain number of blocks, which in turn limits the maximum size of the file system. Block size is specified as part of the file system options when formatting a device with the <code class="literal">mkfs</code> command. The parameter that specifies the block size varies with the file system.
						</p></dd><dt><span class="term"><code class="literal">Geometry</code></span></dt><dd><p class="simpara">
							File system geometry is concerned with the distribution of data across a file system. If your system uses striped storage, like RAID, you can improve performance by aligning data and metadata with the underlying storage geometry when you format the device.
						</p><p class="simpara">
							Many devices export recommended geometry, which is then set automatically when the devices are formatted with a particular file system. If your device does not export these recommendations, or you want to change the recommended settings, you must specify geometry manually when you format the device with the <code class="literal">mkfs</code> command.
						</p><p class="simpara">
							The parameters that specify file system geometry vary with the file system.
						</p></dd><dt><span class="term"><code class="literal">External journals</code></span></dt><dd>
							Journaling file systems document the changes that will be made during a write operation in a journal file prior to the operation being executed. This reduces the likelihood that a storage device will become corrupted in the event of a system crash or power failure, and speeds up the recovery process.
						</dd></dl></div><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					Red Hat does not recommend using the external journals option.
				</p></div></rh-alert><p>
				Metadata-intensive workloads involve very frequent updates to the journal. A larger journal uses more memory, but reduces the frequency of write operations. Additionally, you can improve the seek time of a device with a metadata-intensive workload by placing its journal on dedicated storage that is as fast as, or faster than, the primary storage.
			</p><rh-alert class="admonition warning" state="danger"><div class="admonition_header" slot="header">Warning</div><div><p>
					Ensure that external journals are reliable. Losing an external journal device causes file system corruption. External journals must be created at format time, with journal devices being specified at mount time.
				</p></div></rh-alert><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">mkfs(8)</code> and <code class="literal">mount(8)</code> man pages on your system
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#overview-of-available-file-systems_managing-file-systems">Overview of available file systems</a>
					</li></ul></div></section><section class="section" id="available-tuning-options-for-mounting-a-file-system_factors-affecting-i-o-and-file-system-performance"><div class="titlepage"><div><div><h3 class="title">32.3. Available tuning options for mounting a file system</h3></div></div></div><p class="_abstract _abstract">
				The following are the options available to most file systems and can be specified as the device is mounted:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">Access Time</code></span></dt><dd><p class="simpara">
							Every time a file is read, its metadata is updated with the time at which access occurred (<code class="literal">atime</code>). This involves additional write I/O. The <code class="literal">relatime</code> is the default <code class="literal">atime</code> setting for most file systems.
						</p><p class="simpara">
							However, if updating this metadata is time consuming, and if accurate access time data is not required, you can mount the file system with the <code class="literal">noatime</code> mount option. This disables updates to metadata when a file is read. It also enables <code class="literal">nodiratime</code> behavior, which disables updates to metadata when a directory is read.
						</p></dd></dl></div><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					Disabling <code class="literal">atime</code> updates by using the <code class="literal">noatime mount</code> option can break applications that rely on them, for example, backup programs.
				</p></div></rh-alert><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">Read-ahead</code></span></dt><dd><p class="simpara">
							<code class="literal">Read-ahead</code> behavior speeds up file access by pre-fetching data that is likely to be needed soon and loading it into the page cache, where it can be retrieved more quickly than if it were on disk. The higher the read-ahead value, the further ahead the system pre-fetches data.
						</p><p class="simpara">
							Red Hat Enterprise Linux attempts to set an appropriate read-ahead value based on what it detects about your file system. However, accurate detection is not always possible. For example, if a storage array presents itself to the system as a single LUN, the system detects the single LUN, and does not set the appropriate read-ahead value for an array.
						</p><p class="simpara">
							Workloads that involve heavy streaming of sequential I/O often benefit from high read-ahead values. The storage-related tuned profiles provided with Red Hat Enterprise Linux raise the read-ahead value, as does using LVM striping, but these adjustments are not always sufficient for all workloads.
						</p></dd></dl></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">mount(8)</code>, <code class="literal">xfs(5)</code>, and <code class="literal">ext4(5)</code> man pages on your system
					</li></ul></div></section><section class="section" id="types-of-discarding-unused-blocks_factors-affecting-i-o-and-file-system-performance"><div class="titlepage"><div><div><h3 class="title">32.4. Types of discarding unused blocks</h3></div></div></div><p class="_abstract _abstract">
				Regularly discarding blocks that are not in use by the file system is a recommended practice for both solid-state disks and thinly-provisioned storage.
			</p><p>
				The following are the two methods of discarding unused blocks:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">Batch discard</code></span></dt><dd>
							This type of discard is part of the <code class="literal">fstrim</code> command. It discards all unused blocks in a file system that match criteria specified by the administrator. Red Hat Enterprise Linux 9 supports batch discard on XFS and ext4 formatted devices that support physical discard operations.
						</dd><dt><span class="term"><code class="literal">Online discard</code></span></dt><dd><p class="simpara">
							This type of discard operation is configured at mount time with the discard option, and runs in real time without user intervention. However, it only discards blocks that are transitioning from used to free. Red Hat Enterprise Linux 9 supports online discard on XFS and ext4 formatted devices.
						</p><p class="simpara">
							Red Hat recommends batch discard, except where online discard is required to maintain performance, or where batch discard is not feasible for the system’s workload.
						</p></dd></dl></div><p>
				Pre-allocation marks disk space as being allocated to a file without writing any data into that space. This can be useful in limiting data fragmentation and poor read performance. Red Hat Enterprise Linux 9 supports pre-allocating space on XFS, ext4, and GFS2 file systems. Applications can also benefit from pre-allocating space by using the <code class="literal">fallocate(2) glibc</code> call.
			</p><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">mount(8)</code> and <code class="literal">fallocate(2)</code> man pages on your system
					</li></ul></div></section><section class="section" id="solid-state-disks-tuning-considerations_factors-affecting-i-o-and-file-system-performance"><div class="titlepage"><div><div><h3 class="title">32.5. Solid-state disks tuning considerations</h3></div></div></div><p class="_abstract _abstract">
				Solid-state disks (SSD) use NAND flash chips rather than rotating magnetic platters to store persistent data. SSD provides a constant access time for data across their full Logical Block Address range, and does not incur measurable seek costs like their rotating counterparts. They are more expensive per gigabyte of storage space and have a lesser storage density, but they also have lower latency and greater throughput than HDDs.
			</p><p>
				Performance generally degrades as the used blocks on an SSD approach the capacity of the disk. The degree of degradation varies by vendor, but all devices experience degradation in this circumstance. Enabling discard behavior can help to alleviate this degradation. For more information, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance#types-of-discarding-unused-blocks_factors-affecting-i-o-and-file-system-performance">Types of discarding unused blocks</a>.
			</p><p>
				The default I/O scheduler and virtual memory options are suitable for use with SSDs. Consider the following factors when configuring settings that can affect SSD performance:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">I/O Scheduler</code></span></dt><dd><p class="simpara">
							Any I/O scheduler is expected to perform well with most SSDs. However, as with any other storage type, Red Hat recommends benchmarking to determine the optimal configuration for a given workload. When using SSDs, Red Hat advises changing the I/O scheduler only for benchmarking particular workloads. For instructions on how to switch between I/O schedulers, see the <code class="literal">/usr/share/doc/kernel-version/Documentation/block/switching-sched.txt</code> file.
						</p><p class="simpara">
							For single queue HBA, the default I/O scheduler is <code class="literal">deadline</code>. For multiple queue HBA, the default I/O scheduler is <code class="literal">none</code>. For information about how to set the I/O scheduler, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-the-disk-scheduler_monitoring-and-managing-system-status-and-performance">Setting the disk scheduler</a>.
						</p></dd><dt><span class="term"><code class="literal">Virtual Memory</code></span></dt><dd>
							Like the I/O scheduler, virtual memory (VM) subsystem requires no special tuning. Given the fast nature of I/O on SSD, try turning down the <code class="literal">vm_dirty_background_ratio</code> and <code class="literal">vm_dirty_ratio</code> settings, as increased write-out activity does not usually have a negative impact on the latency of other operations on the disk. However, this tuning can generate more overall I/O, and is therefore not generally recommended without workload-specific testing.
						</dd><dt><span class="term"><code class="literal">Swap</code></span></dt><dd>
							An SSD can also be used as a swap device, and is likely to produce good page-out and page-in performance.
						</dd></dl></div></section><section class="section" id="generic-block-device-tuning-parameters_factors-affecting-i-o-and-file-system-performance"><div class="titlepage"><div><div><h3 class="title">32.6. Generic block device tuning parameters</h3></div></div></div><p class="_abstract _abstract">
				The generic tuning parameters listed here are available in the <code class="literal">/sys/block/sdX/queue/</code> directory.
			</p><p>
				The following listed tuning parameters are separate from I/O scheduler tuning, and are applicable to all I/O schedulers:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">add_random</code></span></dt><dd>
							Some I/O events contribute to the entropy pool for the <code class="literal">/dev/random</code>. This parameter can be set to <code class="literal">0</code> if the overhead of these contributions become measurable.
						</dd><dt><span class="term"><code class="literal">iostats</code></span></dt><dd><p class="simpara">
							By default, <code class="literal">iostats</code> is enabled and the default value is <code class="literal">1</code>. Setting <code class="literal">iostats</code> value to <code class="literal">0</code> disables the gathering of I/O statistics for the device, which removes a small amount of overhead with the I/O path. Setting <code class="literal">iostats</code> to <code class="literal">0</code> might slightly improve performance for very high performance devices, such as certain NVMe solid-state storage devices. It is recommended to leave <code class="literal">iostats</code> enabled unless otherwise specified for the given storage model by the vendor.
						</p><p class="simpara">
							If you disable <code class="literal">iostats</code>, the I/O statistics for the device are no longer present within the <code class="literal">/proc/diskstats</code> file. The content of <code class="literal">/sys/diskstats</code> file is the source of I/O information for monitoring I/O tools, such as <code class="literal">sar</code> or <code class="literal">iostats</code>. Therefore, if you disable the <code class="literal">iostats</code> parameter for a device, the device is no longer present in the output of I/O monitoring tools.
						</p></dd><dt><span class="term"><code class="literal">max_sectors_kb</code></span></dt><dd><p class="simpara">
							Specifies the maximum size of an I/O request in kilobytes. The default value is <code class="literal">512</code> KB. The minimum value for this parameter is determined by the logical block size of the storage device. The maximum value for this parameter is determined by the value of the <code class="literal">max_hw_sectors_kb</code>.
						</p><p class="simpara">
							Red Hat recommends <code class="literal">max_sectors_kb</code> to always be a multiple of the optimal I/O size and the internal erase block size. Use a value of <code class="literal">logical_block_size</code> for either parameter if they are zero or not specified by the storage device.
						</p></dd><dt><span class="term"><code class="literal">nomerges</code></span></dt><dd>
							Most workloads benefit from request merging. However, disabling merges can be useful for debugging purposes. By default, the <code class="literal">nomerges</code> parameter is set to <code class="literal">0</code>, which enables merging. To disable simple one-hit merging, set <code class="literal">nomerges</code> to <code class="literal">1</code>. To disable all types of merging, set <code class="literal">nomerges</code> to <code class="literal">2</code>.
						</dd><dt><span class="term"><code class="literal">nr_requests</code></span></dt><dd>
							It is the maximum allowed number of the queued I/O. If the current I/O scheduler is <code class="literal">none</code>, this number can only be reduced; otherwise the number can be increased or reduced.
						</dd><dt><span class="term"><code class="literal">optimal_io_size</code></span></dt><dd>
							Some storage devices report an optimal I/O size through this parameter. If this value is reported, Red Hat recommends that applications issue I/O aligned to and in multiples of the optimal I/O size wherever possible.
						</dd><dt><span class="term"><code class="literal">read_ahead_kb</code></span></dt><dd><p class="simpara">
							Defines the maximum number of kilobytes that the operating system may read ahead during a sequential read operation. As a result, the necessary information is already present within the kernel page cache for the next sequential read, which improves read I/O performance.
						</p><p class="simpara">
							Device mappers often benefit from a high <code class="literal">read_ahead_kb</code> value. <code class="literal">128</code> KB for each device to be mapped is a good starting point, but increasing the <code class="literal">read_ahead_kb</code> value up to request queue’s <code class="literal">max_sectors_kb</code> of the disk might improve performance in application environments where sequential reading of large files takes place.
						</p></dd><dt><span class="term"><code class="literal">rotational</code></span></dt><dd>
							Some solid-state disks do not correctly advertise their solid-state status, and are mounted as traditional rotational disks. Manually set the <code class="literal">rotational</code> value to <code class="literal">0</code> to disable unnecessary seek-reducing logic in the scheduler.
						</dd><dt><span class="term"><code class="literal">rq_affinity</code></span></dt><dd>
							The default value of the <code class="literal">rq_affinity</code> is <code class="literal">1</code>. It completes the I/O operations on one CPU core, which is in the same CPU group of the issued CPU core. To perform completions only on the processor that issued the I/O request, set the <code class="literal">rq_affinity</code> to <code class="literal">2</code>. To disable the mentioned two abilities, set it to <code class="literal">0</code>.
						</dd><dt><span class="term"><code class="literal">scheduler</code></span></dt><dd>
							To set the scheduler or scheduler preference order for a particular storage device, edit the <code class="literal">/sys/block/<span class="emphasis"><em>devname</em></span>/queue/scheduler</code> file, where <span class="emphasis"><em>devname</em></span> is the name of the device you want to configure.
						</dd></dl></div></section></section><section class="chapter" id="assembly_using-systemd-to-manage-resources-used-by-applications_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 33. Using systemd to manage resources used by applications</h2></div></div></div><p>
			RHEL 9 moves the resource management settings from the process level to the application level by binding the system of <code class="literal">cgroup</code> hierarchies with the <code class="literal">systemd</code> unit tree. Therefore, you can manage the system resources with the <code class="literal">systemctl</code> command, or by modifying the <code class="literal">systemd</code> unit files.
		</p><p>
			To achieve this, <code class="literal">systemd</code> takes various configuration options from the unit files or directly via the <code class="literal">systemctl</code> command. Then <code class="literal">systemd</code> applies those options to specific process groups by using the Linux kernel system calls and features like <code class="literal">cgroups</code> and <code class="literal">namespaces</code>.
		</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
				You can review the full set of configuration options for <code class="literal">systemd</code> in the following manual pages:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						<code class="literal">systemd.resource-control(5)</code>
					</li><li class="listitem">
						<code class="literal">systemd.exec(5)</code>
					</li></ul></div></div></rh-alert><section class="section" id="con_role-of-systemd-in-resource-management_assembly_using-systemd-to-manage-resources-used-by-applications"><div class="titlepage"><div><div><h3 class="title">33.1. Role of systemd in resource management</h3></div></div></div><p>
				The core function of <code class="literal">systemd</code> is service management and supervision. The <code class="literal">systemd</code> system and service manager :
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						ensures that managed services start at the right time and in the correct order during the boot process.
					</li><li class="listitem">
						ensures that managed services run smoothly to use the underlying hardware platform optimally.
					</li><li class="listitem">
						provides capabilities to define resource management policies.
					</li><li class="listitem">
						provides capabilities to tune various options, which can improve the performance of the service.
					</li></ul></div><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
					In general, Red Hat recommends you use <code class="literal">systemd</code> for controlling the usage of system resources. You should manually configure the <code class="literal">cgroups</code> virtual file system only in special cases. For example, when you need to use <code class="literal">cgroup-v1</code> controllers that have no equivalents in <code class="literal">cgroup-v2</code> hierarchy.
				</p></div></rh-alert></section><section class="section" id="distribution-models-of-system-sources_assembly_using-systemd-to-manage-resources-used-by-applications"><div class="titlepage"><div><div><h3 class="title">33.2. Distribution models of system sources</h3></div></div></div><p>
				To modify the distribution of system resources, you can apply one or more of the following distribution models:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">Weights</span></dt><dd><p class="simpara">
							You can distribute the resource by adding up the weights of all sub-groups and giving each sub-group the fraction matching its ratio against the sum.
						</p><p class="simpara">
							For example, if you have 10 cgroups, each with weight of value 100, the sum is 1000. Each cgroup receives one tenth of the resource.
						</p><p class="simpara">
							Weight is usually used to distribute stateless resources. For example the <span class="emphasis"><em>CPUWeight=</em></span> option is an implementation of this resource distribution model.
						</p></dd><dt><span class="term">Limits</span></dt><dd><p class="simpara">
							A cgroup can consume up to the configured amount of the resource. The sum of sub-group limits can exceed the limit of the parent cgroup. Therefore it is possible to overcommit resources in this model.
						</p><p class="simpara">
							For example the <span class="emphasis"><em>MemoryMax=</em></span> option is an implementation of this resource distribution model.
						</p></dd><dt><span class="term">Protections</span></dt><dd><p class="simpara">
							You can set up a protected amount of a resource for a cgroup. If the resource usage is below the protection boundary, the kernel will try not to penalize this cgroup in favor of other cgroups that compete for the same resource. An overcommit is also possible.
						</p><p class="simpara">
							For example the <span class="emphasis"><em>MemoryLow=</em></span> option is an implementation of this resource distribution model.
						</p></dd><dt><span class="term">Allocations</span></dt><dd>
							Exclusive allocations of an absolute amount of a finite resource. An overcommit is not possible. An example of this resource type in Linux is the real-time budget.
						</dd><dt><span class="term">unit file option</span></dt><dd><p class="simpara">
							A setting for resource control configuration.
						</p><p class="simpara">
							For example, you can configure CPU resource with options like <span class="emphasis"><em>CPUAccounting=</em></span>, or <span class="emphasis"><em>CPUQuota=</em></span>. Similarly, you can configure memory or I/O resources with options like <span class="emphasis"><em>AllowedMemoryNodes=</em></span> and <span class="emphasis"><em>IOAccounting=</em></span>.
						</p></dd></dl></div></section><section class="section" id="proc_allocating-system-resources-using-systemd_assembly_using-systemd-to-manage-resources-used-by-applications"><div class="titlepage"><div><div><h3 class="title">33.3. Allocating system resources using systemd</h3></div></div></div><p>
				Allocating system resources by using systemd involves creating &amp; managing systemd services and units. This can be configured to start, stop, or restart at specific times or in response to certain system events.
			</p><div class="formalpara"><p class="title"><strong>Procedure</strong></p><p>
					To change the required value of the unit file option of your service, you can adjust the value in the unit file, or use the <code class="literal">systemctl</code> command:
				</p></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Check the assigned values for the service of your choice.
					</p><pre class="literallayout"># <span class="strong strong"><strong>systemctl show --property &lt;<span class="emphasis"><em>unit file option</em></span>&gt; &lt;<span class="emphasis"><em>service name</em></span>&gt;</strong></span></pre></li><li class="listitem"><p class="simpara">
						Set the required value of the CPU time allocation policy option:
					</p><pre class="literallayout"># <span class="strong strong"><strong>systemctl set-property &lt;<span class="emphasis"><em>service name</em></span>&gt; &lt;<span class="emphasis"><em>unit file option</em></span>&gt;=&lt;<span class="emphasis"><em>value</em></span>&gt;</strong></span></pre></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Check the newly assigned values for the service of your choice.
					</p><pre class="literallayout"># <span class="strong strong"><strong>systemctl show --property &lt;<span class="emphasis"><em>unit file option</em></span>&gt; &lt;<span class="emphasis"><em>service name</em></span>&gt;</strong></span></pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">systemd.resource-control(5)</code> and <code class="literal">systemd.exec(5)</code> man pages on your system
					</li></ul></div></section><section class="section" id="con_overview-of-systemd-hierarchy-for-cgroups_assembly_using-systemd-to-manage-resources-used-by-applications"><div class="titlepage"><div><div><h3 class="title">33.4. Overview of systemd hierarchy for cgroups</h3></div></div></div><p>
				On the backend, the <code class="literal">systemd</code> system and service manager uses the <code class="literal">slice</code>, the <code class="literal">scope</code>, and the <code class="literal">service</code> units to organize and structure processes in the control groups. You can further modify this hierarchy by creating custom unit files or using the <code class="literal">systemctl</code> command. Also, <code class="literal">systemd</code> automatically mounts hierarchies for important kernel resource controllers at the <code class="literal">/sys/fs/cgroup/</code> directory.
			</p><p>
				For resource control, you can use the following three <code class="literal">systemd</code> unit types:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">Service</span></dt><dd><p class="simpara">
							A process or a group of processes, which <code class="literal">systemd</code> started according to a unit configuration file.
						</p><p class="simpara">
							Services encapsulate the specified processes so that they can be started and stopped as one set. Services are named in the following way:
						</p><pre class="literallayout"><span class="emphasis"><em>&lt;name&gt;</em></span>.service</pre></dd><dt><span class="term">Scope</span></dt><dd><p class="simpara">
							A group of externally created processes. Scopes encapsulate processes that are started and stopped by the arbitrary processes through the <code class="literal">fork()</code> function and then registered by <code class="literal">systemd</code> at runtime. For example, user sessions, containers, and virtual machines are treated as scopes. Scopes are named as follows:
						</p><pre class="literallayout"><span class="emphasis"><em>&lt;name&gt;</em></span>.scope</pre></dd><dt><span class="term">Slice</span></dt><dd><p class="simpara">
							A group of hierarchically organized units. Slices organize a hierarchy in which scopes and services are placed.
						</p><p class="simpara">
							The actual processes are contained in scopes or in services. Every name of a slice unit corresponds to the path to a location in the hierarchy.
						</p><p class="simpara">
							The dash (<code class="literal">-</code>) character acts as a separator of the path components to a slice from the <code class="literal">-.slice</code> root slice. In the following example:
						</p><pre class="literallayout"><span class="emphasis"><em>&lt;parent-name&gt;</em></span>.slice</pre><p class="simpara">
							<code class="literal">parent-name.slice</code> is a sub-slice of <code class="literal">parent.slice</code>, which is a sub-slice of the <code class="literal">-.slice</code> root slice. <code class="literal">parent-name.slice</code> can have its own sub-slice named <code class="literal">parent-name-name2.slice</code>, and so on.
						</p></dd></dl></div><p>
				The <code class="literal">service</code>, the <code class="literal">scope</code>, and the <code class="literal">slice</code> units directly map to objects in the control group hierarchy. When these units are activated, they map directly to control group paths built from the unit names.
			</p><p>
				The following is an abbreviated example of a control group hierarchy:
			</p><pre class="literallayout">Control group /:
-.slice
├─user.slice
│ ├─user-42.slice
│ │ ├─session-c1.scope
│ │ │ ├─ 967 gdm-session-worker [pam/gdm-launch-environment]
│ │ │ ├─1035 /usr/libexec/gdm-x-session gnome-session --autostart /usr/share/gdm/greeter/autostart
│ │ │ ├─1054 /usr/libexec/Xorg vt1 -displayfd 3 -auth /run/user/42/gdm/Xauthority -background none -noreset -keeptty -verbose 3
│ │ │ ├─1212 /usr/libexec/gnome-session-binary --autostart /usr/share/gdm/greeter/autostart
│ │ │ ├─1369 /usr/bin/gnome-shell
│ │ │ ├─1732 ibus-daemon --xim --panel disable
│ │ │ ├─1752 /usr/libexec/ibus-dconf
│ │ │ ├─1762 /usr/libexec/ibus-x11 --kill-daemon
│ │ │ ├─1912 /usr/libexec/gsd-xsettings
│ │ │ ├─1917 /usr/libexec/gsd-a11y-settings
│ │ │ ├─1920 /usr/libexec/gsd-clipboard
…​
├─init.scope
│ └─1 /usr/lib/systemd/systemd --switched-root --system --deserialize 18
└─system.slice
  ├─rngd.service
  │ └─800 /sbin/rngd -f
  ├─systemd-udevd.service
  │ └─659 /usr/lib/systemd/systemd-udevd
  ├─chronyd.service
  │ └─823 /usr/sbin/chronyd
  ├─auditd.service
  │ ├─761 /sbin/auditd
  │ └─763 /usr/sbin/sedispatch
  ├─accounts-daemon.service
  │ └─876 /usr/libexec/accounts-daemon
  ├─example.service
  │ ├─ 929 /bin/bash /home/jdoe/example.sh
  │ └─4902 sleep 1
  …​</pre><p>
				The example above shows that services and scopes contain processes and are placed in slices that do not contain processes of their own.
			</p><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<span class="emphasis"><em><span class="citetitle citetitle"><a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_basic_system_settings/managing-systemd_configuring-basic-system-settings#managing-system-services-with-systemctl_managing-systemd">Managing system services with systemctl</a></span></em></span> in Red Hat Enterprise Linux
					</li><li class="listitem">
						<a class="link" href="#what-kernel-resource-controllers-are_setting-limits-for-applications" title="34.2. Introducing kernel resource controllers">What are kernel resource controllers</a>
					</li><li class="listitem">
						The <code class="literal">systemd.resource-control(5)</code>, <code class="literal">systemd.exec(5)</code>, <code class="literal">cgroups(7)</code>, <code class="literal">fork()</code>, <code class="literal">fork(2)</code> manual pages
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_monitoring_and_updating_the_kernel/index#setting-limits-for-applications_managing-monitoring-and-updating-the-kernel">Understanding cgroups</a>
					</li></ul></div></section><section class="section" id="listing-systemd_units_assembly_using-systemd-to-manage-resources-used-by-applications"><div class="titlepage"><div><div><h3 class="title">33.5. Listing systemd units</h3></div></div></div><p class="_abstract _abstract">
				Use the <code class="literal">systemd</code> system and service manager to list its units.
			</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						List all active units on the system with the <code class="literal">systemctl</code> utility. The terminal returns an output similar to the following example:
					</p><pre class="literallayout"># <span class="strong strong"><strong>systemctl</strong></span>
UNIT                                                LOAD   ACTIVE SUB       DESCRIPTION
…​
init.scope                                          loaded active running   System and Service Manager
session-2.scope                                     loaded active running   Session 2 of user jdoe
abrt-ccpp.service                                   loaded active exited    Install ABRT coredump hook
abrt-oops.service                                   loaded active running   ABRT kernel log watcher
abrt-vmcore.service                                 loaded active exited    Harvest vmcores for ABRT
abrt-xorg.service                                   loaded active running   ABRT Xorg log watcher
…​
-.slice                                             loaded active active    Root Slice
machine.slice                                       loaded active active    Virtual Machine and Container Slice system-getty.slice                                                                       loaded active active    system-getty.slice
system-lvm2\x2dpvscan.slice                         loaded active active    system-lvm2\x2dpvscan.slice
system-sshd\x2dkeygen.slice                         loaded active active    system-sshd\x2dkeygen.slice
system-systemd\x2dhibernate\x2dresume.slice         loaded active active    system-systemd\x2dhibernate\x2dresume&gt;
system-user\x2druntime\x2ddir.slice                 loaded active active    system-user\x2druntime\x2ddir.slice
system.slice                                        loaded active active    System Slice
user-1000.slice                                     loaded active active    User Slice of UID 1000
user-42.slice                                       loaded active active    User Slice of UID 42
user.slice                                          loaded active active    User and Session Slice
…​</pre><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">UNIT</code></span></dt><dd>
									A name of a unit that also reflects the unit position in a control group hierarchy. The units relevant for resource control are a <span class="emphasis"><em>slice</em></span>, a <span class="emphasis"><em>scope</em></span>, and a <span class="emphasis"><em>service</em></span>.
								</dd><dt><span class="term"><code class="literal">LOAD</code></span></dt><dd>
									Indicates whether the unit configuration file was properly loaded. If the unit file failed to load, the field contains the state <span class="emphasis"><em>error</em></span> instead of <span class="emphasis"><em>loaded</em></span>. Other unit load states are: <span class="emphasis"><em>stub</em></span>, <span class="emphasis"><em>merged</em></span>, and <span class="emphasis"><em>masked</em></span>.
								</dd><dt><span class="term"><code class="literal">ACTIVE</code></span></dt><dd>
									The high-level unit activation state, which is a generalization of <code class="literal">SUB</code>.
								</dd><dt><span class="term"><code class="literal">SUB</code></span></dt><dd>
									The low-level unit activation state. The range of possible values depends on the unit type.
								</dd><dt><span class="term"><code class="literal">DESCRIPTION</code></span></dt><dd>
									The description of the unit content and functionality.
								</dd></dl></div></li><li class="listitem"><p class="simpara">
						List all active and inactive units:
					</p><pre class="literallayout"># <span class="strong strong"><strong>systemctl --all</strong></span></pre></li><li class="listitem"><p class="simpara">
						Limit the amount of information in the output:
					</p><pre class="literallayout"># <span class="strong strong"><strong>systemctl --type service,masked</strong></span></pre><p class="simpara">
						The <code class="literal">--type</code> option requires a comma-separated list of unit types such as a <span class="emphasis"><em>service</em></span> and a <span class="emphasis"><em>slice</em></span>, or unit load states such as <span class="emphasis"><em>loaded</em></span> and <span class="emphasis"><em>masked</em></span>.
					</p></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<span class="emphasis"><em><span class="citetitle citetitle"><a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/configuring_basic_system_settings/managing-systemd_configuring-basic-system-settings#managing-system-services-with-systemctl_managing-systemd">Managing system services with systemctl</a></span></em></span> in RHEL
					</li><li class="listitem">
						The <code class="literal">systemd.resource-control(5)</code>, <code class="literal">systemd.exec(5)</code> manual pages
					</li></ul></div></section><section class="section" id="viewing-systemd-control-group-hierarchy_assembly_using-systemd-to-manage-resources-used-by-applications"><div class="titlepage"><div><div><h3 class="title">33.6. Viewing systemd cgroups hierarchy</h3></div></div></div><p class="_abstract _abstract">
				Display control groups (<code class="literal">cgroups</code>) hierarchy and processes running in specific <code class="literal">cgroups</code>.
			</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Display the whole <code class="literal">cgroups</code> hierarchy on your system with the <code class="literal">systemd-cgls</code> command.
					</p><pre class="literallayout"># <span class="strong strong"><strong>systemd-cgls</strong></span>
Control group /:
-.slice
├─user.slice
│ ├─user-42.slice
│ │ ├─session-c1.scope
│ │ │ ├─ 965 gdm-session-worker [pam/gdm-launch-environment]
│ │ │ ├─1040 /usr/libexec/gdm-x-session gnome-session --autostart /usr/share/gdm/greeter/autostart
…​
├─init.scope
│ └─1 /usr/lib/systemd/systemd --switched-root --system --deserialize 18
└─system.slice
  …​
  ├─example.service
  │ ├─6882 /bin/bash /home/jdoe/example.sh
  │ └─6902 sleep 1
  ├─systemd-journald.service
    └─629 /usr/lib/systemd/systemd-journald
  …​</pre><p class="simpara">
						The example output returns the entire <code class="literal">cgroups</code> hierarchy, where the highest level is formed by <span class="emphasis"><em>slices</em></span>.
					</p></li><li class="listitem"><p class="simpara">
						Display the <code class="literal">cgroups</code> hierarchy filtered by a resource controller with the <code class="literal">systemd-cgls &lt;<span class="emphasis"><em>resource_controller</em></span>&gt;</code> command.
					</p><pre class="literallayout"># <span class="strong strong"><strong>systemd-cgls memory</strong></span>
Controller memory; Control group /:
├─1 /usr/lib/systemd/systemd --switched-root --system --deserialize 18
├─user.slice
│ ├─user-42.slice
│ │ ├─session-c1.scope
│ │ │ ├─ 965 gdm-session-worker [pam/gdm-launch-environment]
…​
└─system.slice
  |
  …​
  ├─chronyd.service
  │ └─844 /usr/sbin/chronyd
  ├─example.service
  │ ├─8914 /bin/bash /home/jdoe/example.sh
  │ └─8916 sleep 1
  …​</pre><p class="simpara">
						The example output lists the services that interact with the selected controller.
					</p></li><li class="listitem"><p class="simpara">
						Display detailed information about a certain unit and its part of the <code class="literal">cgroups</code> hierarchy with the <code class="literal">systemctl status &lt;<span class="emphasis"><em>system_unit</em></span>&gt;</code> command.
					</p><pre class="literallayout white-space-pre"># <span class="strong strong"><strong>systemctl status example.service</strong></span>
● example.service - My example service
   Loaded: loaded (/usr/lib/systemd/system/example.service; enabled; vendor preset: disabled)
   Active: active (running) since Tue 2019-04-16 12:12:39 CEST; 3s ago
 Main PID: 17737 (bash)
    Tasks: 2 (limit: 11522)
   Memory: 496.0K (limit: 1.5M)
   CGroup: /system.slice/example.service
           ├─17737 /bin/bash /home/jdoe/example.sh
           └─17743 sleep 1
Apr 16 12:12:39 redhat systemd[1]: Started My example service.
Apr 16 12:12:39 redhat bash[17737]: The current time is Tue Apr 16 12:12:39 CEST 2019
Apr 16 12:12:40 redhat bash[17737]: The current time is Tue Apr 16 12:12:40 CEST 2019</pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">systemd.resource-control(5)</code> and <code class="literal">cgroups(7)</code> man pages on your system
					</li></ul></div></section><section class="section" id="proc_viewing-cgroups-of-processes_assembly_using-systemd-to-manage-resources-used-by-applications"><div class="titlepage"><div><div><h3 class="title">33.7. Viewing cgroups of processes</h3></div></div></div><p>
				You can learn which <span class="emphasis"><em>control group</em></span> (<code class="literal">cgroup</code>) a process belongs to. Then you can check the <code class="literal">cgroup</code> to find which controllers and controller-specific configurations it uses.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						To view which <code class="literal">cgroup</code> a process belongs to, run the <code class="literal"># cat proc/&lt;<span class="emphasis"><em>PID</em></span>&gt;/cgroup</code> command:
					</p><pre class="literallayout"># <span class="strong strong"><strong>cat /proc/2467/cgroup</strong></span>
0::/system.slice/example.service</pre><p class="simpara">
						The example output relates to a process of interest. In this case, it is a process identified by <code class="literal">PID 2467</code>, which belongs to the <code class="literal">example.service</code> unit. You can determine whether the process was placed in a correct control group as defined by the <code class="literal">systemd</code> unit file specifications.
					</p></li><li class="listitem"><p class="simpara">
						To display what controllers and respective configuration files the <code class="literal">cgroup</code> uses, check the <code class="literal">cgroup</code> directory:
					</p><pre class="literallayout"># <span class="strong strong"><strong>cat /sys/fs/cgroup/system.slice/example.service/cgroup.controllers</strong></span>
memory pids

# <span class="strong strong"><strong>ls /sys/fs/cgroup/system.slice/example.service/</strong></span>
cgroup.controllers
cgroup.events
…​
cpu.pressure
cpu.stat
io.pressure
memory.current
memory.events
…​
pids.current
pids.events
pids.max</pre></li></ol></div><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					The version 1 hierarchy of <code class="literal">cgroups</code> uses a per-controller model. Therefore the output from the <code class="literal">/proc/<span class="emphasis"><em>PID</em></span>/cgroup</code> file shows, which <code class="literal">cgroups</code> under each controller the PID belongs to. You can find the respective <code class="literal">cgroups</code> under the controller directories at <code class="literal">/sys/fs/cgroup/<span class="emphasis"><em>&lt;controller_name&gt;</em></span>/</code>.
				</p></div></rh-alert><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						The <code class="literal">cgroups(7)</code> manual page
					</li><li class="listitem">
						<a class="link" href="#what-kernel-resource-controllers-are_setting-limits-for-applications" title="34.2. Introducing kernel resource controllers">What are kernel resource controllers</a>
					</li><li class="listitem">
						Documentation in the <code class="literal">/usr/share/doc/kernel-doc-&lt;kernel_version&gt;/Documentation/admin-guide/cgroup-v2.rst</code> file (after installing the <code class="literal">kernel-doc</code> package)
					</li></ul></div></section><section class="section" id="monitoring-resource-consumption_assembly_using-systemd-to-manage-resources-used-by-applications"><div class="titlepage"><div><div><h3 class="title">33.8. Monitoring resource consumption</h3></div></div></div><p class="_abstract _abstract">
				View a list of currently running control groups (<code class="literal">cgroups</code>) and their resource consumption in real-time.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Display a dynamic account of currently running <code class="literal">cgroups</code> with the <code class="literal">systemd-cgtop</code> command.
					</p><pre class="literallayout white-space-pre"># <span class="strong strong"><strong>systemd-cgtop</strong></span>
Control Group                            Tasks   %CPU   Memory  Input/s Output/s
/                                          607   29.8     1.5G        -        -
/system.slice                              125      -   428.7M        -        -
/system.slice/ModemManager.service           3      -     8.6M        -        -
/system.slice/NetworkManager.service         3      -    12.8M        -        -
/system.slice/accounts-daemon.service        3      -     1.8M        -        -
/system.slice/boot.mount                     -      -    48.0K        -        -
/system.slice/chronyd.service                1      -     2.0M        -        -
/system.slice/cockpit.socket                 -      -     1.3M        -        -
/system.slice/colord.service                 3      -     3.5M        -        -
/system.slice/crond.service                  1      -     1.8M        -        -
/system.slice/cups.service                   1      -     3.1M        -        -
/system.slice/dev-hugepages.mount            -      -   244.0K        -        -
/system.slice/dev-mapper-rhel\x2dswap.swap   -      -   912.0K        -        -
/system.slice/dev-mqueue.mount               -      -    48.0K        -        -
/system.slice/example.service                2      -     2.0M        -        -
/system.slice/firewalld.service              2      -    28.8M        -        -
...</pre><p class="simpara">
						The example output displays currently running <code class="literal">cgroups</code> ordered by their resource usage (CPU, memory, disk I/O load). The list refreshes every 1 second by default. Therefore, it offers a dynamic insight into the actual resource usage of each control group.
					</p></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						The <code class="literal">systemd-cgtop(1)</code> manual page
					</li></ul></div></section><section class="section" id="proc_using-systemd-unit-files-to-set-limits-for-applications_assembly_using-systemd-to-manage-resources-used-by-applications"><div class="titlepage"><div><div><h3 class="title">33.9. Using systemd unit files to set limits for applications</h3></div></div></div><p>
				The <code class="literal">systemd</code> service manager supervises each existing or running unit and creates control groups for them. The units have configuration files in the <code class="literal">/usr/lib/systemd/system/</code> directory.
			</p><p>
				You can manually modify the unit files to:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						set limits.
					</li><li class="listitem">
						prioritize.
					</li><li class="listitem">
						control access to hardware resources for groups of processes.
					</li></ul></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have the <code class="literal">root</code> privileges.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Edit the <code class="literal">/usr/lib/systemd/system/example.service</code> file to limit the memory usage of a service:
					</p><pre class="literallayout">…​
[Service]
MemoryMax=1500K
…​</pre><p class="simpara">
						The configuration limits the maximum memory that the processes in a control group cannot exceed. The <code class="literal">example.service</code> service is part of such a control group which has imposed limitations. You can use suffixes K, M, G, or T to identify Kilobyte, Megabyte, Gigabyte, or Terabyte as a unit of measurement.
					</p></li><li class="listitem"><p class="simpara">
						Reload all unit configuration files:
					</p><pre class="literallayout"># <span class="strong strong"><strong>systemctl daemon-reload</strong></span></pre></li><li class="listitem"><p class="simpara">
						Restart the service:
					</p><pre class="literallayout"># <span class="strong strong"><strong>systemctl restart <span class="emphasis"><em>example.service</em></span></strong></span></pre></li></ol></div><div class="orderedlist"><p class="title"><strong>Verification</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Check that the changes took effect:
					</p><pre class="literallayout"># <span class="strong strong"><strong>cat /sys/fs/cgroup/system.slice/example.service/memory.max</strong></span>
1536000</pre><p class="simpara">
						The example output shows that the memory consumption was limited at around 1,500 KB.
					</p></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_monitoring_and_updating_the_kernel/index#setting-limits-for-applications_managing-monitoring-and-updating-the-kernel">Understanding cgroups</a>
					</li><li class="listitem">
						<span class="emphasis"><em><span class="citetitle citetitle"><a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_basic_system_settings/managing-systemd_configuring-basic-system-settings#managing-system-services-with-systemctl_managing-systemd">Managing system services with systemctl</a></span></em></span> in Red Hat Enterprise Linux
					</li><li class="listitem">
						<code class="literal">systemd.resource-control(5)</code>, <code class="literal">systemd.exec(5)</code>, and <code class="literal">cgroups(7)</code> man pages on your system
					</li></ul></div></section><section class="section" id="proc_using-systemctl-command-to-set-limits-to-applications_assembly_using-systemd-to-manage-resources-used-by-applications"><div class="titlepage"><div><div><h3 class="title">33.10. Using systemctl command to set limits to applications</h3></div></div></div><p class="_abstract _abstract">
				CPU affinity settings help you restrict the access of a particular process to some CPUs. Effectively, the CPU scheduler never schedules the process to run on the CPU that is not in the affinity mask of the process.
			</p><p>
				The default CPU affinity mask applies to all services managed by <code class="literal">systemd</code>.
			</p><p>
				To configure CPU affinity mask for a particular <code class="literal">systemd</code> service, <code class="literal">systemd</code> provides <code class="literal">CPUAffinity=</code> both as:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						a unit file option.
					</li><li class="listitem">
						a configuration option in the [Manager] section of the <code class="literal">/etc/systemd/system.conf</code> file.
					</li></ul></div><p>
				The <code class="literal">CPUAffinity=</code> unit file option sets a list of CPUs or CPU ranges that are merged and used as the affinity mask.
			</p><div class="formalpara"><p class="title"><strong>Procedure</strong></p><p>
					To set CPU affinity mask for a particular <code class="literal">systemd</code> service using the <code class="literal">CPUAffinity</code> unit file option:
				</p></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Check the values of the <code class="literal">CPUAffinity</code> unit file option in the service of your choice:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>systemctl show --property <span class="emphasis"><em>&lt;CPU affinity configuration option&gt;</em></span> <span class="emphasis"><em>&lt;service name&gt;</em></span></strong></span></pre></li><li class="listitem"><p class="simpara">
						As the root user, set the required value of the <code class="literal">CPUAffinity</code> unit file option for the CPU ranges used as the affinity mask:
					</p><pre class="literallayout"># <span class="strong strong"><strong>systemctl set-property <span class="emphasis"><em>&lt;service name&gt;</em></span> CPUAffinity=<span class="emphasis"><em>&lt;value&gt;</em></span></strong></span></pre></li><li class="listitem"><p class="simpara">
						Restart the service to apply the changes.
					</p><pre class="literallayout"># <span class="strong strong"><strong>systemctl restart <span class="emphasis"><em>&lt;service name&gt;</em></span></strong></span></pre></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">systemd.resource-control(5)</code>, <code class="literal">systemd.exec(5)</code>, <code class="literal">cgroups(7)</code> man pages on your system
					</li></ul></div></section><section class="section" id="proc_setting-global-default-cpu-affinity-through-manager-configuration_assembly_using-systemd-to-manage-resources-used-by-applications"><div class="titlepage"><div><div><h3 class="title">33.11. Setting global default CPU affinity through manager configuration</h3></div></div></div><p>
				The <code class="literal">CPUAffinity</code> option in the <code class="literal">/etc/systemd/system.conf</code> file defines an affinity mask for the process identification number (PID) 1 and all processes forked off of PID1. You can then override the <code class="literal">CPUAffinity</code> on a per-service basis.
			</p><p>
				To set the default CPU affinity mask for all <code class="literal">systemd</code> services using the <code class="literal">/etc/systemd/system.conf</code> file:
			</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
						Set the CPU numbers for the <code class="literal">CPUAffinity=</code> option in the [Manager] section of the <code class="literal">/etc/systemd/system.conf</code> file.
					</li><li class="listitem"><p class="simpara">
						Save the edited file and reload the <code class="literal">systemd</code> service:
					</p><pre class="literallayout"># <span class="strong strong"><strong>systemctl daemon-reload</strong></span></pre></li><li class="listitem">
						Reboot the server to apply the changes.
					</li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						The <code class="literal">systemd.resource-control(5)</code> and <code class="literal">systemd.exec(5)</code> man pages.
					</li></ul></div></section><section class="section" id="proc_configuring-numa-using-systemd_assembly_using-systemd-to-manage-resources-used-by-applications"><div class="titlepage"><div><div><h3 class="title">33.12. Configuring NUMA policies using systemd</h3></div></div></div><p class="_abstract _abstract">
				Non-uniform memory access (NUMA) is a computer memory subsystem design, in which the memory access time depends on the physical memory location relative to the processor.
			</p><p>
				Memory close to the CPU has lower latency (local memory) than memory that is local for a different CPU (foreign memory) or is shared between a set of CPUs.
			</p><p>
				In terms of the Linux kernel, NUMA policy governs where (for example, on which NUMA nodes) the kernel allocates physical memory pages for the process.
			</p><p>
				<code class="literal">systemd</code> provides unit file options <code class="literal">NUMAPolicy</code> and <code class="literal">NUMAMask</code> to control memory allocation policies for services.
			</p><div class="formalpara"><p class="title"><strong>Procedure</strong></p><p>
					To set the NUMA memory policy through the <code class="literal">NUMAPolicy</code> unit file option:
				</p></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Check the values of the <code class="literal">NUMAPolicy</code> unit file option in the service of your choice:
					</p><pre class="literallayout">$ <span class="strong strong"><strong>systemctl show --property <span class="emphasis"><em>&lt;NUMA policy configuration option&gt;</em></span> <span class="emphasis"><em>&lt;service name&gt;</em></span></strong></span></pre></li><li class="listitem"><p class="simpara">
						As a root, set the required policy type of the <code class="literal">NUMAPolicy</code> unit file option:
					</p><pre class="literallayout"># <span class="strong strong"><strong>systemctl set-property <span class="emphasis"><em>&lt;service name&gt;</em></span> NUMAPolicy=<span class="emphasis"><em>&lt;value&gt;</em></span></strong></span></pre></li><li class="listitem"><p class="simpara">
						Restart the service to apply the changes.
					</p><pre class="literallayout"># <span class="strong strong"><strong>systemctl restart <span class="emphasis"><em>&lt;service name&gt;</em></span></strong></span></pre></li></ol></div><p>
				To set a global <code class="literal">NUMAPolicy</code> setting using the [Manager] configuration option:
			</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
						Search in the <code class="literal">/etc/systemd/system.conf</code> file for the <code class="literal">NUMAPolicy</code> option in the [Manager] section of the file.
					</li><li class="listitem">
						Edit the policy type and save the file.
					</li><li class="listitem"><p class="simpara">
						Reload the <code class="literal">systemd</code> configuration:
					</p><pre class="literallayout"># <span class="strong strong"><strong>systemd daemon-reload</strong></span></pre></li><li class="listitem">
						Reboot the server.
					</li></ol></div><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
					When you configure a strict NUMA policy, for example <code class="literal">bind</code>, make sure that you also appropriately set the <code class="literal">CPUAffinity=</code> unit file option.
				</p></div></rh-alert><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="#proc_using-systemctl-command-to-set-limits-to-applications_assembly_using-systemd-to-manage-resources-used-by-applications" title="33.10. Using systemctl command to set limits to applications">Using systemctl command to set limits to applications</a>
					</li><li class="listitem">
						The <code class="literal">systemd.resource-control(5)</code>, <code class="literal">systemd.exec(5)</code>, and <code class="literal">set_mempolicy(2)</code> man pages.
					</li></ul></div></section><section class="section" id="ref_numa-policy-configuration-options-with-systemd_assembly_using-systemd-to-manage-resources-used-by-applications"><div class="titlepage"><div><div><h3 class="title">33.13. NUMA policy configuration options for systemd</h3></div></div></div><p class="_abstract _abstract">
				<code class="literal">Systemd</code> provides the following options to configure the NUMA policy:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">NUMAPolicy</code></span></dt><dd><p class="simpara">
							Controls the NUMA memory policy of the executed processes. You can use these policy types:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									default
								</li><li class="listitem">
									preferred
								</li><li class="listitem">
									bind
								</li><li class="listitem">
									interleave
								</li><li class="listitem">
									local
								</li></ul></div></dd><dt><span class="term"><code class="literal">NUMAMask</code></span></dt><dd><p class="simpara">
							Controls the NUMA node list which is associated with the selected NUMA policy.
						</p><p class="simpara">
							Note that you do not have to specify the <code class="literal">NUMAMask</code> option for the following policies:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									default
								</li><li class="listitem">
									local
								</li></ul></div><p class="simpara">
							For the preferred policy, the list specifies only a single NUMA node.
						</p></dd></dl></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">systemd.resource-control(5)</code>, <code class="literal">systemd.exec(5)</code>, and <code class="literal">set_mempolicy(2)</code> man pages on your system
					</li></ul></div></section><section class="section" id="creating-transient-control-groups_assembly_using-systemd-to-manage-resources-used-by-applications"><div class="titlepage"><div><div><h3 class="title">33.14. Creating transient cgroups using systemd-run command</h3></div></div></div><p class="_abstract _abstract">
				The transient <code class="literal">cgroups</code> set limits on resources consumed by a unit (service or scope) during its runtime.
			</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						To create a transient control group, use the <code class="literal">systemd-run</code> command in the following format:
					</p><pre class="literallayout"># <span class="strong strong"><strong>systemd-run --unit=<span class="emphasis"><em>&lt;name&gt;</em></span> --slice=<span class="emphasis"><em>&lt;name&gt;</em></span>.slice <span class="emphasis"><em>&lt;command&gt;</em></span></strong></span></pre><p class="simpara">
						This command creates and starts a transient service or a scope unit and runs a custom command in such a unit.
					</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
								The <code class="literal">--unit=&lt;name&gt;</code> option gives a name to the unit. If <code class="literal">--unit</code> is not specified, the name is generated automatically.
							</li><li class="listitem">
								The <code class="literal">--slice=&lt;<span class="emphasis"><em>name</em></span>&gt;.slice</code> option makes your service or scope unit a member of a specified slice. Replace <code class="literal">&lt;<span class="emphasis"><em>name</em></span>&gt;.slice</code> with the name of an existing slice (as shown in the output of <code class="literal">systemctl -t slice</code>), or create a new slice by passing a unique name. By default, services and scopes are created as members of the <code class="literal">system.slice</code>.
							</li><li class="listitem"><p class="simpara">
								Replace <code class="literal">&lt;<span class="emphasis"><em>command</em></span>&gt;</code> with the command you want to enter in the service or the scope unit.
							</p><p class="simpara">
								The following message is displayed to confirm that you created and started the service or the scope successfully:
							</p><pre class="literallayout"># Running as unit <span class="emphasis"><em>&lt;name&gt;</em></span>.service</pre></li></ul></div></li><li class="listitem"><p class="simpara">
						<span class="emphasis"><em>Optional</em></span>: Keep the unit running after its processes finished to collect run-time information:
					</p><pre class="literallayout"># <span class="strong strong"><strong>systemd-run --unit=<span class="emphasis"><em>&lt;name&gt;</em></span> --slice=<span class="emphasis"><em>&lt;name&gt;</em></span>.slice --remain-after-exit <span class="emphasis"><em>&lt;command&gt;</em></span></strong></span></pre><p class="simpara">
						The command creates and starts a transient service unit and runs a custom command in the unit. The <code class="literal">--remain-after-exit</code> option ensures that the service keeps running after its processes have finished.
					</p></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						The <code class="literal">systemd-run(1)</code> manual page
					</li></ul></div></section><section class="section" id="removing-transient-control-groups_assembly_using-systemd-to-manage-resources-used-by-applications"><div class="titlepage"><div><div><h3 class="title">33.15. Removing transient control groups</h3></div></div></div><p class="_abstract _abstract">
				You can use the <code class="literal">systemd</code> system and service manager to remove transient control groups (<code class="literal">cgroups</code>) if you no longer need to limit, prioritize, or control access to hardware resources for groups of processes.
			</p><p>
				Transient <code class="literal">cgroups</code> are automatically released once all the processes that a service or a scope unit contains finish.
			</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						To stop the service unit with all its processes, enter:
					</p><pre class="literallayout"># <span class="strong strong"><strong>systemctl stop &lt;<span class="emphasis"><em>name</em></span>&gt;.service</strong></span></pre></li><li class="listitem"><p class="simpara">
						To terminate one or more of the unit processes, enter:
					</p><pre class="literallayout"># <span class="strong strong"><strong>systemctl kill &lt;<span class="emphasis"><em>name</em></span>&gt;.service --kill-who=<span class="emphasis"><em>PID,…​</em></span> --signal=&lt;<span class="emphasis"><em>signal</em></span>&gt;</strong></span></pre><p class="simpara">
						The command uses the <code class="literal">--kill-who</code> option to select process(es) from the control group you want to terminate. To kill multiple processes at the same time, pass a comma-separated list of PIDs. The <code class="literal">--signal</code> option determines the type of POSIX signal to be sent to the specified processes. The default signal is <span class="emphasis"><em>SIGTERM</em></span>.
					</p></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="#understanding-control-groups_setting-limits-for-applications" title="34.1. Introducing control groups">What are control groups</a>
					</li><li class="listitem">
						<a class="link" href="#what-kernel-resource-controllers-are_setting-limits-for-applications" title="34.2. Introducing kernel resource controllers">What are kernel resource controllers</a>
					</li><li class="listitem">
						<code class="literal">systemd.resource-control(5)</code> and <code class="literal">cgroups(7)</code> man pages on your system
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_monitoring_and_updating_the_kernel/index#setting-limits-for-applications_managing-monitoring-and-updating-the-kernel">Understanding control groups</a>
					</li><li class="listitem">
						<span class="emphasis"><em><span class="citetitle citetitle"><a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_basic_system_settings/managing-systemd_configuring-basic-system-settings">Managing systemd</a></span></em></span> in RHEL
					</li></ul></div></section></section><section class="chapter" id="setting-limits-for-applications_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 34. Understanding control groups</h2></div></div></div><p class="_abstract _abstract">
			Using the control groups (<code class="literal">cgroups</code>) kernel functionality, you can control resource usage of applications to use them more efficiently.
		</p><p>
			You can use <code class="literal">cgroups</code> for the following tasks:
		</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
					Setting limits for system resource allocation.
				</li><li class="listitem">
					Prioritizing the allocation of hardware resources to specific processes.
				</li><li class="listitem">
					Isolating certain processes from obtaining hardware resources.
				</li></ul></div><section class="section" id="understanding-control-groups_setting-limits-for-applications"><div class="titlepage"><div><div><h3 class="title">34.1. Introducing control groups</h3></div></div></div><p class="_abstract _abstract">
				Using the <span class="emphasis"><em>control groups</em></span> Linux kernel feature, you can organize processes into hierarchically ordered groups - <code class="literal">cgroups</code>. You define the hierarchy (control groups tree) by providing structure to <code class="literal">cgroups</code> virtual file system, mounted by default on the <code class="literal">/sys/fs/cgroup/</code> directory.
			</p><p>
				The <code class="literal">systemd</code> service manager uses <code class="literal">cgroups</code> to organize all units and services that it governs. Manually, you can manage the hierarchies of <code class="literal">cgroups</code> by creating and removing sub-directories in the <code class="literal">/sys/fs/cgroup/</code> directory.
			</p><p>
				The resource controllers in the kernel then modify the behavior of processes in <code class="literal">cgroups</code> by limiting, prioritizing or allocating system resources, of those processes. These resources include the following:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						CPU time
					</li><li class="listitem">
						Memory
					</li><li class="listitem">
						Network bandwidth
					</li><li class="listitem">
						Combinations of these resources
					</li></ul></div><p>
				The primary use case of <code class="literal">cgroups</code> is aggregating system processes and dividing hardware resources among applications and users. This makes it possible to increase the efficiency, stability, and security of your environment.
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">Control groups version 1</span></dt><dd><p class="simpara">
							<span class="emphasis"><em>Control groups version 1</em></span> (<code class="literal">cgroups-v1</code>) provide a per-resource controller hierarchy. This means that each resource (such as CPU, memory, or I/O) has its own control group hierarchy. You can combine different control group hierarchies in a way that one controller can coordinate with another in managing their respective resources. However, when the two controllers belong to different process hierarchies, proper coordination is limited.
						</p><p class="simpara">
							The <code class="literal">cgroups-v1</code> controllers were developed across a large time span and as a result, the behavior and naming of their control files is not uniform.
						</p></dd><dt><span class="term">Control groups version 2</span></dt><dd><p class="simpara">
							<span class="emphasis"><em>Control groups version 2</em></span> (<code class="literal">cgroups-v2</code>) provide a single control group hierarchy against which all resource controllers are mounted.
						</p><p class="simpara">
							The control file behavior and naming is consistent among different controllers.
						</p></dd></dl></div><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
					RHEL 9, by default, mounts and uses <code class="literal">cgroups-v2</code>.
				</p></div></rh-alert><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="#what-kernel-resource-controllers-are_setting-limits-for-applications" title="34.2. Introducing kernel resource controllers">Introducing kernel resource controllers</a>
					</li><li class="listitem">
						The <code class="literal">cgroups(7)</code> manual page
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/labs/rhcb/RHEL-9.0/kernel-5.14.0-70.13.1.el9/source/Documentation/admin-guide/cgroup-v1">cgroups-v1</a>
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/labs/rhcb/RHEL-9.0/kernel-5.14.0-70.13.1.el9/source/blob/Documentation/admin-guide/cgroup-v2.rst">cgroups-v2</a>
					</li></ul></div></section><section class="section" id="what-kernel-resource-controllers-are_setting-limits-for-applications"><div class="titlepage"><div><div><h3 class="title">34.2. Introducing kernel resource controllers</h3></div></div></div><p class="_abstract _abstract">
				Kernel resource controllers enable the functionality of control groups. RHEL 9 supports various controllers for <span class="emphasis"><em>control groups version 1</em></span> (<code class="literal">cgroups-v1</code>) and <span class="emphasis"><em>control groups version 2</em></span> (<code class="literal">cgroups-v2</code>).
			</p><p>
				A resource controller, also called a control group subsystem, is a kernel subsystem that represents a single resource, such as CPU time, memory, network bandwidth or disk I/O. The Linux kernel provides a range of resource controllers that are mounted automatically by the <code class="literal">systemd</code> service manager. You can find a list of the currently mounted resource controllers in the <code class="literal">/proc/cgroups</code> file.
			</p><div class="variablelist"><p class="title"><strong>Controllers available for <code class="literal">cgroups-v1</code>:</strong></p><dl class="variablelist"><dt><span class="term"><code class="literal">blkio</code></span></dt><dd>
							Sets limits on input/output access to and from block devices.
						</dd><dt><span class="term"><code class="literal">cpu</code></span></dt><dd>
							Adjusts the parameters of the Completely Fair Scheduler (CFS) for a control group’s tasks. The <code class="literal">cpu</code> controller is mounted together with the <code class="literal">cpuacct</code> controller on the same mount.
						</dd><dt><span class="term"><code class="literal">cpuacct</code></span></dt><dd>
							Creates automatic reports on CPU resources used by tasks in a control group. The <code class="literal">cpuacct</code> controller is mounted together with the <code class="literal">cpu</code> controller on the same mount.
						</dd><dt><span class="term"><code class="literal">cpuset</code></span></dt><dd>
							Restricts control group tasks to run only on a specified subset of CPUs and to direct the tasks to use memory only on specified memory nodes.
						</dd><dt><span class="term"><code class="literal">devices</code></span></dt><dd>
							Controls access to devices for tasks in a control group.
						</dd><dt><span class="term"><code class="literal">freezer</code></span></dt><dd>
							Suspends or resumes tasks in a control group.
						</dd><dt><span class="term"><code class="literal">memory</code></span></dt><dd>
							Sets limits on memory use by tasks in a control group and generates automatic reports on memory resources used by those tasks.
						</dd><dt><span class="term"><code class="literal">net_cls</code></span></dt><dd>
							Tags network packets with a class identifier (<code class="literal">classid</code>) that enables the Linux traffic controller (the <code class="literal">tc</code> command) to identify packets that originate from a particular control group task. A subsystem of <code class="literal">net_cls</code>, the <code class="literal">net_filter</code> (iptables), can also use this tag to perform actions on such packets. The <code class="literal">net_filter</code> tags network sockets with a firewall identifier (<code class="literal">fwid</code>) that allows the Linux firewall to identify packets that originate from a particular control group task (by using the <code class="literal">iptables</code> command).
						</dd><dt><span class="term"><code class="literal">net_prio</code></span></dt><dd>
							Sets the priority of network traffic.
						</dd><dt><span class="term"><code class="literal">pids</code></span></dt><dd>
							Sets limits for a number of processes and their children in a control group.
						</dd><dt><span class="term"><code class="literal">perf_event</code></span></dt><dd>
							Groups tasks for monitoring by the <code class="literal">perf</code> performance monitoring and reporting utility.
						</dd><dt><span class="term"><code class="literal">rdma</code></span></dt><dd>
							Sets limits on Remote Direct Memory Access/InfiniBand specific resources in a control group.
						</dd><dt><span class="term"><code class="literal">hugetlb</code></span></dt><dd>
							Can be used to limit the usage of large size virtual memory pages by tasks in a control group.
						</dd></dl></div><div class="variablelist"><p class="title"><strong>Controllers available for <code class="literal">cgroups-v2</code>:</strong></p><dl class="variablelist"><dt><span class="term"><code class="literal">io</code></span></dt><dd>
							Sets limits on input/output access to and from block devices.
						</dd><dt><span class="term"><code class="literal">memory</code></span></dt><dd>
							Sets limits on memory use by tasks in a control group and generates automatic reports on memory resources used by those tasks.
						</dd><dt><span class="term"><code class="literal">pids</code></span></dt><dd>
							Sets limits for a number of processes and their children in a control group.
						</dd><dt><span class="term"><code class="literal">rdma</code></span></dt><dd>
							Sets limits on Remote Direct Memory Access/InfiniBand specific resources in a control group.
						</dd><dt><span class="term"><code class="literal">cpu</code></span></dt><dd>
							Adjusts the parameters of the Completely Fair Scheduler (CFS) for a control group’s tasks and creates automatic reports on CPU resources used by tasks in a control group.
						</dd><dt><span class="term"><code class="literal">cpuset</code></span></dt><dd>
							Restricts control group tasks to run only on a specified subset of CPUs and to direct the tasks to use memory only on specified memory nodes. Supports only the core functionality (<code class="literal">cpus{,.effective}</code>, <code class="literal">mems{,.effective}</code>) with a new partition feature.
						</dd><dt><span class="term"><code class="literal">perf_event</code></span></dt><dd>
							Groups tasks for monitoring by the <code class="literal">perf</code> performance monitoring and reporting utility. <code class="literal">perf_event</code> is enabled automatically on the v2 hierarchy.
						</dd></dl></div><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
					A resource controller can be used either in a <code class="literal">cgroups-v1</code> hierarchy or a <code class="literal">cgroups-v2</code> hierarchy, not simultaneously in both.
				</p></div></rh-alert><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						The <code class="literal">cgroups(7)</code> manual page
					</li><li class="listitem">
						Documentation in <code class="literal">/usr/share/doc/kernel-doc-&lt;kernel_version&gt;/Documentation/cgroups-v1/</code> directory (after installing the <code class="literal">kernel-doc</code> package).
					</li></ul></div></section><section class="section" id="what-namespaces-are_setting-limits-for-applications"><div class="titlepage"><div><div><h3 class="title">34.3. Introducing namespaces</h3></div></div></div><p class="_abstract _abstract">
				Namespaces are one of the most important methods for organizing and identifying software objects.
			</p><p>
				A namespace wraps a global system resource (for example, a mount point, a network device, or a hostname) in an abstraction that makes it appear to processes within the namespace that they have their own isolated instance of the global resource. One of the most common technologies that use namespaces are containers.
			</p><p>
				Changes to a particular global resource are visible only to processes in that namespace and do not affect the rest of the system or other namespaces.
			</p><p>
				To inspect which namespaces a process is a member of, you can check the symbolic links in the <code class="literal">/proc/&lt;<span class="emphasis"><em>PID</em></span>&gt;/ns/</code> directory.
			</p><rh-table id="idm140280133762384"><table class="lt-4-cols lt-7-rows"><caption>Table 34.1. Supported namespaces and resources which they isolate:</caption><colgroup><col style="width: 50%; " class="col_1"><!--Empty--><col style="width: 50%; " class="col_2"><!--Empty--></colgroup><thead><tr><th align="left" valign="top" id="idm140280133757584" scope="col">Namespace</th><th align="left" valign="top" id="idm140280133756496" scope="col">Isolates</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm140280133757584"> <p>
								<span class="strong strong"><strong>Mount</strong></span>
							</p>
							 </td><td align="left" valign="top" headers="idm140280133756496"> <p>
								Mount points
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm140280133757584"> <p>
								<span class="strong strong"><strong>UTS</strong></span>
							</p>
							 </td><td align="left" valign="top" headers="idm140280133756496"> <p>
								Hostname and NIS domain name
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm140280133757584"> <p>
								<span class="strong strong"><strong>IPC</strong></span>
							</p>
							 </td><td align="left" valign="top" headers="idm140280133756496"> <p>
								System V IPC, POSIX message queues
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm140280133757584"> <p>
								<span class="strong strong"><strong>PID</strong></span>
							</p>
							 </td><td align="left" valign="top" headers="idm140280133756496"> <p>
								Process IDs
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm140280133757584"> <p>
								<span class="strong strong"><strong>Network</strong></span>
							</p>
							 </td><td align="left" valign="top" headers="idm140280133756496"> <p>
								Network devices, stacks, ports, etc
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm140280133757584"> <p>
								<span class="strong strong"><strong>User</strong></span>
							</p>
							 </td><td align="left" valign="top" headers="idm140280133756496"> <p>
								User and group IDs
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm140280133757584"> <p>
								<span class="strong strong"><strong>Control groups</strong></span>
							</p>
							 </td><td align="left" valign="top" headers="idm140280133756496"> <p>
								Control group root directory
							</p>
							 </td></tr></tbody></table></rh-table><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						The <code class="literal">namespaces(7)</code> and <code class="literal">cgroup_namespaces(7)</code> manual pages
					</li></ul></div></section></section><section class="chapter" id="assembly_using-cgroupfs-to-manually-manage-cgroups_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 35. Using cgroupfs to manually manage cgroups</h2></div></div></div><p>
			You can manage <code class="literal">cgroup</code> hierarchies on your system by creating directories on the <code class="literal">cgroupfs</code> virtual file system. The file system is mounted by default on the <code class="literal">/sys/fs/cgroup/</code> directory and you can specify desired configurations in dedicated control files.
		</p><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
				In general, Red Hat recommends you use <code class="literal">systemd</code> for controlling the usage of system resources. You should manually configure the <code class="literal">cgroups</code> virtual file system only in special cases. For example, when you need to use <code class="literal">cgroup-v1</code> controllers that have no equivalents in <code class="literal">cgroup-v2</code> hierarchy.
			</p></div></rh-alert><section class="section" id="proc_creating-cgroups-and-enabling-controllers-in-cgroups-v2-file-system_assembly_using-cgroupfs-to-manually-manage-cgroups"><div class="titlepage"><div><div><h3 class="title">35.1. Creating cgroups and enabling controllers in cgroups-v2 file system</h3></div></div></div><p>
				You can manage the <span class="emphasis"><em>control groups</em></span> (<code class="literal">cgroups</code>) by creating or removing directories and by writing to files in the <code class="literal">cgroups</code> virtual file system. The file system is by default mounted on the <code class="literal">/sys/fs/cgroup/</code> directory. To use settings from the <code class="literal">cgroups</code> controllers, you also need to enable the desired controllers for child <code class="literal">cgroups</code>. The root <code class="literal">cgroup</code> has, by default, enabled the <code class="literal">memory</code> and <code class="literal">pids</code> controllers for its child <code class="literal">cgroups</code>. Therefore, Red Hat recommends to create at least two levels of child <code class="literal">cgroups</code> inside the <code class="literal">/sys/fs/cgroup/</code> root <code class="literal">cgroup</code>. This way you optionally remove the <code class="literal">memory</code> and <code class="literal">pids</code> controllers from the child <code class="literal">cgroups</code> and maintain better organizational clarity of <code class="literal">cgroup</code> files.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have root permissions.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Create the <code class="literal">/sys/fs/cgroup/Example/</code> directory:
					</p><pre class="literallayout"># <span class="strong strong"><strong>mkdir /sys/fs/cgroup/Example/</strong></span></pre><p class="simpara">
						The <code class="literal">/sys/fs/cgroup/Example/</code> directory defines a child group. When you create the <code class="literal">/sys/fs/cgroup/Example/</code> directory, some <code class="literal">cgroups-v2</code> interface files are automatically created in the directory. The <code class="literal">/sys/fs/cgroup/Example/</code> directory contains also controller-specific files for the <code class="literal">memory</code> and <code class="literal">pids</code> controllers.
					</p></li><li class="listitem"><p class="simpara">
						Optional: Inspect the newly created child control group:
					</p><pre class="literallayout"># <span class="strong strong"><strong>ll /sys/fs/cgroup/Example/</strong></span>
-r—​r—​r--. 1 root root 0 Jun  1 10:33 cgroup.controllers
-r—​r—​r--. 1 root root 0 Jun  1 10:33 cgroup.events
-rw-r—​r--. 1 root root 0 Jun  1 10:33 cgroup.freeze
-rw-r—​r--. 1 root root 0 Jun  1 10:33 cgroup.procs
…​
-rw-r—​r--. 1 root root 0 Jun  1 10:33 cgroup.subtree_control
-r—​r—​r--. 1 root root 0 Jun  1 10:33 memory.events.local
-rw-r—​r--. 1 root root 0 Jun  1 10:33 memory.high
-rw-r—​r--. 1 root root 0 Jun  1 10:33 memory.low
…​
-r—​r—​r--. 1 root root 0 Jun  1 10:33 pids.current
-r—​r—​r--. 1 root root 0 Jun  1 10:33 pids.events
-rw-r—​r--. 1 root root 0 Jun  1 10:33 pids.max</pre><p class="simpara">
						The example output shows general <code class="literal">cgroup</code> control interface files such as <code class="literal">cgroup.procs</code> or <code class="literal">cgroup.controllers</code>. These files are common to all control groups, regardless of enabled controllers.
					</p><p class="simpara">
						The files such as <code class="literal">memory.high</code> and <code class="literal">pids.max</code> relate to the <code class="literal">memory</code> and <code class="literal">pids</code> controllers, which are in the root control group (<code class="literal">/sys/fs/cgroup/</code>), and are enabled by default by <code class="literal">systemd</code>.
					</p><p class="simpara">
						By default, the newly created child group inherits all settings from the parent <code class="literal">cgroup</code>. In this case, there are no limits from the root <code class="literal">cgroup</code>.
					</p></li><li class="listitem"><p class="simpara">
						Verify that the desired controllers are available in the <code class="literal">/sys/fs/cgroup/cgroup.controllers</code> file:
					</p><pre class="literallayout"># <span class="strong strong"><strong>cat /sys/fs/cgroup/cgroup.controllers</strong></span>
cpuset cpu io memory hugetlb pids rdma</pre></li><li class="listitem"><p class="simpara">
						Enable the desired controllers. In this example it is <code class="literal">cpu</code> and <code class="literal">cpuset</code> controllers:
					</p><pre class="literallayout"># <span class="strong strong"><strong>echo "+cpu" &gt;&gt; /sys/fs/cgroup/cgroup.subtree_control</strong></span>
# <span class="strong strong"><strong>echo "+cpuset" &gt;&gt; /sys/fs/cgroup/cgroup.subtree_control</strong></span></pre><p class="simpara">
						These commands enable the <code class="literal">cpu</code> and <code class="literal">cpuset</code> controllers for the immediate child groups of the <code class="literal">/sys/fs/cgroup/</code> root control group. Including the newly created <code class="literal">Example</code> control group. A <span class="emphasis"><em>child group</em></span> is where you can specify processes and apply control checks to each of the processes based on your criteria.
					</p><p class="simpara">
						Users can read the contents of the <code class="literal">cgroup.subtree_control</code> file at any level to get an idea of what controllers are going to be available for enablement in the immediate child group.
					</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
							By default, the <code class="literal">/sys/fs/cgroup/cgroup.subtree_control</code> file in the root control group contains <code class="literal">memory</code> and <code class="literal">pids</code> controllers.
						</p></div></rh-alert></li><li class="listitem"><p class="simpara">
						Enable the desired controllers for child <code class="literal">cgroups</code> of the <code class="literal">Example</code> control group:
					</p><pre class="literallayout"># <span class="strong strong"><strong>echo "+cpu +cpuset" &gt;&gt; /sys/fs/cgroup/Example/cgroup.subtree_control</strong></span></pre><p class="simpara">
						This command ensures that the immediate child control group will <span class="emphasis"><em>only</em></span> have controllers relevant to regulate the CPU time distribution - not to <code class="literal">memory</code> or <code class="literal">pids</code> controllers.
					</p></li><li class="listitem"><p class="simpara">
						Create the <code class="literal">/sys/fs/cgroup/Example/tasks/</code> directory:
					</p><pre class="literallayout"># <span class="strong strong"><strong>mkdir /sys/fs/cgroup/Example/tasks/</strong></span></pre><p class="simpara">
						The <code class="literal">/sys/fs/cgroup/Example/tasks/</code> directory defines a child group with files that relate purely to <code class="literal">cpu</code> and <code class="literal">cpuset</code> controllers. You can now assign processes to this control group and utilize <code class="literal">cpu</code> and <code class="literal">cpuset</code> controller options for your processes.
					</p></li><li class="listitem"><p class="simpara">
						Optional: Inspect the child control group:
					</p><pre class="literallayout"># <span class="strong strong"><strong>ll /sys/fs/cgroup/Example/tasks</strong></span>
-r—​r—​r--. 1 root root 0 Jun  1 11:45 cgroup.controllers
-r—​r—​r--. 1 root root 0 Jun  1 11:45 cgroup.events
-rw-r—​r--. 1 root root 0 Jun  1 11:45 cgroup.freeze
-rw-r—​r--. 1 root root 0 Jun  1 11:45 cgroup.max.depth
-rw-r—​r--. 1 root root 0 Jun  1 11:45 cgroup.max.descendants
-rw-r—​r--. 1 root root 0 Jun  1 11:45 cgroup.procs
-r—​r—​r--. 1 root root 0 Jun  1 11:45 cgroup.stat
-rw-r—​r--. 1 root root 0 Jun  1 11:45 cgroup.subtree_control
-rw-r—​r--. 1 root root 0 Jun  1 11:45 cgroup.threads
-rw-r—​r--. 1 root root 0 Jun  1 11:45 cgroup.type
-rw-r—​r--. 1 root root 0 Jun  1 11:45 cpu.max
-rw-r—​r--. 1 root root 0 Jun  1 11:45 cpu.pressure
-rw-r—​r--. 1 root root 0 Jun  1 11:45 cpuset.cpus
-r—​r—​r--. 1 root root 0 Jun  1 11:45 cpuset.cpus.effective
-rw-r—​r--. 1 root root 0 Jun  1 11:45 cpuset.cpus.partition
-rw-r—​r--. 1 root root 0 Jun  1 11:45 cpuset.mems
-r—​r—​r--. 1 root root 0 Jun  1 11:45 cpuset.mems.effective
-r—​r—​r--. 1 root root 0 Jun  1 11:45 cpu.stat
-rw-r—​r--. 1 root root 0 Jun  1 11:45 cpu.weight
-rw-r—​r--. 1 root root 0 Jun  1 11:45 cpu.weight.nice
-rw-r—​r--. 1 root root 0 Jun  1 11:45 io.pressure
-rw-r—​r--. 1 root root 0 Jun  1 11:45 memory.pressure</pre></li></ol></div><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
					The <code class="literal">cpu</code> controller is only activated if the relevant child control group has at least 2 processes which compete for time on a single CPU.
				</p></div></rh-alert><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Optional: confirm that you have created a new <code class="literal">cgroup</code> with only the desired controllers active:
					</p><pre class="literallayout white-space-pre"># <span class="strong strong"><strong>cat /sys/fs/cgroup/Example/tasks/cgroup.controllers</strong></span>
cpuset cpu</pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="#what-kernel-resource-controllers-are_setting-limits-for-applications" title="34.2. Introducing kernel resource controllers">What are kernel resource controllers</a>
					</li><li class="listitem">
						<a class="link" href="#proc_mounting-cgroups-v1_assembly_using-cgroupfs-to-manually-manage-cgroups" title="35.3. Mounting cgroups-v1">Mounting cgroups-v1</a>
					</li><li class="listitem">
						<code class="literal">cgroups(7)</code>, <code class="literal">sysfs(5)</code> manual pages
					</li></ul></div></section><section class="section" id="proc_controlling-distribution-of-cpu-time-for-applications-by-adjusting-cpu-weight_assembly_using-cgroupfs-to-manually-manage-cgroups"><div class="titlepage"><div><div><h3 class="title">35.2. Controlling distribution of CPU time for applications by adjusting CPU weight</h3></div></div></div><p class="_abstract _abstract">
				You need to assign values to the relevant files of the <code class="literal">cpu</code> controller to regulate distribution of the CPU time to applications under the specific cgroup tree.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have root permissions.
					</li><li class="listitem">
						You have applications for which you want to control distribution of CPU time.
					</li><li class="listitem"><p class="simpara">
						You created a two level hierarchy of <span class="emphasis"><em>child control groups</em></span> inside the <code class="literal">/sys/fs/cgroup/</code> <span class="emphasis"><em>root control group</em></span> as in the following example:
					</p><pre class="literallayout">…​
  ├── Example
  │   ├── g1
  │   ├── g2
  │   └── g3
…​</pre></li><li class="listitem">
						You enabled the <code class="literal">cpu</code> controller in the parent control group and in child control groups similarly as described in <a class="link" href="#proc_creating-cgroups-and-enabling-controllers-in-cgroups-v2-file-system_assembly_using-cgroupfs-to-manually-manage-cgroups" title="35.1. Creating cgroups and enabling controllers in cgroups-v2 file system">Creating cgroups and enabling controllers in cgroups-v2 file system</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Configure desired CPU weights to achieve resource restrictions within the control groups:
					</p><pre class="literallayout"># <span class="strong strong"><strong>echo "150" &gt; /sys/fs/cgroup/Example/g1/cpu.weight</strong></span>
# <span class="strong strong"><strong>echo "100" &gt; /sys/fs/cgroup/Example/g2/cpu.weight</strong></span>
# <span class="strong strong"><strong>echo "50" &gt; /sys/fs/cgroup/Example/g3/cpu.weight</strong></span></pre></li><li class="listitem"><p class="simpara">
						Add the applications' PIDs to the <code class="literal">g1</code>, <code class="literal">g2</code>, and <code class="literal">g3</code> child groups:
					</p><pre class="literallayout"># <span class="strong strong"><strong>echo "33373" &gt; /sys/fs/cgroup/Example/g1/cgroup.procs</strong></span>
# <span class="strong strong"><strong>echo "33374" &gt; /sys/fs/cgroup/Example/g2/cgroup.procs</strong></span>
# <span class="strong strong"><strong>echo "33377" &gt; /sys/fs/cgroup/Example/g3/cgroup.procs</strong></span></pre><p class="simpara">
						The example commands ensure that desired applications become members of the <code class="literal">Example/g*/</code> child cgroups and will get their CPU time distributed as per the configuration of those cgroups.
					</p><p class="simpara">
						The weights of the children cgroups (<code class="literal">g1</code>, <code class="literal">g2</code>, <code class="literal">g3</code>) that have running processes are summed up at the level of the parent cgroup (<code class="literal">Example</code>). The CPU resource is then distributed proportionally based on the respective weights.
					</p><p class="simpara">
						As a result, when all processes run at the same time, the kernel allocates to each of them the proportionate CPU time based on their respective cgroup’s <code class="literal">cpu.weight</code> file:
					</p><rh-table><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 30%; " class="col_1"><!--Empty--><col style="width: 30%; " class="col_2"><!--Empty--><col style="width: 40%; " class="col_3"><!--Empty--></colgroup><thead><tr><th align="left" valign="top" id="idm140280132623312" scope="col">Child cgroup</th><th align="left" valign="top" id="idm140280132622224" scope="col"><code class="literal">cpu.weight</code> file</th><th align="left" valign="top" id="idm140280132620816" scope="col">CPU time allocation</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm140280132623312"> <p>
										g1
									</p>
									 </td><td align="left" valign="top" headers="idm140280132622224"> <p>
										150
									</p>
									 </td><td align="left" valign="top" headers="idm140280132620816"> <p>
										~50% (150/300)
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm140280132623312"> <p>
										g2
									</p>
									 </td><td align="left" valign="top" headers="idm140280132622224"> <p>
										100
									</p>
									 </td><td align="left" valign="top" headers="idm140280132620816"> <p>
										~33% (100/300)
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm140280132623312"> <p>
										g3
									</p>
									 </td><td align="left" valign="top" headers="idm140280132622224"> <p>
										50
									</p>
									 </td><td align="left" valign="top" headers="idm140280132620816"> <p>
										~16% (50/300)
									</p>
									 </td></tr></tbody></table></rh-table><p class="simpara">
						The value of the <code class="literal">cpu.weight</code> controller file is not a percentage.
					</p><p class="simpara">
						If one process stopped running, leaving cgroup <code class="literal">g2</code> with no running processes, the calculation would omit the cgroup <code class="literal">g2</code> and only account weights of cgroups <code class="literal">g1</code> and <code class="literal">g3</code>:
					</p><rh-table><table class="lt-4-cols lt-7-rows"><colgroup><col style="width: 30%; " class="col_1"><!--Empty--><col style="width: 30%; " class="col_2"><!--Empty--><col style="width: 40%; " class="col_3"><!--Empty--></colgroup><thead><tr><th align="left" valign="top" id="idm140280132594192" scope="col">Child cgroup</th><th align="left" valign="top" id="idm140280132593104" scope="col"><code class="literal">cpu.weight</code> file</th><th align="left" valign="top" id="idm140280132591696" scope="col">CPU time allocation</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm140280132594192"> <p>
										g1
									</p>
									 </td><td align="left" valign="top" headers="idm140280132593104"> <p>
										150
									</p>
									 </td><td align="left" valign="top" headers="idm140280132591696"> <p>
										~75% (150/200)
									</p>
									 </td></tr><tr><td align="left" valign="top" headers="idm140280132594192"> <p>
										g3
									</p>
									 </td><td align="left" valign="top" headers="idm140280132593104"> <p>
										50
									</p>
									 </td><td align="left" valign="top" headers="idm140280132591696"> <p>
										~25% (50/200)
									</p>
									 </td></tr></tbody></table></rh-table><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
							If a child cgroup had multiple running processes, the CPU time allocated to the respective cgroup would be distributed equally to the member processes of that cgroup.
						</p></div></rh-alert></li></ol></div><div class="orderedlist"><p class="title"><strong>Verification</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Verify that the applications run in the specified control groups:
					</p><pre class="literallayout"># <span class="strong strong"><strong>cat /proc/33373/cgroup /proc/33374/cgroup /proc/33377/cgroup</strong></span>
0::/Example/g1
0::/Example/g2
0::/Example/g3</pre><p class="simpara">
						The command output shows the processes of the specified applications that run in the <code class="literal">Example/g*/</code> child cgroups.
					</p></li><li class="listitem"><p class="simpara">
						Inspect the current CPU consumption of the throttled applications:
					</p><pre class="literallayout white-space-pre"># <span class="strong strong"><strong>top</strong></span>
top - 05:17:18 up 1 day, 18:25,  1 user,  load average: 3.03, 3.03, 3.00
Tasks:  95 total,   4 running,  91 sleeping,   0 stopped,   0 zombie
%Cpu(s): 18.1 us, 81.6 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.3 hi,  0.0 si,  0.0 st
MiB Mem :   3737.0 total,   3233.7 free,    132.8 used,    370.5 buff/cache
MiB Swap:   4060.0 total,   4060.0 free,      0.0 used.   3373.1 avail Mem

    PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND
  33373 root      20   0   18720   1748   1460 R  <span class="strong strong"><strong>49.5</strong></span>   0.0 415:05.87 sha1sum
  33374 root      20   0   18720   1756   1464 R  <span class="strong strong"><strong>32.9</strong></span>   0.0 412:58.33 sha1sum
  33377 root      20   0   18720   1860   1568 R  <span class="strong strong"><strong>16.3</strong></span>   0.0 411:03.12 sha1sum
    760 root      20   0  416620  28540  15296 S   0.3   0.7   0:10.23 tuned
      1 root      20   0  186328  14108   9484 S   0.0   0.4   0:02.00 systemd
      2 root      20   0       0      0      0 S   0.0   0.0   0:00.01 kthread
...</pre><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
							We forced all the example processes to run on a single CPU for clearer illustration. The CPU weight applies the same principles also when used on multiple CPUs.
						</p></div></rh-alert><p class="simpara">
						Notice that the CPU resource for the <code class="literal">PID 33373</code>, <code class="literal">PID 33374</code>, and <code class="literal">PID 33377</code> was allocated based on the weights, 150, 100, 50, you assigned to the respective child cgroups. The weights correspond to around 50%, 33%, and 16% allocation of CPU time for each application.
					</p></li></ol></div></section><section class="section" id="proc_mounting-cgroups-v1_assembly_using-cgroupfs-to-manually-manage-cgroups"><div class="titlepage"><div><div><h3 class="title">35.3. Mounting cgroups-v1</h3></div></div></div><p>
				During the boot process, RHEL 9 mounts the <code class="literal">cgroup-v2</code> virtual filesystem by default. To utilize <code class="literal">cgroup-v1</code> functionality in limiting resources for your applications, manually configure the system.
			</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					Both <code class="literal">cgroup-v1</code> and <code class="literal">cgroup-v2</code> are fully enabled in the kernel. There is no default control group version from the kernel point of view, and is decided by <code class="literal">systemd</code> to mount at startup.
				</p></div></rh-alert><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have root permissions.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Configure the system to mount <code class="literal">cgroups-v1</code> by default during system boot by the <code class="literal">systemd</code> system and service manager:
					</p><pre class="literallayout white-space-pre"># <span class="strong strong"><strong>grubby --update-kernel=/boot/vmlinuz-$(uname -r) --args="systemd.unified_cgroup_hierarchy=0 systemd.legacy_systemd_cgroup_controller"</strong></span></pre><p class="simpara">
						This adds the necessary kernel command-line parameters to the current boot entry.
					</p><p class="simpara">
						To add the same parameters to all kernel boot entries:
					</p><pre class="literallayout white-space-pre"># <span class="strong strong"><strong>grubby --update-kernel=ALL --args="systemd.unified_cgroup_hierarchy=0 systemd.legacy_systemd_cgroup_controller"</strong></span></pre></li><li class="listitem">
						Reboot the system for the changes to take effect.
					</li></ol></div><div class="orderedlist"><p class="title"><strong>Verification</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Verify that the <code class="literal">cgroups-v1</code> filesystem was mounted:
					</p><pre class="literallayout white-space-pre"># <span class="strong strong"><strong>mount -l | grep cgroup</strong></span>
tmpfs on /sys/fs/cgroup type tmpfs (ro,nosuid,nodev,noexec,seclabel,size=4096k,nr_inodes=1024,mode=755,inode64)
cgroup on /sys/fs/cgroup/systemd type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,xattr,release_agent=/usr/lib/systemd/systemd-cgroups-agent,name=systemd)
cgroup on /sys/fs/cgroup/perf_event type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,perf_event)
cgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,cpu,cpuacct)
cgroup on /sys/fs/cgroup/pids type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,pids)
cgroup on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,cpuset)
cgroup on /sys/fs/cgroup/net_cls,net_prio type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,net_cls,net_prio)
cgroup on /sys/fs/cgroup/hugetlb type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,hugetlb)
cgroup on /sys/fs/cgroup/memory type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,memory)
cgroup on /sys/fs/cgroup/blkio type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,blkio)
cgroup on /sys/fs/cgroup/devices type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,devices)
cgroup on /sys/fs/cgroup/misc type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,misc)
cgroup on /sys/fs/cgroup/freezer type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,freezer)
cgroup on /sys/fs/cgroup/rdma type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,rdma)</pre><p class="simpara">
						The <code class="literal">cgroups-v1</code> filesystems that correspond to various <code class="literal">cgroup-v1</code> controllers, were successfully mounted on the <code class="literal">/sys/fs/cgroup/</code> directory.
					</p></li><li class="listitem"><p class="simpara">
						Inspect the contents of the <code class="literal">/sys/fs/cgroup/</code> directory:
					</p><pre class="literallayout"># <span class="strong strong"><strong>ll /sys/fs/cgroup/</strong></span>
dr-xr-xr-x. 10 root root  0 Mar 16 09:34 blkio
lrwxrwxrwx.  1 root root 11 Mar 16 09:34 cpu → cpu,cpuacct
lrwxrwxrwx.  1 root root 11 Mar 16 09:34 cpuacct → cpu,cpuacct
dr-xr-xr-x. 10 root root  0 Mar 16 09:34 cpu,cpuacct
dr-xr-xr-x.  2 root root  0 Mar 16 09:34 cpuset
dr-xr-xr-x. 10 root root  0 Mar 16 09:34 devices
dr-xr-xr-x.  2 root root  0 Mar 16 09:34 freezer
dr-xr-xr-x.  2 root root  0 Mar 16 09:34 hugetlb
dr-xr-xr-x. 10 root root  0 Mar 16 09:34 memory
dr-xr-xr-x.  2 root root  0 Mar 16 09:34 misc
lrwxrwxrwx.  1 root root 16 Mar 16 09:34 net_cls → net_cls,net_prio
dr-xr-xr-x.  2 root root  0 Mar 16 09:34 net_cls,net_prio
lrwxrwxrwx.  1 root root 16 Mar 16 09:34 net_prio → net_cls,net_prio
dr-xr-xr-x.  2 root root  0 Mar 16 09:34 perf_event
dr-xr-xr-x. 10 root root  0 Mar 16 09:34 pids
dr-xr-xr-x.  2 root root  0 Mar 16 09:34 rdma
dr-xr-xr-x. 11 root root  0 Mar 16 09:34 systemd</pre><p class="simpara">
						The <code class="literal">/sys/fs/cgroup/</code> directory, also called the <span class="emphasis"><em>root control group</em></span>, by default, contains controller-specific directories such as <code class="literal">cpuset</code>. In addition, there are some directories related to <code class="literal">systemd</code>.
					</p></li></ol></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="#what-kernel-resource-controllers-are_setting-limits-for-applications" title="34.2. Introducing kernel resource controllers">What are kernel resource controllers</a>
					</li><li class="listitem">
						<code class="literal">cgroups(7)</code>, <code class="literal">sysfs(5)</code> manual pages
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/9.0_release_notes/index#BZ-1953515">cgroup-v2 enabled by default in RHEL 9</a>
					</li></ul></div></section><section class="section" id="setting-cpu-limits-to-applications-using-cgroups-v1_assembly_using-cgroupfs-to-manually-manage-cgroups"><div class="titlepage"><div><div><h3 class="title">35.4. Setting CPU limits to applications using cgroups-v1</h3></div></div></div><p class="_abstract _abstract">
				To configure CPU limits to an application by using <span class="emphasis"><em>control groups version 1</em></span> (<code class="literal">cgroups-v1</code>), use the <code class="literal">/sys/fs/</code> virtual file system.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have root permissions.
					</li><li class="listitem">
						You have an application whose CPU consumption you want to restrict.
					</li><li class="listitem"><p class="simpara">
						You configured the system to mount <code class="literal">cgroups-v1</code> by default during system boot by the <code class="literal">systemd</code> system and service manager:
					</p><pre class="literallayout white-space-pre"># <span class="strong strong"><strong>grubby --update-kernel=/boot/vmlinuz-$(uname -r) --args="systemd.unified_cgroup_hierarchy=0 systemd.legacy_systemd_cgroup_controller"</strong></span></pre><p class="simpara">
						This adds the necessary kernel command-line parameters to the current boot entry.
					</p></li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Identify the process ID (PID) of the application that you want to restrict in CPU consumption:
					</p><pre class="literallayout white-space-pre"># <span class="strong strong"><strong>top</strong></span>
top - 11:34:09 up 11 min,  1 user,  load average: 0.51, 0.27, 0.22
Tasks: 267 total,   3 running, 264 sleeping,   0 stopped,   0 zombie
%Cpu(s): 49.0 us,  3.3 sy,  0.0 ni, 47.5 id,  0.0 wa,  0.2 hi,  0.0 si,  0.0 st
MiB Mem :   1826.8 total,    303.4 free,   1046.8 used,    476.5 buff/cache
MiB Swap:   1536.0 total,   1396.0 free,    140.0 used.    616.4 avail Mem

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND
 6955 root      20   0  228440   1752   1472 R  <span class="strong strong"><strong>99.3</strong></span>   0.1   0:32.71 sha1sum
 5760 jdoe      20   0 3603868 205188  64196 S   3.7  11.0   0:17.19 gnome-shell
 6448 jdoe      20   0  743648  30640  19488 S   0.7   1.6   0:02.73 gnome-terminal-
    1 root      20   0  245300   6568   4116 S   0.3   0.4   0:01.87 systemd
  505 root      20   0       0      0      0 I   0.3   0.0   0:00.75 kworker/u4:4-events_unbound
...</pre><p class="simpara">
						This example output of the <code class="literal">top</code> program reveals that illustrative application <code class="literal">sha1sum</code> with <code class="literal">PID 6955</code> consumes a lot of CPU resources.
					</p></li><li class="listitem"><p class="simpara">
						Create a sub-directory in the <code class="literal">cpu</code> resource controller directory:
					</p><pre class="literallayout"># <span class="strong strong"><strong>mkdir /sys/fs/cgroup/cpu/Example/</strong></span></pre><p class="simpara">
						This directory represents a control group, where you can place specific processes and apply certain CPU limits to the processes. At the same time, a number of <code class="literal">cgroups-v1</code> interface files and <code class="literal">cpu</code> controller-specific files will be created in the directory.
					</p></li><li class="listitem"><p class="simpara">
						Optional: Inspect the newly created control group:
					</p><pre class="literallayout"># <span class="strong strong"><strong>ll /sys/fs/cgroup/cpu/Example/</strong></span>
-rw-r—​r--. 1 root root 0 Mar 11 11:42 cgroup.clone_children
-rw-r—​r--. 1 root root 0 Mar 11 11:42 cgroup.procs
-r—​r—​r--. 1 root root 0 Mar 11 11:42 cpuacct.stat
-rw-r—​r--. 1 root root 0 Mar 11 11:42 cpuacct.usage
-r—​r—​r--. 1 root root 0 Mar 11 11:42 cpuacct.usage_all
-r—​r—​r--. 1 root root 0 Mar 11 11:42 cpuacct.usage_percpu
-r—​r—​r--. 1 root root 0 Mar 11 11:42 cpuacct.usage_percpu_sys
-r—​r—​r--. 1 root root 0 Mar 11 11:42 cpuacct.usage_percpu_user
-r—​r—​r--. 1 root root 0 Mar 11 11:42 cpuacct.usage_sys
-r—​r—​r--. 1 root root 0 Mar 11 11:42 cpuacct.usage_user
-rw-r—​r--. 1 root root 0 Mar 11 11:42 cpu.cfs_period_us
-rw-r—​r--. 1 root root 0 Mar 11 11:42 cpu.cfs_quota_us
-rw-r—​r--. 1 root root 0 Mar 11 11:42 cpu.rt_period_us
-rw-r—​r--. 1 root root 0 Mar 11 11:42 cpu.rt_runtime_us
-rw-r—​r--. 1 root root 0 Mar 11 11:42 cpu.shares
-r—​r—​r--. 1 root root 0 Mar 11 11:42 cpu.stat
-rw-r—​r--. 1 root root 0 Mar 11 11:42 notify_on_release
-rw-r—​r--. 1 root root 0 Mar 11 11:42 tasks</pre><p class="simpara">
						This example output shows files, such as <code class="literal">cpuacct.usage</code>, <code class="literal">cpu.cfs._period_us</code>, that represent specific configurations and/or limits, which can be set for processes in the <code class="literal">Example</code> control group. Note that the respective file names are prefixed with the name of the control group controller to which they belong.
					</p><p class="simpara">
						By default, the newly created control group inherits access to the system’s entire CPU resources without a limit.
					</p></li><li class="listitem"><p class="simpara">
						Configure CPU limits for the control group:
					</p><pre class="literallayout"># <span class="strong strong"><strong>echo "1000000" &gt; /sys/fs/cgroup/cpu/Example/cpu.cfs_period_us</strong></span>
# <span class="strong strong"><strong>echo "200000" &gt; /sys/fs/cgroup/cpu/Example/cpu.cfs_quota_us</strong></span></pre><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								The <code class="literal">cpu.cfs_period_us</code> file represents a period of time in microseconds (µs, represented here as "us") for how frequently a control group’s access to CPU resources should be reallocated. The upper limit is 1 000 000 microsecond and the lower limit is 1 000 microseconds.
							</li><li class="listitem"><p class="simpara">
								The <code class="literal">cpu.cfs_quota_us</code> file represents the total amount of time in microseconds for which all processes collectively in a control group can run during one period (as defined by <code class="literal">cpu.cfs_period_us</code>). When processes in a control group, during a single period, use up all the time specified by the quota, they are throttled for the remainder of the period and not allowed to run until the next period. The lower limit is 1 000 microseconds.
							</p><p class="simpara">
								The example commands above set the CPU time limits so that all processes collectively in the <code class="literal">Example</code> control group will be able to run only for 0.2 seconds (defined by <code class="literal">cpu.cfs_quota_us</code>) out of every 1 second (defined by <code class="literal">cpu.cfs_period_us</code>).
							</p></li></ul></div></li><li class="listitem"><p class="simpara">
						Optional: Verify the limits:
					</p><pre class="literallayout"># <span class="strong strong"><strong>cat /sys/fs/cgroup/cpu/Example/cpu.cfs_period_us /sys/fs/cgroup/cpu/Example/cpu.cfs_quota_us</strong></span>
1000000
200000</pre></li><li class="listitem"><p class="simpara">
						Add the application’s PID to the <code class="literal">Example</code> control group:
					</p><pre class="literallayout"># <span class="strong strong"><strong>echo "6955" &gt; /sys/fs/cgroup/cpu/Example/cgroup.procs</strong></span></pre><p class="simpara">
						This command ensures that a specific application becomes a member of the <code class="literal">Example</code> control group and hence does not exceed the CPU limits configured for the <code class="literal">Example</code> control group. The PID should represent an existing process in the system. The <code class="literal">PID 6955</code> here was assigned to process <code class="literal">sha1sum /dev/zero &amp;</code>, used to illustrate the use case of the <code class="literal">cpu</code> controller.
					</p></li></ol></div><div class="orderedlist"><p class="title"><strong>Verification</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Verify that the application runs in the specified control group:
					</p><pre class="literallayout"># <span class="strong strong"><strong>cat /proc/6955/cgroup</strong></span>
12:cpuset:/
11:hugetlb:/
10:net_cls,net_prio:/
9:memory:/user.slice/user-1000.slice/user@1000.service
8:devices:/user.slice
7:blkio:/
6:freezer:/
5:rdma:/
4:pids:/user.slice/user-1000.slice/user@1000.service
3:perf_event:/
2:cpu,cpuacct:/Example
1:name=systemd:/user.slice/user-1000.slice/user@1000.service/gnome-terminal-server.service</pre><p class="simpara">
						This example output shows that the process of the desired application runs in the <code class="literal">Example</code> control group, which applies CPU limits to the application’s process.
					</p></li><li class="listitem"><p class="simpara">
						Identify the current CPU consumption of your throttled application:
					</p><pre class="literallayout white-space-pre"># <span class="strong strong"><strong>top</strong></span>
top - 12:28:42 up  1:06,  1 user,  load average: 1.02, 1.02, 1.00
Tasks: 266 total,   6 running, 260 sleeping,   0 stopped,   0 zombie
%Cpu(s): 11.0 us,  1.2 sy,  0.0 ni, 87.5 id,  0.0 wa,  0.2 hi,  0.0 si,  0.2 st
MiB Mem :   1826.8 total,    287.1 free,   1054.4 used,    485.3 buff/cache
MiB Swap:   1536.0 total,   1396.7 free,    139.2 used.    608.3 avail Mem

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND
 6955 root      20   0  228440   1752   1472 R  <span class="strong strong"><strong>20.6</strong></span>   0.1  47:11.43 sha1sum
 5760 jdoe      20   0 3604956 208832  65316 R   2.3  11.2   0:43.50 gnome-shell
 6448 jdoe      20   0  743836  31736  19488 S   0.7   1.7   0:08.25 gnome-terminal-
  505 root      20   0       0      0      0 I   0.3   0.0   0:03.39 kworker/u4:4-events_unbound
 4217 root      20   0   74192   1612   1320 S   0.3   0.1   0:01.19 spice-vdagentd
...</pre><p class="simpara">
						Note that the CPU consumption of the <code class="literal">PID 6955</code> has decreased from 99% to 20%.
					</p></li></ol></div><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					The <code class="literal">cgroups-v2</code> counterpart for <code class="literal">cpu.cfs_period_us</code> and <code class="literal">cpu.cfs_quota_us</code> is the <code class="literal">cpu.max</code> file. The <code class="literal">cpu.max</code> file is available through the <code class="literal">cpu</code> controller.
				</p></div></rh-alert><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="#what-kernel-resource-controllers-are_setting-limits-for-applications" title="34.2. Introducing kernel resource controllers">Introducing kernel resource controllers</a>
					</li><li class="listitem">
						<code class="literal">cgroups(7)</code>, <code class="literal">sysfs(5)</code> manual pages
					</li></ul></div></section></section><section class="chapter" id="analyzing-system-performance-with-bpf-compiler_collection_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 36. Analyzing system performance with BPF Compiler Collection</h2></div></div></div><p class="_abstract _abstract">
			As a system administrator, you can use the BPF Compiler Collection (BCC) library to create tools for analyzing the performance of your Linux operating system and gathering information, which could be difficult to obtain through other interfaces.
		</p><section class="section" id="installing-the-bcc-tools-package_analyzing-system-performance-with-bpf-compiler_collection"><div class="titlepage"><div><div><h3 class="title">36.1. Installing the bcc-tools package</h3></div></div></div><p class="_abstract _abstract">
				Install the <code class="literal">bcc-tools</code> package, which also installs the BPF Compiler Collection (BCC) library as a dependency.
			</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Install <code class="literal">bcc-tools</code>.
					</p><pre class="literallayout"># <span class="strong strong"><strong>dnf install bcc-tools</strong></span></pre><p class="simpara">
						The BCC tools are installed in the <code class="literal">/usr/share/bcc/tools/</code> directory.
					</p></li></ul></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Inspect the installed tools:
					</p><pre class="literallayout"># <span class="strong strong"><strong>ls -l /usr/share/bcc/tools/</strong></span>
...
-rwxr-xr-x. 1 root root  4198 Dec 14 17:53 dcsnoop
-rwxr-xr-x. 1 root root  3931 Dec 14 17:53 dcstat
-rwxr-xr-x. 1 root root 20040 Dec 14 17:53 deadlock_detector
-rw-r--r--. 1 root root  7105 Dec 14 17:53 deadlock_detector.c
drwxr-xr-x. 3 root root  8192 Mar 11 10:28 doc
-rwxr-xr-x. 1 root root  7588 Dec 14 17:53 execsnoop
-rwxr-xr-x. 1 root root  6373 Dec 14 17:53 ext4dist
-rwxr-xr-x. 1 root root 10401 Dec 14 17:53 ext4slower
...</pre><p class="simpara">
						The <code class="literal systemitem">doc</code> directory in the listing above contains documentation for each tool.
					</p></li></ul></div></section><section class="section" id="using-selected-bcc-tools-for-performance-analyses_analyzing-system-performance-with-bpf-compiler_collection"><div class="titlepage"><div><div><h3 class="title">36.2. Using selected bcc-tools for performance analyses</h3></div></div></div><p class="_abstract _abstract">
				Use certain pre-created programs from the BPF Compiler Collection (BCC) library to efficiently and securely analyze the system performance on the per-event basis. The set of pre-created programs in the BCC library can serve as examples for creation of additional programs.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						<a class="link" href="#installing-the-bcc-tools-package_analyzing-system-performance-with-bpf-compiler_collection" title="36.1. Installing the bcc-tools package">Installed bcc-tools package</a>
					</li><li class="listitem">
						Root permissions
					</li></ul></div><div class="variablelist"><p class="title"><strong>Procedure</strong></p><dl class="variablelist"><dt><span class="term">Using execsnoop to examine the system processes</span></dt><dd><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
									Run the <code class="literal">execsnoop</code> program in one terminal:
								</li></ol></div><pre class="screen"># <span class="strong strong"><strong>/usr/share/bcc/tools/execsnoop</strong></span></pre><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
									In another terminal run, for example:
								</p><pre class="screen">$ <span class="strong strong"><strong>ls /usr/share/bcc/tools/doc/</strong></span></pre><p class="simpara">
									The above creates a short-lived process of the <code class="literal">ls</code> command.
								</p></li><li class="listitem"><p class="simpara">
									The terminal running <code class="literal">execsnoop</code> shows the output similar to the following:
								</p><pre class="screen">PCOMM	PID    PPID   RET ARGS
ls   	8382   8287     0 /usr/bin/ls --color=auto /usr/share/bcc/tools/doc/
...</pre><p class="simpara">
									The <code class="literal">execsnoop</code> program prints a line of output for each new process, which consumes system resources. It even detects processes of programs that run very shortly, such as <code class="literal">ls</code>, and most monitoring tools would not register them.
								</p><p class="simpara">
									The <code class="literal">execsnoop</code> output displays the following fields:
								</p></li></ol></div></dd><dt><span class="term">PCOMM</span></dt><dd>
							The parent process name. (<code class="literal">ls</code>)
						</dd><dt><span class="term">PID</span></dt><dd>
							The process ID. (<code class="literal">8382</code>)
						</dd><dt><span class="term">PPID</span></dt><dd>
							The parent process ID. (<code class="literal">8287</code>)
						</dd><dt><span class="term">RET</span></dt><dd>
							The return value of the <code class="literal">exec()</code> system call (<code class="literal">0</code>), which loads program code into new processes.
						</dd><dt><span class="term">ARGS</span></dt><dd>
							The location of the started program with arguments.
						</dd></dl></div><p>
				To see more details, examples, and options for <code class="literal">execsnoop</code>, refer to the <code class="literal">/usr/share/bcc/tools/doc/execsnoop_example.txt</code> file.
			</p><p>
				For more information about <code class="literal">exec()</code>, see <code class="literal">exec(3)</code> manual pages.
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">Using opensnoop to track what files a command opens</span></dt><dd><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
									Run the <code class="literal">opensnoop</code> program in one terminal:
								</li></ol></div><pre class="screen"># <span class="strong strong"><strong>/usr/share/bcc/tools/opensnoop -n uname</strong></span></pre><p class="simpara">
							The above prints output for files, which are opened only by the process of the <code class="literal">uname</code> command.
						</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
									In another terminal, enter:
								</p><pre class="screen">$ <span class="strong strong"><strong>uname</strong></span></pre><p class="simpara">
									The command above opens certain files, which are captured in the next step.
								</p></li><li class="listitem"><p class="simpara">
									The terminal running <code class="literal">opensnoop</code> shows the output similar to the following:
								</p><pre class="screen">PID    COMM 	FD ERR PATH
8596   uname 	3  0   /etc/ld.so.cache
8596   uname 	3  0   /lib64/libc.so.6
8596   uname 	3  0   /usr/lib/locale/locale-archive
...</pre><p class="simpara">
									The <code class="literal">opensnoop</code> program watches the <code class="literal">open()</code> system call across the whole system, and prints a line of output for each file that <code class="literal">uname</code> tried to open along the way.
								</p><p class="simpara">
									The <code class="literal">opensnoop</code> output displays the following fields:
								</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">PID</span></dt><dd>
												The process ID. (<code class="literal">8596</code>)
											</dd><dt><span class="term">COMM</span></dt><dd>
												The process name. (<code class="literal">uname</code>)
											</dd><dt><span class="term">FD</span></dt><dd>
												The file descriptor - a value that <code class="literal">open()</code> returns to refer to the open file. (<code class="literal">3</code>)
											</dd><dt><span class="term">ERR</span></dt><dd>
												Any errors.
											</dd><dt><span class="term">PATH</span></dt><dd>
												The location of files that <code class="literal">open()</code> tried to open.
											</dd></dl></div><p class="simpara">
									If a command tries to read a non-existent file, then the <code class="literal">FD</code> column returns <code class="literal">-1</code> and the <code class="literal">ERR</code> column prints a value corresponding to the relevant error. As a result, <code class="literal">opensnoop</code> can help you identify an application that does not behave properly.
								</p></li></ol></div></dd></dl></div><p>
				To see more details, examples, and options for <code class="literal">opensnoop</code>, refer to the <code class="literal">/usr/share/bcc/tools/doc/opensnoop_example.txt</code> file.
			</p><p>
				For more information about <code class="literal">open()</code>, see <code class="literal">open(2)</code> manual pages.
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">Using biotop to examine the I/O operations on the disk</span></dt><dd><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
									Run the <code class="literal">biotop</code> program in one terminal:
								</li></ol></div><pre class="screen"># <span class="strong strong"><strong>/usr/share/bcc/tools/biotop 30</strong></span></pre><p class="simpara">
							The command enables you to monitor the top processes, which perform I/O operations on the disk. The argument ensures that the command will produce a 30 second summary.
						</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
								When no argument provided, the output screen by default refreshes every 1 second.
							</p></div></rh-alert><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
									In another terminal enter, for example :
								</p><pre class="screen"># <span class="strong strong"><strong>dd if=/dev/vda of=/dev/zero</strong></span></pre><p class="simpara">
									The command above reads the content from the local hard disk device and writes the output to the <code class="literal">/dev/zero</code> file. This step generates certain I/O traffic to illustrate <code class="literal">biotop</code>.
								</p></li><li class="listitem"><p class="simpara">
									The terminal running <code class="literal">biotop</code> shows the output similar to the following:
								</p><pre class="screen">PID    COMM             D MAJ MIN DISK       I/O  Kbytes     AVGms
9568   dd               R 252 0   vda      16294 14440636.0  3.69
48     kswapd0          W 252 0   vda       1763 120696.0    1.65
7571   gnome-shell      R 252 0   vda        834 83612.0     0.33
1891   gnome-shell      R 252 0   vda       1379 19792.0     0.15
7515   Xorg             R 252 0   vda        280  9940.0     0.28
7579   llvmpipe-1       R 252 0   vda        228  6928.0     0.19
9515   gnome-control-c  R 252 0   vda         62  6444.0     0.43
8112   gnome-terminal-  R 252 0   vda         67  2572.0     1.54
7807   gnome-software   R 252 0   vda         31  2336.0     0.73
9578   awk              R 252 0   vda         17  2228.0     0.66
7578   llvmpipe-0       R 252 0   vda        156  2204.0     0.07
9581   pgrep            R 252 0   vda         58  1748.0     0.42
7531   InputThread      R 252 0   vda         30  1200.0     0.48
7504   gdbus            R 252 0   vda          3  1164.0     0.30
1983   llvmpipe-1       R 252 0   vda         39   724.0     0.08
1982   llvmpipe-0       R 252 0   vda         36   652.0     0.06
...</pre><p class="simpara">
									The <code class="literal">biotop</code> output displays the following fields:
								</p></li></ol></div></dd><dt><span class="term">PID</span></dt><dd>
							The process ID. (<code class="literal">9568</code>)
						</dd><dt><span class="term">COMM</span></dt><dd>
							The process name. (<code class="literal">dd</code>)
						</dd><dt><span class="term">DISK</span></dt><dd>
							The disk performing the read operations. (<code class="literal">vda</code>)
						</dd><dt><span class="term">I/O</span></dt><dd>
							The number of read operations performed. (16294)
						</dd><dt><span class="term">Kbytes</span></dt><dd>
							The amount of Kbytes reached by the read operations. (14,440,636)
						</dd><dt><span class="term">AVGms</span></dt><dd>
							The average I/O time of read operations. (3.69)
						</dd></dl></div><p>
				To see more details, examples, and options for <code class="literal">biotop</code>, refer to the <code class="literal">/usr/share/bcc/tools/doc/biotop_example.txt</code> file.
			</p><p>
				For more information about <code class="literal">dd</code>, see <code class="literal">dd(1)</code> manual pages.
			</p><h5 id="using_xfsslower_to_expose_unexpectedly_slow_file_system_operations">Using xfsslower to expose unexpectedly slow file system operations</h5><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Run the <code class="literal">xfsslower</code> program in one terminal:
					</p><pre class="screen"># <span class="strong strong"><strong>/usr/share/bcc/tools/xfsslower 1</strong></span></pre><p class="simpara">
						The command above measures the time the XFS file system spends in performing read, write, open or sync (<code class="literal">fsync</code>) operations. The <code class="literal">1</code> argument ensures that the program shows only the operations that are slower than 1 ms.
					</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
							When no arguments provided, <code class="literal">xfsslower</code> by default displays operations slower than 10 ms.
						</p></div></rh-alert></li><li class="listitem"><p class="simpara">
						In another terminal enter, for example, the following:
					</p><pre class="screen">$ <span class="strong strong"><strong>vim text</strong></span></pre><p class="simpara">
						The command above creates a text file in the <code class="literal">vim</code> editor to initiate certain interaction with the XFS file system.
					</p></li><li class="listitem"><p class="simpara">
						The terminal running <code class="literal">xfsslower</code> shows something similar upon saving the file from the previous step:
					</p><pre class="screen">TIME     COMM           PID    T BYTES   OFF_KB   LAT(ms) FILENAME
13:07:14 b'bash'        4754   R 256     0           7.11 b'vim'
13:07:14 b'vim'         4754   R 832     0           4.03 b'libgpm.so.2.1.0'
13:07:14 b'vim'         4754   R 32      20          1.04 b'libgpm.so.2.1.0'
13:07:14 b'vim'         4754   R 1982    0           2.30 b'vimrc'
13:07:14 b'vim'         4754   R 1393    0           2.52 b'getscriptPlugin.vim'
13:07:45 b'vim'         4754   S 0       0           6.71 b'text'
13:07:45 b'pool'        2588   R 16      0           5.58 b'text'
...</pre><p class="simpara">
						Each line above represents an operation in the file system, which took more time than a certain threshold. <code class="literal">xfsslower</code> is good at exposing possible file system problems, which can take form of unexpectedly slow operations.
					</p><p class="simpara">
						The <code class="literal">xfsslower</code> output displays the following fields:
					</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">COMM</span></dt><dd>
									The process name. (<code class="literal">b’bash'</code>)
								</dd><dt><span class="term">T</span></dt><dd><p class="simpara">
									The operation type. (<code class="literal">R</code>)
								</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
											<span class="strong strong"><strong>R</strong></span>ead
										</li><li class="listitem">
											<span class="strong strong"><strong>W</strong></span>rite
										</li><li class="listitem">
											<span class="strong strong"><strong>S</strong></span>ync
										</li></ul></div></dd><dt><span class="term">OFF_KB</span></dt><dd>
									The file offset in KB. (0)
								</dd><dt><span class="term">FILENAME</span></dt><dd>
									The file being read, written, or synced.
								</dd></dl></div></li></ol></div><p>
				To see more details, examples, and options for <code class="literal">xfsslower</code>, refer to the <code class="literal">/usr/share/bcc/tools/doc/xfsslower_example.txt</code> file.
			</p><p>
				For more information about <code class="literal">fsync</code>, see <code class="literal">fsync(2)</code> manual pages.
			</p></section></section><section class="chapter" id="configuring-an-operating-system-to-optimize-memory-access_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 37. Configuring an operating system to optimize memory access</h2></div></div></div><p class="_abstract _abstract">
			You can configure the operating system to optimize memory access across workloads with the tools that are included in RHEL
		</p><section class="section" id="tools-for-monitoring-and-diagnosing-system-memory-issues_configuring-an-operating-system-to-optimize-memory-access"><div class="titlepage"><div><div><h3 class="title">37.1. Tools for monitoring and diagnosing system memory issues</h3></div></div></div><p class="_abstract _abstract">
				The following tools are available in Red Hat Enterprise Linux 9 for monitoring system performance and diagnosing performance problems related to system memory:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						<code class="literal">vmstat</code> tool, provided by the <code class="literal">procps-ng</code> package, displays reports of a system’s processes, memory, paging, block I/O, traps, disks, and CPU activity. It provides an instantaneous report of the average of these events since the machine was last turned on, or since the previous report.
					</li><li class="listitem"><p class="simpara">
						<code class="literal">valgrind</code> framework provides instrumentation to user-space binaries. Install this tool, using the <code class="literal">dnf install valgrind</code> command. It includes a number of tools, that you can use to profile and analyze program performance, such as:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem"><p class="simpara">
								<code class="literal">memcheck</code> option is the default <code class="literal">valgrind</code> tool. It detects and reports on a number of memory errors that can be difficult to detect and diagnose, such as:
							</p><div class="itemizedlist"><ul class="itemizedlist" type="square"><li class="listitem">
										Memory access that should not occur
									</li><li class="listitem">
										Undefined or uninitialized value use
									</li><li class="listitem">
										Incorrectly freed heap memory
									</li><li class="listitem">
										Pointer overlap
									</li><li class="listitem"><p class="simpara">
										Memory leaks
									</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
											Memcheck can only report these errors, it cannot prevent them from occurring. However, <code class="literal">memcheck</code> logs an error message immediately before the error occurs.
										</p></div></rh-alert></li></ul></div></li><li class="listitem">
								<code class="literal">cachegrind</code> option simulates application interaction with a system’s cache hierarchy and branch predictor. It gathers statistics for the duration of application’s execution and outputs a summary to the console.
							</li><li class="listitem">
								<code class="literal">massif</code> option measures the heap space used by a specified application. It measures both useful space and any additional space allocated for bookkeeping and alignment purposes.
							</li></ul></div></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">vmstat(8)</code> and <code class="literal">valgrind(1)</code> man pages on your system
					</li><li class="listitem">
						<code class="literal">/usr/share/doc/valgrind-version/valgrind_manual.pdf</code> file
					</li></ul></div></section><section class="section" id="overview-of-a-systems-memory_configuring-an-operating-system-to-optimize-memory-access"><div class="titlepage"><div><div><h3 class="title">37.2. Overview of a system’s memory</h3></div></div></div><p class="_abstract _abstract">
				The Linux Kernel is designed to maximize the utilization of a system’s memory resources (RAM). Due to these design characteristics, and depending on the memory requirements of the workload, part of the system’s memory is in use within the kernel on behalf of the workload, while a small part of the memory is free. This free memory is reserved for special system allocations, and for other low or high priority system services.
			</p><p>
				The rest of the system’s memory is dedicated to the workload itself, and divided into the following two categories:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">File memory</code></span></dt><dd><p class="simpara">
							Pages added in this category represent parts of files in permanent storage. These pages, from the page cache, can be mapped or unmapped in an application’s address spaces. You can use applications to map files into their address space using the <code class="literal">mmap</code> system calls, or to operate on files via the buffered I/O read or write system calls.
						</p><p class="simpara">
							Buffered I/O system calls, as well as applications that map pages directly, can re-utilize unmapped pages. As a result, these pages are stored in the cache by the kernel, especially when the system is not running any memory intensive tasks, to avoid re-issuing costly I/O operations over the same set of pages.
						</p></dd><dt><span class="term"><code class="literal">Anonymous memory</code></span></dt><dd>
							Pages in this category are in use by a dynamically allocated process, or are not related to files in permanent storage. This set of pages back up the in-memory control structures of each task, such as the application stack and heap areas.
						</dd></dl></div><div class="figure" id="idm140280130515456"><p class="title"><strong>Figure 37.1. Memory usage patterns</strong></p><div class="figure-contents"><div class="mediaobject"><img src="https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/81d9c47bcca9529ab234cc7297b69aad/RHEL_Memory_Usage_Patterns.png" alt="RHEL Memory Usage Patterns"></div></div></div></section><section class="section" id="virtual-memory-parameters_configuring-an-operating-system-to-optimize-memory-access"><div class="titlepage"><div><div><h3 class="title">37.3. Virtual memory parameters</h3></div></div></div><p class="_abstract _abstract">
				The virtual memory parameters are listed in the <code class="literal">/proc/sys/vm</code> directory.
			</p><p>
				The following are the available virtual memory parameters:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">vm.dirty_ratio</code></span></dt><dd>
							Is a percentage value. When this percentage of the total system memory is modified, the system begins writing the modifications to the disk. The default value is <code class="literal">20</code> percent.
						</dd><dt><span class="term"><code class="literal">vm.dirty_background_ratio</code></span></dt><dd>
							A percentage value. When this percentage of total system memory is modified, the system begins writing the modifications to the disk in the background. The default value is <code class="literal">10</code> percent.
						</dd><dt><span class="term"><code class="literal">vm.overcommit_memory</code></span></dt><dd><p class="simpara">
							Defines the conditions that determine whether a large memory request is accepted or denied.The default value is <code class="literal">0</code>.
						</p><p class="simpara">
							By default, the kernel performs checks if a virtual memory allocation request fits into the present amount of memory (total + swap) and rejects only large requests. Otherwise virtual memory allocations are granted, and this means they allow memory overcommitment.
						</p><p class="simpara">
							Setting the <code class="literal">overcommit_memory</code> parameter’s value:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									When this parameter is set to <code class="literal">1</code>, the kernel performs no memory overcommit handling. This increases the possibility of memory overload, but improves performance for memory-intensive tasks.
								</li><li class="listitem">
									When this parameter is set to <code class="literal">2</code>, the kernel denies requests for memory equal to or larger than the sum of the total available swap space and the percentage of physical RAM specified in the <code class="literal">overcommit_ratio</code>. This reduces the risk of overcommitting memory, but is recommended only for systems with swap areas larger than their physical memory.
								</li></ul></div></dd><dt><span class="term"><code class="literal">vm.overcommit_ratio</code></span></dt><dd>
							Specifies the percentage of physical RAM considered when <code class="literal">overcommit_memory</code> is set to <code class="literal">2</code>. The default value is <code class="literal">50</code>.
						</dd><dt><span class="term"><code class="literal">vm.max_map_count</code></span></dt><dd>
							Defines the maximum number of memory map areas that a process can use. The default value is <code class="literal">65530</code>. Increase this value if your application needs more memory map areas.
						</dd><dt><span class="term"><code class="literal">vm.min_free_kbytes</code></span></dt><dd><p class="simpara">
							Sets the size of the reserved free pages pool. It is also responsible for setting the <code class="literal">min_page</code>, <code class="literal">low_page</code>, and <code class="literal">high_page</code> thresholds that govern the behavior of the Linux kernel’s page reclaim algorithms. It also specifies the minimum number of kilobytes to keep free across the system. This calculates a specific value for each low memory zone, each of which is assigned a number of reserved free pages in proportion to their size.
						</p><p class="simpara">
							Setting the <code class="literal">vm.min_free_kbytes</code> parameter’s value:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									Increasing the parameter value effectively reduces the application working set usable memory. Therefore, you might want to use it for only kernel-driven workloads, where driver buffers need to be allocated in atomic contexts.
								</li><li class="listitem"><p class="simpara">
									Decreasing the parameter value might render the kernel unable to service system requests, if memory becomes heavily contended in the system.
								</p><rh-alert class="admonition warning" state="danger"><div class="admonition_header" slot="header">Warning</div><div><p>
										Extreme values can be detrimental to the system’s performance. Setting the <code class="literal">vm.min_free_kbytes</code> to an extremely low value prevents the system from reclaiming memory effectively, which can result in system crashes and failure to service interrupts or other kernel services. However, setting <code class="literal">vm.min_free_kbytes</code> too high considerably increases system reclaim activity, causing allocation latency due to a false direct reclaim state. This might cause the system to enter an out-of-memory state immediately.
									</p></div></rh-alert><p class="simpara">
									The <code class="literal">vm.min_free_kbytes</code> parameter also sets a page reclaim watermark, called <code class="literal">min_pages</code>. This watermark is used as a factor when determining the two other memory watermarks, <code class="literal">low_pages</code>, and <code class="literal">high_pages</code>, that govern page reclaim algorithms.
								</p></li></ul></div></dd><dt><span class="term"><code class="literal">/proc/<span class="emphasis"><em>PID</em></span>/oom_adj</code></span></dt><dd><p class="simpara">
							In the event that a system runs out of memory, and the <code class="literal">panic_on_oom</code> parameter is set to <code class="literal">0</code>, the <code class="literal">oom_killer</code> function kills processes, starting with the process that has the highest <code class="literal">oom_score</code>, until the system recovers.
						</p><p class="simpara">
							The <code class="literal">oom_adj</code> parameter determines the <code class="literal">oom_score</code> of a process. This parameter is set per process identifier. A value of <code class="literal">-17</code> disables the <code class="literal">oom_killer</code> for that process. Other valid values range from <code class="literal">-16</code> to <code class="literal">15</code>.
						</p></dd></dl></div><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					Processes created by an adjusted process inherit the <code class="literal">oom_score</code> of that process.
				</p></div></rh-alert><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">vm.swappiness</code></span></dt><dd><p class="simpara">
							The swappiness value, ranging from <code class="literal">0</code> to <code class="literal">200</code>, controls the degree to which the system favors reclaiming memory from the anonymous memory pool, or the page cache memory pool.
						</p><p class="simpara">
							Setting the <code class="literal">swappiness</code> parameter’s value:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									Higher values favor file-mapped driven workloads while swapping out the less actively accessed processes’ anonymous mapped memory of RAM. This is useful for file-servers or streaming applications that depend on data, from files in the storage, to reside on memory to reduce I/O latency for the service requests.
								</li><li class="listitem"><p class="simpara">
									Low values favor anonymous-mapped driven workloads while reclaiming the page cache (file mapped memory). This setting is useful for applications that do not depend heavily on the file system information, and heavily utilize dynamically allocated and private memory, such as mathematical and number crunching applications, and few hardware virtualization supervisors like QEMU.
								</p><p class="simpara">
									The default value of the <code class="literal">vm.swappiness</code> parameter is <code class="literal">60</code>.
								</p><rh-alert class="admonition warning" state="danger"><div class="admonition_header" slot="header">Warning</div><div><p>
										Setting the <code class="literal">vm.swappiness</code> to <code class="literal">0</code> aggressively avoids swapping anonymous memory out to a disk, this increases the risk of processes being killed by the <code class="literal">oom_killer</code> function when under memory or I/O intensive workloads.
									</p></div></rh-alert></li></ul></div></dd></dl></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">sysctl(8)</code> man page on your system
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index#setting-memory-related-kernel-parameters_configuring-an-operating-system-to-optimize-memory-access">Setting memory-related kernel parameters</a>
					</li></ul></div></section><section class="section" id="file-system-parameters_configuring-an-operating-system-to-optimize-memory-access"><div class="titlepage"><div><div><h3 class="title">37.4. File system parameters</h3></div></div></div><p class="_abstract _abstract">
				The file system parameters are listed in the <code class="literal">/proc/sys/fs</code> directory. The following are the available file system parameters:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">aio-max-nr</code></span></dt><dd>
							Defines the maximum allowed number of events in all active asynchronous input/output contexts. The default value is <code class="literal">65536</code>, and modifying this value does not pre-allocate or resize any kernel data structures.
						</dd><dt><span class="term"><code class="literal">file-max</code></span></dt><dd><p class="simpara">
							Determines the maximum number of file handles for the entire system. The default value on Red Hat Enterprise Linux 9 is either <code class="literal">8192</code> or one tenth of the free memory pages available at the time the kernel starts, whichever is higher.
						</p><p class="simpara">
							Raising this value can resolve errors caused by a lack of available file handles.
						</p></dd></dl></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">sysctl(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="kernel-parameters_configuring-an-operating-system-to-optimize-memory-access"><div class="titlepage"><div><div><h3 class="title">37.5. Kernel parameters</h3></div></div></div><p class="_abstract _abstract">
				The default values for the kernel parameters are located in the <code class="literal">/proc/sys/kernel/</code> directory. These are set default values provided by the kernel or values specified by a user via <code class="literal">sysctl</code>.
			</p><p>
				The following are the available kernel parameters used to set up limits for the <code class="literal">msg*</code> and <code class="literal">shm*</code> System V IPC (<code class="literal">sysvipc</code>) system calls:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">msgmax</code></span></dt><dd>
							Defines the maximum allowed size in bytes of any single message in a message queue. This value must not exceed the size of the queue (<code class="literal">msgmnb</code>). Use the <code class="literal">sysctl msgmax</code> command to determine the current <code class="literal">msgmax</code> value on your system.
						</dd><dt><span class="term"><code class="literal">msgmnb</code></span></dt><dd>
							Defines the maximum size in bytes of a single message queue. Use the <code class="literal">sysctl msgmnb</code> command to determine the current <code class="literal">msgmnb</code> value on your system.
						</dd><dt><span class="term"><code class="literal">msgmni</code></span></dt><dd>
							Defines the maximum number of message queue identifiers, and therefore the maximum number of queues. Use the <code class="literal">sysctl msgmni</code> command to determine the current <code class="literal">msgmni</code> value on your system.
						</dd><dt><span class="term"><code class="literal">shmall</code></span></dt><dd>
							Defines the total amount of shared memory <code class="literal">pages</code> that can be used on the system at one time. For example, a page is <code class="literal">4096</code> bytes on the AMD64 and Intel 64 architecture. Use the <code class="literal">sysctl shmall</code> command to determine the current <code class="literal">shmall</code> value on your system.
						</dd><dt><span class="term"><code class="literal">shmmax</code></span></dt><dd>
							Defines the maximum size in bytes of a single shared memory segment allowed by the kernel. Shared memory segments up to 1Gb are now supported in the kernel. Use the <code class="literal">sysctl shmmax</code> command to determine the current <code class="literal">shmmax</code> value on your system.
						</dd><dt><span class="term"><code class="literal">shmmni</code></span></dt><dd>
							Defines the system-wide maximum number of shared memory segments. The default value is <code class="literal">4096</code> on all systems.
						</dd></dl></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">sysvipc(7)</code> and <code class="literal">sysctl(8)</code> man pages on your system
					</li></ul></div></section><section class="section" id="setting-memory-related-kernel-parameters_configuring-an-operating-system-to-optimize-memory-access"><div class="titlepage"><div><div><h3 class="title">37.6. Setting memory-related kernel parameters</h3></div></div></div><p class="_abstract _abstract">
				Setting a parameter temporarily is useful for determining the effect the parameter has on a system. You can later set the parameter persistently when you are sure that the parameter value has the desired effect.
			</p><p>
				This procedure describes how to set a memory-related kernel parameter temporarily and persistently.
			</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						To temporarily set the memory-related kernel parameters, edit the respective files in the <code class="literal">/proc</code> file system or the <code class="literal">sysctl</code> tool.
					</p><p class="simpara">
						For example, to temporarily set the <code class="literal">vm.overcommit_memory</code> parameter to <span class="emphasis"><em>1</em></span>:
					</p><pre class="screen"># echo <span class="emphasis"><em>1</em></span> &gt; /proc/sys/vm/overcommit_memory
# sysctl -w vm.overcommit_memory=<span class="emphasis"><em>1</em></span></pre></li><li class="listitem"><p class="simpara">
						To persistently set the memory-related kernel parameter, edit the <code class="literal">/etc/sysctl.conf</code> file and reload the settings.
					</p><p class="simpara">
						For example, to persistently set the <code class="literal">vm.overcommit_memory</code> parameter to <span class="emphasis"><em>1</em></span>:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem"><p class="simpara">
								Add the following content in the <code class="literal">/etc/sysctl.conf</code> file:
							</p><pre class="screen">vm.overcommit_memory=<span class="emphasis"><em>1</em></span></pre></li><li class="listitem"><p class="simpara">
								Reload the <code class="literal">sysctl</code> settings from the <code class="literal">/etc/sysctl.conf</code> file:
							</p><pre class="screen"># sysctl -p</pre></li></ul></div></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">sysctl(8)</code> and <code class="literal">proc(5)</code> man pages on your system
					</li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/solutions/3530941">Tuning Red Hat Enterprise Linux for IBM DB2</a> (Red Hat Knowledgebase)
					</li></ul></div></section></section><section class="chapter" id="configuring-huge-pages_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 38. Configuring huge pages</h2></div></div></div><p class="_abstract _abstract">
			Physical memory is managed in fixed-size chunks called pages. On the x86_64 architecture, supported by Red Hat Enterprise Linux 9, the default size of a memory page is <code class="literal">4 KB</code>. This default page size has proved to be suitable for general-purpose operating systems, such as Red Hat Enterprise Linux, which supports many different kinds of workloads.
		</p><p>
			However, specific applications can benefit from using larger page sizes in certain cases. For example, an application that works with a large and relatively fixed data set of hundreds of megabytes or even dozens of gigabytes can have performance issues when using <code class="literal">4 KB</code> pages. Such data sets can require a huge amount of <code class="literal">4 KB</code> pages, which can lead to overhead in the operating system and the CPU.
		</p><p>
			This section provides information about huge pages available in RHEL 9 and how you can configure them.
		</p><section class="section" id="available-hugepage-features_configuring-huge-pages"><div class="titlepage"><div><div><h3 class="title">38.1. Available huge page features</h3></div></div></div><p class="_abstract _abstract">
				With Red Hat Enterprise Linux 9, you can use huge pages for applications that work with big data sets, and improve the performance of such applications.
			</p><p>
				The following are the huge page methods, which are supported in RHEL 9:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">HugeTLB pages</code></span></dt><dd><p class="simpara">
							HugeTLB pages are also called static huge pages. There are two ways of reserving HugeTLB pages:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									At boot time: It increases the possibility of success because the memory has not yet been significantly fragmented. However, on NUMA machines, the number of pages is automatically split among the NUMA nodes.
								</li></ul></div></dd></dl></div><p>
				For more information about parameters that influence HugeTLB page behavior at boot time, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/configuring-huge-pages_monitoring-and-managing-system-status-and-performance#parameters-for-reserving-hugetlb-pages-at-boot-time_configuring-huge-pages">Parameters for reserving HugeTLB pages at boot time</a> and how to use these parameters to configure HugeTLB pages at boot time, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/configuring-huge-pages_monitoring-and-managing-system-status-and-performance#configuring-hugetlb-at-boot-time_configuring-huge-pages">Configuring HugeTLB at boot time</a>.
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						At run time: It allows you to reserve the huge pages per NUMA node. If the run-time reservation is done as early as possible in the boot process, the probability of memory fragmentation is lower.
					</li></ul></div><p>
				For more information about parameters that influence HugeTLB page behavior at run time, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/monitoring_and_managing_system_status_and_performance/configuring-huge-pages_monitoring-and-managing-system-status-and-performance#parameters-for-reserving-hugetlb-pages-at-run-time_configuring-huge-pages">Parameters for reserving HugeTLB pages at run time</a> and how to use these parameters to configure HugeTLB pages at run time, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/monitoring_and_managing_system_status_and_performance/configuring-huge-pages_monitoring-and-managing-system-status-and-performance#configuring-hugetlb-at-run-time_configuring-huge-pages">Configuring HugeTLB at run time</a>.
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">Transparent HugePages (THP)</code></span></dt><dd><p class="simpara">
							With THP, the kernel automatically assigns huge pages to processes, and therefore there is no need to manually reserve the static huge pages. The following are the two modes of operation in THP:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									<code class="literal">system-wide</code>: Here, the kernel tries to assign huge pages to a process whenever it is possible to allocate the huge pages and the process is using a large contiguous virtual memory area.
								</li><li class="listitem"><p class="simpara">
									<code class="literal">per-process</code>: Here, the kernel only assigns huge pages to the memory areas of individual processes which you can specify using the <code class="literal">madvise</code>() system call.
								</p><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
										The THP feature only supports <code class="literal">2 MB</code> pages.
									</p></div></rh-alert></li></ul></div></dd></dl></div><p>
				For more information about parameters that influence HugeTLB page behavior at boot time, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/configuring-huge-pages_monitoring-and-managing-system-status-and-performance#enabling-transparent-hugepages_configuring-huge-pages">Enabling transparent hugepages</a> and <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/configuring-huge-pages_monitoring-and-managing-system-status-and-performance#disabling-transparent-hugepages_configuring-huge-pages">Disabling transparent hugepages</a>.
			</p></section><section class="section" id="parameters-for-reserving-hugetlb-pages-at-boot-time_configuring-huge-pages"><div class="titlepage"><div><div><h3 class="title">38.2. Parameters for reserving HugeTLB pages at boot time</h3></div></div></div><p class="_abstract _abstract">
				Use the following parameters to influence HugeTLB page behavior at boot time.
			</p><p>
				For more infomration on how to use these parameters to configure HugeTLB pages at boot time, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/monitoring_and_managing_system_status_and_performance/configuring-huge-pages_monitoring-and-managing-system-status-and-performance#configuring-hugetlb-at-boot-time_configuring-huge-pages">Configuring HugeTLB at boot time</a>.
			</p><rh-table id="idm140280129468800"><table class="lt-4-cols lt-7-rows"><caption>Table 38.1. Parameters used to configure HugeTLB pages at boot time</caption><colgroup><col style="width: 33%; " class="col_1"><!--Empty--><col style="width: 33%; " class="col_2"><!--Empty--><col style="width: 33%; " class="col_3"><!--Empty--></colgroup><thead><tr><th align="left" valign="top" id="idm140280129463008" scope="col">Parameter</th><th align="left" valign="top" id="idm140280129461920" scope="col">Description</th><th align="left" valign="top" id="idm140280129460832" scope="col">Default value</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm140280129463008"> <p>
								<code class="literal">hugepages</code>
							</p>
							 </td><td align="left" valign="top" headers="idm140280129461920"> <p>
								Defines the number of persistent huge pages configured in the kernel at boot time.
							</p>
							 <p>
								In a NUMA system, huge pages, that have this parameter defined, are divided equally between nodes.
							</p>
							 <p>
								You can assign huge pages to specific nodes at runtime by changing the value of the nodes in the <code class="literal">/sys/devices/system/node/node_id/hugepages/hugepages-size/nr_hugepages</code> file.
							</p>
							 </td><td align="left" valign="top" headers="idm140280129460832"> <p>
								The default value is <code class="literal">0</code>.
							</p>
							 <p>
								To update this value at boot, change the value of this parameter in the <code class="literal">/proc/sys/vm/nr_hugepages</code> file.
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm140280129463008"> <p>
								<code class="literal">hugepagesz</code>
							</p>
							 </td><td align="left" valign="top" headers="idm140280129461920"> <p>
								Defines the size of persistent huge pages configured in the kernel at boot time.
							</p>
							 </td><td align="left" valign="top" headers="idm140280129460832"> <p>
								Valid values are <code class="literal">2 MB</code> and <code class="literal">1 GB</code>. The default value is <code class="literal">2 MB</code>.
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm140280129463008"> <p>
								<code class="literal">default_hugepagesz</code>
							</p>
							 </td><td align="left" valign="top" headers="idm140280129461920"> <p>
								Defines the default size of persistent huge pages configured in the kernel at boot time.
							</p>
							 </td><td align="left" valign="top" headers="idm140280129460832"> <p>
								Valid values are <code class="literal">2 MB</code> and <code class="literal">1 GB</code>. The default value is <code class="literal">2 MB</code>.
							</p>
							 </td></tr></tbody></table></rh-table></section><section class="section" id="configuring-hugetlb-at-boot-time_configuring-huge-pages"><div class="titlepage"><div><div><h3 class="title">38.3. Configuring HugeTLB at boot time</h3></div></div></div><p class="_abstract _abstract">
				The page size, which the HugeTLB subsystem supports, depends on the architecture. The x86_64 architecture supports <code class="literal">2 MB</code> huge pages and <code class="literal">1 GB</code> gigantic pages.
			</p><p>
				This procedure describes how to reserve a <code class="literal">1 GB</code> page at boot time.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						To create a HugeTLB pool for <code class="literal">1 GB</code> pages, enable the <code class="literal">default_hugepagesz=1G</code> and <code class="literal">hugepagesz=1G</code> kernel options:
					</p><pre class="screen"># grubby --update-kernel=ALL --args="default_hugepagesz=1G hugepagesz=1G"</pre></li><li class="listitem"><p class="simpara">
						Create a new file called <code class="literal">hugetlb-gigantic-pages.service</code> in the <code class="literal">/usr/lib/systemd/system/</code> directory and add the following content:
					</p><pre class="screen">[Unit]
Description=HugeTLB Gigantic Pages Reservation
DefaultDependencies=no
Before=dev-hugepages.mount
ConditionPathExists=/sys/devices/system/node
ConditionKernelCommandLine=hugepagesz=1G

[Service]
Type=oneshot
RemainAfterExit=yes
ExecStart=/usr/lib/systemd/hugetlb-reserve-pages.sh

[Install]
WantedBy=sysinit.target</pre></li><li class="listitem"><p class="simpara">
						Create a new file called <code class="literal">hugetlb-reserve-pages.sh</code> in the <code class="literal">/usr/lib/systemd/</code> directory and add the following content:
					</p><p class="simpara">
						While adding the following content, replace <span class="emphasis"><em>number_of_pages</em></span> with the number of 1GB pages you want to reserve, and <span class="emphasis"><em>node</em></span> with the name of the node on which to reserve these pages.
					</p><pre class="screen">#!/bin/sh

nodes_path=/sys/devices/system/node/
if [ ! -d $nodes_path ]; then
    echo "ERROR: $nodes_path does not exist"
    exit 1
fi

reserve_pages()
{
    echo $1 &gt; $nodes_path/$2/hugepages/hugepages-1048576kB/nr_hugepages
}

reserve_pages <span class="emphasis"><em>number_of_pages</em></span> <span class="emphasis"><em>node</em></span></pre><p class="simpara">
						For example, to reserve two <code class="literal">1 GB</code> pages on <span class="emphasis"><em>node0</em></span> and one 1GB page on <span class="emphasis"><em>node1</em></span>, replace the <span class="emphasis"><em>number_of_pages</em></span> with 2 for <span class="emphasis"><em>node0</em></span> and 1 for <span class="emphasis"><em>node1</em></span>:
					</p><pre class="screen">reserve_pages 2 node0
reserve_pages 1 node1</pre></li><li class="listitem"><p class="simpara">
						Create an executable script:
					</p><pre class="screen"># chmod +x /usr/lib/systemd/hugetlb-reserve-pages.sh</pre></li><li class="listitem"><p class="simpara">
						Enable early boot reservation:
					</p><pre class="screen"># systemctl enable hugetlb-gigantic-pages</pre></li></ol></div><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							You can try reserving more <code class="literal">1 GB</code> pages at runtime by writing to <code class="literal">nr_hugepages</code> at any time. However, to prevent failures due to memory fragmentation, reserve <code class="literal">1 GB</code> pages early during the boot process.
						</li><li class="listitem">
							Reserving static huge pages can effectively reduce the amount of memory available to the system, and prevents it from properly utilizing its full memory capacity. Although a properly sized pool of reserved huge pages can be beneficial to applications that utilize it, an oversized or unused pool of reserved huge pages will eventually be detrimental to overall system performance. When setting a reserved huge page pool, ensure that the system can properly utilize its full memory capacity.
						</li></ul></div></div></rh-alert><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">systemd.service(5)</code> man page on your system
					</li><li class="listitem">
						<code class="literal">/usr/share/doc/kernel-doc-kernel_version/Documentation/vm/hugetlbpage.txt</code> file
					</li></ul></div></section><section class="section" id="parameters-for-reserving-hugetlb-pages-at-run-time_configuring-huge-pages"><div class="titlepage"><div><div><h3 class="title">38.4. Parameters for reserving HugeTLB pages at run time</h3></div></div></div><p class="_abstract _abstract">
				Use the following parameters to influence HugeTLB page behavior at run time.
			</p><p>
				For more information about how to use these parameters to configure HugeTLB pages at run time, see <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/monitoring_and_managing_system_status_and_performance/configuring-huge-pages_monitoring-and-managing-system-status-and-performance#configuring-hugetlb-at-run-time_configuring-huge-pages">Configuring HugeTLB at run time</a>.
			</p><rh-table id="idm140280129398528"><table class="lt-4-cols lt-7-rows"><caption>Table 38.2. Parameters used to configure HugeTLB pages at run time</caption><colgroup><col style="width: 33%; " class="col_1"><!--Empty--><col style="width: 33%; " class="col_2"><!--Empty--><col style="width: 33%; " class="col_3"><!--Empty--></colgroup><thead><tr><th align="left" valign="top" id="idm140280129392736" scope="col">Parameter</th><th align="left" valign="top" id="idm140280129391648" scope="col">Description</th><th align="left" valign="top" id="idm140280129390560" scope="col">File name</th></tr></thead><tbody><tr><td align="left" valign="top" headers="idm140280129392736"> <p>
								<code class="literal">nr_hugepages</code>
							</p>
							 </td><td align="left" valign="top" headers="idm140280129391648"> <p>
								Defines the number of huge pages of a specified size assigned to a specified NUMA node.
							</p>
							 </td><td align="left" valign="top" headers="idm140280129390560"> <p>
								<code class="literal">/sys/devices/system/node/node_id/hugepages/hugepages-size/nr_hugepages</code>
							</p>
							 </td></tr><tr><td align="left" valign="top" headers="idm140280129392736"> <p>
								<code class="literal">nr_overcommit_hugepages</code>
							</p>
							 </td><td align="left" valign="top" headers="idm140280129391648"> <p>
								Defines the maximum number of additional huge pages that can be created and used by the system through overcommitting memory.
							</p>
							 <p>
								Writing any non-zero value into this file indicates that the system obtains that number of huge pages from the kernel’s normal page pool if the persistent huge page pool is exhausted. As these surplus huge pages become unused, they are then freed and returned to the kernel’s normal page pool.
							</p>
							 </td><td align="left" valign="top" headers="idm140280129390560"> <p>
								<code class="literal">/proc/sys/vm/nr_overcommit_hugepages</code>
							</p>
							 </td></tr></tbody></table></rh-table></section><section class="section" id="configuring-hugetlb-at-run-time_configuring-huge-pages"><div class="titlepage"><div><div><h3 class="title">38.5. Configuring HugeTLB at run time</h3></div></div></div><p class="_abstract _abstract">
				This procedure describes how to add <span class="emphasis"><em>20</em></span> <span class="emphasis"><em>2048 kB</em></span> huge pages to <span class="emphasis"><em>node2</em></span>.
			</p><p>
				To reserve pages based on your requirements, replace:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
						<span class="emphasis"><em>20</em></span> with the number of huge pages you wish to reserve,
					</li><li class="listitem">
						<span class="emphasis"><em>2048kB</em></span> with the size of the huge pages,
					</li><li class="listitem">
						<span class="emphasis"><em>node2</em></span> with the node on which you wish to reserve the pages.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Display the memory statistics:
					</p><pre class="screen"># numastat -cm | egrep 'Node|Huge'
                 Node 0 Node 1 Node 2 Node 3  Total add
AnonHugePages         0      2      0      8     10
HugePages_Total       0      0      0      0      0
HugePages_Free        0      0      0      0      0
HugePages_Surp        0      0      0      0      0</pre></li><li class="listitem"><p class="simpara">
						Add the number of huge pages of a specified size to the node:
					</p><pre class="screen"># echo <span class="emphasis"><em>20</em></span> &gt; /sys/devices/system/node/node2/hugepages/hugepages-<span class="emphasis"><em>2048kB</em></span>/nr_hugepages</pre></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Ensure that the number of huge pages are added:
					</p><pre class="screen"># numastat -cm | egrep 'Node|Huge'
                 Node 0 Node 1 Node 2 Node 3  Total
AnonHugePages         0      2      0      8     10
HugePages_Total       0      0     40      0     40
HugePages_Free        0      0     40      0     40
HugePages_Surp        0      0      0      0      0</pre></li></ul></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">numastat(8)</code> man page on your system
					</li></ul></div></section><section class="section" id="enabling-transparent-hugepages_configuring-huge-pages"><div class="titlepage"><div><div><h3 class="title">38.6. Enabling transparent hugepages</h3></div></div></div><p class="_abstract _abstract">
				THP is enabled by default in Red Hat Enterprise Linux 9. However, you can enable or disable THP.
			</p><p>
				This procedure describes how to enable THP.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Check the current status of THP:
					</p><pre class="screen"># cat /sys/kernel/mm/transparent_hugepage/enabled</pre></li><li class="listitem"><p class="simpara">
						Enable THP:
					</p><pre class="screen"># echo always &gt; /sys/kernel/mm/transparent_hugepage/enabled</pre></li><li class="listitem"><p class="simpara">
						To prevent applications from allocating more memory resources than necessary, disable the system-wide transparent huge pages and only enable them for the applications that explicitly request it through the <code class="literal">madvise</code>:
					</p><pre class="screen"># echo madvise &gt; /sys/kernel/mm/transparent_hugepage/enabled</pre></li></ol></div><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					Sometimes, providing low latency to short-lived allocations has higher priority than immediately achieving the best performance with long-lived allocations. In such cases, you can disable direct compaction while leaving THP enabled.
				</p><p>
					Direct compaction is a synchronous memory compaction during the huge page allocation. Disabling direct compaction provides no guarantee of saving memory, but can decrease the risk of higher latencies during frequent page faults. Note that if the workload benefits significantly from THP, the performance decreases. Disable direct compaction:
				</p><pre class="screen"># echo madvise &gt; /sys/kernel/mm/transparent_hugepage/defrag</pre></div></rh-alert><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">madvise(2)</code> man page on your system
					</li><li class="listitem">
						<a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index#disabling-transparent-hugepages_configuring-huge-pages">Disabling transparent hugepages</a>.
					</li></ul></div></section><section class="section" id="disabling-transparent-hugepages_configuring-huge-pages"><div class="titlepage"><div><div><h3 class="title">38.7. Disabling transparent hugepages</h3></div></div></div><p class="_abstract _abstract">
				THP is enabled by default in Red Hat Enterprise Linux 9. However, you can enable or disable THP.
			</p><p>
				This procedure describes how to disable THP.
			</p><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Check the current status of THP:
					</p><pre class="screen"># cat /sys/kernel/mm/transparent_hugepage/enabled</pre></li><li class="listitem"><p class="simpara">
						Disable THP:
					</p><pre class="screen"># echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled</pre></li></ol></div></section><section class="section" id="impact-of-page-size-on-translation-lookaside-buffer-size_configuring-huge-pages"><div class="titlepage"><div><div><h3 class="title">38.8. Impact of page size on translation lookaside buffer size</h3></div></div></div><p class="_abstract _abstract">
				Reading address mappings from the page table is time-consuming and resource-expensive, so CPUs are built with a cache for recently-used addresses, called the Translation Lookaside Buffer (TLB). However, the default TLB can only cache a certain number of address mappings.
			</p><p>
				If a requested address mapping is not in the TLB, called a TLB miss, the system still needs to read the page table to determine the physical to virtual address mapping. Because of the relationship between application memory requirements and the size of pages used to cache address mappings, applications with large memory requirements are more likely to suffer performance degradation from TLB misses than applications with minimal memory requirements. It is therefore important to avoid TLB misses wherever possible.
			</p><p>
				Both HugeTLB and Transparent Huge Page features allow applications to use pages larger than <code class="literal">4 KB</code>. This allows addresses stored in the TLB to reference more memory, which reduces TLB misses and improves application performance.
			</p></section></section><section class="chapter" id="getting-started-with-systemtap_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 39. Getting started with SystemTap</h2></div></div></div><p class="_abstract _abstract">
			As a system administrator, you can use SystemTap to identify underlying causes of a bug or performance problem on a running RHEL system.
		</p><p>
			As an application developer, you can use SystemTap to monitor in fine detail how your application behaves within the RHEL system.
		</p><section class="section" id="the-purpose-of-systemtap_getting-started-with-systemtap"><div class="titlepage"><div><div><h3 class="title">39.1. The purpose of SystemTap</h3></div></div></div><p class="_abstract _abstract">
				SystemTap is a tracing and probing tool that you can use to study and monitor the activities of your operating system (particularly, the kernel) in fine detail. SystemTap provides information similar to the output of tools such as <code class="literal">netstat</code>, <code class="literal">ps</code>, <code class="literal">top</code>, and <code class="literal">iostat</code>. However, SystemTap provides more filtering and analysis options for collected information. In SystemTap scripts, you specify the information that SystemTap gathers.
			</p><p>
				SystemTap aims to supplement the existing suite of Linux monitoring tools by providing users with the infrastructure to track kernel activity and combining this capability with two attributes:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><span class="strong strong"><strong>Flexibility</strong></span></span></dt><dd>
							the SystemTap framework enables you to develop simple scripts for investigating and monitoring a wide variety of kernel functions, system calls, and other events that occur in kernel space. With this, SystemTap is not so much a tool as it is a system that allows you to develop your own kernel-specific forensic and monitoring tools.
						</dd><dt><span class="term"><span class="strong strong"><strong>Ease-of-Use</strong></span></span></dt><dd>
							SystemTap enables you to monitor kernel activity without having to recompile the kernel or reboot the system.
						</dd></dl></div></section><section class="section" id="installing-systemtap_getting-started-with-systemtap"><div class="titlepage"><div><div><h3 class="title">39.2. Installing SystemTap</h3></div></div></div><p class="_abstract _abstract">
				To begin using SystemTap, install the required packages. To use SystemTap on more than one kernel where a system has multiple kernels installed, install the corresponding required kernel packages for <span class="emphasis"><em>each</em></span> kernel version.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have enabled debug repositories as described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/developing_c_and_cpp_applications_in_rhel_9/setting-up-a-development-workstation_developing-applications#enabling-debug-and-source-repositories_setting-up-a-development-workstation">Enabling debug and source repositories</a>.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Install the required SystemTap packages:
					</p><pre class="screen"># dnf install systemtap</pre></li><li class="listitem"><p class="simpara">
						Install the required kernel packages:
					</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
								Using <code class="literal">stap-prep</code>:
							</p><pre class="screen"># stap-prep</pre></li><li class="listitem"><p class="simpara">
								If <code class="literal">stap-prep</code> does not work, install the required kernel packages manually:
							</p><pre class="screen"># dnf install kernel-debuginfo-$(uname -r) kernel-debuginfo-common-$(uname -i)-$(uname -r) kernel-devel-$(uname -r)</pre><p class="simpara">
								<code class="literal">$(uname -i)</code> is automatically replaced with the hardware platform of your system and <code class="literal">$(uname -r)</code> is automatically replaced with the version of your running kernel.
							</p></li></ol></div></li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						If the kernel to be probed with SystemTap is currently in use, test if your installation was successful:
					</p><pre class="screen"># stap -v -e 'probe kernel.function("vfs_read") {printf("read performed\n"); exit()}'</pre><p class="simpara">
						A successful SystemTap deployment results in an output similar to the following:
					</p><pre class="screen">Pass 1: parsed user script and 45 library script(s) in 340usr/0sys/358real ms.
Pass 2: analyzed script: 1 probe(s), 1 function(s), 0 embed(s), 0 global(s) in 290usr/260sys/568real ms.
Pass 3: translated to C into "/tmp/stapiArgLX/stap_e5886fa50499994e6a87aacdc43cd392_399.c" in 490usr/430sys/938real ms.
Pass 4: compiled C into "stap_e5886fa50499994e6a87aacdc43cd392_399.ko" in 3310usr/430sys/3714real ms.
Pass 5: starting run. <span id="CO1-1"><!--Empty--></span><span class="callout">1</span>
read performed <span id="CO1-2"><!--Empty--></span><span class="callout">2</span>
Pass 5: run completed in 10usr/40sys/73real ms. <span id="CO1-3"><!--Empty--></span><span class="callout">3</span></pre><p class="simpara">
						The last three lines of output (beginning with <code class="literal">Pass 5</code>) indicate that:
					</p><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO1-1"><span class="callout">1</span></a> </dt><dd><div class="para">
								SystemTap successfully created the instrumentation to probe the kernel and ran the instrumentation.
							</div></dd><dt><a href="#CO1-2"><span class="callout">2</span></a> </dt><dd><div class="para">
								SystemTap detected the specified event (in this case, A VFS read).
							</div></dd><dt><a href="#CO1-3"><span class="callout">3</span></a> </dt><dd><div class="para">
								SystemTap executed a valid handler (printed text and then closed it with no errors).
							</div></dd></dl></div></li></ul></div></section><section class="section" id="privileges-to-run-systemtap_getting-started-with-systemtap"><div class="titlepage"><div><div><h3 class="title">39.3. Privileges to run SystemTap</h3></div></div></div><p class="_abstract _abstract">
				Running SystemTap scripts requires elevated system privileges but, in some instances, non-privileged users might need to run SystemTap instrumentation on their machine.
			</p><p>
				To allow users to run SystemTap without root access, add users to <span class="strong strong"><strong>both</strong></span> of these user groups:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">stapdev</code></span></dt><dd><p class="simpara">
							Members of this group can use <code class="literal">stap</code> to run SystemTap scripts, or <code class="literal">staprun</code> to run SystemTap instrumentation modules.
						</p><p class="simpara">
							Running <code class="literal">stap</code> involves compiling SystemTap scripts into kernel modules and loading them into the kernel. This requires elevated privileges to the system, which are granted to <code class="literal">stapdev</code> members. Unfortunately, such privileges also grant effective root access to <code class="literal">stapdev</code> members. As such, only grant <code class="literal">stapdev</code> group membership to users who can be trusted with root access.
						</p></dd><dt><span class="term"><code class="literal">stapusr</code></span></dt><dd>
							Members of this group can only use <code class="literal">staprun</code> to run SystemTap instrumentation modules. In addition, they can only run those modules from the <code class="literal">/lib/modules/<span class="emphasis"><em>kernel_version</em></span>/systemtap/</code> directory. This directory must be owned only by the root user, and must only be writable by the root user.
						</dd></dl></div></section><section class="section" id="running-systemtap-scripts_getting-started-with-systemtap"><div class="titlepage"><div><div><h3 class="title">39.4. Running SystemTap scripts</h3></div></div></div><p class="_abstract _abstract">
				You can run SystemTap scripts from standard input or from a file.
			</p><p>
				Sample scripts that are distributed with the installation of SystemTap can be found in the <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-systemtap_monitoring-and-managing-system-status-and-performance#useful-examples-of-systemtap-scripts">Useful examples of SystemTap scripts</a> or in the <code class="literal">/usr/share/systemtap/examples</code> directory.
			</p><div class="orderedlist"><p class="title"><strong>Prerequisites</strong></p><ol class="orderedlist" type="1"><li class="listitem">
						SystemTap and the associated required kernel packages are installed as described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-systemtap_monitoring-and-managing-system-status-and-performance#installing-systemtap_getting-started-with-systemtap">Installing Systemtap</a>.
					</li><li class="listitem"><p class="simpara">
						To run SystemTap scripts as a normal user, add the user to the SystemTap groups:
					</p><pre class="screen"># usermod --append --groups
stapdev,stapusr <span class="emphasis"><em>user-name</em></span></pre></li></ol></div><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						Run the SystemTap script:
					</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem"><p class="simpara">
								From standard input:
							</p><pre class="screen"># <span class="strong strong"><strong>stap -e "probe timer.s(1) {exit()}"</strong></span></pre><p class="simpara">
								This command instructs <code class="literal">stap -e</code> to run the script in parenthesis to standard input.
							</p></li><li class="listitem"><p class="simpara">
								From a file:
							</p><pre class="screen"># <span class="strong strong"><strong>stap <span class="emphasis"><em>file_name</em></span>.stp</strong></span></pre></li></ul></div></li></ul></div></section><section class="section" id="useful-examples-of-systemtap-scripts_getting-started-with-systemtap"><div class="titlepage"><div><div><h3 class="title">39.5. Useful examples of SystemTap scripts</h3></div></div></div><p class="_abstract _abstract">
				Sample example scripts that are distributed with the installation of SystemTap can be found in the <code class="literal">/usr/share/systemtap/examples</code> directory.
			</p><p>
				You can use the <code class="literal command">stap</code> command to execute different SystemTap scripts:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">Tracing function calls</span></dt><dd><p class="simpara">
							You can use the <code class="literal">para-callgraph.stp</code> SystemTap script to trace function calls and function returns.
						</p><pre class="screen"># <span class="strong strong"><strong>stap para-callgraph.stp <span class="emphasis"><em>argument1</em></span> <span class="emphasis"><em>argument2</em></span></strong></span></pre><p class="simpara">
							The script takes two command-line arguments: The name of the function(s) whose entry/exit you are tracing. An optional trigger function, which enables or disables tracing on a per-thread basis. Tracing in each thread will continue as long as the trigger function has not exited yet.
						</p></dd><dt><span class="term">Monitoring polling applications</span></dt><dd><p class="simpara">
							You can use the timeout.stp SystemTap script to identify and monitor which applications are polling. Knowing this, you can track unnecessary or excessive polling, which helps you pinpoint areas for improvement in terms of CPU usage and power savings.
						</p><pre class="screen"># <span class="strong strong"><strong>stap timeout.stp</strong></span></pre><p class="simpara">
							This script tracks how many times each application uses <code class="literal">poll</code>, <code class="literal">select</code>, <code class="literal">epoll</code>, <code class="literal">itimer</code>, <code class="literal">futex</code>, <code class="literal">nanosleep</code> and <code class="literal">Signal</code> system calls over time
						</p></dd><dt><span class="term">Tracking system call volume per process</span></dt><dd><p class="simpara">
							You can use the <code class="literal">syscalls_by_proc.stp</code> SystemTap script to see what processes are performing the highest volume of system calls. It displays the 20 processes performing the most of system calls.
						</p><pre class="screen"># <span class="strong strong"><strong>stap syscalls_by_proc.stp</strong></span></pre></dd><dt><span class="term">Tracing functions called in network socket code</span></dt><dd><p class="simpara">
							You can use the <code class="literal">socket-trace.stp</code> example SystemTap script to trace functions called from the kernel’s net/socket.c file. This helps you identify how each process interacts with the network at the kernel level in fine detail.
						</p><pre class="screen"># <span class="strong strong"><strong>stap socket-trace.stp</strong></span></pre></dd><dt><span class="term">Tracking I/O time for each file read or write</span></dt><dd><p class="simpara">
							You can use the <code class="literal">iotime.stp</code> SystemTap script to monitor the amount of time it takes for each process to read from or write to any file. This helps you to determine what files are slow to load on a system.
						</p><pre class="screen"># <span class="strong strong"><strong>stap iotime.stp</strong></span></pre></dd><dt><span class="term">Track IRQ’s and other processes stealing cycles from a task</span></dt><dd><p class="simpara">
							You can use the <code class="literal">cycle_thief.stp</code> SystemTap script to track the amount of time a task is running and the amount of time it is not running. This helps you to identify which processes are stealing cycles from a task.
						</p><pre class="screen"># <span class="strong strong"><strong>stap cycle_thief.stp -x <span class="emphasis"><em>pid</em></span></strong></span></pre></dd></dl></div><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Note</div><div><p>
					You can find more examples and information about SystemTap scripts in the <code class="literal">/usr/share/systemtap/examples/index.html</code> file. Open it in a web browser to see a list of all the available scripts and their descriptions.
				</p></div></rh-alert><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
						<code class="literal">/usr/share/systemtap/examples</code> directory
					</li></ul></div></section></section><section class="chapter" id="cross-instrumentation-of-systemtap_monitoring-and-managing-system-status-and-performance"><div class="titlepage"><div><div><h2 class="title">Chapter 40. Cross-instrumentation of SystemTap</h2></div></div></div><p class="_abstract _abstract">
			Cross-instrumentation of SystemTap is creating SystemTap instrumentation modules from a SystemTap script on one system to be used on another system that does not have SystemTap fully deployed.
		</p><section class="section" id="systemtap-cross-instrumentation_cross-instrumentation-of-systemtap"><div class="titlepage"><div><div><h3 class="title">40.1. SystemTap cross-instrumentation</h3></div></div></div><p class="_abstract _abstract">
				When you run a SystemTap script, a kernel module is built out of that script. SystemTap then loads the module into the kernel.
			</p><p>
				Normally, SystemTap scripts can run only on systems where SystemTap is deployed. To run SystemTap on ten systems, SystemTap needs to be deployed on all those systems. In some cases, this might be neither feasible nor desired. For example, corporate policy might prohibit you from installing packages that provide compilers or debug information about specific machines, which will prevent the deployment of SystemTap.
			</p><p>
				To work around this, use <span class="emphasis"><em>cross-instrumentation</em></span>. Cross-instrumentation is the process of generating SystemTap instrumentation modules from a SystemTap script on one system to be used on another system. This process offers the following benefits:
			</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
						The kernel information packages for various machines can be installed on a single host machine.
					</p><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
							Kernel packaging bugs may prevent the installation. In such cases, the <code class="literal">kernel-debuginfo</code> and <code class="literal">kernel-devel</code> packages for the <span class="emphasis"><em>host system</em></span> and <span class="emphasis"><em>target system</em></span> must match. If a bug occurs, report the bug at <a class="link" href="https://bugzilla.redhat.com/">https://bugzilla.redhat.com/</a>.
						</p></div></rh-alert></li><li class="listitem"><p class="simpara">
						Each <span class="emphasis"><em>target machine</em></span> needs only one package to be installed to use the generated SystemTap instrumentation module: <code class="literal">systemtap-runtime</code>.
					</p><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
							The <span class="emphasis"><em>host system</em></span> must be the same architecture and running the same distribution of Linux as the <span class="emphasis"><em>target system</em></span> in order for the built <span class="emphasis"><em>instrumentation module</em></span> to work.
						</p></div></rh-alert></li></ul></div><rh-alert class="admonition note" state="info"><div class="admonition_header" slot="header">Terminology</div><div><div class="variablelist"><dl class="variablelist"><dt><span class="term"><span class="emphasis"><em>instrumentation module</em></span></span></dt><dd>
								The kernel module built from a SystemTap script; the SystemTap module is built on the <span class="emphasis"><em>host system</em></span>, and will be loaded on the <span class="emphasis"><em>target kernel</em></span> of the <span class="emphasis"><em>target system</em></span>.
							</dd><dt><span class="term"><span class="emphasis"><em>host system</em></span></span></dt><dd>
								The system on which the instrumentation modules (from SystemTap scripts) are compiled, to be loaded on <span class="emphasis"><em>target systems</em></span>.
							</dd><dt><span class="term"><span class="emphasis"><em>target system</em></span></span></dt><dd>
								The system in which the <span class="emphasis"><em>instrumentation module</em></span> is being built (from SystemTap scripts).
							</dd><dt><span class="term"><span class="emphasis"><em>target kernel</em></span></span></dt><dd>
								The kernel of the <span class="emphasis"><em>target system</em></span>. This is the kernel that loads and runs the <span class="emphasis"><em>instrumentation module</em></span>.
							</dd></dl></div></div></rh-alert></section><section class="section" id="initializing-cross-instrumentation-of-systemtap_cross-instrumentation-of-systemtap"><div class="titlepage"><div><div><h3 class="title">40.2. Initializing cross-instrumentation of SystemTap</h3></div></div></div><p class="_abstract _abstract">
				Initialize cross-instrumentation of SystemTap to build SystemTap instrumentation modules from a SystemTap script on one system and use them on another system that does not have SystemTap fully deployed.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						SystemTap is installed on the <span class="emphasis"><em>host system</em></span> as described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-systemtap_monitoring-and-managing-system-status-and-performance#installing-systemtap_getting-started-with-systemtap">Installing Systemtap</a>.
					</li><li class="listitem"><p class="simpara">
						The <code class="literal">systemtap-runtime</code> package is installed on each <span class="emphasis"><em>target system</em></span>:
					</p><pre class="screen"># dnf install systemtap-runtime</pre></li><li class="listitem">
						Both the <span class="emphasis"><em>host system</em></span> and <span class="emphasis"><em>target system</em></span> are the same architecture.
					</li><li class="listitem">
						Both the <span class="emphasis"><em>host system</em></span> and <span class="emphasis"><em>target system</em></span> are running the same major version of Red Hat Enterprise Linux (such as Red Hat Enterprise Linux 9).
					</li></ul></div><rh-alert class="admonition important" state="warning"><div class="admonition_header" slot="header">Important</div><div><p>
					Kernel packaging bugs may prevent multiple <code class="literal">kernel-debuginfo</code> and <code class="literal">kernel-devel</code> packages from being installed on one system. In such cases, the minor version for the <span class="emphasis"><em>host system</em></span> and <span class="emphasis"><em>target system</em></span> must match. If a bug occurs, report it at <a class="link" href="https://bugzilla.redhat.com/">https://bugzilla.redhat.com/</a>.
				</p></div></rh-alert><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Determine the kernel running on each <span class="emphasis"><em>target system</em></span>:
					</p><pre class="screen">$ uname -r</pre><p class="simpara">
						Repeat this step for each <span class="emphasis"><em>target system</em></span>.
					</p></li><li class="listitem">
						On the <span class="emphasis"><em>host system</em></span>, install the <span class="emphasis"><em>target kernel</em></span> and related packages for each <span class="emphasis"><em>target system</em></span> by the method described in <a class="link" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-systemtap_monitoring-and-managing-system-status-and-performance#installing-systemtap_getting-started-with-systemtap">Installing Systemtap</a>.
					</li><li class="listitem"><p class="simpara">
						Build an instrumentation module on the <span class="emphasis"><em>host system</em></span>, copy this module to and run this module on on the <span class="emphasis"><em>target system</em></span> either:
					</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
								Using remote implementation:
							</p><pre class="screen"># stap --remote <span class="emphasis"><em>target_system</em></span> <span class="emphasis"><em>script</em></span></pre><p class="simpara">
								This command remotely implements the specified script on the <span class="emphasis"><em>target system</em></span>. You must ensure an SSH connection can be made to the <span class="emphasis"><em>target system</em></span> from the <span class="emphasis"><em>host system</em></span> for this to be successful.
							</p></li><li class="listitem"><p class="simpara">
								Manually:
							</p><div class="orderedlist"><ol class="orderedlist" type="i"><li class="listitem"><p class="simpara">
										Build the instrumentation module on the <span class="emphasis"><em>host system</em></span>:
									</p><pre class="screen"># stap -r <span class="emphasis"><em>kernel_version</em></span> <span class="emphasis"><em>script</em></span> -m <span class="emphasis"><em>module_name</em></span> -p 4</pre><p class="simpara">
										Here, <span class="emphasis"><em>kernel_version</em></span> refers to the version of the <span class="emphasis"><em>target kernel</em></span> determined in step 1, <span class="emphasis"><em>script</em></span> refers to the script to be converted into an <span class="emphasis"><em>instrumentation module</em></span>, and <span class="emphasis"><em>module_name</em></span> is the desired name of the <span class="emphasis"><em>instrumentation module</em></span>. The <code class="literal">-p4</code> option tells SystemTap to not load and run the compiled module.
									</p></li><li class="listitem"><p class="simpara">
										Once the <span class="emphasis"><em>instrumentation module</em></span> is compiled, copy it to the target system and load it using the following command:
									</p><pre class="screen"># staprun <span class="emphasis"><em>module_name</em></span>.ko</pre></li></ol></div></li></ol></div></li></ol></div></section></section><div><div xml:lang="en-US" class="legalnotice" id="idm140280140052320"><h2 class="legalnotice">Legal Notice</h2><div class="para">
		Copyright <span class="trademark"><!--Empty--></span>© 2024 Red Hat, Inc.
	</div><div class="para">
		The text of and illustrations in this document are licensed by Red Hat under a Creative Commons Attribution–Share Alike 3.0 Unported license ("CC-BY-SA"). An explanation of CC-BY-SA is available at <a class="uri" href="http://creativecommons.org/licenses/by-sa/3.0/">http://creativecommons.org/licenses/by-sa/3.0/</a>. In accordance with CC-BY-SA, if you distribute this document or an adaptation of it, you must provide the URL for the original version.
	</div><div class="para">
		Red Hat, as the licensor of this document, waives the right to enforce, and agrees not to assert, Section 4d of CC-BY-SA to the fullest extent permitted by applicable law.
	</div><div class="para">
		Red Hat, Red Hat Enterprise Linux, the Shadowman logo, the Red Hat logo, JBoss, OpenShift, Fedora, the Infinity logo, and RHCE are trademarks of Red Hat, Inc., registered in the United States and other countries.
	</div><div class="para">
		<span class="trademark">Linux</span>® is the registered trademark of Linus Torvalds in the United States and other countries.
	</div><div class="para">
		<span class="trademark">Java</span>® is a registered trademark of Oracle and/or its affiliates.
	</div><div class="para">
		<span class="trademark">XFS</span>® is a trademark of Silicon Graphics International Corp. or its subsidiaries in the United States and/or other countries.
	</div><div class="para">
		<span class="trademark">MySQL</span>® is a registered trademark of MySQL AB in the United States, the European Union and other countries.
	</div><div class="para">
		<span class="trademark">Node.js</span>® is an official trademark of Joyent. Red Hat is not formally related to or endorsed by the official Joyent Node.js open source or commercial project.
	</div><div class="para">
		The <span class="trademark">OpenStack</span>® Word Mark and OpenStack logo are either registered trademarks/service marks or trademarks/service marks of the OpenStack Foundation, in the United States and other countries and are used with the OpenStack Foundation's permission. We are not affiliated with, endorsed or sponsored by the OpenStack Foundation, or the OpenStack community.
	</div><div class="para">
		All other trademarks are the property of their respective owners.
	</div></div></div></div></body></section><!----></div></article><aside id="layout" class="span-xs-12 span-sm-2 span-md-2 content-format-selectors" aria-label="Select page format" data-v-8589d091><div class="sticky-top page-layout-options" data-v-8589d091><label for="page-format" data-v-8589d091>Format</label><select id="page-format" class="page-format-dropdown" data-v-8589d091><option class="page-type" value="html" data-v-8589d091>Multi-page</option><option selected class="page-type" value="html-single" data-v-8589d091>Single-page</option><option class="page-type" value="pdf" data-v-8589d091>View full doc as PDF</option></select></div><!----></aside></div><div class="btn-container hidden" data-v-8589d091><pf-button class="top-scroll-btn" icon="angle-up" icon-set="fas" icon-position="right" data-v-8589d091>Back to top</pf-button></div><!--]--><!--]--></main><rh-footer data-analytics-region="page-footer" data-v-97dd2752><a slot="logo" href="/en" data-analytics-category="Footer" data-analytics-text="Logo" data-v-97dd2752><img alt="Red Hat logo" src="/Logo-Red_Hat-Documentation-A-Reverse-RGB.svg" loading="lazy" width="222" height="40" data-v-97dd2752></a><rh-footer-social-link slot="social-links" icon="github" data-v-97dd2752><a href="https://github.com/redhat-documentation" data-analytics-region="social-links-exit" data-analytics-category="Footer|social-links" data-analytics-text="LinkedIn" data-v-97dd2752>Github</a></rh-footer-social-link><rh-footer-social-link slot="social-links" icon="reddit" data-v-97dd2752><a href="https://www.reddit.com/r/redhat/" data-analytics-region="social-links-exit" data-analytics-category="Footer|social-links" data-analytics-text="YouTube" data-v-97dd2752>Reddit</a></rh-footer-social-link><rh-footer-social-link slot="social-links" icon="youtube" data-v-97dd2752><a href="https://www.youtube.com/@redhat" data-analytics-region="social-links-exit" data-analytics-category="Footer|social-links" data-analytics-text="Facebook" data-v-97dd2752>Youtube</a></rh-footer-social-link><rh-footer-social-link slot="social-links" icon="twitter" data-v-97dd2752><a href="https://twitter.com/RedHat" data-analytics-region="social-links-exit" data-analytics-category="Footer|social-links" data-analytics-text="Twitter" data-v-97dd2752>Twitter</a></rh-footer-social-link><h3 slot="links" data-analytics-text="Learn" data-v-97dd2752>Learn</h3><ul slot="links" data-v-97dd2752><li data-v-97dd2752><a href="https://developers.redhat.com/learn" data-analytics-category="Footer|Learn" data-analytics-text="Developer resources" data-v-97dd2752>Developer resources</a></li><li data-v-97dd2752><a href="https://cloud.redhat.com/learn" data-analytics-category="Footer|Learn" data-analytics-text="Cloud learning hub" data-v-97dd2752>Cloud learning hub</a></li><li data-v-97dd2752><a href="https://www.redhat.com/en/interactive-labs" data-analytics-category="Footer|Learn" data-analytics-text="Interactive labs" data-v-97dd2752>Interactive labs</a></li><li data-v-97dd2752><a href="https://www.redhat.com/services/training-and-certification" data-analytics-category="Footer|Learn" data-analytics-text="Training and certification" data-v-97dd2752>Training and certification</a></li><li data-v-97dd2752><a href="https://access.redhat.com/support" data-analytics-category="Footer|Learn" data-analytics-text="Customer support" data-v-97dd2752>Customer support</a></li><li data-v-97dd2752><a href="/products" data-analytics-category="Footer|Learn" data-analytics-text="See all documentation" data-v-97dd2752>See all documentation</a></li></ul><h3 slot="links" data-analytics-text="Try buy sell" data-v-97dd2752>Try, buy, &amp; sell</h3><ul slot="links" data-v-97dd2752><li data-v-97dd2752><a href="https://redhat.com/en/products/trials" data-analytics-category="Footer|Try buy sell" data-analytics-text="Product trial center" data-v-97dd2752>Product trial center</a></li><li data-v-97dd2752><a href="https://marketplace.redhat.com" data-analytics-category="Footer|Try buy sell" data-analytics-text="Red Hat Marketplace" data-v-97dd2752>Red Hat Marketplace</a></li><li data-v-97dd2752><a href="https://catalog.redhat.com/" data-analytics-category="Footer|Try buy sell" data-analytics-text="Red Hat Ecosystem Catalog" data-v-97dd2752>Red Hat Ecosystem Catalog</a></li><li data-v-97dd2752><a href="https://www.redhat.com/en/store" data-analytics-category="Footer|Try buy sell" data-analytics-text="Red Hat Store" data-v-97dd2752>Red Hat Store</a></li><li data-v-97dd2752><a href="https://www.redhat.com/about/japan-buy" data-analytics-category="Footer|Try buy sell" data-analytics-text="Buy online (Japan)" data-v-97dd2752>Buy online (Japan)</a></li></ul><h3 slot="links" data-analytics-text="Communities" data-v-97dd2752>Communities</h3><ul slot="links" data-v-97dd2752><li data-v-97dd2752><a href="https://access.redhat.com/community" data-analytics-category="Footer|Communities" data-analytics-text="Customer Portal Community" data-v-97dd2752>Customer Portal Community</a></li><li data-v-97dd2752><a href="https://www.redhat.com/events" data-analytics-category="Footer|Communities" data-analytics-text="Events" data-v-97dd2752>Events</a></li><li data-v-97dd2752><a href="https://www.redhat.com/about/our-community-contributions" data-analytics-category="Footer|Communities" data-analytics-text="How we contribute" data-v-97dd2752>How we contribute</a></li></ul><rh-footer-block slot="main-secondary" data-v-97dd2752><h3 slot="header" data-analytics-text="About Red Hat Documentation" data-v-97dd2752>About Red Hat Documentation</h3><p data-v-97dd2752>We help Red Hat users innovate and achieve their goals with our products and services with content they can trust.</p></rh-footer-block><rh-footer-block slot="main-secondary" data-v-97dd2752><h3 slot="header" data-analytics-text="Making open source more inclusive" data-v-97dd2752>Making open source more inclusive</h3><p data-v-97dd2752>Red Hat is committed to replacing problematic language in our code, documentation, and web properties. For more details, see the <a href=" https://www.redhat.com/en/blog/making-open-source-more-inclusive-eradicating-problematic-language" data-analytics-category="Footer|Making open source more inclusive" data-analytics-text="Red Hat Blog" data-v-97dd2752>Red Hat Blog</a>.</p></rh-footer-block><rh-footer-block slot="main-secondary" data-v-97dd2752><h3 slot="header" data-analytics-text="About Red Hat" data-v-97dd2752>About Red Hat</h3><p data-v-97dd2752>We deliver hardened solutions that make it easier for enterprises to work across platforms and environments, from the core datacenter to the network edge.</p></rh-footer-block><rh-footer-universal slot="universal" data-v-97dd2752><h3 slot="links-primary" data-analytics-text="Red Hat legal and privacy links" hidden data-v-97dd2752>Red Hat legal and privacy links</h3><ul slot="links-primary" data-analytics-region="page-footer-bottom-primary" data-v-97dd2752><li data-v-97dd2752><a href="https://redhat.com/en/about/company" data-analytics-category="Footer|Corporate" data-analytics-text="About Red Hat" data-v-97dd2752>About Red Hat</a></li><li data-v-97dd2752><a href="https://redhat.com/en/jobs" data-analytics-category="Footer|Corporate" data-analytics-text="Jobs" data-v-97dd2752>Jobs</a></li><li data-v-97dd2752><a href="https://redhat.com/en/events" data-analytics-category="Footer|Corporate" data-analytics-text="Events" data-v-97dd2752>Events</a></li><li data-v-97dd2752><a href="https://redhat.com/en/about/office-locations" data-analytics-category="Footer|Corporate" data-analytics-text="Locations" data-v-97dd2752>Locations</a></li><li data-v-97dd2752><a href="https://redhat.com/en/contact" data-analytics-category="Footer|Corporate" data-analytics-text="Contact Red Hat" data-v-97dd2752>Contact Red Hat</a></li><li data-v-97dd2752><a href="https://redhat.com/en/blog" data-analytics-category="Footer|Corporate" data-analytics-text="Red Hat Blog" data-v-97dd2752>Red Hat Blog</a></li><li data-v-97dd2752><a href="https://redhat.com/en/about/our-culture/diversity-equity-inclusion" data-analytics-category="Footer|Corporate" data-analytics-text="Diversity equity and inclusion" data-v-97dd2752>Diversity, equity, and inclusion</a></li><li data-v-97dd2752><a href="https://coolstuff.redhat.com/" data-analytics-category="Footer|Corporate" data-analytics-text="Cool Stuff Store" data-v-97dd2752>Cool Stuff Store</a></li><li data-v-97dd2752><a href="https://www.redhat.com/en/summit" data-analytics-category="Footer|Corporate" data-analytics-text="Red Hat Summit" data-v-97dd2752>Red Hat Summit</a></li></ul><span data-v-97dd2752 data-v-5f538988></span><rh-footer-copyright slot="links-secondary" data-v-97dd2752>© 2024 Red Hat, Inc.</rh-footer-copyright><h3 slot="links-secondary" data-analytics-text="Red Hat legal and privacy links" hidden data-v-97dd2752>Red Hat legal and privacy links</h3><ul slot="links-secondary" data-analytics-region="page-footer-bottom-secondary" data-v-97dd2752><li data-v-97dd2752><a href="https://redhat.com/en/about/privacy-policy" data-analytics-category="Footer|Red Hat legal and privacy links" data-analytics-text="Privacy statement" data-v-97dd2752>Privacy statement</a></li><li data-v-97dd2752><a href="https://redhat.com/en/about/terms-use" data-analytics-category="Footer|Red Hat legal and privacy links" data-analytics-text="Terms of use" data-v-97dd2752>Terms of use</a></li><li data-v-97dd2752><a href="https://redhat.com/en/about/all-policies-guidelines" data-analytics-category="Footer|Red Hat legal and privacy links" data-analytics-text="All policies and guidelines" data-v-97dd2752>All policies and guidelines</a></li><li data-v-97dd2752><a href="https://redhat.com/en/about/digital-accessibility" data-analytics-category="Footer|Red Hat legal and privacy links" data-analytics-text="Digital accessibility" class="active" data-v-97dd2752>Digital accessibility</a></li><li data-v-97dd2752><span id="teconsent" data-v-97dd2752></span></li></ul></rh-footer-universal></rh-footer><div id="consent_blackbar" style="position:fixed;bottom:0;width:100%;z-index:5;padding:10px;"></div><!--]--><!--]--></div><div id="teleports"></div><script type="application/json" id="__NUXT_DATA__" data-ssr="true">[["ShallowReactive",1],{"data":2,"state":1758,"once":1761,"_errors":1762,"serverRendered":15,"path":1764},["ShallowReactive",3],{"s8LoCEfG4A":4,"uUstF4AIyn":10,"Pn02PlJOas":1686,"rFVLKcOK8e":1757},[5,6,7,8,9],"fr-fr","zh-cn","en-us","ko-kr","ja-jp",{"name":11,"html":12,"type":-1,"toc":13,"breadcrumbs":1577,"error":18,"title":1585,"productName":1579,"productVersions":1594,"pagination":1623,"redirect":1667,"canonicalLinks":1668,"openShiftProducts":1670,"tocFromVolume":-1,"jumpLinks":1685},"Monitoring and managing system status and performance","\u003Cbody>\u003Cdiv xml:lang=\"en-US\" class=\"book\" id=\"idm140280158333552\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv class=\"producttitle\">\u003Cspan class=\"productname\">Red Hat Enterprise Linux\u003C/span> \u003Cspan class=\"productnumber\">9\u003C/span>\u003C/div>\u003Cdiv>\u003Ch3 class=\"subtitle\">Optimizing system throughput, latency, and power consumption\u003C/h3>\u003C/div>\u003Cdiv>\u003Cdiv xml:lang=\"en-US\" class=\"authorgroup\">\u003Cspan class=\"orgname\">Red Hat\u003C/span> \u003Cspan class=\"orgdiv\">Customer Content Services\u003C/span>\u003C/div>\u003C/div>\u003Cdiv>\u003Ca href=\"#idm140280140052320\">Legal Notice\u003C/a>\u003C/div>\u003Cdiv>\u003Cdiv class=\"abstract\">\u003Cp class=\"title\">\u003Cstrong>Abstract\u003C/strong>\u003C/p>\u003Cdiv class=\"para\">\n\t\t\t\tMonitor and optimize the throughput, latency, and power consumption of Red Hat Enterprise Linux 9 in different scenarios.\n\t\t\t\u003C/div>\u003C/div>\u003C/div>\u003C/div>\u003Chr/>\u003C/div>\u003Csection class=\"preface\" id=\"proc_providing-feedback-on-red-hat-documentation_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Providing feedback on Red Hat documentation\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tWe appreciate your feedback on our documentation. Let us know how we can improve it.\n\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Submitting feedback through Jira (account required)\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\n\t\t\t\t\tLog in to the \u003Ca class=\"link\" href=\"https://issues.redhat.com/projects/RHELDOCS/issues\">Jira\u003C/a> website.\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tClick \u003Cspan class=\"strong strong\">\u003Cstrong>Create\u003C/strong>\u003C/span> in the top navigation bar\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tEnter a descriptive title in the \u003Cspan class=\"strong strong\">\u003Cstrong>Summary\u003C/strong>\u003C/span> field.\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tEnter your suggestion for improvement in the \u003Cspan class=\"strong strong\">\u003Cstrong>Description\u003C/strong>\u003C/span> field. Include links to the relevant parts of the documentation.\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tClick \u003Cspan class=\"strong strong\">\u003Cstrong>Create\u003C/strong>\u003C/span> at the bottom of the dialogue.\n\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"chapter\" id=\"getting-started-with-tuned_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 1. Getting started with TuneD\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tAs a system administrator, you can use the \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> application to optimize the performance profile of your system for a variety of use cases.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"the-purpose-of-tuned_getting-started-with-tuned\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">1.1. The purpose of TuneD\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> is a service that monitors your system and optimizes the performance under certain workloads. The core of \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> are \u003Cspan class=\"emphasis\">\u003Cem>profiles\u003C/em>\u003C/span>, which tune your system for different use cases.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> is distributed with a number of predefined profiles for use cases such as:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tHigh throughput\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tLow latency\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tSaving power\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tIt is possible to modify the rules defined for each profile and customize how to tune a particular device. When you switch to another profile or deactivate \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span>, all changes made to the system settings by the previous profile revert back to their original state.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tYou can also configure \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> to react to changes in device usage and adjusts settings to improve performance of active devices and reduce power consumption of inactive devices.\n\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"tuned-profiles_getting-started-with-tuned\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">1.2. TuneD profiles\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tA detailed analysis of a system can be very time-consuming. \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> provides a number of predefined profiles for typical use cases. You can also create, modify, and delete profiles.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe profiles provided with \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> are divided into the following categories:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tPower-saving profiles\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tPerformance-boosting profiles\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tThe performance-boosting profiles include profiles that focus on the following aspects:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tLow latency for storage and network\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tHigh throughput for storage and network\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tVirtual machine performance\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tVirtualization host performance\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Ch5 id=\"syntax_of_profile_configuration\">Syntax of profile configuration\u003C/h5>\u003Cp>\n\t\t\t\tThe \u003Ccode class=\"literal\">tuned.conf\u003C/code> file can contain one \u003Ccode class=\"literal\">[main]\u003C/code> section and other sections for configuring plug-in instances. However, all sections are optional.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tLines starting with the hash sign (\u003Ccode class=\"literal\">#\u003C/code>) are comments.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">tuned.conf(5)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"the-default-tuned-profile_getting-started-with-tuned\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">1.3. The default TuneD profile\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tDuring the installation, the best profile for your system is selected automatically. Currently, the default profile is selected according to the following customizable rules:\n\t\t\t\u003C/p>\u003Crh-table>\u003Ctable class=\"lt-4-cols lt-7-rows\">\u003Ccolgroup>\u003Ccol style=\"width: 29%; \" class=\"col_1\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 29%; \" class=\"col_2\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 43%; \" class=\"col_3\">\u003C!--Empty-->\u003C/col>\u003C/colgroup>\u003Cthead>\u003Ctr>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280149291312\" scope=\"col\">Environment\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280149290224\" scope=\"col\">Default profile\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280160796032\" scope=\"col\">Goal\u003C/th>\u003C/tr>\u003C/thead>\u003Ctbody>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280149291312\"> \u003Cp>\n\t\t\t\t\t\t\t\tCompute nodes\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280149290224\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">throughput-performance\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280160796032\"> \u003Cp>\n\t\t\t\t\t\t\t\tThe best throughput performance\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280149291312\"> \u003Cp>\n\t\t\t\t\t\t\t\tVirtual machines\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280149290224\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">virtual-guest\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280160796032\"> \u003Cp>\n\t\t\t\t\t\t\t\tThe best performance. If you are not interested in the best performance, you can change it to the \u003Ccode class=\"literal\">balanced\u003C/code> or \u003Ccode class=\"literal\">powersave\u003C/code> profile.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280149291312\"> \u003Cp>\n\t\t\t\t\t\t\t\tOther cases\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280149290224\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">balanced\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280160796032\"> \u003Cp>\n\t\t\t\t\t\t\t\tBalanced performance and power consumption\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\u003C/rh-table>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">tuned.conf(5)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"merged-tuned-profiles_getting-started-with-tuned\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">1.4. Merged TuneD profiles\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tAs an experimental feature, it is possible to select more profiles at once. \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> will try to merge them during the load.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tIf there are conflicts, the settings from the last specified profile takes precedence.\n\t\t\t\u003C/p>\u003Cdiv class=\"example\" id=\"idm140280150601488\">\u003Cp class=\"title\">\u003Cstrong>Example 1.1. Low power consumption in a virtual guest\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\tThe following example optimizes the system to run in a virtual machine for the best performance and concurrently tunes it for low power consumption, while the low power consumption is the priority:\n\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># tuned-adm profile virtual-guest powersave\u003C/pre>\u003C/div>\u003C/div>\u003Crh-alert class=\"admonition warning\" state=\"danger\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Warning\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tMerging is done automatically without checking whether the resulting combination of parameters makes sense. Consequently, the feature might tune some parameters the opposite way, which might be counterproductive: for example, setting the disk for high throughput by using the \u003Ccode class=\"literal\">throughput-performance\u003C/code> profile and concurrently setting the disk spindown to the low value by the \u003Ccode class=\"literal\">spindown-disk\u003C/code> profile.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">tuned-adm\u003C/code> and \u003Ccode class=\"literal\">tuned.conf(5)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"the-location-of-tuned-profiles_getting-started-with-tuned\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">1.5. The location of TuneD profiles\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> stores profiles in the following directories:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal filename\">/usr/lib/tuned/\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDistribution-specific profiles are stored in the directory. Each profile has its own directory. The profile consists of the main configuration file called \u003Ccode class=\"literal\">tuned.conf\u003C/code>, and optionally other files, for example helper scripts.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal filename\">/etc/tuned/\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tIf you need to customize a profile, copy the profile directory into the directory, which is used for custom profiles. If there are two profiles of the same name, the custom profile located in \u003Ccode class=\"literal filename\">/etc/tuned/\u003C/code> is used.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">tuned.conf(5)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"tuned-profiles-distributed-with-rhel_getting-started-with-tuned\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">1.6. TuneD profiles distributed with RHEL\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe following is a list of profiles that are installed with \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> on Red Hat Enterprise Linux.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tThere might be more product-specific or third-party \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profiles available. Such profiles are usually provided by separate RPM packages.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">balanced\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe default power-saving profile. It is intended to be a compromise between performance and power consumption. It uses auto-scaling and auto-tuning whenever possible. The only drawback is the increased latency. In the current \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> release, it enables the CPU, disk, audio, and video plugins, and activates the \u003Ccode class=\"literal\">conservative\u003C/code> CPU governor. The \u003Ccode class=\"literal\">radeon_powersave\u003C/code> option uses the \u003Ccode class=\"literal\">dpm-balanced\u003C/code> value if it is supported, otherwise it is set to \u003Ccode class=\"literal\">auto\u003C/code>.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIt changes the \u003Ccode class=\"literal\">energy_performance_preference\u003C/code> attribute to the \u003Ccode class=\"literal\">normal\u003C/code> energy setting. It also changes the \u003Ccode class=\"literal\">scaling_governor\u003C/code> policy attribute to either the \u003Ccode class=\"literal\">conservative\u003C/code> or \u003Ccode class=\"literal\">powersave\u003C/code> CPU governor.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">powersave\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tA profile for maximum power saving performance. It can throttle the performance in order to minimize the actual power consumption. In the current \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> release it enables USB autosuspend, WiFi power saving, and Aggressive Link Power Management (ALPM) power savings for SATA host adapters. It also schedules multi-core power savings for systems with a low wakeup rate and activates the \u003Ccode class=\"literal\">ondemand\u003C/code> governor. It enables AC97 audio power saving or, depending on your system, HDA-Intel power savings with a 10 seconds timeout. If your system contains a supported Radeon graphics card with enabled KMS, the profile configures it to automatic power saving. On ASUS Eee PCs, a dynamic Super Hybrid Engine is enabled.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIt changes the \u003Ccode class=\"literal\">energy_performance_preference\u003C/code> attribute to the \u003Ccode class=\"literal\">powersave\u003C/code> or \u003Ccode class=\"literal\">power\u003C/code> energy setting. It also changes the \u003Ccode class=\"literal\">scaling_governor\u003C/code> policy attribute to either the \u003Ccode class=\"literal\">ondemand\u003C/code> or \u003Ccode class=\"literal\">powersave\u003C/code> CPU governor.\n\t\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\t\tIn certain cases, the \u003Ccode class=\"literal\">balanced\u003C/code> profile is more efficient compared to the \u003Ccode class=\"literal\">powersave\u003C/code> profile.\n\t\t\t\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\t\t\t\tConsider there is a defined amount of work that needs to be done, for example a video file that needs to be transcoded. Your machine might consume less energy if the transcoding is done on the full power, because the task is finished quickly, the machine starts to idle, and it can automatically step-down to very efficient power save modes. On the other hand, if you transcode the file with a throttled machine, the machine consumes less power during the transcoding, but the process takes longer and the overall consumed energy can be higher.\n\t\t\t\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\t\t\t\tThat is why the \u003Ccode class=\"literal\">balanced\u003C/code> profile can be generally a better option.\n\t\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">throughput-performance\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tA server profile optimized for high throughput. It disables power savings mechanisms and enables \u003Ccode class=\"literal\">sysctl\u003C/code> settings that improve the throughput performance of the disk and network IO. CPU governor is set to \u003Ccode class=\"literal\">performance\u003C/code>.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIt changes the \u003Ccode class=\"literal\">energy_performance_preference\u003C/code> and \u003Ccode class=\"literal\">scaling_governor\u003C/code> attribute to the \u003Ccode class=\"literal\">performance\u003C/code> profile.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">accelerator-performance\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">accelerator-performance\u003C/code> profile contains the same tuning as the \u003Ccode class=\"literal\">throughput-performance\u003C/code> profile. Additionally, it locks the CPU to low C states so that the latency is less than 100us. This improves the performance of certain accelerators, such as GPUs.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">latency-performance\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tA server profile optimized for low latency. It disables power savings mechanisms and enables \u003Ccode class=\"literal\">sysctl\u003C/code> settings that improve latency. CPU governor is set to \u003Ccode class=\"literal\">performance\u003C/code> and the CPU is locked to the low C states (by PM QoS).\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIt changes the \u003Ccode class=\"literal\">energy_performance_preference\u003C/code> and \u003Ccode class=\"literal\">scaling_governor\u003C/code> attribute to the \u003Ccode class=\"literal\">performance\u003C/code> profile.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">network-latency\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tA profile for low latency network tuning. It is based on the \u003Ccode class=\"literal\">latency-performance\u003C/code> profile. It additionally disables transparent huge pages and NUMA balancing, and tunes several other network-related \u003Ccode class=\"literal\">sysctl\u003C/code> parameters.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIt inherits the \u003Ccode class=\"literal\">latency-performance\u003C/code> profile which changes the \u003Ccode class=\"literal\">energy_performance_preference\u003C/code> and \u003Ccode class=\"literal\">scaling_governor\u003C/code> attribute to the \u003Ccode class=\"literal\">performance\u003C/code> profile.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">hpc-compute\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tA profile optimized for high-performance computing. It is based on the \u003Ccode class=\"literal\">latency-performance\u003C/code> profile.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">network-throughput\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tA profile for throughput network tuning. It is based on the \u003Ccode class=\"literal\">throughput-performance\u003C/code> profile. It additionally increases kernel network buffers.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIt inherits either the \u003Ccode class=\"literal\">latency-performance\u003C/code> or \u003Ccode class=\"literal\">throughput-performance\u003C/code> profile, and changes the \u003Ccode class=\"literal\">energy_performance_preference\u003C/code> and \u003Ccode class=\"literal\">scaling_governor\u003C/code> attribute to the \u003Ccode class=\"literal\">performance\u003C/code> profile.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">virtual-guest\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tA profile designed for Red Hat Enterprise Linux 9 virtual machines and VMWare guests based on the \u003Ccode class=\"literal\">throughput-performance\u003C/code> profile that, among other tasks, decreases virtual memory swappiness and increases disk readahead values. It does not disable disk barriers.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIt inherits the \u003Ccode class=\"literal\">throughput-performance\u003C/code> profile and changes the \u003Ccode class=\"literal\">energy_performance_preference\u003C/code> and \u003Ccode class=\"literal\">scaling_governor\u003C/code> attribute to the \u003Ccode class=\"literal\">performance\u003C/code> profile.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">virtual-host\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tA profile designed for virtual hosts based on the \u003Ccode class=\"literal\">throughput-performance\u003C/code> profile that, among other tasks, decreases virtual memory swappiness, increases disk readahead values, and enables a more aggressive value of dirty pages writeback.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIt inherits the \u003Ccode class=\"literal\">throughput-performance\u003C/code> profile and changes the \u003Ccode class=\"literal\">energy_performance_preference\u003C/code> and \u003Ccode class=\"literal\">scaling_governor\u003C/code> attribute to the \u003Ccode class=\"literal\">performance\u003C/code> profile.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">oracle\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tA profile optimized for Oracle databases loads based on \u003Ccode class=\"literal\">throughput-performance\u003C/code> profile. It additionally disables transparent huge pages and modifies other performance-related kernel parameters. This profile is provided by the \u003Ccode class=\"literal package\">tuned-profiles-oracle\u003C/code> package.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">desktop\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tA profile optimized for desktops, based on the \u003Ccode class=\"literal\">balanced\u003C/code> profile. It additionally enables scheduler autogroups for better response of interactive applications.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">optimize-serial-console\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tA profile that tunes down I/O activity to the serial console by reducing the printk value. This should make the serial console more responsive. This profile is intended to be used as an overlay on other profiles. For example:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># tuned-adm profile throughput-performance optimize-serial-console\u003C/pre>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">mssql\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tA profile provided for Microsoft SQL Server. It is based on the \u003Ccode class=\"literal\">throughput-performance\u003C/code> profile.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">intel-sst\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tA profile optimized for systems with user-defined Intel Speed Select Technology configurations. This profile is intended to be used as an overlay on other profiles. For example:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># tuned-adm profile cpu-partitioning intel-sst\u003C/pre>\u003C/dd>\u003C/dl>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"tuned-cpu-partitioning-profile_getting-started-with-tuned\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">1.7. TuneD cpu-partitioning profile\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tFor tuning Red Hat Enterprise Linux 9 for latency-sensitive workloads, Red Hat recommends to use the \u003Ccode class=\"literal\">cpu-partitioning\u003C/code> TuneD profile.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tPrior to Red Hat Enterprise Linux 9, the low-latency Red Hat documentation described the numerous low-level steps needed to achieve low-latency tuning. In Red Hat Enterprise Linux 9, you can perform low-latency tuning more efficiently by using the \u003Ccode class=\"literal\">cpu-partitioning\u003C/code> TuneD profile. This profile is easily customizable according to the requirements for individual low-latency applications.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe following figure is an example to demonstrate how to use the \u003Ccode class=\"literal\">cpu-partitioning\u003C/code> profile. This example uses the CPU and node layout.\n\t\t\t\u003C/p>\u003Cdiv class=\"figure\" id=\"cpu-partitioning_getting-started-with-tuned\">\u003Cp class=\"title\">\u003Cstrong>Figure 1.1. Figure cpu-partitioning\u003C/strong>\u003C/p>\u003Cdiv class=\"figure-contents\">\u003Cdiv class=\"mediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/367206bd2d1527d49965f718f51722e3/cpu-partitioning.png\" alt=\"cpu partitioning\"/>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tYou can configure the cpu-partitioning profile in the \u003Ccode class=\"literal\">/etc/tuned/cpu-partitioning-variables.conf\u003C/code> file using the following configuration options:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">Isolated CPUs with load balancing\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIn the cpu-partitioning figure, the blocks numbered from 4 to 23, are the default isolated CPUs. The kernel scheduler’s process load balancing is enabled on these CPUs. It is designed for low-latency processes with multiple threads that need the kernel scheduler load balancing.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tYou can configure the cpu-partitioning profile in the \u003Ccode class=\"literal\">/etc/tuned/cpu-partitioning-variables.conf\u003C/code> file using the \u003Ccode class=\"literal\">isolated_cores=cpu-list\u003C/code> option, which lists CPUs to isolate that will use the kernel scheduler load balancing.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe list of isolated CPUs is comma-separated or you can specify a range using a dash, such as \u003Ccode class=\"literal\">3-5\u003C/code>. This option is mandatory. Any CPU missing from this list is automatically considered a housekeeping CPU.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Isolated CPUs without load balancing\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIn the cpu-partitioning figure, the blocks numbered 2 and 3, are the isolated CPUs that do not provide any additional kernel scheduler process load balancing.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tYou can configure the cpu-partitioning profile in the \u003Ccode class=\"literal\">/etc/tuned/cpu-partitioning-variables.conf\u003C/code> file using the \u003Ccode class=\"literal\">no_balance_cores=cpu-list\u003C/code> option, which lists CPUs to isolate that will not use the kernel scheduler load balancing.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tSpecifying the \u003Ccode class=\"literal\">no_balance_cores\u003C/code> option is optional, however any CPUs in this list must be a subset of the CPUs listed in the \u003Ccode class=\"literal\">isolated_cores\u003C/code> list.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tApplication threads using these CPUs need to be pinned individually to each CPU.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Housekeeping CPUs\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tAny CPU not isolated in the \u003Ccode class=\"literal\">cpu-partitioning-variables.conf\u003C/code> file is automatically considered a housekeeping CPU. On the housekeeping CPUs, all services, daemons, user processes, movable kernel threads, interrupt handlers, and kernel timers are permitted to execute.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">tuned-profiles-cpu-partitioning(7)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"using-the-tuned-cpu-partitioning-profile-for-low-latency-tuning_getting-started-with-tuned\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">1.8. Using the TuneD cpu-partitioning profile for low-latency tuning\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure describes how to tune a system for low-latency using the TuneD’s \u003Ccode class=\"literal\">cpu-partitioning\u003C/code> profile. It uses the example of a low-latency application that can use \u003Ccode class=\"literal\">cpu-partitioning\u003C/code> and the CPU layout as mentioned in the \u003Ca class=\"link\" href=\"#cpu-partitioning_getting-started-with-tuned\" title=\"Figure 1.1. Figure cpu-partitioning\">cpu-partitioning\u003C/a> figure.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe application in this case uses:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tOne dedicated reader thread that reads data from the network will be pinned to CPU 2.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tA large number of threads that process this network data will be pinned to CPUs 4-23.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tA dedicated writer thread that writes the processed data to the network will be pinned to CPU 3.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have installed the \u003Ccode class=\"literal\">cpu-partitioning\u003C/code> TuneD profile by using the \u003Ccode class=\"literal\">dnf install tuned-profiles-cpu-partitioning\u003C/code> command as root.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEdit \u003Ccode class=\"literal\">/etc/tuned/cpu-partitioning-variables.conf\u003C/code> file and add the following information:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># All isolated CPUs:\nisolated_cores=2-23\n# Isolated CPUs without the kernel’s scheduler load balancing:\nno_balance_cores=2,3\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tSet the \u003Ccode class=\"literal\">cpu-partitioning\u003C/code> TuneD profile:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># tuned-adm profile cpu-partitioning\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tReboot\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAfter rebooting, the system is tuned for low-latency, according to the isolation in the cpu-partitioning figure. The application can use taskset to pin the reader and writer threads to CPUs 2 and 3, and the remaining application threads on CPUs 4-23.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">tuned-profiles-cpu-partitioning(7)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"customizing-the-cpu-partitioning-tuned-profile_getting-started-with-tuned\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">1.9. Customizing the cpu-partitioning TuneD profile\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can extend the TuneD profile to make additional tuning changes.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tFor example, the \u003Ccode class=\"literal\">cpu-partitioning\u003C/code> profile sets the CPUs to use \u003Ccode class=\"literal\">cstate=1\u003C/code>. In order to use the \u003Ccode class=\"literal\">cpu-partitioning\u003C/code> profile but to additionally change the CPU cstate from cstate1 to cstate0, the following procedure describes a new TuneD profile named \u003Cspan class=\"emphasis\">\u003Cem>my_profile\u003C/em>\u003C/span>, which inherits the \u003Ccode class=\"literal\">cpu-partitioning\u003C/code> profile and then sets C state-0.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate the \u003Ccode class=\"literal\">/etc/tuned/my_profile\u003C/code> directory:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mkdir /etc/tuned/\u003Cspan class=\"emphasis\">\u003Cem>my_profile\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a \u003Ccode class=\"literal\">tuned.conf\u003C/code> file in this directory, and add the following content:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># vi /etc/tuned/\u003Cspan class=\"emphasis\">\u003Cem>my_profile\u003C/em>\u003C/span>/tuned.conf\n[main]\nsummary=Customized tuning on top of cpu-partitioning\ninclude=cpu-partitioning\n[cpu]\nforce_latency=cstate.id:0|1\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tUse the new profile:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># tuned-adm profile \u003Cspan class=\"emphasis\">\u003Cem>my_profile\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tIn the shared example, a reboot is not required. However, if the changes in the \u003Cspan class=\"emphasis\">\u003Cem>my_profile\u003C/em>\u003C/span> profile require a reboot to take effect, then reboot your machine.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">tuned-profiles-cpu-partitioning(7)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"real-time-tuned-profiles-distributed-with-rhel_getting-started-with-tuned\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">1.10. Real-time TuneD profiles distributed with RHEL\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tReal-time profiles are intended for systems running the real-time kernel. Without a special kernel build, they do not configure the system to be real-time. On RHEL, the profiles are available from additional repositories.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe following real-time profiles are available:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">realtime\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tUse on bare-metal real-time systems.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tProvided by the \u003Ccode class=\"literal package\">tuned-profiles-realtime\u003C/code> package, which is available from the RT or NFV repositories.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">realtime-virtual-host\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tUse in a virtualization host configured for real-time.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tProvided by the \u003Ccode class=\"literal package\">tuned-profiles-nfv-host\u003C/code> package, which is available from the NFV repository.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">realtime-virtual-guest\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tUse in a virtualization guest configured for real-time.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tProvided by the \u003Ccode class=\"literal package\">tuned-profiles-nfv-guest\u003C/code> package, which is available from the NFV repository.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003C/dl>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"static-and-dynamic-tuning-in-tuned_getting-started-with-tuned\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">1.11. Static and dynamic tuning in TuneD\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tUnderstanding the difference between the two categories of system tuning that \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> applies, \u003Cspan class=\"emphasis\">\u003Cem>static\u003C/em>\u003C/span> and \u003Cspan class=\"emphasis\">\u003Cem>dynamic\u003C/em>\u003C/span>, is important when determining which one to use for a given situation or purpose.\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">Static tuning\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tMainly consists of the application of predefined \u003Ccode class=\"literal\">sysctl\u003C/code> and \u003Ccode class=\"literal\">sysfs\u003C/code> settings and one-shot activation of several configuration tools such as \u003Ccode class=\"literal\">ethtool\u003C/code>.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Dynamic tuning\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tWatches how various system components are used throughout the uptime of your system. \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> adjusts system settings dynamically based on that monitoring information.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFor example, the hard drive is used heavily during startup and login, but is barely used later when the user might mainly work with applications such as web browsers or email clients. Similarly, the CPU and network devices are used differently at different times. \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> monitors the activity of these components and reacts to the changes in their use.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tBy default, dynamic tuning is disabled. To enable it, edit the \u003Ccode class=\"literal filename\">/etc/tuned/tuned-main.conf\u003C/code> file and change the \u003Ccode class=\"literal option\">dynamic_tuning\u003C/code> option to \u003Ccode class=\"literal\">1\u003C/code>. \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> then periodically analyzes system statistics and uses them to update your system tuning settings. To configure the time interval in seconds between these updates, use the \u003Ccode class=\"literal option\">update_interval\u003C/code> option.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tCurrently implemented dynamic tuning algorithms try to balance the performance and powersave, and are therefore disabled in the performance profiles. Dynamic tuning for individual plug-ins can be enabled or disabled in the \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profiles.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"example\" id=\"idm140280148199536\">\u003Cp class=\"title\">\u003Cstrong>Example 1.2. Static and dynamic tuning on a workstation\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\tOn a typical office workstation, the Ethernet network interface is inactive most of the time. Only a few emails go in and out or some web pages might be loaded.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tFor those kinds of loads, the network interface does not have to run at full speed all the time, as it does by default. \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> has a monitoring and tuning plug-in for network devices that can detect this low activity and then automatically lower the speed of that interface, typically resulting in a lower power usage.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tIf the activity on the interface increases for a longer period of time, for example because a DVD image is being downloaded or an email with a large attachment is opened, \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> detects this and sets the interface speed to maximum to offer the best performance while the activity level is high.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tThis principle is used for other plug-ins for CPU and disks as well.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"tuned-no-daemon-mode_getting-started-with-tuned\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">1.12. TuneD no-daemon mode\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can run \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> in \u003Ccode class=\"literal\">no-daemon\u003C/code> mode, which does not require any resident memory. In this mode, \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> applies the settings and exits.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tBy default, \u003Ccode class=\"literal\">no-daemon\u003C/code> mode is disabled because a lot of \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> functionality is missing in this mode, including:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tD-Bus support\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tHot-plug support\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tRollback support for settings\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tTo enable \u003Ccode class=\"literal\">no-daemon\u003C/code> mode, include the following line in the \u003Ccode class=\"literal filename\">/etc/tuned/tuned-main.conf\u003C/code> file:\n\t\t\t\u003C/p>\u003Cpre class=\"screen\">daemon = 0\u003C/pre>\u003C/section>\u003Csection class=\"section\" id=\"installing-and-enabling-tuned_getting-started-with-tuned\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">1.13. Installing and enabling TuneD\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure installs and enables the \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> application, installs \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profiles, and presets a default \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profile for your system.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInstall the \u003Ccode class=\"literal package\">TuneD\u003C/code> package:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf install tuned\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnable and start the \u003Ccode class=\"literal\">TuneD\u003C/code> service:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># systemctl enable --now tuned\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOptional: Install \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profiles for real-time systems:\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor the \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profiles for real-time systems enable \u003Ccode class=\"literal\">rhel-9\u003C/code> repository.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># subscription-manager repos --enable=rhel-9-for-x86_64-nfv-beta-rpms\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInstall it.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf install tuned-profiles-realtime tuned-profiles-nfv\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify that a \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profile is active and applied:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ tuned-adm active\n\nCurrent active profile: \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">throughput-performance\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\tThe active profile TuneD automatically presets differs based on your machine type and system settings.\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cpre class=\"screen\">$ tuned-adm verify\n\nVerification succeeded, current system settings match the preset profile.\nSee tuned log file ('/var/log/tuned/tuned.log') for details.\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"listing-available-tuned-profiles_getting-started-with-tuned\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">1.14. Listing available TuneD profiles\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure lists all \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profiles that are currently available on your system.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo list all available \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profiles on your system, use:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen white-space-pre white-space-pre\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>tuned-adm list\u003C/strong>\u003C/span>\n\nAvailable profiles:\n- accelerator-performance - Throughput performance based tuning with disabled higher latency STOP states\n- balanced                - General non-specialized TuneD profile\n- desktop                 - Optimize for the desktop use-case\n- latency-performance     - Optimize for deterministic performance at the cost of increased power consumption\n- network-latency         - Optimize for deterministic performance at the cost of increased power consumption, focused on low latency network performance\n- network-throughput      - Optimize for streaming network throughput, generally only necessary on older CPUs or 40G+ networks\n- powersave               - Optimize for low power consumption\n- throughput-performance  - Broadly applicable tuning that provides excellent performance across a variety of common server workloads\n- virtual-guest           - Optimize for running inside a virtual guest\n- virtual-host            - Optimize for running KVM guests\nCurrent active profile: \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">balanced\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo display only the currently active profile, use:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>tuned-adm active\u003C/strong>\u003C/span>\n\nCurrent active profile: \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">throughput-performance\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">tuned-adm(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"setting-a-tuned-profile_getting-started-with-tuned\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">1.15. Setting a TuneD profile\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure activates a selected \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profile on your system.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">TuneD\u003C/code> service is running. See \u003Ca class=\"link\" href=\"#installing-and-enabling-tuned_getting-started-with-tuned\" title=\"1.13. Installing and enabling TuneD\">Installing and Enabling TuneD\u003C/a> for details.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOptional: You can let \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> recommend the most suitable profile for your system:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># tuned-adm recommend\n\n\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">throughput-performance\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tActivate a profile:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># tuned-adm profile \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">selected-profile\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAlternatively, you can activate a combination of multiple profiles:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># tuned-adm profile \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">selected-profile1\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">selected-profile2\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cdiv class=\"example\" id=\"idm140280148419296\">\u003Cp class=\"title\">\u003Cstrong>Example 1.3. A virtual machine optimized for low power consumption\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\t\t\tThe following example optimizes the system to run in a virtual machine with the best performance and concurrently tunes it for low power consumption, while the low power consumption is the priority:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># tuned-adm profile virtual-guest powersave\u003C/pre>\u003C/div>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tView the current active \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profile on your system:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># tuned-adm active\n\nCurrent active profile: \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">selected-profile\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tReboot the system:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># reboot\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify that the \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profile is active and applied:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ tuned-adm verify\n\nVerification succeeded, current system settings match the preset profile.\nSee tuned log file ('/var/log/tuned/tuned.log') for details.\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">tuned-adm(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"using-the-tuned-d-bus-interface_getting-started-with-tuned\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">1.16. Using the TuneD D-Bus interface\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can directly communicate with TuneD at runtime through the TuneD D-Bus interface to control a variety of TuneD services.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tYou can use the \u003Ccode class=\"literal\">busctl\u003C/code> or \u003Ccode class=\"literal\">dbus-send\u003C/code> commands to access the D-Bus API.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tAlthough you can use either the \u003Ccode class=\"literal\">busctl\u003C/code> or \u003Ccode class=\"literal\">dbus-send\u003C/code> command, the \u003Ccode class=\"literal\">busctl\u003C/code> command is a part of \u003Ccode class=\"literal\">systemd\u003C/code> and, therefore, present on most hosts already.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Csection class=\"section\" id=\"using-the-tuned-d-bus-interface-to-show-available-tuned-d-bus-api-methods_using-the-tuned-d-bus-interface\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">1.16.1. Using the TuneD D-Bus interface to show available TuneD D-Bus API methods\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\t\tYou can see the D-Bus API methods available to use with TuneD by using the TuneD D-Bus interface.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe TuneD service is running. See \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-tuned_monitoring-and-managing-system-status-and-performance#installing-and-enabling-tuned_getting-started-with-tuned\">Installing and Enabling TuneD\u003C/a> for details.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tTo see the available TuneD API methods, run:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ busctl introspect com.redhat.tuned /Tuned com.redhat.tuned.control\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe output should look similar to the following:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">NAME                       \tTYPE  \tSIGNATURE RESULT/VALUE FLAGS\n.active_profile            \tmethod\t-     \t  s            -\n.auto_profile              \tmethod\t-     \t  (bs)         -\n.disable                   \tmethod\t-      \t  b            -\n.get_all_plugins           \tmethod\t-     \t  a{sa{ss}}    -\n.get_plugin_documentation  \tmethod\ts     \t  s            -\n.get_plugin_hints          \tmethod\ts     \t  a{ss}        -\n.instance_acquire_devices  \tmethod\tss    \t  (bs)         -\n.is_running                \tmethod\t-     \t  b            -\n.log_capture_finish        \tmethod\ts     \t  s            -\n.log_capture_start         \tmethod\tii    \t  s            -\n.post_loaded_profile       \tmethod\t-     \t  s            -\n.profile_info              \tmethod\ts     \t  (bsss)       -\n.profile_mode              \tmethod\t-     \t  (ss)         -\n.profiles                  \tmethod\t-     \t  as           -\n.profiles2                 \tmethod\t-     \t  a(ss)        -\n.recommend_profile         \tmethod\t-     \t  s            -\n.register_socket_signal_path    method\ts     \t  b            -\n.reload                    \tmethod\t-     \t  b            -\n.start                     \tmethod\t-     \t  b            -\n.stop                      \tmethod\t-     \t  b            -\n.switch_profile            \tmethod\ts     \t  (bs)         -\n.verify_profile            \tmethod\t-     \t  b            -\n.verify_profile_ignore_missing  method\t-     \t  b            -\n.profile_changed           \tsignal\tsbs   \t  -            -\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tYou can find descriptions of the different available methods in the \u003Ca class=\"link\" href=\"https://github.com/redhat-performance/tuned/blob/master/com.redhat.tuned.policy\">TuneD upstream repository\u003C/a>.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"using-the-tuned-d-bus-interface-to-change-the-active-tuned-profile_using-the-tuned-d-bus-interface\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">1.16.2. Using the TuneD D-Bus interface to change the active TuneD profile\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\t\tYou can replace the active TuneD profile with your desired TuneD profile by using the TuneD D-Bus interface.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe TuneD service is running. See \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-tuned_monitoring-and-managing-system-status-and-performance#installing-and-enabling-tuned_getting-started-with-tuned\">Installing and Enabling TuneD\u003C/a> for details.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tTo change the active TuneD profile, run:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ busctl call com.redhat.tuned /Tuned com.redhat.tuned.control switch_profile s \u003Cspan class=\"emphasis\">\u003Cem>profile\u003C/em>\u003C/span>\n(bs) true \"OK\"\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>profile\u003C/em>\u003C/span> with the name of your desired profile.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tTo view the current active TuneD profile, run:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ busctl call com.redhat.tuned /Tuned com.redhat.tuned.control active_profile\ns \"\u003Cspan class=\"emphasis\">\u003Cem>profile\u003C/em>\u003C/span>\"\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"section\" id=\"disabling-tuned_getting-started-with-tuned\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">1.17. Disabling TuneD\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure disables \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> and resets all affected system settings to their original state before \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> modified them.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo disable all tunings temporarily:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># tuned-adm off\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe tunings are applied again after the \u003Ccode class=\"literal\">TuneD\u003C/code> service restarts.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAlternatively, to stop and disable the \u003Ccode class=\"literal\">TuneD\u003C/code> service permanently:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># systemctl disable --now tuned\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">tuned-adm(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"customizing-tuned-profiles_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 2. Customizing TuneD profiles\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tYou can create or modify \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profiles to optimize system performance for your intended use case.\n\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\tInstall and enable \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> as described in \u003Ca class=\"link\" href=\"#installing-and-enabling-tuned_getting-started-with-tuned\" title=\"1.13. Installing and enabling TuneD\">Installing and Enabling TuneD\u003C/a> for details.\n\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Csection class=\"section\" id=\"tuned-profiles_customizing-tuned-profiles\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">2.1. TuneD profiles\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tA detailed analysis of a system can be very time-consuming. \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> provides a number of predefined profiles for typical use cases. You can also create, modify, and delete profiles.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe profiles provided with \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> are divided into the following categories:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tPower-saving profiles\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tPerformance-boosting profiles\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tThe performance-boosting profiles include profiles that focus on the following aspects:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tLow latency for storage and network\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tHigh throughput for storage and network\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tVirtual machine performance\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tVirtualization host performance\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Ch5 id=\"syntax_of_profile_configuration_2\">Syntax of profile configuration\u003C/h5>\u003Cp>\n\t\t\t\tThe \u003Ccode class=\"literal\">tuned.conf\u003C/code> file can contain one \u003Ccode class=\"literal\">[main]\u003C/code> section and other sections for configuring plug-in instances. However, all sections are optional.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tLines starting with the hash sign (\u003Ccode class=\"literal\">#\u003C/code>) are comments.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">tuned.conf(5)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"the-default-tuned-profile_customizing-tuned-profiles\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">2.2. The default TuneD profile\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tDuring the installation, the best profile for your system is selected automatically. Currently, the default profile is selected according to the following customizable rules:\n\t\t\t\u003C/p>\u003Crh-table>\u003Ctable class=\"lt-4-cols lt-7-rows\">\u003Ccolgroup>\u003Ccol style=\"width: 29%; \" class=\"col_1\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 29%; \" class=\"col_2\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 43%; \" class=\"col_3\">\u003C!--Empty-->\u003C/col>\u003C/colgroup>\u003Cthead>\u003Ctr>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280148905584\" scope=\"col\">Environment\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280149435088\" scope=\"col\">Default profile\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280149434000\" scope=\"col\">Goal\u003C/th>\u003C/tr>\u003C/thead>\u003Ctbody>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280148905584\"> \u003Cp>\n\t\t\t\t\t\t\t\tCompute nodes\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280149435088\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">throughput-performance\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280149434000\"> \u003Cp>\n\t\t\t\t\t\t\t\tThe best throughput performance\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280148905584\"> \u003Cp>\n\t\t\t\t\t\t\t\tVirtual machines\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280149435088\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">virtual-guest\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280149434000\"> \u003Cp>\n\t\t\t\t\t\t\t\tThe best performance. If you are not interested in the best performance, you can change it to the \u003Ccode class=\"literal\">balanced\u003C/code> or \u003Ccode class=\"literal\">powersave\u003C/code> profile.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280148905584\"> \u003Cp>\n\t\t\t\t\t\t\t\tOther cases\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280149435088\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">balanced\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280149434000\"> \u003Cp>\n\t\t\t\t\t\t\t\tBalanced performance and power consumption\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\u003C/rh-table>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">tuned.conf(5)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"merged-tuned-profiles_customizing-tuned-profiles\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">2.3. Merged TuneD profiles\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tAs an experimental feature, it is possible to select more profiles at once. \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> will try to merge them during the load.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tIf there are conflicts, the settings from the last specified profile takes precedence.\n\t\t\t\u003C/p>\u003Cdiv class=\"example\" id=\"idm140280159482160\">\u003Cp class=\"title\">\u003Cstrong>Example 2.1. Low power consumption in a virtual guest\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\tThe following example optimizes the system to run in a virtual machine for the best performance and concurrently tunes it for low power consumption, while the low power consumption is the priority:\n\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># tuned-adm profile virtual-guest powersave\u003C/pre>\u003C/div>\u003C/div>\u003Crh-alert class=\"admonition warning\" state=\"danger\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Warning\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tMerging is done automatically without checking whether the resulting combination of parameters makes sense. Consequently, the feature might tune some parameters the opposite way, which might be counterproductive: for example, setting the disk for high throughput by using the \u003Ccode class=\"literal\">throughput-performance\u003C/code> profile and concurrently setting the disk spindown to the low value by the \u003Ccode class=\"literal\">spindown-disk\u003C/code> profile.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">tuned-adm\u003C/code> and \u003Ccode class=\"literal\">tuned.conf(5)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"the-location-of-tuned-profiles_customizing-tuned-profiles\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">2.4. The location of TuneD profiles\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> stores profiles in the following directories:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal filename\">/usr/lib/tuned/\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDistribution-specific profiles are stored in the directory. Each profile has its own directory. The profile consists of the main configuration file called \u003Ccode class=\"literal\">tuned.conf\u003C/code>, and optionally other files, for example helper scripts.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal filename\">/etc/tuned/\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tIf you need to customize a profile, copy the profile directory into the directory, which is used for custom profiles. If there are two profiles of the same name, the custom profile located in \u003Ccode class=\"literal filename\">/etc/tuned/\u003C/code> is used.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">tuned.conf(5)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"inheritance-between-tuned-profiles_customizing-tuned-profiles\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">2.5. Inheritance between TuneD profiles\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profiles can be based on other profiles and modify only certain aspects of their parent profile.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe \u003Ccode class=\"literal\">[main]\u003C/code> section of \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profiles recognizes the \u003Ccode class=\"literal option\">include\u003C/code> option:\n\t\t\t\u003C/p>\u003Cpre class=\"screen\">[main]\ninclude=\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">parent\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cp>\n\t\t\t\tAll settings from the \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">parent\u003C/span>\u003C/em>\u003C/span> profile are loaded in this \u003Cspan class=\"emphasis\">\u003Cem>child\u003C/em>\u003C/span> profile. In the following sections, the \u003Cspan class=\"emphasis\">\u003Cem>child\u003C/em>\u003C/span> profile can override certain settings inherited from the \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">parent\u003C/span>\u003C/em>\u003C/span> profile or add new settings not present in the \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">parent\u003C/span>\u003C/em>\u003C/span> profile.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tYou can create your own \u003Cspan class=\"emphasis\">\u003Cem>child\u003C/em>\u003C/span> profile in the \u003Ccode class=\"literal filename\">/etc/tuned/\u003C/code> directory based on a pre-installed profile in \u003Ccode class=\"literal filename\">/usr/lib/tuned/\u003C/code> with only some parameters adjusted.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tIf the \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">parent\u003C/span>\u003C/em>\u003C/span> profile is updated, such as after a \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> upgrade, the changes are reflected in the \u003Cspan class=\"emphasis\">\u003Cem>child\u003C/em>\u003C/span> profile.\n\t\t\t\u003C/p>\u003Cdiv class=\"example\" id=\"idm140280153160048\">\u003Cp class=\"title\">\u003Cstrong>Example 2.2. A power-saving profile based on balanced\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\tThe following is an example of a custom profile that extends the \u003Ccode class=\"literal\">balanced\u003C/code> profile and sets Aggressive Link Power Management (ALPM) for all devices to the maximum powersaving.\n\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">[main]\ninclude=balanced\n\n[scsi_host]\nalpm=min_power\u003C/pre>\u003C/div>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">tuned.conf(5)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"static-and-dynamic-tuning-in-tuned_customizing-tuned-profiles\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">2.6. Static and dynamic tuning in TuneD\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tUnderstanding the difference between the two categories of system tuning that \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> applies, \u003Cspan class=\"emphasis\">\u003Cem>static\u003C/em>\u003C/span> and \u003Cspan class=\"emphasis\">\u003Cem>dynamic\u003C/em>\u003C/span>, is important when determining which one to use for a given situation or purpose.\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">Static tuning\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tMainly consists of the application of predefined \u003Ccode class=\"literal\">sysctl\u003C/code> and \u003Ccode class=\"literal\">sysfs\u003C/code> settings and one-shot activation of several configuration tools such as \u003Ccode class=\"literal\">ethtool\u003C/code>.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Dynamic tuning\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tWatches how various system components are used throughout the uptime of your system. \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> adjusts system settings dynamically based on that monitoring information.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFor example, the hard drive is used heavily during startup and login, but is barely used later when the user might mainly work with applications such as web browsers or email clients. Similarly, the CPU and network devices are used differently at different times. \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> monitors the activity of these components and reacts to the changes in their use.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tBy default, dynamic tuning is disabled. To enable it, edit the \u003Ccode class=\"literal filename\">/etc/tuned/tuned-main.conf\u003C/code> file and change the \u003Ccode class=\"literal option\">dynamic_tuning\u003C/code> option to \u003Ccode class=\"literal\">1\u003C/code>. \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> then periodically analyzes system statistics and uses them to update your system tuning settings. To configure the time interval in seconds between these updates, use the \u003Ccode class=\"literal option\">update_interval\u003C/code> option.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tCurrently implemented dynamic tuning algorithms try to balance the performance and powersave, and are therefore disabled in the performance profiles. Dynamic tuning for individual plug-ins can be enabled or disabled in the \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profiles.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"example\" id=\"idm140280143659776\">\u003Cp class=\"title\">\u003Cstrong>Example 2.3. Static and dynamic tuning on a workstation\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\tOn a typical office workstation, the Ethernet network interface is inactive most of the time. Only a few emails go in and out or some web pages might be loaded.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tFor those kinds of loads, the network interface does not have to run at full speed all the time, as it does by default. \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> has a monitoring and tuning plug-in for network devices that can detect this low activity and then automatically lower the speed of that interface, typically resulting in a lower power usage.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tIf the activity on the interface increases for a longer period of time, for example because a DVD image is being downloaded or an email with a large attachment is opened, \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> detects this and sets the interface speed to maximum to offer the best performance while the activity level is high.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tThis principle is used for other plug-ins for CPU and disks as well.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"tuned-plug-ins_customizing-tuned-profiles\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">2.7. TuneD plug-ins\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tPlug-ins are modules in \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profiles that \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> uses to monitor or optimize different devices on the system.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> uses two types of plug-ins:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">Monitoring plug-ins\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tMonitoring plug-ins are used to get information from a running system. The output of the monitoring plug-ins can be used by tuning plug-ins for dynamic tuning.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tMonitoring plug-ins are automatically instantiated whenever their metrics are needed by any of the enabled tuning plug-ins. If two tuning plug-ins require the same data, only one instance of the monitoring plug-in is created and the data is shared.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Tuning plug-ins\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tEach tuning plug-in tunes an individual subsystem and takes several parameters that are populated from the TuneD profiles. Each subsystem can have multiple devices, such as multiple CPUs or network cards, that are handled by individual instances of the tuning plug-ins. Specific settings for individual devices are also supported.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Ch5 id=\"syntax_for_plug_ins_in_tuned_profiles\">Syntax for plug-ins in TuneD profiles\u003C/h5>\u003Cp>\n\t\t\t\tSections describing plug-in instances are formatted in the following way:\n\t\t\t\u003C/p>\u003Cpre class=\"screen\">[\u003Cspan class=\"emphasis\">\u003Cem>NAME\u003C/em>\u003C/span>]\ntype=\u003Cspan class=\"emphasis\">\u003Cem>TYPE\u003C/em>\u003C/span>\ndevices=\u003Cspan class=\"emphasis\">\u003Cem>DEVICES\u003C/em>\u003C/span>\u003C/pre>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">NAME\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tis the name of the plug-in instance as it is used in the logs. It can be an arbitrary string.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">TYPE\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tis the type of the tuning plug-in.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">DEVICES\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tis the list of devices that this plug-in instance handles.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">devices\u003C/code> line can contain a list, a wildcard (\u003Ccode class=\"literal\">*\u003C/code>), and negation (\u003Ccode class=\"literal\">!\u003C/code>). If there is no \u003Ccode class=\"literal\">devices\u003C/code> line, all devices present or later attached on the system of the \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">TYPE\u003C/span>\u003C/em>\u003C/span> are handled by the plug-in instance. This is same as using the \u003Ccode class=\"literal option\">devices=*\u003C/code> option.\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"example\" id=\"idm140280160531840\">\u003Cp class=\"title\">\u003Cstrong>Example 2.4. Matching block devices with a plug-in\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\t\t\t\tThe following example matches all block devices starting with \u003Ccode class=\"literal\">sd\u003C/code>, such as \u003Ccode class=\"literal\">sda\u003C/code> or \u003Ccode class=\"literal\">sdb\u003C/code>, and does not disable barriers on them:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">[data_disk]\ntype=disk\ndevices=sd*\ndisable_barriers=false\u003C/pre>\u003Cp>\n\t\t\t\t\t\t\t\tThe following example matches all block devices except \u003Ccode class=\"literal\">sda1\u003C/code> and \u003Ccode class=\"literal\">sda2\u003C/code>:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">[data_disk]\ntype=disk\ndevices=!sda1, !sda2\ndisable_barriers=false\u003C/pre>\u003C/div>\u003C/div>\u003C/dd>\u003C/dl>\u003C/div>\u003Cp>\n\t\t\t\tIf no instance of a plug-in is specified, the plug-in is not enabled.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tIf the plug-in supports more options, they can be also specified in the plug-in section. If the option is not specified and it was not previously specified in the included plug-in, the default value is used.\n\t\t\t\u003C/p>\u003Ch5 id=\"short_plug_in_syntax\">Short plug-in syntax\u003C/h5>\u003Cp>\n\t\t\t\tIf you do not need custom names for the plug-in instance and there is only one definition of the instance in your configuration file, \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> supports the following short syntax:\n\t\t\t\u003C/p>\u003Cpre class=\"screen\">[\u003Cspan class=\"emphasis\">\u003Cem>TYPE\u003C/em>\u003C/span>]\ndevices=\u003Cspan class=\"emphasis\">\u003Cem>DEVICES\u003C/em>\u003C/span>\u003C/pre>\u003Cp>\n\t\t\t\tIn this case, it is possible to omit the \u003Ccode class=\"literal\">type\u003C/code> line. The instance is then referred to with a name, same as the type. The previous example could be then rewritten into:\n\t\t\t\u003C/p>\u003Cdiv class=\"example\" id=\"idm140280155091088\">\u003Cp class=\"title\">\u003Cstrong>Example 2.5. Matching block devices using the short syntax\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cpre class=\"screen\">[disk]\ndevices=sdb*\ndisable_barriers=false\u003C/pre>\u003C/div>\u003C/div>\u003Ch5 id=\"conflicting_plug_in_definitions_in_a_profile\">Conflicting plug-in definitions in a profile\u003C/h5>\u003Cp>\n\t\t\t\tIf the same section is specified more than once using the \u003Ccode class=\"literal\">include\u003C/code> option, the settings are merged. If they cannot be merged due to a conflict, the last conflicting definition overrides the previous settings. If you do not know what was previously defined, you can use the \u003Ccode class=\"literal option\">replace\u003C/code> Boolean option and set it to \u003Ccode class=\"literal\">true\u003C/code>. This causes all the previous definitions with the same name to be overwritten and the merge does not happen.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tYou can also disable the plug-in by specifying the \u003Ccode class=\"literal option\">enabled=false\u003C/code> option. This has the same effect as if the instance was never defined. Disabling the plug-in is useful if you are redefining the previous definition from the \u003Ccode class=\"literal option\">include\u003C/code> option and do not want the plug-in to be active in your custom profile.\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">NOTE\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> includes the ability to run any shell command as part of enabling or disabling a tuning profile. This enables you to extend \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profiles with functionality that has not been integrated into TuneD yet.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tYou can specify arbitrary shell commands using the \u003Ccode class=\"literal\">script\u003C/code> plug-in.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">tuned.conf(5)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"available-tuned-plug-ins_customizing-tuned-profiles\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">2.8. Available TuneD plug-ins\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Ch5 id=\"monitoring_plug_ins\">Monitoring plug-ins\u003C/h5>\u003Cp>\n\t\t\t\tCurrently, the following monitoring plug-ins are implemented:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">disk\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tGets disk load (number of IO operations) per device and measurement interval.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">net\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tGets network load (number of transferred packets) per network card and measurement interval.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">load\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tGets CPU load per CPU and measurement interval.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Ch5 id=\"tuning_plug_ins\">Tuning plug-ins\u003C/h5>\u003Cp>\n\t\t\t\tCurrently, the following tuning plug-ins are implemented. Only some of these plug-ins implement dynamic tuning. Options supported by plug-ins are also listed:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">cpu\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tSets the CPU governor to the value specified by the \u003Ccode class=\"literal option\">governor\u003C/code> option and dynamically changes the Power Management Quality of Service (PM QoS) CPU Direct Memory Access (DMA) latency according to the CPU load.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIf the CPU load is lower than the value specified by the \u003Ccode class=\"literal option\">load_threshold\u003C/code> option, the latency is set to the value specified by the \u003Ccode class=\"literal option\">latency_high\u003C/code> option, otherwise it is set to the value specified by \u003Ccode class=\"literal option\">latency_low\u003C/code>.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tYou can also force the latency to a specific value and prevent it from dynamically changing further. To do so, set the \u003Ccode class=\"literal option\">force_latency\u003C/code> option to the required latency value.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">eeepc_she\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tDynamically sets the front-side bus (FSB) speed according to the CPU load.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThis feature can be found on some netbooks and is also known as the ASUS Super Hybrid Engine (SHE).\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIf the CPU load is lower or equal to the value specified by the \u003Ccode class=\"literal option\">load_threshold_powersave\u003C/code> option, the plug-in sets the FSB speed to the value specified by the \u003Ccode class=\"literal option\">she_powersave\u003C/code> option. If the CPU load is higher or equal to the value specified by the \u003Ccode class=\"literal option\">load_threshold_normal\u003C/code> option, it sets the FSB speed to the value specified by the \u003Ccode class=\"literal option\">she_normal\u003C/code> option.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tStatic tuning is not supported and the plug-in is transparently disabled if \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> does not detect the hardware support for this feature.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">net\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tConfigures the Wake-on-LAN functionality to the values specified by the \u003Ccode class=\"literal option\">wake_on_lan\u003C/code> option. It uses the same syntax as the \u003Ccode class=\"literal\">ethtool\u003C/code> utility. It also dynamically changes the interface speed according to the interface utilization.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">sysctl\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tSets various \u003Ccode class=\"literal\">sysctl\u003C/code> settings specified by the plug-in options.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe syntax is \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">name\u003C/span>\u003C/em>\u003C/span>=\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">value\u003C/span>\u003C/em>\u003C/span>\u003C/code>, where \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">name\u003C/span>\u003C/em>\u003C/span> is the same as the name provided by the \u003Ccode class=\"literal\">sysctl\u003C/code> utility.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tUse the \u003Ccode class=\"literal\">sysctl\u003C/code> plug-in if you need to change system settings that are not covered by other plug-ins available in \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span>. If the settings are covered by some specific plug-ins, prefer these plug-ins.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">usb\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tSets autosuspend timeout of USB devices to the value specified by the \u003Ccode class=\"literal option\">autosuspend\u003C/code> parameter.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe value \u003Ccode class=\"literal\">0\u003C/code> means that autosuspend is disabled.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">vm\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tEnables or disables transparent huge pages depending on the value of the \u003Ccode class=\"literal option\">transparent_hugepages\u003C/code> option.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tValid values of the \u003Ccode class=\"literal option\">transparent_hugepages\u003C/code> option are:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\"always\"\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\"never\"\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\"madvise\"\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">audio\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tSets the autosuspend timeout for audio codecs to the value specified by the \u003Ccode class=\"literal option\">timeout\u003C/code> option.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tCurrently, the \u003Ccode class=\"literal\">snd_hda_intel\u003C/code> and \u003Ccode class=\"literal\">snd_ac97_codec\u003C/code> codecs are supported. The value \u003Ccode class=\"literal\">0\u003C/code> means that the autosuspend is disabled. You can also enforce the controller reset by setting the Boolean option \u003Ccode class=\"literal option\">reset_controller\u003C/code> to \u003Ccode class=\"literal\">true\u003C/code>.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">disk\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tSets the disk elevator to the value specified by the \u003Ccode class=\"literal option\">elevator\u003C/code> option.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIt also sets:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tAPM to the value specified by the \u003Ccode class=\"literal option\">apm\u003C/code> option\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tScheduler quantum to the value specified by the \u003Ccode class=\"literal option\">scheduler_quantum\u003C/code> option\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tDisk spindown timeout to the value specified by the \u003Ccode class=\"literal option\">spindown\u003C/code> option\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tDisk readahead to the value specified by the \u003Ccode class=\"literal option\">readahead\u003C/code> parameter\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tThe current disk readahead to a value multiplied by the constant specified by the \u003Ccode class=\"literal option\">readahead_multiply\u003C/code> option\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIn addition, this plug-in dynamically changes the advanced power management and spindown timeout setting for the drive according to the current drive utilization. The dynamic tuning can be controlled by the Boolean option \u003Ccode class=\"literal option\">dynamic\u003C/code> and is enabled by default.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">scsi_host\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tTunes options for SCSI hosts.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIt sets Aggressive Link Power Management (ALPM) to the value specified by the \u003Ccode class=\"literal option\">alpm\u003C/code> option.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">mounts\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tEnables or disables barriers for mounts according to the Boolean value of the \u003Ccode class=\"literal option\">disable_barriers\u003C/code> option.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">script\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tExecutes an external script or binary when the profile is loaded or unloaded. You can choose an arbitrary executable.\n\t\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">script\u003C/code> plug-in is provided mainly for compatibility with earlier releases. Prefer other \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> plug-ins if they cover the required functionality.\n\t\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> calls the executable with one of the following arguments:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">start\u003C/code> when loading the profile\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">stop\u003C/code> when unloading the profile\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tYou need to correctly implement the \u003Ccode class=\"literal\">stop\u003C/code> action in your executable and revert all settings that you changed during the \u003Ccode class=\"literal\">start\u003C/code> action. Otherwise, the roll-back step after changing your \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profile will not work.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tBash scripts can import the \u003Ccode class=\"literal filename\">/usr/lib/tuned/functions\u003C/code> Bash library and use the functions defined there. Use these functions only for functionality that is not natively provided by \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span>. If a function name starts with an underscore, such as \u003Ccode class=\"literal\">_wifi_set_power_level\u003C/code>, consider the function private and do not use it in your scripts, because it might change in the future.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tSpecify the path to the executable using the \u003Ccode class=\"literal\">script\u003C/code> parameter in the plug-in configuration.\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"example\" id=\"idm140280155386608\">\u003Cp class=\"title\">\u003Cstrong>Example 2.6. Running a Bash script from a profile\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\t\t\t\tTo run a Bash script named \u003Ccode class=\"literal\">script.sh\u003C/code> that is located in the profile directory, use:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">[script]\nscript=${i:PROFILE_DIR}/script.sh\u003C/pre>\u003C/div>\u003C/div>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">sysfs\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tSets various \u003Ccode class=\"literal\">sysfs\u003C/code> settings specified by the plug-in options.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe syntax is \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">name\u003C/span>\u003C/em>\u003C/span>=\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">value\u003C/span>\u003C/em>\u003C/span>\u003C/code>, where \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">name\u003C/span>\u003C/em>\u003C/span> is the \u003Ccode class=\"literal\">sysfs\u003C/code> path to use.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tUse this plugin in case you need to change some settings that are not covered by other plug-ins. Prefer specific plug-ins if they cover the required settings.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">video\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tSets various powersave levels on video cards. Currently, only the Radeon cards are supported.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe powersave level can be specified by using the \u003Ccode class=\"literal option\">radeon_powersave\u003C/code> option. Supported values are:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">default\u003C/code>\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">auto\u003C/code>\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">low\u003C/code>\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">mid\u003C/code>\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">high\u003C/code>\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">dynpm\u003C/code>\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">dpm-battery\u003C/code>\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">dpm-balanced\u003C/code>\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">dpm-perfomance\u003C/code>\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFor details, see \u003Ca class=\"link\" href=\"https://www.x.org/wiki/RadeonFeature/#KMS_Power_Management_Options\">www.x.org\u003C/a>. Note that this plug-in is experimental and the option might change in future releases.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">bootloader\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tAdds options to the kernel command line. This plug-in supports only the GRUB 2 boot loader.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tCustomized non-standard location of the GRUB 2 configuration file can be specified by the \u003Ccode class=\"literal option\">grub2_cfg_file\u003C/code> option.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe kernel options are added to the current GRUB configuration and its templates. The system needs to be rebooted for the kernel options to take effect.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tSwitching to another profile or manually stopping the \u003Ccode class=\"literal\">TuneD\u003C/code> service removes the additional options. If you shut down or reboot the system, the kernel options persist in the \u003Ccode class=\"literal filename\">grub.cfg\u003C/code> file.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe kernel options can be specified by the following syntax:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">cmdline=\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">arg1\u003C/span>\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">arg2\u003C/span>\u003C/em>\u003C/span> ... \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">argN\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cdiv class=\"example\" id=\"idm140280137455712\">\u003Cp class=\"title\">\u003Cstrong>Example 2.7. Modifying the kernel command line\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\t\t\t\tFor example, to add the \u003Ccode class=\"literal option\">quiet\u003C/code> kernel option to a \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profile, include the following lines in the \u003Ccode class=\"literal filename\">tuned.conf\u003C/code> file:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">[bootloader]\ncmdline=quiet\u003C/pre>\u003Cp>\n\t\t\t\t\t\t\t\tThe following is an example of a custom profile that adds the \u003Ccode class=\"literal option\">isolcpus=2\u003C/code> option to the kernel command line:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">[bootloader]\ncmdline=isolcpus=2\u003C/pre>\u003C/div>\u003C/div>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">service\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tHandles various \u003Ccode class=\"literal\">sysvinit\u003C/code>, \u003Ccode class=\"literal\">sysv-rc\u003C/code>, \u003Ccode class=\"literal\">openrc\u003C/code>, and \u003Ccode class=\"literal\">systemd\u003C/code> services specified by the plug-in options.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe syntax is \u003Ccode class=\"literal\">service.\u003Cspan class=\"emphasis\">\u003Cem>service_name\u003C/em>\u003C/span>=\u003Cspan class=\"emphasis\">\u003Cem>command\u003C/em>\u003C/span>[,file:\u003Cspan class=\"emphasis\">\u003Cem>file\u003C/em>\u003C/span>]\u003C/code>.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tSupported service-handling commands are:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">start\u003C/code>\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">stop\u003C/code>\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">enable\u003C/code>\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">disable\u003C/code>\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tSeparate multiple commands using either a comma (\u003Ccode class=\"literal\">,\u003C/code>) or a semicolon (\u003Ccode class=\"literal\">;\u003C/code>). If the directives conflict, the \u003Ccode class=\"literal\">service\u003C/code> plugin uses the last listed one.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tUse the optional \u003Ccode class=\"literal\">file:\u003Cspan class=\"emphasis\">\u003Cem>file\u003C/em>\u003C/span>\u003C/code> directive to install an overlay configuration file, \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>file\u003C/em>\u003C/span>\u003C/code>, for \u003Ccode class=\"literal\">systemd\u003C/code> only. Other init systems ignore this directive. The \u003Ccode class=\"literal\">service\u003C/code> plugin copies overlay configuration files to \u003Ccode class=\"literal\">/etc/systemd/system/\u003Cspan class=\"emphasis\">\u003Cem>service_name\u003C/em>\u003C/span>.service.d/\u003C/code> directories. Once profiles are unloaded, the \u003Ccode class=\"literal\">service\u003C/code> plugin removes these directories if they are empty.\n\t\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">service\u003C/code> plugin only operates on the current runlevel with non-\u003Ccode class=\"literal\">systemd\u003C/code> init systems.\n\t\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"example\" id=\"idm140280161031456\">\u003Cp class=\"title\">\u003Cstrong>Example 2.8. Starting and enabling the sendmail \u003Ccode class=\"literal\">sendmail\u003C/code> service with an overlay file\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cpre class=\"screen\">[service]\nservice.sendmail=start,enable,file:${i:PROFILE_DIR}/tuned-sendmail.conf\u003C/pre>\u003Cp>\n\t\t\t\t\t\t\t\tThe internal variable \u003Ccode class=\"literal\">${i:PROFILE_DIR}\u003C/code> points to the directory the plugin loads the profile from.\n\t\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/div>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">scheduler\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tOffers a variety of options for the tuning of scheduling priorities, CPU core isolation, and process, thread, and IRQ affinities.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cp>\n\t\t\t\tFor specifics of the different options available, see \u003Ca class=\"link\" href=\"#functionalities-of-the-scheduler-tuned-plug-in_customizing-tuned-profiles\" title=\"2.9. Functionalities of the scheduler TuneD plugin\">Functionalities of the \u003Ccode class=\"literal\">scheduler\u003C/code> TuneD plug-in\u003C/a>.\n\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"functionalities-of-the-scheduler-tuned-plug-in_customizing-tuned-profiles\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">2.9. Functionalities of the \u003Ccode class=\"literal\">scheduler\u003C/code> TuneD plugin\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tUse the \u003Ccode class=\"literal\">scheduler\u003C/code> \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> plugin to control and tune scheduling priorities, CPU core isolation, and process, thread, and IRQ afinities.\n\t\t\t\u003C/p>\u003Cdiv class=\"formalpara\">\u003Cp class=\"title\">\u003Cstrong>CPU isolation\u003C/strong>\u003C/p>\u003Cp>\n\t\t\t\t\tTo prevent processes, threads, and IRQs from using certain CPUs, use the \u003Ccode class=\"literal option\">isolated_cores\u003C/code> option. It changes process and thread affinities, IRQ affinities, and sets the \u003Ccode class=\"literal\">default_smp_affinity\u003C/code> parameter for IRQs.\n\t\t\t\t\u003C/p>\u003C/div>\u003Cp>\n\t\t\t\tThe CPU affinity mask is adjusted for all processes and threads matching the \u003Ccode class=\"literal option\">ps_whitelist\u003C/code> option, subject to success of the \u003Ccode class=\"literal\">sched_setaffinity()\u003C/code> system call. The default setting of the \u003Ccode class=\"literal option\">ps_whitelist\u003C/code> regular expression is \u003Ccode class=\"literal\">.*\u003C/code> to match all processes and thread names. To exclude certain processes and threads, use the \u003Ccode class=\"literal option\">ps_blacklist\u003C/code> option. The value of this option is also interpreted as a regular expression. Process and thread names are matched against that expression. Profile rollback enables all matching processes and threads to run on all CPUs, and restores the IRQ settings prior to the profile application.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tMultiple regular expressions separated by \u003Ccode class=\"literal\">;\u003C/code> for the \u003Ccode class=\"literal option\">ps_whitelist\u003C/code> and \u003Ccode class=\"literal option\">ps_blacklist\u003C/code> options are supported. Escaped semicolon \u003Ccode class=\"literal\">\\;\u003C/code> is taken literally.\n\t\t\t\u003C/p>\u003Cdiv class=\"example\" id=\"idm140280151825456\">\u003Cp class=\"title\">\u003Cstrong>Example 2.9. Isolate CPUs 2-4\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\tThe following configuration isolates CPUs 2-4. Processes and threads that match the \u003Ccode class=\"literal\">ps_blacklist\u003C/code> regular expression can use any CPUs regardless of the isolation:\n\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">[scheduler]\nisolated_cores=2-4\nps_blacklist=.*pmd.*;.*PMD.*;^DPDK;.*qemu-kvm.*\u003C/pre>\u003C/div>\u003C/div>\u003Cdiv class=\"formalpara\">\u003Cp class=\"title\">\u003Cstrong>IRQ SMP affinity\u003C/strong>\u003C/p>\u003Cp>\n\t\t\t\t\tThe \u003Ccode class=\"literal\">/proc/irq/default_smp_affinity\u003C/code> file contains a bitmask representing the default target CPU cores on a system for all inactive interrupt request (IRQ) sources. Once an IRQ is activated or allocated, the value in the \u003Ccode class=\"literal\">/proc/irq/default_smp_affinity\u003C/code> file determines the IRQ’s affinity bitmask.\n\t\t\t\t\u003C/p>\u003C/div>\u003Cp>\n\t\t\t\tThe \u003Ccode class=\"literal\">default_irq_smp_affinity\u003C/code> parameter controls what \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> writes to the \u003Ccode class=\"literal\">/proc/irq/default_smp_affinity\u003C/code> file. The \u003Ccode class=\"literal\">default_irq_smp_affinity\u003C/code> parameter supports the following values and behaviors:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">calc\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tCalculates the content of the \u003Ccode class=\"literal\">/proc/irq/default_smp_affinity\u003C/code> file from the \u003Ccode class=\"literal\">isolated_cores\u003C/code> parameter. An inversion of the \u003Ccode class=\"literal\">isolated_cores\u003C/code> parameter calculates the non-isolated cores.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe intersection of the non-isolated cores and the previous content of the \u003Ccode class=\"literal\">/proc/irq/default_smp_affinity\u003C/code> file is then written to the \u003Ccode class=\"literal\">/proc/irq/default_smp_affinity\u003C/code> file.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThis is the default behavior if the \u003Ccode class=\"literal\">default_irq_smp_affinity\u003C/code> parameter is omitted.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">ignore\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> does not modify the \u003Ccode class=\"literal\">/proc/irq/default_smp_affinity\u003C/code> file.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">A CPU list\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tTakes the form of a single number such as \u003Ccode class=\"literal\">1\u003C/code>, a comma separated list such as \u003Ccode class=\"literal\">1,3\u003C/code>, or a range such as \u003Ccode class=\"literal\">3-5\u003C/code>.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tUnpacks the CPU list and writes it directly to the \u003Ccode class=\"literal\">/proc/irq/default_smp_affinity\u003C/code> file.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"example\" id=\"idm140280148669888\">\u003Cp class=\"title\">\u003Cstrong>Example 2.10. Setting the default IRQ smp affinity using an explicit CPU list\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\tThe following example uses an explicit CPU list to set the default IRQ SMP affinity to CPUs 0 and 2:\n\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">[scheduler]\nisolated_cores=1,3\ndefault_irq_smp_affinity=0,2\u003C/pre>\u003C/div>\u003C/div>\u003Cdiv class=\"formalpara\">\u003Cp class=\"title\">\u003Cstrong>Scheduling policy\u003C/strong>\u003C/p>\u003Cp>\n\t\t\t\t\tTo adjust scheduling policy, priority and affinity for a group of processes or threads, use the following syntax:\n\t\t\t\t\u003C/p>\u003C/div>\u003Cpre class=\"screen\">group.\u003Cspan class=\"emphasis\">\u003Cem>groupname\u003C/em>\u003C/span>=\u003Cspan class=\"emphasis\">\u003Cem>rule_prio\u003C/em>\u003C/span>:\u003Cspan class=\"emphasis\">\u003Cem>sched\u003C/em>\u003C/span>:\u003Cspan class=\"emphasis\">\u003Cem>prio\u003C/em>\u003C/span>:\u003Cspan class=\"emphasis\">\u003Cem>affinity\u003C/em>\u003C/span>:\u003Cspan class=\"emphasis\">\u003Cem>regex\u003C/em>\u003C/span>\u003C/pre>\u003Cp>\n\t\t\t\twhere \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>rule_prio\u003C/em>\u003C/span>\u003C/code> defines internal \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> priority of the rule. Rules are sorted based on priority. This is needed for inheritance to be able to reorder previously defined rules. Equal \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>rule_prio\u003C/em>\u003C/span>\u003C/code> rules should be processed in the order they were defined. However, this is Python interpreter dependent. To disable an inherited rule for \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>groupname\u003C/em>\u003C/span>\u003C/code>, use:\n\t\t\t\u003C/p>\u003Cpre class=\"screen\">group.\u003Cspan class=\"emphasis\">\u003Cem>groupname\u003C/em>\u003C/span>=\u003C/pre>\u003Cp>\n\t\t\t\t\u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>sched\u003C/em>\u003C/span>\u003C/code> must be one of the following:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">f\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tfor first in, first out (FIFO)\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">b\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tfor batch\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">r\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tfor round robin\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">o\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tfor other\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">*\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tfor do not change\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cp>\n\t\t\t\t\u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>affinity\u003C/em>\u003C/span>\u003C/code> is CPU affinity in hexadecimal. Use \u003Ccode class=\"literal\">*\u003C/code> for no change.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>prio\u003C/em>\u003C/span>\u003C/code> is scheduling priority (see \u003Ccode class=\"literal\">chrt -m\u003C/code>).\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>regex\u003C/em>\u003C/span>\u003C/code> is Python regular expression. It is matched against the output of the \u003Ccode class=\"literal\">ps -eo cmd\u003C/code> command.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tAny given process name can match more than one group. In such cases, the last matching \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>regex\u003C/em>\u003C/span>\u003C/code> determines the priority and scheduling policy.\n\t\t\t\u003C/p>\u003Cdiv class=\"example\" id=\"idm140280149235248\">\u003Cp class=\"title\">\u003Cstrong>Example 2.11. Setting scheduling policies and priorities\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\tThe following example sets the scheduling policy and priorities to kernel threads and watchdog:\n\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">[scheduler]\ngroup.kthreads=0:*:1:*:\\[.*\\]$\ngroup.watchdog=0:f:99:*:\\[watchdog.*\\]\u003C/pre>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tThe \u003Ccode class=\"literal\">scheduler\u003C/code> plugin uses a \u003Ccode class=\"literal\">perf\u003C/code> event loop to identify newly created processes. By default, it listens to \u003Ccode class=\"literal\">perf.RECORD_COMM\u003C/code> and \u003Ccode class=\"literal\">perf.RECORD_EXIT\u003C/code> events.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tSetting the \u003Ccode class=\"literal\">perf_process_fork\u003C/code> parameter to \u003Ccode class=\"literal\">true\u003C/code> tells the plug-in to also listen to \u003Ccode class=\"literal\">perf.RECORD_FORK\u003C/code> events, meaning that child processes created by the \u003Ccode class=\"literal\">fork()\u003C/code> system call are processed.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tProcessing \u003Ccode class=\"literal\">perf\u003C/code> events can pose a significant CPU overhead.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cp>\n\t\t\t\tThe CPU overhead of the scheduler plugin can be mitigated by using the scheduler \u003Ccode class=\"literal option\">runtime\u003C/code> option and setting it to \u003Ccode class=\"literal\">0\u003C/code>. This completely disables the dynamic scheduler functionality and the perf events are not monitored and acted upon. The disadvantage of this is that the process and thread tuning will be done only at profile application.\n\t\t\t\u003C/p>\u003Cdiv class=\"example\" id=\"idm140280139485440\">\u003Cp class=\"title\">\u003Cstrong>Example 2.12. Disabling the dynamic scheduler functionality\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\tThe following example disables the dynamic scheduler functionality while also isolating CPUs 1 and 3:\n\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">[scheduler]\nruntime=0\nisolated_cores=1,3\u003C/pre>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tThe \u003Ccode class=\"literal\">mmapped\u003C/code> buffer is used for \u003Ccode class=\"literal\">perf\u003C/code> events. Under heavy loads, this buffer might overflow and as a result the plugin might start missing events and not processing some newly created processes. In such cases, use the \u003Ccode class=\"literal\">perf_mmap_pages\u003C/code> parameter to increase the buffer size. The value of the \u003Ccode class=\"literal\">perf_mmap_pages\u003C/code> parameter must be a power of 2. If the \u003Ccode class=\"literal\">perf_mmap_pages\u003C/code> parameter is not manually set, a default value of 128 is used.\n\t\t\t\u003C/p>\u003Cdiv class=\"formalpara\">\u003Cp class=\"title\">\u003Cstrong>Confinement using \u003Ccode class=\"literal\">cgroups\u003C/code>\u003C/strong>\u003C/p>\u003Cp>\n\t\t\t\t\tThe \u003Ccode class=\"literal\">scheduler\u003C/code> plugin supports process and thread confinement using \u003Ccode class=\"literal\">cgroups\u003C/code> v1.\n\t\t\t\t\u003C/p>\u003C/div>\u003Cp>\n\t\t\t\tThe \u003Ccode class=\"literal option\">cgroup_mount_point\u003C/code> option specifies the path to mount the cgroup file system, or, where \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> expects it to be mounted. If it is unset, \u003Ccode class=\"literal\">/sys/fs/cgroup/cpuset\u003C/code> is expected.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tIf the \u003Ccode class=\"literal option\">cgroup_groups_init\u003C/code> option is set to \u003Ccode class=\"literal\">1\u003C/code>, \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> creates and removes all \u003Ccode class=\"literal\">cgroups\u003C/code> defined with the \u003Ccode class=\"literal\">cgroup*\u003C/code> options. This is the default behavior. If the \u003Ccode class=\"literal option\">cgroup_mount_point\u003C/code> option is set to \u003Ccode class=\"literal\">0\u003C/code>, the \u003Ccode class=\"literal\">cgroups\u003C/code> must be preset by other means.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tIf the \u003Ccode class=\"literal option\">cgroup_mount_point_init\u003C/code> option is set to \u003Ccode class=\"literal\">1\u003C/code>, \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> creates and removes the cgroup mount point. It implies \u003Ccode class=\"literal\">cgroup_groups_init = 1\u003C/code>. If the \u003Ccode class=\"literal option\">cgroup_mount_point_init\u003C/code> option is set to \u003Ccode class=\"literal\">0\u003C/code>, you must preset the \u003Ccode class=\"literal\">cgroups\u003C/code> mount point by other means. This is the default behavior.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe \u003Ccode class=\"literal option\">cgroup_for_isolated_cores\u003C/code> option is the \u003Ccode class=\"literal\">cgroup\u003C/code> name for the \u003Ccode class=\"literal option\">isolated_cores\u003C/code> option functionality. For example, if a system has 4 CPUs, \u003Ccode class=\"literal\">isolated_cores=1\u003C/code> means that \u003Cspan class=\"strong strong\">\u003Cstrong>Tuned\u003C/strong>\u003C/span> moves all processes and threads to CPUs 0, 2, and 3. The \u003Ccode class=\"literal\">scheduler\u003C/code> plug-in isolates the specified core by writing the calculated CPU affinity to the \u003Ccode class=\"literal\">cpuset.cpus\u003C/code> control file of the specified cgroup and moves all the matching processes and threads to this group. If this option is unset, classic cpuset affinity using \u003Ccode class=\"literal\">sched_setaffinity()\u003C/code> sets the CPU affinity.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe \u003Ccode class=\"literal option\">cgroup.\u003Cspan class=\"emphasis\">\u003Cem>cgroup_name\u003C/em>\u003C/span>\u003C/code> option defines affinities for arbitrary \u003Ccode class=\"literal\">cgroups\u003C/code>. You can even use hierarchic cgroups, but you must specify the hierarchy in the correct order. \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> does not do any sanity checks here, with the exception that it forces the \u003Ccode class=\"literal\">cgroup\u003C/code> to be in the location specified by the \u003Ccode class=\"literal option\">cgroup_mount_point\u003C/code> option.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe syntax of the scheduler option starting with \u003Ccode class=\"literal\">group.\u003C/code> has been augmented to use \u003Ccode class=\"literal\">cgroup.\u003Cspan class=\"emphasis\">\u003Cem>cgroup_name\u003C/em>\u003C/span>\u003C/code> instead of the hexadecimal \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>affinity\u003C/em>\u003C/span>\u003C/code>. The matching processes are moved to the \u003Ccode class=\"literal\">cgroup\u003C/code> \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>cgroup_name\u003C/em>\u003C/span>\u003C/code>. You can also use cgroups not defined by the \u003Ccode class=\"literal option\">cgroup.\u003C/code> option as described above. For example, \u003Ccode class=\"literal\">cgroups\u003C/code> not managed by \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span>.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tAll \u003Ccode class=\"literal\">cgroup\u003C/code> names are sanitized by replacing all periods (\u003Ccode class=\"literal\">.\u003C/code>) with slashes (\u003Ccode class=\"literal\">/\u003C/code>). This prevents the plugin from writing outside the location specified by the \u003Ccode class=\"literal option\">cgroup_mount_point\u003C/code> option.\n\t\t\t\u003C/p>\u003Cdiv class=\"example\" id=\"idm140280139587216\">\u003Cp class=\"title\">\u003Cstrong>Example 2.13. Using \u003Ccode class=\"literal\">cgroups\u003C/code> v1 with the \u003Ccode class=\"literal\">scheduler\u003C/code> plug-in\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\tThe following example creates 2 \u003Ccode class=\"literal\">cgroups\u003C/code>, \u003Ccode class=\"literal\">group1\u003C/code> and \u003Ccode class=\"literal\">group2\u003C/code>. It sets the cgroup \u003Ccode class=\"literal\">group1\u003C/code> affinity to CPU 2 and the \u003Ccode class=\"literal\">cgroup\u003C/code> \u003Ccode class=\"literal\">group2\u003C/code> to CPUs 0 and 2. Given a 4 CPU setup, the \u003Ccode class=\"literal option\">isolated_cores=1\u003C/code> option moves all processes and threads to CPU cores 0, 2, and 3. Processes and threads specified by the \u003Ccode class=\"literal option\">ps_blacklist\u003C/code> regular expression are not moved.\n\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">[scheduler]\ncgroup_mount_point=/sys/fs/cgroup/cpuset\ncgroup_mount_point_init=1\ncgroup_groups_init=1\ncgroup_for_isolated_cores=group\ncgroup.group1=2\ncgroup.group2=0,2\n\ngroup.ksoftirqd=0:f:2:cgroup.group1:ksoftirqd.*\nps_blacklist=ksoftirqd.*;rcuc.*;rcub.*;ktimersoftd.*\nisolated_cores=1\u003C/pre>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tThe \u003Ccode class=\"literal option\">cgroup_ps_blacklist\u003C/code> option excludes processes belonging to the specified \u003Ccode class=\"literal\">cgroups\u003C/code>. The regular expression specified by this option is matched against \u003Ccode class=\"literal\">cgroup\u003C/code> hierarchies from \u003Ccode class=\"literal\">/proc/\u003Cspan class=\"emphasis\">\u003Cem>PID\u003C/em>\u003C/span>/cgroups\u003C/code>. Commas (\u003Ccode class=\"literal\">,\u003C/code>) separate \u003Ccode class=\"literal\">cgroups\u003C/code> v1 hierarchies from \u003Ccode class=\"literal\">/proc/\u003Cspan class=\"emphasis\">\u003Cem>PID\u003C/em>\u003C/span>/cgroups\u003C/code> before regular expression matching. The following is an example of content the regular expression is matched against:\n\t\t\t\u003C/p>\u003Cpre class=\"screen\">10:hugetlb:/,9:perf_event:/,8:blkio:/\u003C/pre>\u003Cp>\n\t\t\t\tMultiple regular expressions can be separated by semicolons (\u003Ccode class=\"literal\">;\u003C/code>). The semicolon represents a logical 'or' operator.\n\t\t\t\u003C/p>\u003Cdiv class=\"example\" id=\"idm140280146511376\">\u003Cp class=\"title\">\u003Cstrong>Example 2.14. Excluding processes from the scheduler using cgroups\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\tIn the following example, the \u003Ccode class=\"literal\">scheduler\u003C/code> plug-in moves all processes away from core 1, except for processes which belong to cgroup \u003Ccode class=\"literal\">/daemons\u003C/code>. The \u003Ccode class=\"literal\">\\b\u003C/code> string is a regular expression metacharacter that matches a word boundary.\n\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">[scheduler]\nisolated_cores=1\ncgroup_ps_blacklist=:/daemons\\b\u003C/pre>\u003Cp>\n\t\t\t\t\tIn the following example, the \u003Ccode class=\"literal\">scheduler\u003C/code> plugin excludes all processes which belong to a cgroup with a hierarchy-ID of 8 and controller-list \u003Ccode class=\"literal\">blkio\u003C/code>.\n\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">[scheduler]\nisolated_cores=1\ncgroup_ps_blacklist=\\b8:blkio:\u003C/pre>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tRecent kernels moved some \u003Ccode class=\"literal\">sched_\u003C/code> and \u003Ccode class=\"literal\">numa_balancing_\u003C/code> kernel run-time parameters from the \u003Ccode class=\"literal\">/proc/sys/kernel\u003C/code> directory managed by the \u003Ccode class=\"literal\">sysctl\u003C/code> utility, to \u003Ccode class=\"literal\">debugfs\u003C/code>, typically mounted under the \u003Ccode class=\"literal\">/sys/kernel/debug\u003C/code> directory. \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> provides an abstraction mechanism for the following parameters via the \u003Ccode class=\"literal\">scheduler\u003C/code> plugin where, based on the kernel used, \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> writes the specified value to the correct location:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal option\">sched_min_granularity_ns\u003C/code>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal option\">sched_latency_ns\u003C/code>,\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal option\">sched_wakeup_granularity_ns\u003C/code>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal option\">sched_tunable_scaling\u003C/code>,\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal option\">sched_migration_cost_ns\u003C/code>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal option\">sched_nr_migrate\u003C/code>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal option\">numa_balancing_scan_delay_ms\u003C/code>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal option\">numa_balancing_scan_period_min_ms\u003C/code>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal option\">numa_balancing_scan_period_max_ms\u003C/code>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\u003Ccode class=\"literal option\">numa_balancing_scan_size_mb\u003C/code>\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"example\" id=\"idm140280149974544\">\u003Cp class=\"title\">\u003Cstrong>Example 2.15. Set tasks' \"cache hot\" value for migration decisions.\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\t\t\tOn the old kernels, setting the following parameter meant that \u003Ccode class=\"literal\">sysctl\u003C/code> wrote a value of \u003Ccode class=\"literal\">500000\u003C/code> to the \u003Ccode class=\"literal\">/proc/sys/kernel/sched_migration_cost_ns\u003C/code> file:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">[sysctl]\nkernel.sched_migration_cost_ns=500000\u003C/pre>\u003Cp>\n\t\t\t\t\t\t\tThis is, on more recent kernels, equivalent to setting the following parameter via the \u003Ccode class=\"literal\">scheduler\u003C/code> plugin:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">[scheduler]\nsched_migration_cost_ns=500000\u003C/pre>\u003Cp>\n\t\t\t\t\t\t\tMeaning \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> writes a value of \u003Ccode class=\"literal\">500000\u003C/code> to the \u003Ccode class=\"literal\">/sys/kernel/debug/sched/migration_cost_ns\u003C/code> file.\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"variables-in-tuned-profiles_customizing-tuned-profiles\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">2.10. Variables in TuneD profiles\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tVariables expand at run time when a \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profile is activated.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tUsing \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> variables reduces the amount of necessary typing in \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profiles.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThere are no predefined variables in \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profiles. You can define your own variables by creating the \u003Ccode class=\"literal\">[variables]\u003C/code> section in a profile and using the following syntax:\n\t\t\t\u003C/p>\u003Cpre class=\"screen\">[variables]\n\n\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">variable_name\u003C/span>\u003C/em>\u003C/span>=\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">value\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cp>\n\t\t\t\tTo expand the value of a variable in a profile, use the following syntax:\n\t\t\t\u003C/p>\u003Cpre class=\"screen\">${\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">variable_name\u003C/span>\u003C/em>\u003C/span>}\u003C/pre>\u003Cdiv class=\"example\" id=\"idm140280139713920\">\u003Cp class=\"title\">\u003Cstrong>Example 2.16. Isolating CPU cores using variables\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\tIn the following example, the \u003Ccode class=\"literal\">${isolated_cores}\u003C/code> variable expands to \u003Ccode class=\"literal\">1,2\u003C/code>; hence the kernel boots with the \u003Ccode class=\"literal option\">isolcpus=1,2\u003C/code> option:\n\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">[variables]\nisolated_cores=1,2\n\n[bootloader]\ncmdline=isolcpus=${isolated_cores}\u003C/pre>\u003Cp>\n\t\t\t\t\tThe variables can be specified in a separate file. For example, you can add the following lines to \u003Ccode class=\"literal filename\">tuned.conf\u003C/code>:\n\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">[variables]\ninclude=/etc/tuned/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-variables.conf\u003C/span>\u003C/em>\u003C/span>\n\n[bootloader]\ncmdline=isolcpus=${isolated_cores}\u003C/pre>\u003Cp>\n\t\t\t\t\tIf you add the \u003Ccode class=\"literal option\">isolated_cores=1,2\u003C/code> option to the \u003Ccode class=\"literal filename\">/etc/tuned/my-variables.conf\u003C/code> file, the kernel boots with the \u003Ccode class=\"literal option\">isolcpus=1,2\u003C/code> option.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">tuned.conf(5)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"built-in-functions-in-tuned-profiles_customizing-tuned-profiles\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">2.11. Built-in functions in TuneD profiles\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tBuilt-in functions expand at run time when a \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profile is activated.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tYou can:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tUse various built-in functions together with \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> variables\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tCreate custom functions in Python and add them to \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> in the form of plug-ins\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tTo call a function, use the following syntax:\n\t\t\t\u003C/p>\u003Cpre class=\"screen\">${f:\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">function_name\u003C/span>\u003C/em>\u003C/span>:\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">argument_1\u003C/span>\u003C/em>\u003C/span>:\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">argument_2\u003C/span>\u003C/em>\u003C/span>}\u003C/pre>\u003Cp>\n\t\t\t\tTo expand the directory path where the profile and the \u003Ccode class=\"literal\">tuned.conf\u003C/code> file are located, use the \u003Ccode class=\"literal\">PROFILE_DIR\u003C/code> function, which requires special syntax:\n\t\t\t\u003C/p>\u003Cpre class=\"screen\">${i:PROFILE_DIR}\u003C/pre>\u003Cdiv class=\"example\" id=\"idm140280158002080\">\u003Cp class=\"title\">\u003Cstrong>Example 2.17. Isolating CPU cores using variables and built-in functions\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\tIn the following example, the \u003Ccode class=\"literal\">${non_isolated_cores}\u003C/code> variable expands to \u003Ccode class=\"literal\">0,3-5\u003C/code>, and the \u003Ccode class=\"literal\">cpulist_invert\u003C/code> built-in function is called with the \u003Ccode class=\"literal\">0,3-5\u003C/code> argument:\n\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">[variables]\nnon_isolated_cores=0,3-5\n\n[bootloader]\ncmdline=isolcpus=${f:cpulist_invert:${non_isolated_cores}}\u003C/pre>\u003Cp>\n\t\t\t\t\tThe \u003Ccode class=\"literal\">cpulist_invert\u003C/code> function inverts the list of CPUs. For a 6-CPU machine, the inversion is \u003Ccode class=\"literal\">1,2\u003C/code>, and the kernel boots with the \u003Ccode class=\"literal option\">isolcpus=1,2\u003C/code> command-line option.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">tuned.conf(5)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"built-in-functions-available-in-tuned-profiles_customizing-tuned-profiles\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">2.12. Built-in functions available in TuneD profiles\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe following built-in functions are available in all \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profiles:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">PROFILE_DIR\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tReturns the directory path where the profile and the \u003Ccode class=\"literal\">tuned.conf\u003C/code> file are located.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">exec\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tExecutes a process and returns its output.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">assertion\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tCompares two arguments. If they \u003Cspan class=\"emphasis\">\u003Cem>do not match\u003C/em>\u003C/span>, the function logs text from the first argument and aborts profile loading.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">assertion_non_equal\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tCompares two arguments. If they \u003Cspan class=\"emphasis\">\u003Cem>match\u003C/em>\u003C/span>, the function logs text from the first argument and aborts profile loading.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">kb2s\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tConverts kilobytes to disk sectors.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">s2kb\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tConverts disk sectors to kilobytes.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">strip\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tCreates a string from all passed arguments and deletes both leading and trailing white space.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">virt_check\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tChecks whether \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> is running inside a virtual machine (VM) or on bare metal:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tInside a VM, the function returns the first argument.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tOn bare metal, the function returns the second argument, even in case of an error.\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">cpulist_invert\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tInverts a list of CPUs to make its complement. For example, on a system with 4 CPUs, numbered from 0 to 3, the inversion of the list \u003Ccode class=\"literal\">0,2,3\u003C/code> is \u003Ccode class=\"literal\">1\u003C/code>.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">cpulist2hex\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tConverts a CPU list to a hexadecimal CPU mask.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">cpulist2hex_invert\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tConverts a CPU list to a hexadecimal CPU mask and inverts it.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">hex2cpulist\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tConverts a hexadecimal CPU mask to a CPU list.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">cpulist_online\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tChecks whether the CPUs from the list are online. Returns the list containing only online CPUs.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">cpulist_present\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tChecks whether the CPUs from the list are present. Returns the list containing only present CPUs.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">cpulist_unpack\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tUnpacks a CPU list in the form of \u003Ccode class=\"literal\">1-3,4\u003C/code> to \u003Ccode class=\"literal\">1,2,3,4\u003C/code>.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">cpulist_pack\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tPacks a CPU list in the form of \u003Ccode class=\"literal\">1,2,3,5\u003C/code> to \u003Ccode class=\"literal\">1-3,5\u003C/code>.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"creating-new-tuned-profiles_customizing-tuned-profiles\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">2.13. Creating new TuneD profiles\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure creates a new \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profile with custom performance rules.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">TuneD\u003C/code> service is running. See \u003Ca class=\"link\" href=\"#installing-and-enabling-tuned_getting-started-with-tuned\" title=\"1.13. Installing and enabling TuneD\">Installing and Enabling TuneD\u003C/a> for details.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn the \u003Ccode class=\"literal filename\">/etc/tuned/\u003C/code> directory, create a new directory named the same as the profile that you want to create:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mkdir /etc/tuned/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-profile\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn the new directory, create a file named \u003Ccode class=\"literal filename\">tuned.conf\u003C/code>. Add a \u003Ccode class=\"literal\">[main]\u003C/code> section and plug-in definitions in it, according to your requirements.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor example, see the configuration of the \u003Ccode class=\"literal\">balanced\u003C/code> profile:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">[main]\nsummary=General non-specialized TuneD profile\n\n[cpu]\ngovernor=conservative\nenergy_perf_bias=normal\n\n[audio]\ntimeout=10\n\n[video]\nradeon_powersave=dpm-balanced, auto\n\n[scsi_host]\nalpm=medium_power\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo activate the profile, use:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># tuned-adm profile \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-profile\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify that the \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profile is active and the system settings are applied:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ tuned-adm active\n\nCurrent active profile: \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-profile\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cpre class=\"screen\">$ tuned-adm verify\n\nVerification succeeded, current system settings match the preset profile.\nSee tuned log file ('/var/log/tuned/tuned.log') for details.\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">tuned.conf(5)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"modifying-existing-tuned-profiles_customizing-tuned-profiles\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">2.14. Modifying existing TuneD profiles\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure creates a modified child profile based on an existing \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profile.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">TuneD\u003C/code> service is running. See \u003Ca class=\"link\" href=\"#installing-and-enabling-tuned_getting-started-with-tuned\" title=\"1.13. Installing and enabling TuneD\">Installing and Enabling TuneD\u003C/a> for details.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn the \u003Ccode class=\"literal filename\">/etc/tuned/\u003C/code> directory, create a new directory named the same as the profile that you want to create:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mkdir /etc/tuned/\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">modified-profile\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn the new directory, create a file named \u003Ccode class=\"literal filename\">tuned.conf\u003C/code>, and set the \u003Ccode class=\"literal\">[main]\u003C/code> section as follows:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">[main]\ninclude=\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">parent-profile\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">parent-profile\u003C/span>\u003C/em>\u003C/span> with the name of the profile you are modifying.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInclude your profile modifications.\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"example\" id=\"idm140280161404224\">\u003Cp class=\"title\">\u003Cstrong>Example 2.18. Lowering swappiness in the throughput-performance profile\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\t\t\tTo use the settings from the \u003Ccode class=\"literal\">throughput-performance\u003C/code> profile and change the value of \u003Ccode class=\"literal\">vm.swappiness\u003C/code> to 5, instead of the default 10, use:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">[main]\ninclude=throughput-performance\n\n[sysctl]\nvm.swappiness=5\u003C/pre>\u003C/div>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo activate the profile, use:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># tuned-adm profile \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">modified-profile\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify that the \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profile is active and the system settings are applied:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ tuned-adm active\n\nCurrent active profile: \u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">my-profile\u003C/span>\u003C/em>\u003C/span>\u003C/pre>\u003Cpre class=\"screen\">$ tuned-adm verify\n\nVerification succeeded, current system settings match the preset profile.\nSee tuned log file ('/var/log/tuned/tuned.log') for details.\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">tuned.conf(5)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"setting-the-disk-scheduler-using-tuned_customizing-tuned-profiles\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">2.15. Setting the disk scheduler using TuneD\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure creates and enables a \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profile that sets a given disk scheduler for selected block devices. The setting persists across system reboots.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tIn the following commands and configuration, replace:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span> with the name of the block device, for example \u003Ccode class=\"literal\">sdf\u003C/code>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Cspan class=\"emphasis\">\u003Cem>selected-scheduler\u003C/em>\u003C/span> with the disk scheduler that you want to set for the device, for example \u003Ccode class=\"literal\">bfq\u003C/code>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">TuneD\u003C/code> service is installed and enabled. For details, see \u003Ca class=\"link\" href=\"#installing-and-enabling-tuned_getting-started-with-tuned\" title=\"1.13. Installing and enabling TuneD\">Installing and enabling TuneD\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOptional: Select an existing \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profile on which your profile will be based. For a list of available profiles, see \u003Ca class=\"link\" href=\"#tuned-profiles-distributed-with-rhel_getting-started-with-tuned\" title=\"1.6. TuneD profiles distributed with RHEL\">TuneD profiles distributed with RHEL\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo see which profile is currently active, use:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ tuned-adm active\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a new directory to hold your \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profile:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mkdir /etc/tuned/\u003Cspan class=\"emphasis\">\u003Cem>my-profile\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFind the system unique identifier of the selected block device:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ udevadm info --query=property --name=/dev/\u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span> | grep -E '(WWN|SERIAL)'\n\nID_WWN=\u003Cspan class=\"emphasis\">\u003Cem>0x5002538d00000000_\u003C/em>\u003C/span>\nID_SERIAL=\u003Cspan class=\"emphasis\">\u003Cem>Generic-_SD_MMC_20120501030900000-0:0\u003C/em>\u003C/span>\nID_SERIAL_SHORT=\u003Cspan class=\"emphasis\">\u003Cem>20120501030900000\u003C/em>\u003C/span>\u003C/pre>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\tThe command in the this example will return all values identified as a World Wide Name (WWN) or serial number associated with the specified block device. Although it is preferred to use a WWN, the WWN is not always available for a given device and any values returned by the example command are acceptable to use as the \u003Cspan class=\"emphasis\">\u003Cem>device system unique ID\u003C/em>\u003C/span>.\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate the \u003Ccode class=\"literal\">/etc/tuned/\u003Cspan class=\"emphasis\">\u003Cem>my-profile\u003C/em>\u003C/span>/tuned.conf\u003C/code> configuration file. In the file, set the following options:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tOptional: Include an existing profile:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">[main]\ninclude=\u003Cspan class=\"emphasis\">\u003Cem>existing-profile\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tSet the selected disk scheduler for the device that matches the WWN identifier:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">[disk]\ndevices_udev_regex=\u003Cspan class=\"emphasis\">\u003Cem>IDNAME\u003C/em>\u003C/span>=\u003Cspan class=\"emphasis\">\u003Cem>device system unique id\u003C/em>\u003C/span>\nelevator=\u003Cspan class=\"emphasis\">\u003Cem>selected-scheduler\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tHere:\n\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>IDNAME\u003C/em>\u003C/span> with the name of the identifier being used (for example, \u003Ccode class=\"literal\">ID_WWN\u003C/code>).\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>device system unique id\u003C/em>\u003C/span> with the value of the chosen identifier (for example, \u003Ccode class=\"literal\">0x5002538d00000000\u003C/code>).\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\tTo match multiple devices in the \u003Ccode class=\"literal\">devices_udev_regex\u003C/code> option, enclose the identifiers in parentheses and separate them with vertical bars:\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">devices_udev_regex=(ID_WWN=\u003Cspan class=\"emphasis\">\u003Cem>0x5002538d00000000\u003C/em>\u003C/span>)|(ID_WWN=\u003Cspan class=\"emphasis\">\u003Cem>0x1234567800000000\u003C/em>\u003C/span>)\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnable your profile:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># tuned-adm profile \u003Cspan class=\"emphasis\">\u003Cem>my-profile\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify that the TuneD profile is active and applied:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ tuned-adm active\n\nCurrent active profile: \u003Cspan class=\"emphasis\">\u003Cem>my-profile\u003C/em>\u003C/span>\u003C/pre>\u003Cpre class=\"screen\">$ tuned-adm verify\n\nVerification succeeded, current system settings match the preset profile.\nSee TuneD log file ('/var/log/tuned/tuned.log') for details.\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRead the contents of the \u003Ccode class=\"literal\">/sys/block/\u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span>/queue/scheduler\u003C/code> file:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># cat /sys/block/\u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span>/queue/scheduler\n\n[mq-deadline] kyber bfq none\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn the file name, replace \u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span> with the block device name, for example \u003Ccode class=\"literal\">sdc\u003C/code>.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe active scheduler is listed in square brackets (\u003Ccode class=\"literal\">[]\u003C/code>).\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"#customizing-tuned-profiles_monitoring-and-managing-system-status-and-performance\" title=\"Chapter 2. Customizing TuneD profiles\">Customizing TuneD profiles\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"reviewing-a-system-using-tuna-interface_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 3. Reviewing a system by using the tuna interface\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tThe \u003Ccode class=\"literal\">tuna\u003C/code> tool reduces the complexity of performing tuning tasks. Use \u003Ccode class=\"literal\">tuna\u003C/code> to adjust scheduler tunables, tune thread priority, IRQ handlers, and to isolate CPU cores and sockets. By using the \u003Ccode class=\"literal\">tuna\u003C/code> tool, you can perform the following operations:\n\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\tList the CPUs on a system.\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tList the interrupt requests (IRQs) currently running on a system.\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tChange policy and priority information about threads.\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tDisplay the current policies and priorities of a system.\n\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Csection class=\"section\" id=\"installing-tuna-tool_reviewing-a-system-using-tuna-interface\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">3.1. Installing the tuna tool\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe \u003Ccode class=\"literal\">tuna\u003C/code> tool is designed to be used on a running system. This allows application-specific measurement tools to see and analyze system performance immediately after changes have been made.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInstall the \u003Ccode class=\"literal\">tuna\u003C/code> tool:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>dnf install tuna\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tDisplay the available \u003Ccode class=\"literal\">tuna\u003C/code> CLI options:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>tuna -h\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">tuna(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"viewing-the-system-status-using-tuna-tool_reviewing-a-system-using-tuna-interface\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">3.2. Viewing the system status by using the tuna tool\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can use the \u003Ccode class=\"literal\">tuna\u003C/code> command-line interface (CLI) tool to view the system status.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">tuna\u003C/code> tool is installed. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/reviewing-a-system-using-tuna-interface_monitoring-and-managing-system-status-and-performance#installing-tuna-tool_reviewing-a-system-using-tuna-interface\">Installing the tuna tool\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tView the current policies and priorities:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>tuna show_threads\u003C/strong>\u003C/span>\npid   SCHED_ rtpri affinity             cmd\n1      OTHER     0      0,1            init\n2       FIFO    99        0     migration/0\n3      OTHER     0        0     ksoftirqd/0\n4       FIFO    99        0      watchdog/0\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAlternatively, to view a specific thread corresponding to a PID or matching a command name, enter:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>tuna show_threads -t pid_or_cmd_list\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe \u003Cspan class=\"emphasis\">\u003Cem>pid_or_cmd_list\u003C/em>\u003C/span> argument is a list of comma-separated PIDs or command-name patterns.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tDepending on you scenario, perform one of the following actions:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tTo tune CPUs by using the \u003Ccode class=\"literal\">tuna\u003C/code> CLI, complete the steps in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/reviewing-a-system-using-tuna-interface_monitoring-and-managing-system-status-and-performance#tuning-cpus-using-tuna-tool_reviewing-a-system-using-tuna-interface\">Tuning CPUs by using the tuna tool\u003C/a>.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tTo tune the IRQs by using the \u003Ccode class=\"literal\">tuna\u003C/code> tool, complete the steps in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/reviewing-a-system-using-tuna-interface_monitoring-and-managing-system-status-and-performance#tuning-irqs-using-tuna-tool_reviewing-a-system-using-tuna-interface\">Tuning IRQs by using the tuna tool\u003C/a>.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tSave the changed configuration:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>tuna save filename\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThis command saves only currently running kernel threads. Processes that are not running are not saved.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">tuna(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"tuning-cpus-using-tuna-tool_reviewing-a-system-using-tuna-interface\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">3.3. Tuning CPUs by using the tuna tool\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe \u003Ccode class=\"literal\">tuna\u003C/code> tool commands can target individual CPUs. By using the \u003Ccode class=\"literal\">tuna\u003C/code> tool, you can perform the following actions:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Isolate CPUs\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tAll tasks running on the specified CPU move to the next available CPU. Isolating a CPU makes this CPU unavailable by removing it from the affinity mask of all threads.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Include CPUs\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tAllows tasks to run on the specified CPU.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Restore CPUs\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tRestores the specified CPU to its previous configuration.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">tuna\u003C/code> tool is installed. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/reviewing-a-system-using-tuna-interface_monitoring-and-managing-system-status-and-performance#installing-tuna-tool_reviewing-a-system-using-tuna-interface\">Installing the tuna tool\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tList all CPUs and specify the list of CPUs to be affected by the command:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ps ax | awk 'BEGIN { ORS=\",\" }{ print $1 }'\u003C/strong>\u003C/span>\nPID,1,2,3,4,5,6,8,10,11,12,13,14,15,16,17,19\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tDisplay the thread list in the \u003Ccode class=\"literal\">tuna\u003C/code> interface:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>tuna show_threads -t 'thread_list from above cmd'\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tSpecify the list of CPUs to be affected by a command:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># *tuna [\u003Cspan class=\"emphasis\">\u003Cem>command\u003C/em>\u003C/span>] --cpus \u003Cspan class=\"emphasis\">\u003Cem>cpu_list\u003C/em>\u003C/span> *\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe \u003Cspan class=\"emphasis\">\u003Cem>cpu_list\u003C/em>\u003C/span> argument is a list of comma-separated CPU numbers, for example, \u003Ccode class=\"literal\">--cpus \u003Cspan class=\"emphasis\">\u003Cem>0,2\u003C/em>\u003C/span>\u003C/code>.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo add a specific CPU to the current \u003Cspan class=\"emphasis\">\u003Cem>cpu_list\u003C/em>\u003C/span>, use, for example, \u003Ccode class=\"literal\">--cpus +0\u003C/code>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tDepending on your scenario, perform one of the following actions:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tTo isolate a CPU, enter:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>tuna isolate --cpus cpu_list\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tTo include a CPU, enter:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>tuna include --cpus cpu_list\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo use a system with four or more processors, make all \u003Ccode class=\"literal\">ssh\u003C/code> threads run on CPU \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span> and \u003Cspan class=\"emphasis\">\u003Cem>1\u003C/em>\u003C/span> and all \u003Ccode class=\"literal\">http\u003C/code> threads on CPU \u003Cspan class=\"emphasis\">\u003Cem>2\u003C/em>\u003C/span> and \u003Cspan class=\"emphasis\">\u003Cem>3\u003C/em>\u003C/span>:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>tuna move --cpus 0,1 -t ssh\u003C/strong>\u003C/span>*\n# \u003Cspan class=\"strong strong\">\u003Cstrong>tuna move --cpus 2,3 -t http\\\u003C/strong>\u003C/span>*\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tDisplay the current configuration and verify that the changes were applied:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout white-space-pre\"># \u003Cspan class=\"strong strong\">\u003Cstrong>tuna show_threads -t ssh\u003C/strong>\u003C/span>*\n\npid   SCHED_  rtpri  affinity   voluntary   nonvoluntary   cmd\n855   OTHER   0      0,1        23           15            sshd\n\n# \u003Cspan class=\"strong strong\">\u003Cstrong>tuna show_threads -t http\\\u003C/strong>\u003C/span>*\npid   SCHED_  rtpri  affinity   voluntary   nonvoluntary   cmd\n855   OTHER   0       2,3        23           15           http\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/proc/cpuinfo\u003C/code> file\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">tuna(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"tuning-irqs-using-tuna-tool_reviewing-a-system-using-tuna-interface\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">3.4. Tuning IRQs by using the tuna tool\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe \u003Ccode class=\"literal\">/proc/interrupts\u003C/code> file records the number of interrupts per IRQ, the type of interrupt, and the name of the device that is located at that IRQ.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">tuna\u003C/code> tool is installed. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/reviewing-a-system-using-tuna-interface_monitoring-and-managing-system-status-and-performance#installing-tuna-tool_reviewing-a-system-using-tuna-interface\">Installing tuna tool\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tView the current IRQs and their affinity:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>tuna show_irqs\u003C/strong>\u003C/span>\n# users            affinity\n0 timer                   0\n1 i8042                   0\n7 parport0                0\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tSpecify the list of IRQs to be affected by a command:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>tuna [\u003Cspan class=\"emphasis\">\u003Cem>command\u003C/em>\u003C/span>] --irqs \u003Cspan class=\"emphasis\">\u003Cem>irq_list\u003C/em>\u003C/span> --cpus \u003Cspan class=\"emphasis\">\u003Cem>cpu_list\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe \u003Cspan class=\"emphasis\">\u003Cem>irq_list\u003C/em>\u003C/span> argument is a list of comma-separated IRQ numbers or user-name patterns.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tReplace [\u003Cspan class=\"emphasis\">\u003Cem>command\u003C/em>\u003C/span>] with, for example, \u003Ccode class=\"literal\">--spread\u003C/code>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tMove an interrupt to a specified CPU:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>tuna show_irqs --irqs \u003Cspan class=\"emphasis\">\u003Cem>128\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\nusers            affinity\n128 iwlwifi           0,1,2,3\n\n# \u003Cspan class=\"strong strong\">\u003Cstrong>tuna move --irqs \u003Cspan class=\"emphasis\">\u003Cem>128\u003C/em>\u003C/span> --cpus 3\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>128\u003C/em>\u003C/span> with the irq_list argument and \u003Cspan class=\"emphasis\">\u003Cem>3\u003C/em>\u003C/span> with the cpu_list argument.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe \u003Cspan class=\"emphasis\">\u003Cem>cpu_list\u003C/em>\u003C/span> argument is a list of comma-separated CPU numbers, for example, \u003Ccode class=\"literal\">--cpus \u003Cspan class=\"emphasis\">\u003Cem>0,2\u003C/em>\u003C/span>\u003C/code>. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/reviewing-a-system-using-tuna-interface_monitoring-and-managing-system-status-and-performance#tuning-cpus-using-tuna-tool_reviewing-a-system-using-tuna-interface\">Tuning CPUs by using the tuna tool\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCompare the state of the selected IRQs before and after moving any interrupt to a specified CPU:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>tuna show_irqs --irqs \u003Cspan class=\"emphasis\">\u003Cem>128\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\n     users            affinity\n 128 iwlwifi                 3\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/procs/interrupts\u003C/code> file\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">tuna(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"monitoring-performance-by-using-the-metrics-rhel-system-role_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 4. Configuring performance monitoring with PCP by using RHEL system roles\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tPerformance Co-Pilot (PCP) is a system performance analysis toolkit. You can use it to record and analyze performance data from many components on a Red Hat Enterprise Linux system.\n\t\t\u003C/p>\u003Cp>\n\t\t\tYou can use the \u003Ccode class=\"literal\">metrics\u003C/code> RHEL system role to automate the installation and configuration of PCP, and the role can configure Grafana to visualize PCP metrics.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"configuring-performance-co-pilot-by-using-the-metrics-rhel-system-role_monitoring-performance-by-using-the-metrics-rhel-system-role\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">4.1. Configuring Performance Co-Pilot by using the \u003Ccode class=\"literal\">metrics\u003C/code> RHEL system role\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tYou can use Performance Co-Pilot (PCP) to monitor many metrics, such as CPU utilization and memory usage. For example, this can help to identify resource and performance bottlenecks. By using the \u003Ccode class=\"literal\">metrics\u003C/code> RHEL system role, you can remotely configure PCP on multiple hosts to record metrics.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles\">You have prepared the control node and the managed nodes\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou are logged in to the control node as a user who can run playbooks on the managed nodes.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe account you use to connect to the managed nodes has \u003Ccode class=\"literal\">sudo\u003C/code> permissions on them.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a playbook file, for example \u003Ccode class=\"literal\">~/playbook.yml\u003C/code>, with the following content:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"programlisting language-yaml\">---\n- name: Monitoring performance metrics\n  hosts: managed-node-01.example.com\n  tasks:\n    - name: Configure Performance Co-Pilot\n      ansible.builtin.include_role:\n        name: rhel-system-roles.metrics\n      vars:\n        metrics_retention_days: 14\n        metrics_manage_firewall: true\n        metrics_manage_selinux: true\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe settings specified in the example playbook include the following:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">metrics_retention_days: \u003Cspan class=\"emphasis\">\u003Cem>&lt;number&gt;\u003C/em>\u003C/span>\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\tSets the number of days after which the \u003Ccode class=\"literal\">pmlogger_daily\u003C/code> systemd timer removes old PCP archives.\n\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">metrics_manage_firewall: \u003Cspan class=\"emphasis\">\u003Cem>&lt;true|false&gt;\u003C/em>\u003C/span>\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\tDefines whether the role should open the required ports in the \u003Ccode class=\"literal\">firewalld\u003C/code> service. If you want to remotely access PCP on the managed nodes, set this variable to \u003Ccode class=\"literal\">true\u003C/code>.\n\t\t\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor details about all variables used in the playbook, see the \u003Ccode class=\"literal\">/usr/share/ansible/roles/rhel-system-roles.metrics/README.md\u003C/code> file on the control node.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tValidate the playbook syntax:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-playbook --syntax-check ~/playbook.yml\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tNote that this command only validates the syntax and does not protect against a wrong but valid configuration.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRun the playbook:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-playbook ~/playbook.yml\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tQuery a metric, for example:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ansible managed-node-01.example.com -m command -a 'pminfo -f kernel.all.load'\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Next step\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tOptional: \u003Ca class=\"link\" href=\"#setting-up-grafana-by-using-the-metrics-rhel-system-role-to-monitor-multiple-hosts-with-performance-co-pilot_monitoring-performance-by-using-the-metrics-rhel-system-role\" title=\"4.3. Setting up Grafana by using the metrics RHEL system role to monitor multiple hosts with Performance Co-Pilot\">Configure Grafana to monitor PCP hosts and visualize metrics\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/ansible/roles/rhel-system-roles.metrics/README.md\u003C/code> file\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/doc/rhel-system-roles/metrics/\u003C/code> directory\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"configuring-performance-co-pilot-with-authentication-by-using-the-metrics-rhel-system-role_monitoring-performance-by-using-the-metrics-rhel-system-role\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">4.2. Configuring Performance Co-Pilot with authentication by using the \u003Ccode class=\"literal\">metrics\u003C/code> RHEL system role\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tYou can enable authentication in Performance Co-Pilot (PCP) so that the \u003Ccode class=\"literal\">pmcd\u003C/code> service and Performance Metrics Domain Agents (PDMAs) can determine whether the user running the monitoring tools is allowed to perform an action. Authenticated users have access to metrics with sensitive information. Additionally, certain agents require authentication. For example, the \u003Ccode class=\"literal\">bpftrace\u003C/code> agent uses authentication to identify whether a user is allowed to load \u003Ccode class=\"literal\">bpftrace\u003C/code> scripts into the kernel to generate metrics.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tBy using the \u003Ccode class=\"literal\">metrics\u003C/code> RHEL system role, you can remotely configure PCP with authentication on multiple hosts.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles\">You have prepared the control node and the managed nodes\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou are logged in to the control node as a user who can run playbooks on the managed nodes.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe account you use to connect to the managed nodes has \u003Ccode class=\"literal\">sudo\u003C/code> permissions on them.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tStore your sensitive variables in an encrypted file:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tCreate the vault:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-vault create vault.yml\u003C/strong>\u003C/span>\nNew Vault password: \u003Cspan class=\"emphasis\">\u003Cem>&lt;vault_password&gt;\u003C/em>\u003C/span>\nConfirm New Vault password: \u003Cspan class=\"emphasis\">\u003Cem>&lt;vault_password&gt;\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tAfter the \u003Ccode class=\"literal\">ansible-vault create\u003C/code> command opens an editor, enter the sensitive data in the \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>&lt;key&gt;\u003C/em>\u003C/span>: \u003Cspan class=\"emphasis\">\u003Cem>&lt;value&gt;\u003C/em>\u003C/span>\u003C/code> format:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"programlisting language-ini\">metrics_usr: \u003Cspan class=\"emphasis\">\u003Cem>&lt;username&gt;\u003C/em>\u003C/span>\nmetrics_pwd: \u003Cspan class=\"emphasis\">\u003Cem>&lt;password&gt;\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tSave the changes, and close the editor. Ansible encrypts the data in the vault.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a playbook file, for example \u003Ccode class=\"literal\">~/playbook.yml\u003C/code>, with the following content:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"programlisting language-yaml\">---\n- name: Monitoring performance metrics\n  hosts: managed-node-01.example.com\n  tasks:\n    - name: Configure Performance Co-Pilot\n      ansible.builtin.include_role:\n        name: rhel-system-roles.metrics\n      vars:\n        metrics_retention_days: 14\n        metrics_manage_firewall: true\n        metrics_manage_selinux: true\n\tmetrics_username: \"{{ metrics_usr }}\"\n        metrics_password: \"{{ metrics_pwd }}\"\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe settings specified in the example playbook include the following:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">metrics_retention_days: \u003Cspan class=\"emphasis\">\u003Cem>&lt;number&gt;\u003C/em>\u003C/span>\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\tSets the number of days after which the \u003Ccode class=\"literal\">pmlogger_daily\u003C/code> systemd timer removes old PCP archives.\n\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">metrics_manage_firewall: \u003Cspan class=\"emphasis\">\u003Cem>&lt;true|false&gt;\u003C/em>\u003C/span>\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\tDefines whether the role should open the required ports in the \u003Ccode class=\"literal\">firewalld\u003C/code> service. If you want to remotely access PCP on the managed nodes, set this variable to \u003Ccode class=\"literal\">true\u003C/code>.\n\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">metrics_username: \u003Cspan class=\"emphasis\">\u003Cem>&lt;username&gt;\u003C/em>\u003C/span>\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\tThe role creates this user locally on the managed node, adds the credentials to the \u003Ccode class=\"literal\">/etc/pcp/passwd.db\u003C/code> Simple Authentication and Security Layer (SASL) database, and configures authentication in PCP. Additionally, if you set \u003Ccode class=\"literal\">metrics_from_bpftrace: true\u003C/code> in the playbook, PCP uses this account to register \u003Ccode class=\"literal\">bpftrace\u003C/code> scripts.\n\t\t\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor details about all variables used in the playbook, see the \u003Ccode class=\"literal\">/usr/share/ansible/roles/rhel-system-roles.metrics/README.md\u003C/code> file on the control node.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tValidate the playbook syntax:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-playbook --ask-vault-pass --syntax-check ~/playbook.yml\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tNote that this command only validates the syntax and does not protect against a wrong but valid configuration.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRun the playbook:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-playbook --ask-vault-pass ~/playbook.yml\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOn a host with the \u003Ccode class=\"literal\">pcp\u003C/code> package installed, query a metric that requires authentication:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tQuery the metrics by using the credentials that you used in the playbook:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>pminfo -fmdt -h pcp://managed-node-01.example.com?username=\u003Cspan class=\"emphasis\">\u003Cem>&lt;user&gt;\u003C/em>\u003C/span> proc.fd.count\u003C/strong>\u003C/span>\nPassword: \u003Cspan class=\"emphasis\">\u003Cem>&lt;password&gt;\u003C/em>\u003C/span>\n\nproc.fd.count\n    inst [844 or \"000844 /var/lib/pcp/pmdas/proc/pmdaproc\"] value 5\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tIf the command succeeds, it returns the value of the \u003Ccode class=\"literal\">proc.fd.count\u003C/code> metric.\n\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tRun the command again, but omit the username to verify that the command fails for unauthenticated users:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>pminfo -fmdt -h pcp://managed-node-01.example.com proc.fd.count\u003C/strong>\u003C/span>\n\nproc.fd.count\nError: No permission to perform requested operation\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Next step\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tOptional: \u003Ca class=\"link\" href=\"#setting-up-grafana-by-using-the-metrics-rhel-system-role-to-monitor-multiple-hosts-with-performance-co-pilot_monitoring-performance-by-using-the-metrics-rhel-system-role\" title=\"4.3. Setting up Grafana by using the metrics RHEL system role to monitor multiple hosts with Performance Co-Pilot\">Configure Grafana to monitor PCP hosts and visualize metrics\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/ansible/roles/rhel-system-roles.metrics/README.md\u003C/code> file\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/doc/rhel-system-roles/metrics/\u003C/code> directory\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/ansible-vault_automating-system-administration-by-using-rhel-system-roles\">Ansible vault\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"setting-up-grafana-by-using-the-metrics-rhel-system-role-to-monitor-multiple-hosts-with-performance-co-pilot_monitoring-performance-by-using-the-metrics-rhel-system-role\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">4.3. Setting up Grafana by using the \u003Ccode class=\"literal\">metrics\u003C/code> RHEL system role to monitor multiple hosts with Performance Co-Pilot\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tIf you have already configured Performance Co-Pilot (PCP) on multiple hosts, you can use an instance of Grafana to visualize the metrics for these hosts. You can display the live data and, if the PCP data is stored in a Redis database, also past data.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tBy using the \u003Ccode class=\"literal\">metrics\u003C/code> RHEL system role, you can automate the process of setting up Grafana, the PCP plug-in, the optional Redis database, and the configuration of the data sources.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tIf you use the \u003Ccode class=\"literal\">metrics\u003C/code> role to install Grafana on a host, the role also installs automatically PCP on this host.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles\">You have prepared the control node and the managed nodes\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou are logged in to the control node as a user who can run playbooks on the managed nodes.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe account you use to connect to the managed nodes has \u003Ccode class=\"literal\">sudo\u003C/code> permissions on them.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"#configuring-performance-co-pilot-by-using-the-metrics-rhel-system-role_monitoring-performance-by-using-the-metrics-rhel-system-role\" title=\"4.1. Configuring Performance Co-Pilot by using the metrics RHEL system role\">PCP is configured for remote access on the hosts you want to monitor\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe host on which you want to install Grafana can access port 44321 on the PCP nodes you plan to monitor.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tStore your sensitive variables in an encrypted file:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tCreate the vault:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-vault create vault.yml\u003C/strong>\u003C/span>\nNew Vault password: \u003Cspan class=\"emphasis\">\u003Cem>&lt;vault_password&gt;\u003C/em>\u003C/span>\nConfirm New Vault password: \u003Cspan class=\"emphasis\">\u003Cem>&lt;vault_password&gt;\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tAfter the \u003Ccode class=\"literal\">ansible-vault create\u003C/code> command opens an editor, enter the sensitive data in the \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>&lt;key&gt;\u003C/em>\u003C/span>: \u003Cspan class=\"emphasis\">\u003Cem>&lt;value&gt;\u003C/em>\u003C/span>\u003C/code> format:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"programlisting language-ini\">grafana_admin_pwd: \u003Cspan class=\"emphasis\">\u003Cem>&lt;password&gt;\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tSave the changes, and close the editor. Ansible encrypts the data in the vault.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a playbook file, for example \u003Ccode class=\"literal\">~/playbook.yml\u003C/code>, with the following content:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"programlisting language-yaml\">---\n- name: Monitoring performance metrics\n  hosts: managed-node-01.example.com\n  vars_files:\n    - vault.yml\n  tasks:\n    - name: Set up Grafana to monitor multiple hosts\n      ansible.builtin.include_role:\n        name: rhel-system-roles.metrics\n      vars:\n        metrics_graph_service: true\n        metrics_query_service: true\n        metrics_monitored_hosts:\n          - \u003Cspan class=\"emphasis\">\u003Cem>&lt;pcp_host_1.example.com&gt;\u003C/em>\u003C/span>\n          - \u003Cspan class=\"emphasis\">\u003Cem>&lt;pcp_host_2.example.com&gt;\u003C/em>\u003C/span>\n        metrics_manage_firewall: true\n        metrics_manage_selinux: true\n\n    - name: Set Grafana admin password\n      ansible.builtin.shell:\n        cmd: grafana-cli admin reset-admin-password \"{{ grafana_admin_pwd }}\"\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe settings specified in the example playbook include the following:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">metrics_graph_service: true\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\tInstalls Grafana and the PCP plug-in. Additionally, the role adds the \u003Ccode class=\"literal\">PCP Vector\u003C/code>, \u003Ccode class=\"literal\">PCP Redis\u003C/code>, and \u003Ccode class=\"literal\">PCP bpftrace\u003C/code> data sources to Grafana.\n\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">metrics_query_service: \u003Cspan class=\"emphasis\">\u003Cem>&lt;true|false&gt;\u003C/em>\u003C/span>\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\tDefines whether the role should install and configure Redis for centralized metric recording. If enabled, data collected from PCP clients is stored in Redis and, as a result, you can also display historical data instead of only live data.\n\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">metrics_monitored_hosts: \u003Cspan class=\"emphasis\">\u003Cem>&lt;list_of_hosts&gt;\u003C/em>\u003C/span>\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\tDefines the list of hosts to monitor. In Grafana, you can then display the data of these hosts and, additionally, the host that runs Grafana.\n\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">metrics_manage_firewall: \u003Cspan class=\"emphasis\">\u003Cem>&lt;true|false&gt;\u003C/em>\u003C/span>\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\tDefines whether the role should open the required ports in the \u003Ccode class=\"literal\">firewalld\u003C/code> service. If you set this variable to \u003Ccode class=\"literal\">true\u003C/code>, you can, for example, access Grafana remotely.\n\t\t\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor details about all variables used in the playbook, see the \u003Ccode class=\"literal\">/usr/share/ansible/roles/rhel-system-roles.metrics/README.md\u003C/code> file on the control node.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tValidate the playbook syntax:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-playbook --ask-vault-pass --syntax-check ~/playbook.yml\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tNote that this command only validates the syntax and does not protect against a wrong but valid configuration.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRun the playbook:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ansible-playbook --ask-vault-pass ~/playbook.yml\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tOpen \u003Ccode class=\"literal\">http://\u003Cspan class=\"emphasis\">\u003Cem>&lt;grafana_server_IP_or_hostname&gt;\u003C/em>\u003C/span>:3000\u003C/code> in your browser, and log in as the \u003Ccode class=\"literal\">admin\u003C/code> user with the password you set in the procedure.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tDisplay monitoring data:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tTo display live data:\n\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"i\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\tClick \u003Cspan class=\"guimenu\">Menu\u003C/span> → \u003Cspan class=\"guisubmenu\">Apps\u003C/span> → \u003Cspan class=\"guisubmenu\">Performance Co-Pilot\u003C/span> → \u003Cspan class=\"guimenuitem\">PCP Vector Checklist\u003C/span>\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\tBy default, the graphs display metrics from the host that runs Grafana. To switch to a different host, enter the hostname in the \u003Ccode class=\"literal\">hostspec\u003C/code> field and press \u003Ckbd class=\"keycap\">Enter\u003C/kbd>.\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tTo display historical data stored in a Redis database: \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance#creating-panel-and-alerts-in-pcp-redis-data-source_setting-up-graphical-representation-of-pcp-metrics\">Create a panel with a PCP Redis data source\u003C/a>. This requires that you set \u003Ccode class=\"literal\">metrics_query_service: true\u003C/code> in the playbook.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/ansible/roles/rhel-system-roles.metrics/README.md\u003C/code> file\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/doc/rhel-system-roles/metrics/\u003C/code> directory\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/ansible-vault_automating-system-administration-by-using-rhel-system-roles\">Ansible vault\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"configuring-web-hooks-in-performance-co-pilot-by-using-the-metrics-rhel-system-role_monitoring-performance-by-using-the-metrics-rhel-system-role\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">4.4. Configuring web hooks in Performance Co-Pilot by using the \u003Ccode class=\"literal\">metrics\u003C/code> RHEL system role\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tThe Performance Co-Pilot (PCP) suite contains the performance metrics inference engine (PMIE) service. This service evaluates performance rules in real time. For example, you can use the default rules to detect excessive swap activities.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tYou can configure a host as a central PCP management site that collects the monitoring data from multiple PCP nodes. If a rule matches, this central host sends a notification to a web hook to notify other services. For example, the web hook can trigger Event-Driven Ansible to run on Ansible Automation Platform template or playbook on the host that had caused the event.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tBy using the \u003Ccode class=\"literal\">metrics\u003C/code> RHEL system role, you can automate the configuration of a central PCP management host that notifies a web hook.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/automating_system_administration_by_using_rhel_system_roles/assembly_preparing-a-control-node-and-managed-nodes-to-use-rhel-system-roles_automating-system-administration-by-using-rhel-system-roles\">You have prepared the control node and the managed nodes\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou are logged in to the control node as a user who can run playbooks on the managed nodes.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe account you use to connect to the managed nodes has \u003Ccode class=\"literal\">sudo\u003C/code> permissions on them.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"#configuring-performance-co-pilot-by-using-the-metrics-rhel-system-role_monitoring-performance-by-using-the-metrics-rhel-system-role\" title=\"4.1. Configuring Performance Co-Pilot by using the metrics RHEL system role\">PCP is configured for remote access on the hosts you want to monitor\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe host on which you want to configure PMIE can access port 44321 on the PCP nodes you plan to monitor.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a playbook file, for example \u003Ccode class=\"literal\">~/playbook.yml\u003C/code>, with the following content:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"programlisting language-yaml\">---\n- name: Monitoring performance metrics\n  hosts: managed-node-01.example.com\n  tasks:\n    - name: Configure PMIE web hooks\n      ansible.builtin.include_role:\n        name: redhat.rhel_system_roles.metrics\n      vars:\n        metrics_manage_firewall: true\n        metrics_retention_days: 7\n        metrics_monitored_hosts:\n          - pcp-node-01.example.com\n          - pcp-node-02.example.com\n        metrics_webhook_endpoint: \"https://&lt;webserver&gt;:&lt;port&gt;/&lt;endpoint&gt;\"\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe settings specified in the example playbook include the following:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">metrics_retention_days: \u003Cspan class=\"emphasis\">\u003Cem>&lt;number&gt;\u003C/em>\u003C/span>\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\tSets the number of days after which the \u003Ccode class=\"literal\">pmlogger_daily\u003C/code> systemd timer removes old PCP archives.\n\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">metrics_manage_firewall: \u003Cspan class=\"emphasis\">\u003Cem>&lt;true|false&gt;\u003C/em>\u003C/span>\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\tDefines whether the role should open the required ports in the \u003Ccode class=\"literal\">firewalld\u003C/code> service. If you want to remotely access PCP on the managed nodes, set this variable to \u003Ccode class=\"literal\">true\u003C/code>.\n\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">metrics_monitored_hosts: \u003Cspan class=\"emphasis\">\u003Cem>&lt;list_of_hosts&gt;\u003C/em>\u003C/span>\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\tSpecifies the hosts to observe.\n\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">metrics_webhook_endpoint: \u003Cspan class=\"emphasis\">\u003Cem>&lt;URL&gt;\u003C/em>\u003C/span>\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\tSets the web hook endpoint to which the performance metrics inference engine (PMIE) sends notifications about detected performance issues. By default, these issues are logged to the local system only.\n\t\t\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor details about all variables used in the playbook, see the \u003Ccode class=\"literal\">/usr/share/ansible/roles/rhel-system-roles.metrics/README.md\u003C/code> file on the control node.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tValidate the playbook syntax:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ ansible-playbook --syntax-check ~/playbook.yml\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tNote that this command only validates the syntax and does not protect against a wrong but valid configuration.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRun the playbook:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ ansible-playbook ~/playbook.yml\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCheck the configuration summary on \u003Ccode class=\"literal\">managed-node-node-01.example.com\u003C/code>:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ansible managed-node-01.example.com -m command -a 'pcp summary'\u003C/strong>\u003C/span>\nPerformance Co-Pilot configuration on managed-node-01.example.com:\n\n platform: Linux managed-node-node-01.example.com 5.14.0-427.el9.x86_64 #1 SMP PREEMPT_DYNAMIC Fri Feb 23 01:51:18 EST 2024 x86_64\n hardware: 8 cpus, 1 disk, 1 node, 1773MB RAM\n timezone: CEST-2\n services: pmcd pmproxy\n pmcd: Version 6.2.0-1, 12 agents, 6 clients\n pmda: root pmcd proc pmproxy xfs linux nfsclient mmv kvm jbd2\n       dm openmetrics\n pmlogger: primary logger: /var/log/pcp/pmlogger/managed-node-node-01.example.com/20240510.16.25\n           pcp-node-01.example.com: /var/log/pmlogger/pcp-node-01.example.com/20240510.16.25\n           pcp-node-02.example.com: /var/log/pmlogger/pcp-node-02.example.com/20240510.16.25\n pmie: primary engine: /var/log/pcp/pmie/managed-node-node-01.example.com/pmie.log\n       pcp-node-01.example.com: : /var/log/pcp/pmie/pcp-node-01.example.com/pmie.log\n       pcp-node-02.example.com: : /var/log/pcp/pmie/pcp-node-02.example.com/pmie.log\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe last three lines confirm that PMIE is configured to monitor three systems.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/ansible/roles/rhel-system-roles.metrics/README.md\u003C/code> file\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/doc/rhel-system-roles/metrics/\u003C/code> directory\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://www.redhat.com/en/blog/automate-performance-management-performance-co-pilot\">Automate performance management with Performance Co-Pilot using Event-Driven Ansible\u003C/a> blog post\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"setting-up-pcp_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 5. Setting up PCP\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tPerformance Co-Pilot (PCP) is a suite of tools, services, and libraries for monitoring, visualizing, storing, and analyzing system-level performance measurements.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"overview-of-pcp_setting-up-pcp\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">5.1. Overview of PCP\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can add performance metrics using Python, Perl, C++, and C interfaces. Analysis tools can use the Python, C++, C client APIs directly, and rich web applications can explore all available performance data using a JSON interface.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tYou can analyze data patterns by comparing live results with archived data.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tFeatures of PCP:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tLight-weight distributed architecture, which is useful during the centralized analysis of complex systems.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIt allows the monitoring and management of real-time data.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIt allows logging and retrieval of historical data.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tPCP has the following components:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe Performance Metric Collector Daemon (\u003Ccode class=\"literal\">pmcd\u003C/code>) collects performance data from the installed Performance Metric Domain Agents (\u003Ccode class=\"literal\">pmda\u003C/code>). \u003Cspan class=\"strong strong\">\u003Cstrong>PMDAs\u003C/strong>\u003C/span> can be individually loaded or unloaded on the system and are controlled by the \u003Cspan class=\"strong strong\">\u003Cstrong>PMCD\u003C/strong>\u003C/span> on the same host.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tVarious client tools, such as \u003Ccode class=\"literal\">pminfo\u003C/code> or \u003Ccode class=\"literal\">pmstat\u003C/code>, can retrieve, display, archive, and process this data on the same host or over the network.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">pcp\u003C/code> package provides the command-line tools and underlying functionality.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">pcp-gui\u003C/code> package provides the graphical application. Install the \u003Ccode class=\"literal\">pcp-gui\u003C/code> package by executing the \u003Ccode class=\"literal\">dnf install pcp-gui\u003C/code> command. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/monitoring-performance-with-performance-co-pilot_monitoring-and-managing-system-status-and-performance#visually-tracing-pcp-log-archives-with-pcp-charts_monitoring-performance-with-performance-co-pilot\">Visually tracing PCP log archives with the PCP Charts application\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">pcp(1)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/doc/pcp-doc/\u003C/code> directory\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index#system-services-distributed-with-pcp_setting-up-pcp\">System services and tools distributed with PCP\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/articles/1145953\">Index of Performance Co-Pilot (PCP) articles, solutions, tutorials, and white papers fromon Red Hat Customer Portal\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/articles/2372811\">Side-by-side comparison of PCP tools with legacy tools Red Hat Knowledgebase article\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"http://pcp.io/documentation.html\">PCP upstream documentation\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"installing-and-enabling-pcp_setting-up-pcp\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">5.2. Installing and enabling PCP\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tTo begin using PCP, install all the required packages and enable the PCP monitoring services.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThis procedure describes how to install PCP using the \u003Ccode class=\"literal\">pcp\u003C/code> package. If you want to automate the PCP installation, install it using the \u003Ccode class=\"literal\">pcp-zeroconf\u003C/code> package. For more information about installing PCP by using \u003Ccode class=\"literal\">pcp-zeroconf\u003C/code>, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index#setting-up-pcp-with-pcp-zeroconf_setting-up-graphical-representation-of-pcp-metrics\">Setting up PCP with pcp-zeroconf\u003C/a>.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInstall the \u003Ccode class=\"literal\">pcp\u003C/code> package:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf install pcp\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnable and start the \u003Ccode class=\"literal\">pmcd\u003C/code> service on the host machine:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># systemctl enable pmcd\n\n# systemctl start pmcd\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify if the \u003Ccode class=\"literal\">pmcd\u003C/code> process is running on the host:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># pcp\n\nPerformance Co-Pilot configuration on workstation:\n\nplatform: Linux workstation 4.18.0-80.el8.x86_64 #1 SMP Wed Mar 13 12:02:46 UTC 2019 x86_64\nhardware: 12 cpus, 2 disks, 1 node, 36023MB RAM\ntimezone: CEST-2\nservices: pmcd\npmcd: Version 4.3.0-1, 8 agents\npmda: root pmcd proc xfs linux mmv kvm jbd2\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">pmcd(1)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index#system-services-distributed-with-pcp_setting-up-pcp\">System services and tools distributed with PCP\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"deploying-a-minimal-pcp-setup_setting-up-pcp\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">5.3. Deploying a minimal PCP setup\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe minimal PCP setup collects performance statistics on Red Hat Enterprise Linux. The setup involves adding the minimum number of packages on a production system needed to gather data for further analysis.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tYou can analyze the resulting \u003Ccode class=\"literal\">tar.gz\u003C/code> file and the archive of the \u003Ccode class=\"literal\">pmlogger\u003C/code> output using various PCP tools and compare them with other sources of performance information.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tPCP is installed. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#installing-and-enabling-pcp_setting-up-pcp\">Installing and enabling PCP\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tUpdate the \u003Ccode class=\"literal\">pmlogger\u003C/code> configuration:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># pmlogconf -r /var/lib/pcp/config/pmlogger/config.default\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tStart the \u003Ccode class=\"literal\">pmcd\u003C/code> and \u003Ccode class=\"literal\">pmlogger\u003C/code> services:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># systemctl start pmcd.service\n\n# systemctl start pmlogger.service\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tExecute the required operations to record the performance data.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tStop the \u003Ccode class=\"literal\">pmcd\u003C/code> and \u003Ccode class=\"literal\">pmlogger\u003C/code> services:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># systemctl stop pmcd.service\n\n# systemctl stop pmlogger.service\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tSave the output and save it to a \u003Ccode class=\"literal\">tar.gz\u003C/code> file named based on the host name and the current date and time:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># cd /var/log/pcp/pmlogger/\n\n# tar -czf $(hostname).$(date +%F-%Hh%M).pcp.tar.gz $(hostname)\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tExtract this file and analyze the data using PCP tools.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">pmlogconf(1)\u003C/code>, \u003Ccode class=\"literal\">pmlogger(1)\u003C/code>, and \u003Ccode class=\"literal\">pmcd(1)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#system-services-distributed-with-pcp_setting-up-pcp\">System services and tools distributed with PCP\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"system-services-distributed-with-pcp_setting-up-pcp\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">5.4. System services and tools distributed with PCP\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tPerformance Co-Pilot (PCP) includes various system services and tools you can use for measuring performance. The basic package \u003Ccode class=\"literal\">pcp\u003C/code> includes the system services and basic tools. Additional tools are provided with the \u003Ccode class=\"literal\">pcp-system-tools\u003C/code>, \u003Ccode class=\"literal\">pcp-gui\u003C/code>, and \u003Ccode class=\"literal\">pcp-devel\u003C/code> packages.\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cp class=\"title\">\u003Cstrong>Roles of system services distributed with PCP\u003C/strong>\u003C/p>\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmcd\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe Performance Metric Collector Daemon (PMCD).\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmie\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe Performance Metrics Inference Engine.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmlogger\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe performance metrics logger.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmproxy\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe realtime and historical performance metrics proxy, time series query and REST API service.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"variablelist\">\u003Cp class=\"title\">\u003Cstrong>Tools distributed with base PCP package\u003C/strong>\u003C/p>\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pcp\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDisplays the current status of a Performance Co-Pilot installation.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pcp-vmstat\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tProvides a high-level system performance overview every 5 seconds. Displays information about processes, memory, paging, block IO, traps, and CPU activity.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmconfig\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDisplays the values of configuration parameters.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmdiff\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tCompares the average values for every metric in either one or two archives, in a given time window, for changes that are likely to be of interest when searching for performance regressions.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmdumplog\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDisplays control, metadata, index, and state information from a Performance Co-Pilot archive file.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmfind\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tFinds PCP services on the network.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmie\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tAn inference engine that periodically evaluates a set of arithmetic, logical, and rule expressions. The metrics are collected either from a live system, or from a Performance Co-Pilot archive file.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmieconf\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDisplays or sets configurable \u003Ccode class=\"literal\">pmie\u003C/code> variables.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmiectl\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tManages non-primary instances of \u003Ccode class=\"literal\">pmie\u003C/code>.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pminfo\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDisplays information about performance metrics. The metrics are collected either from a live system, or from a Performance Co-Pilot archive file.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmlc\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tInteractively configures active \u003Ccode class=\"literal\">pmlogger\u003C/code> instances.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmlogcheck\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tIdentifies invalid data in a Performance Co-Pilot archive file.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmlogconf\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tCreates and modifies a \u003Ccode class=\"literal\">pmlogger\u003C/code> configuration file.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmlogctl\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tManages non-primary instances of \u003Ccode class=\"literal\">pmlogger\u003C/code>.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmloglabel\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tVerifies, modifies, or repairs the label of a Performance Co-Pilot archive file.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmlogredact\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tRemoves sensitive information from PCP archives.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmlogsummary\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tCalculates statistical information about performance metrics stored in a Performance Co-Pilot archive file.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmprobe\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDetermines the availability of performance metrics.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmsocks\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tAllows access to a Performance Co-Pilot hosts through a firewall.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmstat\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tPeriodically displays a brief summary of system performance.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmstore\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tModifies the values of performance metrics.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmtrace\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tProvides a command line interface to the trace PMDA.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmval\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDisplays the current value of a performance metric.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"variablelist\">\u003Cp class=\"title\">\u003Cstrong>Tools distributed with the separately installed \u003Ccode class=\"literal\">pcp-system-tools\u003C/code> package\u003C/strong>\u003C/p>\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pcp-atop\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tShows the system-level occupation of the most critical hardware resources from the performance point of view: CPU, memory, disk, and network.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pcp-atopsar\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tGenerates a system-level activity report over a variety of system resource utilization. The report is generated from a raw logfile previously recorded using \u003Ccode class=\"literal\">pmlogger\u003C/code> or the \u003Ccode class=\"literal\">-w\u003C/code> option of \u003Ccode class=\"literal\">pcp-atop\u003C/code>.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pcp-buddyinfo\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tReports statistics for the buddy algorithm.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pcp-dmcache\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDisplays information about configured Device Mapper Cache targets, such as: device IOPs, cache and metadata device utilization, as well as hit and miss rates and ratios for both reads and writes for each cache device.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pcp-dstat\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDisplays metrics of one system at a time. To display metrics of multiple systems, use \u003Ccode class=\"literal\">--host\u003C/code> option.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pcp-free\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tReports on free and used memory in a system.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pcp-htop\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDisplays all processes running on a system along with their command line arguments in a manner similar to the \u003Ccode class=\"literal\">top\u003C/code> command, but allows you to scroll vertically and horizontally as well as interact using a mouse. You can also view processes in a tree format and select and act on multiple processes at once.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pcp-ipcs\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDisplays information about the inter-process communication (IPC) facilities that the calling process has read access for.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pcp-meminfo\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tReports statistics for the kernel system memory.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pcp-mpstat\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tReports CPU and interrupt-related statistics.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pcp-netstat\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tReports statistics for network protocols and network interfaces.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pcp-numastat\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDisplays NUMA allocation statistics from the kernel memory allocator.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pcp-pidstat\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDisplays information about individual tasks or processes running on the system, such as CPU percentage, memory and stack usage, scheduling, and priority. Reports live data for the local host by default.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pcp-shping\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tSamples and reports on the shell-ping service metrics exported by the \u003Ccode class=\"literal\">pmdashping\u003C/code> Performance Metrics Domain Agent (PMDA).\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pcp-slabinfo\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tReports statistics for the kernel slab allocator.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pcp-ss\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDisplays socket statistics collected by the \u003Ccode class=\"literal\">pmdasockets\u003C/code> PMDA.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pcp-tapestat\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tReports I/O statistics for tape devices.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pcp-uptime\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDisplays how long the system has been running, how many users are currently logged on, and the system load averages for the past 1, 5, and 15 minutes.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pcp-zoneinfo\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tReports statistics related to Non-Uniform Memory Access (NUMA) nodes.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pcp-verify\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tInspects various aspects of a Performance Co-Pilot collector installation and reports on whether it is configured correctly for certain modes of operation.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmiostat\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tReports I/O statistics for SCSI devices (by default) or device-mapper devices (with the \u003Ccode class=\"literal\">-x\u003C/code> device-mapper option).\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmrep\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tReports on selected, easily customizable, performance metrics values.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"variablelist\">\u003Cp class=\"title\">\u003Cstrong>Tools distributed with the separately installed \u003Ccode class=\"literal\">pcp-gui\u003C/code> package\u003C/strong>\u003C/p>\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmchart\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tPlots performance metrics values available through the facilities of the Performance Co-Pilot.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmdumptext\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tOutputs the values of performance metrics collected live or from a Performance Co-Pilot archive.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"variablelist\">\u003Cp class=\"title\">\u003Cstrong>Tools distributed with the separately installed \u003Ccode class=\"literal\">pcp-devel\u003C/code> package\u003C/strong>\u003C/p>\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmclient\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDisplays high-level system performance metrics by using the Performance Metrics Application Programming Interface (PMAPI).\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmdbg\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDisplays available Performance Co-Pilot debug control flags and their values.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmerr\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDisplays available Performance Co-Pilot error codes and their corresponding error messages.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"variablelist\">\u003Cp class=\"title\">\u003Cstrong>Tool distributed with the separately installed \u003Ccode class=\"literal\">pcp-geolocate\u003C/code> package\u003C/strong>\u003C/p>\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pcp-geolocate\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDiscovers collector system geographical labels and reports the latitude and longitude for the local PCP collector host in JSON format.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"pcp-deployment-architectures_setting-up-pcp\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">5.5. PCP deployment architectures\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tPerformance Co-Pilot (PCP) supports multiple deployment architectures, based on the scale of the PCP deployment, and offers many options to accomplish advanced setups.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tAvailable scaling deployment setup variants based on the recommended deployment set up by Red Hat, sizing factors, and configuration options include:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Localhost\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tEach service runs locally on the monitored machine. When you start a service without any configuration changes, this is the default deployment. Scaling beyond the individual node is not possible in this case.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tBy default, the deployment setup for Redis is standalone, localhost. However, Redis can optionally perform in a highly-available and highly scalable clustered fashion, where data is shared across multiple hosts. Another viable option is to deploy a Redis cluster in the cloud, or to utilize a managed Redis cluster from a cloud vendor.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Decentralized\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe only difference between localhost and decentralized setup is the centralized Redis service. In this model, the host executes \u003Ccode class=\"literal\">pmlogger\u003C/code> service on each monitored host and retrieves metrics from a local \u003Ccode class=\"literal\">pmcd\u003C/code> instance. A local \u003Ccode class=\"literal\">pmproxy\u003C/code> service then exports the performance metrics to a central Redis instance.\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"figure\" id=\"idm140280153089744\">\u003Cp class=\"title\">\u003Cstrong>Figure 5.1. Decentralized logging\u003C/strong>\u003C/p>\u003Cdiv class=\"figure-contents\">\u003Cdiv class=\"mediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/8e69aa84f8186f3fa2ee8f1787c2dc17/173_RHEL_instaling_PCP_0721_decentralized.png\" alt=\"Decentralized logging\"/>\u003C/div>\u003C/div>\u003C/div>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Centralized logging - pmlogger farm\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tWhen the resource usage on the monitored hosts is constrained, another deployment option is a \u003Ccode class=\"literal\">pmlogger\u003C/code> farm, which is also known as centralized logging. In this setup, a single logger host executes multiple \u003Ccode class=\"literal\">pmlogger\u003C/code> processes, and each is configured to retrieve performance metrics from a different remote \u003Ccode class=\"literal\">pmcd\u003C/code> host. The centralized logger host is also configured to execute the \u003Ccode class=\"literal\">pmproxy\u003C/code> service, which discovers the resulting PCP archives logs and loads the metric data into a Redis instance.\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"figure\" id=\"idm140280133379776\">\u003Cp class=\"title\">\u003Cstrong>Figure 5.2. Centralized logging - pmlogger farm\u003C/strong>\u003C/p>\u003Cdiv class=\"figure-contents\">\u003Cdiv class=\"mediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/6a30238925dab26408092ae39258801e/173_RHEL_instaling_PCP_0721_centralized.png\" alt=\"Centralized logging - pmlogger farm\"/>\u003C/div>\u003C/div>\u003C/div>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Federated - multiple pmlogger farms\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFor large scale deployments, Red Hat recommends to deploy multiple \u003Ccode class=\"literal\">pmlogger\u003C/code> farms in a federated fashion. For example, one \u003Ccode class=\"literal\">pmlogger\u003C/code> farm per rack or data center. Each \u003Ccode class=\"literal\">pmlogger\u003C/code> farm loads the metrics into a central Redis instance.\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"figure\" id=\"idm140280158647136\">\u003Cp class=\"title\">\u003Cstrong>Figure 5.3. Federated - multiple pmlogger farms\u003C/strong>\u003C/p>\u003Cdiv class=\"figure-contents\">\u003Cdiv class=\"mediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/0184fc52d4cf8596c8a0927914cab33c/173_RHEL_instaling_PCP_0721_federated.png\" alt=\"Federated - multiple pmlogger farms\"/>\u003C/div>\u003C/div>\u003C/div>\u003C/dd>\u003C/dl>\u003C/div>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tBy default, the deployment setup for Redis is standalone, localhost. However, Redis can optionally perform in a highly-available and highly scalable clustered fashion, where data is shared across multiple hosts. Another viable option is to deploy a Redis cluster in the cloud, or to utilize a managed Redis cluster from a cloud vendor.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">pcp(1)\u003C/code>, \u003Ccode class=\"literal\">pmlogger(1)\u003C/code>, \u003Ccode class=\"literal\">pmproxy(1)\u003C/code>, and \u003Ccode class=\"literal\">pmcd(1)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index#recommended-deployment-architecture_setting-up-pcp\">Recommended deployment architecture\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"recommended-deployment-architecture_setting-up-pcp\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">5.6. Recommended deployment architecture\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe following table describes the recommended deployment architectures based on the number of monitored hosts.\n\t\t\t\u003C/p>\u003Crh-table id=\"idm140280153819360\">\u003Ctable class=\"gt-4-cols lt-7-rows\">\u003Ccaption>Table 5.1. Recommended deployment architecture\u003C/caption>\u003Ccolgroup>\u003Ccol style=\"width: 25%; \" class=\"col_1\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 25%; \" class=\"col_2\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 25%; \" class=\"col_3\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 25%; \" class=\"col_4\">\u003C!--Empty-->\u003C/col>\u003C/colgroup>\u003Cthead>\u003Ctr>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280150578208\" scope=\"col\">Number of hosts (N)\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280150577120\" scope=\"col\">1-10\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280150576032\" scope=\"col\">10-100\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280150574944\" scope=\"col\">100-1000\u003C/th>\u003C/tr>\u003C/thead>\u003Ctbody>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280150578208\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">pmcd\u003C/code> servers\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280150577120\"> \u003Cp>\n\t\t\t\t\t\t\t\tN\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280150576032\"> \u003Cp>\n\t\t\t\t\t\t\t\tN\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280150574944\"> \u003Cp>\n\t\t\t\t\t\t\t\tN\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280150578208\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">pmlogger\u003C/code> servers\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280150577120\"> \u003Cp>\n\t\t\t\t\t\t\t\t1 to N\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280150576032\"> \u003Cp>\n\t\t\t\t\t\t\t\tN/10 to N\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280150574944\"> \u003Cp>\n\t\t\t\t\t\t\t\tN/100 to N\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280150578208\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">pmproxy\u003C/code> servers\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280150577120\"> \u003Cp>\n\t\t\t\t\t\t\t\t1 to N\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280150576032\"> \u003Cp>\n\t\t\t\t\t\t\t\t1 to N\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280150574944\"> \u003Cp>\n\t\t\t\t\t\t\t\tN/100 to N\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280150578208\"> \u003Cp>\n\t\t\t\t\t\t\t\tRedis servers\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280150577120\"> \u003Cp>\n\t\t\t\t\t\t\t\t1 to N\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280150576032\"> \u003Cp>\n\t\t\t\t\t\t\t\t1 to N/10\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280150574944\"> \u003Cp>\n\t\t\t\t\t\t\t\tN/100 to N/10\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280150578208\"> \u003Cp>\n\t\t\t\t\t\t\t\tRedis cluster\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280150577120\"> \u003Cp>\n\t\t\t\t\t\t\t\tNo\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280150576032\"> \u003Cp>\n\t\t\t\t\t\t\t\tMaybe\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280150574944\"> \u003Cp>\n\t\t\t\t\t\t\t\tYes\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280150578208\"> \u003Cp>\n\t\t\t\t\t\t\t\tRecommended deployment setup\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280150577120\"> \u003Cp>\n\t\t\t\t\t\t\t\tLocalhost, Decentralized, or Centralized logging\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280150576032\"> \u003Cp>\n\t\t\t\t\t\t\t\tDecentralized, Centralized logging, or Federated\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280150574944\"> \u003Cp>\n\t\t\t\t\t\t\t\tDecentralized or Federated\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\u003C/rh-table>\u003C/section>\u003Csection class=\"section\" id=\"sizing-factors_setting-up-pcp\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">5.7. Sizing factors\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe following are the sizing factors required for scaling:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Remote system size\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe number of CPUs, disks, network interfaces, and other hardware resources affects the amount of data collected by each \u003Ccode class=\"literal\">pmlogger\u003C/code> on the centralized logging host.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Logged Metrics\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe number and types of logged metrics play an important role. In particular, the \u003Ccode class=\"literal\">per-process proc.*\u003C/code> metrics require a large amount of disk space, for example, with the standard \u003Ccode class=\"literal\">pcp-zeroconf\u003C/code> setup, 10s logging interval, 11 MB without proc metrics versus 155 MB with proc metrics - a factor of 10 times more. Additionally, the number of instances for each metric, for example the number of CPUs, block devices, and network interfaces also impacts the required storage capacity.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Logging Interval\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe interval how often metrics are logged, affects the storage requirements. The expected daily PCP archive file sizes are written to the \u003Ccode class=\"literal\">pmlogger.log\u003C/code> file for each \u003Ccode class=\"literal\">pmlogger\u003C/code> instance. These values are uncompressed estimates. Since PCP archives compress very well, approximately 10:1, the actual long term disk space requirements can be determined for a particular site.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmlogrewrite\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tAfter every PCP upgrade, the \u003Ccode class=\"literal\">pmlogrewrite\u003C/code> tool is executed and rewrites old archives if there were changes in the metric metadata from the previous version and the new version of PCP. This process duration scales linear with the number of archives stored.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">pmlogrewrite(1)\u003C/code> and \u003Ccode class=\"literal\">pmlogger(1)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"configuration-options-for-pcp-scaling_setting-up-pcp\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">5.8. Configuration options for PCP scaling\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe following are the configuration options, which are required for scaling:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">sysctl and rlimit settings\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tWhen archive discovery is enabled, \u003Ccode class=\"literal\">pmproxy\u003C/code> requires four descriptors for every \u003Ccode class=\"literal\">pmlogger\u003C/code> that it is monitoring or log-tailing, along with the additional file descriptors for the service logs and \u003Ccode class=\"literal\">pmproxy\u003C/code> client sockets, if any. Each \u003Ccode class=\"literal\">pmlogger\u003C/code> process uses about 20 file descriptors for the remote \u003Ccode class=\"literal\">pmcd\u003C/code> socket, archive files, service logs, and others. In total, this can exceed the default 1024 soft limit on a system running around 200 \u003Ccode class=\"literal\">pmlogger\u003C/code> processes. The \u003Ccode class=\"literal\">pmproxy\u003C/code> service in \u003Ccode class=\"literal\">pcp-5.3.0\u003C/code> and later automatically increases the soft limit to the hard limit. On earlier versions of PCP, tuning is required if a high number of \u003Ccode class=\"literal\">pmlogger\u003C/code> processes are to be deployed, and this can be accomplished by increasing the soft or hard limits for \u003Ccode class=\"literal\">pmlogger\u003C/code>. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/solutions/1346533\">How to set limits (ulimit) for services run by systemd\u003C/a>.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Local Archives\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">pmlogger\u003C/code> service stores metrics of local and remote \u003Ccode class=\"literal\">pmcds\u003C/code> in the \u003Ccode class=\"literal\">/var/log/pcp/pmlogger/\u003C/code> directory. To control the logging interval of the local system, update the \u003Ccode class=\"literal\">/etc/pcp/pmlogger/control.d/\u003Cspan class=\"emphasis\">\u003Cem>configfile\u003C/em>\u003C/span>\u003C/code> file and add \u003Ccode class=\"literal\">-t \u003Cspan class=\"emphasis\">\u003Cem>X\u003C/em>\u003C/span>\u003C/code> in the arguments, where \u003Cspan class=\"emphasis\">\u003Cem>X\u003C/em>\u003C/span> is the logging interval in seconds. To configure which metrics should be logged, execute \u003Ccode class=\"literal\">pmlogconf /var/lib/pcp/config/pmlogger/config.\u003Cspan class=\"emphasis\">\u003Cem>clienthostname\u003C/em>\u003C/span>\u003C/code>. This command deploys a configuration file with a default set of metrics, which can optionally be further customized. To specify retention settings, that is when to purge old PCP archives, update the \u003Ccode class=\"literal\">/etc/sysconfig/pmlogger_timers\u003C/code> file and specify \u003Ccode class=\"literal\">PMLOGGER_DAILY_PARAMS=\"-E -k \u003Cspan class=\"emphasis\">\u003Cem>X\u003C/em>\u003C/span>\"\u003C/code>, where \u003Cspan class=\"emphasis\">\u003Cem>X\u003C/em>\u003C/span> is the amount of days to keep PCP archives.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Redis\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">pmproxy\u003C/code> service sends logged metrics from \u003Ccode class=\"literal\">pmlogger\u003C/code> to a Redis instance. The following are the available two options to specify the retention settings in the \u003Ccode class=\"literal\">/etc/pcp/pmproxy/pmproxy.conf\u003C/code> configuration file:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">stream.expire\u003C/code> specifies the duration when stale metrics should be removed, that is metrics which were not updated in a specified amount of time in seconds.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">stream.maxlen\u003C/code> specifies the maximum number of metric values for one metric per host. This setting should be the retention time divided by the logging interval, for example 20160 for 14 days of retention and 60s logging interval (60*60*24*14/60)\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">pmproxy(1)\u003C/code>, \u003Ccode class=\"literal\">pmlogger(1)\u003C/code>, and \u003Ccode class=\"literal\">sysctl(8)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"example-analyzing-the-centralized-logging-deployment_setting-up-pcp\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">5.9. Example: Analyzing the centralized logging deployment\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe following results were gathered on a centralized logging setup, also known as pmlogger farm deployment, with a default \u003Ccode class=\"literal\">pcp-zeroconf 5.3.0\u003C/code> installation, where each remote host is an identical container instance running \u003Ccode class=\"literal\">pmcd\u003C/code> on a server with 64 CPU cores, 376 GB RAM, and one disk attached.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe logging interval is 10s, proc metrics of remote nodes are not included, and the memory values refer to the Resident Set Size (RSS) value.\n\t\t\t\u003C/p>\u003Crh-table id=\"idm140280139551008\">\u003Ctable class=\"lt-4-cols lt-7-rows\">\u003Ccaption>Table 5.2. Detailed utilization statistics for 10s logging interval\u003C/caption>\u003Ccolgroup>\u003Ccol style=\"width: 33%; \" class=\"col_1\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 33%; \" class=\"col_2\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 33%; \" class=\"col_3\">\u003C!--Empty-->\u003C/col>\u003C/colgroup>\u003Cthead>\u003Ctr>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280161850736\" scope=\"col\">Number of Hosts\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280161849648\" scope=\"col\">10\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280161848560\" scope=\"col\">50\u003C/th>\u003C/tr>\u003C/thead>\u003Ctbody>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280161850736\"> \u003Cp>\n\t\t\t\t\t\t\t\tPCP Archives Storage per Day\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280161849648\"> \u003Cp>\n\t\t\t\t\t\t\t\t91 MB\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280161848560\"> \u003Cp>\n\t\t\t\t\t\t\t\t522 MB\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280161850736\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">pmlogger\u003C/code> Memory\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280161849648\"> \u003Cp>\n\t\t\t\t\t\t\t\t160 MB\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280161848560\"> \u003Cp>\n\t\t\t\t\t\t\t\t580 MB\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280161850736\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">pmlogger\u003C/code> Network per Day (In)\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280161849648\"> \u003Cp>\n\t\t\t\t\t\t\t\t2 MB\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280161848560\"> \u003Cp>\n\t\t\t\t\t\t\t\t9 MB\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280161850736\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">pmproxy\u003C/code> Memory\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280161849648\"> \u003Cp>\n\t\t\t\t\t\t\t\t1.4 GB\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280161848560\"> \u003Cp>\n\t\t\t\t\t\t\t\t6.3 GB\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280161850736\"> \u003Cp>\n\t\t\t\t\t\t\t\tRedis Memory per Day\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280161849648\"> \u003Cp>\n\t\t\t\t\t\t\t\t2.6 GB\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280161848560\"> \u003Cp>\n\t\t\t\t\t\t\t\t12 GB\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\u003C/rh-table>\u003Crh-table id=\"idm140280148158976\">\u003Ctable class=\"gt-4-cols lt-7-rows\">\u003Ccaption>Table 5.3. Used resources depending on monitored hosts for 60s logging interval\u003C/caption>\u003Ccolgroup>\u003Ccol style=\"width: 25%; \" class=\"col_1\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 25%; \" class=\"col_2\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 25%; \" class=\"col_3\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 25%; \" class=\"col_4\">\u003C!--Empty-->\u003C/col>\u003C/colgroup>\u003Cthead>\u003Ctr>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280159714928\" scope=\"col\">Number of Hosts\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280159713840\" scope=\"col\">10\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280159712752\" scope=\"col\">50\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280159711664\" scope=\"col\">100\u003C/th>\u003C/tr>\u003C/thead>\u003Ctbody>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280159714928\"> \u003Cp>\n\t\t\t\t\t\t\t\tPCP Archives Storage per Day\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280159713840\"> \u003Cp>\n\t\t\t\t\t\t\t\t20 MB\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280159712752\"> \u003Cp>\n\t\t\t\t\t\t\t\t120 MB\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280159711664\"> \u003Cp>\n\t\t\t\t\t\t\t\t271 MB\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280159714928\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">pmlogger\u003C/code> Memory\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280159713840\"> \u003Cp>\n\t\t\t\t\t\t\t\t104 MB\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280159712752\"> \u003Cp>\n\t\t\t\t\t\t\t\t524 MB\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280159711664\"> \u003Cp>\n\t\t\t\t\t\t\t\t1049 MB\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280159714928\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">pmlogger\u003C/code> Network per Day (In)\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280159713840\"> \u003Cp>\n\t\t\t\t\t\t\t\t0.38 MB\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280159712752\"> \u003Cp>\n\t\t\t\t\t\t\t\t1.75 MB\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280159711664\"> \u003Cp>\n\t\t\t\t\t\t\t\t3.48 MB\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280159714928\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">pmproxy\u003C/code> Memory\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280159713840\"> \u003Cp>\n\t\t\t\t\t\t\t\t2.67 GB\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280159712752\"> \u003Cp>\n\t\t\t\t\t\t\t\t5.5GB\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280159711664\"> \u003Cp>\n\t\t\t\t\t\t\t\t9 GB\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280159714928\"> \u003Cp>\n\t\t\t\t\t\t\t\tRedis Memory per Day\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280159713840\"> \u003Cp>\n\t\t\t\t\t\t\t\t0.54 GB\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280159712752\"> \u003Cp>\n\t\t\t\t\t\t\t\t2.65 GB\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280159711664\"> \u003Cp>\n\t\t\t\t\t\t\t\t5.3 GB\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\u003C/rh-table>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tThe \u003Ccode class=\"literal\">pmproxy\u003C/code> queues Redis requests and employs Redis pipelining to speed up Redis queries. This can result in high memory usage. For troubleshooting this issue, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index#troubleshooting-high-memory-usage_setting-up-pcp\">Troubleshooting high memory usage\u003C/a>.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/section>\u003Csection class=\"section\" id=\"example-analyzing-the-federated-setup-deployment_setting-up-pcp\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">5.10. Example: Analyzing the federated setup deployment\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe following results were observed on a federated setup, also known as multiple \u003Ccode class=\"literal\">pmlogger\u003C/code> farms, consisting of three centralized logging (\u003Ccode class=\"literal\">pmlogger\u003C/code> farm) setups, where each \u003Ccode class=\"literal\">pmlogger\u003C/code> farm was monitoring 100 remote hosts, that is 300 hosts in total.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThis setup of the \u003Ccode class=\"literal\">pmlogger\u003C/code> farms is identical to the configuration mentioned in the\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\u003Ca class=\"link\" href=\"#example-analyzing-the-centralized-logging-deployment_setting-up-pcp\" title=\"5.9. Example: Analyzing the centralized logging deployment\">Example: Analyzing the centralized logging deployment\u003C/a> for 60s logging interval, except that the Redis servers were operating in cluster mode.\n\t\t\t\u003C/p>\u003Crh-table id=\"idm140280153889888\">\u003Ctable class=\"gt-4-cols lt-7-rows\">\u003Ccaption>Table 5.4. Used resources depending on federated hosts for 60s logging interval\u003C/caption>\u003Ccolgroup>\u003Ccol style=\"width: 20%; \" class=\"col_1\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 20%; \" class=\"col_2\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 20%; \" class=\"col_3\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 20%; \" class=\"col_4\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 20%; \" class=\"col_5\">\u003C!--Empty-->\u003C/col>\u003C/colgroup>\u003Cthead>\u003Ctr>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280142321680\" scope=\"col\">PCP Archives Storage per Day\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280142320576\" scope=\"col\">\u003Ccode class=\"literal\">pmlogger\u003C/code> Memory\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280142319168\" scope=\"col\">Network per Day (In/Out)\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280142318064\" scope=\"col\">\u003Ccode class=\"literal\">pmproxy\u003C/code> Memory\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280142316656\" scope=\"col\">Redis Memory per Day\u003C/th>\u003C/tr>\u003C/thead>\u003Ctbody>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280142321680\"> \u003Cp>\n\t\t\t\t\t\t\t\t277 MB\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280142320576\"> \u003Cp>\n\t\t\t\t\t\t\t\t1058 MB\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280142319168\"> \u003Cp>\n\t\t\t\t\t\t\t\t15.6 MB / 12.3 MB\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280142318064\"> \u003Cp>\n\t\t\t\t\t\t\t\t6-8 GB\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280142316656\"> \u003Cp>\n\t\t\t\t\t\t\t\t5.5 GB\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\u003C/rh-table>\u003Cp>\n\t\t\t\tHere, all values are per host. The network bandwidth is higher due to the inter-node communication of the Redis cluster.\n\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"establishing-secure-pcp-connections_setting-up-pcp\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">5.11. Establishing secure PCP connections\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can configure PCP collector and monitoring components to participate in secure PCP protocol exchanges.\n\t\t\t\u003C/p>\u003Csection class=\"section\" id=\"secure-pcp-connections_establishing-secure-pcp-connections\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">5.11.1. Secure PCP connections\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tYou can establish secure connections between Performance Co-Pilot (PCP) collector and monitoring components. PCP collector components are the parts of PCP that collect and extract performance data from different sources. PCP monitor components are the parts of PCP that display data collected from hosts or archives that have the PCP collector components installed. Establishing secure connections between these components helps prevent unauthorized parties from accessing or modifying the data being collected and monitored.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tAll connections with the Performance Metrics Collector Daemon (\u003Ccode class=\"literal\">pmcd\u003C/code>) are made using the TCP/IP based PCP protocol. Protocol proxying and the PCP REST APIs are served by the \u003Ccode class=\"literal\">pmproxy\u003C/code> daemon - the REST API can be accessed over HTTPS, ensuring a secure connection.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tBoth the \u003Ccode class=\"literal\">pmcd\u003C/code> and \u003Ccode class=\"literal\">pmproxy\u003C/code> daemons are capable of simultaneous TLS and non-TLS communications on a single port. The default port for \u003Ccode class=\"literal\">pmcd\u003C/code> is 44321 and 44322 for \u003Ccode class=\"literal\">pmproxy\u003C/code>. This means that you do not have to choose between TLS or non-TLS communications for your PCP collector systems and can use both at the same time.\n\t\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"configuring-secure-connections-for-pcp-collector-components_establishing-secure-pcp-connections\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">5.11.2. Configuring secure connections for PCP collector components\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tAll PCP collector systems must have valid certificates in order to participate in secure PCP protocol exchanges.\n\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\tthe \u003Ccode class=\"literal\">pmproxy\u003C/code> daemon operates as both a client and a server from the perspective of TLS.\n\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tPCP is installed. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#installing-and-enabling-pcp_setting-up-pcp\">Installing and enabling PCP\u003C/a>.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe private client key is stored in the \u003Ccode class=\"literal\">/etc/pcp/tls/client.key\u003C/code> file. If you use a different path, adapt the corresponding steps of the procedure.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFor details about creating a private key and certificate signing request (CSR), as well as how to request a certificate from a certificate authority (CA), see your CA’s documentation.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe TLS client certificate is stored in the \u003Ccode class=\"literal\">/etc/pcp/tls/client.crt\u003C/code> file. If you use a different path, adapt the corresponding steps of the procedure.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe CA certificate is stored in the \u003Ccode class=\"literal\">/etc/pcp/tls/ca.crt\u003C/code> file. If you use a different path, adapt the corresponding steps of the procedure. Additionally, for the \u003Ccode class=\"literal\">pmproxy\u003C/code> daemon:\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe private server key is stored in the \u003Ccode class=\"literal\">/etc/pcp/tls/server.key\u003C/code> file. If you use a different path, adapt the corresponding steps of the procedure\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe TLS server certificate is stored in the \u003Ccode class=\"literal\">/etc/pcp/tls/server.crt\u003C/code> file. If you use a different path, adapt the corresponding steps of the procedure.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tUpdate the PCP TLS configuration file on the collector systems to use the CA issued certificates to establish a secure connection:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># cat &gt; /etc/pcp/tls.conf &lt;&lt; END\ntls-ca-cert-file = /etc/pcp/tls/ca.crt\ntls-key-file = /etc/pcp/tls/server.key\ntls-cert-file = /etc/pcp/tls/server.crt\ntls-client-key-file = /etc/pcp/tls/client.key\ntls-client-cert-file = /etc/pcp/tls/client.crt\nEND\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tRestart the PCP collector infrastructure:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># systemctl restart pmcd.service\n# systemctl restart pmproxy.service\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tVerify the TLS configuration:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tOn the \u003Ccode class=\"literal\">pmcd\u003C/code> service:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># grep 'Info:' /var/log/pcp/pmcd/pmcd.log\n[Tue Feb 07 11:47:33] pmcd(6558) Info: OpenSSL 3.0.7 setup\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tOn the \u003Ccode class=\"literal\">pmproxy\u003C/code> service:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># grep 'Info:' /var/log/pcp/pmproxy/pmproxy.log\n[Tue Feb 07 11:44:13] pmproxy(6014) Info: OpenSSL 3.0.7 setup\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"configuring-secure-connections-for-pcp-monitoring-components_establishing-secure-pcp-connections\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">5.11.3. Configuring secure connections for PCP monitoring components\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tConfigure your PCP monitoring components to participate in secure PCP protocol exchanges.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tPCP is installed. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#installing-and-enabling-pcp_setting-up-pcp\">Installing and enabling PCP\u003C/a>.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe private client key is stored in the \u003Ccode class=\"literal\">~/.pcp/tls/client.key\u003C/code> file. If you use a different path, adapt the corresponding steps of the procedure.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFor details about creating a private key and certificate signing request (CSR), as well as how to request a certificate from a certificate authority (CA), see your CA’s documentation.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe TLS client certificate is stored in the \u003Ccode class=\"literal\">~/.pcp/tls/client.crt\u003C/code> file. If you use a different path, adapt the corresponding steps of the procedure.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe CA certificate is stored in the \u003Ccode class=\"literal\">/etc/pcp/tls/ca.crt\u003C/code> file. If you use a different path, adapt the corresponding steps of the procedure.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tCreate a TLS configuration file with the following information:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ home=\u003Ccode class=\"literal\">echo ~\u003C/code>\n$ cat &gt; ~/.pcp/tls.conf &lt;&lt; END\ntls-ca-cert-file = /etc/pcp/tls/ca.crt\ntls-key-file = $home/.pcp/tls/client.key\ntls-cert-file = $home/.pcp/tls/client.crt\nEND\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tEstablish the secure connection:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ export PCP_SECURE_SOCKETS=enforce\n$ export PCP_TLSCONF_PATH=~/.pcp/tls.conf\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tVerify the secure connection is configured:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ pminfo --fetch --host pcps://localhost kernel.all.load\n\nkernel.all.load\n    inst [1 or \"1 minute\"] value 1.26\n    inst [5 or \"5 minute\"] value 1.29\n    inst [15 or \"15 minute\"] value 1.28\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"section\" id=\"troubleshooting-high-memory-usage_setting-up-pcp\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">5.12. Troubleshooting high memory usage\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe following scenarios can result in high memory usage:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">pmproxy\u003C/code> process is busy processing new PCP archives and does not have spare CPU cycles to process Redis requests and responses.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe Redis node or cluster is overloaded and cannot process incoming requests on time.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tThe \u003Ccode class=\"literal\">pmproxy\u003C/code> service daemon uses Redis streams and supports the configuration parameters, which are PCP tuning parameters and affects Redis memory usage and key retention. The \u003Ccode class=\"literal\">/etc/pcp/pmproxy/pmproxy.conf\u003C/code> file lists the available configuration options for \u003Ccode class=\"literal\">pmproxy\u003C/code> and the associated APIs.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe following procedure describes how to troubleshoot high memory usage issue.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInstall the \u003Ccode class=\"literal\">pcp-pmda-redis\u003C/code> package:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf install pcp-pmda-redis\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInstall the redis PMDA:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># cd /var/lib/pcp/pmdas/redis &amp;&amp; ./Install\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo troubleshoot high memory usage, execute the following command and observe the \u003Ccode class=\"literal\">inflight\u003C/code> column:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ pmrep :pmproxy\n         backlog  inflight  reqs/s  resp/s   wait req err  resp err  changed  throttled\n          byte     count   count/s  count/s  s/s  count/s   count/s  count/s   count/s\n14:59:08   0         0       N/A       N/A   N/A    N/A      N/A      N/A        N/A\n14:59:09   0         0    2268.9    2268.9    28     0        0       2.0        4.0\n14:59:10   0         0       0.0       0.0     0     0        0       0.0        0.0\n14:59:11   0         0       0.0       0.0     0     0        0       0.0        0.0\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThis column shows how many Redis requests are in-flight, which means they are queued or sent, and no reply was received so far.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tA high number indicates one of the following conditions:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">pmproxy\u003C/code> process is busy processing new PCP archives and does not have spare CPU cycles to process Redis requests and responses.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe Redis node or cluster is overloaded and cannot process incoming requests on time.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo troubleshoot the high memory usage issue, reduce the number of \u003Ccode class=\"literal\">pmlogger\u003C/code> processes for this farm, and add another pmlogger farm. Use the federated - multiple pmlogger farms setup.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIf the Redis node is using 100% CPU for an extended amount of time, move it to a host with better performance or use a clustered Redis setup instead.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo view the \u003Ccode class=\"literal\">pmproxy.redis.*\u003C/code> metrics, use the following command:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ pminfo -ftd pmproxy.redis\npmproxy.redis.responses.wait [wait time for responses]\n    Data Type: 64-bit unsigned int  InDom: PM_INDOM_NULL 0xffffffff\n    Semantics: counter  Units: microsec\n    value 546028367374\npmproxy.redis.responses.error [number of error responses]\n    Data Type: 64-bit unsigned int  InDom: PM_INDOM_NULL 0xffffffff\n    Semantics: counter  Units: count\n    value 1164\n[...]\npmproxy.redis.requests.inflight.bytes [bytes allocated for inflight requests]\n    Data Type: 64-bit int  InDom: PM_INDOM_NULL 0xffffffff\n    Semantics: discrete  Units: byte\n    value 0\n\npmproxy.redis.requests.inflight.total [inflight requests]\n    Data Type: 64-bit unsigned int  InDom: PM_INDOM_NULL 0xffffffff\n    Semantics: discrete  Units: count\n    value 0\n[...]\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo view how many Redis requests are inflight, see the \u003Ccode class=\"literal\">pmproxy.redis.requests.inflight.total\u003C/code> metric and \u003Ccode class=\"literal\">pmproxy.redis.requests.inflight.bytes\u003C/code> metric to view how many bytes are occupied by all current inflight Redis requests.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn general, the redis request queue would be zero but can build up based on the usage of large pmlogger farms, which limits scalability and can cause high latency for \u003Ccode class=\"literal\">pmproxy\u003C/code> clients.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tUse the \u003Ccode class=\"literal\">pminfo\u003C/code> command to view information about performance metrics. For example, to view the \u003Ccode class=\"literal\">redis.*\u003C/code> metrics, use the following command:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ pminfo -ftd redis\nredis.redis_build_id [Build ID]\n    Data Type: string  InDom: 24.0 0x6000000\n    Semantics: discrete  Units: count\n    inst [0 or \"localhost:6379\"] value \"87e335e57cffa755\"\nredis.total_commands_processed [Total number of commands processed by the server]\n    Data Type: 64-bit unsigned int  InDom: 24.0 0x6000000\n    Semantics: counter  Units: count\n    inst [0 or \"localhost:6379\"] value 595627069\n[...]\n\nredis.used_memory_peak [Peak memory consumed by Redis (in bytes)]\n    Data Type: 32-bit unsigned int  InDom: 24.0 0x6000000\n    Semantics: instant  Units: count\n    inst [0 or \"localhost:6379\"] value 572234920\n[...]\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo view the peak memory usage, see the \u003Ccode class=\"literal\">redis.used_memory_peak\u003C/code> metric.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">pmdaredis(1)\u003C/code>, \u003Ccode class=\"literal\">pmproxy(1)\u003C/code>, and \u003Ccode class=\"literal\">pminfo(1)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"#pcp-deployment-architectures_setting-up-pcp\" title=\"5.5. PCP deployment architectures\">PCP deployment architectures\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"logging-performance-data-with-pmlogger_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 6. Logging performance data with pmlogger\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tWith the PCP tool you can log the performance metric values and replay them later. This allows you to perform a retrospective performance analysis.\n\t\t\u003C/p>\u003Cp>\n\t\t\tUsing the \u003Ccode class=\"literal\">pmlogger\u003C/code> tool, you can:\n\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\tCreate the archived logs of selected metrics on the system\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tSpecify which metrics are recorded on the system and how often\n\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Csection class=\"section\" id=\"modifying-the-pmlogger-configuration-file-with-pmlogconf_logging-performance-data-with-pmlogger\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">6.1. Modifying the pmlogger configuration file with pmlogconf\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tWhen the \u003Ccode class=\"literal\">pmlogger\u003C/code> service is running, PCP logs a default set of metrics on the host.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tUse the \u003Ccode class=\"literal\">pmlogconf\u003C/code> utility to check the default configuration. If the \u003Ccode class=\"literal\">pmlogger\u003C/code> configuration file does not exist, \u003Ccode class=\"literal\">pmlogconf\u003C/code> creates it with a default metric values.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tPCP is installed. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#installing-and-enabling-pcp_setting-up-pcp\">Installing and enabling PCP\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate or modify the \u003Ccode class=\"literal\">pmlogger\u003C/code> configuration file:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># pmlogconf -r /var/lib/pcp/config/pmlogger/config.default\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tFollow \u003Ccode class=\"literal\">pmlogconf\u003C/code> prompts to enable or disable groups of related performance metrics and to control the logging interval for each enabled group.\n\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">pmlogconf(1)\u003C/code> and \u003Ccode class=\"literal\">pmlogger(1)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#system-services-distributed-with-pcp_setting-up-pcp\">System services and tools distributed with PCP\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"editing-the-pmlogger-configuration-file-manually_logging-performance-data-with-pmlogger\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">6.2. Editing the pmlogger configuration file manually\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tTo create a tailored logging configuration with specific metrics and given intervals, edit the \u003Ccode class=\"literal\">pmlogger\u003C/code> configuration file manually. The default \u003Ccode class=\"literal\">pmlogger\u003C/code> configuration file is \u003Ccode class=\"literal\">/var/lib/pcp/config/pmlogger/config.default\u003C/code>. The configuration file specifies which metrics are logged by the primary logging instance.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tIn manual configuration, you can:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tRecord metrics which are not listed in the automatic configuration.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tChoose custom logging frequencies.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tAdd \u003Cspan class=\"strong strong\">\u003Cstrong>PMDA\u003C/strong>\u003C/span> with the application metrics.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tPCP is installed. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#installing-and-enabling-pcp_setting-up-pcp\">Installing and enabling PCP\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOpen and edit the \u003Ccode class=\"literal\">/var/lib/pcp/config/pmlogger/config.default\u003C/code> file to add specific metrics:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># It is safe to make additions from here on ...\n#\n\nlog mandatory on every 5 seconds {\n    xfs.write\n    xfs.write_bytes\n    xfs.read\n    xfs.read_bytes\n}\n\nlog mandatory on every 10 seconds {\n    xfs.allocs\n    xfs.block_map\n    xfs.transactions\n    xfs.log\n\n}\n\n[access]\ndisallow * : all;\nallow localhost : enquire;\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">pmlogger(1)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#system-services-distributed-with-pcp_setting-up-pcp\">System services and tools distributed with PCP\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"enabling-the-pmlogger-service_logging-performance-data-with-pmlogger\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">6.3. Enabling the pmlogger service\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe \u003Ccode class=\"literal\">pmlogger\u003C/code> service must be started and enabled to log the metric values on the local machine.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThis procedure describes how to enable the \u003Ccode class=\"literal\">pmlogger\u003C/code> service.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tPCP is installed. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#installing-and-enabling-pcp_setting-up-pcp\">Installing and enabling PCP\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tStart and enable the \u003Ccode class=\"literal\">pmlogger\u003C/code> service:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># systemctl start pmlogger\n\n# systemctl enable pmlogger\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify if the \u003Ccode class=\"literal\">pmlogger\u003C/code> service is enabled:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># pcp\n\nPerformance Co-Pilot configuration on workstation:\n\nplatform: Linux workstation 4.18.0-80.el8.x86_64 #1 SMP Wed Mar 13 12:02:46 UTC 2019 x86_64\nhardware: 12 cpus, 2 disks, 1 node, 36023MB RAM\ntimezone: CEST-2\nservices: pmcd\npmcd: Version 4.3.0-1, 8 agents, 1 client\npmda: root pmcd proc xfs linux mmv kvm jbd2\npmlogger: primary logger: /var/log/pcp/pmlogger/workstation/20190827.15.54\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">pmlogger(1)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#system-services-distributed-with-pcp_setting-up-pcp\">System services and tools distributed with PCP\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/var/lib/pcp/config/pmlogger/config.default\u003C/code> file\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"setting-up-a-client-system-for-metrics-collection_logging-performance-data-with-pmlogger\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">6.4. Setting up a client system for metrics collection\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure describes how to set up a client system so that a central server can collect metrics from clients running PCP.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tPCP is installed. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#installing-and-enabling-pcp_setting-up-pcp\">Installing and enabling PCP\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInstall the \u003Ccode class=\"literal\">pcp-system-tools\u003C/code> package:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf install pcp-system-tools\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tConfigure an IP address for \u003Ccode class=\"literal\">pmcd\u003C/code>:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># echo \"-i \u003Cspan class=\"emphasis\">\u003Cem>192.168.4.62\u003C/em>\u003C/span>\" &gt;&gt;/etc/pcp/pmcd/pmcd.options\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>192.168.4.62\u003C/em>\u003C/span> with the IP address, the client should listen on.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tBy default, \u003Ccode class=\"literal\">pmcd\u003C/code> is listening on the localhost.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tConfigure the firewall to add the public \u003Ccode class=\"literal\">zone\u003C/code> permanently:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># firewall-cmd --permanent --zone=public --add-port=44321/tcp\nsuccess\n\n# firewall-cmd --reload\nsuccess\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tSet an SELinux boolean:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># setsebool -P pcp_bind_all_unreserved_ports on\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnable the \u003Ccode class=\"literal\">pmcd\u003C/code> and \u003Ccode class=\"literal\">pmlogger\u003C/code> services:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># systemctl enable pmcd pmlogger\n# systemctl restart pmcd pmlogger\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify if the \u003Ccode class=\"literal\">pmcd\u003C/code> is correctly listening on the configured IP address:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout white-space-pre\"># ss -tlp | grep 44321\nLISTEN   0   5     127.0.0.1:44321   0.0.0.0:*   users:((\"pmcd\",pid=151595,fd=6))\nLISTEN   0   5  \u003Cspan class=\"emphasis\">\u003Cem>192.168.4.62:44321\u003C/em>\u003C/span>   0.0.0.0:*   users:((\"pmcd\",pid=151595,fd=0))\nLISTEN   0   5         [::1]:44321      [::]:*   users:((\"pmcd\",pid=151595,fd=7))\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">pmlogger(1)\u003C/code>, \u003Ccode class=\"literal\">firewall-cmd(1)\u003C/code>, \u003Ccode class=\"literal\">ss(8)\u003C/code>, and \u003Ccode class=\"literal\">setsebool(8)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#system-services-distributed-with-pcp_setting-up-pcp\">System services and tools distributed with PCP\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/var/lib/pcp/config/pmlogger/config.default\u003C/code> file\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"setting-up-the-central-server-to-collect-data_logging-performance-data-with-pmlogger\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">6.5. Setting up a central server to collect data\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure describes how to create a central server to collect metrics from clients running PCP.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tPCP is installed. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#installing-and-enabling-pcp_setting-up-pcp\">Installing and enabling PCP\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClient is configured for metrics collection. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/logging-performance-data-with-pmlogger_monitoring-and-managing-system-status-and-performance#setting-up-a-client-system-for-metrics-collection_logging-performance-data-with-pmlogger\">Setting up a client system for metrics collection\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInstall the \u003Ccode class=\"literal\">pcp-system-tools\u003C/code> package:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf install pcp-system-tools\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate the \u003Ccode class=\"literal\">/etc/pcp/pmlogger/control.d/remote\u003C/code> file with the following content:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout white-space-pre\"># DO NOT REMOVE OR EDIT THE FOLLOWING LINE\n$version=1.1\n\n\u003Cspan class=\"emphasis\">\u003Cem>192.168.4.13\u003C/em>\u003C/span> n n PCP_ARCHIVE_DIR/rhel7u4a -r -T24h10m -c config.rhel7u4a\n\u003Cspan class=\"emphasis\">\u003Cem>192.168.4.14\u003C/em>\u003C/span> n n PCP_ARCHIVE_DIR/rhel6u10a -r -T24h10m -c config.rhel6u10a\n\u003Cspan class=\"emphasis\">\u003Cem>192.168.4.62\u003C/em>\u003C/span> n n PCP_ARCHIVE_DIR/rhel8u1a -r -T24h10m -c config.rhel8u1a\n\u003Cspan class=\"emphasis\">\u003Cem>192.168.4.69\u003C/em>\u003C/span> n n PCP_ARCHIVE_DIR/rhel9u3a -r -T24h10m -c config.rhel9u3a\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>192.168.4.13\u003C/em>\u003C/span>, \u003Cspan class=\"emphasis\">\u003Cem>192.168.4.14\u003C/em>\u003C/span>, \u003Cspan class=\"emphasis\">\u003Cem>192.168.4.62\u003C/em>\u003C/span> and \u003Cspan class=\"emphasis\">\u003Cem>192.168.4.69\u003C/em>\u003C/span> with the client IP addresses.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnable the \u003Ccode class=\"literal\">pmcd\u003C/code> and \u003Ccode class=\"literal\">pmlogger\u003C/code> services:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># systemctl enable pmcd pmlogger\n# systemctl restart pmcd pmlogger\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnsure that you can access the latest archive file from each directory:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># for i in /var/log/pcp/pmlogger/rhel*/*.0; do pmdumplog -L $i; done\nLog Label (Log Format Version 2)\nPerformance metrics from host rhel6u10a.local\n  commencing Mon Nov 25 21:55:04.851 2019\n  ending     Mon Nov 25 22:06:04.874 2019\nArchive timezone: JST-9\nPID for pmlogger: 24002\nLog Label (Log Format Version 2)\nPerformance metrics from host rhel7u4a\n  commencing Tue Nov 26 06:49:24.954 2019\n  ending     Tue Nov 26 07:06:24.979 2019\nArchive timezone: CET-1\nPID for pmlogger: 10941\n[..]\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe archive files from the \u003Ccode class=\"literal\">/var/log/pcp/pmlogger/\u003C/code> directory can be used for further analysis and graphing.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">pmlogger(1)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#system-services-distributed-with-pcp_setting-up-pcp\">System services and tools distributed with PCP\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/var/lib/pcp/config/pmlogger/config.default\u003C/code> file\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"systemd-units-and-pmlogger_logging-performance-data-with-pmlogger\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">6.6. \u003Ccode class=\"literal\">Systemd\u003C/code> units and \u003Ccode class=\"literal\">pmlogger\u003C/code>\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tWhen you deploy the \u003Ccode class=\"literal\">pmlogger\u003C/code> service, either as a single host monitoring itself or a \u003Ccode class=\"literal\">pmlogger\u003C/code> farm with a single host collecting metrics from several remote hosts, there are several associated \u003Ccode class=\"literal\">systemd\u003C/code> service and timer units that are automatically deployed. These services and timers provide routine checks to ensure that your \u003Ccode class=\"literal\">pmlogger\u003C/code> instances are running, restart any missing instances, and perform archive management such as file compression.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe checking and housekeeping services typically deployed by \u003Ccode class=\"literal\">pmlogger\u003C/code> are:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmlogger_daily.service\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tRuns daily, soon after midnight by default, to aggregate, compress, and rotate one or more sets of PCP archives. Also culls archives older than the limit, 2 weeks by default. Triggered by the \u003Ccode class=\"literal\">pmlogger_daily.timer\u003C/code> unit, which is required by the \u003Ccode class=\"literal\">pmlogger.service\u003C/code> unit.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmlogger_check\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tPerforms half-hourly checks that \u003Ccode class=\"literal\">pmlogger\u003C/code> instances are running. Restarts any missing instances and performs any required compression tasks. Triggered by the \u003Ccode class=\"literal\">pmlogger_check.timer\u003C/code> unit, which is required by the \u003Ccode class=\"literal\">pmlogger.service\u003C/code> unit.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pmlogger_farm_check\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tChecks the status of all configured \u003Ccode class=\"literal\">pmlogger\u003C/code> instances. Restarts any missing instances. Migrates all non–primary instances to the \u003Ccode class=\"literal\">pmlogger_farm\u003C/code> service. Triggered by the \u003Ccode class=\"literal\">pmlogger_farm_check.timer\u003C/code>, which is required by the \u003Ccode class=\"literal\">pmlogger_farm.service\u003C/code> unit that is itself required by the \u003Ccode class=\"literal\">pmlogger.service\u003C/code> unit.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cp>\n\t\t\t\tThese services are managed through a series of positive dependencies, meaning that they are all enabled upon activating the primary \u003Ccode class=\"literal\">pmlogger\u003C/code> instance. Note that while \u003Ccode class=\"literal\">pmlogger_daily.service\u003C/code> is disabled by default, \u003Ccode class=\"literal\">pmlogger_daily.timer\u003C/code> being active via the dependency with \u003Ccode class=\"literal\">pmlogger.service\u003C/code> will trigger \u003Ccode class=\"literal\">pmlogger_daily.service\u003C/code> to run.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\u003Ccode class=\"literal\">pmlogger_daily\u003C/code> is also integrated with \u003Ccode class=\"literal\">pmlogrewrite\u003C/code> for automatically rewriting archives before merging. This helps to ensure metadata consistency amid changing production environments and PMDAs. For example, if \u003Ccode class=\"literal\">pmcd\u003C/code> on one monitored host is updated during the logging interval, the semantics for some metrics on the host might be updated, thus making the new archives incompatible with the previously recorded archives from that host. For more information see the \u003Ca class=\"link\" href=\"https://man7.org/linux/man-pages/man1/pmlogrewrite.1.html\">\u003Ccode class=\"literal\">pmlogrewrite(1)\u003C/code>\u003C/a> man page.\n\t\t\t\u003C/p>\u003Cdiv class=\"formalpara\">\u003Cp class=\"title\">\u003Cstrong>Managing \u003Ccode class=\"literal\">systemd\u003C/code> services triggered by \u003Ccode class=\"literal\">pmlogger\u003C/code>\u003C/strong>\u003C/p>\u003Cp>\n\t\t\t\t\tYou can create an automated custom archive management system for data collected by your \u003Ccode class=\"literal\">pmlogger\u003C/code> instances. This is done using control files. These control files are:\n\t\t\t\t\u003C/p>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor the primary \u003Ccode class=\"literal\">pmlogger\u003C/code> instance:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">etc/pcp/pmlogger/control\u003C/code>\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">/etc/pcp/pmlogger/control.d/local\u003C/code>\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor the remote hosts:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">/etc/pcp/pmlogger/control.d/remote\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>remote\u003C/em>\u003C/span> with your desired file name.\n\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">NOTE\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\t\t\tThe primary \u003Ccode class=\"literal\">pmlogger\u003C/code> instance must be running on the same host as the \u003Ccode class=\"literal\">pmcd\u003C/code> it connects to. You do not need to have a primary instance and you might not need it in your configuration if one central host is collecting data on several \u003Ccode class=\"literal\">pmlogger\u003C/code> instances connected to \u003Ccode class=\"literal\">pmcd\u003C/code> instances running on remote host\n\t\t\t\t\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tThe file should contain one line for each host to be logged. The default format of the primary logger instance that is automatically created looks similar to:\n\t\t\t\u003C/p>\u003Cpre class=\"screen\"># === LOGGER CONTROL SPECIFICATIONS ===\n#\n#Host   \t P?  S?    directory   \t\t args\n\n# local primary logger\nLOCALHOSTNAME    y   n    PCP_ARCHIVE_DIR/LOCALHOSTNAME    -r -T24h10m -c config.default -v 100Mb\u003C/pre>\u003Cp>\n\t\t\t\tThe fields are:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Host\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe name of the host to be logged\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">P?\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tStands for “Primary?” This field indicates if the host is the primary logger instance, \u003Ccode class=\"literal\">y\u003C/code>, or not, \u003Ccode class=\"literal\">n\u003C/code>. There can only be one primary logger across all the files in your configuration and it must be running on the same host as the \u003Ccode class=\"literal\">pmcd\u003C/code> it connects to.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">S?\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tStands for “Socks?” This field indicates if this logger instance needs to use the \u003Ccode class=\"literal\">SOCKS\u003C/code> protocol to connect to \u003Ccode class=\"literal\">pmcd\u003C/code> through a firewall, \u003Ccode class=\"literal\">y\u003C/code>, or not, \u003Ccode class=\"literal\">n\u003C/code>.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">directory\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tAll archives associated with this line are created in this directory.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">args\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tArguments passed to \u003Ccode class=\"literal\">pmlogger\u003C/code>.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe default values for the \u003Ccode class=\"literal\">args\u003C/code> field are:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">-r\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\t\tReport the archive sizes and growth rate.\n\t\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">T24h10m\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\t\tSpecifies when to end logging for each day. This is typically the time when \u003Ccode class=\"literal\">pmlogger_daily.service\u003C/code> runs. The default value of \u003Ccode class=\"literal\">24h10m\u003C/code> indicates that logging should end 24 hours and 10 minutes after it begins, at the latest.\n\t\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">-c config.default\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\t\tSpecifies which configuration file to use. This essentially defines what metrics to record.\n\t\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">-v 100Mb\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\t\tSpecifies the size at which point one data volume is filled and another is created. After it switches to the new archive, the previously recorded one will be compressed by either \u003Ccode class=\"literal\">pmlogger_daily\u003C/code> or \u003Ccode class=\"literal\">pmlogger_check\u003C/code>.\n\t\t\t\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">pmlogger(1)\u003C/code> and \u003Ccode class=\"literal\">pmlogrewrite(1)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">pmlogger_daily(1)\u003C/code>, \u003Ccode class=\"literal\">pmlogger_check(1)\u003C/code>, and \u003Ccode class=\"literal\">pmlogger.control(5)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"replaying-the-pcp-log-archives_logging-performance-data-with-pmlogger\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">6.7. Replaying the PCP log archives with pmrep\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tAfter recording the metric data, you can replay the PCP log archives. To export the logs to text files and import them into spreadsheets, use PCP utilities such as \u003Ccode class=\"literal\">pcp2csv\u003C/code>, \u003Ccode class=\"literal\">pcp2xml\u003C/code>, \u003Ccode class=\"literal\">pmrep\u003C/code> or \u003Ccode class=\"literal\">pmlogsummary\u003C/code>.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tUsing the \u003Ccode class=\"literal\">pmrep\u003C/code> tool, you can:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tView the log files\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tParse the selected PCP log archive and export the values into an ASCII table\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tExtract the entire archive log or only select metric values from the log by specifying individual metrics on the command line\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tPCP is installed. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#installing-and-enabling-pcp_setting-up-pcp\">Installing and enabling PCP\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">pmlogger\u003C/code> service is enabled. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/logging-performance-data-with-pmlogger_monitoring-and-managing-system-status-and-performance#enabling-the-pmlogger-service_logging-performance-data-with-pmlogger\">Enabling the pmlogger service\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInstall the \u003Ccode class=\"literal\">pcp-gui\u003C/code> package:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf install pcp-gui\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tDisplay the data on the metric:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ pmrep --start @3:00am --archive 20211128 --interval 5seconds --samples 10 --output csv disk.dev.write\nTime,\"disk.dev.write-sda\",\"disk.dev.write-sdb\"\n2021-11-28 03:00:00,,\n2021-11-28 03:00:05,4.000,5.200\n2021-11-28 03:00:10,1.600,7.600\n2021-11-28 03:00:15,0.800,7.100\n2021-11-28 03:00:20,16.600,8.400\n2021-11-28 03:00:25,21.400,7.200\n2021-11-28 03:00:30,21.200,6.800\n2021-11-28 03:00:35,21.000,27.600\n2021-11-28 03:00:40,12.400,33.800\n2021-11-28 03:00:45,9.800,20.600\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe mentioned example displays the data on the \u003Ccode class=\"literal\">disk.dev.write\u003C/code> metric collected in an archive at a \u003Cspan class=\"emphasis\">\u003Cem>5 second\u003C/em>\u003C/span> interval in comma-separated-value format.\n\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\tReplace \u003Ccode class=\"literal\">20211128\u003C/code> in this example with a filename containing the \u003Ccode class=\"literal\">pmlogger\u003C/code> archive you want to display data for.\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">pmlogger(1)\u003C/code>, \u003Ccode class=\"literal\">pmrep(1)\u003C/code>, and \u003Ccode class=\"literal\">pmlogsummary(1)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#system-services-distributed-with-pcp_setting-up-pcp\">System services and tools distributed with PCP\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"enabling-pcp-version-3-archives_logging-performance-data-with-pmlogger\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">6.8. Enabling PCP version 3 archives\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tPerformance Co-Pilot (PCP) archives store historical values of PCP metrics recorded from a single host and support retrospective performance analysis. PCP archives contain all the important metric data and metadata needed for offline or offsite analysis. These archives can be read by most PCP client tools or dumped raw by the \u003Ccode class=\"literal\">pmdumplog\u003C/code> tool.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tFrom PCP 6.0, version 3 archives are supported in addition to version 2 archives. Version 2 archives remain the default and will continue to receive long-term support for backwards compatibility purposes in addition to version 3 archives receiving long-term support from RHEL 9.2 and on.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tUsing PCP version 3 archives offers the following benefits over version 2:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tSupport for instance domain change-deltas\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tY2038-safe timestamps\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tNanosecond-precision timestamps\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tArbitrary timezones support\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t64-bit file offsets used for individual volumes larger than 2GB\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tPCP is installed. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#installing-and-enabling-pcp_setting-up-pcp\">Installing and enabling PCP\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOpen the \u003Ccode class=\"literal\">/etc/pcp.conf\u003C/code> file in a text editor of your choice and set the PCP archive version:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">PCP_ARCHIVE_VERSION=3\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRestart the \u003Ccode class=\"literal\">pmlogger\u003C/code> service to apply your configuration changes:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># systemctl restart pmlogger.service\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tCreate a new PCP archive log using your new configuration. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/logging-performance-data-with-pmlogger_monitoring-and-managing-system-status-and-performance\">Logging performance data with pmlogger\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify the version of the archive created with your new configuration:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># pmloglabel -l /var/log/pcp/pmlogger/\u003Cspan class=\"emphasis\">\u003Cem>20230208\u003C/em>\u003C/span>\nLog Label (Log Format Version 3)\nPerformance metrics from host \u003Cspan class=\"emphasis\">\u003Cem>host1\u003C/em>\u003C/span>\n        commencing Wed Feb   08 00:11:09.396 2023\n        ending           Thu  Feb   07 00:13:54.347 2023\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">logarchive(5)\u003C/code> and \u003Ccode class=\"literal\">pmlogger(1)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/logging-performance-data-with-pmlogger_monitoring-and-managing-system-status-and-performance\">Logging performance data with pmlogger\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"monitoring-performance-with-performance-co-pilot_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 7. Monitoring performance with Performance Co-Pilot\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tPerformance Co-Pilot (PCP) is a suite of tools, services, and libraries for monitoring, visualizing, storing, and analyzing system-level performance measurements.\n\t\t\u003C/p>\u003Cp>\n\t\t\tAs a system administrator, you can monitor the system’s performance using the PCP application in Red Hat Enterprise Linux 9.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"monitoring-postfix-with-pmda-postfix_monitoring-performance-with-performance-co-pilot\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">7.1. Monitoring postfix with pmda-postfix\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure describes how to monitor performance metrics of the \u003Ccode class=\"literal\">postfix\u003C/code> mail server with \u003Ccode class=\"literal\">pmda-postfix\u003C/code>. It helps to check how many emails are received per second.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tPCP is installed. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#installing-and-enabling-pcp_setting-up-pcp\">Installing and enabling PCP\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">pmlogger\u003C/code> service is enabled. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/logging-performance-data-with-pmlogger_monitoring-and-managing-system-status-and-performance#enabling-the-pmlogger-service_logging-performance-data-with-pmlogger\">Enabling the pmlogger service\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInstall the following packages:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tInstall the \u003Ccode class=\"literal\">pcp-system-tools\u003C/code>:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf install pcp-system-tools\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tInstall the \u003Ccode class=\"literal\">pmda-postfix\u003C/code> package to monitor \u003Ccode class=\"literal\">postfix\u003C/code>:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf install pcp-pmda-postfix postfix\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tInstall the logging daemon:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf install rsyslog\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tInstall the mail client for testing:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf install mutt\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnable the \u003Ccode class=\"literal\">postfix\u003C/code> and \u003Ccode class=\"literal\">rsyslog\u003C/code> services:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># systemctl enable postfix rsyslog\n# systemctl restart postfix rsyslog\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnable the SELinux boolean, so that \u003Ccode class=\"literal\">pmda-postfix\u003C/code> can access the required log files:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># setsebool -P pcp_read_generic_logs=on\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInstall the \u003Ccode class=\"literal\">PMDA\u003C/code>:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># cd /var/lib/pcp/pmdas/postfix/\n\n# ./Install\n\nUpdating the Performance Metrics Name Space (PMNS) ...\nTerminate PMDA if already installed ...\nUpdating the PMCD control file, and notifying PMCD ...\nWaiting for pmcd to terminate ...\nStarting pmcd ...\nCheck postfix metrics have appeared ... 7 metrics and 58 values\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify the \u003Ccode class=\"literal\">pmda-postfix\u003C/code> operation:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">echo testmail | mutt root\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify the available metrics:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># pminfo postfix\n\npostfix.received\npostfix.sent\npostfix.queues.incoming\npostfix.queues.maildrop\npostfix.queues.hold\npostfix.queues.deferred\npostfix.queues.active\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">rsyslogd(8)\u003C/code>, \u003Ccode class=\"literal\">postfix(1)\u003C/code>, and \u003Ccode class=\"literal\">setsebool(8)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#system-services-distributed-with-pcp_setting-up-pcp\">System services and tools distributed with PCP\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"visually-tracing-pcp-log-archives-with-pcp-charts_monitoring-performance-with-performance-co-pilot\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">7.2. Visually tracing PCP log archives with the PCP Charts application\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tAfter recording metric data, you can replay the PCP log archives as graphs. The metrics are sourced from one or more live hosts with alternative options to use metric data from PCP log archives as a source of historical data. To customize the \u003Cspan class=\"strong strong\">\u003Cstrong>PCP Charts\u003C/strong>\u003C/span> application interface to display the data from the performance metrics, you can use line plot, bar graphs, or utilization graphs.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tUsing the \u003Cspan class=\"strong strong\">\u003Cstrong>PCP Charts\u003C/strong>\u003C/span> application, you can:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tReplay the data in the \u003Cspan class=\"strong strong\">\u003Cstrong>PCP Charts\u003C/strong>\u003C/span> application application and use graphs to visualize the retrospective data alongside live data of the system.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tPlot performance metric values into graphs.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tDisplay multiple charts simultaneously.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tPCP is installed. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#installing-and-enabling-pcp_setting-up-pcp\">Installing and enabling PCP\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tLogged performance data with the \u003Ccode class=\"literal\">pmlogger\u003C/code>. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/logging-performance-data-with-pmlogger_monitoring-and-managing-system-status-and-performance\">Logging performance data with pmlogger\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInstall the \u003Ccode class=\"literal\">pcp-gui\u003C/code> package:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf install pcp-gui\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tLaunch the \u003Cspan class=\"strong strong\">\u003Cstrong>PCP Charts\u003C/strong>\u003C/span> application from the command line:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># pmchart\u003C/pre>\u003Cdiv class=\"figure\" id=\"idm140280153202064\">\u003Cp class=\"title\">\u003Cstrong>Figure 7.1. PCP Charts application\u003C/strong>\u003C/p>\u003Cdiv class=\"figure-contents\">\u003Cdiv class=\"mediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/804544b6996d4a37ca90b153dab642ea/pmchart_started.png\" alt=\"pmchart started\"/>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">pmtime\u003C/code> server settings are located at the bottom. The \u003Cspan class=\"strong strong\">\u003Cstrong>start\u003C/strong>\u003C/span> and \u003Cspan class=\"strong strong\">\u003Cstrong>pause\u003C/strong>\u003C/span> button allows you to control:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe interval in which PCP polls the metric data\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe date and time for the metrics of historical data\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick \u003Cspan class=\"strong strong\">\u003Cstrong>File\u003C/strong>\u003C/span> and then \u003Cspan class=\"strong strong\">\u003Cstrong>New Chart\u003C/strong>\u003C/span> to select metric from both the local machine and remote machines by specifying their host name or address. Advanced configuration options include the ability to manually set the axis values for the chart, and to manually choose the color of the plots.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRecord the views created in the \u003Cspan class=\"strong strong\">\u003Cstrong>PCP Charts\u003C/strong>\u003C/span> application:\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFollowing are the options to take images or record the views created in the \u003Cspan class=\"strong strong\">\u003Cstrong>PCP Charts\u003C/strong>\u003C/span> application:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tClick \u003Cspan class=\"strong strong\">\u003Cstrong>File\u003C/strong>\u003C/span> and then \u003Cspan class=\"strong strong\">\u003Cstrong>Export\u003C/strong>\u003C/span> to save an image of the current view.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tClick \u003Cspan class=\"strong strong\">\u003Cstrong>Record\u003C/strong>\u003C/span> and then \u003Cspan class=\"strong strong\">\u003Cstrong>Start\u003C/strong>\u003C/span> to start a recording. Click \u003Cspan class=\"strong strong\">\u003Cstrong>Record\u003C/strong>\u003C/span> and then \u003Cspan class=\"strong strong\">\u003Cstrong>Stop\u003C/strong>\u003C/span> to stop the recording. After stopping the recording, the recorded metrics are archived to be viewed later.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOptional: In the \u003Cspan class=\"strong strong\">\u003Cstrong>PCP Charts\u003C/strong>\u003C/span> application, the main configuration file, known as the \u003Cspan class=\"strong strong\">\u003Cstrong>view\u003C/strong>\u003C/span>, allows the metadata associated with one or more charts to be saved. This metadata describes all chart aspects, including the metrics used and the chart columns. Save the custom \u003Cspan class=\"strong strong\">\u003Cstrong>view\u003C/strong>\u003C/span> configuration by clicking \u003Cspan class=\"strong strong\">\u003Cstrong>File\u003C/strong>\u003C/span> and then \u003Cspan class=\"strong strong\">\u003Cstrong>Save View\u003C/strong>\u003C/span>, and load the \u003Cspan class=\"strong strong\">\u003Cstrong>view\u003C/strong>\u003C/span> configuration later.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe following example of the \u003Cspan class=\"strong strong\">\u003Cstrong>PCP Charts\u003C/strong>\u003C/span> application view configuration file describes a stacking chart graph showing the total number of bytes read and written to the given XFS file system \u003Ccode class=\"literal\">loop1\u003C/code>:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">#kmchart\nversion 1\n\nchart title \"Filesystem Throughput /loop1\" style stacking antialiasing off\n    plot legend \"Read rate\"   metric xfs.read_bytes   instance  \"loop1\"\n    plot legend \"Write rate\"  metric xfs.write_bytes  instance  \"loop1\"\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">pmchart(1)\u003C/code> and \u003Ccode class=\"literal\">pmtime(1)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#system-services-distributed-with-pcp_setting-up-pcp\">System services and tools distributed with PCP\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"collecting-data-from-sql-server-using-pcp_monitoring-performance-with-performance-co-pilot\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">7.3. Collecting data from SQL server using PCP\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe SQL Server agent is available in Performance Co-Pilot (PCP), which helps you to monitor and analyze database performance issues.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThis procedure describes how to collect data for Microsoft SQL Server via \u003Ccode class=\"literal\">pcp\u003C/code> on your system.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have installed Microsoft SQL Server for Red Hat Enterprise Linux and established a 'trusted' connection to an SQL server.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have installed the Microsoft ODBC driver for SQL Server for Red Hat Enterprise Linux.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInstall PCP:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf install pcp-zeroconf\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInstall packages required for the \u003Ccode class=\"literal\">pyodbc\u003C/code> driver:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf install python3-pyodbc\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInstall the \u003Ccode class=\"literal\">mssql\u003C/code> agent:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tInstall the Microsoft SQL Server domain agent for PCP:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf install pcp-pmda-mssql\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tEdit the \u003Ccode class=\"literal\">/etc/pcp/mssql/mssql.conf\u003C/code> file to configure the SQL server account’s username and password for the \u003Ccode class=\"literal\">mssql\u003C/code> agent. Ensure that the account you configure has access rights to performance data.\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">username: \u003Cspan class=\"emphasis\">\u003Cem>user_name\u003C/em>\u003C/span>\npassword: \u003Cspan class=\"emphasis\">\u003Cem>user_password\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>user_name\u003C/em>\u003C/span> with the SQL Server account and \u003Cspan class=\"emphasis\">\u003Cem>user_password\u003C/em>\u003C/span> with the SQL Server user password for this account.\n\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInstall the agent:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># cd /var/lib/pcp/pmdas/mssql\n# ./Install\nUpdating the Performance Metrics Name Space (PMNS) ...\nTerminate PMDA if already installed ...\nUpdating the PMCD control file, and notifying PMCD ...\nCheck mssql metrics have appeared ... 168 metrics and 598 values\n[...]\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tUsing the \u003Ccode class=\"literal\">pcp\u003C/code> command, verify if the SQL Server PMDA (\u003Ccode class=\"literal\">mssql\u003C/code>) is loaded and running:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ pcp\nPerformance Co-Pilot configuration on rhel.local:\n\nplatform: Linux rhel.local 4.18.0-167.el8.x86_64 #1 SMP Sun Dec 15 01:24:23 UTC 2019 x86_64\n hardware: 2 cpus, 1 disk, 1 node, 2770MB RAM\n timezone: PDT+7\n services: pmcd pmproxy\n     pmcd: Version 5.0.2-1, 12 agents, 4 clients\n     pmda: root pmcd proc pmproxy xfs linux nfsclient mmv kvm mssql\n           jbd2 dm\n pmlogger: primary logger: /var/log/pcp/pmlogger/rhel.local/20200326.16.31\n     pmie: primary engine: /var/log/pcp/pmie/rhel.local/pmie.log\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tView the complete list of metrics that PCP can collect from the SQL Server:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># pminfo mssql\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAfter viewing the list of metrics, you can report the rate of transactions. For example, to report on the overall transaction count per second, over a five second time window:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># pmval -t 1 -T 5 mssql.databases.transactions\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tView the graphical chart of these metrics on your system by using the \u003Ccode class=\"literal\">pmchart\u003C/code> command. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/monitoring-performance-with-performance-co-pilot_monitoring-and-managing-system-status-and-performance#visually-tracing-pcp-log-archives-with-pcp-charts_monitoring-performance-with-performance-co-pilot\">Visually tracing PCP log archives with the PCP Charts application\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">pcp(1)\u003C/code>, \u003Ccode class=\"literal\">pminfo(1)\u003C/code>, \u003Ccode class=\"literal\">pmval(1)\u003C/code>, \u003Ccode class=\"literal\">pmchart(1)\u003C/code>, and \u003Ccode class=\"literal\">pmdamssql(1)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://www.redhat.com/en/blog/performance-co-pilot-microsoft-sql-server-rhel-82\">Performance Co-Pilot for Microsoft SQL Server with RHEL 8.2 Red Hat Developers Blog post\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"proc_generating-pcp-archives-from-sadc-archives_monitoring-performance-with-performance-co-pilot\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">7.4. Generating PCP archives from sadc archives\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can use the \u003Ccode class=\"literal\">sadf\u003C/code> tool provided by the \u003Ccode class=\"literal\">sysstat\u003C/code> package to generate PCP archives from native \u003Ccode class=\"literal\">sadc\u003C/code> archives.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tA \u003Ccode class=\"literal\">sadc\u003C/code> archive has been created:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># /usr/lib64/sa/sadc 1 5 -\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn this example, \u003Ccode class=\"literal\">sadc\u003C/code> is sampling system data 1 time in a 5 second interval. The outfile is specified as \u003Ccode class=\"literal\">-\u003C/code> which results in \u003Ccode class=\"literal\">sadc\u003C/code> writing the data to the standard system activity daily data file. This file is named saDD and is located in the /var/log/sa directory by default.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tGenerate a PCP archive from a \u003Ccode class=\"literal\">sadc\u003C/code> archive:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># sadf -l -O pcparchive=/tmp/recording -2\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn this example, using the \u003Ccode class=\"literal\">-2\u003C/code> option results in \u003Ccode class=\"literal\">sadf\u003C/code> generating a PCP archive from a \u003Ccode class=\"literal\">sadc\u003C/code> archive recorded 2 days ago.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"formalpara\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cp>\n\t\t\t\t\tYou can use PCP commands to inspect and analyze the PCP archive generated from a \u003Ccode class=\"literal\">sadc\u003C/code> archive as you would a native PCP archive. For example:\n\t\t\t\t\u003C/p>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo show a list of metrics in the PCP archive generated from an \u003Ccode class=\"literal\">sadc\u003C/code> archive archive, run:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ pminfo --archive /tmp/recording\nDisk.dev.avactive\nDisk.dev.read\nDisk.dev.write\nDisk.dev.blkread\n[...]\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo show the timespace of the archive and hostname of the PCP archive, run:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ pmdumplog --label /tmp/recording\nLog Label (Log Format Version 2)\nPerformance metrics from host shard\n        commencing Tue Jul 20 00:10:30.642477 2021\n        ending     Wed Jul 21 00:10:30.222176 2021\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo plot performance metrics values into graphs, run:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ pmchart --archive /tmp/recording\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"performance-analysis-of-xfs-with-pcp_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 8. Performance analysis of XFS with PCP\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tThe XFS PMDA ships as part of the \u003Ccode class=\"literal\">pcp\u003C/code> package and is enabled by default during the installation. It is used to gather performance metric data of XFS file systems in Performance Co-Pilot (PCP).\n\t\t\u003C/p>\u003Cp>\n\t\t\tYou can use PCP to analyze XFS file system’s performance.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"installing-xfs-pmda-manually_performance-analysis-of-xfs-with-pcp\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">8.1. Installing XFS PMDA manually\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tIf the XFS PMDA is not listed in the \u003Ccode class=\"literal\">pcp\u003C/code> configuration output, install the PMDA agent manually.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThis procedure describes how to manually install the PMDA agent.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tPCP is installed. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#installing-and-enabling-pcp_setting-up-pcp\">Installing and enabling PCP\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tNavigate to the xfs directory:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># cd /var/lib/pcp/pmdas/xfs/\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInstall the XFS PMDA manually:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">xfs]# ./Install\nUpdating the Performance Metrics Name Space (PMNS) ...\nTerminate PMDA if already installed ...\nUpdating the PMCD control file, and notifying PMCD ...\nCheck xfs metrics have appeared ... 387 metrics and 387 values\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify that the \u003Ccode class=\"literal\">pmcd\u003C/code> process is running on the host and the XFS PMDA is listed as enabled in the configuration:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># pcp\n\nPerformance Co-Pilot configuration on workstation:\n\nplatform: Linux workstation 4.18.0-80.el8.x86_64 #1 SMP Wed Mar 13 12:02:46 UTC 2019 x86_64\nhardware: 12 cpus, 2 disks, 1 node, 36023MB RAM\ntimezone: CEST-2\nservices: pmcd\npmcd: Version 4.3.0-1, 8 agents\npmda: root pmcd proc xfs linux mmv kvm jbd2\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">pmcd(1)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#system-services-distributed-with-pcp_setting-up-pcp\">System services and tools distributed with PCP\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"examining-xfs-performance-metrics-with-pminfo_performance-analysis-of-xfs-with-pcp\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">8.2. Examining XFS performance metrics with pminfo\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tPCP enables XFS PMDA to allow the reporting of certain XFS metrics per each of the mounted XFS file systems. This makes it easier to pinpoint specific mounted file system issues and evaluate performance.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe \u003Ccode class=\"literal\">pminfo\u003C/code> command provides per-device XFS metrics for each mounted XFS file system.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThis procedure displays a list of all available metrics provided by the XFS PMDA.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tPCP is installed. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#installing-and-enabling-pcp_setting-up-pcp\">Installing and enabling PCP\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tDisplay the list of all available metrics provided by the XFS PMDA:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># pminfo xfs\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tDisplay information for the individual metrics. The following examples examine specific XFS \u003Ccode class=\"literal\">read\u003C/code> and \u003Ccode class=\"literal\">write\u003C/code> metrics using the \u003Ccode class=\"literal\">pminfo\u003C/code> tool:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tDisplay a short description of the \u003Ccode class=\"literal\">xfs.write_bytes\u003C/code> metric:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># pminfo --oneline xfs.write_bytes\n\nxfs.write_bytes [number of bytes written in XFS file system write operations]\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tDisplay a long description of the \u003Ccode class=\"literal\">xfs.read_bytes\u003C/code> metric:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># pminfo --helptext xfs.read_bytes\n\nxfs.read_bytes\nHelp:\nThis is the number of bytes read via read(2) system calls to files in\nXFS file systems. It can be used in conjunction with the read_calls\ncount to calculate the average size of the read operations to file in\nXFS file systems.\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tObtain the current performance value of the \u003Ccode class=\"literal\">xfs.read_bytes\u003C/code> metric:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># pminfo --fetch xfs.read_bytes\n\nxfs.read_bytes\n    value 4891346238\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tObtain per-device XFS metrics with \u003Ccode class=\"literal\">pminfo\u003C/code>:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># pminfo --fetch --oneline xfs.perdev.read xfs.perdev.write\n\nxfs.perdev.read [number of XFS file system read operations]\ninst [0 or \"loop1\"] value 0\ninst [0 or \"loop2\"] value 0\n\nxfs.perdev.write [number of XFS file system write operations]\ninst [0 or \"loop1\"] value 86\ninst [0 or \"loop2\"] value 0\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">pminfo(1)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/performance-analysis-of-xfs-with-pcp_monitoring-and-managing-system-status-and-performance#pcp-metric-groups-for-xfs_performance-analysis-of-xfs-with-pcp\">PCP metric groups for XFS\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/performance-analysis-of-xfs-with-pcp_monitoring-and-managing-system-status-and-performance#per-device-pcp-metric-groups-for-xfs_performance-analysis-of-xfs-with-pcp\">Per-device PCP metric groups for XFS\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"resetting-xfs-performance-metrics-with-pmstore_performance-analysis-of-xfs-with-pcp\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">8.3. Resetting XFS performance metrics with pmstore\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tWith PCP, you can modify the values of certain metrics, especially if the metric acts as a control variable, such as the \u003Ccode class=\"literal\">xfs.control.reset\u003C/code> metric. To modify a metric value, use the \u003Ccode class=\"literal\">pmstore\u003C/code> tool.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThis procedure describes how to reset XFS metrics using the \u003Ccode class=\"literal\">pmstore\u003C/code> tool.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tPCP is installed. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#installing-and-enabling-pcp_setting-up-pcp\">Installing and enabling PCP\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tDisplay the value of a metric:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ pminfo -f xfs.write\n\nxfs.write\n    value 325262\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tReset all the XFS metrics:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># pmstore xfs.control.reset 1\n\nxfs.control.reset old value=0 new value=1\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tView the information after resetting the metric:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ pminfo --fetch xfs.write\n\nxfs.write\n    value 0\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">pmstore(1)\u003C/code> and \u003Ccode class=\"literal\">pminfo(1)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#system-services-distributed-with-pcp_setting-up-pcp\">System services and tools distributed with PCP\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/performance-analysis-of-xfs-with-pcp_monitoring-and-managing-system-status-and-performance#pcp-metric-groups-for-xfs_performance-analysis-of-xfs-with-pcp\">PCP metric groups for XFS\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"pcp-metric-groups-for-xfs_performance-analysis-of-xfs-with-pcp\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">8.4. PCP metric groups for XFS\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe following table describes the available PCP metric groups for XFS.\n\t\t\t\u003C/p>\u003Crh-table id=\"idm140280144977840\">\u003Ctable class=\"lt-4-cols lt-7-rows\">\u003Ccaption>Table 8.1. Metric groups for XFS\u003C/caption>\u003Ccolgroup>\u003Ccol style=\"width: 50%; \" class=\"col_1\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 50%; \" class=\"col_2\">\u003C!--Empty-->\u003C/col>\u003C/colgroup>\u003Ctbody>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\tMetric Group\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\tMetrics provided\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs.*\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\tGeneral XFS metrics including the read and write operation counts, read and write byte counts. Along with counters for the number of times inodes are flushed, clustered and number of failure to cluster.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs.allocs.*\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs.alloc_btree.*\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\tRange of metrics regarding the allocation of objects in the file system, these include number of extent and block creations/frees. Allocation tree lookup and compares along with extend record creation and deletion from the btree.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs.block_map.*\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs.bmap_btree.*\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\tMetrics include the number of block map read/write and block deletions, extent list operations for insertion, deletions and lookups. Also operations counters for compares, lookups, insertions and deletion operations from the blockmap.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs.dir_ops.*\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\tCounters for directory operations on XFS file systems for creation, entry deletions, count of “getdent” operations.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs.transactions.*\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\tCounters for the number of meta-data transactions, these include the count for the number of synchronous and asynchronous transactions along with the number of empty transactions.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs.inode_ops.*\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\tCounters for the number of times that the operating system looked for an XFS inode in the inode cache with different outcomes. These count cache hits, cache misses, and so on.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs.log.*\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs.log_tail.*\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\tCounters for the number of log buffer writes over XFS file sytems includes the number of blocks written to disk. Metrics also for the number of log flushes and pinning.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs.xstrat.*\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\tCounts for the number of bytes of file data flushed out by the XFS flush deamon along with counters for number of buffers flushed to contiguous and non-contiguous space on disk.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs.attr.*\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\tCounts for the number of attribute get, set, remove and list operations over all XFS file systems.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs.quota.*\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\tMetrics for quota operation over XFS file systems, these include counters for number of quota reclaims, quota cache misses, cache hits and quota data reclaims.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs.buffer.*\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\tRange of metrics regarding XFS buffer objects. Counters include the number of requested buffer calls, successful buffer locks, waited buffer locks, miss_locks, miss_retries and buffer hits when looking up pages.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs.btree.*\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\tMetrics regarding the operations of the XFS btree.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs.control.reset\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\tConfiguration metrics which are used to reset the metric counters for the XFS stats. Control metrics are toggled by means of the pmstore tool.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\u003C/rh-table>\u003C/section>\u003Csection class=\"section\" id=\"per-device-pcp-metric-groups-for-xfs_performance-analysis-of-xfs-with-pcp\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">8.5. Per-device PCP metric groups for XFS\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe following table describes the available per-device PCP metric group for XFS.\n\t\t\t\u003C/p>\u003Crh-table id=\"idm140280140070240\">\u003Ctable class=\"lt-4-cols lt-7-rows\">\u003Ccaption>Table 8.2. Per-device PCP metric groups for XFS\u003C/caption>\u003Ccolgroup>\u003Ccol style=\"width: 50%; \" class=\"col_1\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 50%; \" class=\"col_2\">\u003C!--Empty-->\u003C/col>\u003C/colgroup>\u003Ctbody>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\tMetric Group\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\tMetrics provided\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs.perdev.*\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\tGeneral XFS metrics including the read and write operation counts, read and write byte counts. Along with counters for the number of times inodes are flushed, clustered and number of failure to cluster.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs.perdev.allocs.*\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs.perdev.alloc_btree.*\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\tRange of metrics regarding the allocation of objects in the file system, these include number of extent and block creations/frees. Allocation tree lookup and compares along with extend record creation and deletion from the btree.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs.perdev.block_map.*\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs.perdev.bmap_btree.*\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\tMetrics include the number of block map read/write and block deletions, extent list operations for insertion, deletions and lookups. Also operations counters for compares, lookups, insertions and deletion operations from the blockmap.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs.perdev.dir_ops.*\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\tCounters for directory operations of XFS file systems for creation, entry deletions, count of “getdent” operations.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs.perdev.transactions.*\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\tCounters for the number of meta-data transactions, these include the count for the number of synchronous and asynchronous transactions along with the number of empty transactions.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs.perdev.inode_ops.*\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\tCounters for the number of times that the operating system looked for an XFS inode in the inode cache with different outcomes. These count cache hits, cache misses, and so on.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs.perdev.log.*\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs.perdev.log_tail.*\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\tCounters for the number of log buffer writes over XFS filesytems includes the number of blocks written to disk. Metrics also for the number of log flushes and pinning.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs.perdev.xstrat.*\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\tCounts for the number of bytes of file data flushed out by the XFS flush deamon along with counters for number of buffers flushed to contiguous and non-contiguous space on disk.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs.perdev.attr.*\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\tCounts for the number of attribute get, set, remove and list operations over all XFS file systems.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs.perdev.quota.*\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\tMetrics for quota operation over XFS file systems, these include counters for number of quota reclaims, quota cache misses, cache hits and quota data reclaims.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs.perdev.buffer.*\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\tRange of metrics regarding XFS buffer objects. Counters include the number of requested buffer calls, successful buffer locks, waited buffer locks, miss_locks, miss_retries and buffer hits when looking up pages.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">xfs.perdev.btree.*\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\tMetrics regarding the operations of the XFS btree.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\u003C/rh-table>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 9. Setting up graphical representation of PCP metrics\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tUsing a combination of \u003Ccode class=\"literal\">pcp\u003C/code>, \u003Ccode class=\"literal\">grafana\u003C/code>, \u003Ccode class=\"literal\">pcp redis\u003C/code>, \u003Ccode class=\"literal\">pcp bpftrace\u003C/code>, and \u003Ccode class=\"literal\">pcp vector\u003C/code> provides graphical representation of the live data or data collected by Performance Co-Pilot (PCP).\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"setting-up-pcp-with-pcp-zeroconf_setting-up-graphical-representation-of-pcp-metrics\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">9.1. Setting up PCP with pcp-zeroconf\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure describes how to set up PCP on a system with the \u003Ccode class=\"literal\">pcp-zeroconf\u003C/code> package. Once the \u003Ccode class=\"literal\">pcp-zeroconf\u003C/code> package is installed, the system records the default set of metrics into archived files.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInstall the \u003Ccode class=\"literal\">pcp-zeroconf\u003C/code> package:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf install pcp-zeroconf\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnsure that the \u003Ccode class=\"literal\">pmlogger\u003C/code> service is active, and starts archiving the metrics:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout white-space-pre\"># pcp | grep pmlogger\n pmlogger: primary logger: /var/log/pcp/pmlogger/\u003Cspan class=\"emphasis\">\u003Cem>localhost.localdomain/20200401.00.12\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">pmlogger\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index#monitoring-performance-with-performance-co-pilot_monitoring-and-managing-system-status-and-performance\">Monitoring performance with Performance Co-Pilot\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"setting-up-a-grafana-server_setting-up-graphical-representation-of-pcp-metrics\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">9.2. Setting up a Grafana server\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tGrafana generates graphs that are accessible from a browser. The Grafana server is a back-end server for the Grafana dashboard. It listens, by default, on all interfaces, and provides web services accessed through the web browser. The \u003Ccode class=\"literal\">grafana-pcp\u003C/code> plugin interacts with the \u003Ccode class=\"literal\">pmproxy\u003C/code> daemon in the backend.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThis procedure describes how to set up a Grafana server.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tPCP is configured. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance#setting-up-pcp-with-pcp-zeroconf_setting-up-graphical-representation-of-pcp-metrics\">Setting up PCP with pcp-zeroconf\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInstall the following packages:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf install grafana grafana-pcp\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRestart and enable the following service:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># systemctl restart grafana-server\n# systemctl enable grafana-server\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOpen the server’s firewall for network traffic to the Grafana service.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># firewall-cmd --permanent --add-service=grafana\nsuccess\n\n# firewall-cmd --reload\nsuccess\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnsure that the Grafana server is listening and responding to requests:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># ss -ntlp | grep 3000\nLISTEN  0  128  *:3000  *:*  users:((\"grafana-server\",pid=19522,fd=7))\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnsure that the \u003Ccode class=\"literal\">grafana-pcp\u003C/code> plugin is installed:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># grafana-cli plugins ls | grep performancecopilot-pcp-app\n\nperformancecopilot-pcp-app @ 5.1.1\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">pmproxy(1)\u003C/code> and \u003Ccode class=\"literal\">grafana-server(1)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"accessing-the-grafana-web-ui_setting-up-graphical-representation-of-pcp-metrics\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">9.3. Accessing the Grafana web UI\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure describes how to access the Grafana web interface.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tUsing the Grafana web interface, you can:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tAdd PCP Redis, PCP bpftrace, and PCP Vector data sources\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tCreate dashboard\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tView an overview of any useful metrics\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tCreate alerts in PCP Redis.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tPCP is configured. For more information, see \u003Ca class=\"link\" href=\"#setting-up-pcp-with-pcp-zeroconf_setting-up-graphical-representation-of-pcp-metrics\" title=\"9.1. Setting up PCP with pcp-zeroconf\">Setting up PCP with pcp-zeroconf\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe Grafana server is configured. For more information, see \u003Ca class=\"link\" href=\"#setting-up-a-grafana-server_setting-up-graphical-representation-of-pcp-metrics\" title=\"9.2. Setting up a Grafana server\">Setting up a Grafana server\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tOn the client system, open \u003Ccode class=\"literal\">http://\u003Cspan class=\"emphasis\">\u003Cem>&lt;grafana_server_IP_address_or_hostname&gt;\u003C/em>\u003C/span>:3000\u003C/code> in your browser.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor the first login, enter \u003Cspan class=\"strong strong\">\u003Cstrong>admin\u003C/strong>\u003C/span> in both the \u003Cspan class=\"strong strong\">\u003Cstrong>Email or username\u003C/strong>\u003C/span> and \u003Cspan class=\"strong strong\">\u003Cstrong>Password\u003C/strong>\u003C/span> field.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tGrafana prompts to set a \u003Cspan class=\"strong strong\">\u003Cstrong>New password\u003C/strong>\u003C/span> to create a secured account.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the menu, navigate to \u003Cspan class=\"strong strong\">\u003Cstrong>Administration\u003C/strong>\u003C/span> and then click \u003Cspan class=\"strong strong\">\u003Cstrong>Plugins\u003C/strong>\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Plugins\u003C/strong>\u003C/span> tab, type \u003Ccode class=\"literal\">performance co-pilot\u003C/code> in the \u003Cspan class=\"strong strong\">\u003Cstrong>Search Grafana plugins\u003C/strong>\u003C/span> text box and then click \u003Cspan class=\"strong strong\">\u003Cstrong>Performance Co-Pilot\u003C/strong>\u003C/span> (PCP) plugin.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Plugins / Performance Co-Pilot\u003C/strong>\u003C/span> pane, click \u003Cspan class=\"guibutton\">Enable\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tClick the Grafana icon   \n\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/a025b5a74873fcc2faa26c2441a34c43/grafana-home-page-whirl-icon.png\" alt=\"grafana home page whirl icon\"/>\u003C/span>\n\t\t\t\t\t\t  . The Grafana \u003Cspan class=\"strong strong\">\u003Cstrong>Home\u003C/strong>\u003C/span> page is displayed.\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"figure\" id=\"idm140280147165632\">\u003Cp class=\"title\">\u003Cstrong>Figure 9.1. Home Dashboard\u003C/strong>\u003C/p>\u003Cdiv class=\"figure-contents\">\u003Cdiv class=\"mediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/bf19e85b8f020e04a0450cff1108b4e3/grafana-home-dashboard1.png\" alt=\"grafana home dashboard1\"/>\u003C/div>\u003C/div>\u003C/div>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\tThe top right corner of the screen has a settings (gear) icon   \n\t\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/3ba1a1723dd2484923c87992667e6de4/grafana-gear-icon1.png\" alt=\"grafana gear icon1\"/>\u003C/span>\n\t\t\t\t\t\t\t   that controls the general \u003Cspan class=\"strong strong\">\u003Cstrong>Dashboard settings\u003C/strong>\u003C/span>.\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn the Grafana \u003Cspan class=\"strong strong\">\u003Cstrong>Home\u003C/strong>\u003C/span> page, click \u003Cspan class=\"strong strong\">\u003Cstrong>Add your first data source\u003C/strong>\u003C/span> to add PCP Redis, PCP bpftrace, and PCP Vector data sources. For more information about adding data source, see:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tTo add pcp redis data source, view default dashboard, create a panel, and an alert rule, see \u003Ca class=\"link\" href=\"#creating-panel-and-alerts-in-pcp-redis-data-source_setting-up-graphical-representation-of-pcp-metrics\" title=\"9.6. Creating panels and alerts in PCP Redis data source\">Creating panels and alert in PCP Redis data source\u003C/a>.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tTo add pcp bpftrace data source and view the default dashboard, see \u003Ca class=\"link\" href=\"#viewing-the-pcp-bpftrace-system-analysis-dashboard_setting-up-graphical-representation-of-pcp-metrics\" title=\"9.10. Viewing the PCP bpftrace System Analysis dashboard\">Viewing the PCP bpftrace System Analysis dashboard\u003C/a>.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tTo add pcp vector data source, view the default dashboard, and to view the vector checklist, see \u003Ca class=\"link\" href=\"#viewing-the-pcp-vector-checklist_setting-up-graphical-representation-of-pcp-metrics\" title=\"9.12. Viewing the PCP Vector Checklist\">Viewing the PCP Vector Checklist\u003C/a>.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tOptional: From the menu, hover over the \u003Cspan class=\"strong strong\">\u003Cstrong>admin\u003C/strong>\u003C/span> profile icon   \n\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/fb429591107dc7a2751707e864b36b6f/grafana-logout-option-icon.png\" alt=\"grafana logout option icon\"/>\u003C/span>\n\t\t\t\t\t\t   to update your \u003Cspan class=\"strong strong\">\u003Cstrong>Profile\u003C/strong>\u003C/span>, view \u003Cspan class=\"strong strong\">\u003Cstrong>Notification history\u003C/strong>\u003C/span>, \u003Cspan class=\"strong strong\">\u003Cstrong>Change password\u003C/strong>\u003C/span>, or to \u003Cspan class=\"strong strong\">\u003Cstrong>Sign out\u003C/strong>\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">grafana-cli(1)\u003C/code> and \u003Ccode class=\"literal\">grafana-server(1)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"configuring-secure-connections-for-grafana_setting-up-graphical-representation-of-pcp-metrics\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">9.4. Configuring secure connections for Grafana\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tYou can establish secure connections between Grafana and Performance Co-Pilot (PCP) components. Establishing secure connections between these components helps prevent unauthorized parties from accessing or modifying the data being collected and monitored.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tPCP is installed. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance#installing-and-enabling-pcp_setting-up-pcp\">Installing and enabling PCP\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe Grafana server is configured. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance#setting-up-a-grafana-server_setting-up-graphical-representation-of-pcp-metrics\">Setting up a Grafana server\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe private client key is stored in the \u003Ccode class=\"literal\">/etc/grafana/grafana.key\u003C/code> file. If you use a different path, modify the path in the corresponding steps of the procedure.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor details about creating a private key and certificate signing request (CSR), as well as how to request a certificate from a certificate authority (CA), see your CA’s documentation.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe TLS client certificate is stored in the \u003Ccode class=\"literal\">/etc/grafana/grafana.crt\u003C/code> file. If you use a different path, modify the path in the corresponding steps of the procedure.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAs a root user, open the \u003Ccode class=\"literal\">/etc/grafana/grafana.ini\u003C/code> file and adjust the following options in the \u003Ccode class=\"literal\">[server]\u003C/code> section to reflect the following:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">protocol = https\ncert_key = /etc/grafana/grafana.key\ncert_file = /etc/grafana/grafana.crt\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnsure grafana can access the certificates:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># su grafana -s /bin/bash -c \\\n  'ls -1 /etc/grafana/grafana.crt /etc/grafana/grafana.key'\n/etc/grafana/grafana.crt\n/etc/grafana/grafana.key\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRestart and enable the Grafana service to apply the configuration changes:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># systemctl restart grafana-server\n# systemctl enable grafana-server\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tOn the client system, open a browser and access the Grafana server machine on port 3000, using the \u003Cspan class=\"emphasis\">\u003Cem>https://192.0.2.0:3000\u003C/em>\u003C/span> link. Replace 192.0.2.0 with your machine IP.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tConfirm the lock icon   \n\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/e35cc95bbc36bfbb39b356d56c9fa2a3/lock_icon.png\" alt=\"lock icon\"/>\u003C/span>\n\t\t\t\t\t\t   is displayed beside the address bar.\n\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\tIf the protocol is set to \u003Ccode class=\"literal\">http\u003C/code> and an HTTPS connection is attempted, you will receive a \u003Ccode class=\"literal\">ERR_SSL_PROTOCOL_ERROR\u003C/code> error. If the protocol is set to \u003Ccode class=\"literal\">https\u003C/code> and an HTTP connection is attempted, the Grafana server responds with a “Client sent an HTTP request to an HTTPS server” message.\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"configuring-pcp-redis_setting-up-graphical-representation-of-pcp-metrics\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">9.5. Configuring PCP Redis\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tUse the PCP Redis data source to:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tView data archives\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tQuery time series using pmseries language\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tAnalyze data across multiple hosts\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tPCP is configured. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance#setting-up-pcp-with-pcp-zeroconf_setting-up-graphical-representation-of-pcp-metrics\">Setting up PCP with pcp-zeroconf\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe Grafana server is configured. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance#setting-up-a-grafana-server_setting-up-graphical-representation-of-pcp-metrics\">Setting up a Grafana server\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tMail transfer agent, for example, \u003Ccode class=\"literal\">sendmail\u003C/code> or \u003Ccode class=\"literal\">postfix\u003C/code> is installed and configured.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInstall the \u003Ccode class=\"literal\">redis\u003C/code> package:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf install redis\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tStart and enable the following services:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># systemctl start pmproxy redis\n# systemctl enable pmproxy redis\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRestart the Grafana server:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># systemctl restart grafana-server\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnsure that the \u003Ccode class=\"literal\">pmproxy\u003C/code> and \u003Ccode class=\"literal\">redis\u003C/code> are working:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># pmseries disk.dev.read\n2eb3e58d8f1e231361fb15cf1aa26fe534b4d9df\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThis command does not return any data if the \u003Ccode class=\"literal\">redis\u003C/code> package is not installed.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">pmseries(1)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"creating-panel-and-alerts-in-pcp-redis-data-source_setting-up-graphical-representation-of-pcp-metrics\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">9.6. Creating panels and alerts in PCP Redis data source\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tAfter adding the PCP Redis data source, you can view the dashboard with an overview of useful metrics, add a query to visualize the load graph, and create alerts that help you to view the system issues after they occur.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe PCP Redis is configured. For more information, see \u003Ca class=\"link\" href=\"#configuring-pcp-redis_setting-up-graphical-representation-of-pcp-metrics\" title=\"9.5. Configuring PCP Redis\">Configuring PCP Redis\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe Grafana server is accessible. For more information, see \u003Ca class=\"link\" href=\"#accessing-the-grafana-web-ui_setting-up-graphical-representation-of-pcp-metrics\" title=\"9.3. Accessing the Grafana web UI\">Accessing the Grafana web UI\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tLog into the Grafana web UI.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the Grafana \u003Cspan class=\"strong strong\">\u003Cstrong>Home\u003C/strong>\u003C/span> page, click \u003Cspan class=\"strong strong\">\u003Cstrong>Add your first data source\u003C/strong>\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Add data source\u003C/strong>\u003C/span> pane, type \u003Ccode class=\"literal\">redis\u003C/code> in the \u003Cspan class=\"strong strong\">\u003Cstrong>Filter by name or type\u003C/strong>\u003C/span> text box and then click \u003Cspan class=\"strong strong\">\u003Cstrong>PCP Redis\u003C/strong>\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Data Sources / PCP Redis\u003C/strong>\u003C/span> pane, perform the following:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tAdd \u003Ccode class=\"literal\">http://localhost:44322\u003C/code> in the \u003Cspan class=\"strong strong\">\u003Cstrong>URL\u003C/strong>\u003C/span> field and then click \u003Cspan class=\"guibutton\">Save &amp; Test\u003C/span>.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tClick \u003Cspan class=\"guimenu\">Dashboards tab\u003C/span> → \u003Cspan class=\"guisubmenu\">Import\u003C/span> → \u003Cspan class=\"guimenuitem\">PCP Redis: Host Overview\u003C/span> to see a dashboard with an overview of any useful metrics.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tOptional: In the drop-down menu next to the clock icon   \n\t\t\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/aad623ee40b87d8742467494b5efb798/grafana-clock-icon.png\" alt=\"grafana clock icon\"/>\u003C/span>\n\t\t\t\t\t\t\t\t  , you can set the timeline of the displayed metrics either by setting the absolute time range or by selecting a predefined range. You can also use the zoom out icon   \n\t\t\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/17baf4f1be1024c49bcc7039de10977e/grafana-zoom-out-icon.png\" alt=\"grafana zoom out icon\"/>\u003C/span>\n\t\t\t\t\t\t\t\t   to modify the displayed time range.\n\t\t\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\t\t\tThe time frame displayed by default might not be aligned with the time frame covered by the archive files created by the \u003Ccode class=\"literal\">pmlogger\u003C/code> service.\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"figure\" id=\"idm140280147402448\">\u003Cp class=\"title\">\u003Cstrong>Figure 9.2. PCP Redis: Host Overview\u003C/strong>\u003C/p>\u003Cdiv class=\"figure-contents\">\u003Cdiv class=\"mediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/a65ab7967b9ce306fd522737f3eb7324/pcp-redis-host-overview1.png\" alt=\"pcp redis host overview1\"/>\u003C/div>\u003C/div>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAdd a new panel:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tFrom the plus sign   \n\t\t\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/4bef4168e28b542ff381b4cf2e80a0ca/grafana-plus-sign1.png\" alt=\"grafana plus sign1\"/>\u003C/span>\n\t\t\t\t\t\t\t\t   drop-down menu, select \u003Cspan class=\"strong strong\">\u003Cstrong>New dashboard\u003C/strong>\u003C/span>.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tFrom the \u003Cspan class=\"strong strong\">\u003Cstrong>Add\u003C/strong>\u003C/span>   \u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/176d40372fa3d6f6e415514ac0e8db22/grafana-add-drop-down.png\" alt=\"grafana add drop down\"/>\u003C/span>\n\t\t\t\t\t\t\t\t   drop-down menu, select \u003Cspan class=\"strong strong\">\u003Cstrong>Visualization\u003C/strong>\u003C/span>.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Query\u003C/strong>\u003C/span> tab, select the \u003Cspan class=\"strong strong\">\u003Cstrong>pcp-redis-datasource\u003C/strong>\u003C/span> as the \u003Cspan class=\"strong strong\">\u003Cstrong>Data source\u003C/strong>\u003C/span>.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tIn the text field below \u003Cspan class=\"strong strong\">\u003Cstrong>A\u003C/strong>\u003C/span>, enter metric, for example, \u003Ccode class=\"literal\">kernel.all.load\u003C/code> to visualize the kernel load graph.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tOptional: From the \u003Cspan class=\"strong strong\">\u003Cstrong>Time series\u003C/strong>\u003C/span> drop-down menu on the right, select another format of visualization, for example, \u003Cspan class=\"strong strong\">\u003Cstrong>Bar chart\u003C/strong>\u003C/span>, \u003Cspan class=\"strong strong\">\u003Cstrong>Table\u003C/strong>\u003C/span>, or \u003Cspan class=\"strong strong\">\u003Cstrong>Heatmap\u003C/strong>\u003C/span>.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tOptional: Add \u003Cspan class=\"strong strong\">\u003Cstrong>Panel title\u003C/strong>\u003C/span> and \u003Cspan class=\"strong strong\">\u003Cstrong>Description\u003C/strong>\u003C/span>, and update other options.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tClick \u003Cspan class=\"guibutton\">Save\u003C/span> to apply changes and save the dashboard. Add \u003Cspan class=\"strong strong\">\u003Cstrong>Title\u003C/strong>\u003C/span>.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tClick \u003Cspan class=\"guibutton\">Apply\u003C/span> to apply changes and go back to the dashboard.\n\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"figure\" id=\"idm140280130725072\">\u003Cp class=\"title\">\u003Cstrong>Figure 9.3. PCP Redis query panel\u003C/strong>\u003C/p>\u003Cdiv class=\"figure-contents\">\u003Cdiv class=\"mediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/fb3c3f442d7a30ad1870192b27e646b9/pcp-redis-query.png\" alt=\"pcp redis query\"/>\u003C/div>\u003C/div>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate an alert rule:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>PCP Redis query panel\u003C/strong>\u003C/span>, click \u003Cspan class=\"strong strong\">\u003Cstrong>Alert\u003C/strong>\u003C/span>   \u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/27faa831b9bb3c08a33a610ea23926df/grafana-alert.png\" alt=\"grafana alert\"/>\u003C/span>\n\t\t\t\t\t\t\t\t   and then click \u003Cspan class=\"strong strong\">\u003Cstrong>New alert rule\u003C/strong>\u003C/span>.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tEnter alert rule name.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tDefine query and alert condition.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tSet evaluation behavior.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tOptional: Add annotations.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tAdd labels and notifications.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tClick \u003Cspan class=\"guibutton\">Save rule an exit\u003C/span> to apply changes in alert rules.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tClick \u003Cspan class=\"guibutton\">Apply\u003C/span> to apply changes and go back to the dashboard.\n\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"figure\" id=\"idm140280148325984\">\u003Cp class=\"title\">\u003Cstrong>Figure 9.4. Creating alerts in the PCP Redis panel\u003C/strong>\u003C/p>\u003Cdiv class=\"figure-contents\">\u003Cdiv class=\"mediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/05755c9f85d5eb517bbe54bed543b40c/pcp-redis-alert1.png\" alt=\"pcp redis alert1\"/>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tTo add a notification channel for the created alert rule to receive an alert notification from Grafana, see \u003Ca class=\"link\" href=\"#adding-notification-channels-for-alerts_setting-up-graphical-representation-of-pcp-metrics\" title=\"9.7. Adding notification channels for alerts\">Adding notification channels for alerts\u003C/a>.\n\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"adding-notification-channels-for-alerts_setting-up-graphical-representation-of-pcp-metrics\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">9.7. Adding notification channels for alerts\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tBy adding notification channels, you can receive an alert notification from Grafana whenever the alert rule conditions are met and the system needs further monitoring.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tYou can receive these alerts after selecting any one type from the supported list of notifiers, which includes:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tAlertmanager\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tCisco Webex Teams\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tDingDing\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tDiscord\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tEmail\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tGoogle Chat\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tKafka REST Proxy\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tLINE\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tMicrosoft Teams\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tOpsGenie\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tPagerDuty\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tPushover\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tSensu Go\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tSlack\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tTelegram\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThreema Gateway\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tVictorOps\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tWeCom\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tWebhook\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe Grafana server is accessible. For more information, see \u003Ca class=\"link\" href=\"#accessing-the-grafana-web-ui_setting-up-graphical-representation-of-pcp-metrics\" title=\"9.3. Accessing the Grafana web UI\">Accessing the Grafana web UI\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tAn alert rule is created. For more information, see \u003Ca class=\"link\" href=\"#creating-panel-and-alerts-in-pcp-redis-data-source_setting-up-graphical-representation-of-pcp-metrics\" title=\"9.6. Creating panels and alerts in PCP Redis data source\">Creating panels and alert in PCP Redis data source\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tConfigure SMTP and add a valid sender’s email address in the \u003Ccode class=\"literal\">/etc/grafana/grafana.ini\u003C/code> file:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">[smtp]\nenabled = true\nfrom_address = \u003Cspan class=\"emphasis\">\u003Cem>&lt;sender_email_address&gt;\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRestart the Grafana server.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># systemctl restart grafana-server.service\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFrom the menu, select \u003Cspan class=\"guimenu\">Alerting\u003C/span> → \u003Cspan class=\"guisubmenu\">Contact points\u003C/span> → \u003Cspan class=\"guimenuitem\">+ Add contact point\u003C/span>.\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"figure\" id=\"idm140280147955840\">\u003Cp class=\"title\">\u003Cstrong>Figure 9.5. Alerting in Grafana\u003C/strong>\u003C/p>\u003Cdiv class=\"figure-contents\">\u003Cdiv class=\"mediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/3a62289eefc2075c37e590702f80a9f3/grafana-alerting-panel.png\" alt=\"grafana alerting panel\"/>\u003C/div>\u003C/div>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Create contact point\u003C/strong>\u003C/span> details view, perform the following:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tEnter your name in the \u003Cspan class=\"strong strong\">\u003Cstrong>Name\u003C/strong>\u003C/span> text box.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tSelect the \u003Cspan class=\"strong strong\">\u003Cstrong>Integration\u003C/strong>\u003C/span> type, for example, Email and enter the email address or multiple email addresses.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tOptional: Configure \u003Cspan class=\"strong strong\">\u003Cstrong>Optional Email settings\u003C/strong>\u003C/span> and \u003Cspan class=\"strong strong\">\u003Cstrong>Notification settings\u003C/strong>\u003C/span>.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick \u003Cspan class=\"guibutton\">Save contact point\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tSelect a notification channel in the alert rule:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tFrom the \u003Cspan class=\"strong strong\">\u003Cstrong>Alerting\u003C/strong>\u003C/span> menu, select \u003Cspan class=\"strong strong\">\u003Cstrong>Notification policies\u003C/strong>\u003C/span>.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tClick the three dots icon   \n\t\t\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/4ace5574078c2572f3c088e45d5e27d5/grafana-3-dots.png\" alt=\"grafana 3 dots\"/>\u003C/span>\n\t\t\t\t\t\t\t\t   on the far right of \u003Cspan class=\"strong strong\">\u003Cstrong>Default policy\u003C/strong>\u003C/span> and select \u003Cspan class=\"strong strong\">\u003Cstrong>Edit\u003C/strong>\u003C/span>.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tChoose the \u003Cspan class=\"strong strong\">\u003Cstrong>Contact point\u003C/strong>\u003C/span> you have just created and click \u003Cspan class=\"strong strong\">\u003Cstrong>Update default policy\u003C/strong>\u003C/span>.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tOptional: Configure a nested policy in addition to the default policy.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tOptional: Configure \u003Cspan class=\"strong strong\">\u003Cstrong>Mute Timings\u003C/strong>\u003C/span>.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://grafana.com/docs/grafana/v10.0/alerting/alerting-rules/create-notification-policy/\">Upstream Grafana documentation for alert notification policies\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"setting-up-authentication-between-pcp-components_setting-up-graphical-representation-of-pcp-metrics\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">9.8. Setting up authentication between PCP components\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can setup authentication using the \u003Ccode class=\"literal\">scram-sha-256\u003C/code> authentication mechanism, which is supported by PCP through the Simple Authentication Security Layer (SASL) framework.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInstall the \u003Ccode class=\"literal\">sasl\u003C/code> framework for the \u003Ccode class=\"literal\">scram-sha-256\u003C/code> authentication mechanism:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf install cyrus-sasl-scram cyrus-sasl-lib\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tSpecify the supported authentication mechanism and the user database path in the \u003Ccode class=\"literal\">pmcd.conf\u003C/code> file:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># vi /etc/sasl2/pmcd.conf\n\nmech_list: scram-sha-256\n\nsasldb_path: /etc/pcp/passwd.db\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a new user:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># useradd -r \u003Cspan class=\"emphasis\">\u003Cem>metrics\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>metrics\u003C/em>\u003C/span> by your user name.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAdd the created user in the user database:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># saslpasswd2 -a pmcd \u003Cspan class=\"emphasis\">\u003Cem>metrics\u003C/em>\u003C/span>\n\nPassword:\nAgain (for verification):\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo add the created user, you are required to enter the \u003Cspan class=\"emphasis\">\u003Cem>metrics\u003C/em>\u003C/span> account password.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tSet the permissions of the user database:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># chown root:pcp /etc/pcp/passwd.db\n# chmod 640 /etc/pcp/passwd.db\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRestart the \u003Ccode class=\"literal\">pmcd\u003C/code> service:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># systemctl restart pmcd\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify the \u003Ccode class=\"literal\">sasl\u003C/code> configuration:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout white-space-pre\"># pminfo -f -h \"pcp://127.0.0.1?username=\u003Cspan class=\"emphasis\">\u003Cem>metrics\u003C/em>\u003C/span>\" disk.dev.read\nPassword:\ndisk.dev.read\ninst [0 or \"sda\"] value 19540\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">saslauthd(8)\u003C/code>, \u003Ccode class=\"literal\">pminfo(1)\u003C/code>, and \u003Ccode class=\"literal\">sha256\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/solutions/5041891\">How can I setup authentication between PCP components, like PMDAs and pmcd in RHEL 8.2?\u003C/a> (Red Hat Knowledgebase)\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"installing-pcp-bpftrace_setting-up-graphical-representation-of-pcp-metrics\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">9.9. Installing PCP bpftrace\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tInstall the PCP \u003Ccode class=\"literal\">bpftrace\u003C/code> agent to introspect a system and to gather metrics from the kernel and user-space tracepoints.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe \u003Ccode class=\"literal\">bpftrace\u003C/code> agent uses bpftrace scripts to gather the metrics. The \u003Ccode class=\"literal\">bpftrace\u003C/code> scripts use the enhanced Berkeley Packet Filter (\u003Ccode class=\"literal\">eBPF\u003C/code>).\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThis procedure describes how to install a \u003Ccode class=\"literal\">pcp bpftrace\u003C/code>.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tPCP is configured. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance#setting-up-pcp-with-pcp-zeroconf_setting-up-graphical-representation-of-pcp-metrics\">Setting up PCP with pcp-zeroconf\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe Grafana server is configured. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance#setting-up-a-grafana-server_setting-up-graphical-representation-of-pcp-metrics\">Setting up a Grafana server\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">scram-sha-256\u003C/code> authentication mechanism is configured. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance#setting-up-authentication-between-pcp-components_setting-up-graphical-representation-of-pcp-metrics\">Setting up authentication between PCP components\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInstall the \u003Ccode class=\"literal\">pcp-pmda-bpftrace\u003C/code> package:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf install pcp-pmda-bpftrace\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEdit the \u003Ccode class=\"literal\">bpftrace.conf\u003C/code> file and add the user that you have created in \u003Ca class=\"link\" href=\"#setting-up-authentication-between-pcp-components_setting-up-graphical-representation-of-pcp-metrics\" title=\"9.8. Setting up authentication between PCP components\">Setting up authentication between PCP components\u003C/a>:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># vi /var/lib/pcp/pmdas/bpftrace/bpftrace.conf\n\n[dynamic_scripts]\nenabled = true\nauth_enabled = true\nallowed_users = root,\u003Cspan class=\"emphasis\">\u003Cem>metrics\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>metrics\u003C/em>\u003C/span> by your user name.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInstall \u003Ccode class=\"literal\">bpftrace\u003C/code> PMDA:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># cd /var/lib/pcp/pmdas/bpftrace/\n# ./Install\nUpdating the Performance Metrics Name Space (PMNS) ...\nTerminate PMDA if already installed ...\nUpdating the PMCD control file, and notifying PMCD ...\nCheck bpftrace metrics have appeared ... 7 metrics and 6 values\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">pmda-bpftrace\u003C/code> is now installed, and can only be used after authenticating your user. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance#viewing-the-pcp-bpftrace-system-analysis-dashboard_setting-up-graphical-representation-of-pcp-metrics\">Viewing the PCP bpftrace System Analysis dashboard\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">pmdabpftrace(1)\u003C/code> and \u003Ccode class=\"literal\">bpftrace\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"viewing-the-pcp-bpftrace-system-analysis-dashboard_setting-up-graphical-representation-of-pcp-metrics\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">9.10. Viewing the PCP bpftrace System Analysis dashboard\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tUsing the PCP bpftrace data source, you can access the live data from sources which are not available as normal data from the \u003Ccode class=\"literal\">pmlogger\u003C/code> or archives\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tIn the PCP bpftrace data source, you can view the dashboard with an overview of useful metrics.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe PCP bpftrace is installed. For more information, see \u003Ca class=\"link\" href=\"#installing-pcp-bpftrace_setting-up-graphical-representation-of-pcp-metrics\" title=\"9.9. Installing PCP bpftrace\">Installing PCP bpftrace\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe Grafana server is accessible. For more information, see \u003Ca class=\"link\" href=\"#accessing-the-grafana-web-ui_setting-up-graphical-representation-of-pcp-metrics\" title=\"9.3. Accessing the Grafana web UI\">Accessing the Grafana web UI\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tLog into the Grafana web UI.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the menu, navigate to \u003Cspan class=\"guimenu\">Connections\u003C/span> → \u003Cspan class=\"guisubmenu\">Data sources\u003C/span> → \u003Cspan class=\"guimenuitem\">+ Add new data source\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Add data source\u003C/strong>\u003C/span> pane, type bpftrace in the \u003Cspan class=\"strong strong\">\u003Cstrong>Filter by name or type\u003C/strong>\u003C/span> text box and then click \u003Cspan class=\"strong strong\">\u003Cstrong>PCP bpftrace\u003C/strong>\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Data Sources / pcp-bpftrace-datasource\u003C/strong>\u003C/span> pane, perform the following:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tAdd \u003Ccode class=\"literal\">http://localhost:44322\u003C/code> in the \u003Cspan class=\"strong strong\">\u003Cstrong>URL\u003C/strong>\u003C/span> field.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tToggle the \u003Cspan class=\"strong strong\">\u003Cstrong>Basic Auth\u003C/strong>\u003C/span> option and add the created user credentials in the \u003Cspan class=\"strong strong\">\u003Cstrong>User\u003C/strong>\u003C/span> and \u003Cspan class=\"strong strong\">\u003Cstrong>Password\u003C/strong>\u003C/span> field.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tClick \u003Cspan class=\"guibutton\">Save &amp; Test\u003C/span>.\n\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"figure\" id=\"idm140280149813488\">\u003Cp class=\"title\">\u003Cstrong>Figure 9.6. Adding PCP bpftrace in the data source\u003C/strong>\u003C/p>\u003Cdiv class=\"figure-contents\">\u003Cdiv class=\"mediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/9df0f37edb579f894d76bff2821315b2/pcp-bpftrace.png\" alt=\"pcp bpftrace\"/>\u003C/div>\u003C/div>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tClick \u003Cspan class=\"guimenu\">Dashboards tab\u003C/span> → \u003Cspan class=\"guisubmenu\">Import\u003C/span> → \u003Cspan class=\"guimenuitem\">PCP bpftrace: System Analysis\u003C/span> to see a dashboard with an overview of any useful metrics.\n\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"figure\" id=\"idm140280150479328\">\u003Cp class=\"title\">\u003Cstrong>Figure 9.7. PCP bpftrace: System Analysis\u003C/strong>\u003C/p>\u003Cdiv class=\"figure-contents\">\u003Cdiv class=\"mediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/8b57d67ce674ef329aad1a0443df11a1/pcp-bpftrace-system-analysis1.png\" alt=\"pcp bpftrace system analysis1\"/>\u003C/div>\u003C/div>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"installing-pcp-vector_setting-up-graphical-representation-of-pcp-metrics\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">9.11. Installing PCP Vector\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure describes how to install a \u003Ccode class=\"literal\">pcp vector\u003C/code>.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tPCP is configured. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance#setting-up-pcp-with-pcp-zeroconf_setting-up-graphical-representation-of-pcp-metrics\">Setting up PCP with pcp-zeroconf\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe Grafana server is configured. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance#setting-up-a-grafana-server_setting-up-graphical-representation-of-pcp-metrics\">Setting up a Grafana server\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInstall the \u003Ccode class=\"literal\">bcc\u003C/code> PMDA:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># cd /var/lib/pcp/pmdas/bcc\n# ./Install\n[Wed Apr  1 00:27:48] pmdabcc(22341) Info: Initializing, currently in 'notready' state.\n[Wed Apr  1 00:27:48] pmdabcc(22341) Info: Enabled modules:\n[Wed Apr  1 00:27:48] pmdabcc(22341) Info: ['biolatency', 'sysfork',\n[...]\nUpdating the Performance Metrics Name Space (PMNS) ...\nTerminate PMDA if already installed ...\nUpdating the PMCD control file, and notifying PMCD ...\nCheck bcc metrics have appeared ... 1 warnings, 1 metrics and 0 values\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">pmdabcc(1)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"viewing-the-pcp-vector-checklist_setting-up-graphical-representation-of-pcp-metrics\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">9.12. Viewing the PCP Vector Checklist\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe PCP Vector data source displays live metrics and uses the \u003Ccode class=\"literal\">pcp\u003C/code> metrics. It analyzes data for individual hosts.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tAfter adding the PCP Vector data source, you can view the dashboard with an overview of useful metrics and view the related troubleshooting or reference links in the checklist.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe PCP Vector is installed. For more information, see \u003Ca class=\"link\" href=\"#installing-pcp-vector_setting-up-graphical-representation-of-pcp-metrics\" title=\"9.11. Installing PCP Vector\">Installing PCP Vector\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe Grafana server is accessible. For more information, see \u003Ca class=\"link\" href=\"#accessing-the-grafana-web-ui_setting-up-graphical-representation-of-pcp-metrics\" title=\"9.3. Accessing the Grafana web UI\">Accessing the Grafana web UI\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tLog into the Grafana web UI.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the menu, navigate to \u003Cspan class=\"guimenu\">Connections\u003C/span> → \u003Cspan class=\"guisubmenu\">Data sources\u003C/span> → \u003Cspan class=\"guimenuitem\">+ Add new data source\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Add data source\u003C/strong>\u003C/span> pane, type vector in the \u003Cspan class=\"strong strong\">\u003Cstrong>Filter by name or type\u003C/strong>\u003C/span> text box and then click \u003Cspan class=\"strong strong\">\u003Cstrong>PCP Vector\u003C/strong>\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Data Sources / pcp-vector-datasource\u003C/strong>\u003C/span> pane, perform the following:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tAdd \u003Ccode class=\"literal\">http://localhost:44322\u003C/code> in the \u003Cspan class=\"strong strong\">\u003Cstrong>URL\u003C/strong>\u003C/span> field and then click \u003Cspan class=\"guibutton\">Save &amp; Test\u003C/span>.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tClick \u003Cspan class=\"guimenu\">Dashboards tab\u003C/span> → \u003Cspan class=\"guisubmenu\">Import\u003C/span> → \u003Cspan class=\"guimenuitem\">PCP Vector: Host Overview\u003C/span> to see a dashboard with an overview of any useful metrics.\n\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"figure\" id=\"idm140280138903248\">\u003Cp class=\"title\">\u003Cstrong>Figure 9.8. PCP Vector: Host Overview\u003C/strong>\u003C/p>\u003Cdiv class=\"figure-contents\">\u003Cdiv class=\"mediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/4d178ed3d910ced56dc97c587729c2a6/pcp-vector-host-overview1.png\" alt=\"pcp vector host overview1\"/>\u003C/div>\u003C/div>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn the menu, navigate to \u003Cspan class=\"guimenu\">Apps\u003C/span> → \u003Cspan class=\"guisubmenu\">Performance Co-Pilot\u003C/span> → \u003Cspan class=\"guimenuitem\">PCP Vector Checklist\u003C/span>.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn the PCP checklist, click the question mark icon   \n\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/aeafb42a73abe35a996fbef332985497/pcp-vector-checklist-troubleshooting-doc.png\" alt=\"pcp vector checklist troubleshooting doc\"/>\u003C/span>\n\t\t\t\t\t\t   for help or the warning icon   \n\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/d5171f39042726c86cc66894ed34a88a/pcp-vector-checklist-warning.png\" alt=\"pcp vector checklist warning\"/>\u003C/span>\n\t\t\t\t\t\t   to view the related troubleshooting or reference links.\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"figure\" id=\"idm140280150238608\">\u003Cp class=\"title\">\u003Cstrong>Figure 9.9. Performance Co-Pilot / PCP Vector Checklist\u003C/strong>\u003C/p>\u003Cdiv class=\"figure-contents\">\u003Cdiv class=\"mediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/8767f919ee35f25eb3aaf26dd10a1931/pcp-vector-checklist1.png\" alt=\"pcp vector checklist1\"/>\u003C/div>\u003C/div>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"using-heatmaps-in-grafana_setting-up-graphical-representation-of-pcp-metrics\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">9.13. Using heatmaps in Grafana\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tYou can use heatmaps in Grafana to view histograms of your data over time, identify trends and patterns in your data, and see how they change over time. Each column within a heatmap represents a single histogram with different colored cells representing the different densities of observation of a given value within that histogram.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tThis specific workflow is for the heatmaps in Grafana version 10 and later on RHEL9.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tPCP Redis is configured. For more information see \u003Ca class=\"link\" href=\"#configuring-pcp-redis_setting-up-graphical-representation-of-pcp-metrics\" title=\"9.5. Configuring PCP Redis\">Configuring PCP Redis\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe Grafana server is accessible. For more information see \u003Ca class=\"link\" href=\"#accessing-the-grafana-web-ui_setting-up-graphical-representation-of-pcp-metrics\" title=\"9.3. Accessing the Grafana web UI\">Accessing the Grafana Web UI\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe PCP Redis data source is configured. For more information see \u003Ca class=\"link\" href=\"#creating-panel-and-alerts-in-pcp-redis-data-source_setting-up-graphical-representation-of-pcp-metrics\" title=\"9.6. Creating panels and alerts in PCP Redis data source\">Creating panels and alerts in PCP Redis data source\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the menu, select \u003Cspan class=\"guimenu\">Dashboards\u003C/span> → \u003Cspan class=\"guisubmenu\">New Dashboard\u003C/span> → \u003Cspan class=\"guimenuitem\">+ Add visualization\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Select data source\u003C/strong>\u003C/span> pane, select \u003Cspan class=\"strong strong\">\u003Cstrong>pcp-redis-datasource\u003C/strong>\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Query\u003C/strong>\u003C/span> tab, in the text field below \u003Cspan class=\"strong strong\">\u003Cstrong>A\u003C/strong>\u003C/span>, enter a metric, for example, \u003Ccode class=\"literal\">kernel.all.load\u003C/code> to visualize the kernel load graph.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tFrom the \u003Cspan class=\"strong strong\">\u003Cstrong>Time series\u003C/strong>\u003C/span> drop-down menu on the right, select \u003Cspan class=\"strong strong\">\u003Cstrong>Heatmap\u003C/strong>\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tOptional: In the \u003Cspan class=\"strong strong\">\u003Cstrong>Panel Options\u003C/strong>\u003C/span> dropdown menu, add a \u003Cspan class=\"strong strong\">\u003Cstrong>Panel Title\u003C/strong>\u003C/span> and \u003Cspan class=\"strong strong\">\u003Cstrong>Description\u003C/strong>\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Heatmap\u003C/strong>\u003C/span> dropdown menu, under the \u003Cspan class=\"strong strong\">\u003Cstrong>Calculate from data\u003C/strong>\u003C/span> setting, click \u003Cspan class=\"strong strong\">\u003Cstrong>Yes\u003C/strong>\u003C/span>.\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"formalpara\">\u003Cp class=\"title\">\u003Cstrong>Heatmap\u003C/strong>\u003C/p>\u003Cp>\n\t\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/ac37e49e146f7139fe58971516c38f99/grafana_heatmap.png\" alt=\"A configured Grafana heatmap\"/>\u003C/span>\n\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tOptional: In the \u003Cspan class=\"strong strong\">\u003Cstrong>Colors\u003C/strong>\u003C/span> dropdown menu, change the \u003Cspan class=\"strong strong\">\u003Cstrong>Scheme\u003C/strong>\u003C/span> from the default \u003Cspan class=\"strong strong\">\u003Cstrong>Orange\u003C/strong>\u003C/span> and select the number of steps (color shades).\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOptional: In the \u003Cspan class=\"strong strong\">\u003Cstrong>Tooltip\u003C/strong>\u003C/span> dropdown menu, click the toggle to display a cell’s position within its specific histogram when hovering your cursor over a cell in the heatmap. For example:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"formalpara\">\u003Cp class=\"title\">\u003Cstrong>Show histogram (Y Axis) cell display\u003C/strong>\u003C/p>\u003Cp>\n\t\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/3f6341feaf365f49731bd763dd4442ff/grafana_histogram.png\" alt=\"A cell’s specific position within its histogram\"/>\u003C/span>\n\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"troubleshooting-grafana-issues_setting-up-graphical-representation-of-pcp-metrics\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">9.14. Troubleshooting Grafana issues\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tIt is sometimes neccesary to troubleshoot Grafana issues, such as, Grafana does not display any data, the dashboard is black, or similar issues.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify that the \u003Ccode class=\"literal\">pmlogger\u003C/code> service is up and running by executing the following command:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ systemctl status pmlogger\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify if files were created or modified to the disk by executing the following command:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ ls /var/log/pcp/pmlogger/$(hostname)/ -rlt\ntotal 4024\n-rw-r--r--. 1 pcp pcp   45996 Oct 13  2019 20191013.20.07.meta.xz\n-rw-r--r--. 1 pcp pcp     412 Oct 13  2019 20191013.20.07.index\n-rw-r--r--. 1 pcp pcp   32188 Oct 13  2019 20191013.20.07.0.xz\n-rw-r--r--. 1 pcp pcp   44756 Oct 13  2019 20191013.20.30-00.meta.xz\n[..]\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify that the \u003Ccode class=\"literal\">pmproxy\u003C/code> service is running by executing the following command:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ systemctl status pmproxy\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify that \u003Ccode class=\"literal\">pmproxy\u003C/code> is running, time series support is enabled, and a connection to Redis is established by viewing the \u003Ccode class=\"literal\">/var/log/pcp/pmproxy/pmproxy.log\u003C/code> file and ensure that it contains the following text:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">pmproxy(1716) Info: Redis slots, command keys, schema version setup\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tHere, \u003Cspan class=\"strong strong\">\u003Cstrong>1716\u003C/strong>\u003C/span> is the PID of pmproxy, which will be different for every invocation of \u003Ccode class=\"literal\">pmproxy\u003C/code>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify if the Redis database contains any keys by executing the following command:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ redis-cli dbsize\n(integer) 34837\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify if any PCP metrics are in the Redis database and \u003Ccode class=\"literal\">pmproxy\u003C/code> is able to access them by executing the following commands:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ pmseries disk.dev.read\n2eb3e58d8f1e231361fb15cf1aa26fe534b4d9df\n\n$ pmseries \"disk.dev.read[count:10]\"\n2eb3e58d8f1e231361fb15cf1aa26fe534b4d9df\n    [Mon Jul 26 12:21:10.085468000 2021] 117971 70e83e88d4e1857a3a31605c6d1333755f2dd17c\n    [Mon Jul 26 12:21:00.087401000 2021] 117758 70e83e88d4e1857a3a31605c6d1333755f2dd17c\n    [Mon Jul 26 12:20:50.085738000 2021] 116688 70e83e88d4e1857a3a31605c6d1333755f2dd17c\n[...]\u003C/pre>\u003Cpre class=\"literallayout\">$ redis-cli --scan --pattern \"*$(pmseries 'disk.dev.read')\"\n\npcp:metric.name:series:2eb3e58d8f1e231361fb15cf1aa26fe534b4d9df\npcp:values:series:2eb3e58d8f1e231361fb15cf1aa26fe534b4d9df\npcp:desc:series:2eb3e58d8f1e231361fb15cf1aa26fe534b4d9df\npcp:labelvalue:series:2eb3e58d8f1e231361fb15cf1aa26fe534b4d9df\npcp:instances:series:2eb3e58d8f1e231361fb15cf1aa26fe534b4d9df\npcp:labelflags:series:2eb3e58d8f1e231361fb15cf1aa26fe534b4d9df\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify if there are any errors in the Grafana logs by executing the following command:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ journalctl -e -u grafana-server\n-- Logs begin at Mon 2021-07-26 11:55:10 IST, end at Mon 2021-07-26 12:30:15 IST. --\nJul 26 11:55:17 localhost.localdomain systemd[1]: Starting Grafana instance...\nJul 26 11:55:17 localhost.localdomain grafana-server[1171]: t=2021-07-26T11:55:17+0530 lvl=info msg=\"Starting Grafana\" logger=server version=7.3.6 c&gt;\nJul 26 11:55:17 localhost.localdomain grafana-server[1171]: t=2021-07-26T11:55:17+0530 lvl=info msg=\"Config loaded from\" logger=settings file=/usr/s&gt;\nJul 26 11:55:17 localhost.localdomain grafana-server[1171]: t=2021-07-26T11:55:17+0530 lvl=info msg=\"Config loaded from\" logger=settings file=/etc/g&gt;\n[...]\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"using-the-web-console-for-selecting-performance-profiles_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 10. Optimizing the system performance using the web console\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tLearn how to set a performance profile in the RHEL web console to optimize the performance of the system for a selected task.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"performance-tuning-options-in-the-web-console_optimizing-the-system-performance-using-the-web-console\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">10.1. Performance tuning options in the web console\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tRed Hat Enterprise Linux 9 provides several performance profiles that optimize the system for the following tasks:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tSystems using the desktop\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThroughput performance\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tLatency performance\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tNetwork performance\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tLow power consumption\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tVirtual machines\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tThe \u003Ccode class=\"literal\">TuneD\u003C/code> service optimizes system options to match the selected profile.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tIn the web console, you can set which performance profile your system uses.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-tuned_monitoring-and-managing-system-status-and-performance\">Getting started with TuneD\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"setting-a-performance-profile-in-the-web-console_optimizing-the-system-performance-using-the-web-console\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">10.2. Setting a performance profile in the web console\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tDepending on the task you want to perform, you can use the web console to optimize system performance by setting a suitable performance profile.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tYou have installed the RHEL 9 web console.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor instructions, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console\">Installing and enabling the web console\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tLog in to the RHEL 9 web console.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor details, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#logging-in-to-the-web-console_getting-started-with-the-rhel-9-web-console\">Logging in to the web console\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick \u003Cspan class=\"strong strong\">\u003Cstrong>Overview\u003C/strong>\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Configuration\u003C/strong>\u003C/span> section, click the current performance profile.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/6657171b9c582eae939d7b0d427f1cab/cockpit-performance-profile-pf4.png\" alt=\"Image displaying the Overview pane of the cockpit interface.\"/>\u003C/span>\n\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Change Performance Profile\u003C/strong>\u003C/span> dialog box, set the required profile.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/44d16f8526acc4d5468e8ad42cdd52ab/cockpit-performance-profile-change-pf4.png\" alt=\"Image displaying the Change performance profile dialog box.\"/>\u003C/span>\n\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick \u003Cspan class=\"guibutton\">Change Profile\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Cspan class=\"strong strong\">\u003Cstrong>Overview\u003C/strong>\u003C/span> tab now shows the selected performance profile in the \u003Cspan class=\"strong strong\">\u003Cstrong>Configuration\u003C/strong>\u003C/span> section.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"monitoring-performance-using-the-web-console_optimizing-the-system-performance-using-the-web-console\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">10.3. Monitoring performance on the local system by using the web console\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tRed Hat Enterprise Linux web console uses the Utilization Saturation and Errors (USE) Method for troubleshooting. The new performance metrics page has a historical view of your data organized chronologically with the newest data at the top.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Metrics and history\u003C/strong>\u003C/span> page, you can view events, errors, and graphical representation for resource utilization and saturation.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tYou have installed the RHEL 9 web console.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor instructions, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console\">Installing and enabling the web console\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">cockpit-pcp\u003C/code> package, which enables collecting the performance metrics, is installed.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe Performance Co-Pilot (PCP) service is enabled:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl enable --now pmlogger.service pmproxy.service\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tLog in to the RHEL 9 web console.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor details, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#logging-in-to-the-web-console_getting-started-with-the-rhel-9-web-console\">Logging in to the web console\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick \u003Cspan class=\"strong strong\">\u003Cstrong>Overview\u003C/strong>\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Usage\u003C/strong>\u003C/span> section, click \u003Cspan class=\"strong strong\">\u003Cstrong>View metrics and history\u003C/strong>\u003C/span>.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/6657171b9c582eae939d7b0d427f1cab/cockpit-performance-profile-pf4.png\" alt=\"Image displaying the Overview pane of the cockpit interface.\"/>\u003C/span>\n\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe \u003Cspan class=\"strong strong\">\u003Cstrong>Metrics and history\u003C/strong>\u003C/span> section opens:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe current system configuration and usage: \n\t\t\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/b947ab3a7147c086e7c837d0abb496de/webconsole-view-details.png\" alt=\"Image displaying the current system configuration and usage\"/>\u003C/span>\n\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe performance metrics in a graphical form over a user-specified time interval: \n\t\t\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/2f82ace99e1cb1ddc0598f2a2b301402/webconsole-performance-metrics.png\" alt=\"Image displaying the performance metrics of the CPU\"/>\u003C/span>\n\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"proc_enabling-performance-metrics-export-with-pcp-from-the-web-console_optimizing-the-system-performance-using-the-web-console\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">10.4. Monitoring performance on several systems by using the web console and Grafana\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tGrafana enables you to collect data from several systems at once and review a graphical representation of their collected Performance Co-Pilot (PCP) metrics. You can set up performance metrics monitoring and export for several systems in the web console interface.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tYou have installed the RHEL 9 web console.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor instructions, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console\">Installing and enabling the web console\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have installed the \u003Ccode class=\"literal\">cockpit-pcp\u003C/code> package.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tYou have enabled the PCP service:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl enable --now pmlogger.service pmproxy.service\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have set up the Grafana dashboard. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance#setting-up-a-grafana-server_setting-up-graphical-representation-of-pcp-metrics\">Setting up a grafana-server\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tYou have installed the \u003Ccode class=\"literal\">redis\u003C/code> package.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAlternatively, you can install the package from the web console interface later in the procedure.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tLog in to the RHEL 9 web console.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor details, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#logging-in-to-the-web-console_getting-started-with-the-rhel-9-web-console\">Logging in to the web console\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Overview\u003C/strong>\u003C/span> page, click \u003Cspan class=\"strong strong\">\u003Cstrong>View metrics and history\u003C/strong>\u003C/span> in the \u003Cspan class=\"strong strong\">\u003Cstrong>Usage\u003C/strong>\u003C/span> table.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick the \u003Cspan class=\"guibutton\">Metrics settings\u003C/span> button.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tMove the \u003Cspan class=\"strong strong\">\u003Cstrong>Export to network\u003C/strong>\u003C/span> slider to active position.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/55761d5cf5f7a430b868dc184530bffa/cockpit-export-to-network-slider.png\" alt=\"Metrics settings\"/>\u003C/span>\n\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIf you do not have the \u003Ccode class=\"literal\">redis\u003C/code> package installed, the web console prompts you to install it.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tTo open the \u003Ccode class=\"literal\">pmproxy\u003C/code> service, select a zone from a drop-down list and click the \u003Cspan class=\"guibutton\">Add pmproxy\u003C/span> button.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick \u003Cspan class=\"strong strong\">\u003Cstrong>Save\u003C/strong>\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tClick \u003Cspan class=\"strong strong\">\u003Cstrong>Networking\u003C/strong>\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn the \u003Cspan class=\"strong strong\">\u003Cstrong>Firewall\u003C/strong>\u003C/span> table, click the \u003Cspan class=\"guibutton\">Edit rules and zones\u003C/span> button.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tSearch for \u003Ccode class=\"literal\">pmproxy\u003C/code> in your selected zone.\n\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tRepeat this procedure on all the systems you want to watch.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance#setting-up-pcp-with-pcp-zeroconf_setting-up-graphical-representation-of-pcp-metrics\">Setting up graphical representation of PCP metrics\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"setting-the-disk-scheduler_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 11. Setting the disk scheduler\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tThe disk scheduler is responsible for ordering the I/O requests submitted to a storage device.\n\t\t\u003C/p>\u003Cp>\n\t\t\tYou can configure the scheduler in several different ways:\n\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\tSet the scheduler using \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span>, as described in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-the-disk-scheduler_monitoring-and-managing-system-status-and-performance#setting-the-disk-scheduler-using-tuned_setting-the-disk-scheduler\">Setting the disk scheduler using TuneD\u003C/a>\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tSet the scheduler using \u003Ccode class=\"literal\">udev\u003C/code>, as described in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-the-disk-scheduler_monitoring-and-managing-system-status-and-performance#setting-the-disk-scheduler-using-udev-rules_setting-the-disk-scheduler\">Setting the disk scheduler using udev rules\u003C/a>\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tTemporarily change the scheduler on a running system, as described in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-the-disk-scheduler_monitoring-and-managing-system-status-and-performance#temporarily-setting-a-scheduler-for-a-specific-disk_setting-the-disk-scheduler\">Temporarily setting a scheduler for a specific disk\u003C/a>\n\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\tIn Red Hat Enterprise Linux 9, block devices support only multi-queue scheduling. This enables the block layer performance to scale well with fast solid-state drives (SSDs) and multi-core systems.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe traditional, single-queue schedulers, which were available in Red Hat Enterprise Linux 7 and earlier versions, have been removed.\n\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Csection class=\"section\" id=\"available-disk-schedulers_setting-the-disk-scheduler\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">11.1. Available disk schedulers\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe following multi-queue disk schedulers are supported in Red Hat Enterprise Linux 9:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">none\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tImplements a first-in first-out (FIFO) scheduling algorithm. It merges requests at the generic block layer through a simple last-hit cache.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">mq-deadline\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tAttempts to provide a guaranteed latency for requests from the point at which requests reach the scheduler.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">mq-deadline\u003C/code> scheduler sorts queued I/O requests into a read or write batch and then schedules them for execution in increasing logical block addressing (LBA) order. By default, read batches take precedence over write batches, because applications are more likely to block on read I/O operations. After \u003Ccode class=\"literal\">mq-deadline\u003C/code> processes a batch, it checks how long write operations have been starved of processor time and schedules the next read or write batch as appropriate.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThis scheduler is suitable for most use cases, but particularly those in which the write operations are mostly asynchronous.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">bfq\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tTargets desktop systems and interactive tasks.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">bfq\u003C/code> scheduler ensures that a single application is never using all of the bandwidth. In effect, the storage device is always as responsive as if it was idle. In its default configuration, \u003Ccode class=\"literal\">bfq\u003C/code> focuses on delivering the lowest latency rather than achieving the maximum throughput.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\u003Ccode class=\"literal\">bfq\u003C/code> is based on \u003Ccode class=\"literal\">cfq\u003C/code> code. It does not grant the disk to each process for a fixed time slice but assigns a \u003Cspan class=\"emphasis\">\u003Cem>budget\u003C/em>\u003C/span> measured in number of sectors to the process.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThis scheduler is suitable while copying large files and the system does not become unresponsive in this case.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">kyber\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe scheduler tunes itself to achieve a latency goal by calculating the latencies of every I/O request submitted to the block I/O layer. You can configure the target latencies for read, in the case of cache-misses, and synchronous write requests.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThis scheduler is suitable for fast devices, for example NVMe, SSD, or other low latency devices.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003C/dl>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"different-disk-schedulers-for-different-use-cases_setting-the-disk-scheduler\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">11.2. Different disk schedulers for different use cases\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tDepending on the task that your system performs, the following disk schedulers are recommended as a baseline prior to any analysis and tuning tasks:\n\t\t\t\u003C/p>\u003Crh-table id=\"idm140280143512464\">\u003Ctable class=\"lt-4-cols lt-7-rows\">\u003Ccaption>Table 11.1. Disk schedulers for different use cases\u003C/caption>\u003Ccolgroup>\u003Ccol style=\"width: 50%; \" class=\"col_1\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 50%; \" class=\"col_2\">\u003C!--Empty-->\u003C/col>\u003C/colgroup>\u003Cthead>\u003Ctr>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280150191504\" scope=\"col\">Use case\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280150190416\" scope=\"col\">Disk scheduler\u003C/th>\u003C/tr>\u003C/thead>\u003Ctbody>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280150191504\"> \u003Cp>\n\t\t\t\t\t\t\t\tTraditional HDD with a SCSI interface\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280150190416\"> \u003Cp>\n\t\t\t\t\t\t\t\tUse \u003Ccode class=\"literal\">mq-deadline\u003C/code> or \u003Ccode class=\"literal\">bfq\u003C/code>.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280150191504\"> \u003Cp>\n\t\t\t\t\t\t\t\tHigh-performance SSD or a CPU-bound system with fast storage\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280150190416\"> \u003Cp>\n\t\t\t\t\t\t\t\tUse \u003Ccode class=\"literal\">none\u003C/code>, especially when running enterprise applications. Alternatively, use \u003Ccode class=\"literal\">kyber\u003C/code>.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280150191504\"> \u003Cp>\n\t\t\t\t\t\t\t\tDesktop or interactive tasks\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280150190416\"> \u003Cp>\n\t\t\t\t\t\t\t\tUse \u003Ccode class=\"literal\">bfq\u003C/code>.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280150191504\"> \u003Cp>\n\t\t\t\t\t\t\t\tVirtual guest\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280150190416\"> \u003Cp>\n\t\t\t\t\t\t\t\tUse \u003Ccode class=\"literal\">mq-deadline\u003C/code>. With a host bus adapter (HBA) driver that is multi-queue capable, use \u003Ccode class=\"literal\">none\u003C/code>.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\u003C/rh-table>\u003C/section>\u003Csection class=\"section\" id=\"the-default-disk-scheduler_setting-the-disk-scheduler\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">11.3. The default disk scheduler\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tBlock devices use the default disk scheduler unless you specify another scheduler.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tFor \u003Ccode class=\"literal\">non-volatile Memory Express (NVMe)\u003C/code> block devices specifically, the default scheduler is \u003Ccode class=\"literal\">none\u003C/code> and Red Hat recommends not changing this.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cp>\n\t\t\t\tThe kernel selects a default disk scheduler based on the type of device. The automatically selected scheduler is typically the optimal setting. If you require a different scheduler, Red Hat recommends to use \u003Ccode class=\"literal\">udev\u003C/code> rules or the \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> application to configure it. Match the selected devices and switch the scheduler only for those devices.\n\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"determining-the-active-disk-scheduler_setting-the-disk-scheduler\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">11.4. Determining the active disk scheduler\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure determines which disk scheduler is currently active on a given block device.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRead the content of the \u003Ccode class=\"literal\">/sys/block/\u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span>/queue/scheduler\u003C/code> file:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># cat /sys/block/\u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span>/queue/scheduler\n\n[mq-deadline] kyber bfq none\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn the file name, replace \u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span> with the block device name, for example \u003Ccode class=\"literal\">sdc\u003C/code>.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe active scheduler is listed in square brackets (\u003Ccode class=\"literal\">[ ]\u003C/code>).\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"setting-the-disk-scheduler-using-tuned_setting-the-disk-scheduler\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">11.5. Setting the disk scheduler using TuneD\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure creates and enables a \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profile that sets a given disk scheduler for selected block devices. The setting persists across system reboots.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tIn the following commands and configuration, replace:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span> with the name of the block device, for example \u003Ccode class=\"literal\">sdf\u003C/code>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Cspan class=\"emphasis\">\u003Cem>selected-scheduler\u003C/em>\u003C/span> with the disk scheduler that you want to set for the device, for example \u003Ccode class=\"literal\">bfq\u003C/code>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">TuneD\u003C/code> service is installed and enabled. For details, see \u003Ca class=\"link\" href=\"#installing-and-enabling-tuned_getting-started-with-tuned\" title=\"1.13. Installing and enabling TuneD\">Installing and enabling TuneD\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOptional: Select an existing \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profile on which your profile will be based. For a list of available profiles, see \u003Ca class=\"link\" href=\"#tuned-profiles-distributed-with-rhel_getting-started-with-tuned\" title=\"1.6. TuneD profiles distributed with RHEL\">TuneD profiles distributed with RHEL\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo see which profile is currently active, use:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ tuned-adm active\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a new directory to hold your \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profile:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mkdir /etc/tuned/\u003Cspan class=\"emphasis\">\u003Cem>my-profile\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFind the system unique identifier of the selected block device:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ udevadm info --query=property --name=/dev/\u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span> | grep -E '(WWN|SERIAL)'\n\nID_WWN=\u003Cspan class=\"emphasis\">\u003Cem>0x5002538d00000000_\u003C/em>\u003C/span>\nID_SERIAL=\u003Cspan class=\"emphasis\">\u003Cem>Generic-_SD_MMC_20120501030900000-0:0\u003C/em>\u003C/span>\nID_SERIAL_SHORT=\u003Cspan class=\"emphasis\">\u003Cem>20120501030900000\u003C/em>\u003C/span>\u003C/pre>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\tThe command in the this example will return all values identified as a World Wide Name (WWN) or serial number associated with the specified block device. Although it is preferred to use a WWN, the WWN is not always available for a given device and any values returned by the example command are acceptable to use as the \u003Cspan class=\"emphasis\">\u003Cem>device system unique ID\u003C/em>\u003C/span>.\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate the \u003Ccode class=\"literal\">/etc/tuned/\u003Cspan class=\"emphasis\">\u003Cem>my-profile\u003C/em>\u003C/span>/tuned.conf\u003C/code> configuration file. In the file, set the following options:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tOptional: Include an existing profile:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">[main]\ninclude=\u003Cspan class=\"emphasis\">\u003Cem>existing-profile\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tSet the selected disk scheduler for the device that matches the WWN identifier:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">[disk]\ndevices_udev_regex=\u003Cspan class=\"emphasis\">\u003Cem>IDNAME\u003C/em>\u003C/span>=\u003Cspan class=\"emphasis\">\u003Cem>device system unique id\u003C/em>\u003C/span>\nelevator=\u003Cspan class=\"emphasis\">\u003Cem>selected-scheduler\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tHere:\n\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>IDNAME\u003C/em>\u003C/span> with the name of the identifier being used (for example, \u003Ccode class=\"literal\">ID_WWN\u003C/code>).\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>device system unique id\u003C/em>\u003C/span> with the value of the chosen identifier (for example, \u003Ccode class=\"literal\">0x5002538d00000000\u003C/code>).\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\tTo match multiple devices in the \u003Ccode class=\"literal\">devices_udev_regex\u003C/code> option, enclose the identifiers in parentheses and separate them with vertical bars:\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">devices_udev_regex=(ID_WWN=\u003Cspan class=\"emphasis\">\u003Cem>0x5002538d00000000\u003C/em>\u003C/span>)|(ID_WWN=\u003Cspan class=\"emphasis\">\u003Cem>0x1234567800000000\u003C/em>\u003C/span>)\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnable your profile:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># tuned-adm profile \u003Cspan class=\"emphasis\">\u003Cem>my-profile\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify that the TuneD profile is active and applied:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ tuned-adm active\n\nCurrent active profile: \u003Cspan class=\"emphasis\">\u003Cem>my-profile\u003C/em>\u003C/span>\u003C/pre>\u003Cpre class=\"screen\">$ tuned-adm verify\n\nVerification succeeded, current system settings match the preset profile.\nSee TuneD log file ('/var/log/tuned/tuned.log') for details.\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRead the contents of the \u003Ccode class=\"literal\">/sys/block/\u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span>/queue/scheduler\u003C/code> file:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># cat /sys/block/\u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span>/queue/scheduler\n\n[mq-deadline] kyber bfq none\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn the file name, replace \u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span> with the block device name, for example \u003Ccode class=\"literal\">sdc\u003C/code>.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe active scheduler is listed in square brackets (\u003Ccode class=\"literal\">[]\u003C/code>).\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"#customizing-tuned-profiles_monitoring-and-managing-system-status-and-performance\" title=\"Chapter 2. Customizing TuneD profiles\">Customizing TuneD profiles\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"setting-the-disk-scheduler-using-udev-rules_setting-the-disk-scheduler\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">11.6. Setting the disk scheduler using udev rules\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure sets a given disk scheduler for specific block devices using \u003Ccode class=\"literal\">udev\u003C/code> rules. The setting persists across system reboots.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tIn the following commands and configuration, replace:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span> with the name of the block device, for example \u003Ccode class=\"literal\">sdf\u003C/code>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Cspan class=\"emphasis\">\u003Cem>selected-scheduler\u003C/em>\u003C/span> with the disk scheduler that you want to set for the device, for example \u003Ccode class=\"literal\">bfq\u003C/code>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFind the system unique identifier of the block device:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ udevadm info --name=/dev/\u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span> | grep -E '(WWN|SERIAL)'\nE: ID_WWN=\u003Cspan class=\"emphasis\">\u003Cem>0x5002538d00000000\u003C/em>\u003C/span>\nE: ID_SERIAL=\u003Cspan class=\"emphasis\">\u003Cem>Generic-_SD_MMC_20120501030900000-0:0\u003C/em>\u003C/span>\nE: ID_SERIAL_SHORT=\u003Cspan class=\"emphasis\">\u003Cem>20120501030900000\u003C/em>\u003C/span>\u003C/pre>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\tThe command in the this example will return all values identified as a World Wide Name (WWN) or serial number associated with the specified block device. Although it is preferred to use a WWN, the WWN is not always available for a given device and any values returned by the example command are acceptable to use as the \u003Cspan class=\"emphasis\">\u003Cem>device system unique ID\u003C/em>\u003C/span>.\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tConfigure the \u003Ccode class=\"literal\">udev\u003C/code> rule. Create the \u003Ccode class=\"literal\">/etc/udev/rules.d/99-scheduler.rules\u003C/code> file with the following content:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">ACTION==\"add|change\", SUBSYSTEM==\"block\", ENV{\u003Cspan class=\"emphasis\">\u003Cem>IDNAME\u003C/em>\u003C/span>}==\"\u003Cspan class=\"emphasis\">\u003Cem>device system unique id\u003C/em>\u003C/span>\", ATTR{queue/scheduler}=\"\u003Cspan class=\"emphasis\">\u003Cem>selected-scheduler\u003C/em>\u003C/span>\"\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tHere:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>IDNAME\u003C/em>\u003C/span> with the name of the identifier being used (for example, \u003Ccode class=\"literal\">ID_WWN\u003C/code>).\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>device system unique id\u003C/em>\u003C/span> with the value of the chosen identifier (for example, \u003Ccode class=\"literal\">0x5002538d00000000\u003C/code>).\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tReload \u003Ccode class=\"literal\">udev\u003C/code> rules:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># udevadm control --reload-rules\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tApply the scheduler configuration:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># udevadm trigger --type=devices --action=change\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify the active scheduler:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># cat /sys/block/\u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span>/queue/scheduler\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"temporarily-setting-a-scheduler-for-a-specific-disk_setting-the-disk-scheduler\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">11.7. Temporarily setting a scheduler for a specific disk\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure sets a given disk scheduler for specific block devices. The setting does not persist across system reboots.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tWrite the name of the selected scheduler to the \u003Ccode class=\"literal\">/sys/block/\u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span>/queue/scheduler\u003C/code> file:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># echo \u003Cspan class=\"emphasis\">\u003Cem>selected-scheduler\u003C/em>\u003C/span> &gt; /sys/block/\u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span>/queue/scheduler\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn the file name, replace \u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span> with the block device name, for example \u003Ccode class=\"literal\">sdc\u003C/code>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify that the scheduler is active on the device:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># cat /sys/block/\u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span>/queue/scheduler\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"assembly_tuning-the-performance-of-a-samba-server_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 12. Tuning the performance of a Samba server\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tLearn what settings can improve the performance of Samba in certain situations, and which settings can have a negative performance impact.\n\t\t\u003C/p>\u003Cp>\n\t\t\tParts of this section were adopted from the \u003Ca class=\"link\" href=\"https://wiki.samba.org/index.php/Performance_Tuning\">Performance Tuning\u003C/a> documentation published in the Samba Wiki. License: \u003Ca class=\"link\" href=\"https://creativecommons.org/licenses/by/4.0/\">CC BY 4.0\u003C/a>. Authors and contributors: See the \u003Ca class=\"link\" href=\"https://wiki.samba.org/index.php?title=Performance_Tuning&amp;action=history\">history\u003C/a> tab on the Wiki page.\n\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\tSamba is set up as a file or print server\n\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Csection class=\"section\" id=\"proc_setting-the-smb-protocol-version_assembly_tuning-the-performance-of-a-samba-server\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">12.1. Setting the SMB protocol version\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tEach new SMB version adds features and improves the performance of the protocol. The recent Windows and Windows Server operating systems always supports the latest protocol version. If Samba also uses the latest protocol version, Windows clients connecting to Samba benefit from the performance improvements. In Samba, the default value of the server max protocol is set to the latest supported stable SMB protocol version.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tTo always have the latest stable SMB protocol version enabled, do not set the \u003Ccode class=\"literal\">server max protocol\u003C/code> parameter. If you set the parameter manually, you will need to modify the setting with each new version of the SMB protocol, to have the latest protocol version enabled.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cp>\n\t\t\t\tThe following procedure explains how to use the default value in the \u003Ccode class=\"literal\">server max protocol\u003C/code> parameter.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tRemove the \u003Ccode class=\"literal\">server max protocol\u003C/code> parameter from the \u003Ccode class=\"literal\">[global]\u003C/code> section in the \u003Ccode class=\"literal filename\">/etc/samba/smb.conf\u003C/code> file.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tReload the Samba configuration\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>smbcontrol all reload-config\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"proc_tuning-shares-with-directories-that-contain-a-large-number-of-files_assembly_tuning-the-performance-of-a-samba-server\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">12.2. Tuning shares with directories that contain a large number of files\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tLinux supports case-sensitive file names. For this reason, Samba needs to scan directories for uppercase and lowercase file names when searching or accessing a file. You can configure a share to create new files only in lowercase or uppercase, which improves the performance.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tSamba is configured as a file server\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRename all files on the share to lowercase.\n\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\tUsing the settings in this procedure, files with names other than in lowercase will no longer be displayed.\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tSet the following parameters in the share’s section:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">case sensitive = true\ndefault case = lower\npreserve case = no\nshort preserve case = no\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor details about the parameters, see their descriptions in the \u003Ccode class=\"literal\">smb.conf(5)\u003C/code> man page on your system.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify the \u003Ccode class=\"literal filename\">/etc/samba/smb.conf\u003C/code> file:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>testparm\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tReload the Samba configuration:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>smbcontrol all reload-config\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cp>\n\t\t\t\tAfter you applied these settings, the names of all newly created files on this share use lowercase. Because of these settings, Samba no longer needs to scan the directory for uppercase and lowercase, which improves the performance.\n\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"con_settings-that-can-have-a-negative-performance-impact_assembly_tuning-the-performance-of-a-samba-server\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">12.3. Settings that can have a negative performance impact\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tBy default, the kernel in Red Hat Enterprise Linux is tuned for high network performance. For example, the kernel uses an auto-tuning mechanism for buffer sizes. Setting the \u003Ccode class=\"literal\">socket options\u003C/code> parameter in the \u003Ccode class=\"literal filename\">/etc/samba/smb.conf\u003C/code> file overrides these kernel settings. As a result, setting this parameter decreases the Samba network performance in most cases.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tTo use the optimized settings from the Kernel, remove the \u003Ccode class=\"literal\">socket options\u003C/code> parameter from the \u003Ccode class=\"literal\">[global]\u003C/code> section in the \u003Ccode class=\"literal filename\">/etc/samba/smb.conf\u003C/code>.\n\t\t\t\u003C/p>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"optimizing-virtual-machine-performance-in-rhel_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 13. Optimizing virtual machine performance\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\tVirtual machines (VMs) always experience some degree of performance deterioration in comparison to the host. The following sections explain the reasons for this deterioration and provide instructions on how to minimize the performance impact of virtualization in RHEL 9, so that your hardware infrastructure resources can be used as efficiently as possible.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"what-influences-virtual-machine-performance_optimizing-virtual-machine-performance-in-rhel\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">13.1. What influences virtual machine performance\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tVMs are run as user-space processes on the host. The hypervisor therefore needs to convert the host’s system resources so that the VMs can use them. As a consequence, a portion of the resources is consumed by the conversion, and the VM therefore cannot achieve the same performance efficiency as the host.\n\t\t\t\u003C/p>\u003Ch5 id=\"the_impact_of_virtualization_on_system_performance\">The impact of virtualization on system performance\u003C/h5>\u003Cp>\n\t\t\t\tMore specific reasons for VM performance loss include:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tVirtual CPUs (vCPUs) are implemented as threads on the host, handled by the Linux scheduler.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tVMs do not automatically inherit optimization features, such as NUMA or huge pages, from the host kernel.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tDisk and network I/O settings of the host might have a significant performance impact on the VM.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tNetwork traffic typically travels to a VM through a software-based bridge.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tDepending on the host devices and their models, there might be significant overhead due to emulation of particular hardware.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tThe severity of the virtualization impact on the VM performance is influenced by a variety factors, which include:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe number of concurrently running VMs.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe amount of virtual devices used by each VM.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe device types used by the VMs.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Ch5 id=\"reducing_vm_performance_loss\">Reducing VM performance loss\u003C/h5>\u003Cp>\n\t\t\t\tRHEL 9 provides a number of features you can use to reduce the negative performance effects of virtualization. Notably:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"#optimizing-virtual-machine-performance-using-tuned_optimizing-virtual-machine-performance-in-rhel\" title=\"13.2. Optimizing virtual machine performance by using TuneD\">The \u003Ccode class=\"literal\">TuneD\u003C/code> service\u003C/a> can automatically optimize the resource distribution and performance of your VMs.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"#optimizing-virtual-machine-i-o-performance_optimizing-virtual-machine-performance-in-rhel\" title=\"13.5. Optimizing virtual machine I/O performance\">Block I/O tuning\u003C/a> can improve the performances of the VM’s block devices, such as disks.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"#optimizing-virtual-machine-cpu-performance_optimizing-virtual-machine-performance-in-rhel\" title=\"13.6. Optimizing virtual machine CPU performance\">NUMA tuning\u003C/a> can increase vCPU performance.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"#optimizing-virtual-machine-network-performance_optimizing-virtual-machine-performance-in-rhel\" title=\"13.7. Optimizing virtual machine network performance\">Virtual networking\u003C/a> can be optimized in various ways.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tTuning VM performance can have negative effects on other virtualization functions. For example, it can make migrating the modified VM more difficult.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/section>\u003Csection class=\"section\" id=\"optimizing-virtual-machine-performance-using-tuned_optimizing-virtual-machine-performance-in-rhel\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">13.2. Optimizing virtual machine performance by using TuneD\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tThe \u003Ccode class=\"literal\">TuneD\u003C/code> utility is a tuning profile delivery mechanism that adapts RHEL for certain workload characteristics, such as requirements for CPU-intensive tasks or storage-network throughput responsiveness. It provides a number of tuning profiles that are pre-configured to enhance performance and reduce power consumption in a number of specific use cases. You can edit these profiles or create new profiles to create performance solutions tailored to your environment, including virtualized environments.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tTo optimize RHEL 9 for virtualization, use the following profiles:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tFor RHEL 9 virtual machines, use the \u003Cspan class=\"strong strong\">\u003Cstrong>virtual-guest\u003C/strong>\u003C/span> profile. It is based on the generally applicable \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>throughput-performance\u003C/em>\u003C/span>\u003C/code> profile, but also decreases the swappiness of virtual memory.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tFor RHEL 9 virtualization hosts, use the \u003Cspan class=\"strong strong\">\u003Cstrong>virtual-host\u003C/strong>\u003C/span> profile. This enables more aggressive writeback of dirty memory pages, which benefits the host performance.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">TuneD\u003C/code> service is \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-tuned_monitoring-and-managing-system-status-and-performance#installing-and-enabling-tuned_getting-started-with-tuned\">installed and enabled\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"formalpara\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cp>\n\t\t\t\t\tTo enable a specific \u003Ccode class=\"literal\">TuneD\u003C/code> profile:\n\t\t\t\t\u003C/p>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tList the available \u003Ccode class=\"literal\">TuneD\u003C/code> profiles.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>tuned-adm list\u003C/strong>\u003C/span>\n\nAvailable profiles:\n- balanced             - General non-specialized TuneD profile\n- desktop              - Optimize for the desktop use-case\n[...]\n- virtual-guest        - Optimize for running inside a virtual guest\n- virtual-host         - Optimize for running KVM guests\nCurrent active profile: \u003Cspan class=\"emphasis\">\u003Cem>balanced\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOptional: Create a new \u003Ccode class=\"literal\">TuneD\u003C/code> profile or edit an existing \u003Ccode class=\"literal\">TuneD\u003C/code> profile.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/customizing-tuned-profiles_monitoring-and-managing-system-status-and-performance\">Customizing TuneD profiles\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tActivate a \u003Ccode class=\"literal\">TuneD\u003C/code> profile.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>tuned-adm profile \u003Cspan class=\"emphasis\">\u003Cem>selected-profile\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tTo optimize a virtualization host, use the \u003Cspan class=\"emphasis\">\u003Cem>virtual-host\u003C/em>\u003C/span> profile.\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>tuned-adm profile virtual-host\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tOn a RHEL guest operating system, use the \u003Cspan class=\"emphasis\">\u003Cem>virtual-guest\u003C/em>\u003C/span> profile.\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>tuned-adm profile virtual-guest\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tDisplay the active profile for \u003Ccode class=\"literal\">TuneD\u003C/code>.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>tuned-adm active\u003C/strong>\u003C/span>\nCurrent active profile: virtual-host\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnsure that the \u003Ccode class=\"literal\">TuneD\u003C/code> profile settings have been applied on your system.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>tuned-adm verify\u003C/strong>\u003C/span>\nVerification succeeded, current system settings match the preset profile. See tuned log file ('/var/log/tuned/tuned.log') for details.\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/\">Monitoring and managing system status and performance\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"assembly_optimizing-libvirt-daemons_optimizing-virtual-machine-performance-in-rhel\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">13.3. Optimizing libvirt daemons\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tThe \u003Ccode class=\"literal\">libvirt\u003C/code> virtualization suite works as a management layer for the RHEL hypervisor, and your \u003Ccode class=\"literal\">libvirt\u003C/code> configuration significantly impacts your virtualization host. Notably, RHEL 9 contains two different types of \u003Ccode class=\"literal\">libvirt\u003C/code> daemons, monolithic or modular, and which type of daemons you use affects how granularly you can configure individual virtualization drivers.\n\t\t\t\u003C/p>\u003Csection class=\"section\" id=\"con_types-of-libvirt-daemons_assembly_optimizing-libvirt-daemons\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">13.3.1. Types of libvirt daemons\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tRHEL 9 supports the following \u003Ccode class=\"literal\">libvirt\u003C/code> daemon types:\n\t\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">Monolithic libvirt\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tThe traditional \u003Ccode class=\"literal\">libvirt\u003C/code> daemon, \u003Ccode class=\"literal\">libvirtd\u003C/code>, controls a wide variety of virtualization drivers, by using a single configuration file - \u003Ccode class=\"literal\">/etc/libvirt/libvirtd.conf\u003C/code>.\n\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tAs such, \u003Ccode class=\"literal\">libvirtd\u003C/code> allows for centralized hypervisor configuration, but may use system resources inefficiently. Therefore, \u003Ccode class=\"literal\">libvirtd\u003C/code> will become unsupported in a future major release of RHEL.\n\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tHowever, if you updated to RHEL 9 from RHEL 8, your host still uses \u003Ccode class=\"literal\">libvirtd\u003C/code> by default.\n\t\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Modular libvirt\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tNewly introduced in RHEL 9, modular \u003Ccode class=\"literal\">libvirt\u003C/code> provides a specific daemon for each virtualization driver. These include the following:\n\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>virtqemud\u003C/strong>\u003C/span> - A primary daemon for hypervisor management\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>virtinterfaced\u003C/strong>\u003C/span> - A secondary daemon for host NIC management\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>virtnetworkd\u003C/strong>\u003C/span> - A secondary daemon for virtual network management\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>virtnodedevd\u003C/strong>\u003C/span> - A secondary daemon for host physical device management\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>virtnwfilterd\u003C/strong>\u003C/span> - A secondary daemon for host firewall management\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>virtsecretd\u003C/strong>\u003C/span> - A secondary daemon for host secret management\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>virtstoraged\u003C/strong>\u003C/span> - A secondary daemon for storage management\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tEach of the daemons has a separate configuration file - for example \u003Ccode class=\"literal\">/etc/libvirt/virtqemud.conf\u003C/code>. As such, modular \u003Ccode class=\"literal\">libvirt\u003C/code> daemons provide better options for fine-tuning \u003Ccode class=\"literal\">libvirt\u003C/code> resource management.\n\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tIf you performed a fresh install of RHEL 9, modular \u003Ccode class=\"literal\">libvirt\u003C/code> is configured by default.\n\t\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Next steps\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tIf your RHEL 9 uses \u003Ccode class=\"literal\">libvirtd\u003C/code>, Red Hat recommends switching to modular daemons. For instructions, see \u003Ca class=\"link\" href=\"#proc_enabling-modular-libvirt-daemons_assembly_optimizing-libvirt-daemons\" title=\"13.3.2. Enabling modular libvirt daemons\">Enabling modular libvirt daemons\u003C/a>.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"proc_enabling-modular-libvirt-daemons_assembly_optimizing-libvirt-daemons\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">13.3.2. Enabling modular libvirt daemons\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tIn RHEL 9, the \u003Ccode class=\"literal\">libvirt\u003C/code> library uses modular daemons that handle individual virtualization driver sets on your host. For example, the \u003Ccode class=\"literal\">virtqemud\u003C/code> daemon handles QEMU drivers.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tIf you performed a fresh install of a RHEL 9 host, your hypervisor uses modular \u003Ccode class=\"literal\">libvirt\u003C/code> daemons by default. However, if you upgraded your host from RHEL 8 to RHEL 9, your hypervisor uses the monolithic \u003Ccode class=\"literal\">libvirtd\u003C/code> daemon, which is the default in RHEL 8.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tIf that is the case, Red Hat recommends enabling the modular \u003Ccode class=\"literal\">libvirt\u003C/code> daemons instead, because they provide better options for fine-tuning \u003Ccode class=\"literal\">libvirt\u003C/code> resource management. In addition, \u003Ccode class=\"literal\">libvirtd\u003C/code> will become unsupported in a future major release of RHEL.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tYour hypervisor is using the monolithic \u003Ccode class=\"literal\">libvirtd\u003C/code> service.\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl is-active libvirtd.service\u003C/strong>\u003C/span>\nactive\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIf this command displays \u003Ccode class=\"literal\">active\u003C/code>, you are using \u003Ccode class=\"literal\">libvirtd\u003C/code>.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tYour virtual machines are shut down.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tStop \u003Ccode class=\"literal\">libvirtd\u003C/code> and its sockets.\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl stop libvirtd.service\u003C/strong>\u003C/span>\n$ \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl stop libvirtd{,-ro,-admin,-tcp,-tls}.socket\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tDisable \u003Ccode class=\"literal\">libvirtd\u003C/code> to prevent it from starting on boot.\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl disable libvirtd.service\u003C/strong>\u003C/span>\n$ \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl disable libvirtd{,-ro,-admin,-tcp,-tls}.socket\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tEnable the modular \u003Ccode class=\"literal\">libvirt\u003C/code> daemons.\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>for drv in qemu interface network nodedev nwfilter secret storage; do systemctl unmask virt${drv}d.service; systemctl unmask virt${drv}d{,-ro,-admin}.socket; systemctl enable virt${drv}d.service; systemctl enable virt${drv}d{,-ro,-admin}.socket; done\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tStart the sockets for the modular daemons.\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>for drv in qemu network nodedev nwfilter secret storage; do systemctl start virt${drv}d{,-ro,-admin}.socket; done\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tOptional: If you require connecting to your host from remote hosts, enable and start the virtualization proxy daemon.\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tCheck whether the \u003Ccode class=\"literal\">libvirtd-tls.socket\u003C/code> service is enabled on your system.\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>grep listen_tls /etc/libvirt/libvirtd.conf\u003C/strong>\u003C/span>\n\nlisten_tls = 0\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tIf \u003Ccode class=\"literal\">libvirtd-tls.socket\u003C/code> is not enabled (\u003Ccode class=\"literal\">listen_tls = 0\u003C/code>), activate \u003Ccode class=\"literal\">virtproxyd\u003C/code> as follows:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl unmask virtproxyd.service\u003C/strong>\u003C/span>\n# \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl unmask virtproxyd{,-ro,-admin}.socket\u003C/strong>\u003C/span>\n# \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl enable virtproxyd.service\u003C/strong>\u003C/span>\n# \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl enable virtproxyd{,-ro,-admin}.socket\u003C/strong>\u003C/span>\n# \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl start virtproxyd{,-ro,-admin}.socket\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tIf \u003Ccode class=\"literal\">libvirtd-tls.socket\u003C/code> is enabled (\u003Ccode class=\"literal\">listen_tls = 1\u003C/code>), activate \u003Ccode class=\"literal\">virtproxyd\u003C/code> as follows:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl unmask virtproxyd.service\u003C/strong>\u003C/span>\n# \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl unmask virtproxyd{,-ro,-admin,-tls}.socket\u003C/strong>\u003C/span>\n# \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl enable virtproxyd.service\u003C/strong>\u003C/span>\n# \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl enable virtproxyd{,-ro,-admin,-tls}.socket\u003C/strong>\u003C/span>\n# \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl start virtproxyd{,-ro,-admin,-tls}.socket\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tTo enable the TLS socket of \u003Ccode class=\"literal\">virtproxyd\u003C/code>, your host must have TLS certificates configured to work with \u003Ccode class=\"literal\">libvirt\u003C/code>. For more information, see the \u003Ca class=\"link\" href=\"https://libvirt.org/kbase/tlscerts.html\">Upstream libvirt documentation\u003C/a>.\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tActivate the enabled virtualization daemons.\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virsh uri\u003C/strong>\u003C/span>\nqemu:///system\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tVerify that your host is using the \u003Ccode class=\"literal\">virtqemud\u003C/code> modular daemon.\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl is-active virtqemud.service\u003C/strong>\u003C/span>\nactive\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIf the status is \u003Ccode class=\"literal\">active\u003C/code>, you have successfully enabled modular \u003Ccode class=\"literal\">libvirt\u003C/code> daemons.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"section\" id=\"configuring-virtual-machine-ram_optimizing-virtual-machine-performance-in-rhel\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">13.4. Configuring virtual machine memory\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tTo improve the performance of a virtual machine (VM), you can assign additional host RAM to the VM. Similarly, you can decrease the amount of memory allocated to a VM so the host memory can be allocated to other VMs or tasks.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tTo perform these actions, you can use \u003Ca class=\"link\" href=\"#adding-and-removing-virtual-machine-ram-using-the-web-console_configuring-virtual-machine-ram\" title=\"13.4.1. Adding and removing virtual machine memory by using the web console\">the web console\u003C/a> or \u003Ca class=\"link\" href=\"#adding-and-removing-virtual-machine-ram-using-the-command-line-interface_configuring-virtual-machine-ram\" title=\"13.4.2. Adding and removing virtual machine memory by using the command-line interface\">the command-line interface\u003C/a>.\n\t\t\t\u003C/p>\u003Csection class=\"section\" id=\"adding-and-removing-virtual-machine-ram-using-the-web-console_configuring-virtual-machine-ram\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">13.4.1. Adding and removing virtual machine memory by using the web console\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tTo improve the performance of a virtual machine (VM) or to free up the host resources it is using, you can use the web console to adjust amount of memory allocated to the VM.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tYou have installed the RHEL 9 web console.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFor instructions, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console\">Installing and enabling the web console\u003C/a>.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe guest OS is running the memory balloon drivers. To verify this is the case:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tEnsure the VM’s configuration includes the \u003Ccode class=\"literal\">memballoon\u003C/code> device:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virsh dumpxml \u003Cspan class=\"emphasis\">\u003Cem>testguest\u003C/em>\u003C/span> | grep memballoon\u003C/strong>\u003C/span>\n&lt;memballoon model='virtio'&gt;\n    &lt;/memballoon&gt;\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tIf this commands displays any output and the model is not set to \u003Ccode class=\"literal\">none\u003C/code>, the \u003Ccode class=\"literal\">memballoon\u003C/code> device is present.\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tEnsure the balloon drivers are running in the guest OS.\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\tIn Windows guests, the drivers are installed as a part of the \u003Ccode class=\"literal\">virtio-win\u003C/code> driver package. For instructions, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/installing-and-managing-windows-virtual-machines-on-rhel_configuring-and-managing-virtualization#installing-kvm-paravirtualized-drivers-for-rhel-virtual-machines_optimizing-windows-virtual-machines-on-rhel\">Installing paravirtualized KVM drivers for Windows virtual machines\u003C/a>.\n\t\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\tIn Linux guests, the drivers are generally included by default and activate when the \u003Ccode class=\"literal\">memballoon\u003C/code> device is present.\n\t\t\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe web console VM plug-in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/managing-virtual-machines-in-the-web-console_configuring-and-managing-virtualization\">is installed on your system\u003C/a>.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tOptional: Obtain the information about the maximum memory and currently used memory for a VM. This will serve as a baseline for your changes, and also for verification.\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virsh dominfo \u003Cspan class=\"emphasis\">\u003Cem>testguest\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\nMax memory:     2097152 KiB\nUsed memory:    2097152 KiB\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tLog in to the RHEL 9 web console.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFor details, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#logging-in-to-the-web-console_getting-started-with-the-rhel-9-web-console\">Logging in to the web console\u003C/a>.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIn the \u003Cspan class=\"guimenu\">Virtual Machines\u003C/span> interface, click the VM whose information you want to see.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tA new page opens with an Overview section with basic information about the selected VM and a Console section to access the VM’s graphical interface.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tClick \u003Cspan class=\"guibutton\">edit\u003C/span> next to the \u003Ccode class=\"literal\">Memory\u003C/code> line in the Overview pane.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">Memory Adjustment\u003C/code> dialog appears.\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"informalfigure\">\u003Cdiv class=\"mediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/839e2ecc24d24759503df5eeb06e6888/virt-cockpit-memory.png\" width=\"540\" alt=\"Image displaying the VM memory adjustment dialog box.\"/>\u003C/div>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tConfigure the virtual memory for the selected VM.\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>Maximum allocation\u003C/strong>\u003C/span> - Sets the maximum amount of host memory that the VM can use for its processes. You can specify the maximum memory when creating the VM or increase it later. You can specify memory as multiples of MiB or GiB.\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tAdjusting maximum memory allocation is only possible on a shut-off VM.\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>Current allocation\u003C/strong>\u003C/span> - Sets the actual amount of memory allocated to the VM. This value can be less than the Maximum allocation but cannot exceed it. You can adjust the value to regulate the memory available to the VM for its processes. You can specify memory as multiples of MiB or GiB.\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tIf you do not specify this value, the default allocation is the \u003Cspan class=\"strong strong\">\u003Cstrong>Maximum allocation\u003C/strong>\u003C/span> value.\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tClick \u003Cspan class=\"guibutton\">Save\u003C/span>.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe memory allocation of the VM is adjusted.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/optimizing-virtual-machine-performance-in-rhel_configuring-and-managing-virtualization#adding-and-removing-virtual-machine-ram-using-the-command-line-interface_configuring-virtual-machine-ram\">Adding and removing virtual machine memory by using the command-line interface\u003C/a>\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/optimizing-virtual-machine-performance-in-rhel_configuring-and-managing-virtualization#optimizing-virtual-machine-cpu-performance_optimizing-virtual-machine-performance-in-rhel\">Optimizing virtual machine CPU performance\u003C/a>\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"adding-and-removing-virtual-machine-ram-using-the-command-line-interface_configuring-virtual-machine-ram\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">13.4.2. Adding and removing virtual machine memory by using the command-line interface\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tTo improve the performance of a virtual machine (VM) or to free up the host resources it is using, you can use the CLI to adjust amount of memory allocated to the VM.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe guest OS is running the memory balloon drivers. To verify this is the case:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tEnsure the VM’s configuration includes the \u003Ccode class=\"literal\">memballoon\u003C/code> device:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virsh dumpxml \u003Cspan class=\"emphasis\">\u003Cem>testguest\u003C/em>\u003C/span> | grep memballoon\u003C/strong>\u003C/span>\n&lt;memballoon model='virtio'&gt;\n    &lt;/memballoon&gt;\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tIf this commands displays any output and the model is not set to \u003Ccode class=\"literal\">none\u003C/code>, the \u003Ccode class=\"literal\">memballoon\u003C/code> device is present.\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tEnsure the ballon drivers are running in the guest OS.\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\tIn Windows guests, the drivers are installed as a part of the \u003Ccode class=\"literal\">virtio-win\u003C/code> driver package. For instructions, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/installing-and-managing-windows-virtual-machines-on-rhel_configuring-and-managing-virtualization#installing-kvm-paravirtualized-drivers-for-rhel-virtual-machines_optimizing-windows-virtual-machines-on-rhel\">Installing paravirtualized KVM drivers for Windows virtual machines\u003C/a>.\n\t\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\tIn Linux guests, the drivers are generally included by default and activate when the \u003Ccode class=\"literal\">memballoon\u003C/code> device is present.\n\t\t\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tOptional: Obtain the information about the maximum memory and currently used memory for a VM. This will serve as a baseline for your changes, and also for verification.\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virsh dominfo \u003Cspan class=\"emphasis\">\u003Cem>testguest\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\nMax memory:     2097152 KiB\nUsed memory:    2097152 KiB\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tAdjust the maximum memory allocated to a VM. Increasing this value improves the performance potential of the VM, and reducing the value lowers the performance footprint the VM has on your host. Note that this change can only be performed on a shut-off VM, so adjusting a running VM requires a reboot to take effect.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFor example, to change the maximum memory that the \u003Cspan class=\"emphasis\">\u003Cem>testguest\u003C/em>\u003C/span> VM can use to 4096 MiB:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virt-xml \u003Cspan class=\"emphasis\">\u003Cem>testguest\u003C/em>\u003C/span> --edit --memory memory=4096,currentMemory=4096\u003C/strong>\u003C/span>\nDomain 'testguest' defined successfully.\nChanges will take effect after the domain is fully powered off.\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tTo increase the maximum memory of a running VM, you can attach a memory device to the VM. This is also referred to as \u003Cspan class=\"strong strong\">\u003Cstrong>memory hot plug\u003C/strong>\u003C/span>. For details, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/managing-virtual-devices_configuring-and-managing-virtualization#attaching-devices-to-virtual-machines_assembly_managing-virtual-devices-using-the-cli\">Attaching devices to virtual machines\u003C/a>.\n\t\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition warning\" state=\"danger\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Warning\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\t\tRemoving memory devices from a running VM (also referred as a memory hot unplug) is not supported, and highly discouraged by Red Hat.\n\t\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tOptional: You can also adjust the memory currently used by the VM, up to the maximum allocation. This regulates the memory load that the VM has on the host until the next reboot, without changing the maximum VM allocation.\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virsh setmem \u003Cspan class=\"emphasis\">\u003Cem>testguest\u003C/em>\u003C/span> --current 2048\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tConfirm that the memory used by the VM has been updated:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virsh dominfo \u003Cspan class=\"emphasis\">\u003Cem>testguest\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\nMax memory:     4194304 KiB\nUsed memory:    2097152 KiB\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tOptional: If you adjusted the current VM memory, you can obtain the memory balloon statistics of the VM to evaluate how effectively it regulates its memory use.\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"> # \u003Cspan class=\"strong strong\">\u003Cstrong>virsh domstats --balloon \u003Cspan class=\"emphasis\">\u003Cem>testguest\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\nDomain: 'testguest'\n  balloon.current=365624\n  balloon.maximum=4194304\n  balloon.swap_in=0\n  balloon.swap_out=0\n  balloon.major_fault=306\n  balloon.minor_fault=156117\n  balloon.unused=3834448\n  balloon.available=4035008\n  balloon.usable=3746340\n  balloon.last-update=1587971682\n  balloon.disk_caches=75444\n  balloon.hugetlb_pgalloc=0\n  balloon.hugetlb_pgfail=0\n  balloon.rss=1005456\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/optimizing-virtual-machine-performance-in-rhel_configuring-and-managing-virtualization#adding-and-removing-virtual-machine-ram-using-the-web-console_configuring-virtual-machine-ram\">Adding and removing virtual machine memory by using the web console\u003C/a>\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/optimizing-virtual-machine-performance-in-rhel_configuring-and-managing-virtualization#optimizing-virtual-machine-cpu-performance_optimizing-virtual-machine-performance-in-rhel\">Optimizing virtual machine CPU performance\u003C/a>\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"adding-and-removing-virtual-machine-memory-by-using-virtio-mem_configuring-virtual-machine-ram\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">13.4.3. Adding and removing virtual machine memory by using virtio-mem\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tRHEL 9 provides the \u003Ccode class=\"literal\">virtio-mem\u003C/code> paravirtualized memory device. This device makes it possible to dynamically add or remove host memory in virtual machines (VMs). For example, you can use \u003Ccode class=\"literal\">virtio-mem\u003C/code> to move memory resources between running VMs or to resize VM memory in cloud setups based on your current requirements.\n\t\t\t\t\u003C/p>\u003Csection class=\"section\" id=\"overview-of-virtio-mem_adding-and-removing-virtual-machine-memory-by-using-virtio-mem\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch5 class=\"title\">13.4.3.1. Overview of virtio-mem\u003C/h5>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\t\t\u003Ccode class=\"literal\">virtio-mem\u003C/code> is a paravirtualized memory device that can be used to dynamically add or remove host memory in virtual machines (VMs). For example, you can use this device to move memory resources between running VMs or to resize VM memory in cloud setups based on your current requirements.\n\t\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\t\tBy using \u003Ccode class=\"literal\">virtio-mem\u003C/code>, you can increase the memory of a VM beyond its initial size, and shrink it back to its original size, in units that can have the size of 4 to several hundred mebibytes (MiBs). Note, however, that \u003Ccode class=\"literal\">virtio-mem\u003C/code> also relies on a specific guest operating system configuration, especially to reliably unplug memory.\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"formalpara\">\u003Cp class=\"title\">\u003Cstrong>virtio-mem feature limitations\u003C/strong>\u003C/p>\u003Cp>\n\t\t\t\t\t\t\t\u003Ccode class=\"literal\">virtio-mem\u003C/code> is currently not compatible with the following features:\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tUsing memory locking for real-time applications on the host\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tUsing encrypted virtualization on the host\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tCombining \u003Ccode class=\"literal\">virtio-mem\u003C/code> with \u003Ccode class=\"literal\">memballoon\u003C/code> inflation and deflation on the host\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tUnloading or reloading the \u003Ccode class=\"literal\">virtio_mem\u003C/code> driver in a VM\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tUsing vhost-user devices, with the exception of \u003Ccode class=\"literal\">virtiofs\u003C/code>\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"#configuring-memory-onlining-in-virtual-machines_adding-and-removing-virtual-machine-memory-by-using-virtio-mem\" title=\"13.4.3.2. Configuring memory onlining in virtual machines\">Configuring memory onlining in virtual machines\u003C/a>\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"#attaching-a-virtio-mem-device-to-virtual-machines_adding-and-removing-virtual-machine-memory-by-using-virtio-mem\" title=\"13.4.3.3. Attaching a virtio-mem device to virtual machines\">Attaching a virtio-mem device to virtual machines\u003C/a>\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"configuring-memory-onlining-in-virtual-machines_adding-and-removing-virtual-machine-memory-by-using-virtio-mem\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch5 class=\"title\">13.4.3.2. Configuring memory onlining in virtual machines\u003C/h5>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\t\tBefore using \u003Ccode class=\"literal\">virtio-mem\u003C/code> to attach memory to a running virtual machine (also known as memory hot-plugging), you must configure the virtual machine (VM) operating system to automatically set the hot-plugged memory to an online state. Otherwise, the guest operating system is not able to use the additional memory. You can choose from one of the following configurations for memory onlining:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">online_movable\u003C/code>\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">online_kernel\u003C/code>\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">auto-movable\u003C/code>\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\t\t\tTo learn about differences between these configurations, see: \u003Ca class=\"link\" href=\"#comparison-of-memory-onlining-configurations_adding-and-removing-virtual-machine-memory-by-using-virtio-mem\" title=\"13.4.3.4. Comparison of memory onlining configurations\">Comparison of memory onlining configurations\u003C/a>\n\t\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\t\tMemory onlining is configured with udev rules by default in RHEL. However, when using \u003Ccode class=\"literal\">virtio-mem\u003C/code>, it is recommended to configure memory onlining directly in the kernel.\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe host uses the Intel 64, AMD64, or ARM 64 CPU architecture.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe host uses RHEL 9.4 or later as the operating system.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tVMs running on the host use one of the following operating system versions:\n\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\tRHEL 8.10\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\t\t\t\t\tUnplugging memory from a running VM is disabled by default in RHEL 8.10 VMs.\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\tRHEL 9\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tTo set memory onlining to use the \u003Ccode class=\"literal\">online_movable\u003C/code> configuration in the VM:\n\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\tSet the \u003Ccode class=\"literal\">memhp_default_state\u003C/code> kernel command line parameter to \u003Ccode class=\"literal\">online_movable\u003C/code>:\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>grubby --update-kernel=ALL --remove-args=memhp_default_state --args=memhp_default_state=online_movable\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\tReboot the VM.\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tTo set memory onlining to use the \u003Ccode class=\"literal\">online_kernel\u003C/code> configuration in the VM:\n\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\tSet the \u003Ccode class=\"literal\">memhp_default_state\u003C/code> kernel command line parameter to \u003Ccode class=\"literal\">online_kernel\u003C/code>:\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>grubby --update-kernel=ALL --remove-args=memhp_default_state --args=memhp_default_state=online_kernel\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\tReboot the VM.\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tTo use the \u003Ccode class=\"literal\">auto-movable\u003C/code> memory onlining policy in the VM:\n\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\tSet the \u003Ccode class=\"literal\">memhp_default_state\u003C/code> kernel command line parameter to \u003Ccode class=\"literal\">online\u003C/code>:\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>grubby --update-kernel=ALL --remove-args=memhp_default_state --args=memhp_default_state=online\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\tSet the \u003Ccode class=\"literal\">memory_hotplug.online_policy\u003C/code> kernel command line parameter to \u003Ccode class=\"literal\">auto-movable\u003C/code>:\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>grubby --update-kernel=ALL --remove-args=\"memory_hotplug.online_policy\" --args=memory_hotplug.online_policy=auto-movable\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\tOptional: To further tune the \u003Ccode class=\"literal\">auto-movable\u003C/code> onlining policy, change the \u003Ccode class=\"literal\">memory_hotplug.auto_movable_ratio\u003C/code> and \u003Ccode class=\"literal\">memory_hotplug.auto_movable_numa_aware\u003C/code> parameters:\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>grubby --update-kernel=ALL --remove-args=\"memory_hotplug.auto_movable_ratio\" --args=memory_hotplug.auto_movable_ratio=\u003Cspan class=\"emphasis\">\u003Cem>&lt;percentage&gt;\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\n\n# \u003Cspan class=\"strong strong\">\u003Cstrong>grubby --update-kernel=ALL --remove-args=\"memory_hotplug.memory_auto_movable_numa_aware\" --args=memory_hotplug.auto_movable_numa_aware=\u003Cspan class=\"emphasis\">\u003Cem>&lt;y/n&gt;\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">memory_hotplug.auto_movable_ratio parameter\u003C/code> sets the maximum ratio of memory only available for movable allocations compared to memory available for any allocations. The ratio is expressed in percents and the default value is: \u003Cspan class=\"emphasis\">\u003Cem>301\u003C/em>\u003C/span> (%), which is a 3:1 ratio.\n\t\t\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">memory_hotplug.auto_movable_numa_aware\u003C/code> parameter controls whether the \u003Ccode class=\"literal\">memory_hotplug.auto_movable_ratio\u003C/code> parameter applies to memory across all available NUMA nodes or only for memory within a single NUMA node. The default value is: \u003Cspan class=\"emphasis\">\u003Cem>y\u003C/em>\u003C/span> (yes)\n\t\t\t\t\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\t\t\tFor example, if the maximum ratio is set to 301% and the \u003Ccode class=\"literal\">memory_hotplug.auto_movable_numa_aware\u003C/code> is set to \u003Cspan class=\"emphasis\">\u003Cem>y\u003C/em>\u003C/span> (yes), than the 3:1 ratio is applied even within the NUMA node with the attached \u003Ccode class=\"literal\">virtio-mem\u003C/code> device. If the parameter is set to \u003Cspan class=\"emphasis\">\u003Cem>n\u003C/em>\u003C/span> (no), the maximum 3:1 ratio is applied only for all the NUMA nodes as a whole.\n\t\t\t\t\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\t\t\tAdditionally, if the ratio is not exceeded, the newly hot-plugged memory will be available only for movable allocations. Otherwise, the newly hot-plugged memory will be available for both movable and unmovable allocations.\n\t\t\t\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\tReboot the VM.\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tTo see if the \u003Ccode class=\"literal\">online_movable\u003C/code> configuration has been set correctly, check the current value of the \u003Ccode class=\"literal\">memhp_default_state\u003C/code> kernel parameter:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>cat /sys/devices/system/memory/auto_online_blocks\u003C/strong>\u003C/span>\n\nonline_movable\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tTo see if the \u003Ccode class=\"literal\">online_kernel\u003C/code> configuration has been set correctly, check the current value of the \u003Ccode class=\"literal\">memhp_default_state\u003C/code> kernel parameter:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>cat /sys/devices/system/memory/auto_online_blocks\u003C/strong>\u003C/span>\n\nonline_kernel\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tTo see if the \u003Ccode class=\"literal\">auto-movable\u003C/code> configuration has been set correctly, check the following kernel parameters:\n\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">memhp_default_state\u003C/code>:\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>cat /sys/devices/system/memory/auto_online_blocks\u003C/strong>\u003C/span>\n\nonline\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">memory_hotplug.online_policy\u003C/code>:\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>cat /sys/module/memory_hotplug/parameters/online_policy\u003C/strong>\u003C/span>\n\nauto-movable\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">memory_hotplug.auto_movable_ratio\u003C/code>:\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>cat /sys/module/memory_hotplug/parameters/auto_movable_ratio\u003C/strong>\u003C/span>\n\n301\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">memory_hotplug.auto_movable_numa_aware\u003C/code>:\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>cat /sys/module/memory_hotplug/parameters/auto_movable_numa_aware\u003C/strong>\u003C/span>\n\ny\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"#overview-of-virtio-mem_adding-and-removing-virtual-machine-memory-by-using-virtio-mem\" title=\"13.4.3.1. Overview of virtio-mem\">Overview of virtio-mem\u003C/a>\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"#attaching-a-virtio-mem-device-to-virtual-machines_adding-and-removing-virtual-machine-memory-by-using-virtio-mem\" title=\"13.4.3.3. Attaching a virtio-mem device to virtual machines\">Attaching a virtio-mem device to virtual machines\u003C/a>\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://www.kernel.org/doc/html/latest/admin-guide/mm/memory-hotplug.html#configuring-memory-hot-un-plug\">Configuring Memory Hot(Un)Plug\u003C/a>\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"attaching-a-virtio-mem-device-to-virtual-machines_adding-and-removing-virtual-machine-memory-by-using-virtio-mem\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch5 class=\"title\">13.4.3.3. Attaching a virtio-mem device to virtual machines\u003C/h5>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\t\tTo attach additional memory to a running virtual machine (also known as memory hot-plugging) and afterwards be able to resize the hot-plugged memory, you can use a \u003Ccode class=\"literal\">virtio-mem\u003C/code> device. Specifically, you can use libvirt XML configuration files and \u003Ccode class=\"literal\">virsh\u003C/code> commands to define and attach \u003Ccode class=\"literal\">virtio-mem\u003C/code> devices to virtual machines (VMs).\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe host uses the Intel 64, AMD64, or ARM 64 CPU architecture.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe host uses RHEL 9.4 or later as the operating system.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tVMs running on the host use one of the following operating system versions:\n\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\tRHEL 8.10\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\t\t\t\t\tUnplugging memory from a running VM is disabled by default in RHEL 8.10 VMs.\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\tRHEL 9\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe VM has memory onlining configured. For instructions, see: \u003Ca class=\"link\" href=\"#configuring-memory-onlining-in-virtual-machines_adding-and-removing-virtual-machine-memory-by-using-virtio-mem\" title=\"13.4.3.2. Configuring memory onlining in virtual machines\">Configuring memory onlining in virtual machines\u003C/a>\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tEnsure the XML configuration of the target VM includes the \u003Ccode class=\"literal\">maxMemory\u003C/code> parameter:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virsh edit testguest1\u003C/strong>\u003C/span>\n\n&lt;domain type='kvm'&gt;\n  &lt;name&gt;testguest1&lt;/name&gt;\n  ...\n  \u003Cspan class=\"strong strong\">\u003Cstrong>&lt;maxMemory unit='GiB'&gt;128&lt;/maxMemory&gt;\u003C/strong>\u003C/span>\n  ...\n&lt;/domain&gt;\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tIn this example, the XML configuration of the \u003Ccode class=\"literal\">testguest1\u003C/code> VM defines a \u003Ccode class=\"literal\">maxMemory\u003C/code> parameter with a 128 gibibyte (GiB) size. The \u003Ccode class=\"literal\">maxMemory\u003C/code> size specifies the maximum memory the VM can use, which includes both initial and hot-plugged memory.\n\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tCreate and open an XML file to define \u003Ccode class=\"literal\">virtio-mem\u003C/code> devices on the host, for example:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>vim virtio-mem-device.xml\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tAdd XML definitions of \u003Ccode class=\"literal\">virtio-mem\u003C/code> devices to the file and save it:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"programlisting language-xml\">&lt;memory model='virtio-mem'&gt;\n        &lt;target&gt;\n                &lt;size unit='GiB'&gt;48&lt;/size&gt;\n                &lt;node&gt;0&lt;/node&gt;\n                &lt;block unit='MiB'&gt;2&lt;/block&gt;\n                &lt;requested unit='GiB'&gt;16&lt;/requested&gt;\n                &lt;current unit='GiB'&gt;16&lt;/current&gt;\n        &lt;/target&gt;\n        &lt;alias name='ua-virtiomem0'/&gt;\n        &lt;address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x0'/&gt;\n&lt;/memory&gt;\n&lt;memory model='virtio-mem'&gt;\n        &lt;target&gt;\n                &lt;size unit='GiB'&gt;48&lt;/size&gt;\n                &lt;node&gt;1&lt;/node&gt;\n                &lt;block unit='MiB'&gt;2&lt;/block&gt;\n                &lt;requested unit='GiB'&gt;0&lt;/requested&gt;\n                &lt;current unit='GiB'&gt;0&lt;/current&gt;\n        &lt;/target&gt;\n        &lt;alias name='ua-virtiomem1'/&gt;\n        &lt;address type='pci' domain='0x0000' bus='0x00' slot='0x04' function='0x0'/&gt;\n&lt;/memory&gt;\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tIn this example, two \u003Ccode class=\"literal\">virtio-mem\u003C/code> devices are defined with the following parameters:\n\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">size\u003C/code>: This is the maximum size of the device. In the example, it is 48 GiB. The \u003Ccode class=\"literal\">size\u003C/code> must be a multiple of the \u003Ccode class=\"literal\">block\u003C/code> size.\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">node\u003C/code>: This is the assigned vNUMA node for the \u003Ccode class=\"literal\">virtio-mem\u003C/code> device.\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">block\u003C/code>: This is the block size of the device. It must be at least the size of the Transparent Huge Page (THP), which is 2 MiB on Intel 64 and AMD64 CPU architecture. On ARM64 architecture, the size of THP can be 2 MiB or 512 MiB depending on the base page size. The 2 MiB block size on Intel 64 or AMD64 architecture is usually a good default choice. When using \u003Ccode class=\"literal\">virtio-mem\u003C/code> with \u003Cspan class=\"emphasis\">\u003Cem>Virtual Function I/O (VFIO)\u003C/em>\u003C/span> or \u003Cspan class=\"emphasis\">\u003Cem>mediated devices (mdev)\u003C/em>\u003C/span>, the total number of blocks across all \u003Ccode class=\"literal\">virtio-mem\u003C/code> devices must not be larger than 32768, otherwise the plugging of RAM might fail.\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">requested\u003C/code>: This is the amount of memory you attach to the VM with the \u003Ccode class=\"literal\">virtio-mem\u003C/code> device. However, it is just a request towards the VM and it might not be resolved successfully, for example if the VM is not properly configured. The \u003Ccode class=\"literal\">requested\u003C/code> size must be a multiple of the \u003Ccode class=\"literal\">block\u003C/code> size and cannot exceed the maximum defined \u003Ccode class=\"literal\">size\u003C/code>.\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">current\u003C/code>: This represents the current size the \u003Ccode class=\"literal\">virtio-mem\u003C/code> device provides to the VM. The \u003Ccode class=\"literal\">current\u003C/code> size can differ from the \u003Ccode class=\"literal\">requested\u003C/code> size, for example when requests cannot be completed or when rebooting the VM.\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">alias\u003C/code>: This is an optional user-defined alias that you can use to specify the intended \u003Ccode class=\"literal\">virtio-mem\u003C/code> device, for example when editing the device with libvirt commands. All user-defined aliases in libvirt must start with the \u003Cspan class=\"emphasis\">\u003Cem>\"ua-\"\u003C/em>\u003C/span> prefix.\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\tApart from these specific parameters, \u003Ccode class=\"literal\">libvirt\u003C/code> handles the \u003Ccode class=\"literal\">virtio-mem\u003C/code> device like any other PCI device.\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tUse the XML file to attach the defined \u003Ccode class=\"literal\">virtio-mem\u003C/code> devices to a VM. For example, to permanently attach the two devices defined in the \u003Ccode class=\"literal\">virtio-mem-device.xml\u003C/code> to the running \u003Ccode class=\"literal\">testguest1\u003C/code> VM:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virsh attach-device testguest1 virtio-mem-device.xml --live --config\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">--live\u003C/code> option attaches the device to a running VM only, without persistence between boots. The \u003Ccode class=\"literal\">--config\u003C/code> option makes the configuration changes persistent. You can also attach the device to a shutdown VM without the \u003Ccode class=\"literal\">--live\u003C/code> option.\n\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tOptional: To dynamically change the \u003Ccode class=\"literal\">requested\u003C/code> size of a \u003Ccode class=\"literal\">virtio-mem\u003C/code> device attached to a running VM, use the \u003Ccode class=\"literal\">virsh update-memory-device\u003C/code> command:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virsh update-memory-device testguest1 --alias ua-virtiomem0 --requested-size 4GiB\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tIn this example:\n\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">testguest1\u003C/code> is the VM you want to update.\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">--alias ua-virtiomem0\u003C/code> is the \u003Ccode class=\"literal\">virtio-mem\u003C/code> device specified by a previously defined alias.\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">--requested-size 4GiB\u003C/code> changes the \u003Ccode class=\"literal\">requested\u003C/code> size of the \u003Ccode class=\"literal\">virtio-mem\u003C/code> device to 4 GiB.\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition warning\" state=\"danger\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Warning\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\t\t\t\t\tUnplugging memory from a running VM by reducing the \u003Ccode class=\"literal\">requested\u003C/code> size might be unreliable. Whether this process succeeds depends on various factors, such as the memory onlining policy that is used.\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\t\t\t\t\t\t\tIn some cases, the guest operating system cannot complete the request successfully, because changing the amount of hot-plugged memory is not possible at that time.\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\t\t\t\t\t\t\tAdditionally, unplugging memory from a running VM is disabled by default in RHEL 8.10 VMs.\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tOptional: To unplug a \u003Ccode class=\"literal\">virtio-mem\u003C/code> device from a shut-down VM, use the \u003Ccode class=\"literal\">virsh detach-device\u003C/code> command:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virsh detach-device testguest1 virtio-mem-device.xml\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tOptional: To unplug a \u003Ccode class=\"literal\">virtio-mem\u003C/code> device from a running VM:\n\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\tChange the \u003Ccode class=\"literal\">requested\u003C/code> size of the \u003Ccode class=\"literal\">virtio-mem\u003C/code> device to 0, otherwise the attempt to unplug a \u003Ccode class=\"literal\">virtio-mem\u003C/code> device from a running VM will fail.\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virsh update-memory-device testguest1 --alias ua-virtiomem0 --requested-size 0\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\tUnplug a \u003Ccode class=\"literal\">virtio-mem\u003C/code> device from the running VM:\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virsh detach-device testguest1 virtio-mem-device.xml --config\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tIn the VM, check the available RAM and see if the total amount now includes the hot-plugged memory:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>free -h\u003C/strong>\u003C/span>\n\n        total    used    free   shared  buff/cache   available\nMem:    31Gi     5.5Gi   14Gi   1.3Gi   11Gi         23Gi\nSwap:   8.0Gi    0B      8.0Gi\u003C/pre>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>numactl -H\u003C/strong>\u003C/span>\n\navailable: 1 nodes (0)\nnode 0 cpus: 0 1 2 3 4 5 6 7\nnode 0 size: 29564 MB\nnode 0 free: 13351 MB\nnode distances:\nnode   0\n  0:  10\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tThe current amount of plugged-in RAM can be also viewed on the host by displaying the XML configuration of the running VM:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virsh dumpxml testguest1\u003C/strong>\u003C/span>\n\n&lt;domain type='kvm'&gt;\n  &lt;name&gt;testguest1&lt;/name&gt;\n  ...\n  \u003Cspan class=\"strong strong\">\u003Cstrong>&lt;currentMemory unit='GiB'&gt;31&lt;/currentMemory&gt;\u003C/strong>\u003C/span>\n  ...\n  &lt;memory model='virtio-mem'&gt;\n      &lt;target&gt;\n        &lt;size unit='GiB'&gt;48&lt;/size&gt;\n        &lt;node&gt;0&lt;/node&gt;\n        &lt;block unit='MiB'&gt;2&lt;/block&gt;\n        &lt;requested unit='GiB'&gt;16&lt;/requested&gt;\n        \u003Cspan class=\"strong strong\">\u003Cstrong>&lt;current unit='GiB'&gt;16&lt;/current&gt;\u003C/strong>\u003C/span>\n      &lt;/target&gt;\n      &lt;alias name='ua-virtiomem0'/&gt;\n      &lt;address type='pci' domain='0x0000' bus='0x08' slot='0x00' function='0x0'/&gt;\n  ...\n&lt;/domain&gt;\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tIn this example:\n\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">&lt;currentMemory unit='GiB'&gt;31&lt;/currentMemory&gt;\u003C/code> represents the total RAM available in the VM from all sources.\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">&lt;current unit='GiB'&gt;16&lt;/current&gt;\u003C/code> represents the current size of the plugged-in RAM provided by the \u003Ccode class=\"literal\">virtio-mem\u003C/code> device.\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"#overview-of-virtio-mem_adding-and-removing-virtual-machine-memory-by-using-virtio-mem\" title=\"13.4.3.1. Overview of virtio-mem\">Overview of virtio-mem\u003C/a>\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"#configuring-memory-onlining-in-virtual-machines_adding-and-removing-virtual-machine-memory-by-using-virtio-mem\" title=\"13.4.3.2. Configuring memory onlining in virtual machines\">Configuring memory onlining in virtual machines\u003C/a>\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"comparison-of-memory-onlining-configurations_adding-and-removing-virtual-machine-memory-by-using-virtio-mem\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch5 class=\"title\">13.4.3.4. Comparison of memory onlining configurations\u003C/h5>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\t\tWhen attaching memory to a running RHEL virtual machine (also known as memory hot-plugging), you must set the hot-plugged memory to an online state in the virtual machine (VM) operating system. Otherwise, the system will not be able to use the memory.\n\t\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\t\tThe following table summarizes the main considerations when choosing between the available memory onlining configurations.\n\t\t\t\t\t\u003C/p>\u003Crh-table id=\"idm140280133393392\">\u003Ctable class=\"gt-4-cols lt-7-rows\">\u003Ccaption>Table 13.1. Comparison of memory onlining configurations\u003C/caption>\u003Ccolgroup>\u003Ccol style=\"width: 20%; \" class=\"col_1\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 20%; \" class=\"col_2\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 20%; \" class=\"col_3\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 20%; \" class=\"col_4\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 20%; \" class=\"col_5\">\u003C!--Empty-->\u003C/col>\u003C/colgroup>\u003Cthead>\u003Ctr>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280134453664\" scope=\"col\">Configuration name\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280134452576\" scope=\"col\">Unplugging memory from a VM\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280134451520\" scope=\"col\">A risk of creating a memory zone imbalance\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280134450400\" scope=\"col\">A potential use case\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280134449312\" scope=\"col\">Memory requirements of the intended workload\u003C/th>\u003C/tr>\u003C/thead>\u003Ctbody>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280134453664\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">online_movable\u003C/code>\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280134452576\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\tHot-plugged memory can be reliably unplugged.\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280134451520\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\tYes\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280134450400\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\tHot-plugging a comparatively small amount of memory\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280134449312\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\tMostly user-space memory\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280134453664\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">auto-movable\u003C/code>\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280134452576\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\tMovable portions of hot-plugged memory can be reliably unplugged.\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280134451520\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\tMinimal\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280134450400\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\tHot-plugging a large amount of memory\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280134449312\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\tMostly user-space memory\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280134453664\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">online_kernel\u003C/code>\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280134452576\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\tHot-plugged memory cannot be reliably unplugged.\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280134451520\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\tNo\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280134450400\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\tUnreliable memory unplugging is acceptable.\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280134449312\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\tUser-space or kernel-space memory\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\u003C/rh-table>\u003Cp>\n\t\t\t\t\t\tA \u003Cspan class=\"emphasis\">\u003Cem>zone imbalance\u003C/em>\u003C/span> is a lack of available memory pages in one of the Linux memory zones. A \u003Cspan class=\"emphasis\">\u003Cem>zone imbalance\u003C/em>\u003C/span> can negatively impact the system performance. For example, the kernel might crash if it runs out of free memory for unmovable allocations. Usually, movable allocations contain mostly user-space memory pages and unmovable allocations contain mostly kernel-space memory pages.\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://www.kernel.org/doc/html/latest/admin-guide/mm/memory-hotplug.html#onlining-and-offlining-memory-blocks\">Onlining and Offlining Memory Blocks\u003C/a>\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://www.kernel.org/doc/html/latest/admin-guide/mm/memory-hotplug.html#zone-movable\">Zone Imbalances\u003C/a>\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"#configuring-memory-onlining-in-virtual-machines_adding-and-removing-virtual-machine-memory-by-using-virtio-mem\" title=\"13.4.3.2. Configuring memory onlining in virtual machines\">Configuring memory onlining in virtual machines\u003C/a>\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"section _additional-resources\" id=\"additional_resources\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">13.4.4. Additional resources\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tAttaching devices to virtual machines \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/managing-virtual-devices_configuring-and-managing-virtualization#attaching-devices-to-virtual-machines_assembly_managing-virtual-devices-using-the-cli\">Attaching devices to virtual machines\u003C/a>.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"section\" id=\"optimizing-virtual-machine-i-o-performance_optimizing-virtual-machine-performance-in-rhel\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">13.5. Optimizing virtual machine I/O performance\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tThe input and output (I/O) capabilities of a virtual machine (VM) can significantly limit the VM’s overall efficiency. To address this, you can optimize a VM’s I/O by configuring block I/O parameters.\n\t\t\t\u003C/p>\u003Csection class=\"section\" id=\"tuning-block-i-o-in-virtual-machines_optimizing-virtual-machine-i-o-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">13.5.1. Tuning block I/O in virtual machines\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tWhen multiple block devices are being used by one or more VMs, it might be important to adjust the I/O priority of specific virtual devices by modifying their \u003Cspan class=\"emphasis\">\u003Cem>I/O weights\u003C/em>\u003C/span>.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tIncreasing the I/O weight of a device increases its priority for I/O bandwidth, and therefore provides it with more host resources. Similarly, reducing a device’s weight makes it consume less host resources.\n\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\tEach device’s \u003Ccode class=\"literal\">weight\u003C/code> value must be within the \u003Ccode class=\"literal\">100\u003C/code> to \u003Ccode class=\"literal\">1000\u003C/code> range. Alternatively, the value can be \u003Ccode class=\"literal\">0\u003C/code>, which removes that device from per-device listings.\n\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"formalpara\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cp>\n\t\t\t\t\t\tTo display and set a VM’s block I/O parameters:\n\t\t\t\t\t\u003C/p>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tDisplay the current \u003Ccode class=\"literal\">&lt;blkio&gt;\u003C/code> parameters for a VM:\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\u003Ccode class=\"literal\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virsh dumpxml \u003Cspan class=\"emphasis\">\u003Cem>VM-name\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/code>\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"programlisting language-xml\">&lt;domain&gt;\n  [...]\n  &lt;blkiotune&gt;\n    &lt;weight&gt;800&lt;/weight&gt;\n    &lt;device&gt;\n      &lt;path&gt;/dev/sda&lt;/path&gt;\n      &lt;weight&gt;1000&lt;/weight&gt;\n    &lt;/device&gt;\n    &lt;device&gt;\n      &lt;path&gt;/dev/sdb&lt;/path&gt;\n      &lt;weight&gt;500&lt;/weight&gt;\n    &lt;/device&gt;\n  &lt;/blkiotune&gt;\n  [...]\n&lt;/domain&gt;\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tEdit the I/O weight of a specified device:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virsh blkiotune \u003Cspan class=\"emphasis\">\u003Cem>VM-name\u003C/em>\u003C/span> --device-weights \u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span>, \u003Cspan class=\"emphasis\">\u003Cem>I/O-weight\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFor example, the following changes the weight of the \u003Cspan class=\"emphasis\">\u003Cem>/dev/sda\u003C/em>\u003C/span> device in the \u003Cspan class=\"emphasis\">\u003Cem>testguest1\u003C/em>\u003C/span> VM to 500.\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virsh blkiotune testguest1 --device-weights /dev/sda, 500\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"disk-i-o-throttling-in-virtual-machines_optimizing-virtual-machine-i-o-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">13.5.2. Disk I/O throttling in virtual machines\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tWhen several VMs are running simultaneously, they can interfere with system performance by using excessive disk I/O. Disk I/O throttling in KVM virtualization provides the ability to set a limit on disk I/O requests sent from the VMs to the host machine. This can prevent a VM from over-utilizing shared resources and impacting the performance of other VMs.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tTo enable disk I/O throttling, set a limit on disk I/O requests sent from each block device attached to VMs to the host machine.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tUse the \u003Ccode class=\"literal\">virsh domblklist\u003C/code> command to list the names of all the disk devices on a specified VM.\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virsh domblklist rollin-coal\u003C/strong>\u003C/span>\nTarget     Source\n------------------------------------------------\nvda        /var/lib/libvirt/images/rollin-coal.qcow2\nsda        -\nsdb        /home/horridly-demanding-processes.iso\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFind the host block device where the virtual disk that you want to throttle is mounted.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFor example, if you want to throttle the \u003Ccode class=\"literal\">sdb\u003C/code> virtual disk from the previous step, the following output shows that the disk is mounted on the \u003Ccode class=\"literal\">/dev/nvme0n1p3\u003C/code> partition.\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>lsblk\u003C/strong>\u003C/span>\nNAME                                          MAJ:MIN RM   SIZE RO TYPE  MOUNTPOINT\nzram0                                         252:0    0     4G  0 disk  [SWAP]\nnvme0n1                                       259:0    0 238.5G  0 disk\n├─nvme0n1p1                                   259:1    0   600M  0 part  /boot/efi\n├─nvme0n1p2                                   259:2    0     1G  0 part  /boot\n└─nvme0n1p3                                   259:3    0 236.9G  0 part\n  └─luks-a1123911-6f37-463c-b4eb-fxzy1ac12fea 253:0    0 236.9G  0 crypt /home\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tSet I/O limits for the block device by using the \u003Ccode class=\"literal\">virsh blkiotune\u003C/code> command.\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virsh blkiotune \u003Cspan class=\"emphasis\">\u003Cem>VM-name\u003C/em>\u003C/span> --parameter \u003Cspan class=\"emphasis\">\u003Cem>device\u003C/em>\u003C/span>,\u003Cspan class=\"emphasis\">\u003Cem>limit\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe following example throttles the \u003Ccode class=\"literal\">sdb\u003C/code> disk on the \u003Ccode class=\"literal\">rollin-coal\u003C/code> VM to 1000 read and write I/O operations per second and to 50 MB per second read and write throughput.\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virsh blkiotune rollin-coal --device-read-iops-sec /dev/nvme0n1p3,1000 --device-write-iops-sec /dev/nvme0n1p3,1000 --device-write-bytes-sec /dev/nvme0n1p3,52428800 --device-read-bytes-sec /dev/nvme0n1p3,52428800\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Additional information\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tDisk I/O throttling can be useful in various situations, for example when VMs belonging to different customers are running on the same host, or when quality of service guarantees are given for different VMs. Disk I/O throttling can also be used to simulate slower disks.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tI/O throttling can be applied independently to each block device attached to a VM and supports limits on throughput and I/O operations.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tRed Hat does not support using the \u003Ccode class=\"literal\">virsh blkdeviotune\u003C/code> command to configure I/O throttling in VMs. For more information about unsupported features when using RHEL 9 as a VM host, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/configuring_and_managing_virtualization/index#unsupported-features-in-rhel-9-virtualization_feature-support-and-limitations-in-rhel-9-virtualization\">Unsupported features in RHEL 9 virtualization\u003C/a>.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"configuring-multi-queue-virtio-scsi_optimizing-virtual-machine-i-o-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">13.5.3. Enabling multi-queue virtio-scsi\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tWhen using \u003Ccode class=\"literal\">virtio-scsi\u003C/code> storage devices in your virtual machines (VMs), the \u003Cspan class=\"emphasis\">\u003Cem>multi-queue virtio-scsi\u003C/em>\u003C/span> feature provides improved storage performance and scalability. It enables each virtual CPU (vCPU) to have a separate queue and interrupt to use without affecting other vCPUs.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tTo enable multi-queue virtio-scsi support for a specific VM, add the following to the VM’s XML configuration, where \u003Cspan class=\"emphasis\">\u003Cem>N\u003C/em>\u003C/span> is the total number of vCPU queues:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"programlisting language-xml\">&lt;controller type='scsi' index='0' model='virtio-scsi'&gt;\n   &lt;driver queues='N' /&gt;\n&lt;/controller&gt;\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"section\" id=\"optimizing-virtual-machine-cpu-performance_optimizing-virtual-machine-performance-in-rhel\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">13.6. Optimizing virtual machine CPU performance\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tMuch like physical CPUs in host machines, vCPUs are critical to virtual machine (VM) performance. As a result, optimizing vCPUs can have a significant impact on the resource efficiency of your VMs. To optimize your vCPU:\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tAdjust how many host CPUs are assigned to the VM. You can do this using \u003Ca class=\"link\" href=\"#adding-and-removing-virtual-cpus-using-the-command-line-interface_optimizing-virtual-machine-cpu-performance\" title=\"13.6.1. Adding and removing virtual CPUs by using the command-line interface\">the CLI\u003C/a> or \u003Ca class=\"link\" href=\"#managing-virtual-cpus-using-the-web-console_optimizing-virtual-machine-cpu-performance\" title=\"13.6.2. Managing virtual CPUs by using the web console\">the web console\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnsure that the vCPU model is aligned with the CPU model of the host. For example, to set the \u003Cspan class=\"emphasis\">\u003Cem>testguest1\u003C/em>\u003C/span> VM to use the CPU model of the host:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virt-xml testguest1 --edit --cpu host-model\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOn an ARM 64 system, use \u003Ccode class=\"literal\">--cpu host-passthrough\u003C/code>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"#proc_managing-ksm_optimizing-virtual-machine-cpu-performance\" title=\"13.6.5. Enabling and disabling kernel same-page merging\">Manage kernel same-page merging (KSM)\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIf your host machine uses Non-Uniform Memory Access (NUMA), you can also \u003Cspan class=\"strong strong\">\u003Cstrong>configure NUMA\u003C/strong>\u003C/span> for its VMs. This maps the host’s CPU and memory processes onto the CPU and memory processes of the VM as closely as possible. In effect, NUMA tuning provides the vCPU with a more streamlined access to the system memory allocated to the VM, which can improve the vCPU processing effectiveness.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor details, see \u003Ca class=\"link\" href=\"#configuring-numa-in-a-virtual-machine_optimizing-virtual-machine-cpu-performance\" title=\"13.6.3. Configuring NUMA in a virtual machine\">Configuring NUMA in a virtual machine\u003C/a> and \u003Ca class=\"link\" href=\"#sample-vcpu-performance-tuning-scenario_optimizing-virtual-machine-cpu-performance\" title=\"13.6.4. Sample vCPU performance tuning scenario\">Sample vCPU performance tuning scenario\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003Csection class=\"section\" id=\"adding-and-removing-virtual-cpus-using-the-command-line-interface_optimizing-virtual-machine-cpu-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">13.6.1. Adding and removing virtual CPUs by using the command-line interface\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tTo increase or optimize the CPU performance of a virtual machine (VM), you can add or remove virtual CPUs (vCPUs) assigned to the VM.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tWhen performed on a running VM, this is also referred to as vCPU hot plugging and hot unplugging. However, note that vCPU hot unplug is not supported in RHEL 9, and Red Hat highly discourages its use.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tOptional: View the current state of the vCPUs in the targeted VM. For example, to display the number of vCPUs on the \u003Cspan class=\"emphasis\">\u003Cem>testguest\u003C/em>\u003C/span> VM:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virsh vcpucount \u003Cspan class=\"emphasis\">\u003Cem>testguest\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\nmaximum      config         4\nmaximum      live           2\ncurrent      config         2\ncurrent      live           1\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThis output indicates that \u003Cspan class=\"emphasis\">\u003Cem>testguest\u003C/em>\u003C/span> is currently using 1 vCPU, and 1 more vCPu can be hot plugged to it to increase the VM’s performance. However, after reboot, the number of vCPUs \u003Cspan class=\"emphasis\">\u003Cem>testguest\u003C/em>\u003C/span> uses will change to 2, and it will be possible to hot plug 2 more vCPUs.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tAdjust the maximum number of vCPUs that can be attached to a VM, which takes effect on the VM’s next boot.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFor example, to increase the maximum vCPU count for the \u003Cspan class=\"emphasis\">\u003Cem>testguest\u003C/em>\u003C/span> VM to 8:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virsh setvcpus testguest 8 --maximum --config\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tNote that the maximum may be limited by the CPU topology, host hardware, the hypervisor, and other factors.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tAdjust the current number of vCPUs attached to a VM, up to the maximum configured in the previous step. For example:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tTo increase the number of vCPUs attached to the running \u003Cspan class=\"emphasis\">\u003Cem>testguest\u003C/em>\u003C/span> VM to 4:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virsh setvcpus testguest 4 --live\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tThis increases the VM’s performance and host load footprint of \u003Cspan class=\"emphasis\">\u003Cem>testguest\u003C/em>\u003C/span> until the VM’s next boot.\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tTo permanently decrease the number of vCPUs attached to the \u003Cspan class=\"emphasis\">\u003Cem>testguest\u003C/em>\u003C/span> VM to 1:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virsh setvcpus testguest 1 --config\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tThis decreases the VM’s performance and host load footprint of \u003Cspan class=\"emphasis\">\u003Cem>testguest\u003C/em>\u003C/span> after the VM’s next boot. However, if needed, additional vCPUs can be hot plugged to the VM to temporarily increase its performance.\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tConfirm that the current state of vCPU for the VM reflects your changes.\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virsh vcpucount \u003Cspan class=\"emphasis\">\u003Cem>testguest\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\nmaximum      config         8\nmaximum      live           4\ncurrent      config         1\ncurrent      live           4\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/optimizing-virtual-machine-performance-in-rhel_configuring-and-managing-virtualization#managing-virtual-cpus-using-the-web-console_optimizing-virtual-machine-cpu-performance\">Managing virtual CPUs by using the web console\u003C/a>\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"managing-virtual-cpus-using-the-web-console_optimizing-virtual-machine-cpu-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">13.6.2. Managing virtual CPUs by using the web console\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tBy using the RHEL 9 web console, you can review and configure virtual CPUs used by virtual machines (VMs) to which the web console is connected.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tYou have installed the RHEL 9 web console.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFor instructions, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#installing-the-web-console_getting-started-with-the-rhel-9-web-console\">Installing and enabling the web console\u003C/a>.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe web console VM plug-in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/managing-virtual-machines-in-the-web-console_configuring-and-managing-virtualization\">is installed on your system\u003C/a>.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tLog in to the RHEL 9 web console.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFor details, see \u003Ca class=\"link\" href=\"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html/managing_systems_using_the_rhel_9_web_console/getting-started-with-the-rhel-9-web-console_system-management-using-the-rhel-9-web-console#logging-in-to-the-web-console_getting-started-with-the-rhel-9-web-console\">Logging in to the web console\u003C/a>.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIn the \u003Cspan class=\"guimenu\">Virtual Machines\u003C/span> interface, click the VM whose information you want to see.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tA new page opens with an Overview section with basic information about the selected VM and a Console section to access the VM’s graphical interface.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tClick \u003Cspan class=\"guibutton\">edit\u003C/span> next to the number of vCPUs in the Overview pane.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe vCPU details dialog appears.\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"informalfigure\">\u003Cdiv class=\"mediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/822593b143a5fe3f23f61dc63a892afb/virt-cockpit-configure-vCPUs.png\" width=\"540\" alt=\"Image displaying the VM CPU details dialog box.\"/>\u003C/div>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tConfigure the virtual CPUs for the selected VM.\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>vCPU Count\u003C/strong>\u003C/span> - The number of vCPUs currently in use.\n\t\t\t\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\t\t\t\tThe vCPU count cannot be greater than the vCPU Maximum.\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>vCPU Maximum\u003C/strong>\u003C/span> - The maximum number of virtual CPUs that can be configured for the VM. If this value is higher than the \u003Cspan class=\"strong strong\">\u003Cstrong>vCPU Count\u003C/strong>\u003C/span>, additional vCPUs can be attached to the VM.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>Sockets\u003C/strong>\u003C/span> - The number of sockets to expose to the VM.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>Cores per socket\u003C/strong>\u003C/span> - The number of cores for each socket to expose to the VM.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>Threads per core\u003C/strong>\u003C/span> - The number of threads for each core to expose to the VM.\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tNote that the \u003Cspan class=\"strong strong\">\u003Cstrong>Sockets\u003C/strong>\u003C/span>, \u003Cspan class=\"strong strong\">\u003Cstrong>Cores per socket\u003C/strong>\u003C/span>, and \u003Cspan class=\"strong strong\">\u003Cstrong>Threads per core\u003C/strong>\u003C/span> options adjust the CPU topology of the VM. This may be beneficial for vCPU performance and may impact the functionality of certain software in the guest OS. If a different setting is not required by your deployment, keep the default values.\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tClick \u003Cspan class=\"guibutton\">Apply\u003C/span>.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe virtual CPUs for the VM are configured.\n\t\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\t\tChanges to virtual CPU settings only take effect after the VM is restarted.\n\t\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/optimizing-virtual-machine-performance-in-rhel_configuring-and-managing-virtualization#adding-and-removing-virtual-cpus-using-the-command-line-interface_optimizing-virtual-machine-cpu-performance\">Adding and removing virtual CPUs by using the command-line interface\u003C/a>\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"configuring-numa-in-a-virtual-machine_optimizing-virtual-machine-cpu-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">13.6.3. Configuring NUMA in a virtual machine\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tThe following methods can be used to configure Non-Uniform Memory Access (NUMA) settings of a virtual machine (VM) on a RHEL 9 host.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe host is a NUMA-compatible machine. To detect whether this is the case, use the \u003Ccode class=\"literal\">virsh nodeinfo\u003C/code> command and see the \u003Ccode class=\"literal\">NUMA cell(s)\u003C/code> line:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virsh nodeinfo\u003C/strong>\u003C/span>\nCPU model:           x86_64\nCPU(s):              48\nCPU frequency:       1200 MHz\nCPU socket(s):       1\nCore(s) per socket:  12\nThread(s) per core:  2\nNUMA cell(s):        \u003Cspan class=\"strong strong\">\u003Cstrong>2\u003C/strong>\u003C/span>\nMemory size:         67012964 KiB\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIf the value of the line is 2 or greater, the host is NUMA-compatible.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"formalpara\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cp>\n\t\t\t\t\t\tFor ease of use, you can set up a VM’s NUMA configuration by using automated utilities and services. However, manual NUMA setup is more likely to yield a significant performance improvement.\n\t\t\t\t\t\u003C/p>\u003C/div>\u003Cp>\n\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>Automatic methods\u003C/strong>\u003C/span>\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tSet the VM’s NUMA policy to \u003Ccode class=\"literal\">Preferred\u003C/code>. For example, to do so for the \u003Cspan class=\"emphasis\">\u003Cem>testguest5\u003C/em>\u003C/span> VM:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virt-xml testguest5 --edit --vcpus placement=auto\u003C/strong>\u003C/span>\n# \u003Cspan class=\"strong strong\">\u003Cstrong>virt-xml testguest5 --edit --numatune mode=preferred\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tEnable automatic NUMA balancing on the host:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>echo 1 &gt; /proc/sys/kernel/numa_balancing\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tStart the \u003Ccode class=\"literal\">numad\u003C/code> service to automatically align the VM CPU with memory resources.\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl start numad\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>Manual methods\u003C/strong>\u003C/span>\n\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tPin specific vCPU threads to a specific host CPU or range of CPUs. This is also possible on non-NUMA hosts and VMs, and is recommended as a safe method of vCPU performance improvement.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFor example, the following commands pin vCPU threads 0 to 5 of the \u003Cspan class=\"emphasis\">\u003Cem>testguest6\u003C/em>\u003C/span> VM to host CPUs 1, 3, 5, 7, 9, and 11, respectively:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virsh vcpupin testguest6 0 1\u003C/strong>\u003C/span>\n# \u003Cspan class=\"strong strong\">\u003Cstrong>virsh vcpupin testguest6 1 3\u003C/strong>\u003C/span>\n# \u003Cspan class=\"strong strong\">\u003Cstrong>virsh vcpupin testguest6 2 5\u003C/strong>\u003C/span>\n# \u003Cspan class=\"strong strong\">\u003Cstrong>virsh vcpupin testguest6 3 7\u003C/strong>\u003C/span>\n# \u003Cspan class=\"strong strong\">\u003Cstrong>virsh vcpupin testguest6 4 9\u003C/strong>\u003C/span>\n# \u003Cspan class=\"strong strong\">\u003Cstrong>virsh vcpupin testguest6 5 11\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tAfterwards, you can verify whether this was successful:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virsh vcpupin testguest6\u003C/strong>\u003C/span>\nVCPU   CPU Affinity\n----------------------\n0      1\n1      3\n2      5\n3      7\n4      9\n5      11\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tAfter pinning vCPU threads, you can also pin QEMU process threads associated with a specified VM to a specific host CPU or range of CPUs. For example, the following commands pin the QEMU process thread of \u003Cspan class=\"emphasis\">\u003Cem>testguest6\u003C/em>\u003C/span> to CPUs 13 and 15, and verify this was successful:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virsh emulatorpin testguest6 13,15\u003C/strong>\u003C/span>\n# \u003Cspan class=\"strong strong\">\u003Cstrong>virsh emulatorpin testguest6\u003C/strong>\u003C/span>\nemulator: CPU Affinity\n----------------------------------\n       *: 13,15\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFinally, you can also specify which host NUMA nodes will be assigned specifically to a certain VM. This can improve the host memory usage by the VM’s vCPU. For example, the following commands set \u003Cspan class=\"emphasis\">\u003Cem>testguest6\u003C/em>\u003C/span> to use host NUMA nodes 3 to 5, and verify this was successful:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virsh numatune testguest6 --nodeset 3-5\u003C/strong>\u003C/span>\n# \u003Cspan class=\"strong strong\">\u003Cstrong>virsh numatune testguest6\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\tFor best performance results, it is recommended to use all of the manual tuning methods listed above\n\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Known issues\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/assembly_feature-support-and-limitations-in-rhel-9-virtualization_configuring-and-managing-virtualization#how-virtualization-on-ibm-z-differs-from-amd64-and-intel64_feature-support-and-limitations-in-rhel-9-virtualization\">NUMA tuning currently cannot be performed on IBM Z hosts\u003C/a>.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/optimizing-virtual-machine-performance-in-rhel_configuring-and-managing-virtualization#sample-vcpu-performance-tuning-scenario_optimizing-virtual-machine-cpu-performance\">Sample vCPU performance tuning scenario\u003C/a>\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/optimizing-virtual-machine-performance-in-rhel_configuring-and-managing-virtualization#virtual-machine-performance-monitoring-tools_optimizing-virtual-machine-performance-in-rhel\">View the current NUMA configuration of your system\u003C/a> using the \u003Ccode class=\"literal\">numastat\u003C/code> utility\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"sample-vcpu-performance-tuning-scenario_optimizing-virtual-machine-cpu-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">13.6.4. Sample vCPU performance tuning scenario\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tTo obtain the best vCPU performance possible, Red Hat recommends by using manual \u003Ccode class=\"literal\">vcpupin\u003C/code>, \u003Ccode class=\"literal\">emulatorpin\u003C/code>, and \u003Ccode class=\"literal\">numatune\u003C/code> settings together, for example like in the following scenario.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Starting scenario\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tYour host has the following hardware specifics:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t2 NUMA nodes\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t3 CPU cores on each node\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t2 threads on each core\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe output of \u003Ccode class=\"literal\">virsh nodeinfo\u003C/code> of such a machine would look similar to:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virsh nodeinfo\u003C/strong>\u003C/span>\nCPU model:           x86_64\nCPU(s):              12\nCPU frequency:       3661 MHz\nCPU socket(s):       2\nCore(s) per socket:  3\nThread(s) per core:  2\nNUMA cell(s):        2\nMemory size:         31248692 KiB\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tYou intend to modify an existing VM to have 8 vCPUs, which means that it will not fit in a single NUMA node.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tTherefore, you should distribute 4 vCPUs on each NUMA node and make the vCPU topology resemble the host topology as closely as possible. This means that vCPUs that run as sibling threads of a given physical CPU should be pinned to host threads on the same core. For details, see the \u003Cspan class=\"emphasis\">\u003Cem>Solution\u003C/em>\u003C/span> below:\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Solution\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tObtain the information about the host topology:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virsh capabilities\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe output should include a section that looks similar to the following:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"programlisting language-xml\">&lt;topology&gt;\n  &lt;cells num=\"2\"&gt;\n    &lt;cell id=\"0\"&gt;\n      &lt;memory unit=\"KiB\"&gt;15624346&lt;/memory&gt;\n      &lt;pages unit=\"KiB\" size=\"4\"&gt;3906086&lt;/pages&gt;\n      &lt;pages unit=\"KiB\" size=\"2048\"&gt;0&lt;/pages&gt;\n      &lt;pages unit=\"KiB\" size=\"1048576\"&gt;0&lt;/pages&gt;\n      &lt;distances&gt;\n        &lt;sibling id=\"0\" value=\"10\" /&gt;\n        &lt;sibling id=\"1\" value=\"21\" /&gt;\n      &lt;/distances&gt;\n      &lt;cpus num=\"6\"&gt;\n        &lt;cpu id=\"0\" socket_id=\"0\" core_id=\"0\" siblings=\"0,3\" /&gt;\n        &lt;cpu id=\"1\" socket_id=\"0\" core_id=\"1\" siblings=\"1,4\" /&gt;\n        &lt;cpu id=\"2\" socket_id=\"0\" core_id=\"2\" siblings=\"2,5\" /&gt;\n        &lt;cpu id=\"3\" socket_id=\"0\" core_id=\"0\" siblings=\"0,3\" /&gt;\n        &lt;cpu id=\"4\" socket_id=\"0\" core_id=\"1\" siblings=\"1,4\" /&gt;\n        &lt;cpu id=\"5\" socket_id=\"0\" core_id=\"2\" siblings=\"2,5\" /&gt;\n      &lt;/cpus&gt;\n    &lt;/cell&gt;\n    &lt;cell id=\"1\"&gt;\n      &lt;memory unit=\"KiB\"&gt;15624346&lt;/memory&gt;\n      &lt;pages unit=\"KiB\" size=\"4\"&gt;3906086&lt;/pages&gt;\n      &lt;pages unit=\"KiB\" size=\"2048\"&gt;0&lt;/pages&gt;\n      &lt;pages unit=\"KiB\" size=\"1048576\"&gt;0&lt;/pages&gt;\n      &lt;distances&gt;\n        &lt;sibling id=\"0\" value=\"21\" /&gt;\n        &lt;sibling id=\"1\" value=\"10\" /&gt;\n      &lt;/distances&gt;\n      &lt;cpus num=\"6\"&gt;\n        &lt;cpu id=\"6\" socket_id=\"1\" core_id=\"3\" siblings=\"6,9\" /&gt;\n        &lt;cpu id=\"7\" socket_id=\"1\" core_id=\"4\" siblings=\"7,10\" /&gt;\n        &lt;cpu id=\"8\" socket_id=\"1\" core_id=\"5\" siblings=\"8,11\" /&gt;\n        &lt;cpu id=\"9\" socket_id=\"1\" core_id=\"3\" siblings=\"6,9\" /&gt;\n        &lt;cpu id=\"10\" socket_id=\"1\" core_id=\"4\" siblings=\"7,10\" /&gt;\n        &lt;cpu id=\"11\" socket_id=\"1\" core_id=\"5\" siblings=\"8,11\" /&gt;\n      &lt;/cpus&gt;\n    &lt;/cell&gt;\n  &lt;/cells&gt;\n&lt;/topology&gt;\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tOptional: Test the performance of the VM by using \u003Ca class=\"link\" href=\"#virtual-machine-performance-monitoring-tools_optimizing-virtual-machine-performance-in-rhel\" title=\"13.8. Virtual machine performance monitoring tools\">the applicable tools and utilities\u003C/a>.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tSet up and mount 1 GiB huge pages on the host:\n\t\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\t\t1 GiB huge pages might not be available on some architectures and configurations, such as ARM 64 hosts.\n\t\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tAdd the following line to the host’s kernel command line:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">default_hugepagesz=1G hugepagesz=1G\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tCreate the \u003Ccode class=\"literal\">/etc/systemd/system/hugetlb-gigantic-pages.service\u003C/code> file with the following content:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">[Unit]\nDescription=HugeTLB Gigantic Pages Reservation\nDefaultDependencies=no\nBefore=dev-hugepages.mount\nConditionPathExists=/sys/devices/system/node\nConditionKernelCommandLine=hugepagesz=1G\n\n[Service]\nType=oneshot\nRemainAfterExit=yes\nExecStart=/etc/systemd/hugetlb-reserve-pages.sh\n\n[Install]\nWantedBy=sysinit.target\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tCreate the \u003Ccode class=\"literal\">/etc/systemd/hugetlb-reserve-pages.sh\u003C/code> file with the following content:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">#!/bin/sh\n\nnodes_path=/sys/devices/system/node/\nif [ ! -d $nodes_path ]; then\n\techo \"ERROR: $nodes_path does not exist\"\n\texit 1\nfi\n\nreserve_pages()\n{\n\techo $1 &gt; $nodes_path/$2/hugepages/hugepages-1048576kB/nr_hugepages\n}\n\nreserve_pages 4 node1\nreserve_pages 4 node2\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tThis reserves four 1GiB huge pages from \u003Cspan class=\"emphasis\">\u003Cem>node1\u003C/em>\u003C/span> and four 1GiB huge pages from \u003Cspan class=\"emphasis\">\u003Cem>node2\u003C/em>\u003C/span>.\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tMake the script created in the previous step executable:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>chmod +x /etc/systemd/hugetlb-reserve-pages.sh\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tEnable huge page reservation on boot:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl enable hugetlb-gigantic-pages\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tUse the \u003Ccode class=\"literal\">virsh edit\u003C/code> command to edit the XML configuration of the VM you wish to optimize, in this example \u003Cspan class=\"emphasis\">\u003Cem>super-VM\u003C/em>\u003C/span>:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>virsh edit super-vm\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tAdjust the XML configuration of the VM in the following way:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tSet the VM to use 8 static vCPUs. Use the \u003Ccode class=\"literal\">&lt;vcpu/&gt;\u003C/code> element to do this.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tPin each of the vCPU threads to the corresponding host CPU threads that it mirrors in the topology. To do so, use the \u003Ccode class=\"literal\">&lt;vcpupin/&gt;\u003C/code> elements in the \u003Ccode class=\"literal\">&lt;cputune&gt;\u003C/code> section.\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tNote that, as shown by the \u003Ccode class=\"literal\">virsh capabilities\u003C/code> utility above, host CPU threads are not ordered sequentially in their respective cores. In addition, the vCPU threads should be pinned to the highest available set of host cores on the same NUMA node. For a table illustration, see the \u003Cspan class=\"strong strong\">\u003Cstrong>Sample topology\u003C/strong>\u003C/span> section below.\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tThe XML configuration for steps a. and b. can look similar to:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"programlisting language-xml\">&lt;cputune&gt;\n  &lt;vcpupin vcpu='0' cpuset='1'/&gt;\n  &lt;vcpupin vcpu='1' cpuset='4'/&gt;\n  &lt;vcpupin vcpu='2' cpuset='2'/&gt;\n  &lt;vcpupin vcpu='3' cpuset='5'/&gt;\n  &lt;vcpupin vcpu='4' cpuset='7'/&gt;\n  &lt;vcpupin vcpu='5' cpuset='10'/&gt;\n  &lt;vcpupin vcpu='6' cpuset='8'/&gt;\n  &lt;vcpupin vcpu='7' cpuset='11'/&gt;\n  &lt;emulatorpin cpuset='6,9'/&gt;\n&lt;/cputune&gt;\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tSet the VM to use 1 GiB huge pages:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"programlisting language-xml\">&lt;memoryBacking&gt;\n  &lt;hugepages&gt;\n    &lt;page size='1' unit='GiB'/&gt;\n  &lt;/hugepages&gt;\n&lt;/memoryBacking&gt;\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tConfigure the VM’s NUMA nodes to use memory from the corresponding NUMA nodes on the host. To do so, use the \u003Ccode class=\"literal\">&lt;memnode/&gt;\u003C/code> elements in the \u003Ccode class=\"literal\">&lt;numatune/&gt;\u003C/code> section:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"programlisting language-xml\">&lt;numatune&gt;\n  &lt;memory mode=\"preferred\" nodeset=\"1\"/&gt;\n  &lt;memnode cellid=\"0\" mode=\"strict\" nodeset=\"0\"/&gt;\n  &lt;memnode cellid=\"1\" mode=\"strict\" nodeset=\"1\"/&gt;\n&lt;/numatune&gt;\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tEnsure the CPU mode is set to \u003Ccode class=\"literal\">host-passthrough\u003C/code>, and that the CPU uses cache in \u003Ccode class=\"literal\">passthrough\u003C/code> mode:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"programlisting language-xml\">&lt;cpu mode=\"host-passthrough\"&gt;\n  &lt;topology sockets=\"2\" cores=\"2\" threads=\"2\"/&gt;\n  &lt;cache mode=\"passthrough\"/&gt;\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tOn an ARM 64 system, omit the \u003Ccode class=\"literal\">&lt;cache mode=\"passthrough\"/&gt;\u003C/code> line.\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tConfirm that the resulting XML configuration of the VM includes a section similar to the following:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"programlisting language-xml\">[...]\n  &lt;memoryBacking&gt;\n    &lt;hugepages&gt;\n      &lt;page size='1' unit='GiB'/&gt;\n    &lt;/hugepages&gt;\n  &lt;/memoryBacking&gt;\n  &lt;vcpu placement='static'&gt;8&lt;/vcpu&gt;\n  &lt;cputune&gt;\n    &lt;vcpupin vcpu='0' cpuset='1'/&gt;\n    &lt;vcpupin vcpu='1' cpuset='4'/&gt;\n    &lt;vcpupin vcpu='2' cpuset='2'/&gt;\n    &lt;vcpupin vcpu='3' cpuset='5'/&gt;\n    &lt;vcpupin vcpu='4' cpuset='7'/&gt;\n    &lt;vcpupin vcpu='5' cpuset='10'/&gt;\n    &lt;vcpupin vcpu='6' cpuset='8'/&gt;\n    &lt;vcpupin vcpu='7' cpuset='11'/&gt;\n    &lt;emulatorpin cpuset='6,9'/&gt;\n  &lt;/cputune&gt;\n  &lt;numatune&gt;\n    &lt;memory mode=\"preferred\" nodeset=\"1\"/&gt;\n    &lt;memnode cellid=\"0\" mode=\"strict\" nodeset=\"0\"/&gt;\n    &lt;memnode cellid=\"1\" mode=\"strict\" nodeset=\"1\"/&gt;\n  &lt;/numatune&gt;\n  &lt;cpu mode=\"host-passthrough\"&gt;\n    &lt;topology sockets=\"2\" cores=\"2\" threads=\"2\"/&gt;\n    &lt;cache mode=\"passthrough\"/&gt;\n    &lt;numa&gt;\n      &lt;cell id=\"0\" cpus=\"0-3\" memory=\"2\" unit=\"GiB\"&gt;\n        &lt;distances&gt;\n          &lt;sibling id=\"0\" value=\"10\"/&gt;\n          &lt;sibling id=\"1\" value=\"21\"/&gt;\n        &lt;/distances&gt;\n      &lt;/cell&gt;\n      &lt;cell id=\"1\" cpus=\"4-7\" memory=\"2\" unit=\"GiB\"&gt;\n        &lt;distances&gt;\n          &lt;sibling id=\"0\" value=\"21\"/&gt;\n          &lt;sibling id=\"1\" value=\"10\"/&gt;\n        &lt;/distances&gt;\n      &lt;/cell&gt;\n    &lt;/numa&gt;\n  &lt;/cpu&gt;\n&lt;/domain&gt;\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tOptional: Test the performance of the VM by using \u003Ca class=\"link\" href=\"#virtual-machine-performance-monitoring-tools_optimizing-virtual-machine-performance-in-rhel\" title=\"13.8. Virtual machine performance monitoring tools\">the applicable tools and utilities\u003C/a> to evaluate the impact of the VM’s optimization.\n\t\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Sample topology\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe following tables illustrate the connections between the vCPUs and the host CPUs they should be pinned to:\n\t\t\t\t\t\t\u003C/p>\u003Crh-table id=\"idm140280139896848\">\u003Ctable class=\"gt-8-cols lt-7-rows\">\u003Ccaption>Table 13.2. Host topology\u003C/caption>\u003Ccolgroup>\u003Ccol style=\"width: 7%; \" class=\"col_1\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 7%; \" class=\"col_2\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 7%; \" class=\"col_3\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 7%; \" class=\"col_4\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 7%; \" class=\"col_5\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 7%; \" class=\"col_6\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 7%; \" class=\"col_7\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 7%; \" class=\"col_8\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 7%; \" class=\"col_9\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 7%; \" class=\"col_10\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 7%; \" class=\"col_11\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 7%; \" class=\"col_12\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 7%; \" class=\"col_13\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 7%; \" class=\"col_14\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 7%; \" class=\"col_15\">\u003C!--Empty-->\u003C/col>\u003C/colgroup>\u003Ctbody>\u003Ctr>\u003Ctd colspan=\"3\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>CPU threads\u003C/strong>\u003C/span>\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t0\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t3\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t1\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t4\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t2\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t5\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t6\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t9\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t7\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t10\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t8\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t11\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd colspan=\"3\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>Cores\u003C/strong>\u003C/span>\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd colspan=\"2\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t0\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd colspan=\"2\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t1\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd colspan=\"2\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t2\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd colspan=\"2\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t3\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd colspan=\"2\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t4\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd colspan=\"2\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t5\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd colspan=\"3\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>Sockets\u003C/strong>\u003C/span>\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd colspan=\"6\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t0\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd colspan=\"6\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t1\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd colspan=\"3\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>NUMA nodes\u003C/strong>\u003C/span>\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd colspan=\"6\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t0\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd colspan=\"6\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t1\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\u003C/rh-table>\u003Crh-table id=\"idm140280131378592\">\u003Ctable class=\"gt-8-cols lt-7-rows\">\u003Ccaption>Table 13.3. VM topology\u003C/caption>\u003Ccolgroup>\u003Ccol style=\"width: 9%; \" class=\"col_1\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 9%; \" class=\"col_2\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 9%; \" class=\"col_3\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 9%; \" class=\"col_4\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 9%; \" class=\"col_5\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 9%; \" class=\"col_6\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 9%; \" class=\"col_7\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 9%; \" class=\"col_8\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 9%; \" class=\"col_9\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 9%; \" class=\"col_10\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 9%; \" class=\"col_11\">\u003C!--Empty-->\u003C/col>\u003C/colgroup>\u003Ctbody>\u003Ctr>\u003Ctd colspan=\"3\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>vCPU threads\u003C/strong>\u003C/span>\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t0\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t1\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t2\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t3\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t4\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t5\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t6\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t7\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd colspan=\"3\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>Cores\u003C/strong>\u003C/span>\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd colspan=\"2\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t0\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd colspan=\"2\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t1\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd colspan=\"2\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t2\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd colspan=\"2\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t3\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd colspan=\"3\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>Sockets\u003C/strong>\u003C/span>\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd colspan=\"4\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t0\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd colspan=\"4\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t1\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd colspan=\"3\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>NUMA nodes\u003C/strong>\u003C/span>\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd colspan=\"4\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t0\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd colspan=\"4\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t1\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\u003C/rh-table>\u003Crh-table id=\"idm140280132257584\">\u003Ctable class=\"gt-8-cols lt-7-rows\">\u003Ccaption>Table 13.4. Combined host and VM topology\u003C/caption>\u003Ccolgroup>\u003Ccol style=\"width: 7%; \" class=\"col_1\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 7%; \" class=\"col_2\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 7%; \" class=\"col_3\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 7%; \" class=\"col_4\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 7%; \" class=\"col_5\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 7%; \" class=\"col_6\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 7%; \" class=\"col_7\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 7%; \" class=\"col_8\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 7%; \" class=\"col_9\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 7%; \" class=\"col_10\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 7%; \" class=\"col_11\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 7%; \" class=\"col_12\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 7%; \" class=\"col_13\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 7%; \" class=\"col_14\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 7%; \" class=\"col_15\">\u003C!--Empty-->\u003C/col>\u003C/colgroup>\u003Ctbody>\u003Ctr>\u003Ctd colspan=\"3\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>vCPU threads\u003C/strong>\u003C/span>\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd colspan=\"2\" align=\"center\" valign=\"top\"> \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t0\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t1\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t2\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t3\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd colspan=\"2\" align=\"center\" valign=\"top\"> \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t4\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t5\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t6\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t7\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd colspan=\"3\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>Host CPU threads\u003C/strong>\u003C/span>\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t0\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t3\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t1\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t4\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t2\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t5\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t6\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t9\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t7\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t10\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t8\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t11\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd colspan=\"3\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>Cores\u003C/strong>\u003C/span>\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd colspan=\"2\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t0\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd colspan=\"2\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t1\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd colspan=\"2\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t2\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd colspan=\"2\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t3\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd colspan=\"2\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t4\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd colspan=\"2\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t5\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd colspan=\"3\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>Sockets\u003C/strong>\u003C/span>\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd colspan=\"6\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t0\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd colspan=\"6\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t1\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd colspan=\"3\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>NUMA nodes\u003C/strong>\u003C/span>\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd colspan=\"6\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t0\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd colspan=\"6\" align=\"center\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t1\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\u003C/rh-table>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIn this scenario, there are 2 NUMA nodes and 8 vCPUs. Therefore, 4 vCPU threads should be pinned to each node.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIn addition, Red Hat recommends leaving at least a single CPU thread available on each node for host system operations.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tBecause in this example, each NUMA node houses 3 cores, each with 2 host CPU threads, the set for node 0 translates as follows:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"programlisting language-xml\">&lt;vcpupin vcpu='0' cpuset='1'/&gt;\n&lt;vcpupin vcpu='1' cpuset='4'/&gt;\n&lt;vcpupin vcpu='2' cpuset='2'/&gt;\n&lt;vcpupin vcpu='3' cpuset='5'/&gt;\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"proc_managing-ksm_optimizing-virtual-machine-cpu-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">13.6.5. Enabling and disabling kernel same-page merging\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tKernel Same-Page Merging (KSM) improves memory density by sharing identical memory pages between virtual machines (VMs). Therefore, enabling KSM might improve memory efficiency of your VM deployment.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tHowever, enabling KSM also increases CPU utilization, and might negatively affect overall performance depending on the workload.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tIn RHEL 9 and later, KSM is disabled by default. To enable KSM and test its impact on your VM performance, see the following instructions.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tRoot access to your host system.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tEnable KSM:\n\t\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition warning\" state=\"danger\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Warning\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\t\tEnabling KSM increases CPU utilization and affects overall CPU performance.\n\t\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tInstall the \u003Ccode class=\"literal\">ksmtuned\u003C/code> service:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>{PackageManagerCommand} install ksmtuned\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tStart the service:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\t\tTo enable KSM for a single session, use the \u003Ccode class=\"literal\">systemctl\u003C/code> utility to start the \u003Ccode class=\"literal\">ksm\u003C/code> and \u003Ccode class=\"literal\">ksmtuned\u003C/code> services.\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl start ksm\u003C/strong>\u003C/span>\n# \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl start ksmtuned\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\t\tTo enable KSM persistently, use the \u003Ccode class=\"literal\">systemctl\u003C/code> utility to enable the \u003Ccode class=\"literal\">ksm\u003C/code> and \u003Ccode class=\"literal\">ksmtuned\u003C/code> services.\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl enable ksm\u003C/strong>\u003C/span>\nCreated symlink /etc/systemd/system/multi-user.target.wants/ksm.service → /usr/lib/systemd/system/ksm.service\n\n# \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl enable ksmtuned\u003C/strong>\u003C/span>\nCreated symlink /etc/systemd/system/multi-user.target.wants/ksmtuned.service → /usr/lib/systemd/system/ksmtuned.service\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tMonitor the performance and resource consumption of VMs on your host to evaluate the benefits of activating KSM. Specifically, ensure that the additional CPU usage by KSM does not offset the memory improvements and does not cause additional performance issues. In latency-sensitive workloads, also pay attention to cross-NUMA page merges.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tOptional: If KSM has not improved your VM performance, disable it:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tTo disable KSM for a single session, use the \u003Ccode class=\"literal\">systemctl\u003C/code> utility to stop \u003Ccode class=\"literal\">ksm\u003C/code> and \u003Ccode class=\"literal\">ksmtuned\u003C/code> services.\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl stop ksm\u003C/strong>\u003C/span>\n# \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl stop ksmtuned\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tTo disable KSM persistently, use the \u003Ccode class=\"literal\">systemctl\u003C/code> utility to disable \u003Ccode class=\"literal\">ksm\u003C/code> and \u003Ccode class=\"literal\">ksmtuned\u003C/code> services.\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl disable ksm\u003C/strong>\u003C/span>\nRemoved /etc/systemd/system/multi-user.target.wants/ksm.service.\n# \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl disable ksmtuned\u003C/strong>\u003C/span>\nRemoved /etc/systemd/system/multi-user.target.wants/ksmtuned.service.\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\tMemory pages shared between VMs before deactivating KSM will remain shared. To stop sharing, delete all the \u003Ccode class=\"literal\">PageKSM\u003C/code> pages in the system by using the following command:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>echo 2 &gt; /sys/kernel/mm/ksm/run\u003C/strong>\u003C/span>\u003C/pre>\u003Cp>\n\t\t\t\t\t\tHowever, this command increases memory usage, and might cause performance problems on your host or your VMs.\n\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/section>\u003C/section>\u003Csection class=\"section\" id=\"optimizing-virtual-machine-network-performance_optimizing-virtual-machine-performance-in-rhel\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">13.7. Optimizing virtual machine network performance\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tDue to the virtual nature of a VM’s network interface card (NIC), the VM loses a portion of its allocated host network bandwidth, which can reduce the overall workload efficiency of the VM. The following tips can minimize the negative impact of virtualization on the virtual NIC (vNIC) throughput.\n\t\t\t\u003C/p>\u003Cdiv class=\"formalpara\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cp>\n\t\t\t\t\tUse any of the following methods and observe if it has a beneficial effect on your VM network performance:\n\t\t\t\t\u003C/p>\u003C/div>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">Enable the vhost_net module\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tOn the host, ensure the \u003Ccode class=\"literal\">vhost_net\u003C/code> kernel feature is enabled:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>lsmod | grep vhost\u003C/strong>\u003C/span>\nvhost_net              32768  1\nvhost                  53248  1 vhost_net\ntap                    24576  1 vhost_net\ntun                    57344  6 vhost_net\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIf the output of this command is blank, enable the \u003Ccode class=\"literal\">vhost_net\u003C/code> kernel module:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>modprobe vhost_net\u003C/strong>\u003C/span>\u003C/pre>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Set up multi-queue virtio-net\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tTo set up the \u003Cspan class=\"emphasis\">\u003Cem>multi-queue virtio-net\u003C/em>\u003C/span> feature for a VM, use the \u003Ccode class=\"literal\">virsh edit\u003C/code> command to edit to the XML configuration of the VM. In the XML, add the following to the \u003Ccode class=\"literal\">&lt;devices&gt;\u003C/code> section, and replace \u003Ccode class=\"literal\">N\u003C/code> with the number of vCPUs in the VM, up to 16:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">&lt;interface type='network'&gt;\n      &lt;source network='default'/&gt;\n      &lt;model type='virtio'/&gt;\n      &lt;driver name='vhost' queues='N'/&gt;\n&lt;/interface&gt;\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIf the VM is running, restart it for the changes to take effect.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Batching network packets\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIn Linux VM configurations with a long transmission path, batching packets before submitting them to the kernel may improve cache utilization. To set up packet batching, use the following command on the host, and replace \u003Cspan class=\"emphasis\">\u003Cem>tap0\u003C/em>\u003C/span> with the name of the network interface that the VMs use:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ethtool -C \u003Cspan class=\"emphasis\">\u003Cem>tap0\u003C/em>\u003C/span> rx-frames 64\u003C/strong>\u003C/span>\u003C/pre>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">SR-IOV\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tIf your host NIC supports SR-IOV, use SR-IOV device assignment for your vNICs. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/managing-virtual-devices_configuring-and-managing-virtualization#managing-sr-iov-devices_managing-virtual-devices\">Managing SR-IOV devices\u003C/a>.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/configuring-virtual-machine-network-connections_configuring-and-managing-virtualization#understanding-virtual-networking-overview_configuring-virtual-machine-network-connections\">Understanding virtual networking\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"virtual-machine-performance-monitoring-tools_optimizing-virtual-machine-performance-in-rhel\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">13.8. Virtual machine performance monitoring tools\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tTo identify what consumes the most VM resources and which aspect of VM performance needs optimization, performance diagnostic tools, both general and VM-specific, can be used.\n\t\t\t\u003C/p>\u003Cdiv class=\"formalpara\">\u003Cp class=\"title\">\u003Cstrong>Default OS performance monitoring tools\u003C/strong>\u003C/p>\u003Cp>\n\t\t\t\t\tFor standard performance evaluation, you can use the utilities provided by default by your host and guest operating systems:\n\t\t\t\t\u003C/p>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOn your RHEL 9 host, as root, use the \u003Ccode class=\"literal\">top\u003C/code> utility or the \u003Cspan class=\"strong strong\">\u003Cstrong>system monitor\u003C/strong>\u003C/span> application, and look for \u003Ccode class=\"literal\">qemu\u003C/code> and \u003Ccode class=\"literal\">virt\u003C/code> in the output. This shows how much host system resources your VMs are consuming.\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tIf the monitoring tool displays that any of the \u003Ccode class=\"literal\">qemu\u003C/code> or \u003Ccode class=\"literal\">virt\u003C/code> processes consume a large portion of the host CPU or memory capacity, use the \u003Ccode class=\"literal\">perf\u003C/code> utility to investigate. For details, see below.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tIn addition, if a \u003Ccode class=\"literal\">vhost_net\u003C/code> thread process, named for example \u003Cspan class=\"emphasis\">\u003Cem>vhost_net-1234\u003C/em>\u003C/span>, is displayed as consuming an excessive amount of host CPU capacity, consider using \u003Ca class=\"link\" href=\"#optimizing-virtual-machine-network-performance_optimizing-virtual-machine-performance-in-rhel\" title=\"13.7. Optimizing virtual machine network performance\">virtual network optimization features\u003C/a>, such as \u003Ccode class=\"literal\">multi-queue virtio-net\u003C/code>.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOn the guest operating system, use performance utilities and applications available on the system to evaluate which processes consume the most system resources.\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tOn Linux systems, you can use the \u003Ccode class=\"literal\">top\u003C/code> utility.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tOn Windows systems, you can use the \u003Cspan class=\"strong strong\">\u003Cstrong>Task Manager\u003C/strong>\u003C/span> application.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"formalpara\">\u003Cp class=\"title\">\u003Cstrong>perf kvm\u003C/strong>\u003C/p>\u003Cp>\n\t\t\t\t\tYou can use the \u003Ccode class=\"literal\">perf\u003C/code> utility to collect and analyze virtualization-specific statistics about the performance of your RHEL 9 host. To do so:\n\t\t\t\t\u003C/p>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOn the host, install the \u003Cspan class=\"emphasis\">\u003Cem>perf\u003C/em>\u003C/span> package:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>dnf install perf\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tUse one of the \u003Ccode class=\"literal\">perf kvm stat\u003C/code> commands to display perf statistics for your virtualization host:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tFor real-time monitoring of your hypervisor, use the \u003Ccode class=\"literal\">perf kvm stat live\u003C/code> command.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tTo log the perf data of your hypervisor over a period of time, activate the logging by using the \u003Ccode class=\"literal\">perf kvm stat record\u003C/code> command. After the command is canceled or interrupted, the data is saved in the \u003Ccode class=\"literal\">perf.data.guest\u003C/code> file, which can be analyzed by using the \u003Ccode class=\"literal\">perf kvm stat report\u003C/code> command.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAnalyze the \u003Ccode class=\"literal\">perf\u003C/code> output for types of \u003Ccode class=\"literal\">VM-EXIT\u003C/code> events and their distribution. For example, the \u003Ccode class=\"literal\">PAUSE_INSTRUCTION\u003C/code> events should be infrequent, but in the following output, the high occurrence of this event suggests that the host CPUs are not handling the running vCPUs well. In such a scenario, consider shutting down some of your active VMs, removing vCPUs from these VMs, or \u003Ca class=\"link\" href=\"#optimizing-virtual-machine-cpu-performance_optimizing-virtual-machine-performance-in-rhel\" title=\"13.6. Optimizing virtual machine CPU performance\">tuning the performance of the vCPUs\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>perf kvm stat report\u003C/strong>\u003C/span>\n\nAnalyze events for all VMs, all VCPUs:\n\n\n             VM-EXIT    Samples  Samples%     Time%    Min Time    Max Time         Avg time\n\n  EXTERNAL_INTERRUPT     365634    31.59%    18.04%      0.42us  58780.59us    204.08us ( +-   0.99% )\n           MSR_WRITE     293428    25.35%     0.13%      0.59us  17873.02us      1.80us ( +-   4.63% )\n    PREEMPTION_TIMER     276162    23.86%     0.23%      0.51us  21396.03us      3.38us ( +-   5.19% )\n   PAUSE_INSTRUCTION     189375    16.36%    11.75%      0.72us  29655.25us    256.77us ( +-   0.70% )\n                 HLT      20440     1.77%    69.83%      0.62us  79319.41us  14134.56us ( +-   0.79% )\n              VMCALL      12426     1.07%     0.03%      1.02us   5416.25us      8.77us ( +-   7.36% )\n       EXCEPTION_NMI         27     0.00%     0.00%      0.69us      1.34us      0.98us ( +-   3.50% )\n       EPT_MISCONFIG          5     0.00%     0.00%      5.15us     10.85us      7.88us ( +-  11.67% )\n\nTotal Samples:1157497, Total events handled time:413728274.66us.\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOther event types that can signal problems in the output of \u003Ccode class=\"literal\">perf kvm stat\u003C/code> include:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">INSN_EMULATION\u003C/code> - suggests suboptimal \u003Ca class=\"link\" href=\"#optimizing-virtual-machine-i-o-performance_optimizing-virtual-machine-performance-in-rhel\" title=\"13.5. Optimizing virtual machine I/O performance\">VM I/O configuration\u003C/a>.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003Cp>\n\t\t\t\tFor more information about using \u003Ccode class=\"literal\">perf\u003C/code> to monitor virtualization performance, see the \u003Ccode class=\"literal\">perf-kvm\u003C/code> man page on your system.\n\t\t\t\u003C/p>\u003Cdiv class=\"formalpara\">\u003Cp class=\"title\">\u003Cstrong>numastat\u003C/strong>\u003C/p>\u003Cp>\n\t\t\t\t\tTo see the current NUMA configuration of your system, you can use the \u003Ccode class=\"literal\">numastat\u003C/code> utility, which is provided by installing the \u003Cspan class=\"strong strong\">\u003Cstrong>numactl\u003C/strong>\u003C/span> package.\n\t\t\t\t\u003C/p>\u003C/div>\u003Cp>\n\t\t\t\tThe following shows a host with 4 running VMs, each obtaining memory from multiple NUMA nodes. This is not optimal for vCPU performance, and \u003Ca class=\"link\" href=\"#configuring-numa-in-a-virtual-machine_optimizing-virtual-machine-cpu-performance\" title=\"13.6.3. Configuring NUMA in a virtual machine\">warrants adjusting\u003C/a>:\n\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>numastat -c qemu-kvm\u003C/strong>\u003C/span>\n\nPer-node process memory usage (in MBs)\nPID              Node 0 Node 1 Node 2 Node 3 Node 4 Node 5 Node 6 Node 7 Total\n---------------  ------ ------ ------ ------ ------ ------ ------ ------ -----\n51722 (qemu-kvm)     68     16    357   6936      2      3    147    598  8128\n51747 (qemu-kvm)    245     11      5     18   5172   2532      1     92  8076\n53736 (qemu-kvm)     62    432   1661    506   4851    136     22    445  8116\n53773 (qemu-kvm)   1393      3      1      2     12      0      0   6702  8114\n---------------  ------ ------ ------ ------ ------ ------ ------ ------ -----\nTotal              1769    463   2024   7462  10037   2672    169   7837 32434\u003C/pre>\u003Cp>\n\t\t\t\tIn contrast, the following shows memory being provided to each VM by a single node, which is significantly more efficient.\n\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>numastat -c qemu-kvm\u003C/strong>\u003C/span>\n\nPer-node process memory usage (in MBs)\nPID              Node 0 Node 1 Node 2 Node 3 Node 4 Node 5 Node 6 Node 7 Total\n---------------  ------ ------ ------ ------ ------ ------ ------ ------ -----\n51747 (qemu-kvm)      0      0      7      0   8072      0      1      0  8080\n53736 (qemu-kvm)      0      0      7      0      0      0   8113      0  8120\n53773 (qemu-kvm)      0      0      7      0      0      0      1   8110  8118\n59065 (qemu-kvm)      0      0   8050      0      0      0      0      0  8051\n---------------  ------ ------ ------ ------ ------ ------ ------ ------ -----\nTotal                 0      0   8072      0   8072      0   8114   8110 32368\u003C/pre>\u003C/section>\u003Csection class=\"section _additional-resources\" id=\"related-information-optimizing-virtual-machine-performance-in-rhel\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">13.9. Additional resources\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/configuring_and_managing_virtualization/index#optimizing-windows-virtual-machines-on-rhel_installing-and-managing-windows-virtual-machines-on-rhel\">Optimizing Windows virtual machines\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"importance-of-power-management_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 14. Importance of power management\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tReducing the overall power consumption of computer systems helps to save cost. Effectively optimizing energy consumption of each system component includes studying different tasks that your system performs, and configuring each component to ensure that its performance is correct for that job. Lowering the power consumption of a specific component or of the system as a whole leads to lower heat and performance.\n\t\t\u003C/p>\u003Cp>\n\t\t\tProper power management results in:\n\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\theat reduction for servers and computing centers\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\treduced secondary costs, including cooling, space, cables, generators, and uninterruptible power supplies (UPS)\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\textended battery life for laptops\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tlower carbon dioxide output\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tmeeting government regulations or legal requirements regarding Green IT, for example, Energy Star\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tmeeting company guidelines for new systems\n\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\tThis section describes the information regarding power management of your Red Hat Enterprise Linux systems.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"power-management-basics_importance-of-power-management\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">14.1. Power management basics\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tEffective power management is built on the following principles:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">An idle CPU should only wake up when needed\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tSince Red Hat Enterprise Linux 6, the kernel runs \u003Ccode class=\"literal\">tickless\u003C/code>, which means the previous periodic timer interrupts have been replaced with on-demand interrupts. Therefore, idle CPUs are allowed to remain idle until a new task is queued for processing, and CPUs that have entered lower power states can remain in these states longer. However, benefits from this feature can be offset if your system has applications that create unnecessary timer events. Polling events, such as checks for volume changes or mouse movement, are examples of such events.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tRed Hat Enterprise Linux includes tools using which you can identify and audit applications on the basis of their CPU usage. For more information see, \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index#audit-and-analysis-overview_importance-of-power-management\">Audit and analysis overview\u003C/a> and \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index#tools-for-auditing_importance-of-power-management\">Tools for auditing\u003C/a>.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Unused hardware and devices should be disabled completely\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThis is true for devices that have moving parts, for example, hard disks. In addition to this, some applications may leave an unused but enabled device \"open\"; when this occurs, the kernel assumes that the device is in use, which can prevent the device from going into a power saving state.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Low activity should translate to low wattage\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIn many cases, however, this depends on modern hardware and correct BIOS configuration or UEFI on modern systems, including non-x86 architectures. Make sure that you are using the latest official firmware for your systems and that in the power management or device configuration sections of the BIOS the power management features are enabled. Some features to look for include:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tCollaborative Processor Performance Controls (CPPC) support for ARM64\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tPowerNV support for IBM Power Systems\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tSpeedStep\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tPowerNow!\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tCool’n’Quiet\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tACPI (C-state)\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tSmart\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tIf your hardware has support for these features and they are enabled in the BIOS, Red Hat Enterprise Linux uses them by default.\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Different forms of CPU states and their effects\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tModern CPUs together with Advanced Configuration and Power Interface (ACPI) provide different power states. The three different states are:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tSleep (C-states)\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tFrequency and voltage (P-states)\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tHeat output (T-states or thermal states)\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tA CPU running on the lowest sleep state, consumes the least amount of watts, but it also takes considerably more time to wake it up from that state when needed. In very rare cases this can lead to the CPU having to wake up immediately every time it just went to sleep. This situation results in an effectively permanently busy CPU and loses some of the potential power saving if another state had been used.\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">A turned off machine uses the least amount of power\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tOne of the best ways to save power is to turn off systems. For example, your company can develop a corporate culture focused on \"green IT\" awareness with a guideline to turn off machines during lunch break or when going home. You also might consolidate several physical servers into one bigger server and virtualize them using the virtualization technology, which is shipped with Red Hat Enterprise Linux.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"audit-and-analysis-overview_importance-of-power-management\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">14.2. Audit and analysis overview\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe detailed manual audit, analysis, and tuning of a single system is usually the exception because the time and cost spent to do so typically outweighs the benefits gained from these last pieces of system tuning.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tHowever, performing these tasks once for a large number of nearly identical systems where you can reuse the same settings for all systems can be very useful. For example, consider the deployment of thousands of desktop systems, or an HPC cluster where the machines are nearly identical. Another reason to do auditing and analysis is to provide a basis for comparison against which you can identify regressions or changes in system behavior in the future. The results of this analysis can be very helpful in cases where hardware, BIOS, or software updates happen regularly and you want to avoid any surprises with regard to power consumption. Generally, a thorough audit and analysis gives you a much better idea of what is really happening on a particular system.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tAuditing and analyzing a system with regard to power consumption is relatively hard, even with the most modern systems available. Most systems do not provide the necessary means to measure power use via software. Exceptions exist though:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tiLO management console of Hewlett Packard server systems has a power management module that you can access through the web.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIBM provides a similar solution in their BladeCenter power management module.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tOn some Dell systems, the IT Assistant offers power monitoring capabilities as well.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tOther vendors are likely to offer similar capabilities for their server platforms, but as can be seen there is no single solution available that is supported by all vendors. Direct measurements of power consumption are often only necessary to maximize savings as far as possible.\n\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"tools-for-auditing_importance-of-power-management\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">14.3. Tools for auditing\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tRed Hat Enterprise Linux 8 offers tools using which you can perform system auditing and analysis. Most of them can be used as supplementary sources of information in case you want to verify what you have discovered already or in case you need more in-depth information about certain parts.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tMany of these tools are used for performance tuning as well, which include:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">PowerTOP\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tIt identifies specific components of kernel and user-space applications that frequently wake up the CPU. Use the \u003Ccode class=\"literal\">powertop\u003C/code> command as root to start the \u003Cspan class=\"strong strong\">\u003Cstrong>PowerTop\u003C/strong>\u003C/span> tool and \u003Ccode class=\"literal\">powertop --calibrate\u003C/code> to calibrate the power estimation engine. For more information about PowerTop, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index#managing-power-consumption-with-powertop_monitoring-and-managing-system-status-and-performance\">Managing power consumption with PowerTOP\u003C/a>.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Diskdevstat and netdevstat\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThey are SystemTap tools that collect detailed information about the disk activity and network activity of all applications running on a system. Using the collected statistics by these tools, you can identify applications that waste power with many small I/O operations rather than fewer, larger operations. Using the \u003Ccode class=\"literal\">dnf install tuned-utils-systemtap kernel-debuginfo\u003C/code> command as root, install the \u003Ccode class=\"literal\">diskdevstat\u003C/code> and \u003Ccode class=\"literal\">netdevstat\u003C/code> tool.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tTo view the detailed information about the disk and network activity, use:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout white-space-pre\"># diskdevstat\n\nPID   UID   DEV   WRITE_CNT   WRITE_MIN   WRITE_MAX   WRITE_AVG   READ_CNT   READ_MIN   READ_MAX   READ_AVG   COMMAND\n\n3575  1000  dm-2   59          0.000      0.365        0.006        5         0.000        0.000      0.000      mozStorage #5\n3575  1000  dm-2    7          0.000      0.000        0.000        0         0.000        0.000      0.000      localStorage DB\n[...]\n\n\n# netdevstat\n\nPID   UID   DEV       XMIT_CNT   XMIT_MIN   XMIT_MAX   XMIT_AVG   RECV_CNT   RECV_MIN   RECV_MAX   RECV_AVG   COMMAND\n3572  991  enp0s31f6    40       0.000      0.882       0.108        0         0.000       0.000       0.000     openvpn\n3575  1000 enp0s31f6    27       0.000      1.363       0.160        0         0.000       0.000       0.000     Socket Thread\n[...]\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tWith these commands, you can specify three parameters: \u003Ccode class=\"literal\">update_interval\u003C/code>, \u003Ccode class=\"literal\">total_duration\u003C/code>, and \u003Ccode class=\"literal\">display_histogram\u003C/code>.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">TuneD\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tIt is a profile-based system tuning tool that uses the \u003Ccode class=\"literal\">udev\u003C/code> device manager to monitor connected devices, and enables both static and dynamic tuning of system settings. You can use the \u003Ccode class=\"literal\">tuned-adm recommend\u003C/code> command to determine which profile Red Hat recommends as the most suitable for a particular product. For more information about TuneD, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index#getting-started-with-tuned_monitoring-and-managing-system-status-and-performance\">Getting started with TuneD\u003C/a> and \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index#customizing-tuned-profiles_monitoring-and-managing-system-status-and-performance\">Customizing TuneD profiles\u003C/a>. Using the \u003Ccode class=\"literal\">powertop2tuned utility\u003C/code>, you can create custom TuneD profiles from \u003Ccode class=\"literal\">PowerTOP\u003C/code> suggestions. For information about the \u003Ccode class=\"literal\">powertop2tuned\u003C/code> utility, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index#optimizing-power-consumption_managing-power-consumption-with-powertop\">Optimizing power consumption\u003C/a>.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Virtual memory statistics (vmstat)\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIt is provided by the \u003Ccode class=\"literal\">procps-ng\u003C/code> package. Using this tool, you can view the detailed information about processes, memory, paging, block I/O, traps, and CPU activity.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tTo view this information, use:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout white-space-pre\">$ vmstat\nprocs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----\nr  b  swpd  free    buff   cache   si   so  bi   bo   in  cs  us  sy id  wa  st\n1  0   0   5805576 380856 4852848   0    0  119  73  814  640  2   2 96   0   0\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tUsing the \u003Ccode class=\"literal\">vmstat -a\u003C/code> command, you can display active and inactive memory. For more information about other \u003Ccode class=\"literal\">vmstat\u003C/code> options, see the \u003Ccode class=\"literal\">vmstat\u003C/code> man page on your system.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">iostat\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIt is provided by the \u003Ccode class=\"literal\">sysstat\u003C/code> package. This tool is similar to \u003Ccode class=\"literal\">vmstat\u003C/code>, but only for monitoring I/O on block devices. It also provides more verbose output and statistics.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tTo monitor the system I/O, use:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout white-space-pre\">$ iostat\navg-cpu:  %user   %nice %system %iowait  %steal   %idle\n           2.05    0.46    1.55    0.26    0.00   95.67\n\nDevice     tps     kB_read/s    kB_wrtn/s    kB_read    kB_wrtn\nnvme0n1    53.54     899.48     616.99      3445229     2363196\ndm-0       42.84     753.72     238.71      2886921      914296\ndm-1        0.03       0.60       0.00         2292           0\ndm-2       24.15     143.12     379.80       548193     1454712\u003C/pre>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">blktrace\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIt provides detailed information about how time is spent in the I/O subsystem.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tTo view this information in human readable format, use:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout white-space-pre\"># blktrace -d /dev/dm-0 -o - | blkparse -i -\n\n253,0   1    1   0.000000000  17694  Q   W 76423384 + 8 [kworker/u16:1]\n253,0   2    1   0.001926913     0   C   W 76423384 + 8 [0]\n[...]\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tHere, The first column, \u003Cspan class=\"strong strong\">\u003Cstrong>253,0\u003C/strong>\u003C/span> is the device major and minor tuple. The second column, \u003Cspan class=\"strong strong\">\u003Cstrong>1\u003C/strong>\u003C/span>, gives information about the CPU, followed by columns for timestamps and PID of the process issuing the IO process.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe sixth column, \u003Cspan class=\"strong strong\">\u003Cstrong>Q\u003C/strong>\u003C/span>, shows the event type, the 7th column, \u003Cspan class=\"strong strong\">\u003Cstrong>W\u003C/strong>\u003C/span> for write operation, the 8th column, \u003Cspan class=\"strong strong\">\u003Cstrong>76423384\u003C/strong>\u003C/span>, is the block number, and the \u003Cspan class=\"strong strong\">\u003Cstrong>+ 8\u003C/strong>\u003C/span> is the number of requested blocks.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe last field, \u003Cspan class=\"strong strong\">\u003Cstrong>[kworker/u16:1]\u003C/strong>\u003C/span>, is the process name.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tBy default, the \u003Ccode class=\"literal\">blktrace\u003C/code> command runs forever until the process is explicitly killed. Use the \u003Ccode class=\"literal\">-w\u003C/code> option to specify the run-time duration.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">turbostat\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIt is provided by the \u003Ccode class=\"literal\">kernel-tools\u003C/code> package. It reports on processor topology, frequency, idle power-state statistics, temperature, and power usage on x86-64 processors.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tTo view this summary, use:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout white-space-pre\"># turbostat\n\nCPUID(0): GenuineIntel 0x16 CPUID levels; 0x80000008 xlevels; family:model:stepping 0x6:8e:a (6:142:10)\nCPUID(1): SSE3 MONITOR SMX EIST TM2 TSC MSR ACPI-TM HT TM\nCPUID(6): APERF, TURBO, DTS, PTM, HWP, HWPnotify, HWPwindow, HWPepp, No-HWPpkg, EPB\n[...]\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tBy default, \u003Ccode class=\"literal\">turbostat\u003C/code> prints a summary of counter results for the entire screen, followed by counter results every 5 seconds. Specify a different period between counter results with the \u003Ccode class=\"literal\">-i\u003C/code> option, for example, execute \u003Ccode class=\"literal\">turbostat -i 10\u003C/code> to print results every 10 seconds instead.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>Turbostat\u003C/strong>\u003C/span> is also useful for identifying servers that are inefficient in terms of power usage or idle time. It also helps to identify the rate of system management interrupts (SMIs) occurring on the system. It can also be used to verify the effects of power management tuning.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">cpupower\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIT is a collection of tools to examine and tune power saving related features of processors. Use the \u003Ccode class=\"literal\">cpupower\u003C/code> command with the \u003Ccode class=\"literal\">frequency-info\u003C/code>, \u003Ccode class=\"literal\">frequency-set\u003C/code>, \u003Ccode class=\"literal\">idle-info\u003C/code>, \u003Ccode class=\"literal\">idle-set\u003C/code>, \u003Ccode class=\"literal\">set\u003C/code>, \u003Ccode class=\"literal\">info\u003C/code>, and \u003Ccode class=\"literal\">monitor\u003C/code> options to display and set processor related values.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFor example, to view available cpufreq governors, use:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout white-space-pre\">$ cpupower frequency-info --governors\nanalyzing CPU 0:\n  available cpufreq governors: performance powersave\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFor more information about \u003Ccode class=\"literal\">cpupower\u003C/code>, see Viewing CPU related information.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">GNOME Power Manager\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tIt is a daemon that is installed as part of the GNOME desktop environment. GNOME Power Manager notifies you of changes in your system’s power status; for example, a change from battery to AC power. It also reports battery status, and warns you when battery power is low.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">powertop(1)\u003C/code>, \u003Ccode class=\"literal\">diskdevstat(8)\u003C/code>, \u003Ccode class=\"literal\">netdevstat(8)\u003C/code>, \u003Ccode class=\"literal\">tuned(8)\u003C/code>, \u003Ccode class=\"literal\">vmstat(8)\u003C/code>, \u003Ccode class=\"literal\">iostat(1)\u003C/code>, \u003Ccode class=\"literal\">blktrace(8)\u003C/code>, \u003Ccode class=\"literal\">blkparse(8)\u003C/code>, and \u003Ccode class=\"literal\">turbostat(8)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">cpupower(1)\u003C/code>, \u003Ccode class=\"literal\">cpupower-set(1)\u003C/code>, \u003Ccode class=\"literal\">cpupower-info(1)\u003C/code>, \u003Ccode class=\"literal\">cpupower-idle(1)\u003C/code>, \u003Ccode class=\"literal\">cpupower-frequency-set(1)\u003C/code>, \u003Ccode class=\"literal\">cpupower-frequency-info(1)\u003C/code>, and \u003Ccode class=\"literal\">cpupower-monitor(1)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"managing-power-consumption-with-powertop_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 15. Managing power consumption with PowerTOP\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\tAs a system administrator, you can use the \u003Cspan class=\"strong strong\">\u003Cstrong>\u003Cspan class=\"application application\">PowerTOP\u003C/span>\u003C/strong>\u003C/span> tool to analyze and manage power consumption.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"the-purpose-of-powertop_managing-power-consumption-with-powertop\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">15.1. The purpose of PowerTOP\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>\u003Cspan class=\"application application\">PowerTOP\u003C/span>\u003C/strong>\u003C/span> is a program that diagnoses issues related to power consumption and provides suggestions on how to extend battery lifetime.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe \u003Cspan class=\"strong strong\">\u003Cstrong>\u003Cspan class=\"application application\">PowerTOP\u003C/span>\u003C/strong>\u003C/span> tool can provide an estimate of the total power usage of the system and also individual power usage for each process, device, kernel worker, timer, and interrupt handler. The tool can also identify specific components of kernel and user-space applications that frequently wake up the CPU.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tRed Hat Enterprise Linux 9 uses version 2.x of \u003Cspan class=\"strong strong\">\u003Cstrong>\u003Cspan class=\"application application\">PowerTOP\u003C/span>\u003C/strong>\u003C/span>.\n\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"using-powertop_managing-power-consumption-with-powertop\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">15.2. Using PowerTOP\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo be able to use \u003Cspan class=\"strong strong\">\u003Cstrong>\u003Cspan class=\"application application\">PowerTOP\u003C/span>\u003C/strong>\u003C/span>, make sure that the \u003Ccode class=\"literal package\">powertop\u003C/code> package has been installed on your system:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf install powertop\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Csection class=\"section\" id=\"starting-powertop_using-powertop\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">15.2.1. Starting PowerTOP\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tTo run \u003Cspan class=\"strong strong\">\u003Cstrong>\u003Cspan class=\"application application\">PowerTOP\u003C/span>\u003C/strong>\u003C/span>, use the following command:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>powertop\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\tLaptops should run on battery power when running the \u003Ccode class=\"literal package\">powertop\u003C/code> command.\n\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/section>\u003Csection class=\"section\" id=\"calibrating-powertop_using-powertop\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">15.2.2. Calibrating PowerTOP\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tOn a laptop, you can calibrate the power estimation engine by running the following command:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>powertop --calibrate\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tLet the calibration finish without interacting with the machine during the process.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tCalibration takes time because the process performs various tests, cycles through brightness levels and switches devices on and off.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tWhen the calibration process is completed, \u003Cspan class=\"strong strong\">\u003Cstrong>\u003Cspan class=\"application application\">PowerTOP\u003C/span>\u003C/strong>\u003C/span> starts as normal. Let it run for approximately an hour to collect data.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tWhen enough data is collected, power estimation figures will be displayed in the first column of the output table.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\tNote that \u003Ccode class=\"literal command\">powertop --calibrate\u003C/code> can only be used on laptops.\n\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/section>\u003Csection class=\"section\" id=\"setting-the-measuring-interval_using-powertop\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">15.2.3. Setting the measuring interval\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tBy default, \u003Cspan class=\"strong strong\">\u003Cstrong>\u003Cspan class=\"application application\">PowerTOP\u003C/span>\u003C/strong>\u003C/span> takes measurements in 20 seconds intervals.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tIf you want to change this measuring frequency, use the following procedure:\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tRun the \u003Ccode class=\"literal command\">powertop\u003C/code> command with the \u003Ccode class=\"literal option\">--time\u003C/code> option:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>powertop --time=\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"replaceable replaceable\">time in seconds\u003C/span>\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section _additional-resources\" id=\"related-information-using-powertop\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">15.2.4. Additional resources\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tFor more details on how to use \u003Cspan class=\"strong strong\">\u003Cstrong>\u003Cspan class=\"application application\">PowerTOP\u003C/span>\u003C/strong>\u003C/span>, see the \u003Ccode class=\"literal\">powertop\u003C/code> man page on your system\n\t\t\t\t\u003C/p>\u003C/section>\u003C/section>\u003Csection class=\"section\" id=\"powertop-statistics_managing-power-consumption-with-powertop\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">15.3. PowerTOP statistics\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tWhile it runs, \u003Cspan class=\"strong strong\">\u003Cstrong>\u003Cspan class=\"application application\">PowerTOP\u003C/span>\u003C/strong>\u003C/span> gathers statistics from the system.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>\u003Cspan class=\"application application\">PowerTOP\u003C/span>\u003C/strong>\u003C/span>'s output provides multiple tabs:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">Overview\u003C/code>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">Idle stats\u003C/code>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">Frequency stats\u003C/code>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">Device stats\u003C/code>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">Tunables\u003C/code>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">WakeUp\u003C/code>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tYou can use the \u003Ccode class=\"literal\">Tab\u003C/code> and \u003Ccode class=\"literal\">Shift+Tab\u003C/code> keys to cycle through these tabs.\n\t\t\t\u003C/p>\u003Csection class=\"section\" id=\"overview-tab_managing-power-consumption-with-powertop\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">15.3.1. The Overview tab\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tIn the \u003Ccode class=\"literal\">Overview\u003C/code> tab, you can view a list of the components that either send wakeups to the CPU most frequently or consume the most power. The items within the \u003Ccode class=\"literal\">Overview\u003C/code> tab, including processes, interrupts, devices, and other resources, are sorted according to their utilization.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tThe adjacent columns within the \u003Ccode class=\"literal\">Overview\u003C/code> tab provide the following pieces of information:\n\t\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">Usage\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\tPower estimation of how the resource is being used.\n\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Events/s\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\tWakeups per second. The number of wakeups per second indicates how efficiently the services or the devices and drivers of the kernel are performing. Less wakeups means that less power is consumed. Components are ordered by how much further their power usage can be optimized.\n\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Category\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\tClassification of the component; such as process, device, or timer.\n\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Description\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\tDescription of the component.\n\t\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cp>\n\t\t\t\t\tIf properly calibrated, a power consumption estimation for every listed item in the first column is shown as well.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tApart from this, the \u003Ccode class=\"literal\">Overview\u003C/code> tab includes the line with summary statistics such as:\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tTotal power consumption\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tRemaining battery life (only if applicable)\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tSummary of total wakeups per second, GPU operations per second, and virtual file system operations per second\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"idle-stats-tab_managing-power-consumption-with-powertop\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">15.3.2. The Idle stats tab\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tThe \u003Ccode class=\"literal\">Idle stats\u003C/code> tab shows usage of C-states for all processors and cores, while the \u003Ccode class=\"literal\">Frequency stats\u003C/code> tab shows usage of P-states including the Turbo mode, if applicable, for all processors and cores. The duration of C- or P-states is an indication of how well the CPU usage has been optimized. The longer the CPU stays in the higher C- or P-states (for example C4 is higher than C3), the better the CPU usage optimization is. Ideally, residency is 90% or more in the highest C- or P-state when the system is idle.\n\t\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"device-stats-tab_managing-power-consumption-with-powertop\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">15.3.3. The Device stats tab\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tThe \u003Ccode class=\"literal\">Device stats\u003C/code> tab provides similar information to the \u003Ccode class=\"literal\">Overview\u003C/code> tab but only for devices.\n\t\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"tunables-tab_managing-power-consumption-with-powertop\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">15.3.4. The Tunables tab\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tThe \u003Ccode class=\"literal\">Tunables\u003C/code> tab contains \u003Cspan class=\"strong strong\">\u003Cstrong>\u003Cspan class=\"application application\">PowerTOP\u003C/span>\u003C/strong>\u003C/span>'s suggestions for optimizing the system for lower power consumption.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tUse the \u003Ccode class=\"literal\">up\u003C/code> and \u003Ccode class=\"literal\">down\u003C/code> keys to move through suggestions, and the \u003Ccode class=\"literal\">enter\u003C/code> key to toggle the suggestion on or off.\n\t\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"wakeup-tab_managing-power-consumption-with-powertop\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">15.3.5. The WakeUp tab\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tThe \u003Ccode class=\"literal\">WakeUp\u003C/code> tab displays the device wakeup settings available for users to change as and when required.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tUse the \u003Ccode class=\"literal\">up\u003C/code> and \u003Ccode class=\"literal\">down\u003C/code> keys to move through the available settings, and the \u003Ccode class=\"literal\">enter\u003C/code> key to enable or disable a setting.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"figure\" id=\"idm140280139869856\">\u003Cp class=\"title\">\u003Cstrong>Figure 15.1. PowerTOP output\u003C/strong>\u003C/p>\u003Cdiv class=\"figure-contents\">\u003Cdiv class=\"mediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/99b231a090ded326ccc3823ca0f7f134/powertop2-14.png\" alt=\"powertop2 14\"/>\u003C/div>\u003C/div>\u003C/div>\u003Cdiv class=\"_additional-resources _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cp>\n\t\t\t\t\t\tFor more details on \u003Cspan class=\"strong strong\">\u003Cstrong>\u003Cspan class=\"application application\">PowerTOP\u003C/span>\u003C/strong>\u003C/span>, see \u003Ca class=\"link\" href=\"https://01.org/powertop/\">PowerTOP’s home page\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"section\" id=\"con_why-powertop-does-not-display-frequency-stats-values-in-some-instances_managing-power-consumption-with-powertop\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">15.4. Why Powertop does not display Frequency stats values in some instances\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tWhile using the Intel P-State driver, PowerTOP only displays values in the \u003Ccode class=\"literal\">Frequency Stats\u003C/code> tab if the driver is in passive mode. But, even in this case, the values may be incomplete.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tIn total, there are three possible modes of the Intel P-State driver:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tActive mode with Hardware P-States (HWP)\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tActive mode without HWP\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tPassive mode\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tSwitching to the ACPI CPUfreq driver results in complete information being displayed by PowerTOP. However, it is recommended to keep your system on the default settings.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tTo see what driver is loaded and in what mode, run:\n\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_driver\u003C/strong>\u003C/span>\u003C/pre>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">intel_pstate\u003C/code> is returned if the Intel P-State driver is loaded and in active mode.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">intel_cpufreq\u003C/code> is returned if the Intel P-State driver is loaded and in passive mode.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">acpi-cpufreq\u003C/code> is returned if the ACPI CPUfreq driver is loaded.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tWhile using the Intel P-State driver, add the following argument to the kernel boot command line to force the driver to run in passive mode:\n\t\t\t\u003C/p>\u003Cpre class=\"screen\">intel_pstate=passive\u003C/pre>\u003Cp>\n\t\t\t\tTo disable the Intel P-State driver and use, instead, the ACPI CPUfreq driver, add the following argument to the kernel boot command line:\n\t\t\t\u003C/p>\u003Cpre class=\"screen\">intel_pstate=disable\u003C/pre>\u003C/section>\u003Csection class=\"section\" id=\"generating-an-html-output_managing-power-consumption-with-powertop\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">15.5. Generating an HTML output\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tApart from the \u003Ccode class=\"literal command\">powertop’s\u003C/code> output in terminal, you can also generate an HTML report.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRun the \u003Ccode class=\"literal command\">powertop\u003C/code> command with the \u003Ccode class=\"literal option\">--html\u003C/code> option:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>powertop --html=htmlfile.html\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tReplace the \u003Ccode class=\"literal\">htmlfile.html\u003C/code> parameter with the required name for the output file.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"optimizing-power-consumption_managing-power-consumption-with-powertop\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">15.6. Optimizing power consumption\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tTo optimize power consumption, you can use either the \u003Ccode class=\"literal\">powertop\u003C/code> service or the \u003Ccode class=\"literal\">powertop2tuned\u003C/code> utility.\n\t\t\t\u003C/p>\u003Csection class=\"section\" id=\"optimizing-power-consumption-using-the-powertop-service_optimizing-power-consumption\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">15.6.1. Optimizing power consumption using the powertop service\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tYou can use the \u003Ccode class=\"literal\">powertop\u003C/code> service to automatically enable all \u003Cspan class=\"strong strong\">\u003Cstrong>\u003Cspan class=\"application application\">PowerTOP\u003C/span>\u003C/strong>\u003C/span>'s suggestions from the \u003Ccode class=\"literal\">Tunables\u003C/code> tab on the boot:\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tEnable the \u003Ccode class=\"literal\">powertop\u003C/code> service:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl enable powertop\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"powertop2tuned-utility_optimizing-power-consumption\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">15.6.2. The powertop2tuned utility\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tThe \u003Ccode class=\"literal\">powertop2tuned\u003C/code> utility allows you to create custom \u003Cspan class=\"strong strong\">\u003Cstrong>\u003Cspan class=\"application application\">TuneD\u003C/span>\u003C/strong>\u003C/span> profiles from \u003Cspan class=\"strong strong\">\u003Cstrong>\u003Cspan class=\"application application\">PowerTOP\u003C/span>\u003C/strong>\u003C/span> suggestions.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tBy default, \u003Ccode class=\"literal\">powertop2tuned\u003C/code> creates profiles in the \u003Ccode class=\"literal filename\">/etc/tuned/\u003C/code> directory, and bases the custom profile on the currently selected \u003Cspan class=\"strong strong\">\u003Cstrong>\u003Cspan class=\"application application\">TuneD\u003C/span>\u003C/strong>\u003C/span> profile. For safety reasons, all \u003Cspan class=\"strong strong\">\u003Cstrong>\u003Cspan class=\"application application\">PowerTOP\u003C/span>\u003C/strong>\u003C/span> tunings are initially disabled in the new profile.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tTo enable the tunings, you can:\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tUncomment them in the \u003Ccode class=\"literal filename\">/etc/tuned/profile_name/tuned.conf file\u003C/code>.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tUse the \u003Ccode class=\"literal option\">--enable\u003C/code> or \u003Ccode class=\"literal option\">-e\u003C/code> option to generate a new profile that enables most of the tunings suggested by \u003Cspan class=\"strong strong\">\u003Cstrong>\u003Cspan class=\"application application\">PowerTOP\u003C/span>\u003C/strong>\u003C/span>.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tCertain potentially problematic tunings, such as the USB autosuspend, are disabled by default and need to be uncommented manually.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"optimizing-power-consumption-with-powertop2tuned_optimizing-power-consumption\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">15.6.3. Optimizing power consumption using the powertop2tuned utility\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">powertop2tuned\u003C/code> utility is installed on the system:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>dnf install tuned-utils\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tCreate a custom profile:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>powertop2tuned new_profile_name\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tActivate the new profile:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>tuned-adm profile new_profile_name\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Additional information\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFor a complete list of options that \u003Ccode class=\"literal\">powertop2tuned\u003C/code> supports, use:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>powertop2tuned --help\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"con_comparison-of-powertop-service-and-powertop2tuned_optimizing-power-consumption\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">15.6.4. Comparison of powertop.service and powertop2tuned\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tOptimizing power consumption with \u003Ccode class=\"literal\">powertop2tuned\u003C/code> is preferred over \u003Ccode class=\"literal\">powertop.service\u003C/code> for the following reasons:\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">powertop2tuned\u003C/code> utility represents integration of \u003Cspan class=\"strong strong\">\u003Cstrong>\u003Cspan class=\"application application\">PowerTOP\u003C/span>\u003C/strong>\u003C/span> into \u003Cspan class=\"strong strong\">\u003Cstrong>\u003Cspan class=\"application application\">TuneD\u003C/span>\u003C/strong>\u003C/span>, which enables to benefit of advantages of both tools.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">powertop2tuned\u003C/code> utility allows for fine-grained control of enabled tuning.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tWith \u003Ccode class=\"literal\">powertop2tuned\u003C/code>, potentially dangerous tuning are not automatically enabled.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tWith \u003Ccode class=\"literal\">powertop2tuned\u003C/code>, rollback is possible without reboot.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"getting-started-with-perf_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 16. Getting started with perf\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tAs a system administrator, you can use the \u003Ccode class=\"literal\">perf\u003C/code> tool to collect and analyze performance data of your system.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"introduction-to-perf_getting-started-with-perf\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">16.1. Introduction to perf\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe \u003Ccode class=\"literal\">perf\u003C/code> user-space tool interfaces with the kernel-based subsystem \u003Cspan class=\"emphasis\">\u003Cem>Performance Counters for Linux\u003C/em>\u003C/span> (PCL). \u003Ccode class=\"literal\">perf\u003C/code> is a powerful tool that uses the Performance Monitoring Unit (PMU) to measure, record, and monitor a variety of hardware and software events. \u003Ccode class=\"literal\">perf\u003C/code> also supports tracepoints, kprobes, and uprobes.\n\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"installing-perf_getting-started-with-perf\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">16.2. Installing perf\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure installs the \u003Ccode class=\"literal\">perf\u003C/code> user-space tool.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInstall the \u003Ccode class=\"literal\">perf\u003C/code> tool:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf install perf\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"common-perf-commands_getting-started-with-perf\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">16.3. Common perf commands\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cdiv class=\"variablelist _abstract\">\u003Cdl class=\"variablelist _abstract\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal command\">perf stat\u003C/code> \u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThis command provides overall statistics for common performance events, including instructions executed and clock cycles consumed. Options allow for selection of events other than the default measurement events.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal command\">perf record\u003C/code> \u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThis command records performance data into a file, \u003Ccode class=\"literal\">perf.data\u003C/code>, which can be later analyzed using the \u003Ccode class=\"literal\">perf report\u003C/code> command.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal command\">perf report\u003C/code> \u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThis command reads and displays the performance data from the \u003Ccode class=\"literal\">perf.data\u003C/code> file created by \u003Ccode class=\"literal\">perf record\u003C/code>.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal command\">perf list\u003C/code> \u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThis command lists the events available on a particular machine. These events will vary based on performance monitoring hardware and software configuration of the system.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal command\">perf top\u003C/code> \u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThis command performs a similar function to the \u003Ccode class=\"literal\">top\u003C/code> utility. It generates and displays a performance counter profile in realtime.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal command\">perf trace\u003C/code> \u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThis command performs a similar function to the \u003Ccode class=\"literal\">strace\u003C/code> tool. It monitors the system calls used by a specified thread or process and all signals received by that application.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal command\">perf help\u003C/code> \u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThis command displays a complete list of \u003Ccode class=\"literal\">perf\u003C/code> commands.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tAdd the \u003Ccode class=\"literal\">--help\u003C/code> option to a subcommand to open the man page.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"profiling-cpu-usage-in-real-time-with-top_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 17. Profiling CPU usage in real time with perf top\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tYou can use the \u003Ccode class=\"literal command\">perf top\u003C/code> command to measure CPU usage of different functions in real time.\n\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\tYou have the \u003Ccode class=\"literal\">perf\u003C/code> user space tool installed as described in \u003Ca class=\"link\" href=\"#installing-perf_getting-started-with-perf\" title=\"16.2. Installing perf\">Installing perf\u003C/a>.\n\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Csection class=\"section\" id=\"the-purpose-of-perf-top_profiling-cpu-usage-in-real-time-with-top\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">17.1. The purpose of perf top\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe \u003Ccode class=\"literal command\">perf top\u003C/code> command is used for real time system profiling and functions similarly to the \u003Ccode class=\"literal\">top\u003C/code> utility. However, where the \u003Ccode class=\"literal\">top\u003C/code> utility generally shows you how much CPU time a given process or thread is using, \u003Ccode class=\"literal command\">perf top\u003C/code> shows you how much CPU time each specific function uses. In its default state, \u003Ccode class=\"literal command\">perf top\u003C/code> tells you about functions being used across all CPUs in both the user-space and the kernel-space. To use \u003Ccode class=\"literal command\">perf top\u003C/code> you need root access.\n\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"profiling-cpu-usage-with-perf-top_profiling-cpu-usage-in-real-time-with-top\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">17.2. Profiling CPU usage with perf top\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure activates \u003Ccode class=\"literal\">perf top\u003C/code> and profiles CPU usage in real time.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have the \u003Ccode class=\"literal\">perf\u003C/code> user space tool installed as described in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf\">Installing perf\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have root access\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tStart the \u003Ccode class=\"literal\">perf top\u003C/code> monitoring interface:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># perf top\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe monitoring interface looks similar to the following:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">Samples: 8K of event 'cycles', 2000 Hz, Event count (approx.): 4579432780 lost: 0/0 drop: 0/0\nOverhead  Shared Object       Symbol\n   2.20%  [kernel]            [k] do_syscall_64\n   2.17%  [kernel]            [k] module_get_kallsym\n   1.49%  [kernel]            [k] copy_user_enhanced_fast_string\n   1.37%  libpthread-2.29.so  [.] \u003Cspan class=\"emphasis\">\u003Cem>pthread_mutex_lock 1.31% [unknown] [.] 0000000000000000 1.07% [kernel] [k] psi_task_change 1.04% [kernel] [k] switch_mm_irqs_off 0.94% [kernel] [k] \u003C/em>\u003C/span>fget\n   0.74%  [kernel]            [k] entry_SYSCALL_64\n   0.69%  [kernel]            [k] syscall_return_via_sysret\n   0.69%  libxul.so           [.] 0x000000000113f9b0\n   0.67%  [kernel]            [k] kallsyms_expand_symbol.constprop.0\n   0.65%  firefox             [.] moz_xmalloc\n   0.65%  libpthread-2.29.so  [.] __pthread_mutex_unlock_usercnt\n   0.60%  firefox             [.] free\n   0.60%  libxul.so           [.] 0x000000000241d1cd\n   0.60%  [kernel]            [k] do_sys_poll\n   0.58%  [kernel]            [k] menu_select\n   0.56%  [kernel]            [k] _raw_spin_lock_irqsave\n   0.55%  perf                [.] 0x00000000002ae0f3\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn this example, the kernel function \u003Ccode class=\"literal\">do_syscall_64\u003C/code> is using the most CPU time.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">perf-top(1)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"interpretation-of-perf-top-output_profiling-cpu-usage-in-real-time-with-top\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">17.3. Interpretation of perf top output\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe \u003Ccode class=\"literal\">perf top\u003C/code> monitoring interface displays the data in several columns:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">The \"Overhead\" column \u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDisplays the percent of CPU a given function is using.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">The \"Shared Object\" column \u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDisplays name of the program or library which is using the function.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">The \"Symbol\" column \u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDisplays the function name or symbol. Functions executed in the kernel-space are identified by \u003Ccode class=\"literal\">[k]\u003C/code> and functions executed in the user-space are identified by \u003Ccode class=\"literal\">[.]\u003C/code>.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"why-perf-displays-some-function-names-as-raw-function-addresses_profiling-cpu-usage-in-real-time-with-top\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">17.4. Why perf displays some function names as raw function addresses\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tFor kernel functions, \u003Ccode class=\"literal\">perf\u003C/code> uses the information from the \u003Ccode class=\"literal\">/proc/kallsyms\u003C/code> file to map the samples to their respective function names or symbols. For functions executed in the user space, however, you might see raw function addresses because the binary is stripped.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe \u003Ccode class=\"literal literal\">debuginfo\u003C/code> package of the executable must be installed or, if the executable is a locally developed application, the application must be compiled with debugging information turned on (the \u003Ccode class=\"literal option\">-g\u003C/code> option in GCC) to display the function names or symbols in such a situation.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tIt is not necessary to re-run the \u003Ccode class=\"literal command\">perf record\u003C/code> command after installing the \u003Ccode class=\"literal literal\">debuginfo\u003C/code> associated with an executable. Simply re-run the \u003Ccode class=\"literal command\">perf report\u003C/code> command.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional Resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/developing_c_and_cpp_applications_in_rhel_9/debugging-applications_developing-applications#enabling-debugging-with-debugging-information_debugging-applications\">Enabling debugging with debugging information\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"enabling-debug-and-source-repositories_profiling-cpu-usage-in-real-time-with-top\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">17.5. Enabling debug and source repositories\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tA standard installation of Red Hat Enterprise Linux does not enable the debug and source repositories. These repositories contain information needed to debug the system components and measure their performance.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnable the source and debug information package channels:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># subscription-manager repos --enable rhel-9-for-$(uname -i)-baseos-debug-rpms\n# subscription-manager repos --enable rhel-9-for-$(uname -i)-baseos-source-rpms\n# subscription-manager repos --enable rhel-9-for-$(uname -i)-appstream-debug-rpms\n# subscription-manager repos --enable rhel-9-for-$(uname -i)-appstream-source-rpms\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">$(uname -i)\u003C/code> part is automatically replaced with a matching value for architecture of your system:\n\t\t\t\t\t\u003C/p>\u003Crh-table>\u003Ctable class=\"lt-4-cols lt-7-rows\">\u003Ccolgroup>\u003Ccol style=\"width: 50%; \" class=\"col_1\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 50%; \" class=\"col_2\">\u003C!--Empty-->\u003C/col>\u003C/colgroup>\u003Cthead>\u003Ctr>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280133060912\" scope=\"col\">Architecture name\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280133059824\" scope=\"col\">Value\u003C/th>\u003C/tr>\u003C/thead>\u003Ctbody>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280133060912\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t64-bit Intel and AMD\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280133059824\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\tx86_64\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280133060912\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t64-bit ARM\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280133059824\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\taarch64\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280133060912\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\tIBM POWER\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280133059824\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\tppc64le\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280133060912\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t64-bit IBM Z\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280133059824\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\ts390x\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\u003C/rh-table>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"getting-debuginfo-packages-for-an-application-or-library-using-gdb_profiling-cpu-usage-in-real-time-with-top\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">17.6. Getting debuginfo packages for an application or library using GDB\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tDebugging information is required to debug code. For code that is installed from a package, the GNU Debugger (GDB) automatically recognizes missing debug information, resolves the package name and provides concrete advice on how to get the package.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe application or library you want to debug must be installed on the system.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tGDB and the \u003Ccode class=\"literal command\">debuginfo-install\u003C/code> tool must be installed on the system. For details, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/developing_c_and_cpp_applications_in_rhel_9/setting-up-a-development-workstation_developing-applications#setting-up-to-debug-applications_setting-up-a-development-workstation\">Setting up to debug applications\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tRepositories providing \u003Ccode class=\"literal\">debuginfo\u003C/code> and \u003Ccode class=\"literal\">debugsource\u003C/code> packages must be configured and enabled on the system. For details, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/developing_c_and_cpp_applications_in_rhel_9/index#enabling-debug-and-source-repositories_setting-up-a-development-workstation\">Enabling debug and source repositories\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tStart GDB attached to the application or library you want to debug. GDB automatically recognizes missing debugging information and suggests a command to run.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ gdb -q /bin/ls\nReading symbols from /bin/ls...Reading symbols from .gnu_debugdata for /usr/bin/ls...(no debugging symbols found)...done.\n(no debugging symbols found)...done.\nMissing separate debuginfos, use: dnf \u003Cspan class=\"emphasis\">\u003Cem>debuginfo-install coreutils-8.30-6.el8.x86_64\u003C/em>\u003C/span>\n(gdb)\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tExit GDB: type \u003Ckbd class=\"keycap\">q\u003C/kbd> and confirm with \u003Ckbd class=\"keycap\">Enter\u003C/kbd>.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">(gdb) q\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRun the command suggested by GDB to install the required \u003Ccode class=\"literal\">debuginfo\u003C/code> packages:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf debuginfo-install coreutils-8.30-6.el8.x86_64\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">dnf\u003C/code> package management tool provides a summary of the changes, asks for confirmation and once you confirm, downloads and installs all the necessary files.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn case GDB is not able to suggest the \u003Ccode class=\"literal\">debuginfo\u003C/code> package, follow the procedure described in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/developing_c_and_cpp_applications_in_rhel_9/debugging-applications_developing-applications#getting-debuginfo-packages-for-an-application-or-library-manually_enabling-debugging-with-debugging-information\">Getting debuginfo packages for an application or library manually\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/solutions/9907\">How can I download or install debuginfo packages for RHEL systems?\u003C/a> (Red Hat Knowledgebase)\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"counting-events-during-process-execution-with-perf-stat_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 18. Counting events during process execution with perf stat\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tYou can use the \u003Ccode class=\"literal command\">perf stat\u003C/code> command to count hardware and software events during process execution.\n\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\tYou have the \u003Ccode class=\"literal\">perf\u003C/code> user space tool installed as described in \u003Ca class=\"link\" href=\"#installing-perf_getting-started-with-perf\" title=\"16.2. Installing perf\">Installing perf\u003C/a>.\n\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Csection class=\"section\" id=\"the-purpose-of-perf-stat_counting-events-during-process-execution-with-perf-stat\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">18.1. The purpose of perf stat\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe \u003Ccode class=\"literal command\">perf stat\u003C/code> command executes a specified command, keeps a running count of hardware and software event occurrences during the commands execution, and generates statistics of these counts. If you do not specify any events, then \u003Ccode class=\"literal command\">perf stat\u003C/code> counts a set of common hardware and software events.\n\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"counting-events-with-perf-stat_counting-events-during-process-execution-with-perf-stat\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">18.2. Counting events with perf stat\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can use \u003Ccode class=\"literal\">perf stat\u003C/code> to count hardware and software event occurrences during command execution and generate statistics of these counts. By default, \u003Ccode class=\"literal\">perf stat\u003C/code> operates in per-thread mode.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have the \u003Ccode class=\"literal\">perf\u003C/code> user space tool installed as described in \u003Ca class=\"link\" href=\"#installing-perf_getting-started-with-perf\" title=\"16.2. Installing perf\">Installing perf\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCount the events.\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tRunning the \u003Ccode class=\"literal command\">perf stat\u003C/code> command without root access will only count events occurring in the user space:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ perf stat ls\u003C/pre>\u003Cdiv class=\"example\" id=\"idm140280183700800\">\u003Cp class=\"title\">\u003Cstrong>Example 18.1. Output of perf stat ran without root access\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cpre class=\"screen\">Desktop  Documents  Downloads  Music  Pictures  Public  Templates  Videos\n\n Performance counter stats for 'ls':\n\n              1.28 msec task-clock:u               #    0.165 CPUs utilized\n                 0      context-switches:u         #    0.000 M/sec\n                 0      cpu-migrations:u           #    0.000 K/sec\n               104      page-faults:u              #    0.081 M/sec\n         1,054,302      cycles:u                   #    0.823 GHz\n         1,136,989      instructions:u             #    1.08  insn per cycle\n           228,531      branches:u                 #  178.447 M/sec\n            11,331      branch-misses:u            #    4.96% of all branches\n\n       0.007754312 seconds time elapsed\n\n       0.000000000 seconds user\n       0.007717000 seconds sys\u003C/pre>\u003C/div>\u003C/div>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tAs you can see in the previous example, when \u003Ccode class=\"literal\">perf stat\u003C/code> runs without root access the event names are followed by \u003Ccode class=\"literal\">:u\u003C/code>, indicating that these events were counted only in the user-space.\n\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tTo count both user-space and kernel-space events, you must have root access when running \u003Ccode class=\"literal command\">perf stat\u003C/code>:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># perf stat ls\u003C/pre>\u003Cdiv class=\"example\" id=\"idm140280183694768\">\u003Cp class=\"title\">\u003Cstrong>Example 18.2. Output of perf stat ran with root access\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cpre class=\"screen\">Desktop  Documents  Downloads  Music  Pictures  Public  Templates  Videos\n\n Performance counter stats for 'ls':\n\n              3.09 msec task-clock                #    0.119 CPUs utilized\n                18      context-switches          #    0.006 M/sec\n                 3      cpu-migrations            #    0.969 K/sec\n               108      page-faults               #    0.035 M/sec\n         6,576,004      cycles                    #    2.125 GHz\n         5,694,223      instructions              #    0.87  insn per cycle\n         1,092,372      branches                  #  352.960 M/sec\n            31,515      branch-misses             #    2.89% of all branches\n\n       0.026020043 seconds time elapsed\n\n       0.000000000 seconds user\n       0.014061000 seconds sys\u003C/pre>\u003C/div>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"square\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\tBy default, \u003Ccode class=\"literal\">perf stat\u003C/code> operates in per-thread mode. To change to CPU-wide event counting, pass the \u003Ccode class=\"literal\">-a\u003C/code> option to \u003Ccode class=\"literal\">perf stat\u003C/code>. To count CPU-wide events, you need root access:\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># perf stat -a ls\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">perf-stat(1)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"interpretation-of-perf-stat-output_counting-events-during-process-execution-with-perf-stat\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">18.3. Interpretation of perf stat output\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\t\u003Ccode class=\"literal\">perf stat\u003C/code> executes a specified command and counts event occurrences during the commands execution and displays statistics of these counts in three columns:\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe number of occurrences counted for a given event\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe name of the event that was counted\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tWhen related metrics are available, a ratio or percentage is displayed after the hash sign (\u003Ccode class=\"literal\">#\u003C/code>) in the right-most column.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor example, when running in default mode, \u003Ccode class=\"literal\">perf stat\u003C/code> counts both cycles and instructions and, therefore, calculates and displays instructions per cycle in the right-most column. You can see similar behavior with regard to branch-misses as a percent of all branches since both events are counted by default.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"attaching-perf-stat-to-a-running-process_counting-events-during-process-execution-with-perf-stat\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">18.4. Attaching perf stat to a running process\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can attach \u003Ccode class=\"literal\">perf stat\u003C/code> to a running process. This will instruct \u003Ccode class=\"literal\">perf stat\u003C/code> to count event occurrences only in the specified processes during the execution of a command.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have the \u003Ccode class=\"literal\">perf\u003C/code> user space tool installed as described in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf\">Installing perf\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAttach \u003Ccode class=\"literal\">perf stat\u003C/code> to a running process:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ perf stat -p \u003Cspan class=\"emphasis\">\u003Cem>ID1,ID2\u003C/em>\u003C/span> sleep \u003Cspan class=\"emphasis\">\u003Cem>seconds\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe previous example counts events in the processes with the IDs of \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>ID1\u003C/em>\u003C/span>\u003C/code> and \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>ID2\u003C/em>\u003C/span>\u003C/code> for a time period of \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>seconds\u003C/em>\u003C/span>\u003C/code> seconds as dictated by using the \u003Ccode class=\"literal\">sleep\u003C/code> command.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">perf-stat(1)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"recording-and-analyzing-performance-profiles-with-perf_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 19. Recording and analyzing performance profiles with perf\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tThe \u003Ccode class=\"literal\">perf\u003C/code> tool allows you to record performance data and analyze it at a later time.\n\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\tYou have the \u003Ccode class=\"literal\">perf\u003C/code> user space tool installed as described in \u003Ca class=\"link\" href=\"#installing-perf_getting-started-with-perf\" title=\"16.2. Installing perf\">Installing perf\u003C/a>.\n\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Csection class=\"section\" id=\"the-purpose-of-perf-record_recording-and-analyzing-performance-profiles-with-perf\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">19.1. The purpose of perf record\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe \u003Ccode class=\"literal command\">perf record\u003C/code> command samples performance data and stores it in a file, \u003Ccode class=\"literal file\">perf.data\u003C/code>, which can be read and visualized with other \u003Ccode class=\"literal\">perf\u003C/code> commands. \u003Ccode class=\"literal file\">perf.data\u003C/code> is generated in the current directory and can be accessed at a later time, possibly on a different machine.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tIf you do not specify a command for \u003Ccode class=\"literal command\">perf record\u003C/code> to record during, it will record until you manually stop the process by pressing \u003Ccode class=\"literal\">Ctrl+C\u003C/code>. You can attach \u003Ccode class=\"literal command\">perf record\u003C/code> to specific processes by passing the \u003Ccode class=\"literal option\">-p\u003C/code> option followed by one or more process IDs. You can run \u003Ccode class=\"literal command\">perf record\u003C/code> without root access, however, doing so will only sample performance data in the user space. In the default mode, \u003Ccode class=\"literal command\">perf record\u003C/code> uses CPU cycles as the sampling event and operates in per-thread mode with inherit mode enabled.\n\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"recording-a-performance-profile-without-root-access_recording-and-analyzing-performance-profiles-with-perf\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">19.2. Recording a performance profile without root access\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can use \u003Ccode class=\"literal\">perf record\u003C/code> without root access to sample and record performance data in the user-space only.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have the \u003Ccode class=\"literal\">perf\u003C/code> user space tool installed as described in \u003Ca class=\"link\" href=\"#installing-perf_getting-started-with-perf\" title=\"16.2. Installing perf\">Installing perf\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tSample and record the performance data:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ perf record \u003Cspan class=\"emphasis\">\u003Cem>command\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tReplace \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>command\u003C/em>\u003C/span>\u003C/code> with the command you want to sample data during. If you do not specify a command, then \u003Ccode class=\"literal\">perf record\u003C/code> will sample data until you manually stop it by pressing \u003Ckbd class=\"keycap\">Ctrl\u003C/kbd>+\u003Ckbd class=\"keycap\">C\u003C/kbd>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">perf-record(1)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"recording-a-performance-profile-with-root-access_recording-and-analyzing-performance-profiles-with-perf\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">19.3. Recording a performance profile with root access\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can use \u003Ccode class=\"literal\">perf record\u003C/code> with root access to sample and record performance data in both the user-space and the kernel-space simultaneously.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have the \u003Ccode class=\"literal\">perf\u003C/code> user space tool installed as described in \u003Ca class=\"link\" href=\"#installing-perf_getting-started-with-perf\" title=\"16.2. Installing perf\">Installing perf\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have root access.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tSample and record the performance data:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># perf record \u003Cspan class=\"emphasis\">\u003Cem>command\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tReplace \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>command\u003C/em>\u003C/span>\u003C/code> with the command you want to sample data during. If you do not specify a command, then \u003Ccode class=\"literal\">perf record\u003C/code> will sample data until you manually stop it by pressing \u003Ckbd class=\"keycap\">Ctrl\u003C/kbd>+\u003Ckbd class=\"keycap\">C\u003C/kbd>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">perf-record(1)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"recording-a-performance-profile-in-per-cpu-mode_recording-and-analyzing-performance-profiles-with-perf\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">19.4. Recording a performance profile in per-CPU mode\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can use \u003Ccode class=\"literal\">perf record\u003C/code> in per-CPU mode to sample and record performance data in both and user-space and the kernel-space simultaneously across all threads on a monitored CPU. By default, per-CPU mode monitors all online CPUs.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have the \u003Ccode class=\"literal\">perf\u003C/code> user space tool installed as described in \u003Ca class=\"link\" href=\"#installing-perf_getting-started-with-perf\" title=\"16.2. Installing perf\">Installing perf\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tSample and record the performance data:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># perf record -a \u003Cspan class=\"emphasis\">\u003Cem>command\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tReplace \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>command\u003C/em>\u003C/span>\u003C/code> with the command you want to sample data during. If you do not specify a command, then \u003Ccode class=\"literal\">perf record\u003C/code> will sample data until you manually stop it by pressing \u003Ckbd class=\"keycap\">Ctrl\u003C/kbd>+\u003Ckbd class=\"keycap\">C\u003C/kbd>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">perf-record(1)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"capturing-call-graph-data-with-perf-record_recording-and-analyzing-performance-profiles-with-perf\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">19.5. Capturing call graph data with perf record\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can configure the \u003Ccode class=\"literal\">perf record\u003C/code> tool so that it records which function is calling other functions in the performance profile. This helps to identify a bottleneck if several processes are calling the same function.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have the \u003Ccode class=\"literal\">perf\u003C/code> user space tool installed as described in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf\">Installing perf\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tSample and record performance data with the \u003Ccode class=\"literal\">--call-graph\u003C/code> option:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ perf record --call-graph \u003Cspan class=\"emphasis\">\u003Cem>method\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>command\u003C/em>\u003C/span>\u003C/pre>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tReplace \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>command\u003C/em>\u003C/span>\u003C/code> with the command you want to sample data during. If you do not specify a command, then \u003Ccode class=\"literal\">perf record\u003C/code> will sample data until you manually stop it by pressing \u003Ckbd class=\"keycap\">Ctrl\u003C/kbd>+\u003Ckbd class=\"keycap\">C\u003C/kbd>.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>method\u003C/em>\u003C/span> with one of the following unwinding methods:\n\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">fp\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\t\t\tUses the frame pointer method. Depending on compiler optimization, such as with binaries built with the GCC option \u003Ccode class=\"literal option\">--fomit-frame-pointer\u003C/code>, this may not be able to unwind the stack.\n\t\t\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">dwarf\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\t\t\tUses DWARF Call Frame Information to unwind the stack.\n\t\t\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">lbr\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\t\t\tUses the last branch record hardware on Intel processors.\n\t\t\t\t\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">perf-record(1)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"analyzing-perf-data-with-perf-report_recording-and-analyzing-performance-profiles-with-perf\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">19.6. Analyzing perf.data with perf report\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can use \u003Ccode class=\"literal\">perf report\u003C/code> to display and analyze a \u003Ccode class=\"literal file\">perf.data\u003C/code> file.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have the \u003Ccode class=\"literal\">perf\u003C/code> user space tool installed as described in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf\">Installing perf\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThere is a \u003Ccode class=\"literal file\">perf.data\u003C/code> file in the current directory.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIf the \u003Ccode class=\"literal file\">perf.data\u003C/code> file was created with root access, you need to run \u003Ccode class=\"literal\">perf report\u003C/code> with root access too.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tDisplay the contents of the \u003Ccode class=\"literal file\">perf.data\u003C/code> file for further analysis:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># perf report\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThis command displays output similar to the following:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">Samples: 2K of event 'cycles', Event count (approx.): 235462960\nOverhead  Command          Shared Object                     Symbol\n   2.36%  kswapd0          [kernel.kallsyms]                 [k] page_vma_mapped_walk\n   2.13%  sssd_kcm         libc-2.28.so                      [.] \u003Cspan class=\"emphasis\">\u003Cem>memset_avx2_erms 2.13% perf [kernel.kallsyms] [k] smp_call_function_single 1.53% gnome-shell libc-2.28.so [.] \u003C/em>\u003C/span>strcmp_avx2\n   1.17%  gnome-shell      libglib-2.0.so.0.5600.4           [.] g_hash_table_lookup\n   0.93%  Xorg             libc-2.28.so                      [.] \u003Cspan class=\"emphasis\">\u003Cem>memmove_avx_unaligned_erms 0.89% gnome-shell libgobject-2.0.so.0.5600.4 [.] g_object_unref 0.87% kswapd0 [kernel.kallsyms] [k] page_referenced_one 0.86% gnome-shell libc-2.28.so [.] \u003C/em>\u003C/span>memmove_avx_unaligned_erms\n   0.83%  Xorg             [kernel.kallsyms]                 [k] alloc_vmap_area\n   0.63%  gnome-shell      libglib-2.0.so.0.5600.4           [.] g_slice_alloc\n   0.53%  gnome-shell      libgirepository-1.0.so.1.0.0      [.] g_base_info_unref\n   0.53%  gnome-shell      ld-2.28.so                        [.] _dl_find_dso_for_object\n   0.49%  kswapd0          [kernel.kallsyms]                 [k] vma_interval_tree_iter_next\n   0.48%  gnome-shell      libpthread-2.28.so                [.] \u003Cspan class=\"emphasis\">\u003Cem>pthread_getspecific 0.47% gnome-shell libgirepository-1.0.so.1.0.0 [.] 0x0000000000013b1d 0.45% gnome-shell libglib-2.0.so.0.5600.4 [.] g_slice_free1 0.45% gnome-shell libgobject-2.0.so.0.5600.4 [.] g_type_check_instance_is_fundamentally_a 0.44% gnome-shell libc-2.28.so [.] malloc 0.41% swapper [kernel.kallsyms] [k] apic_timer_interrupt 0.40% gnome-shell ld-2.28.so [.] _dl_lookup_symbol_x 0.39% kswapd0 [kernel.kallsyms] [k] \u003C/em>\u003C/span>raw_callee_save___pv_queued_spin_unlock\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">perf-report(1)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"interpretation-of-perf-report-output_recording-and-analyzing-performance-profiles-with-perf\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">19.7. Interpretation of perf report output\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe table displayed by running the \u003Ccode class=\"literal command\">perf report\u003C/code> command sorts the data into several columns:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">The 'Overhead' column\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tIndicates what percentage of overall samples were collected in that particular function.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">The 'Command' column\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tTells you which process the samples were collected from.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">The 'Shared Object' column\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDisplays the name of the ELF image where the samples come from (the name [kernel.kallsyms] is used when the samples come from the kernel).\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">The 'Symbol' column\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDisplays the function name or symbol.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cp>\n\t\t\t\tIn default mode, the functions are sorted in descending order with those with the highest overhead displayed first.\n\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"generating-a-perf-data-file-that-is-readable-on-a-different-device_recording-and-analyzing-performance-profiles-with-perf\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">19.8. Generating a perf.data file that is readable on a different device\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can use the \u003Ccode class=\"literal\">perf\u003C/code> tool to record performance data into a \u003Ccode class=\"literal\">perf.data\u003C/code> file to be analyzed on a different device.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have the \u003Ccode class=\"literal\">perf\u003C/code> user space tool installed as described in \u003Ca class=\"link\" href=\"#installing-perf_getting-started-with-perf\" title=\"16.2. Installing perf\">Installing perf\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe kernel \u003Ccode class=\"literal\">debuginfo\u003C/code> package is installed. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/developing_c_and_cpp_applications_in_rhel_8/index#getting-debuginfo-packages-for-an-application-or-library-using-gdb_enabling-debugging-with-debugging-information\">Getting debuginfo packages for an application or library using GDB.\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCapture performance data you are interested in investigating further:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># perf record -a --call-graph fp sleep \u003Cspan class=\"emphasis\">\u003Cem>seconds\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThis example would generate a \u003Ccode class=\"literal\">perf.data\u003C/code> over the entire system for a period of \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>seconds\u003C/em>\u003C/span>\u003C/code> seconds as dictated by the use of the \u003Ccode class=\"literal\">sleep\u003C/code> command. It would also capture call graph data using the frame pointer method.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tGenerate an archive file containing debug symbols of the recorded data:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># perf archive\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify that the archive file has been generated in your current active directory:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># ls perf.data*\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe output will display every file in your current directory that begins with \u003Ccode class=\"literal\">perf.data\u003C/code>. The archive file will be named either:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">perf.data.tar.gz\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tor\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">perf.data.tar.bz2\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"#recording-and-analyzing-performance-profiles-with-perf_monitoring-and-managing-system-status-and-performance\" title=\"Chapter 19. Recording and analyzing performance profiles with perf\">Recording and analyzing performance profiles with perf\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"#capturing-call-graph-data-with-perf-record_recording-and-analyzing-performance-profiles-with-perf\" title=\"19.5. Capturing call graph data with perf record\">Capturing call graph data with perf record\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"analyzing-a-perf-data-file-that-was-created-on-a-different-device_recording-and-analyzing-performance-profiles-with-perf\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">19.9. Analyzing a perf.data file that was created on a different device\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can use the \u003Ccode class=\"literal\">perf\u003C/code> tool to analyze a \u003Ccode class=\"literal\">perf.data\u003C/code> file that was generated on a different device.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have the \u003Ccode class=\"literal\">perf\u003C/code> user space tool installed as described in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf\">Installing perf\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tA \u003Ccode class=\"literal\">perf.data\u003C/code> file and associated archive file generated on a different device are present on the current device being used.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tCopy both the \u003Ccode class=\"literal\">perf.data\u003C/code> file and the archive file into your current active directory.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tExtract the archive file into \u003Ccode class=\"literal\">~/.debug\u003C/code>:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mkdir -p ~/.debug\n# tar xf \u003Cspan class=\"emphasis\">\u003Cem>perf.data.tar.bz2\u003C/em>\u003C/span> -C ~/.debug\u003C/pre>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\tThe archive file might also be named \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>perf.data.tar.gz\u003C/em>\u003C/span>\u003C/code>.\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOpen the \u003Ccode class=\"literal\">perf.data\u003C/code> file for further analysis:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># perf report\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"why-perf-displays-some-function-names-as-raw-function-addresses_recording-and-analyzing-performance-profiles-with-perf\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">19.10. Why perf displays some function names as raw function addresses\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tFor kernel functions, \u003Ccode class=\"literal\">perf\u003C/code> uses the information from the \u003Ccode class=\"literal\">/proc/kallsyms\u003C/code> file to map the samples to their respective function names or symbols. For functions executed in the user space, however, you might see raw function addresses because the binary is stripped.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe \u003Ccode class=\"literal literal\">debuginfo\u003C/code> package of the executable must be installed or, if the executable is a locally developed application, the application must be compiled with debugging information turned on (the \u003Ccode class=\"literal option\">-g\u003C/code> option in GCC) to display the function names or symbols in such a situation.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tIt is not necessary to re-run the \u003Ccode class=\"literal command\">perf record\u003C/code> command after installing the \u003Ccode class=\"literal literal\">debuginfo\u003C/code> associated with an executable. Simply re-run the \u003Ccode class=\"literal command\">perf report\u003C/code> command.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional Resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/developing_c_and_cpp_applications_in_rhel_9/debugging-applications_developing-applications#enabling-debugging-with-debugging-information_debugging-applications\">Enabling debugging with debugging information\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"enabling-debug-and-source-repositories_recording-and-analyzing-performance-profiles-with-perf\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">19.11. Enabling debug and source repositories\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tA standard installation of Red Hat Enterprise Linux does not enable the debug and source repositories. These repositories contain information needed to debug the system components and measure their performance.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnable the source and debug information package channels:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># subscription-manager repos --enable rhel-9-for-$(uname -i)-baseos-debug-rpms\n# subscription-manager repos --enable rhel-9-for-$(uname -i)-baseos-source-rpms\n# subscription-manager repos --enable rhel-9-for-$(uname -i)-appstream-debug-rpms\n# subscription-manager repos --enable rhel-9-for-$(uname -i)-appstream-source-rpms\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">$(uname -i)\u003C/code> part is automatically replaced with a matching value for architecture of your system:\n\t\t\t\t\t\u003C/p>\u003Crh-table>\u003Ctable class=\"lt-4-cols lt-7-rows\">\u003Ccolgroup>\u003Ccol style=\"width: 50%; \" class=\"col_1\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 50%; \" class=\"col_2\">\u003C!--Empty-->\u003C/col>\u003C/colgroup>\u003Cthead>\u003Ctr>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280134419776\" scope=\"col\">Architecture name\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280134418688\" scope=\"col\">Value\u003C/th>\u003C/tr>\u003C/thead>\u003Ctbody>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280134419776\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t64-bit Intel and AMD\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280134418688\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\tx86_64\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280134419776\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t64-bit ARM\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280134418688\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\taarch64\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280134419776\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\tIBM POWER\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280134418688\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\tppc64le\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280134419776\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t64-bit IBM Z\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280134418688\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\ts390x\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\u003C/rh-table>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"getting-debuginfo-packages-for-an-application-or-library-using-gdb_recording-and-analyzing-performance-profiles-with-perf\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">19.12. Getting debuginfo packages for an application or library using GDB\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tDebugging information is required to debug code. For code that is installed from a package, the GNU Debugger (GDB) automatically recognizes missing debug information, resolves the package name and provides concrete advice on how to get the package.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe application or library you want to debug must be installed on the system.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tGDB and the \u003Ccode class=\"literal command\">debuginfo-install\u003C/code> tool must be installed on the system. For details, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/developing_c_and_cpp_applications_in_rhel_9/setting-up-a-development-workstation_developing-applications#setting-up-to-debug-applications_setting-up-a-development-workstation\">Setting up to debug applications\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tRepositories providing \u003Ccode class=\"literal\">debuginfo\u003C/code> and \u003Ccode class=\"literal\">debugsource\u003C/code> packages must be configured and enabled on the system. For details, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/developing_c_and_cpp_applications_in_rhel_9/index#enabling-debug-and-source-repositories_setting-up-a-development-workstation\">Enabling debug and source repositories\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tStart GDB attached to the application or library you want to debug. GDB automatically recognizes missing debugging information and suggests a command to run.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ gdb -q /bin/ls\nReading symbols from /bin/ls...Reading symbols from .gnu_debugdata for /usr/bin/ls...(no debugging symbols found)...done.\n(no debugging symbols found)...done.\nMissing separate debuginfos, use: dnf \u003Cspan class=\"emphasis\">\u003Cem>debuginfo-install coreutils-8.30-6.el8.x86_64\u003C/em>\u003C/span>\n(gdb)\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tExit GDB: type \u003Ckbd class=\"keycap\">q\u003C/kbd> and confirm with \u003Ckbd class=\"keycap\">Enter\u003C/kbd>.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">(gdb) q\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRun the command suggested by GDB to install the required \u003Ccode class=\"literal\">debuginfo\u003C/code> packages:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf debuginfo-install coreutils-8.30-6.el8.x86_64\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">dnf\u003C/code> package management tool provides a summary of the changes, asks for confirmation and once you confirm, downloads and installs all the necessary files.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIn case GDB is not able to suggest the \u003Ccode class=\"literal\">debuginfo\u003C/code> package, follow the procedure described in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/developing_c_and_cpp_applications_in_rhel_9/debugging-applications_developing-applications#getting-debuginfo-packages-for-an-application-or-library-manually_enabling-debugging-with-debugging-information\">Getting debuginfo packages for an application or library manually\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/solutions/9907\">How can I download or install debuginfo packages for RHEL systems?\u003C/a> (Red Hat Knowledgebase)\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"investigating-busy-cpus-with-perf_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 20. Investigating busy CPUs with perf\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tWhen investigating performance issues on a system, you can use the \u003Ccode class=\"literal\">perf\u003C/code> tool to identify and monitor the busiest CPUs in order to focus your efforts.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"displaying-which-cpu-events-were-counted-on-with-perf-stat_investigating-busy-cpus-with-perf\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">20.1. Displaying which CPU events were counted on with perf stat\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can use \u003Ccode class=\"literal\">perf stat\u003C/code> to display which CPU events were counted on by disabling CPU count aggregation. You must count events in system-wide mode by using the \u003Ccode class=\"literal\">-a\u003C/code> flag in order to use this functionality.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have the \u003Ccode class=\"literal\">perf\u003C/code> user space tool installed as described in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf\">Installing perf\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCount the events with CPU count aggregation disabled:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># perf stat -a -A sleep \u003Cspan class=\"emphasis\">\u003Cem>seconds\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe previous example displays counts of a default set of common hardware and software events recorded over a time period of \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>seconds\u003C/em>\u003C/span>\u003C/code> seconds, as dictated by using the \u003Ccode class=\"literal\">sleep\u003C/code> command, over each individual CPU in ascending order, starting with \u003Ccode class=\"literal\">CPU0\u003C/code>. As such, it may be useful to specify an event such as cycles:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># perf stat -a -A -e cycles sleep \u003Cspan class=\"emphasis\">\u003Cem>seconds\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"displaying-which-cpu-samples-were-taken-on-with-perf-report_investigating-busy-cpus-with-perf\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">20.2. Displaying which CPU samples were taken on with perf report\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe \u003Ccode class=\"literal\">perf record\u003C/code> command samples performance data and stores this data in a \u003Ccode class=\"literal\">perf.data\u003C/code> file which can be read with the \u003Ccode class=\"literal\">perf report\u003C/code> command. The \u003Ccode class=\"literal\">perf record\u003C/code> command always records which CPU samples were taken on. You can configure \u003Ccode class=\"literal\">perf report\u003C/code> to display this information.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have the \u003Ccode class=\"literal\">perf\u003C/code> user space tool installed as described in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf\">Installing perf\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThere is a \u003Ccode class=\"literal\">perf.data\u003C/code> file created with \u003Ccode class=\"literal\">perf record\u003C/code> in the current directory. If the \u003Ccode class=\"literal\">perf.data\u003C/code> file was created with root access, you need to run \u003Ccode class=\"literal\">perf report\u003C/code> with root access too.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tDisplay the contents of the \u003Ccode class=\"literal\">perf.data\u003C/code> file for further analysis while sorting by CPU:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># perf report --sort cpu\u003C/pre>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tYou can sort by CPU and command to display more detailed information about where CPU time is being spent:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># perf report --sort cpu,comm\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tThis example will list commands from all monitored CPUs by total overhead in descending order of overhead usage and identify the CPU the command was executed on.\n\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/recording-and-analyzing-performance-profiles-with-perf_monitoring-and-managing-system-status-and-performance\">Recording and analyzing performance profiles with perf\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"displaying-specific-cpus-during-profiling-with-perf-top_investigating-busy-cpus-with-perf\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">20.3. Displaying specific CPUs during profiling with perf top\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can configure \u003Ccode class=\"literal\">perf top\u003C/code> to display specific CPUs and their relative usage while profiling your system in real time.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have the \u003Ccode class=\"literal\">perf\u003C/code> user space tool installed as described in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf\">Installing perf\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tStart the \u003Ccode class=\"literal\">perf top\u003C/code> interface while sorting by CPU:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># perf top --sort cpu\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThis example will list CPUs and their respective overhead in descending order of overhead usage in real time.\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tYou can sort by CPU and command for more detailed information of where CPU time is being spent:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># perf top --sort cpu,comm\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tThis example will list commands by total overhead in descending order of overhead usage and identify the CPU the command was executed on in real time.\n\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"monitoring-specific-cpus-with-perf-record-and-perf-report_investigating-busy-cpus-with-perf\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">20.4. Monitoring specific CPUs with perf record and perf report\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can configure \u003Ccode class=\"literal\">perf record\u003C/code> to only sample specific CPUs of interest and analyze the generated \u003Ccode class=\"literal\">perf.data\u003C/code> file with \u003Ccode class=\"literal\">perf report\u003C/code> for further analysis.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have the \u003Ccode class=\"literal\">perf\u003C/code> user space tool installed as described in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf\">Installing perf\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tSample and record the performance data in the specific CPU’s, generating a \u003Ccode class=\"literal\">perf.data\u003C/code> file:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tUsing a comma separated list of CPUs:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># perf record -C \u003Cspan class=\"emphasis\">\u003Cem>0,1\u003C/em>\u003C/span> sleep \u003Cspan class=\"emphasis\">\u003Cem>seconds\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tThe previous example samples and records data in CPUs 0 and 1 for a period of \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>seconds\u003C/em>\u003C/span>\u003C/code> seconds as dictated by the use of the \u003Ccode class=\"literal\">sleep\u003C/code> command.\n\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tUsing a range of CPUs:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># perf record -C \u003Cspan class=\"emphasis\">\u003Cem>0-2\u003C/em>\u003C/span> sleep \u003Cspan class=\"emphasis\">\u003Cem>seconds\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tThe previous example samples and records data in all CPUs from CPU 0 to 2 for a period of \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>seconds\u003C/em>\u003C/span>\u003C/code> seconds as dictated by the use of the \u003Ccode class=\"literal\">sleep\u003C/code> command.\n\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tDisplay the contents of the \u003Ccode class=\"literal\">perf.data\u003C/code> file for further analysis:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># perf report\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThis example will display the contents of \u003Ccode class=\"literal\">perf.data\u003C/code>. If you are monitoring several CPUs and want to know which CPU data was sampled on, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/investigating-busy-cpus-with-perf_monitoring-and-managing-system-status-and-performance#displaying-which-cpu-samples-were-taken-on-with-perf-report_investigating-busy-cpus-with-perf\">Displaying which CPU samples were taken on with perf report\u003C/a>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"monitoring-application-performance-with-perf_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 21. Monitoring application performance with perf\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tYou can use the \u003Ccode class=\"literal\">perf\u003C/code> tool to monitor and analyze application performance.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"attaching-perf-record-to-a-running-process_monitoring-application-performance-with-perf\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">21.1. Attaching perf record to a running process\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can attach \u003Ccode class=\"literal\">perf record\u003C/code> to a running process. This will instruct \u003Ccode class=\"literal\">perf record\u003C/code> to only sample and record performance data in the specified processes.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have the \u003Ccode class=\"literal\">perf\u003C/code> user space tool installed as described in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf\">Installing perf\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAttach \u003Ccode class=\"literal\">perf record\u003C/code> to a running process:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ perf record -p \u003Cspan class=\"emphasis\">\u003Cem>ID1,ID2\u003C/em>\u003C/span> sleep \u003Cspan class=\"emphasis\">\u003Cem>seconds\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe previous example samples and records performance data of the processes with the process ID’s \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>ID1\u003C/em>\u003C/span>\u003C/code> and \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>ID2\u003C/em>\u003C/span>\u003C/code> for a time period of \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>seconds\u003C/em>\u003C/span>\u003C/code> seconds as dictated by using the \u003Ccode class=\"literal\">sleep\u003C/code> command. You can also configure \u003Ccode class=\"literal\">perf\u003C/code> to record events in specific threads:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ perf record -t \u003Cspan class=\"emphasis\">\u003Cem>ID1,ID2\u003C/em>\u003C/span> sleep \u003Cspan class=\"emphasis\">\u003Cem>seconds\u003C/em>\u003C/span>\u003C/pre>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\tWhen using the \u003Ccode class=\"literal\">-t\u003C/code> flag and stipulating thread ID’s, \u003Ccode class=\"literal\">perf\u003C/code> disables inheritance by default. You can enable inheritance by adding the \u003Ccode class=\"literal\">--inherit\u003C/code> option.\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"capturing-call-graph-data-with-perf-record_monitoring-application-performance-with-perf\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">21.2. Capturing call graph data with perf record\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can configure the \u003Ccode class=\"literal\">perf record\u003C/code> tool so that it records which function is calling other functions in the performance profile. This helps to identify a bottleneck if several processes are calling the same function.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have the \u003Ccode class=\"literal\">perf\u003C/code> user space tool installed as described in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf\">Installing perf\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tSample and record performance data with the \u003Ccode class=\"literal\">--call-graph\u003C/code> option:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ perf record --call-graph \u003Cspan class=\"emphasis\">\u003Cem>method\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>command\u003C/em>\u003C/span>\u003C/pre>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tReplace \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>command\u003C/em>\u003C/span>\u003C/code> with the command you want to sample data during. If you do not specify a command, then \u003Ccode class=\"literal\">perf record\u003C/code> will sample data until you manually stop it by pressing \u003Ckbd class=\"keycap\">Ctrl\u003C/kbd>+\u003Ckbd class=\"keycap\">C\u003C/kbd>.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tReplace \u003Cspan class=\"emphasis\">\u003Cem>method\u003C/em>\u003C/span> with one of the following unwinding methods:\n\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">fp\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\t\t\tUses the frame pointer method. Depending on compiler optimization, such as with binaries built with the GCC option \u003Ccode class=\"literal option\">--fomit-frame-pointer\u003C/code>, this may not be able to unwind the stack.\n\t\t\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">dwarf\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\t\t\tUses DWARF Call Frame Information to unwind the stack.\n\t\t\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">lbr\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\t\t\tUses the last branch record hardware on Intel processors.\n\t\t\t\t\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">perf-record(1)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"analyzing-perf-data-with-perf-report_monitoring-application-performance-with-perf\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">21.3. Analyzing perf.data with perf report\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can use \u003Ccode class=\"literal\">perf report\u003C/code> to display and analyze a \u003Ccode class=\"literal file\">perf.data\u003C/code> file.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have the \u003Ccode class=\"literal\">perf\u003C/code> user space tool installed as described in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf\">Installing perf\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThere is a \u003Ccode class=\"literal file\">perf.data\u003C/code> file in the current directory.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tIf the \u003Ccode class=\"literal file\">perf.data\u003C/code> file was created with root access, you need to run \u003Ccode class=\"literal\">perf report\u003C/code> with root access too.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tDisplay the contents of the \u003Ccode class=\"literal file\">perf.data\u003C/code> file for further analysis:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># perf report\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThis command displays output similar to the following:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">Samples: 2K of event 'cycles', Event count (approx.): 235462960\nOverhead  Command          Shared Object                     Symbol\n   2.36%  kswapd0          [kernel.kallsyms]                 [k] page_vma_mapped_walk\n   2.13%  sssd_kcm         libc-2.28.so                      [.] \u003Cspan class=\"emphasis\">\u003Cem>memset_avx2_erms 2.13% perf [kernel.kallsyms] [k] smp_call_function_single 1.53% gnome-shell libc-2.28.so [.] \u003C/em>\u003C/span>strcmp_avx2\n   1.17%  gnome-shell      libglib-2.0.so.0.5600.4           [.] g_hash_table_lookup\n   0.93%  Xorg             libc-2.28.so                      [.] \u003Cspan class=\"emphasis\">\u003Cem>memmove_avx_unaligned_erms 0.89% gnome-shell libgobject-2.0.so.0.5600.4 [.] g_object_unref 0.87% kswapd0 [kernel.kallsyms] [k] page_referenced_one 0.86% gnome-shell libc-2.28.so [.] \u003C/em>\u003C/span>memmove_avx_unaligned_erms\n   0.83%  Xorg             [kernel.kallsyms]                 [k] alloc_vmap_area\n   0.63%  gnome-shell      libglib-2.0.so.0.5600.4           [.] g_slice_alloc\n   0.53%  gnome-shell      libgirepository-1.0.so.1.0.0      [.] g_base_info_unref\n   0.53%  gnome-shell      ld-2.28.so                        [.] _dl_find_dso_for_object\n   0.49%  kswapd0          [kernel.kallsyms]                 [k] vma_interval_tree_iter_next\n   0.48%  gnome-shell      libpthread-2.28.so                [.] \u003Cspan class=\"emphasis\">\u003Cem>pthread_getspecific 0.47% gnome-shell libgirepository-1.0.so.1.0.0 [.] 0x0000000000013b1d 0.45% gnome-shell libglib-2.0.so.0.5600.4 [.] g_slice_free1 0.45% gnome-shell libgobject-2.0.so.0.5600.4 [.] g_type_check_instance_is_fundamentally_a 0.44% gnome-shell libc-2.28.so [.] malloc 0.41% swapper [kernel.kallsyms] [k] apic_timer_interrupt 0.40% gnome-shell ld-2.28.so [.] _dl_lookup_symbol_x 0.39% kswapd0 [kernel.kallsyms] [k] \u003C/em>\u003C/span>raw_callee_save___pv_queued_spin_unlock\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">perf-report(1)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"creating-uprobes-with-perf_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 22. Creating uprobes with perf\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Csection class=\"section\" id=\"proc_creating-uprobes-at-the-fucntion-level-with-perf_assembly_creating-uprobes-with-perf\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">22.1. Creating uprobes at the function level with perf\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can use the \u003Ccode class=\"literal\">perf\u003C/code> tool to create dynamic tracepoints at arbitrary points in a process or application. These tracepoints can then be used in conjunction with other \u003Ccode class=\"literal\">perf\u003C/code> tools such as \u003Ccode class=\"literal\">perf stat\u003C/code> and \u003Ccode class=\"literal\">perf record\u003C/code> to better understand the process or applications behavior.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have the \u003Ccode class=\"literal\">perf\u003C/code> user space tool installed as described in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf\">Installing perf\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate the uprobe in the process or application you are interested in monitoring at a location of interest within the process or application:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># perf probe -x \u003Cspan class=\"emphasis\">\u003Cem>/path/to/executable\u003C/em>\u003C/span> -a \u003Cspan class=\"emphasis\">\u003Cem>function\u003C/em>\u003C/span>\nAdded new event:\n  \u003Cspan class=\"emphasis\">\u003Cem>probe_executable:function\u003C/em>\u003C/span>   (on \u003Cspan class=\"emphasis\">\u003Cem>function\u003C/em>\u003C/span> in \u003Cspan class=\"emphasis\">\u003Cem>/path/to/executable\u003C/em>\u003C/span>)\n\nYou can now use it in all perf tools, such as:\n\n        perf record -e \u003Cspan class=\"emphasis\">\u003Cem>probe_executable:function\u003C/em>\u003C/span> -aR sleep 1\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">perf-probe\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/recording-and-analyzing-performance-profiles-with-perf_monitoring-and-managing-system-status-and-performance\">Recording and analyzing performance profiles with perf\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/counting-events-during-process-execution-with-perf-stat_monitoring-and-managing-system-status-and-performance\">Counting events during process execution with perf stat\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"proc_creating-uprobes-on-lines-within-a-function-with-perf_assembly_creating-uprobes-with-perf\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">22.2. Creating uprobes on lines within a function with perf\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThese tracepoints can then be used in conjunction with other \u003Ccode class=\"literal\">perf\u003C/code> tools such as \u003Ccode class=\"literal\">perf stat\u003C/code> and \u003Ccode class=\"literal\">perf record\u003C/code> to better understand the process or applications behavior.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have the \u003Ccode class=\"literal\">perf\u003C/code> user space tool installed as described in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf\">Installing perf\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tYou have gotten the debugging symbols for your executable:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># objdump -t \u003Cspan class=\"emphasis\">\u003Cem>./your_executable\u003C/em>\u003C/span> | head\u003C/pre>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\tTo do this, the \u003Ccode class=\"literal\">debuginfo\u003C/code> package of the executable must be installed or, if the executable is a locally developed application, the application must be compiled with debugging information, the \u003Ccode class=\"literal\">-g\u003C/code> option in GCC.\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tView the function lines where you can place a uprobe:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ perf probe -x \u003Cspan class=\"emphasis\">\u003Cem>./your_executable\u003C/em>\u003C/span> -L main\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOutput of this command looks similar to:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">&lt;main@/home/\u003Cspan class=\"emphasis\">\u003Cem>user\u003C/em>\u003C/span>/\u003Cspan class=\"emphasis\">\u003Cem>my_executable\u003C/em>\u003C/span>:0&gt;\n              0  int main(int argc, const char **argv)\n              1  {\n                        int err;\n                        const char *cmd;\n                        char sbuf[STRERR_BUFSIZE];\n\n                        /* libsubcmd init */\n              7         exec_cmd_init(\"perf\", PREFIX, PERF_EXEC_PATH, EXEC_PATH_ENVIRONMENT);\n              8         pager_init(PERF_PAGER_ENVIRONMENT);\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate the uprobe for the desired function line:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># perf probe -x ./\u003Cspan class=\"emphasis\">\u003Cem>my_executable\u003C/em>\u003C/span> main:8\nAdded new event:\n          probe_my_executable:main_L8   (on main:8 in /home/user/my_executable)\n\n        You can now use it in all perf tools, such as:\n\n                perf record -e probe_my_executable:main_L8 -aR sleep 1\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"ref_perf-script-output-of-a-perf-data-file-generated-over-uprobes_assembly_creating-uprobes-with-perf\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">22.3. Perf script output of data recorded over uprobes\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tA common method to analyze data collected using uprobes is using the \u003Ccode class=\"literal\">perf script\u003C/code> command to read a \u003Ccode class=\"literal\">perf.data\u003C/code> file and display a detailed trace of the recorded workload.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tIn the perf script example output:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tA uprobe is added to the function \u003Cspan class=\"strong strong\">\u003Cstrong>isprime()\u003C/strong>\u003C/span> in a program called \u003Cspan class=\"strong strong\">\u003Cstrong>my_prog\u003C/strong>\u003C/span>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>a\u003C/strong>\u003C/span> is a function argument added to the uprobe. Alternatively, \u003Cspan class=\"strong strong\">\u003Cstrong>a\u003C/strong>\u003C/span> could be an arbitrary variable visible in the code scope of where you add your uprobe:\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cpre class=\"screen\"># perf script\n    my_prog  1367 [007] 10802159.906593: probe_my_prog:isprime: (400551) a=2\n    my_prog  1367 [007] 10802159.906623: probe_my_prog:isprime: (400551) a=3\n    my_prog  1367 [007] 10802159.906625: probe_my_prog:isprime: (400551) a=4\n    my_prog  1367 [007] 10802159.906627: probe_my_prog:isprime: (400551) a=5\n    my_prog  1367 [007] 10802159.906629: probe_my_prog:isprime: (400551) a=6\n    my_prog  1367 [007] 10802159.906631: probe_my_prog:isprime: (400551) a=7\n    my_prog  1367 [007] 10802159.906633: probe_my_prog:isprime: (400551) a=13\n    my_prog  1367 [007] 10802159.906635: probe_my_prog:isprime: (400551) a=17\n    my_prog  1367 [007] 10802159.906637: probe_my_prog:isprime: (400551) a=19\u003C/pre>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"profiling-memory-accesses-with-perf-mem_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 23. Profiling memory accesses with perf mem\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tYou can use the \u003Ccode class=\"literal\">perf mem\u003C/code> command to sample memory accesses on your system.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"the-purpose-of-perf-mem_profiling-memory-accesses-with-perf-mem\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">23.1. The purpose of perf mem\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe \u003Ccode class=\"literal\">mem\u003C/code> subcommand of the \u003Ccode class=\"literal\">perf\u003C/code> tool enables the sampling of memory accesses (loads and stores). The \u003Ccode class=\"literal\">perf mem\u003C/code> command provides information about memory latency, types of memory accesses, functions causing cache hits and misses, and, by recording the data symbol, the memory locations where these hits and misses occur.\n\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"sampling-memory-access-with-perf-mem_profiling-memory-accesses-with-perf-mem\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">23.2. Sampling memory access with perf mem\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure describes how to use the \u003Ccode class=\"literal\">perf mem\u003C/code> command to sample memory accesses on your system. The command takes the same options as \u003Ccode class=\"literal\">perf record\u003C/code> and \u003Ccode class=\"literal\">perf report\u003C/code> as well as some options exclusive to the \u003Ccode class=\"literal\">mem\u003C/code> subcommand. The recorded data is stored in a \u003Ccode class=\"literal\">perf.data\u003C/code> file in the current directory for later analysis.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have the \u003Ccode class=\"literal\">perf\u003C/code> user space tool installed as described in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf\">Installing perf\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tSample the memory accesses:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># perf mem record -a sleep \u003Cspan class=\"emphasis\">\u003Cem>seconds\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThis example samples memory accesses across all CPUs for a period of \u003Cspan class=\"emphasis\">\u003Cem>seconds\u003C/em>\u003C/span> seconds as dictated by the \u003Ccode class=\"literal\">sleep\u003C/code> command. You can replace the \u003Ccode class=\"literal\">sleep\u003C/code> command for any command during which you want to sample memory access data. By default, \u003Ccode class=\"literal\">perf mem\u003C/code> samples both memory loads and stores. You can select only one memory operation by using the \u003Ccode class=\"literal\">-t\u003C/code> option and specifying either \"load\" or \"store\" between \u003Ccode class=\"literal\">perf mem\u003C/code> and \u003Ccode class=\"literal\">record\u003C/code>. For loads, information over the memory hierarchy level, TLB memory accesses, bus snoops, and memory locks is captured.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOpen the \u003Ccode class=\"literal\">perf.data\u003C/code> file for analysis:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># perf mem report\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIf you have used the example commands, the output is:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">Available samples\n35k cpu/mem-loads,ldlat=30/P\n54k cpu/mem-stores/P\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">cpu/mem-loads,ldlat=30/P\u003C/code> line denotes data collected over memory loads and the \u003Ccode class=\"literal\">cpu/mem-stores/P\u003C/code> line denotes data collected over memory stores. Highlight the category of interest and press \u003Ckbd class=\"keycap\">Enter\u003C/kbd> to view the data:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">Samples: 35K of event 'cpu/mem-loads,ldlat=30/P', Event count (approx.): 4067062\nOverhead       Samples  Local Weight  Memory access             Symbol                                                                 Shared Object                 Data Symbol                                                     Data Object                            Snoop         TLB access              Locked\n   0.07%            29  98            L1 or L1 hit              [.] 0x000000000000a255                                                 libspeexdsp.so.1.5.0          [.] 0x00007f697a3cd0f0                                          anon                                   None          L1 or L2 hit            No\n   0.06%            26  97            L1 or L1 hit              [.] 0x000000000000a255                                                 libspeexdsp.so.1.5.0          [.] 0x00007f697a3cd0f0                                          anon                                   None          L1 or L2 hit            No\n   0.06%            25  96            L1 or L1 hit              [.] 0x000000000000a255                                                 libspeexdsp.so.1.5.0          [.] 0x00007f697a3cd0f0                                          anon                                   None          L1 or L2 hit            No\n   0.06%             1  2325          Uncached or N/A hit       [k] pci_azx_readl                                                      [kernel.kallsyms]             [k] 0xffffb092c06e9084                                          [kernel.kallsyms]                      None          L1 or L2 hit            No\n   0.06%             1  2247          Uncached or N/A hit       [k] pci_azx_readl                                                      [kernel.kallsyms]             [k] 0xffffb092c06e8164                                          [kernel.kallsyms]                      None          L1 or L2 hit            No\n   0.05%             1  2166          L1 or L1 hit              [.] 0x00000000038140d6                                                 libxul.so                     [.] 0x00007ffd7b84b4a8                                          [stack]                                None          L1 or L2 hit            No\n   0.05%             1  2117          Uncached or N/A hit       [k] check_for_unclaimed_mmio                                           [kernel.kallsyms]             [k] 0xffffb092c1842300                                          [kernel.kallsyms]                      None          L1 or L2 hit            No\n   0.05%            22  95            L1 or L1 hit              [.] 0x000000000000a255                                                 libspeexdsp.so.1.5.0          [.] 0x00007f697a3cd0f0                                          anon                                   None          L1 or L2 hit            No\n   0.05%             1  1898          L1 or L1 hit              [.] 0x0000000002a30e07                                                 libxul.so                     [.] 0x00007f610422e0e0                                          anon                                   None          L1 or L2 hit            No\n   0.05%             1  1878          Uncached or N/A hit       [k] pci_azx_readl                                                      [kernel.kallsyms]             [k] 0xffffb092c06e8164                                          [kernel.kallsyms]                      None          L2 miss                 No\n   0.04%            18  94            L1 or L1 hit              [.] 0x000000000000a255                                                 libspeexdsp.so.1.5.0          [.] 0x00007f697a3cd0f0                                          anon                                   None          L1 or L2 hit            No\n   0.04%             1  1593          Local RAM or RAM hit      [.] 0x00000000026f907d                                                 libxul.so                     [.] 0x00007f3336d50a80                                          anon                                   Hit           L2 miss                 No\n   0.03%             1  1399          L1 or L1 hit              [.] 0x00000000037cb5f1                                                 libxul.so                     [.] 0x00007fbe81ef5d78                                          libxul.so                              None          L1 or L2 hit            No\n   0.03%             1  1229          LFB or LFB hit            [.] 0x0000000002962aad                                                 libxul.so                     [.] 0x00007fb6f1be2b28                                          anon                                   None          L2 miss                 No\n   0.03%             1  1202          LFB or LFB hit            [.] __pthread_mutex_lock                                               libpthread-2.29.so            [.] 0x00007fb75583ef20                                          anon                                   None          L1 or L2 hit            No\n   0.03%             1  1193          Uncached or N/A hit       [k] pci_azx_readl                                                      [kernel.kallsyms]             [k] 0xffffb092c06e9164                                          [kernel.kallsyms]                      None          L2 miss                 No\n   0.03%             1  1191          L1 or L1 hit              [k] azx_get_delay_from_lpib                                            [kernel.kallsyms]             [k] 0xffffb092ca7efcf0                                          [kernel.kallsyms]                      None          L1 or L2 hit            No\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAlternatively, you can sort your results to investigate different aspects of interest when displaying the data. For example, to sort data over memory loads by type of memory accesses occurring during the sampling period in descending order of overhead they account for:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># perf mem -t load report --sort=mem\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor example, the output can be:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">Samples: 35K of event 'cpu/mem-loads,ldlat=30/P', Event count (approx.): 40670\nOverhead       Samples  Memory access\n  31.53%          9725  LFB or LFB hit\n  29.70%         12201  L1 or L1 hit\n  23.03%          9725  L3 or L3 hit\n  12.91%          2316  Local RAM or RAM hit\n   2.37%           743  L2 or L2 hit\n   0.34%             9  Uncached or N/A hit\n   0.10%            69  I/O or N/A hit\n   0.02%           825  L3 miss\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">perf-mem(1)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"interpretation-of-perf-mem-report-output_profiling-memory-accesses-with-perf-mem\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">23.3. Interpretation of perf mem report output\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe table displayed by running the \u003Ccode class=\"literal command\">perf mem report\u003C/code> command without any modifiers sorts the data into several columns:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">The 'Overhead' column\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tIndicates percentage of overall samples collected in that particular function.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">The 'Samples' column\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDisplays the number of samples accounted for by that row.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">The 'Local Weight' column\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDisplays the access latency in processor core cycles.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">The 'Memory Access' column\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDisplays the type of memory access that occurred.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">The 'Symbol' column\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDisplays the function name or symbol.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">The 'Shared Object' column\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDisplays the name of the ELF image where the samples come from (the name [kernel.kallsyms] is used when the samples come from the kernel).\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">The 'Data Symbol' column\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDisplays the address of the memory location that row was targeting.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tOftentimes, due to dynamic allocation of memory or stack memory being accessed, the 'Data Symbol' column will display a raw address.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">The \"Snoop\" column\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDisplays bus transactions.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">The 'TLB Access' column\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDisplays TLB memory accesses.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">The 'Locked' column\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tIndicates if a function was or was not memory locked.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cp>\n\t\t\t\tIn default mode, the functions are sorted in descending order with those with the highest overhead displayed first.\n\t\t\t\u003C/p>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"detecting-false-sharing_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 24. Detecting false sharing\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tFalse sharing occurs when a processor core on a Symmetric Multi Processing (SMP) system modifies data items on the same cache line that is in use by other processors to access other data items that are not being shared between the processors.\n\t\t\u003C/p>\u003Cp>\n\t\t\tThis initial modification requires that the other processors using the cache line invalidate their copy and request an updated one despite the processors not needing, or even necessarily having access to, an updated version of the modified data item.\n\t\t\u003C/p>\u003Cp>\n\t\t\tYou can use the \u003Ccode class=\"literal\">perf c2c\u003C/code> command to detect false sharing.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"the-purpose-of-perf-c2c_detecting-false-sharing\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">24.1. The purpose of perf c2c\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe \u003Ccode class=\"literal\">c2c\u003C/code> subcommand of the \u003Ccode class=\"literal\">perf\u003C/code> tool enables Shared Data Cache-to-Cache (C2C) analysis. You can use the \u003Ccode class=\"literal\">perf c2c\u003C/code> command to inspect cache-line contention to detect both true and false sharing.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tCache-line contention occurs when a processor core on a Symmetric Multi Processing (SMP) system modifies data items on the same cache line that is in use by other processors. All other processors using this cache-line must then invalidate their copy and request an updated one. This can lead to degraded performance.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe \u003Ccode class=\"literal\">perf c2c\u003C/code> command provides the following information:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tCache lines where contention has been detected\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tProcesses reading and writing the data\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tInstructions causing the contention\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe Non-Uniform Memory Access (NUMA) nodes involved in the contention\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"detecting-cache-line-contention-with-perf-c2c_detecting-false-sharing\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">24.2. Detecting cache-line contention with perf c2c\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tUse the \u003Ccode class=\"literal\">perf c2c\u003C/code> command to detect cache-line contention in a system.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe \u003Ccode class=\"literal\">perf c2c\u003C/code> command supports the same options as \u003Ccode class=\"literal\">perf record\u003C/code> as well as some options exclusive to the \u003Ccode class=\"literal\">c2c\u003C/code> subcommand. The recorded data is stored in a \u003Ccode class=\"literal\">perf.data\u003C/code> file in the current directory for later analysis.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">perf\u003C/code> user space tool is installed. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf\">installing perf\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tUse \u003Ccode class=\"literal\">perf c2c\u003C/code> to detect cache-line contention:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># perf c2c record -a \u003Cspan class=\"emphasis\">\u003Cem>sleep\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>seconds\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThis example samples and records cache-line contention data across all CPU’s for a period of \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>seconds\u003C/em>\u003C/span>\u003C/code> as dictated by the \u003Ccode class=\"literal\">sleep\u003C/code> command. You can replace the \u003Ccode class=\"literal\">sleep\u003C/code> command with any command you want to collect cache-line contention data over.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">perf-c2c(1)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"visualizing-a-perf-data-file-recorded-with-perf-c2c-record_detecting-false-sharing\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">24.3. Visualizing a perf.data file recorded with perf c2c record\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure describes how to visualize the \u003Ccode class=\"literal\">perf.data\u003C/code> file, which is recorded using the \u003Ccode class=\"literal\">perf c2c\u003C/code> command.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">perf\u003C/code> user space tool is installed. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf\">Installing perf\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tA \u003Ccode class=\"literal\">perf.data\u003C/code> file recorded using the \u003Ccode class=\"literal\">perf c2c\u003C/code> command is available in the current directory. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/detecting-false-sharing_monitoring-and-managing-system-status-and-performance#detecting-cache-line-contention-with-perf-c2c_detecting-false-sharing\">Detecting cache-line contention with perf c2c\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOpen the \u003Ccode class=\"literal\">perf.data\u003C/code> file for further analysis:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># perf c2c report --stdio\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThis command visualizes the \u003Ccode class=\"literal\">perf.data\u003C/code> file into several graphs within the terminal:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">=================================================\n           Trace Event Information\n=================================================\n Total records                     :     329219\n Locked Load/Store Operations      :      14654\n Load Operations                   :      69679\n Loads - uncacheable               :          0\n Loads - IO                        :          0\n Loads - Miss                      :       3972\n Loads - no mapping                :          0\n Load Fill Buffer Hit              :      11958\n Load L1D hit                      :      17235\n Load L2D hit                      :         21\n Load LLC hit                      :      14219\n Load Local HITM                   :       3402\n Load Remote HITM                  :      12757\n Load Remote HIT                   :       5295\n Load Local DRAM                   :        976\n Load Remote DRAM                  :       3246\n Load MESI State Exclusive         :       4222\n Load MESI State Shared            :          0\n Load LLC Misses                   :      22274\n LLC Misses to Local DRAM          :        4.4%\n LLC Misses to Remote DRAM         :       14.6%\n LLC Misses to Remote cache (HIT)  :       23.8%\n LLC Misses to Remote cache (HITM) :       57.3%\n Store Operations                  :     259539\n Store - uncacheable               :          0\n Store - no mapping                :         11\n Store L1D Hit                     :     256696\n Store L1D Miss                    :       2832\n No Page Map Rejects               :       2376\n Unable to parse data source       :          1\n\n=================================================\n   Global Shared Cache Line Event Information\n=================================================\n Total Shared Cache Lines          :         55\n Load HITs on shared lines         :      55454\n Fill Buffer Hits on shared lines  :      10635\n L1D hits on shared lines          :      16415\n L2D hits on shared lines          :          0\n LLC hits on shared lines          :       8501\n Locked Access on shared lines     :      14351\n Store HITs on shared lines        :     109953\n Store L1D hits on shared lines    :     109449\n Total Merged records              :     126112\n\n=================================================\n                 c2c details\n=================================================\n Events                            : cpu/mem-loads,ldlat=30/P\n\t                                    : cpu/mem-stores/P\n Cachelines sort on                : Remote HITMs\n Cacheline data groupping          : offset,pid,iaddr\n\n=================================================\n\t   Shared Data Cache Line Table\n=================================================\n#\n#                              Total      Rmt  ----- LLC Load Hitm -----  ---- Store Reference ----  --- Load Dram ----      LLC    Total  ----- Core Load Hit -----  -- LLC Load Hit --\n# Index           Cacheline  records     Hitm    Total      Lcl      Rmt    Total    L1Hit   L1Miss       Lcl       Rmt  Ld Miss    Loads       FB       L1       L2       Llc       Rmt\n# .....  ..................  .......  .......  .......  .......  .......  .......  .......  .......  ........  ........  .......  .......  .......  .......  .......  ........  ........\n#\n      0            0x602180   149904   77.09%    12103     2269     9834   109504   109036      468       727      2657    13747    40400     5355    16154        0      2875       529\n      1            0x602100    12128   22.20%     3951     1119     2832        0        0        0        65       200     3749    12128     5096      108        0      2056       652\n      2  0xffff883ffb6a7e80      260    0.09%       15        3       12      161      161        0         1         1       15       99       25       50        0         6         1\n      3  0xffffffff81aec000      157    0.07%        9        0        9        1        0        1         0         7       20      156       50       59        0        27         4\n      4  0xffffffff81e3f540      179    0.06%        9        1        8      117       97       20         0        10       25       62       11        1        0        24         7\n\n=================================================\n      Shared Cache Line Distribution Pareto\n=================================================\n#\n#        ----- HITM -----  -- Store Refs --        Data address                               ---------- cycles ----------       cpu                                     Shared\n#   Num      Rmt      Lcl   L1 Hit  L1 Miss              Offset      Pid        Code address  rmt hitm  lcl hitm      load       cnt               Symbol                Object                  Source:Line  Node{cpu list}\n# .....  .......  .......  .......  .......  ..................  .......  ..................  ........  ........  ........  ........  ...................  ....................  ...........................  ....\n#\n  -------------------------------------------------------------\n      0     9834     2269   109036      468            0x602180\n  -------------------------------------------------------------\n          65.51%   55.88%   75.20%    0.00%                 0x0    14604            0x400b4f     27161     26039     26017         9  [.] read_write_func  no_false_sharing.exe  false_sharing_example.c:144   0{0-1,4}  1{24-25,120}  2{48,54}  3{169}\n\t   0.41%    0.35%    0.00%    0.00%                 0x0    14604            0x400b56     18088     12601     26671         9  [.] read_write_func  no_false_sharing.exe  false_sharing_example.c:145   0{0-1,4}  1{24-25,120}  2{48,54}  3{169}\n\t   0.00%    0.00%   24.80%  100.00%                 0x0    14604            0x400b61         0         0         0         9  [.] read_write_func  no_false_sharing.exe  false_sharing_example.c:145   0{0-1,4}  1{24-25,120}  2{48,54}  3{169}\n\t   7.50%    9.92%    0.00%    0.00%                0x20    14604            0x400ba7      2470      1729      1897         2  [.] read_write_func  no_false_sharing.exe  false_sharing_example.c:154   1{122}  2{144}\n\t  17.61%   20.89%    0.00%    0.00%                0x28    14604            0x400bc1      2294      1575      1649         2  [.] read_write_func  no_false_sharing.exe  false_sharing_example.c:158   2{53}  3{170}\n\t   8.97%   12.96%    0.00%    0.00%                0x30    14604            0x400bdb      2325      1897      1828         2  [.] read_write_func  no_false_sharing.exe  false_sharing_example.c:162   0{96}  3{171}\n\n  -------------------------------------------------------------\n      1     2832     1119        0        0            0x602100\n  -------------------------------------------------------------\n\t  29.13%   36.19%    0.00%    0.00%                0x20    14604            0x400bb3      1964      1230      1788         2  [.] read_write_func  no_false_sharing.exe  false_sharing_example.c:155   1{122}  2{144}\n\t  43.68%   34.41%    0.00%    0.00%                0x28    14604            0x400bcd      2274      1566      1793         2  [.] read_write_func  no_false_sharing.exe  false_sharing_example.c:159   2{53}  3{170}\n\t  27.19%   29.40%    0.00%    0.00%                0x30    14604            0x400be7      2045      1247      2011         2  [.] read_write_func  no_false_sharing.exe  false_sharing_example.c:163   0{96}  3{171}\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"interpretation-of-perf-c2c-report-output_detecting-false-sharing\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">24.4. Interpretation of perf c2c report output\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe visualization displayed by running the \u003Ccode class=\"literal\">perf c2c report --stdio\u003C/code> command sorts the data into several tables:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Trace Events Information\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThis table provides a high level summary of all the load and store samples, which are collected by the \u003Ccode class=\"literal\">perf c2c record\u003C/code> command.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Global Shared Cache Line Event Information\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThis table provides statistics over the shared cache lines.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">c2c Details\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThis table provides information about what events were sampled and how the \u003Ccode class=\"literal\">perf c2c report\u003C/code> data is organized within the visualization.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Shared Data Cache Line Table\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThis table provides a one line summary for the hottest cache lines where false sharing is detected and is sorted in descending order by the amount of remote \u003Cspan class=\"strong strong\">\u003Cstrong>Hitm\u003C/strong>\u003C/span> detected per cache line by default.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Shared Cache Line Distribution Pareto\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThis tables provides a variety of information about each cache line experiencing contention:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tThe cache lines are numbered in the \u003Cspan class=\"strong strong\">\u003Cstrong>NUM\u003C/strong>\u003C/span> column, starting at \u003Ccode class=\"literal\">0\u003C/code>.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tThe virtual address of each cache line is contained in the \u003Cspan class=\"strong strong\">\u003Cstrong>Data address Offset\u003C/strong>\u003C/span> column and followed subsequently by the offset into the cache line where different accesses occurred.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tThe \u003Cspan class=\"strong strong\">\u003Cstrong>Pid\u003C/strong>\u003C/span> column contains the process ID.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tThe \u003Cspan class=\"strong strong\">\u003Cstrong>Code Address\u003C/strong>\u003C/span> column contains the instruction pointer code address.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tThe columns under the \u003Cspan class=\"strong strong\">\u003Cstrong>cycles\u003C/strong>\u003C/span> label show average load latencies.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tThe \u003Cspan class=\"strong strong\">\u003Cstrong>cpu cnt\u003C/strong>\u003C/span> column displays how many different CPUs samples came from (essentially, how many different CPUs were waiting for the data indexed at that given location).\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tThe \u003Cspan class=\"strong strong\">\u003Cstrong>Symbol\u003C/strong>\u003C/span> column displays the function name or symbol.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tThe \u003Cspan class=\"strong strong\">\u003Cstrong>Shared Object\u003C/strong>\u003C/span> column displays the name of the ELF image where the samples come from (the name [\u003Ccode class=\"literal\">kernel.kallsyms\u003C/code>] is used when the samples come from the kernel).\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tThe \u003Cspan class=\"strong strong\">\u003Cstrong>Source:Line\u003C/strong>\u003C/span> column displays the source file and line number.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tThe \u003Cspan class=\"strong strong\">\u003Cstrong>Node{cpu list}\u003C/strong>\u003C/span> column displays which specific CPUs samples came from for each node.\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/dd>\u003C/dl>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"detecting-false-sharing-with-perf-c2c_detecting-false-sharing\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">24.5. Detecting false sharing with perf c2c\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure describes how to detect false sharing using the \u003Ccode class=\"literal\">perf c2c\u003C/code> command.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">perf\u003C/code> user space tool is installed. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf\">installing perf\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tA \u003Ccode class=\"literal\">perf.data\u003C/code> file recorded using the \u003Ccode class=\"literal\">perf c2c\u003C/code> command is available in the current directory. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/detecting-false-sharing_monitoring-and-managing-system-status-and-performance#detecting-cache-line-contention-with-perf-c2c_detecting-false-sharing\">Detecting cache-line contention with perf c2c\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOpen the \u003Ccode class=\"literal\">perf.data\u003C/code> file for further analysis:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># perf c2c report --stdio\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThis opens the \u003Ccode class=\"literal\">perf.data\u003C/code> file in the terminal.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn the \"Trace Event Information\" table, locate the row containing the values for \u003Cspan class=\"strong strong\">\u003Cstrong>LLC Misses to Remote Cache (HITM)\u003C/strong>\u003C/span>:\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe percentage in the value column of the \u003Cspan class=\"strong strong\">\u003Cstrong>LLC Misses to Remote Cache (HITM)\u003C/strong>\u003C/span> row represents the percentage of LLC misses that were occurring across NUMA nodes in modified cache-lines and is a key indicator false sharing has occurred.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">=================================================\n            Trace Event Information\n=================================================\n  Total records                     :     329219\n  Locked Load/Store Operations      :      14654\n  Load Operations                   :      69679\n  Loads - uncacheable               :          0\n  Loads - IO                        :          0\n  Loads - Miss                      :       3972\n  Loads - no mapping                :          0\n  Load Fill Buffer Hit              :      11958\n  Load L1D hit                      :      17235\n  Load L2D hit                      :         21\n  Load LLC hit                      :      14219\n  Load Local HITM                   :       3402\n  Load Remote HITM                  :      12757\n  Load Remote HIT                   :       5295\n  Load Local DRAM                   :        976\n  Load Remote DRAM                  :       3246\n  Load MESI State Exclusive         :       4222\n  Load MESI State Shared            :          0\n  Load LLC Misses                   :      22274\n  LLC Misses to Local DRAM          :        4.4%\n  LLC Misses to Remote DRAM         :       14.6%\n  LLC Misses to Remote cache (HIT)  :       23.8%\n  \u003Cspan class=\"strong strong\">\u003Cstrong>LLC Misses to Remote cache (HITM) : 57.3%\u003C/strong>\u003C/span>\n  Store Operations                  :     259539\n  Store - uncacheable               :          0\n  Store - no mapping                :         11\n  Store L1D Hit                     :     256696\n  Store L1D Miss                    :       2832\n  No Page Map Rejects               :       2376\n  Unable to parse data source       :          1\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInspect the \u003Cspan class=\"strong strong\">\u003Cstrong>Rmt\u003C/strong>\u003C/span> column of the \u003Cspan class=\"strong strong\">\u003Cstrong>LLC Load Hitm\u003C/strong>\u003C/span> field of the \u003Cspan class=\"strong strong\">\u003Cstrong>Shared Data Cache Line Table\u003C/strong>\u003C/span>:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">  =================================================\n             Shared Data Cache Line Table\n  =================================================\n  #\n  #                              Total      Rmt  \u003Cspan class=\"strong strong\">\u003Cstrong>----- LLC Load Hitm -----\u003C/strong>\u003C/span>  ---- Store Reference ----  --- Load Dram ----      LLC    Total  ----- Core Load Hit -----  -- LLC Load Hit --\n  # Index           Cacheline  records     Hitm    Total      Lcl      \u003Cspan class=\"strong strong\">\u003Cstrong>Rmt\u003C/strong>\u003C/span>    Total    L1Hit   L1Miss       Lcl       Rmt  Ld Miss    Loads       FB       L1       L2       Llc       Rmt\n  # .....  ..................  .......  .......  .......  .......  .......  .......  .......  .......  ........  ........  .......  .......  .......  .......  .......  ........  ........\n  #\n        0            0x602180   149904   77.09%    12103     2269     9834   109504   109036      468       727      2657    13747    40400     5355    16154        0      2875       529\n        1            0x602100    12128   22.20%     3951     1119     2832        0        0        0        65       200     3749    12128     5096      108        0      2056       652\n        2  0xffff883ffb6a7e80      260    0.09%       15        3       12      161      161        0         1         1       15       99       25       50        0         6         1\n        3  0xffffffff81aec000      157    0.07%        9        0        9        1        0        1         0         7       20      156       50       59        0        27         4\n        4  0xffffffff81e3f540      179    0.06%        9        1        8      117       97       20         0        10       25       62       11        1        0        24         7\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThis table is sorted in descending order by the amount of remote \u003Cspan class=\"strong strong\">\u003Cstrong>Hitm\u003C/strong>\u003C/span> detected per cache line. A high number in the \u003Cspan class=\"strong strong\">\u003Cstrong>Rmt\u003C/strong>\u003C/span> column of the \u003Cspan class=\"strong strong\">\u003Cstrong>LLC Load Hitm\u003C/strong>\u003C/span> section indicates false sharing and requires further inspection of the cache line on which it occurred to debug the false sharing activity.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"getting-started-with-flamegraphs_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 25. Getting started with flamegraphs\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tAs a system administrator, you can use \u003Ccode class=\"literal\">flamegraphs\u003C/code> to create visualizations of system performance data recorded with the \u003Ccode class=\"literal\">perf\u003C/code> tool. As a software developer, you can use \u003Ccode class=\"literal\">flamegraphs\u003C/code> to create visualizations of application performance data recorded with the \u003Ccode class=\"literal\">perf\u003C/code> tool.\n\t\t\u003C/p>\u003Cp>\n\t\t\tSampling stack traces is a common technique for profiling CPU performance with the \u003Ccode class=\"literal\">perf\u003C/code> tool. Unfortunately, the results of profiling stack traces with \u003Ccode class=\"literal\">perf\u003C/code> can be extremely verbose and labor-intensive to analyze. \u003Ccode class=\"literal\">flamegraphs\u003C/code> are visualizations created from data recorded with \u003Ccode class=\"literal\">perf\u003C/code> to make identifying hot code-paths faster and easier.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"installing-flamegraphs_getting-started-with-flamegraphs\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">25.1. Installing flamegraphs\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tTo begin using \u003Ccode class=\"literal\">flamegraphs\u003C/code>, install the required package.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInstall the \u003Ccode class=\"literal\">flamegraphs\u003C/code> package:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf install js-d3-flame-graph\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"creating-flamegraphs-over-the-entire-system_getting-started-with-flamegraphs\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">25.2. Creating flamegraphs over the entire system\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure describes how to visualize performance data recorded over an entire system using \u003Ccode class=\"literal\">flamegraphs\u003C/code>.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">flamegraphs\u003C/code> are installed as described in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-flamegraphs_monitoring-and-managing-system-status-and-performance#installing-flamegraphs_getting-started-with-flamegraphs\">installing flamegraphs\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">perf\u003C/code> tool is installed as described in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf\">installing perf\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRecord the data and create the visualization:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># perf script flamegraph -a -F 99 sleep 60\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThis command samples and records performance data over the entire system for 60 seconds, as stipulated by use of the \u003Ccode class=\"literal\">sleep\u003C/code> command, and then constructs the visualization which will be stored in the current active directory as \u003Ccode class=\"literal\">flamegraph.html\u003C/code>. The command samples call-graph data by default and takes the same arguments as the \u003Ccode class=\"literal\">perf\u003C/code> tool, in this particular case:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">-a\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\tStipulates to record data over the entire system.\n\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">-F\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\tTo set the sampling frequency per second.\n\t\t\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor analysis, view the generated visualization:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># xdg-open flamegraph.html\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThis command opens the visualization in the default browser:\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/a28282f7a290a148d48eb29b3a17d046/flamegraph_allcpus.png\" alt=\"flamegraph allcpus\"/>\u003C/span>\n\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"creating-flamegraphs-over-specific-processes_getting-started-with-flamegraphs\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">25.3. Creating flamegraphs over specific processes\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can use \u003Ccode class=\"literal\">flamegraphs\u003C/code> to visualize performance data recorded over specific running processes.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">flamegraphs\u003C/code> are installed as described in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-flamegraphs_monitoring-and-managing-system-status-and-performance#installing-flamegraphs_getting-started-with-flamegraphs\">installing flamegraphs\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">perf\u003C/code> tool is installed as described in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf\">installing perf\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRecord the data and create the visualization:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># perf script flamegraph -a -F 99 -p \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>ID1,ID2\u003C/em>\u003C/span>\u003C/code> sleep 60\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThis command samples and records performance data of the processes with the process ID’s \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>ID1\u003C/em>\u003C/span>\u003C/code> and \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>ID2\u003C/em>\u003C/span>\u003C/code> for 60 seconds, as stipulated by use of the \u003Ccode class=\"literal\">sleep\u003C/code> command, and then constructs the visualization which will be stored in the current active directory as \u003Ccode class=\"literal\">flamegraph.html\u003C/code>. The command samples call-graph data by default and takes the same arguments as the \u003Ccode class=\"literal\">perf\u003C/code> tool, in this particular case:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">-a\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\tStipulates to record data over the entire system.\n\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">-F\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\tTo set the sampling frequency per second.\n\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">-p\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\tTo stipulate specific process ID’s to sample and record data over.\n\t\t\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor analysis, view the generated visualization:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># xdg-open flamegraph.html\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThis command opens the visualization in the default browser:\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/003d80d4f9d85ea8e33c627a40a2f333/flamegraph.png\" alt=\"flamegraph\"/>\u003C/span>\n\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"interpreting-flamegraphs_getting-started-with-flamegraphs\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">25.4. Interpreting flamegraphs\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tEach box in the flamegraph represents a different function in the stack. The y-axis shows the depth of the stack with the topmost box in each stack being the function that was actually on-CPU and everything below it being ancestry. The x-axis displays the population of the sampled call-graph data.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe children of a stack in a given row are displayed based on the number of samples taken of each respective function in descending order along the x-axis; the x-axis does not represent the passing of time. The wider an individual box is, the more frequent it was on-CPU or part of an on-CPU ancestry at the time the data was being sampled.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo reveal the names of functions which may have not been displayed previously and further investigate the data click on a box within the flamegraph to zoom into the stack at that given location:\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/0ea4b6a35abc82847a9eb7bb25bf1d6e/zoomed-in-flamegraph.png\" alt=\"zoomed in flamegraph\"/>\u003C/span>\n\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tTo return to the default view of the flamegraph, click \u003Cspan class=\"guibutton\">Reset Zoom\u003C/span>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tBoxes representing user-space functions may be labeled as \u003Cspan class=\"strong strong\">\u003Cstrong>Unknown\u003C/strong>\u003C/span> in \u003Ccode class=\"literal\">flamegraphs\u003C/code> because the binary of the function is stripped. The \u003Ccode class=\"literal\">debuginfo\u003C/code> package of the executable must be installed or, if the executable is a locally developed application, the application must be compiled with debugging information. Use the \u003Ccode class=\"literal\">-g\u003C/code> option in GCC, to display the function names or symbols in such a situation.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\t\u003Cspan class=\"inlinemediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/003d80d4f9d85ea8e33c627a40a2f333/flamegraph.png\" alt=\"flamegraph\"/>\u003C/span>\n\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index#why-perf-displays-some-function-names-as-raw-function-addresses_profiling-cpu-usage-in-real-time-with-top\">Why perf displays some function names as raw functions addresses\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/developing_c_and_cpp_applications_in_rhel_9/debugging-applications_developing-applications#enabling-debugging-with-debugging-information_debugging-applications\">Enabling debugging with debugging information\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"creating-custom-circular-buffers-to-collect-specific-data-with-perf_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 26. Monitoring processes for performance bottlenecks using perf circular buffers\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tYou can create circular buffers that take event-specific snapshots of data with the \u003Ccode class=\"literal\">perf\u003C/code> tool in order to monitor performance bottlenecks in specific processes or parts of applications running on your system. In such cases, \u003Ccode class=\"literal\">perf\u003C/code> only writes data to a \u003Ccode class=\"literal\">perf.data\u003C/code> file for later analysis if a specified event is detected.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"circular-buffers-and-event-specific-snapshots_assembly_creating-custom-circular-buffers-to-collect-specific-data-with-perf\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">26.1. Circular buffers and event-specific snapshots with perf\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tWhen investigating performance issues in a process or application with \u003Ccode class=\"literal\">perf\u003C/code>, it may not be affordable or appropriate to record data for hours preceding a specific event of interest occurring. In such cases, you can use \u003Ccode class=\"literal\">perf record\u003C/code> to create custom circular buffers that take snapshots after specific events.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe \u003Ccode class=\"literal option\">--overwrite\u003C/code> option makes \u003Ccode class=\"literal\">perf record\u003C/code> store all data in an overwritable circular buffer. When the buffer gets full, \u003Ccode class=\"literal\">perf record\u003C/code> automatically overwrites the oldest records which, therefore, never get written to a \u003Ccode class=\"literal file\">perf.data\u003C/code> file.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tUsing the \u003Ccode class=\"literal option\">--overwrite\u003C/code> and \u003Ccode class=\"literal option\">--switch-output-event\u003C/code> options together configures a circular buffer that records and dumps data continuously until it detects the \u003Ccode class=\"literal option\">--switch-output-event\u003C/code> trigger event. The trigger event signals to \u003Ccode class=\"literal\">perf record\u003C/code> that something of interest to the user has occurred and to write the data in the circular buffer to a \u003Ccode class=\"literal file\">perf.data\u003C/code> file. This collects specific data you are interested in while simultaneously reducing the overhead of the running \u003Ccode class=\"literal\">perf\u003C/code> process by not writing data you do not want to a \u003Ccode class=\"literal\">perf.data\u003C/code> file.\n\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"using-perf-to-create-custom-circular-buffers-that-perform-event-specific-snapshots_assembly_creating-custom-circular-buffers-to-collect-specific-data-with-perf\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">26.2. Collecting specific data to monitor for performance bottlenecks using perf circular buffers\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tWith the \u003Ccode class=\"literal\">perf\u003C/code> tool, you can create circular buffers that are triggered by events you specify in order to only collect data you are interested in. To create circular buffers that collect event-specific data, use the \u003Ccode class=\"literal\">--overwrite\u003C/code> and \u003Ccode class=\"literal\">--switch-output-event\u003C/code> options for \u003Ccode class=\"literal\">perf\u003C/code>.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have the \u003Ccode class=\"literal\">perf\u003C/code> user space tool installed as described in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf\">Installing perf\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tYou have placed a uprobe in the process or application you are interested in monitoring at a location of interest within the process or application:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># perf probe -x \u003Cspan class=\"emphasis\">\u003Cem>/path/to/executable\u003C/em>\u003C/span> -a \u003Cspan class=\"emphasis\">\u003Cem>function\u003C/em>\u003C/span>\nAdded new event:\n  \u003Cspan class=\"emphasis\">\u003Cem>probe_executable:function\u003C/em>\u003C/span>   (on \u003Cspan class=\"emphasis\">\u003Cem>function\u003C/em>\u003C/span> in \u003Cspan class=\"emphasis\">\u003Cem>/path/to/executable\u003C/em>\u003C/span>)\n\nYou can now use it in all perf tools, such as:\n\n        perf record -e \u003Cspan class=\"emphasis\">\u003Cem>probe_executable:function\u003C/em>\u003C/span> -aR sleep 1\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate the circular buffer with the uprobe as the trigger event:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># perf record --overwrite -e cycles --switch-output-event \u003Cspan class=\"emphasis\">\u003Cem>probe_executable:function\u003C/em>\u003C/span> ./executable\n[ perf record: dump data: Woken up 1 times ]\n[ perf record: Dump perf.data.2021021012231959 ]\n[ perf record: dump data: Woken up 1 times ]\n[ perf record: Dump perf.data.2021021012232008 ]\n^C[ perf record: dump data: Woken up 1 times ]\n[ perf record: Dump perf.data.2021021012232082 ]\n[ perf record: Captured and wrote 5.621 MB perf.data.&lt;timestamp&gt; ]\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThis example initiates the executable and collects cpu cycles, specified after the \u003Ccode class=\"literal\">-e\u003C/code> option, until \u003Ccode class=\"literal\">perf\u003C/code> detects the uprobe, the trigger event specified after the \u003Ccode class=\"literal\">--switch-output-event\u003C/code> option. At that point, \u003Ccode class=\"literal\">perf\u003C/code> takes a snapshot of all the data in the circular buffer and stores it in a unique \u003Ccode class=\"literal\">perf.data\u003C/code> file identified by timestamp. This example produced a total of 2 snapshots, the last \u003Ccode class=\"literal\">perf.data\u003C/code> file was forced by pressing \u003Ckbd class=\"keycap\">Ctrl\u003C/kbd>+\u003Ckbd class=\"keycap\">c\u003C/kbd>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"turning-tracepoints-on-and-off-without-stopping-or-restarting-perf_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 27. Adding and removing tracepoints from a running perf collector without stopping or restarting perf\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tBy using the control pipe interface to enable and disable different tracepoints in a running \u003Ccode class=\"literal\">perf\u003C/code> collector, you can dynamically adjust what data you are collecting without having to stop or restart \u003Ccode class=\"literal\">perf\u003C/code>. This ensures you do not lose performance data that would have otherwise been recorded during the stopping or restarting process.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"adding-tracepoints-to-a-running-perf-collector-without-stopping-or-restarting-perf_turning-tracepoints-on-and-off-without-stopping-or-restarting-perf\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">27.1. Adding tracepoints to a running perf collector without stopping or restarting perf\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tAdd tracepoints to a running \u003Ccode class=\"literal\">perf\u003C/code> collector using the control pipe interface to adjust the data you are recording without having to stop \u003Ccode class=\"literal\">perf\u003C/code> and losing performance data.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have the \u003Ccode class=\"literal\">perf\u003C/code> user space tool installed as described in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf\">Installing perf\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tConfigure the control pipe interface:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mkfifo control ack perf.pipe\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRun \u003Ccode class=\"literal\">perf record\u003C/code> with the control file setup and events you are interested in enabling:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># perf record --control=fifo:control,ack -D -1 --no-buffering -e '\u003Cspan class=\"emphasis\">\u003Cem>sched:*\u003C/em>\u003C/span>' -o - &gt; perf.pipe\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn this example, declaring \u003Ccode class=\"literal\">'sched:*'\u003C/code> after the \u003Ccode class=\"literal\">-e\u003C/code> option starts \u003Ccode class=\"literal\">perf record\u003C/code> with scheduler events.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn a second terminal, start the read side of the control pipe:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># cat perf.pipe | perf --no-pager script -i -\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tStarting the read side of the control pipe triggers the following message in the first terminal:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">Events disabled\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn a third terminal, enable a tracepoint using the control file:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># echo 'enable \u003Cspan class=\"emphasis\">\u003Cem>sched:sched_process_fork\u003C/em>\u003C/span>' &gt; control\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThis command triggers \u003Ccode class=\"literal\">perf\u003C/code> to scan the current event list in the control file for the declared event. If the event is present, the tracepoint is enabled and the following message appears in the first terminal:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">event sched:sched_process_fork enabled\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOnce the tracepoint is enabled, the second terminal displays the output from \u003Ccode class=\"literal\">perf\u003C/code> detecting the tracepoint:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">bash 33349 [034] 149587.674295: sched:sched_process_fork: comm=bash pid=33349 child_comm=bash child_pid=34056\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"removing-tracepoints-from-a-running-perf-collector-without-stopping-or-restarting-perf_turning-tracepoints-on-and-off-without-stopping-or-restarting-perf\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">27.2. Removing tracepoints from a running perf collector without stopping or restarting perf\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tRemove tracepoints from a running \u003Ccode class=\"literal\">perf\u003C/code> collector using the control pipe interface to reduce the scope of data you are collecting without having to stop \u003Ccode class=\"literal\">perf\u003C/code> and losing performance data.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have the \u003Ccode class=\"literal\">perf\u003C/code> user space tool installed as described in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance#installing-perf_getting-started-with-perf\">Installing perf\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have added tracepoints to a running \u003Ccode class=\"literal\">perf\u003C/code> collector via the control pipe interface. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/turning-tracepoints-on-and-off-without-stopping-or-restarting-perf_monitoring-and-managing-system-status-and-performance#adding-tracepoints-to-a-running-perf-collector-without-stopping-or-restarting-perf_turning-tracepoints-on-and-off-without-stopping-or-restarting-perf\">Adding tracepoints to a running perf collector without stopping or restarting perf\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRemove the tracepoint:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># echo 'disable \u003Cspan class=\"emphasis\">\u003Cem>sched:sched_process_fork\u003C/em>\u003C/span>' &gt; control\u003C/pre>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\tThis example assumes you have previously loaded scheduler events into the control file and enabled the tracepoint \u003Ccode class=\"literal\">sched:sched_process_fork\u003C/code>.\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThis command triggers \u003Ccode class=\"literal\">perf\u003C/code> to scan the current event list in the control file for the declared event. If the event is present, the tracepoint is disabled and the following message appears in the terminal used to configure the control pipe:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">event sched:sched_process_fork disabled\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"profiling-memory-allocation-with-numastat_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 28. Profiling memory allocation with numastat\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tWith the \u003Ccode class=\"literal\">numastat\u003C/code> tool, you can display statistics over memory allocations in a system.\n\t\t\u003C/p>\u003Cp>\n\t\t\tThe \u003Ccode class=\"literal\">numastat\u003C/code> tool displays data for each NUMA node separately. You can use this information to investigate memory performance of your system or the effectiveness of different memory policies on your system.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"default-numastat-statistics_profiling-memory-allocation-with-numastat\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">28.1. Default numastat statistics\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tBy default, the \u003Ccode class=\"literal\">numastat\u003C/code> tool displays statistics over these categories of data for each NUMA node:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">numa_hit\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe number of pages that were successfully allocated to this node.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">numa_miss\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe number of pages that were allocated on this node because of low memory on the intended node. Each \u003Ccode class=\"literal\">numa_miss\u003C/code> event has a corresponding \u003Ccode class=\"literal\">numa_foreign\u003C/code> event on another node.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">numa_foreign\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe number of pages initially intended for this node that were allocated to another node instead. Each \u003Ccode class=\"literal\">numa_foreign\u003C/code> event has a corresponding \u003Ccode class=\"literal\">numa_miss\u003C/code> event on another node.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">interleave_hit\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe number of interleave policy pages successfully allocated to this node.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">local_node\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe number of pages successfully allocated on this node by a process on this node.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">other_node\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe number of pages allocated on this node by a process on another node.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tHigh \u003Ccode class=\"literal\">numa_hit\u003C/code> values and low \u003Ccode class=\"literal\">numa_miss\u003C/code> values (relative to each other) indicate optimal performance.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/section>\u003Csection class=\"section\" id=\"viewing-memory-allocation-with-numastat_profiling-memory-allocation-with-numastat\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">28.2. Viewing memory allocation with numastat\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can view the memory allocation of the system by using the \u003Ccode class=\"literal\">numastat\u003C/code> tool.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInstall the \u003Ccode class=\"literal\">numactl\u003C/code> package:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf install numactl\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tView the memory allocation of your system:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ numastat\n                             node0         node1\nnuma_hit                  76557759      92126519\nnuma_miss                 30772308      30827638\nnuma_foreign              30827638      30772308\ninterleave_hit              106507        103832\nlocal_node                76502227      92086995\nother_node                30827840      30867162\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">numastat(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"configuring-an-operating-system-to-optimize-cpu-utilization_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 29. Configuring an operating system to optimize CPU utilization\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tYou can configure the operating system to optimize CPU utilization across their workloads.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"tools-for-monitoring-and-diagnosing-processor-issues_configuring-an-operating-system-to-optimize-cpu-utilization\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">29.1. Tools for monitoring and diagnosing processor issues\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe following are the tools available in Red Hat Enterprise Linux 9 to monitor and diagnose processor-related performance issues:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">turbostat\u003C/code> tool prints counter results at specified intervals to help administrators identify unexpected behavior in servers, such as excessive power usage, failure to enter deep sleep states, or system management interrupts (SMIs) being created unnecessarily.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">numactl\u003C/code> utility provides a number of options to manage processor and memory affinity. The \u003Ccode class=\"literal\">numactl\u003C/code> package includes the \u003Ccode class=\"literal\">libnuma\u003C/code> library which offers a simple programming interface to the NUMA policy supported by the kernel, and can be used for more fine-grained tuning than the \u003Ccode class=\"literal\">numactl\u003C/code> application.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">numastat\u003C/code> tool displays per-NUMA node memory statistics for the operating system and its processes, and shows administrators whether the process memory is spread throughout a system or is centralized on specific nodes. This tool is provided by the \u003Ccode class=\"literal\">numactl\u003C/code> package.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">numad\u003C/code> is an automatic NUMA affinity management daemon. It monitors NUMA topology and resource usage within a system in order to dynamically improve NUMA resource allocation and management.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/proc/interrupts\u003C/code> file displays the interrupt request (IRQ) number, the number of similar interrupt requests handled by each processor in the system, the type of interrupt sent, and a comma-separated list of devices that respond to the listed interrupt request.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">pqos\u003C/code> utility is available in the \u003Ccode class=\"literal\">intel-cmt-cat\u003C/code> package. It monitors CPU cache and memory bandwidth on recent Intel processors. It monitors:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe instructions per cycle (IPC).\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe count of last level cache MISSES.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe size in kilobytes that the program executing in a given CPU occupies in the LLC.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe bandwidth to local memory (MBL).\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe bandwidth to remote memory (MBR).\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">x86_energy_perf_policy\u003C/code> tool allows administrators to define the relative importance of performance and energy efficiency. This information can then be used to influence processors that support this feature when they select options that trade off between performance and energy efficiency.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">taskset\u003C/code> tool is provided by the \u003Ccode class=\"literal\">util-linux\u003C/code> package. It allows administrators to retrieve and set the processor affinity of a running process, or launch a process with a specified processor affinity.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">turbostat(8)\u003C/code>, \u003Ccode class=\"literal\">numactl(8)\u003C/code>, \u003Ccode class=\"literal\">numastat(8)\u003C/code>, \u003Ccode class=\"literal\">numa(7)\u003C/code>, \u003Ccode class=\"literal\">numad(8)\u003C/code>, \u003Ccode class=\"literal\">pqos(8)\u003C/code>, \u003Ccode class=\"literal\">x86_energy_perf_policy(8)\u003C/code>, and \u003Ccode class=\"literal\">taskset(1)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"types-of-system-topology_configuring-an-operating-system-to-optimize-cpu-utilization\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">29.2. Types of system topology\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tIn modern computing, the idea of a CPU is a misleading one, as most modern systems have multiple processors. The topology of the system is the way these processors are connected to each other and to other system resources. This can affect system and application performance, and the tuning considerations for a system.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe following are the two primary types of topology used in modern computing:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Symmetric Multi-Processor (SMP) topology\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tSMP topology allows all processors to access memory in the same amount of time. However, because shared and equal memory access inherently forces serialized memory accesses from all the CPUs, SMP system scaling constraints are now generally viewed as unacceptable. For this reason, practically all modern server systems are NUMA machines.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Non-Uniform Memory Access (NUMA) topology\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tNUMA topology was developed more recently than SMP topology. In a NUMA system, multiple processors are physically grouped on a socket. Each socket has a dedicated area of memory and processors that have local access to that memory, these are referred to collectively as a node. Processors on the same node have high speed access to that node’s memory bank, and slower access to memory banks not on their node.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tTherefore, there is a performance penalty when accessing non-local memory. Thus, performance sensitive applications on a system with NUMA topology should access memory that is on the same node as the processor executing the application, and should avoid accessing remote memory wherever possible.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tMulti-threaded applications that are sensitive to performance may benefit from being configured to execute on a specific NUMA node rather than a specific processor. Whether this is suitable depends on your system and the requirements of your application. If multiple application threads access the same cached data, then configuring those threads to execute on the same processor may be suitable. However, if multiple threads that access and cache different data execute on the same processor, each thread may evict cached data accessed by a previous thread. This means that each thread 'misses' the cache and wastes execution time fetching data from memory and replacing it in the cache. Use the \u003Ccode class=\"literal\">perf\u003C/code> tool to check for an excessive number of cache misses.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003C/dl>\u003C/div>\u003Csection class=\"section\" id=\"displaying-system-topologies_configuring-an-operating-system-to-optimize-cpu-utilization\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">29.2.1. Displaying system topologies\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\t\tThere are a number of commands that help understand the topology of a system. This procedure describes how to determine the system topology.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tTo display an overview of your system topology:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ numactl --hardware\navailable: 4 nodes (0-3)\nnode 0 cpus: 0 4 8 12 16 20 24 28 32 36\nnode 0 size: 65415 MB\nnode 0 free: 43971 MB\n[...]\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tTo gather the information about the CPU architecture, such as the number of CPUs, threads, cores, sockets, and NUMA nodes:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ lscpu\nArchitecture:          x86_64\nCPU op-mode(s):        32-bit, 64-bit\nByte Order:            Little Endian\nCPU(s):                40\nOn-line CPU(s) list:   0-39\nThread(s) per core:    1\nCore(s) per socket:    10\nSocket(s):             4\nNUMA node(s):          4\nVendor ID:             GenuineIntel\nCPU family:            6\nModel:                 47\nModel name:            Intel(R) Xeon(R) CPU E7- 4870  @ 2.40GHz\nStepping:              2\nCPU MHz:               2394.204\nBogoMIPS:              4787.85\nVirtualization:        VT-x\nL1d cache:             32K\nL1i cache:             32K\nL2 cache:              256K\nL3 cache:              30720K\nNUMA node0 CPU(s):     0,4,8,12,16,20,24,28,32,36\nNUMA node1 CPU(s):     2,6,10,14,18,22,26,30,34,38\nNUMA node2 CPU(s):     1,5,9,13,17,21,25,29,33,37\nNUMA node3 CPU(s):     3,7,11,15,19,23,27,31,35,39\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tTo view a graphical representation of your system:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf install hwloc-gui\n# lstopo\u003C/pre>\u003Cdiv class=\"figure\" id=\"idm140280133768240\">\u003Cp class=\"title\">\u003Cstrong>Figure 29.1. The \u003Ccode class=\"literal\">lstopo\u003C/code> output\u003C/strong>\u003C/p>\u003Cdiv class=\"figure-contents\">\u003Cdiv class=\"mediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/7ddd66e302a97d0b710e23e0af9d6524/lstopo.png\" alt=\"lstopo\"/>\u003C/div>\u003C/div>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tTo view the detailed textual output:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf install hwloc\n# lstopo-no-graphics\nMachine (15GB)\n  Package L#0 + L3 L#0 (8192KB)\n    L2 L#0 (256KB) + L1d L#0 (32KB) + L1i L#0 (32KB) + Core L#0\n        PU L#0 (P#0)\n        PU L#1 (P#4)\n       HostBridge L#0\n    PCI 8086:5917\n        GPU L#0 \"renderD128\"\n        GPU L#1 \"controlD64\"\n        GPU L#2 \"card0\"\n    PCIBridge\n        PCI 8086:24fd\n          Net L#3 \"wlp61s0\"\n    PCIBridge\n        PCI 8086:f1a6\n    PCI 8086:15d7\n        Net L#4 \"enp0s31f6\"\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ccode class=\"literal\">numactl(8)\u003C/code>, \u003Ccode class=\"literal\">lscpu(1)\u003C/code>, and \u003Ccode class=\"literal\">lstopo(1)\u003C/code> man pages on your system\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"section\" id=\"configuring-kernel-tick-time_configuring-an-operating-system-to-optimize-cpu-utilization\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">29.3. Configuring kernel tick time\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tBy default, Red Hat Enterprise Linux 9 uses a tickless kernel, which does not interrupt idle CPUs in order to reduce power usage and allow new processors to take advantage of deep sleep states.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tRed Hat Enterprise Linux 9 also offers a dynamic tickless option, which is useful for latency-sensitive workloads, such as high performance computing or realtime computing. By default, the dynamic tickless option is disabled. Red Hat recommends using the \u003Ccode class=\"literal\">cpu-partitioning\u003C/code> \u003Cspan class=\"strong strong\">\u003Cstrong>TuneD\u003C/strong>\u003C/span> profile to enable the dynamic tickless option for cores specified as \u003Ccode class=\"literal\">isolated_cores\u003C/code>.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThis procedure describes how to manually persistently enable dynamic tickless behavior.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo enable dynamic tickless behavior in certain cores, specify those cores on the kernel command line with the \u003Ccode class=\"literal\">nohz_full\u003C/code> parameter. On a 16 core system, enable the \u003Ccode class=\"literal\">nohz_full=1-15\u003C/code> kernel option:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># grubby --update-kernel=ALL --args=\"nohz_full=1-15\"\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThis enables dynamic tickless behavior on cores \u003Ccode class=\"literal\">1\u003C/code> through \u003Ccode class=\"literal\">15\u003C/code>, moving all timekeeping to the only unspecified core (core \u003Ccode class=\"literal\">0\u003C/code>).\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tWhen the system boots, manually move the \u003Ccode class=\"literal\">rcu\u003C/code> threads to the non-latency-sensitive core, in this case core \u003Ccode class=\"literal\">0\u003C/code>:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># for i in `pgrep rcu[^c]` ; do taskset -pc 0 $i ; done\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tOptional: Use the \u003Ccode class=\"literal\">isolcpus\u003C/code> parameter on the kernel command line to isolate certain cores from user-space tasks.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOptional: Set the CPU affinity for the kernel’s \u003Ccode class=\"literal\">write-back bdi-flush\u003C/code> threads to the housekeeping core:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">echo 1 &gt; /sys/bus/workqueue/devices/writeback/cpumask\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOnce the system is rebooted, verify if \u003Ccode class=\"literal\">dynticks\u003C/code> are enabled:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># journalctl -xe | grep dynticks\nMar 15 18:34:54 rhel-server kernel: NO_HZ: Full dynticks CPUs: 1-15.\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify that the dynamic tickless configuration is working correctly:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># perf stat -C 1 -e irq_vectors:local_timer_entry taskset -c 1 sleep 3\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThis command measures ticks on CPU 1 while telling CPU 1 to sleep for 3 seconds.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe default kernel timer configuration shows around 3100 ticks on a regular CPU:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># perf stat -C 0 -e irq_vectors:local_timer_entry taskset -c 0 sleep 3\n\n Performance counter stats for 'CPU(s) 0':\n\n             3,107      irq_vectors:local_timer_entry\n\n       3.001342790 seconds time elapsed\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tWith the dynamic tickless kernel configured, you should see around 4 ticks instead:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># perf stat -C 1 -e irq_vectors:local_timer_entry taskset -c 1 sleep 3\n\n Performance counter stats for 'CPU(s) 1':\n\n                 4      irq_vectors:local_timer_entry\n\n       3.001544078 seconds time elapsed\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">perf(1)\u003C/code> and \u003Ccode class=\"literal\">cpuset(7)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/solutions/2273531\">All about nohz_full kernel parameter Red Hat Knowledgebase article\u003C/a> (Red Hat Knowledgebase)\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/solutions/3875421\">How to verify the list of \"isolated\" and \"nohz_full\" CPU information from sysfs? Red Hat Knowledgebase article\u003C/a> (Red Hat Knowledgebase)\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"overview-of-an-interrupt-request_configuring-an-operating-system-to-optimize-cpu-utilization\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">29.4. Overview of an interrupt request\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tAn interrupt request or IRQ is a signal for immediate attention sent from a piece of hardware to a processor. Each device in a system is assigned one or more IRQ numbers which allow it to send unique interrupts. When interrupts are enabled, a processor that receives an interrupt request immediately pauses execution of the current application thread in order to address the interrupt request.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tBecause interrupt halts normal operation, high interrupt rates can severely degrade system performance. It is possible to reduce the amount of time taken by interrupts by configuring interrupt affinity or by sending a number of lower priority interrupts in a batch (coalescing a number of interrupts).\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tInterrupt requests have an associated affinity property, \u003Ccode class=\"literal\">smp_affinity\u003C/code>, which defines the processors that handle the interrupt request. To improve application performance, assign interrupt affinity and process affinity to the same processor, or processors on the same core. This allows the specified interrupt and application threads to share cache lines.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tOn systems that support interrupt steering, modifying the \u003Ccode class=\"literal\">smp_affinity\u003C/code> property of an interrupt request sets up the hardware so that the decision to service an interrupt with a particular processor is made at the hardware level with no intervention from the kernel.\n\t\t\t\u003C/p>\u003Csection class=\"section\" id=\"balancing-interrupts-manually_configuring-an-operating-system-to-optimize-cpu-utilization\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">29.4.1. Balancing interrupts manually\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\t\tIf your BIOS exports its NUMA topology, the \u003Ccode class=\"literal\">irqbalance\u003C/code> service can automatically serve interrupt requests on the node that is local to the hardware requesting service.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tCheck which devices correspond to the interrupt requests that you want to configure.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFind the hardware specification for your platform. Check if the chipset on your system supports distributing interrupts.\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tIf it does, you can configure interrupt delivery as described in the following steps. Additionally, check which algorithm your chipset uses to balance interrupts. Some BIOSes have options to configure interrupt delivery.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tIf it does not, your chipset always routes all interrupts to a single, static CPU. You cannot configure which CPU is used.\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tCheck which Advanced Programmable Interrupt Controller (APIC) mode is in use on your system:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ journalctl --dmesg | grep APIC\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tHere,\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tIf your system uses a mode other than \u003Ccode class=\"literal\">flat\u003C/code>, you can see a line similar to \u003Ccode class=\"literal\">Setting APIC routing to physical flat\u003C/code>.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tIf you can see no such message, your system uses \u003Ccode class=\"literal\">flat\u003C/code> mode.\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tIf your system uses \u003Ccode class=\"literal\">x2apic\u003C/code> mode, you can disable it by adding the \u003Ccode class=\"literal\">nox2apic\u003C/code> option to the kernel command line in the \u003Ccode class=\"literal\">bootloader\u003C/code> configuration.\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tOnly non-physical flat mode (\u003Ccode class=\"literal\">flat\u003C/code>) supports distributing interrupts to multiple CPUs. This mode is available only for systems that have up to \u003Ccode class=\"literal\">8\u003C/code> CPUs.\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tCalculate the \u003Ccode class=\"literal\">smp_affinity mask\u003C/code>. For more information about how to calculate the \u003Ccode class=\"literal\">smp_affinity mask\u003C/code>, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/configuring-an-operating-system-to-optimize-cpu-utilization_monitoring-and-managing-system-status-and-performance#setting-the-smp_affinity-mask_configuring-an-operating-system-to-optimize-cpu-utilization\">Setting the smp_affinity mask\u003C/a>.\n\t\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ccode class=\"literal\">journalctl(1)\u003C/code> and \u003Ccode class=\"literal\">taskset(1)\u003C/code> man pages on your system\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"setting-the-smp_affinity-mask_configuring-an-operating-system-to-optimize-cpu-utilization\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">29.4.2. Setting the smp_affinity mask\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\t\tThe \u003Ccode class=\"literal\">smp_affinity\u003C/code> value is stored as a hexadecimal bit mask representing all processors in the system. Each bit configures a different CPU. The least significant bit is CPU 0.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tThe default value of the mask is \u003Ccode class=\"literal\">f\u003C/code>, which means that an interrupt request can be handled on any processor in the system. Setting this value to 1 means that only processor 0 can handle the interrupt.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIn binary, use the value 1 for CPUs that handle the interrupts. For example, to set CPU 0 and CPU 7 to handle interrupts, use \u003Ccode class=\"literal\">0000000010000001\u003C/code> as the binary code:\n\t\t\t\t\t\t\u003C/p>\u003Crh-table id=\"idm140280130434080\">\u003Ctable class=\"gt-8-cols lt-7-rows\">\u003Ccaption>Table 29.1. Binary Bits for CPUs\u003C/caption>\u003Ccolgroup>\u003Ccol style=\"width: 17%; \" class=\"col_1\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 5%; \" class=\"col_2\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 5%; \" class=\"col_3\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 5%; \" class=\"col_4\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 5%; \" class=\"col_5\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 5%; \" class=\"col_6\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 5%; \" class=\"col_7\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 5%; \" class=\"col_8\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 5%; \" class=\"col_9\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 5%; \" class=\"col_10\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 5%; \" class=\"col_11\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 5%; \" class=\"col_12\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 5%; \" class=\"col_13\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 5%; \" class=\"col_14\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 5%; \" class=\"col_15\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 5%; \" class=\"col_16\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 5%; \" class=\"col_17\">\u003C!--Empty-->\u003C/col>\u003C/colgroup>\u003Ctbody>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\tCPU\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t15\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t14\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t13\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t12\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t11\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t10\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t9\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t8\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t7\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t6\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t5\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t4\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t3\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t2\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t1\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t0\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\tBinary\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t0\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t0\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t0\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t0\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t0\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t0\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t0\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t0\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t1\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t0\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t0\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t0\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t0\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t0\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t0\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t\t1\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\u003C/rh-table>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tConvert the binary code to hexadecimal:\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFor example, to convert the binary code using Python:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">&gt;&gt;&gt; hex(int('0000000010000001', 2))\n\n'0x81'\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tOn systems with more than 32 processors, you must delimit the \u003Ccode class=\"literal\">smp_affinity\u003C/code> values for discrete 32 bit groups. For example, if you want only the first 32 processors of a 64 processor system to service an interrupt request, use \u003Ccode class=\"literal\">0xffffffff,00000000\u003C/code>.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe interrupt affinity value for a particular interrupt request is stored in the associated \u003Ccode class=\"literal\">/proc/irq/irq_number/smp_affinity\u003C/code> file. Set the \u003Ccode class=\"literal\">smp_affinity\u003C/code> mask in this file:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># echo mask &gt; /proc/irq/irq_number/smp_affinity\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ccode class=\"literal\">journalctl(1)\u003C/code>, \u003Ccode class=\"literal\">irqbalance(1)\u003C/code>, and \u003Ccode class=\"literal\">taskset(1)\u003C/code> man pages on your system\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"tuning-scheduling-policy_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 30. Tuning scheduling policy\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tIn Red Hat Enterprise Linux, the smallest unit of process execution is called a thread. The system scheduler determines which processor runs a thread, and for how long the thread runs. However, because the scheduler’s primary concern is to keep the system busy, it may not schedule threads optimally for application performance.\n\t\t\u003C/p>\u003Cp>\n\t\t\tFor example, say an application on a NUMA system is running on Node A when a processor on Node B becomes available. To keep the processor on Node B busy, the scheduler moves one of the application’s threads to Node B. However, the application thread still requires access to memory on Node A. But, this memory will take longer to access because the thread is now running on Node B and Node A memory is no longer local to the thread. Thus, it may take longer for the thread to finish running on Node B than it would have taken to wait for a processor on Node A to become available, and then to execute the thread on the original node with local memory access.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"con_categories-of-scheduling-policies_tuning-scheduling-policy\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">30.1. Categories of scheduling policies\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tPerformance sensitive applications often benefit from the designer or administrator determining where threads are run. The Linux scheduler implements a number of scheduling policies which determine where and for how long a thread runs.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe following are the two major categories of scheduling policies:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Normal policies\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tNormal threads are used for tasks of normal priority.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Realtime policies\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tRealtime policies are used for time-sensitive tasks that must complete without interruptions. Realtime threads are not subject to time slicing. This means the thread runs until they block, exit, voluntarily yield, or are preempted by a higher priority thread.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe lowest priority realtime thread is scheduled before any thread with a normal policy. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/tuning-scheduling-policy_monitoring-and-managing-system-status-and-performance#static-priority-scheduling-with-SCHED_FIFO_tuning-scheduling-policy\">Static priority scheduling with SCHED_FIFO\u003C/a> and \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/tuning-scheduling-policy_monitoring-and-managing-system-status-and-performance#round-robin-priority-scheduling-with-sched_rr_tuning-scheduling-policy\">Round robin priority scheduling with SCHED_RR\u003C/a>.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">sched(7)\u003C/code>, \u003Ccode class=\"literal\">sched_setaffinity(2)\u003C/code>, \u003Ccode class=\"literal\">sched_getaffinity(2)\u003C/code>, \u003Ccode class=\"literal\">sched_setscheduler(2)\u003C/code>, and \u003Ccode class=\"literal\">sched_getscheduler(2)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"static-priority-scheduling-with-SCHED_FIFO_tuning-scheduling-policy\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">30.2. Static priority scheduling with SCHED_FIFO\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe \u003Ccode class=\"literal\">SCHED_FIFO\u003C/code>, also called static priority scheduling, is a realtime policy that defines a fixed priority for each thread. This policy allows administrators to improve event response time and reduce latency. It is recommended to not execute this policy for an extended period of time for time sensitive tasks.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tWhen \u003Ccode class=\"literal\">SCHED_FIFO\u003C/code> is in use, the scheduler scans the list of all the \u003Ccode class=\"literal\">SCHED_FIFO\u003C/code> threads in order of priority and schedules the highest priority thread that is ready to run. The priority level of a \u003Ccode class=\"literal\">SCHED_FIFO\u003C/code> thread can be any integer from \u003Ccode class=\"literal\">1\u003C/code> to \u003Ccode class=\"literal\">99\u003C/code>, where \u003Ccode class=\"literal\">99\u003C/code> is treated as the highest priority. Red Hat recommends starting with a lower number and increasing priority only when you identify latency issues.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition warning\" state=\"danger\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Warning\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tBecause realtime threads are not subject to time slicing, Red Hat does not recommend setting a priority as 99. This keeps your process at the same priority level as migration and watchdog threads; if your thread goes into a computational loop and these threads are blocked, they will not be able to run. Systems with a single processor will eventually hang in this situation.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cp>\n\t\t\t\tAdministrators can limit \u003Ccode class=\"literal\">SCHED_FIFO\u003C/code> bandwidth to prevent realtime application programmers from initiating realtime tasks that monopolize the processor.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe following are some of the parameters used in this policy:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">/proc/sys/kernel/sched_rt_period_us\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThis parameter defines the time period, in microseconds, that is considered to be one hundred percent of the processor bandwidth. The default value is \u003Ccode class=\"literal\">1000000 μs\u003C/code>, or \u003Ccode class=\"literal\">1 second\u003C/code>.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">/proc/sys/kernel/sched_rt_runtime_us\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThis parameter defines the time period, in microseconds, that is devoted to running real-time threads. The default value is \u003Ccode class=\"literal\">950000 μs\u003C/code>, or \u003Ccode class=\"literal\">0.95 seconds\u003C/code>.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"round-robin-priority-scheduling-with-sched_rr_tuning-scheduling-policy\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">30.3. Round robin priority scheduling with SCHED_RR\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe \u003Ccode class=\"literal\">SCHED_RR\u003C/code> is a round-robin variant of the \u003Ccode class=\"literal\">SCHED_FIFO\u003C/code>. This policy is useful when multiple threads need to run at the same priority level.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tLike \u003Ccode class=\"literal\">SCHED_FIFO\u003C/code>, \u003Ccode class=\"literal\">SCHED_RR\u003C/code> is a realtime policy that defines a fixed priority for each thread. The scheduler scans the list of all SCHED_RR threads in order of priority and schedules the highest priority thread that is ready to run. However, unlike \u003Ccode class=\"literal\">SCHED_FIFO\u003C/code>, threads that have the same priority are scheduled in a round-robin style within a certain time slice.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tYou can set the value of this time slice in milliseconds with the \u003Ccode class=\"literal\">sched_rr_timeslice_ms\u003C/code> kernel parameter in the \u003Ccode class=\"literal\">/proc/sys/kernel/sched_rr_timeslice_ms\u003C/code> file. The lowest value is \u003Ccode class=\"literal\">1 millisecond\u003C/code>.\n\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"normal-scheduling-with-sched_other_tuning-scheduling-policy\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">30.4. Normal scheduling with SCHED_OTHER\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe \u003Ccode class=\"literal\">SCHED_OTHER\u003C/code> is the default scheduling policy in Red Hat Enterprise Linux 9. This policy uses the Completely Fair Scheduler (CFS) to allow fair processor access to all threads scheduled with this policy. This policy is most useful when there are a large number of threads or when data throughput is a priority, as it allows more efficient scheduling of threads over time.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tWhen this policy is in use, the scheduler creates a dynamic priority list based partly on the niceness value of each process thread. Administrators can change the niceness value of a process, but cannot change the scheduler’s dynamic priority list directly.\n\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"setting-scheduler-policies_tuning-scheduling-policy\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">30.5. Setting scheduler policies\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tCheck and adjust scheduler policies and priorities by using the \u003Ccode class=\"literal\">chrt\u003C/code> command line tool. It can start new processes with the desired properties, or change the properties of a running process. It can also be used for setting the policy at runtime.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tView the process ID (PID) of the active processes:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># ps\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tUse the \u003Ccode class=\"literal\">--pid\u003C/code> or \u003Ccode class=\"literal\">-p\u003C/code> option with the \u003Ccode class=\"literal\">ps\u003C/code> command to view the details of the particular PID.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCheck the scheduling policy, PID, and priority of a particular process:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># chrt -p \u003Cspan class=\"emphasis\">\u003Cem>468\u003C/em>\u003C/span>\npid \u003Cspan class=\"emphasis\">\u003Cem>468\u003C/em>\u003C/span>'s current scheduling policy: \u003Cspan class=\"emphasis\">\u003Cem>SCHED_FIFO\u003C/em>\u003C/span>\npid \u003Cspan class=\"emphasis\">\u003Cem>468\u003C/em>\u003C/span>'s current scheduling priority: \u003Cspan class=\"emphasis\">\u003Cem>85\u003C/em>\u003C/span>\n\n# chrt -p \u003Cspan class=\"emphasis\">\u003Cem>476\u003C/em>\u003C/span>\npid \u003Cspan class=\"emphasis\">\u003Cem>476\u003C/em>\u003C/span>'s current scheduling policy: \u003Cspan class=\"emphasis\">\u003Cem>SCHED_OTHER\u003C/em>\u003C/span>\npid \u003Cspan class=\"emphasis\">\u003Cem>476\u003C/em>\u003C/span>'s current scheduling priority: \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tHere, \u003Cspan class=\"emphasis\">\u003Cem>468\u003C/em>\u003C/span> and \u003Cspan class=\"emphasis\">\u003Cem>476\u003C/em>\u003C/span> are PID of a process.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tSet the scheduling policy of a process:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tFor example, to set the process with PID \u003Cspan class=\"emphasis\">\u003Cem>1000\u003C/em>\u003C/span> to \u003Cspan class=\"emphasis\">\u003Cem>SCHED_FIFO\u003C/em>\u003C/span>, with a priority of \u003Cspan class=\"emphasis\">\u003Cem>50\u003C/em>\u003C/span>:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># chrt -f -p \u003Cspan class=\"emphasis\">\u003Cem>50 1000\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tFor example, to set the process with PID \u003Cspan class=\"emphasis\">\u003Cem>1000\u003C/em>\u003C/span> to \u003Cspan class=\"emphasis\">\u003Cem>SCHED_OTHER\u003C/em>\u003C/span>, with a priority of \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># chrt -o -p \u003Cspan class=\"emphasis\">\u003Cem>0 1000\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tFor example, to set the process with PID \u003Cspan class=\"emphasis\">\u003Cem>1000\u003C/em>\u003C/span> to \u003Cspan class=\"emphasis\">\u003Cem>SCHED_RR\u003C/em>\u003C/span>, with a priority of \u003Cspan class=\"emphasis\">\u003Cem>10\u003C/em>\u003C/span>:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># chrt -r -p \u003Cspan class=\"emphasis\">\u003Cem>10 1000\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tTo start a new application with a particular policy and priority, specify the name of the application:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># chrt -f \u003Cspan class=\"emphasis\">\u003Cem>36 /bin/my-app\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">chrt(1)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/tuning-scheduling-policy_monitoring-and-managing-system-status-and-performance#policy-options-for-the-chrt-command_tuning-scheduling-policy\">Policy Options for the chrt command\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/tuning-scheduling-policy_monitoring-and-managing-system-status-and-performance#changing-the-priority-of-service-during-the-boot-process_tuning-scheduling-policy\">Changing the priority of services during the boot process\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"policy-options-for-the-chrt-command_tuning-scheduling-policy\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">30.6. Policy options for the chrt command\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tUsing the \u003Ccode class=\"literal\">chrt\u003C/code> command, you can view and set the scheduling policy of a process.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe following table describes the appropriate policy options, which can be used to set the scheduling policy of a process.\n\t\t\t\u003C/p>\u003Crh-table id=\"idm140280131368304\">\u003Ctable class=\"lt-4-cols lt-7-rows\">\u003Ccaption>Table 30.1. Policy Options for the chrt Command\u003C/caption>\u003Ccolgroup>\u003Ccol style=\"width: 33%; \" class=\"col_1\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 33%; \" class=\"col_2\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 33%; \" class=\"col_3\">\u003C!--Empty-->\u003C/col>\u003C/colgroup>\u003Cthead>\u003Ctr>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280131362528\" scope=\"col\">Short option\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280131361440\" scope=\"col\">Long option\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280131360352\" scope=\"col\">Description\u003C/th>\u003C/tr>\u003C/thead>\u003Ctbody>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280131362528\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">-f\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280131361440\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">--fifo\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280131360352\"> \u003Cp>\n\t\t\t\t\t\t\t\tSet schedule to \u003Ccode class=\"literal\">SCHED_FIFO\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280131362528\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">-o\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280131361440\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">--other\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280131360352\"> \u003Cp>\n\t\t\t\t\t\t\t\tSet schedule to \u003Ccode class=\"literal\">SCHED_OTHER\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280131362528\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">-r\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280131361440\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">--rr\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280131360352\"> \u003Cp>\n\t\t\t\t\t\t\t\tSet schedule to \u003Ccode class=\"literal\">SCHED_RR\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\u003C/rh-table>\u003C/section>\u003Csection class=\"section\" id=\"changing-the-priority-of-service-during-the-boot-process_tuning-scheduling-policy\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">30.7. Changing the priority of services during the boot process\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tUsing the \u003Ccode class=\"literal\">systemd\u003C/code> service, it is possible to set up real-time priorities for services launched during the boot process. The \u003Cspan class=\"emphasis\">\u003Cem>unit configuration directives\u003C/em>\u003C/span> are used to change the priority of a service during the boot process.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe boot process priority change is done by using the following directives in the service section:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">CPUSchedulingPolicy=\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tSets the CPU scheduling policy for executed processes. It is used to set \u003Ccode class=\"literal\">other\u003C/code>, \u003Ccode class=\"literal\">fifo\u003C/code>, and \u003Ccode class=\"literal\">rr\u003C/code> policies.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">CPUSchedulingPriority=\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tSets the CPU scheduling priority for executed processes. The available priority range depends on the selected CPU scheduling policy. For real-time scheduling policies, an integer between \u003Ccode class=\"literal\">1\u003C/code> (lowest priority) and \u003Ccode class=\"literal\">99\u003C/code> (highest priority) can be used.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cp>\n\t\t\t\tThe following procedure describes how to change the priority of a service, during the boot process, using the \u003Ccode class=\"literal\">mcelog\u003C/code> service.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInstall the TuneD package:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf install tuned\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnable and start the TuneD service:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># systemctl enable --now tuned\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tView the scheduling priorities of running threads:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># tuna --show_threads\n                      thread       ctxt_switches\n    pid SCHED_ rtpri affinity voluntary nonvoluntary             cmd\n  1      OTHER     0     0xff      3181          292         systemd\n  2      OTHER     0     0xff       254            0        kthreadd\n  3      OTHER     0     0xff         2            0          rcu_gp\n  4      OTHER     0     0xff         2            0      rcu_par_gp\n  6      OTHER     0        0         9            0 kworker/0:0H-kblockd\n  7      OTHER     0     0xff      1301            1 kworker/u16:0-events_unbound\n  8      OTHER     0     0xff         2            0    mm_percpu_wq\n  9      OTHER     0        0       266            0     ksoftirqd/0\n[...]\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a supplementary \u003Ccode class=\"literal\">mcelog\u003C/code> service configuration directory file and insert the policy name and priority in this file:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># cat &lt;&lt; EOF &gt; /etc/systemd/system/mcelog.service.d/priority.conf\n\n[Service]\nCPUSchedulingPolicy=\u003Cspan class=\"emphasis\">\u003Cem>fifo\u003C/em>\u003C/span>\nCPUSchedulingPriority=\u003Cspan class=\"emphasis\">\u003Cem>20\u003C/em>\u003C/span>\nEOF\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tReload the \u003Ccode class=\"literal\">systemd\u003C/code> scripts configuration:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># systemctl daemon-reload\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRestart the \u003Ccode class=\"literal\">mcelog\u003C/code> service:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># systemctl restart mcelog\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tDisplay the \u003Ccode class=\"literal\">mcelog\u003C/code> priority set by \u003Ccode class=\"literal\">systemd\u003C/code> issue:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># tuna -t mcelog -P\nthread       ctxt_switches\n  pid SCHED_ rtpri affinity voluntary nonvoluntary             cmd\n826     FIFO    20  0,1,2,3        13            0          mcelog\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">systemd(1)\u003C/code> and \u003Ccode class=\"literal\">tuna(8)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/tuning-scheduling-policy_monitoring-and-managing-system-status-and-performance#priority-map_tuning-scheduling-policy\">Description of the priority range\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"priority-map_tuning-scheduling-policy\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">30.8. Priority map\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tPriorities are defined in groups, with some groups dedicated to certain kernel functions. For real-time scheduling policies, an integer between \u003Ccode class=\"literal\">1\u003C/code> (lowest priority) and \u003Ccode class=\"literal\">99\u003C/code> (highest priority) can be used.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe following table describes the priority range, which can be used while setting the scheduling policy of a process.\n\t\t\t\u003C/p>\u003Crh-table id=\"idm140280130694608\">\u003Ctable class=\"lt-4-cols lt-7-rows\">\u003Ccaption>Table 30.2. Description of the priority range\u003C/caption>\u003Ccolgroup>\u003Ccol style=\"width: 33%; \" class=\"col_1\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 33%; \" class=\"col_2\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 33%; \" class=\"col_3\">\u003C!--Empty-->\u003C/col>\u003C/colgroup>\u003Cthead>\u003Ctr>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280130688832\" scope=\"col\">Priority\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280130687744\" scope=\"col\">Threads\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280130686656\" scope=\"col\">Description\u003C/th>\u003C/tr>\u003C/thead>\u003Ctbody>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280130688832\"> \u003Cp>\n\t\t\t\t\t\t\t\t1\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280130687744\"> \u003Cp>\n\t\t\t\t\t\t\t\tLow priority kernel threads\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280130686656\"> \u003Cp>\n\t\t\t\t\t\t\t\tThis priority is usually reserved for the tasks that need to be just above \u003Ccode class=\"literal\">SCHED_OTHER\u003C/code>.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280130688832\"> \u003Cp>\n\t\t\t\t\t\t\t\t2 - 49\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280130687744\"> \u003Cp>\n\t\t\t\t\t\t\t\tAvailable for use\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280130686656\"> \u003Cp>\n\t\t\t\t\t\t\t\tThe range used for typical application priorities.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280130688832\"> \u003Cp>\n\t\t\t\t\t\t\t\t50\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280130687744\"> \u003Cp>\n\t\t\t\t\t\t\t\tDefault hard-IRQ value\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280130686656\"> \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280130688832\"> \u003Cp>\n\t\t\t\t\t\t\t\t51 - 98\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280130687744\"> \u003Cp>\n\t\t\t\t\t\t\t\tHigh priority threads\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280130686656\"> \u003Cp>\n\t\t\t\t\t\t\t\tUse this range for threads that execute periodically and must have quick response times. Do not use this range for CPU-bound threads as you will starve interrupts.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280130688832\"> \u003Cp>\n\t\t\t\t\t\t\t\t99\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280130687744\"> \u003Cp>\n\t\t\t\t\t\t\t\tWatchdogs and migration\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280130686656\"> \u003Cp>\n\t\t\t\t\t\t\t\tSystem threads that must run at the highest priority.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\u003C/rh-table>\u003C/section>\u003Csection class=\"section\" id=\"tuned-cpu-partitioning-profile_tuning-scheduling-policy\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">30.9. TuneD cpu-partitioning profile\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tFor tuning Red Hat Enterprise Linux 9 for latency-sensitive workloads, Red Hat recommends to use the \u003Ccode class=\"literal\">cpu-partitioning\u003C/code> TuneD profile.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tPrior to Red Hat Enterprise Linux 9, the low-latency Red Hat documentation described the numerous low-level steps needed to achieve low-latency tuning. In Red Hat Enterprise Linux 9, you can perform low-latency tuning more efficiently by using the \u003Ccode class=\"literal\">cpu-partitioning\u003C/code> TuneD profile. This profile is easily customizable according to the requirements for individual low-latency applications.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe following figure is an example to demonstrate how to use the \u003Ccode class=\"literal\">cpu-partitioning\u003C/code> profile. This example uses the CPU and node layout.\n\t\t\t\u003C/p>\u003Cdiv class=\"figure\" id=\"cpu-partitioning_tuning-scheduling-policy\">\u003Cp class=\"title\">\u003Cstrong>Figure 30.1. Figure cpu-partitioning\u003C/strong>\u003C/p>\u003Cdiv class=\"figure-contents\">\u003Cdiv class=\"mediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/367206bd2d1527d49965f718f51722e3/cpu-partitioning.png\" alt=\"cpu partitioning\"/>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tYou can configure the cpu-partitioning profile in the \u003Ccode class=\"literal\">/etc/tuned/cpu-partitioning-variables.conf\u003C/code> file using the following configuration options:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">Isolated CPUs with load balancing\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIn the cpu-partitioning figure, the blocks numbered from 4 to 23, are the default isolated CPUs. The kernel scheduler’s process load balancing is enabled on these CPUs. It is designed for low-latency processes with multiple threads that need the kernel scheduler load balancing.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tYou can configure the cpu-partitioning profile in the \u003Ccode class=\"literal\">/etc/tuned/cpu-partitioning-variables.conf\u003C/code> file using the \u003Ccode class=\"literal\">isolated_cores=cpu-list\u003C/code> option, which lists CPUs to isolate that will use the kernel scheduler load balancing.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe list of isolated CPUs is comma-separated or you can specify a range using a dash, such as \u003Ccode class=\"literal\">3-5\u003C/code>. This option is mandatory. Any CPU missing from this list is automatically considered a housekeeping CPU.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Isolated CPUs without load balancing\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIn the cpu-partitioning figure, the blocks numbered 2 and 3, are the isolated CPUs that do not provide any additional kernel scheduler process load balancing.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tYou can configure the cpu-partitioning profile in the \u003Ccode class=\"literal\">/etc/tuned/cpu-partitioning-variables.conf\u003C/code> file using the \u003Ccode class=\"literal\">no_balance_cores=cpu-list\u003C/code> option, which lists CPUs to isolate that will not use the kernel scheduler load balancing.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tSpecifying the \u003Ccode class=\"literal\">no_balance_cores\u003C/code> option is optional, however any CPUs in this list must be a subset of the CPUs listed in the \u003Ccode class=\"literal\">isolated_cores\u003C/code> list.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tApplication threads using these CPUs need to be pinned individually to each CPU.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Housekeeping CPUs\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tAny CPU not isolated in the \u003Ccode class=\"literal\">cpu-partitioning-variables.conf\u003C/code> file is automatically considered a housekeeping CPU. On the housekeeping CPUs, all services, daemons, user processes, movable kernel threads, interrupt handlers, and kernel timers are permitted to execute.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">tuned-profiles-cpu-partitioning(7)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"using-the-tuned-cpu-partitioning-profile-for-low-latency-tuning_tuning-scheduling-policy\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">30.10. Using the TuneD cpu-partitioning profile for low-latency tuning\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure describes how to tune a system for low-latency using the TuneD’s \u003Ccode class=\"literal\">cpu-partitioning\u003C/code> profile. It uses the example of a low-latency application that can use \u003Ccode class=\"literal\">cpu-partitioning\u003C/code> and the CPU layout as mentioned in the \u003Ca class=\"link\" href=\"#cpu-partitioning_tuning-scheduling-policy\" title=\"Figure 30.1. Figure cpu-partitioning\">cpu-partitioning\u003C/a> figure.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe application in this case uses:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tOne dedicated reader thread that reads data from the network will be pinned to CPU 2.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tA large number of threads that process this network data will be pinned to CPUs 4-23.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tA dedicated writer thread that writes the processed data to the network will be pinned to CPU 3.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have installed the \u003Ccode class=\"literal\">cpu-partitioning\u003C/code> TuneD profile by using the \u003Ccode class=\"literal\">dnf install tuned-profiles-cpu-partitioning\u003C/code> command as root.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEdit \u003Ccode class=\"literal\">/etc/tuned/cpu-partitioning-variables.conf\u003C/code> file and add the following information:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># All isolated CPUs:\nisolated_cores=2-23\n# Isolated CPUs without the kernel’s scheduler load balancing:\nno_balance_cores=2,3\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tSet the \u003Ccode class=\"literal\">cpu-partitioning\u003C/code> TuneD profile:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># tuned-adm profile cpu-partitioning\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tReboot\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAfter rebooting, the system is tuned for low-latency, according to the isolation in the cpu-partitioning figure. The application can use taskset to pin the reader and writer threads to CPUs 2 and 3, and the remaining application threads on CPUs 4-23.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">tuned-profiles-cpu-partitioning(7)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"customizing-the-cpu-partitioning-tuned-profile_tuning-scheduling-policy\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">30.11. Customizing the cpu-partitioning TuneD profile\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can extend the TuneD profile to make additional tuning changes.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tFor example, the \u003Ccode class=\"literal\">cpu-partitioning\u003C/code> profile sets the CPUs to use \u003Ccode class=\"literal\">cstate=1\u003C/code>. In order to use the \u003Ccode class=\"literal\">cpu-partitioning\u003C/code> profile but to additionally change the CPU cstate from cstate1 to cstate0, the following procedure describes a new TuneD profile named \u003Cspan class=\"emphasis\">\u003Cem>my_profile\u003C/em>\u003C/span>, which inherits the \u003Ccode class=\"literal\">cpu-partitioning\u003C/code> profile and then sets C state-0.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate the \u003Ccode class=\"literal\">/etc/tuned/my_profile\u003C/code> directory:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># mkdir /etc/tuned/\u003Cspan class=\"emphasis\">\u003Cem>my_profile\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a \u003Ccode class=\"literal\">tuned.conf\u003C/code> file in this directory, and add the following content:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># vi /etc/tuned/\u003Cspan class=\"emphasis\">\u003Cem>my_profile\u003C/em>\u003C/span>/tuned.conf\n[main]\nsummary=Customized tuning on top of cpu-partitioning\ninclude=cpu-partitioning\n[cpu]\nforce_latency=cstate.id:0|1\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tUse the new profile:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># tuned-adm profile \u003Cspan class=\"emphasis\">\u003Cem>my_profile\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tIn the shared example, a reboot is not required. However, if the changes in the \u003Cspan class=\"emphasis\">\u003Cem>my_profile\u003C/em>\u003C/span> profile require a reboot to take effect, then reboot your machine.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">tuned-profiles-cpu-partitioning(7)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"tuning-the-network-performance_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 31. Tuning the network performance\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\tTuning the network settings is a complex process with many factors to consider. For example, this includes the CPU-to-memory architecture, the amount of CPU cores, and more. Red Hat Enterprise Linux uses default settings that are optimized for most scenarios. However, in certain cases, it can be necessary to tune network settings to increase the throughput or latency or to solve problems, such as packet drops.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"tuning-network-adapter-settings_tuning-the-network-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">31.1. Tuning network adapter settings\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tIn high-speed networks with 40 Gbps and faster, certain default values of network adapter-related kernel settings can be a cause of packet drops and performance degradation. Tuning these settings can prevent such problems.\n\t\t\t\u003C/p>\u003Csection class=\"section\" id=\"increasing-the-ring-buffers-to-reduce-a-high-packet-drop-rate_tuning-network-adapter-settings\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">31.1.1. Increasing the ring buffer size to reduce a high packet drop rate by using \u003Ccode class=\"literal\">nmcli\u003C/code>\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\t\tIncrease the size of an Ethernet device’s ring buffers if the packet drop rate causes applications to report a loss of data, timeouts, or other issues.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tReceive ring buffers are shared between the device driver and network interface controller (NIC). The card assigns a transmit (TX) and receive (RX) ring buffer. As the name implies, the ring buffer is a circular buffer where an overflow overwrites existing data. There are two ways to move data from the NIC to the kernel, hardware interrupts and software interrupts, also called SoftIRQs.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tThe kernel uses the RX ring buffer to store incoming packets until the device driver can process them. The device driver drains the RX ring, typically by using SoftIRQs, which puts the incoming packets into a kernel data structure called an \u003Ccode class=\"literal\">sk_buff\u003C/code> or \u003Ccode class=\"literal\">skb\u003C/code> to begin its journey through the kernel and up to the application that owns the relevant socket.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tThe kernel uses the TX ring buffer to hold outgoing packets which should be sent to the network. These ring buffers reside at the bottom of the stack and are a crucial point at which packet drop can occur, which in turn will adversely affect network performance.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tDisplay the packet drop statistics of the interface:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ethtool -S \u003Cspan class=\"emphasis\">\u003Cem>enp1s0\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\n    ...\n    rx_queue_0_drops: \u003Cspan class=\"emphasis\">\u003Cem>97326\u003C/em>\u003C/span>\n    rx_queue_1_drops: \u003Cspan class=\"emphasis\">\u003Cem>63783\u003C/em>\u003C/span>\n    ...\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tNote that the output of the command depends on the network card and the driver.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tHigh values in \u003Ccode class=\"literal\">discard\u003C/code> or \u003Ccode class=\"literal\">drop\u003C/code> counters indicate that the available buffer fills up faster than the kernel can process the packets. Increasing the ring buffers can help to avoid such loss.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tDisplay the maximum ring buffer sizes:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ethtool -g \u003Cspan class=\"emphasis\">\u003Cem>enp1s0\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\n Ring parameters for \u003Cspan class=\"emphasis\">\u003Cem>enp1s0\u003C/em>\u003C/span>:\n Pre-set maximums:\n RX:             \u003Cspan class=\"emphasis\">\u003Cem>4096\u003C/em>\u003C/span>\n RX Mini:        \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>\n RX Jumbo:       \u003Cspan class=\"emphasis\">\u003Cem>16320\u003C/em>\u003C/span>\n TX:             \u003Cspan class=\"emphasis\">\u003Cem>4096\u003C/em>\u003C/span>\n Current hardware settings:\n RX:             \u003Cspan class=\"emphasis\">\u003Cem>255\u003C/em>\u003C/span>\n RX Mini:        \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>\n RX Jumbo:       \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>\n TX:             \u003Cspan class=\"emphasis\">\u003Cem>255\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIf the values in the \u003Ccode class=\"literal\">Pre-set maximums\u003C/code> section are higher than in the \u003Ccode class=\"literal\">Current hardware settings\u003C/code> section, you can change the settings in the next steps.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIdentify the NetworkManager connection profile that uses the interface:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>nmcli connection show\u003C/strong>\u003C/span>\nNAME                UUID                                  TYPE      DEVICE\n\u003Cspan class=\"emphasis\">\u003Cem>Example-Connection\u003C/em>\u003C/span>  \u003Cspan class=\"emphasis\">\u003Cem>a5eb6490-cc20-3668-81f8-0314a27f3f75\u003C/em>\u003C/span>  ethernet  \u003Cspan class=\"emphasis\">\u003Cem>enp1s0\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tUpdate the connection profile, and increase the ring buffers:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tTo increase the RX ring buffer, enter:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>nmcli connection modify \u003Cspan class=\"emphasis\">\u003Cem>Example-Connection\u003C/em>\u003C/span> ethtool.ring-rx \u003Cspan class=\"emphasis\">\u003Cem>4096\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tTo increase the TX ring buffer, enter:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>nmcli connection modify \u003Cspan class=\"emphasis\">\u003Cem>Example-Connection\u003C/em>\u003C/span> ethtool.ring-tx \u003Cspan class=\"emphasis\">\u003Cem>4096\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tReload the NetworkManager connection:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>nmcli connection up \u003Cspan class=\"emphasis\">\u003Cem>Example-Connection\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\t\tDepending on the driver your NIC uses, changing in the ring buffer can shortly interrupt the network connection.\n\t\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/solutions/2073223\">ifconfig and ip commands report packet drops\u003C/a> (Red Hat Knowledgebase)\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/solutions/742043\">Should I be concerned about a 0.05% packet drop rate?\u003C/a> (Red Hat Knowledgebase)\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ccode class=\"literal\">ethtool(8)\u003C/code> man page on your system\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"tuning-the-network-device-backlog-queue-to-avoid-packet-drops_tuning-network-adapter-settings\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">31.1.2. Tuning the network device backlog queue to avoid packet drops\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tWhen a network card receives packets and before the kernel protocol stack processes them, the kernel stores these packets in backlog queues. The kernel maintains a separate queue for each CPU core.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tIf the backlog queue for a core is full, the kernel drops all further incoming packets that the \u003Ccode class=\"literal\">netif_receive_skb()\u003C/code> kernel function assigns to this queue. If the server contains a 10 Gbps or faster network adapter or multiple 1 Gbps adapters, tune the backlog queue size to avoid this problem.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tA 10 Gbps or faster or multiple 1 Gbps network adapters\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tDetermine whether tuning the backlog queue is needed, display the counters in the \u003Ccode class=\"literal\">/proc/net/softnet_stat\u003C/code> file:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>awk '{for (i=1; i&lt;=NF; i++) printf strtonum(\"0x\" $i) (i==NF?\"\\n\":\" \")}' /proc/net/softnet_stat | column -t\u003C/strong>\u003C/span>\n221951548  0      0  0  0  0  0  0  0  0  0  0  0\n192058677  18862  0  0  0  0  0  0  0  0  0  0  1\n455324886  0      0  0  0  0  0  0  0  0  0  0  2\n...\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThis \u003Ccode class=\"literal\">awk\u003C/code> command converts the values in \u003Ccode class=\"literal\">/proc/net/softnet_stat\u003C/code> from hexadecimal to decimal format and displays them in table format. Each line represents a CPU core starting with core 0.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe relevant columns are:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tFirst column: The total number of received frames\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tSecond column: The number of dropped frames because of a full backlog queue\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tLast column: The CPU core number\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIf the values in the second column of the \u003Ccode class=\"literal\">/proc/net/softnet_stat\u003C/code> file increment over time, increase the size of the backlog queue:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tDisplay the current backlog queue size:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>sysctl net.core.netdev_max_backlog\u003C/strong>\u003C/span>\nnet.core.netdev_max_backlog = \u003Cspan class=\"emphasis\">\u003Cem>1000\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tCreate the \u003Ccode class=\"literal\">/etc/sysctl.d/10-netdev_max_backlog.conf\u003C/code> file with the following content:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">\u003Cspan class=\"strong strong\">\u003Cstrong>net.core.netdev_max_backlog = \u003Cspan class=\"emphasis\">\u003Cem>2000\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tSet the \u003Ccode class=\"literal\">net.core.netdev_max_backlog\u003C/code> parameter to a double of the current value.\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tLoad the settings from the \u003Ccode class=\"literal\">/etc/sysctl.d/10-netdev_max_backlog.conf\u003C/code> file:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>sysctl -p /etc/sysctl.d/10-netdev_max_backlog.conf\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tMonitor the second column in the \u003Ccode class=\"literal\">/proc/net/softnet_stat\u003C/code> file:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>awk '{for (i=1; i&lt;=NF; i++) printf strtonum(\"0x\" $i) (i==NF?\"\\n\":\" \")}' /proc/net/softnet_stat | column -t\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIf the values still increase, double the \u003Ccode class=\"literal\">net.core.netdev_max_backlog\u003C/code> value again. Repeat this process until the packet drop counters no longer increase.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"increasing-the-transmit-queue-length-of-a-nic-to-reduce-the-number-of-transmit-errors_tuning-network-adapter-settings\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">31.1.3. Increasing the transmit queue length of a NIC to reduce the number of transmit errors\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tThe kernel stores packets in a transmit queue before transmitting them. The default length (1000 packets) is typically sufficient for 10 Gbps, and often also for 40 Gbps networks. However, in faster networks, or if you encounter an increasing number of transmit errors on an adapter, increase the queue length.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tDisplay the current transmit queue length:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ip -s link show \u003Cspan class=\"emphasis\">\u003Cem>enp1s0\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\n\u003Cspan class=\"emphasis\">\u003Cem>2\u003C/em>\u003C/span>: \u003Cspan class=\"emphasis\">\u003Cem>enp1s0\u003C/em>\u003C/span>: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu \u003Cspan class=\"emphasis\">\u003Cem>1500\u003C/em>\u003C/span> qdisc \u003Cspan class=\"emphasis\">\u003Cem>fq_codel\u003C/em>\u003C/span> state \u003Cspan class=\"emphasis\">\u003Cem>UP\u003C/em>\u003C/span> mode \u003Cspan class=\"emphasis\">\u003Cem>DEFAULT\u003C/em>\u003C/span> group \u003Cspan class=\"emphasis\">\u003Cem>default\u003C/em>\u003C/span> qlen \u003Cspan class=\"emphasis\">\u003Cem>1000\u003C/em>\u003C/span>\n...\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIn this example, the transmit queue length (\u003Ccode class=\"literal\">qlen\u003C/code>) of the \u003Ccode class=\"literal\">enp1s0\u003C/code> interface is \u003Ccode class=\"literal\">1000\u003C/code>.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tMonitor the dropped packets counter of a network interface’s software transmit queue:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>tc -s qdisc show dev \u003Cspan class=\"emphasis\">\u003Cem>enp1s0\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\nqdisc \u003Cspan class=\"emphasis\">\u003Cem>fq_codel\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>: \u003Cspan class=\"emphasis\">\u003Cem>root\u003C/em>\u003C/span> refcnt \u003Cspan class=\"emphasis\">\u003Cem>2\u003C/em>\u003C/span> limit \u003Cspan class=\"emphasis\">\u003Cem>10240p\u003C/em>\u003C/span> flows \u003Cspan class=\"emphasis\">\u003Cem>1024\u003C/em>\u003C/span> quantum \u003Cspan class=\"emphasis\">\u003Cem>1514\u003C/em>\u003C/span> target \u003Cspan class=\"emphasis\">\u003Cem>5ms\u003C/em>\u003C/span> interval \u003Cspan class=\"emphasis\">\u003Cem>100ms\u003C/em>\u003C/span> memory_limit \u003Cspan class=\"emphasis\">\u003Cem>32Mb\u003C/em>\u003C/span> ecn drop_batch \u003Cspan class=\"emphasis\">\u003Cem>64\u003C/em>\u003C/span>\n Sent \u003Cspan class=\"emphasis\">\u003Cem>16889923\u003C/em>\u003C/span> bytes \u003Cspan class=\"emphasis\">\u003Cem>426862765\u003C/em>\u003C/span> pkt (dropped \u003Cspan class=\"emphasis\">\u003Cem>191980\u003C/em>\u003C/span>, overlimits \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span> requeues \u003Cspan class=\"emphasis\">\u003Cem>2\u003C/em>\u003C/span>)\n...\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIf you encounter a high or increasing transmit error count, set a higher transmit queue length:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tIdentify the NetworkManager connection profile that uses this interface:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>nmcli connection show\u003C/strong>\u003C/span>\nNAME                UUID                                  TYPE      DEVICE\n\u003Cspan class=\"emphasis\">\u003Cem>Example-Connection\u003C/em>\u003C/span>  \u003Cspan class=\"emphasis\">\u003Cem>a5eb6490-cc20-3668-81f8-0314a27f3f75\u003C/em>\u003C/span>  \u003Cspan class=\"emphasis\">\u003Cem>ethernet\u003C/em>\u003C/span>  \u003Cspan class=\"emphasis\">\u003Cem>enp1s0\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tUpdate the connection profile, and increase the transmit queue length:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>nmcli connection modify \u003Cspan class=\"emphasis\">\u003Cem>Example-Connection\u003C/em>\u003C/span> link.tx-queue-length \u003Cspan class=\"emphasis\">\u003Cem>2000\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tSet the queue length to double of the current value.\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tApply the changes:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>nmcli connection up \u003Cspan class=\"emphasis\">\u003Cem>Example-Connection\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tDisplay the transmit queue length:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ip -s link show \u003Cspan class=\"emphasis\">\u003Cem>enp1s0\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\n\u003Cspan class=\"emphasis\">\u003Cem>2\u003C/em>\u003C/span>: \u003Cspan class=\"emphasis\">\u003Cem>enp1s0\u003C/em>\u003C/span>: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu \u003Cspan class=\"emphasis\">\u003Cem>1500\u003C/em>\u003C/span> qdisc \u003Cspan class=\"emphasis\">\u003Cem>fq_codel\u003C/em>\u003C/span> state \u003Cspan class=\"emphasis\">\u003Cem>UP\u003C/em>\u003C/span> mode \u003Cspan class=\"emphasis\">\u003Cem>DEFAULT\u003C/em>\u003C/span> group \u003Cspan class=\"emphasis\">\u003Cem>default\u003C/em>\u003C/span> qlen \u003Cspan class=\"emphasis\">\u003Cem>2000\u003C/em>\u003C/span>\n...\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tMonitor the dropped packets counter:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>tc -s qdisc show dev \u003Cspan class=\"emphasis\">\u003Cem>enp1s0\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIf the \u003Ccode class=\"literal\">dropped\u003C/code> counter still increases, double the transmit queue length again. Repeat this process until the counter no longer increases.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"section\" id=\"tuning-irq-balancing_tuning-the-network-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">31.2. Tuning IRQ balancing\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tOn multi-core hosts, you can increase the performance by ensuring that Red Hat Enterprise Linux balances interrupt queues (IRQs) to distribute the interrupts across CPU cores.\n\t\t\t\u003C/p>\u003Csection class=\"section\" id=\"interrupts-and-interrupt-handlers_tuning-irq-balancing\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">31.2.1. Interrupts and interrupt handlers\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tWhen a network interface controller (NIC) receives incoming data, it copies the data into kernel buffers by using Direct Memory Access (DMA). The NIC then notifies the kernel about this data by triggering a hard interrupt. These interrupts are processed by interrupt handlers which do minimal work, as they have already interrupted another task and the handlers cannot interrupt themselves. Hard interrupts can be costly in terms of CPU usage, especially if they use kernel locks.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tThe hard interrupt handler then leaves the majority of packet reception to a software interrupt request (SoftIRQ) process. The kernel can schedule these processes more fairly.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"example\" id=\"idm140280134656864\">\u003Cp class=\"title\">\u003Cstrong>Example 31.1. Displaying hardware interrupts\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\t\tThe kernel stores the interrupt counters in the \u003Ccode class=\"literal\">/proc/interrupts\u003C/code> file. To display the counters for a specific NIC, such as \u003Ccode class=\"literal\">enp1s0\u003C/code>, enter:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>egrep \"CPU|\u003Cspan class=\"emphasis\">\u003Cem>enp1s0\u003C/em>\u003C/span>\" /proc/interrupts\u003C/strong>\u003C/span>\n         CPU0     CPU1     CPU2    CPU3    CPU4   CPU5\n \u003Cspan class=\"emphasis\">\u003Cem>105\u003C/em>\u003C/span>:  \u003Cspan class=\"emphasis\">\u003Cem>141606\u003C/em>\u003C/span>        \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>        \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>       \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>       \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>      \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>  \u003Cspan class=\"emphasis\">\u003Cem>IR-PCI-MSI-edge\u003C/em>\u003C/span>      \u003Cspan class=\"emphasis\">\u003Cem>enp1s0-rx-0\u003C/em>\u003C/span>\n \u003Cspan class=\"emphasis\">\u003Cem>106\u003C/em>\u003C/span>:       \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>   \u003Cspan class=\"emphasis\">\u003Cem>141091\u003C/em>\u003C/span>        \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>       \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>       \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>      \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>  \u003Cspan class=\"emphasis\">\u003Cem>IR-PCI-MSI-edge\u003C/em>\u003C/span>      \u003Cspan class=\"emphasis\">\u003Cem>enp1s0-rx-1\u003C/em>\u003C/span>\n \u003Cspan class=\"emphasis\">\u003Cem>107\u003C/em>\u003C/span>:       \u003Cspan class=\"emphasis\">\u003Cem>2\u003C/em>\u003C/span>        \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>   \u003Cspan class=\"emphasis\">\u003Cem>163785\u003C/em>\u003C/span>       \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>       \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>      \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>  \u003Cspan class=\"emphasis\">\u003Cem>IR-PCI-MSI-edge\u003C/em>\u003C/span>      \u003Cspan class=\"emphasis\">\u003Cem>enp1s0-rx-2\u003C/em>\u003C/span>\n \u003Cspan class=\"emphasis\">\u003Cem>108\u003C/em>\u003C/span>:       \u003Cspan class=\"emphasis\">\u003Cem>3\u003C/em>\u003C/span>        \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>        \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>  \u003Cspan class=\"emphasis\">\u003Cem>194370\u003C/em>\u003C/span>       \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>      \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>  \u003Cspan class=\"emphasis\">\u003Cem>IR-PCI-MSI-edge\u003C/em>\u003C/span>      \u003Cspan class=\"emphasis\">\u003Cem>enp1s0-rx-3\u003C/em>\u003C/span>\n \u003Cspan class=\"emphasis\">\u003Cem>109\u003C/em>\u003C/span>:       \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>        \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>        \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>       \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>       \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>      \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>  \u003Cspan class=\"emphasis\">\u003Cem>IR-PCI-MSI-edge\u003C/em>\u003C/span>      \u003Cspan class=\"emphasis\">\u003Cem>enp1s0-tx\u003C/em>\u003C/span>\u003C/pre>\u003Cp>\n\t\t\t\t\t\tEach queue has an interrupt vector in the first column assigned to it. The kernel initializes these vectors when the system boots or when a user loads the NIC driver module. Each receive (\u003Ccode class=\"literal\">RX\u003C/code>) and transmit (\u003Ccode class=\"literal\">TX\u003C/code>) queue is assigned a unique vector that informs the interrupt handler which NIC or queue the interrupt is coming from. The columns represent the number of incoming interrupts for every CPU core.\n\t\t\t\t\t\u003C/p>\u003C/div>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"software-interrupt-requests_tuning-irq-balancing\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">31.2.2. Software interrupt requests\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tSoftware interrupt requests (SoftIRQs) clear the receive ring buffers of network adapters. The kernel schedules SoftIRQ routines to run at a time when other tasks will not be interrupted. On Red Hat Enterprise Linux, processes named \u003Ccode class=\"literal\">ksoftirqd/\u003Cspan class=\"emphasis\">\u003Cem>cpu-number\u003C/em>\u003C/span>\u003C/code> run these routines and call driver-specific code functions.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tTo monitor the SoftIRQ counters for each CPU core, enter:\n\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>watch -n1 'egrep \"CPU|NET_RX|NET_TX\" /proc/softirqs'\u003C/strong>\u003C/span>\n                    CPU0       CPU1\t  CPU2       CPU3\tCPU4\t   CPU5       CPU6\t CPU7\n      NET_TX:\t   49672      52610\t 28175      97288      12633\t  19843      18746     220689\n      NET_RX:         96       1615        789         46         31\t   1735       1315     470798\u003C/pre>\u003Cp>\n\t\t\t\t\tThe command dynamically updates the output. Press \u003Ckbd class=\"keycap\">Ctrl\u003C/kbd>+\u003Ckbd class=\"keycap\">C\u003C/kbd> to interrupt the output.\n\t\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"napi-polling_tuning-irq-balancing\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">31.2.3. NAPI Polling\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tNew API (NAPI) is an extension to the device driver packet processing framework to improve the efficiency of incoming network packets. Hard interrupts are expensive because they usually cause a context switch from the kernel space to the user space and back again, and cannot interrupt themselves. Even with interrupt coalescence, the interrupt handler monopolizes a CPU core completely. With NAPI, the driver can use a polling mode instead of being hard-interrupted by the kernel for every packet that is received.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tUnder normal operation, the kernel issues an initial hard interrupt, followed by a soft interrupt request (SoftIRQ) handler that polls the network card using NAPI routines. To prevent SoftIRQs from monopolizing a CPU core, the polling routine has a budget that determines the CPU time the SoftIRQ can consume. On completion of the SoftIRQ poll routine, the kernel exits the routine and schedules it to run again at a later time to repeat the process of receiving packets from the network card.\n\t\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"the-irqbalance-service_tuning-irq-balancing\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">31.2.4. The irqbalance service\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tOn systems both with and without Non-Uniform Memory Access (NUMA) architecture, the \u003Ccode class=\"literal\">irqbalance\u003C/code> service balances interrupts effectively across CPU cores, based on system conditions. The \u003Ccode class=\"literal\">irqbalance\u003C/code> service runs in the background and monitors the CPU load every 10 seconds. The service moves interrupts to other CPU cores when a CPU’s load is too high. As a result, the system performs well and handles load more efficiently.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tIf \u003Ccode class=\"literal\">irqbalance\u003C/code> is not running, usually the CPU core 0 handles most of the interrupts. Even at moderate load, this CPU core can become busy trying to handle the workload of all the hardware in the system. As a consequence, interrupts or interrupt-based work can be missed or delayed. This can result in low network and storage performance, packet loss, and potentially other issues.\n\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\tDisabling \u003Ccode class=\"literal\">irqbalance\u003C/code> can negatively impact the network throughput.\n\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cp>\n\t\t\t\t\tOn systems with only a single CPU core, the \u003Ccode class=\"literal\">irqbalance\u003C/code> service provides no benefit and exits on its own.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tBy default, the \u003Ccode class=\"literal\">irqbalance\u003C/code> service is enabled and running on Red Hat Enterprise Linux. To re-enable the service if you disabled it, enter:\n\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl enable --now irqbalance\u003C/strong>\u003C/span>\u003C/pre>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/solutions/41535\">Do we need irqbalance?\u003C/a> (Red Hat Knowledgebase)\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/solutions/4367191\">How should I configure network interface IRQ channels?\u003C/a> (Red Hat Knowledgebase)\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"increasing-the-time-softirqs-can-run-on-the-cpu_tuning-irq-balancing\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">31.2.5. Increasing the time SoftIRQs can run on the CPU\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tIf SoftIRQs do not run long enough, the rate of incoming data could exceed the kernel’s capability to drain the buffer fast enough. As a result, the network interface controller (NIC) buffers overflow and packets are lost.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tIf \u003Ccode class=\"literal\">softirqd\u003C/code> processes could not retrieve all packets from interfaces in one NAPI polling cycle, it is an indicator that the SoftIRQs do not have enough CPU time. This could be the case on hosts with fast NICs, such as 10 Gbps and faster. If you increase the values of the \u003Ccode class=\"literal\">net.core.netdev_budget\u003C/code> and \u003Ccode class=\"literal\">net.core.netdev_budget_usecs\u003C/code> kernel parameters, you can control the time and number of packets \u003Ccode class=\"literal\">softirqd\u003C/code> can process in a polling cycle.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tTo determine whether tuning the \u003Ccode class=\"literal\">net.core.netdev_budget\u003C/code> parameter is needed, display the counters in the \u003Ccode class=\"literal\">/proc/net/softnet_stat\u003C/code> file:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>awk '{for (i=1; i&lt;=NF; i++) printf strtonum(\"0x\" $i) (i==NF?\"\\n\":\" \")}' /proc/net/softnet_stat | column -t\u003C/strong>\u003C/span>\n221951548  0  0      0  0  0  0  0  0  0  0  0  0\n192058677  0  20380  0  0  0  0  0  0  0  0  0  1\n455324886  0  0      0  0  0  0  0  0  0  0  0  2\n...\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThis \u003Ccode class=\"literal\">awk\u003C/code> command converts the values in \u003Ccode class=\"literal\">/proc/net/softnet_stat\u003C/code> from hexadecimal to decimal format and displays them in the table format. Each line represents a CPU core starting with core 0.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe relevant columns are:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tFirst column: The total number of received frames.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tThird column: The number times \u003Ccode class=\"literal\">softirqd\u003C/code> processes that could not retrieve all packets from interfaces in one NAPI polling cycle.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tLast column: The CPU core number.\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIf the counters in the third column of the \u003Ccode class=\"literal\">/proc/net/softnet_stat\u003C/code> file increment over time, tune the system:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tDisplay the current values of the \u003Ccode class=\"literal\">net.core.netdev_budget_usecs\u003C/code> and \u003Ccode class=\"literal\">net.core.netdev_budget\u003C/code> parameters:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>sysctl net.core.netdev_budget_usecs net.core.netdev_budget\u003C/strong>\u003C/span>\nnet.core.netdev_budget_usecs = 2000\nnet.core.netdev_budget = 300\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tWith these settings, \u003Ccode class=\"literal\">softirqd\u003C/code> processes have up to 2000 microseconds to process up to 300 messages from the NIC in one polling cycle. Polling ends based on which condition is met first.\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tCreate the \u003Ccode class=\"literal\">/etc/sysctl.d/10-netdev_budget.conf\u003C/code> file with the following content:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">\u003Cspan class=\"strong strong\">\u003Cstrong>net.core.netdev_budget = \u003Cspan class=\"emphasis\">\u003Cem>600\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\n\u003Cspan class=\"strong strong\">\u003Cstrong>net.core.netdev_budget_usecs = 4000\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tSet the parameters to a double of their current values.\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tLoad the settings from the \u003Ccode class=\"literal\">/etc/sysctl.d/10-netdev_budget.conf\u003C/code> file:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>sysctl -p /etc/sysctl.d/10-netdev_budget.conf\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tMonitor the third column in the \u003Ccode class=\"literal\">/proc/net/softnet_stat\u003C/code> file:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>awk '{for (i=1; i&lt;=NF; i++) printf strtonum(\"0x\" $i) (i==NF?\"\\n\":\" \")}' /proc/net/softnet_stat | column -t\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIf the values still increase, set \u003Ccode class=\"literal\">net.core.netdev_budget_usecs\u003C/code> and \u003Ccode class=\"literal\">net.core.netdev_budget\u003C/code> to higher values. Repeat this process until the counters no longer increase.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"section\" id=\"improving-the-network-latency_tuning-the-network-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">31.3. Improving the network latency\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tCPU power management features can cause unwanted delays in time-sensitive application processing. You can disable some or all of these power management features to improve the network latency.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tFor example, if the latency is higher when the server is idle than under heavy load, CPU power management settings could influence the latency.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tDisabling CPU power management features can cause a higher power consumption and heat loss.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Csection class=\"section\" id=\"how-the-cpu-power-states-influence-the-network-latency_improving-the-network-latency\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">31.3.1. How the CPU power states influence the network latency\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tThe consumption state (C-states) of CPUs optimize and reduce the power consumption of computers. The C-states are numbered, starting at C0. In C0, the processor is fully powered and executing. In C1, the processor is fully powered but not executing. The higher the number of the C-state, the more components the CPU turns off.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tWhenever a CPU core is idle, the built-in power saving logic steps in and attempts to move the core from the current C-state to a higher one by turning off various processor components. If the CPU core must process data, Red Hat Enterprise Linux (RHEL) sends an interrupt to the processor to wake up the core and set its C-state back to C0.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tMoving out of deep C-states back to C0 takes time due to turning power back on to various components of the processor. On multi-core systems, it can also happen that many of the cores are simultaneously idle and, therefore, in deeper C-states. If RHEL tries to wake them up at the same time, the kernel can generate a large number of Inter-Processor Interrupts (IPIs) while all cores return from deep C-states. Due to locking that is required while processing interrupts, the system can then stall for some time while handling all the interrupts. This can result in large delays in the application response to events.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"example\" id=\"idm140280132957856\">\u003Cp class=\"title\">\u003Cstrong>Example 31.2. Displaying times in C-state per core\u003C/strong>\u003C/p>\u003Cdiv class=\"example-contents\">\u003Cp>\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">Idle Stats\u003C/code> page in the PowerTOP application displays how much time the CPU cores spend in each C-state:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">           Pkg(HW)  |            Core(HW) |            CPU(OS) 0   CPU(OS) 4\n                    |                     | C0 active   2.5%        2.2%\n                    |                     | POLL        0.0%    0.0 ms  0.0%    0.1 ms\n                    |                     | C1          0.1%    0.2 ms  0.0%    0.1 ms\nC2 (pc2)   63.7%    |                     |\nC3 (pc3)    0.0%    | C3 (cc3)    0.1%    | C3          0.1%    0.1 ms  0.1%    0.1 ms\nC6 (pc6)    0.0%    | C6 (cc6)    8.3%    | C6          5.2%    0.6 ms  6.0%    0.6 ms\nC7 (pc7)    0.0%    | C7 (cc7)   76.6%    | C7s         0.0%    0.0 ms  0.0%    0.0 ms\nC8 (pc8)    0.0%    |                     | C8          6.3%    0.9 ms  5.8%    0.8 ms\nC9 (pc9)    0.0%    |                     | C9          0.4%    3.7 ms  2.2%    2.2 ms\nC10 (pc10)  0.0%    |                     |\n                    |                     | C10        80.8%    3.7 ms 79.4%    4.4 ms\n                    |                     | C1E         0.1%    0.1 ms  0.1%    0.1 ms\n...\u003C/pre>\u003C/div>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/managing-power-consumption-with-powertop_monitoring-and-managing-system-status-and-performance\">Managing power consumption with PowerTOP\u003C/a>\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"c-state-settings-in-the-efi-firmware_improving-the-network-latency\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">31.3.2. C-state settings in the EFI firmware\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tIn most systems with an EFI firmware, you can enable and disable the individual consumption states (C-states). However, on Red Hat Enterprise Linux (RHEL), the idle driver determines whether the kernel uses the settings from the firmware:\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ccode class=\"literal\">intel_idle\u003C/code>: This is the default driver on hosts with an Intel CPU and ignores the C-state settings from the EFI firmware.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ccode class=\"literal\">acpi_idle\u003C/code>: RHEL uses this driver on hosts with CPUs from vendors other than Intel and if \u003Ccode class=\"literal\">intel_idle\u003C/code> is disabled. By default, the \u003Ccode class=\"literal\">acpi_idle\u003C/code> driver uses the C-state settings from the EFI firmware.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/doc/kernel-doc-\u003Cspan class=\"emphasis\">\u003Cem>&lt;version&gt;\u003C/em>\u003C/span>/Documentation/admin-guide/pm/cpuidle.rst\u003C/code> provided by the \u003Ccode class=\"literal\">kernel-doc\u003C/code> package\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"disabling-c-states-by-using-a-custom-tuned-profile_improving-the-network-latency\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">31.3.3. Disabling C-states by using a custom TuneD profile\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tThe TuneD service uses the Power Management Quality of Service (\u003Ccode class=\"literal\">PMQOS\u003C/code>) interface of the kernel to set consumption states (C-states) locking. The kernel idle driver can communicate with this interface to dynamically limit the C-states. This prevents that administrators must hard code a maximum C-state value by using kernel command line parameters.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">tuned\u003C/code> package is installed.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">tuned\u003C/code> service is enabled and running.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tDisplay the active profile:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>tuned-adm active\u003C/strong>\u003C/span>\nCurrent active profile: \u003Cspan class=\"emphasis\">\u003Cem>network-latency\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tCreate a directory for the custom TuneD profile:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>mkdir /etc/tuned/\u003Cspan class=\"emphasis\">\u003Cem>network-latency-custom\u003C/em>\u003C/span>/\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tCreate the \u003Ccode class=\"literal\">/etc/tuned/\u003Cspan class=\"emphasis\">\u003Cem>network-latency-custom\u003C/em>\u003C/span>/tuned.conf\u003C/code> file with the following content:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">[main]\ninclude=\u003Cspan class=\"emphasis\">\u003Cem>network-latency\u003C/em>\u003C/span>\n\n[cpu]\nforce_latency=\u003Cspan class=\"emphasis\">\u003Cem>cstate.id:1|2\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThis custom profile inherits all settings from the \u003Ccode class=\"literal\">network-latency\u003C/code> profile. The \u003Ccode class=\"literal\">force_latency\u003C/code> TuneD parameter specifies the latency in microseconds (µs). If the C-state latency is higher than the specified value, the idle driver in Red Hat Enterprise Linux prevents the CPU from moving to a higher C-state. With \u003Ccode class=\"literal\">force_latency=cstate.id:1|2\u003C/code>, TuneD first checks if the \u003Ccode class=\"literal\">/sys/devices/system/cpu/cpu_&lt;number&gt;_/cpuidle/state_&lt;cstate.id&gt;_/\u003C/code> directory exists. In this case, TuneD reads the latency value from the \u003Ccode class=\"literal\">latency\u003C/code> file in this directory. If the directory does not exist, TuneD uses 2 microseconds as a fallback value.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tActivate the \u003Ccode class=\"literal\">\u003Cspan class=\"emphasis\">\u003Cem>network-latency-custom\u003C/em>\u003C/span>\u003C/code> profile:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>tuned-adm profile \u003Cspan class=\"emphasis\">\u003Cem>network-latency-custom\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"#getting-started-with-tuned_monitoring-and-managing-system-status-and-performance\" title=\"Chapter 1. Getting started with TuneD\">Getting started with TuneD\u003C/a>\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"#customizing-tuned-profiles_monitoring-and-managing-system-status-and-performance\" title=\"Chapter 2. Customizing TuneD profiles\">Customizing TuneD profiles\u003C/a>\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"disabling-c-states-by-using-a-kernel-command-line-option_improving-the-network-latency\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">31.3.4. Disabling C-states by using a kernel command line option\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tThe \u003Ccode class=\"literal\">processor.max_cstate\u003C/code> and \u003Ccode class=\"literal\">intel_idle.max_cstat\u003C/code> kernel command line parameters configure the maximum consumption states (C-state) CPU cores can use. For example, setting the parameters to \u003Ccode class=\"literal\">1\u003C/code> ensures that the CPU will never request a C-state below C1.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tUse this method to test whether the latency of applications on a host are being affected by C-states. To not hard code a specific state, consider using a more dynamic solution. See \u003Ca class=\"link\" href=\"#disabling-c-states-by-using-a-custom-tuned-profile_improving-the-network-latency\" title=\"31.3.3. Disabling C-states by using a custom TuneD profile\">Disabling C-states by using a custom TuneD profile\u003C/a>.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">tuned\u003C/code> service is not running or configured to not update C-state settings.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tDisplay the idle driver the system uses:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>cat /sys/devices/system/cpu/cpuidle/current_driver\u003C/strong>\u003C/span>\n\u003Cspan class=\"emphasis\">\u003Cem>intel_idle\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIf the host uses the \u003Ccode class=\"literal\">intel_idle\u003C/code> driver, set the \u003Ccode class=\"literal\">intel_idle.max_cstate\u003C/code> kernel parameter to define the highest C-state that CPU cores should be able to use:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>grubby --update-kernel=ALL --args=\"intel_idle.max_cstate=\u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>\"\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tSetting \u003Ccode class=\"literal\">intel_idle.max_cstate=0\u003C/code> disables the \u003Ccode class=\"literal\">intel_idle\u003C/code> driver. Consequently, the kernel uses the \u003Ccode class=\"literal\">acpi_idle\u003C/code> driver that uses the C-state values set in the EFI firmware. For this reason, also set \u003Ccode class=\"literal\">processor.max_cstate\u003C/code> to override these C-state settings.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tOn every host, independent from the CPU vendor, set the highest C-state that CPU cores should be able to use:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>grubby --update-kernel=ALL --args=\"processor.max_cstate=\u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>\"\u003C/strong>\u003C/span>\u003C/pre>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\t\tIf you set \u003Ccode class=\"literal\">processor.max_cstate=0\u003C/code> in addition to \u003Ccode class=\"literal\">intel_idle.max_cstate=0\u003C/code>, the \u003Ccode class=\"literal\">acpi_idle\u003C/code> driver overrides the value of \u003Ccode class=\"literal\">processor.max_cstate\u003C/code> and sets it to \u003Ccode class=\"literal\">1\u003C/code>. As a result, with \u003Ccode class=\"literal\">processor.max_cstate=0 intel_idle.max_cstate=0\u003C/code>, the highest C-state the kernel will use is C1, not C0.\n\t\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tRestart the host for the changes to take effect:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>reboot\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tDisplay the maximum C-state:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>cat /sys/module/processor/parameters/max_cstate\u003C/strong>\u003C/span>\n1\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIf the host uses the \u003Ccode class=\"literal\">intel_idle\u003C/code> driver, display the maximum C-state:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>cat /sys/module/intel_idle/parameters/max_cstate\u003C/strong>\u003C/span>\n0\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/solutions/202743\">What are CPU \"C-states\" and how to disable them if needed?\u003C/a> (Red Hat Knowledgebase)\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/doc/kernel-doc-\u003Cspan class=\"emphasis\">\u003Cem>&lt;version&gt;\u003C/em>\u003C/span>/Documentation/admin-guide/pm/cpuidle.rst\u003C/code> provided by the \u003Ccode class=\"literal\">kernel-doc\u003C/code> package\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"section\" id=\"improving-the-throughput-of-large-amounts-of-contiguous-data-streams_tuning-the-network-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">31.4. Improving the throughput of large amounts of contiguous data streams\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tAccording to the IEEE 802.3 standard, a default Ethernet frame without Virtual Local Area Network (VLAN) tag has a maximum size of 1518 bytes. Each of these frames includes an 18 bytes header, leaving 1500 bytes for payload. Consequently, for every 1500 bytes of data the server transmits over the network, 18 bytes (1.2%) Ethernet frame header are overhead and transmitted as well. Headers from layer 3 and 4 protocols increase the overhead per packet further.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tConsider employing jumbo frames to save overhead if hosts on your network often send numerous contiguous data streams, such as backup servers or file servers hosting numerous huge files. Jumbo frames are non-standardized frames that have a larger Maximum Transmission Unit (MTU) than the standard Ethernet payload size of 1500 bytes. For example, if you configure jumbo frames with the maximum allowed MTU of 9000 bytes payload, the overhead of each frame reduces to 0.2%.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tDepending on the network and services, it can be beneficial to enable jumbo frames only in specific parts of a network, such as the storage backend of a cluster. This avoids packet fragmentation.\n\t\t\t\u003C/p>\u003Csection class=\"section\" id=\"considerations-before-configuring-jumbo-frames_improving-the-throughput-of-large-amounts-of-contiguous-data-streams\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">31.4.1. Considerations before configuring jumbo frames\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tDepending on your hardware, applications, and services in your network, jumbo frames can have different impacts. Decide carefully whether enabling jumbo frames provides a benefit in your scenario.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"formalpara\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cp>\n\t\t\t\t\t\tAll network devices on the transmission path must support jumbo frames and use the same Maximum Transmission Unit (MTU) size. In the opposite case, you can face the following problems:\n\t\t\t\t\t\u003C/p>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tDropped packets.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tHigher latency due to fragmented packets.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tIncreased risk of packet loss caused by fragmentation. For example, if a router fragments a single 9000-bytes frame into six 1500-bytes frames, and any of those 1500-byte frames are lost, the whole frame is lost because it cannot be reassembled.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\t\tIn the following diagram, all hosts in the three subnets must use the same MTU if a host from network A sends a packet to a host in network C:\n\t\t\t\t\u003C/p>\u003Cdiv class=\"informalfigure\">\u003Cdiv class=\"mediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/2418569b01b0a8c1dce179bfba831708/network-diagram-MTU.png\" alt=\"network diagram MTU\"/>\u003C/div>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Benefits of jumbo frames\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tHigher throughput: Each frame contains more user data while the protocol overhead is fixed.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tLower CPU utilization: Jumbo frames cause fewer interrupts and, therefore, save CPU cycles.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Drawbacks of jumbo frames\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tHigher latency: Larger frames delay packets that follow.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tIncreased memory buffer usage: Larger frames can fill buffer queue memory more quickly.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"configuring-the-mtu-in-an-existing-networkmanager-connection-profile_improving-the-throughput-of-large-amounts-of-contiguous-data-streams\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">31.4.2. Configuring the MTU in an existing NetworkManager connection profile\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tIf your network requires a different Maximum Transmission Unit (MTU) than the default, you can configure this setting in the corresponding NetworkManager connection profile.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tJumbo frames are network packets with a payload of between 1500 and 9000 bytes. All devices in the same broadcast domain have to support those frames.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tAll devices in the broadcast domain use the same MTU.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tYou know the MTU of the network.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tYou already configured a connection profile for the network with the divergent MTU.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tOptional: Display the current MTU:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ip link show\u003C/strong>\u003C/span>\n...\n3: enp1s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu \u003Cspan class=\"strong strong\">\u003Cstrong>1500\u003C/strong>\u003C/span> qdisc fq_codel state UP mode DEFAULT group default qlen 1000\n    link/ether 52:54:00:74:79:56 brd ff:ff:ff:ff:ff:ff\n...\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tOptional: Display the NetworkManager connection profiles:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>nmcli connection show\u003C/strong>\u003C/span>\nNAME     UUID                                  TYPE      DEVICE\n\u003Cspan class=\"emphasis\">\u003Cem>Example\u003C/em>\u003C/span>  \u003Cspan class=\"emphasis\">\u003Cem>f2f33f29-bb5c-3a07-9069-be72eaec3ecf\u003C/em>\u003C/span>  ethernet  \u003Cspan class=\"emphasis\">\u003Cem>enp1s0\u003C/em>\u003C/span>\n...\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tSet the MTU in the profile that manages the connection to the network with the divergent MTU:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>nmcli connection modify \u003Cspan class=\"emphasis\">\u003Cem>Example\u003C/em>\u003C/span> mtu \u003Cspan class=\"emphasis\">\u003Cem>9000\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tReactivate the connection:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>nmcli connection up \u003Cspan class=\"emphasis\">\u003Cem>Example\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tDisplay the MTU setting:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ip link show\u003C/strong>\u003C/span>\n...\n3: enp1s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu \u003Cspan class=\"strong strong\">\u003Cstrong>9000\u003C/strong>\u003C/span> qdisc fq_codel state UP mode DEFAULT group default qlen 1000\n    link/ether 52:54:00:74:79:56 brd ff:ff:ff:ff:ff:ff\n...\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tVerify that no host on the transmission paths fragments the packets:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tOn the receiver side, display the IP reassembly statistics of the kernel:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>nstat -az IpReasm\u003C/strong>\u003C/span>*\n#kernel\nIpReasmTimeout 0 0.0\nIpReasmReqds 0 0.0\nIpReasmOKs 0 0.0\nIpReasmFails 0 0.0\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tIf the counters return \u003Ccode class=\"literal\">0\u003C/code>, packets were not reassembled.\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tOn the sender side, transmit an ICMP request with the prohibit-fragmentation-bit:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ping -c1 -Mdo -s \u003Cspan class=\"emphasis\">\u003Cem>8972\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>destination_host\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tIf the command succeeds, the packet was not fragmented.\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tCalculate the value for the \u003Ccode class=\"literal\">-s\u003C/code> packet size option as follows: MTU size - 8 bytes ICMP header - 20 bytes IPv4 header = packet size\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"section\" id=\"tuning-tcp-connections-for-high-throughput_tuning-the-network-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">31.5. Tuning TCP connections for high throughput\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tTune TCP-related settings on Red Hat Enterprise Linux to increase the throughput, reduce the latency, or prevent problems, such as packet loss.\n\t\t\t\u003C/p>\u003Csection class=\"section\" id=\"testing-the-tcp-throughput-using-iperf3_tuning-tcp-connections-for-high-throughput\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">31.5.1. Testing the TCP throughput using iperf3\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tThe \u003Ccode class=\"literal\">iperf3\u003C/code> utility provides a server and client mode to perform network throughput tests between two hosts.\n\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\tThe throughput of applications depends on many factors, such as the buffer sizes that the application uses. Therefore, the results measured with testing utilities, such as \u003Ccode class=\"literal\">iperf3\u003C/code>, can be significantly different from those of applications on a server under production workload.\n\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">iperf3\u003C/code> package is installed on both the client and server.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tNo other services on either host cause network traffic that substantially affects the test result.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tFor 40 Gbps and faster connections, the network card supports Accelerated Receive Flow Steering (ARFS) and the feature is enabled on the interface.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tOptional: Display the maximum network speed of the network interface controller (NIC) on both the server and client:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ethtool enp1s0 | grep \"Speed\"\u003C/strong>\u003C/span>\n   Speed: 100000Mb/s\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tOn the server:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tTemporarily open the default \u003Ccode class=\"literal\">iperf3\u003C/code> TCP port 5201 in the \u003Ccode class=\"literal\">firewalld\u003C/code> service:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>firewall-cmd --add-port=5201/tcp\u003C/strong>\u003C/span>\n# \u003Cspan class=\"strong strong\">\u003Cstrong>firewall-cmd --reload\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tStart \u003Ccode class=\"literal\">iperf3\u003C/code> in server mode:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>iperf3 --server\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tThe service now is waiting for incoming client connections.\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tOn the client:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tStart measuring the throughput:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>iperf3 --time \u003Cspan class=\"emphasis\">\u003Cem>60\u003C/em>\u003C/span> --zerocopy --client \u003Cspan class=\"emphasis\">\u003Cem>192.0.2.1\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">--time \u003Cspan class=\"emphasis\">\u003Cem>&lt;seconds&gt;\u003C/em>\u003C/span>\u003C/code>: Defines the time in seconds when the client stops the transmission.\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\t\tSet this parameter to a value that you expect to work and increase it in later measurements. If the server sends packets at a faster rate than the devices on the transmit path or the client can process, packets can be dropped.\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">--zerocopy\u003C/code>: Enables a zero copy method instead of using the \u003Ccode class=\"literal\">write()\u003C/code> system call. You require this option only if you want to simulate a zero-copy-capable application or to reach 40 Gbps and more on a single stream.\n\t\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">--client &lt;server&gt;\u003C/code>: Enables the client mode and sets the IP address or name of the server that runs the \u003Ccode class=\"literal\">iperf3\u003C/code> server.\n\t\t\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tWait until \u003Ccode class=\"literal\">iperf3\u003C/code> completes the test. Both the server and the client display statistics every second and a summary at the end. For example, the following is a summary displayed on a client:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">[ ID] Interval         Transfer    Bitrate         Retr\n[  5] 0.00-60.00  sec  101 GBytes   14.4 Gbits/sec   0   sender\n[  5] 0.00-60.04  sec  101 GBytes   14.4 Gbits/sec       receiver\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIn this example, the average bitrate was 14.4 Gbps.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tOn the server:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tPress \u003Ckbd class=\"keycap\">Ctrl\u003C/kbd>+\u003Ckbd class=\"keycap\">C\u003C/kbd> to stop the \u003Ccode class=\"literal\">iperf3\u003C/code> server.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tClose the TCP port 5201 in \u003Ccode class=\"literal\">firewalld\u003C/code>:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>firewall-cmd --remove-port=5201/tcp\u003C/strong>\u003C/span>\n# \u003Cspan class=\"strong strong\">\u003Cstrong>firewall-cmd --reload\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ccode class=\"literal\">iperf3(1)\u003C/code> man page on your system\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"the-system-wide-tcp-socket-buffer-settings_tuning-tcp-connections-for-high-throughput\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">31.5.2. The system-wide TCP socket buffer settings\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tSocket buffers temporarily store data that the kernel has received or should send:\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe read socket buffer holds packets that the kernel has received but which the application has not read yet.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe write socket buffer holds packets that an application has written to the buffer but which the kernel has not passed to the IP stack and network driver yet.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\t\tIf a TCP packet is too large and exceeds the buffer size or packets are sent or received at a too fast rate, the kernel drops any new incoming TCP packet until the data is removed from the buffer. In this case, increasing the socket buffers can prevent packet loss.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tBoth the \u003Ccode class=\"literal\">net.ipv4.tcp_rmem\u003C/code> (read) and \u003Ccode class=\"literal\">net.ipv4.tcp_wmem\u003C/code> (write) socket buffer kernel settings contain three values:\n\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">net.ipv4.tcp_rmem = 4096  131072  6291456\nnet.ipv4.tcp_wmem = 4096  16384   4194304\u003C/pre>\u003Cp>\n\t\t\t\t\tThe displayed values are in bytes and Red Hat Enterprise Linux uses them in the following way:\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe first value is the minimum buffer size. New sockets cannot have a smaller size.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe second value is the default buffer size. If an application sets no buffer size, this is the default value.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe third value is the maximum size of automatically tuned buffers. Using the \u003Ccode class=\"literal\">setsockopt()\u003C/code> function with the \u003Ccode class=\"literal\">SO_SNDBUF\u003C/code> socket option in an application disables this maximum buffer size.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\t\tNote that the \u003Ccode class=\"literal\">net.ipv4.tcp_rmem\u003C/code> and \u003Ccode class=\"literal\">net.ipv4.tcp_wmem\u003C/code> parameters set the socket sizes for both the IPv4 and IPv6 protocols.\n\t\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"increasing-the-system-wide-tcp-socket-buffers_tuning-tcp-connections-for-high-throughput\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">31.5.3. Increasing the system-wide TCP socket buffers\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tThe system-wide TCP socket buffers temporarily store data that the kernel has received or should send. Both \u003Ccode class=\"literal\">net.ipv4.tcp_rmem\u003C/code> (read) and \u003Ccode class=\"literal\">net.ipv4.tcp_wmem\u003C/code> (write) socket buffer kernel settings each contain three settings: A minimum, default, and maximum value.\n\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\tSetting too large buffer sizes wastes memory. Each socket can be set to the size that the application requests, and the kernel doubles this value. For example, if an application requests a 256 KiB socket buffer size and opens 1 million sockets, the system can use up to 512 GB RAM (512 KiB x 1 million) only for the potential socket buffer space.\n\t\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\t\tAdditionally, a too large value for the maximum buffer size can increase the latency.\n\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tYou encountered a significant rate of dropped TCP packets.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tDetermine the latency of the connection. For example, ping from the client to server to measure the average Round Trip Time (RTT):\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ping -c \u003Cspan class=\"emphasis\">\u003Cem>10\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>server.example.com\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\n...\n--- \u003Cspan class=\"emphasis\">\u003Cem>server.example.com\u003C/em>\u003C/span> ping statistics ---\n\u003Cspan class=\"emphasis\">\u003Cem>10\u003C/em>\u003C/span> packets transmitted, \u003Cspan class=\"emphasis\">\u003Cem>10\u003C/em>\u003C/span> received, \u003Cspan class=\"emphasis\">\u003Cem>0%\u003C/em>\u003C/span> packet loss, time \u003Cspan class=\"emphasis\">\u003Cem>9014ms\u003C/em>\u003C/span>\nrtt min/avg/max/mdev = \u003Cspan class=\"emphasis\">\u003Cem>117.208\u003C/em>\u003C/span>/\u003Cspan class=\"strong strong\">\u003Cstrong>\u003Cspan class=\"emphasis\">\u003Cem>117.056\u003C/em>\u003C/span>\u003C/strong>\u003C/span>/\u003Cspan class=\"emphasis\">\u003Cem>119.333\u003C/em>\u003C/span>/\u003Cspan class=\"emphasis\">\u003Cem>0.616\u003C/em>\u003C/span> ms\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIn this example, the latency is 117 ms.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tUse the following formula to calculate the Bandwidth Delay Product (BDP) for the traffic you want to tune:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">connection speed in bytes * latency in ms = BDP in bytes\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFor example, to calculate the BDP for a 10 Gbps connection that has a 117 ms latency:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">(10 * 1000 * 1000 * 1000 / 8) * 117 = 10683760 bytes\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tCreate the \u003Ccode class=\"literal\">/etc/sysctl.d/10-tcp-socket-buffers.conf\u003C/code> file and either set the maximum read or write buffer size, or both, based on your requirements:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">\u003Cspan class=\"strong strong\">\u003Cstrong>net.ipv4.tcp_rmem = \u003Cspan class=\"emphasis\">\u003Cem>4096\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>262144\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>21367520\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\n\u003Cspan class=\"strong strong\">\u003Cstrong>net.ipv4.tcp_wmem = \u003Cspan class=\"emphasis\">\u003Cem>4096\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>24576\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>21367520\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tSpecify the values in bytes. Use the following rule of thumb when you try to identify optimized values for your environment:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tDefault buffer size (second value): Increase this value only slightly or set it to \u003Ccode class=\"literal\">524288\u003C/code> (512 KiB) at most. A too high default buffer size can cause buffer collapsing and, consequently, latency spikes.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tMaximum buffer size (third value): A value double to triple of the BDP is often sufficient.\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tLoad the settings from the \u003Ccode class=\"literal\">/etc/sysctl.d/10-tcp-socket-buffers.conf\u003C/code> file:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>sysctl -p /etc/sysctl.d/\u003Cspan class=\"emphasis\">\u003Cem>10-tcp-socket-buffers.conf\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tConfigure your applications to use a larger socket buffer size. The third value in the \u003Ccode class=\"literal\">net.ipv4.tcp_rmem\u003C/code> and \u003Ccode class=\"literal\">net.ipv4.tcp_wmem\u003C/code> parameters defines the maximum buffer size that the \u003Ccode class=\"literal\">setsockopt()\u003C/code> function in an application can request.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFor further details, see the documentation of the programming language of your application. If you are not the developer of the application, contact the developer.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIf you have changed the second value in the \u003Ccode class=\"literal\">net.ipv4.tcp_rmem\u003C/code> or \u003Ccode class=\"literal\">net.ipv4.tcp_wmem\u003C/code> parameter, restart the applications to use the new TCP buffer sizes.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIf you have changed only the third value, you do not need to restart the application because auto-tuning applies these settings dynamically.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tOptional: \u003Ca class=\"link\" href=\"#testing-the-tcp-throughput-using-iperf3_tuning-tcp-connections-for-high-throughput\" title=\"31.5.1. Testing the TCP throughput using iperf3\">Test the TCP throughput using iperf3\u003C/a>.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tMonitor the packet drop statistics using the same method that you used when you encountered the packet drops.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIf packet drops still occur but at a lower rate, increase the buffer sizes further.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/solutions/85913\">What are the implications of changing socket buffer sizes?\u003C/a> (Red Hat Knowledgebase)\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ccode class=\"literal\">tcp(7)\u003C/code> and \u003Ccode class=\"literal\">socket(7)\u003C/code> man pages on your system\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"tcp-window-scaling_tuning-tcp-connections-for-high-throughput\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">31.5.4. TCP Window Scaling\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tThe TCP Window Scaling feature, which is enabled by default in Red Hat Enterprise Linux, is an extension of the TCP protocol that significantly improves the throughput.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tFor example, on a 1 Gbps connection with 1.5 ms Round Trip Time (RTT):\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tWith TCP Window Scaling enabled, approximately 630 Mbps are realistic.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tWith TCP Window Scaling disabled, the throughput goes down to 380 Mbps.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\t\tOne of the features TCP provides is flow control. With flow control, a sender can send as much data as the receiver can receive, but no more. To achieve this, the receiver advertises a \u003Ccode class=\"literal\">window\u003C/code> value, which is the amount of data a sender can send.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tTCP originally supported window sizes up to 64 KiB, but at high Bandwidth Delay Products (BDP), this value becomes a restriction because the sender cannot send more than 64 KiB at a time. High-speed connections can transfer much more than 64 KiB of data at a given time. For example, a 10 Gbps link with 1 ms of latency between systems can have more than 1 MiB of data in transit at a given time. It would be inefficient if a host sends only 64 KiB, then pauses until the other host receives that 64 KiB.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tTo remove this bottleneck, the TCP Window Scaling extension allows the TCP window value to be arithmetically shifted left to increase the window size beyond 64 KiB. For example, the largest window value of \u003Ccode class=\"literal\">65535\u003C/code> shifted 7 places to the left, resulting in a window size of almost 8 MiB. This enables transferring much more data at a given time.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tTCP Window Scaling is negotiated during the three-way TCP handshake that opens every TCP connection. Both sender and receiver must support TCP Window Scaling for the feature to work. If either or both participants do not advertise window scaling ability in their handshake, the connection reverts to using the original 16-bit TCP window size.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tBy default, TCP Window Scaling is enabled in Red Hat Enterprise Linux:\n\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>sysctl net.ipv4.tcp_window_scaling\u003C/strong>\u003C/span>\nnet.ipv4.tcp_window_scaling = 1\u003C/pre>\u003Cp>\n\t\t\t\t\tIf TCP Window Scaling is disabled (\u003Ccode class=\"literal\">0\u003C/code>) on your server, revert the setting in the same way as you set it.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://www.rfc-editor.org/rfc/rfc1323\">RFC 1323: TCP Extensions for High Performance\u003C/a>\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_monitoring_and_updating_the_kernel/configuring-kernel-parameters-at-runtime_managing-monitoring-and-updating-the-kernel\">Configuring kernel parameters at runtime\u003C/a>\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"how-tcp-sack-reduces-the-packet-drop-rate_tuning-tcp-connections-for-high-throughput\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">31.5.5. How TCP SACK reduces the packet drop rate\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tThe TCP Selective Acknowledgment (TCP SACK) feature, which is enabled by default in Red Hat Enterprise Linux (RHEL), is an enhancement of the TCP protocol and increases the efficiency of TCP connections.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tIn TCP transmissions, the receiver sends an ACK packet to the sender for every packet it receives. For example, a client sends the TCP packets 1-10 to the server but the packets number 5 and 6 get lost. Without TCP SACK, the server drops packets 7-10, and the client must retransmit all packets from the point of loss, which is inefficient. With TCP SACK enabled on both hosts, the client must re-transmit only the lost packets 5 and 6.\n\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\tDisabling TCP SACK decreases the performance and causes a higher packet drop rate on the receiver side in a TCP connection.\n\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cp>\n\t\t\t\t\tBy default, TCP SACK is enabled in RHEL. To verify:\n\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>sysctl net.ipv4.tcp_sack\u003C/strong>\u003C/span>\n1\u003C/pre>\u003Cp>\n\t\t\t\t\tIf TCP SACK is disabled (\u003Ccode class=\"literal\">0\u003C/code>) on your server, revert the setting in the same way as you set it.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"http://tools.ietf.org/html/rfc2018\">RFC 2018: TCP Selective Acknowledgment Options\u003C/a>\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/solutions/742043\">Should I be concerned about a 0.05% packet drop rate?\u003C/a> (Red Hat Knowledgebase)\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_monitoring_and_updating_the_kernel/configuring-kernel-parameters-at-runtime_managing-monitoring-and-updating-the-kernel\">Configuring kernel parameters at runtime\u003C/a>\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"section\" id=\"tuning-udp-connections_tuning-the-network-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">31.6. Tuning UDP connections\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tBefore you start tuning Red Hat Enterprise Linux to improve the throughput of UDP traffic, it is important to have the realistic expectations. UDP is a simple protocol. Compared to TCP, UDP does not contain features, such as flow control, congestion control, and data reliability. This makes it difficult to reach reliable communication over UDP with a throughput rate that is close to the maximum speed of the network interface controller (NIC).\n\t\t\t\u003C/p>\u003Csection class=\"section\" id=\"detecting-packet-drops_tuning-udp-connections\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">31.6.1. Detecting packet drops\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tThere are multiple levels in the network stack in which the kernel can drop packets. Red Hat Enterprise Linux provides different utilities to display statistics of these levels. Use them to identify potential problems.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tNote that you can ignore a very small rate of dropped packets. However, if you encounter a significant rate, consider tuning measures.\n\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\tThe kernel drops network packets if the networking stack cannot handle the incoming traffic.\n\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIdentify if the network interface controller (NIC) drops packets:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tDisplay the NIC and driver-specific statistics:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ethtool -S \u003Cspan class=\"emphasis\">\u003Cem>enp1s0\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\nNIC statistics:\n     ...\n     rx_queue\u003Cspan class=\"emphasis\">\u003Cem>_0\u003C/em>\u003C/span>_drops: 17657\n     ...\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tThe naming of the statistics and if they are available depend on the NIC and the driver.\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tDisplay the interface statistics:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ip -s link show \u003Cspan class=\"emphasis\">\u003Cem>enp1s0\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\n\u003Cspan class=\"emphasis\">\u003Cem>2: enp1s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000\u003C/em>\u003C/span>\n    \u003Cspan class=\"emphasis\">\u003Cem>link/ether 52:54:00:74:79:56 brd ff:ff:ff:ff:ff:ff\u003C/em>\u003C/span>\n    RX:   bytes  packets errors dropped  missed   mcast_\n    \u003Cspan class=\"emphasis\">\u003Cem>84697611107\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>56866482\u003C/em>\u003C/span>      \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>   \u003Cspan class=\"emphasis\">\u003Cem>10904\u003C/em>\u003C/span>       \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>       \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>\n    TX:   bytes  packets errors dropped carrier collsns_\n     \u003Cspan class=\"emphasis\">\u003Cem>5540028184\u003C/em>\u003C/span>  \u003Cspan class=\"emphasis\">\u003Cem>3722234\u003C/em>\u003C/span>      \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>       \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>       \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>       \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">RX\u003C/code> represents the statistics of received packets and \u003Ccode class=\"literal\">TX\u003C/code> of transmitted packets.\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIdentify UDP protocol-specific packet drops due to too small socket buffers or slow application processing:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>nstat -az UdpSndbufErrors UdpRcvbufErrors\u003C/strong>\u003C/span>\n#kernel\nUdpSndbufErrors           4    0.0\nUdpRcvbufErrors    45716659    0.0\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe second column in the output lists the counters.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/solutions/21301\">RHEL network interface dropping packets\u003C/a> (Red Hat Knowledgebase)\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/solutions/742043\">Should I be concerned about a 0.05% packet drop rate?\u003C/a> (Red Hat Knowledgebase)\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"testing-the-udp-throughput-using-iperf3_tuning-udp-connections\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">31.6.2. Testing the UDP throughput using iperf3\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tThe \u003Ccode class=\"literal\">iperf3\u003C/code> utility provides a server and client mode to perform network throughput tests between two hosts.\n\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\tThe throughput of applications depend on many factors, such as the buffer sizes that the application uses. Therefore, the results measured with testing utilities, such as \u003Ccode class=\"literal\">iperf3\u003C/code>, can significantly be different from those of applications on a server under production workload.\n\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">iperf3\u003C/code> package is installed on both the client and server.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tNo other services on both hosts cause network traffic that substantially affects the test result.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tOptional: You increased the maximum UDP socket sizes on both the server and the client. For details, see \u003Ca class=\"link\" href=\"#increasing-the-system-wide-udp-socket-buffers_tuning-udp-connections\" title=\"31.6.5. Increasing the system-wide UDP socket buffers\">Increasing the system-wide UDP socket buffers\u003C/a>.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tOptional: Display the maximum network speed of the network interface controller (NIC) on both the server and client:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ethtool enp1s0 | grep \"Speed\"\u003C/strong>\u003C/span>\n   Speed: 10000Mb/s\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tOn the server:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tDisplay the maximum UDP socket read buffer size, and note the value:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>sysctl net.core.rmem_max\u003C/strong>\u003C/span>\nnet.core.rmem_max = \u003Cspan class=\"emphasis\">\u003Cem>16777216\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tThe displayed value is in bytes.\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tTemporarily open the default \u003Ccode class=\"literal\">iperf3\u003C/code> port 5201 in the \u003Ccode class=\"literal\">firewalld\u003C/code> service:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>firewall-cmd --add-port=5201/tcp --add-port=5201/udp\u003C/strong>\u003C/span>\n# \u003Cspan class=\"strong strong\">\u003Cstrong>firewall-cmd --reload\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tNote that, \u003Ccode class=\"literal\">iperf3\u003C/code> opens only a TCP socket on the server. If a clients wants to use UDP, it first connects to this TCP port, and then the server opens a UDP socket on the same port number for performing the UDP traffic throughput test. For this reason, you must open port 5201 for both the TCP and UDP protocol in the local firewall.\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tStart \u003Ccode class=\"literal\">iperf3\u003C/code> in server mode:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>iperf3 --server\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tThe service now waits for incoming client connections.\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tOn the client:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tDisplay the Maximum Transmission Unit (MTU) of the interface that the client will use for the connection to the server, and note the value:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ip link show enp1s0\u003C/strong>\u003C/span>\n\u003Cspan class=\"emphasis\">\u003Cem>2: enp1s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu \u003Cspan class=\"strong strong\">\u003Cstrong>1500\u003C/strong>\u003C/span> qdisc fq_codel state UP mode DEFAULT group default qlen 1000\u003C/em>\u003C/span>\n...\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tDisplay the maximum UDP socket write buffer size, and note the value:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>sysctl net.core.wmem_max\u003C/strong>\u003C/span>\nnet.core.wmem_max = \u003Cspan class=\"emphasis\">\u003Cem>16777216\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tThe displayed value is in bytes.\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tStart measuring the throughput:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>iperf3 --udp --time \u003Cspan class=\"emphasis\">\u003Cem>60\u003C/em>\u003C/span> --window \u003Cspan class=\"emphasis\">\u003Cem>16777216\u003C/em>\u003C/span> --length \u003Cspan class=\"emphasis\">\u003Cem>1472\u003C/em>\u003C/span> --bitrate 2G --client \u003Cspan class=\"emphasis\">\u003Cem>192.0.2.1\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">--udp\u003C/code>: Use the UDP protocol for the test.\n\t\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">--time \u003Cspan class=\"emphasis\">\u003Cem>&lt;seconds&gt;\u003C/em>\u003C/span>\u003C/code>: Defines the time in seconds when the client stops the transmission.\n\t\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">--window \u003Cspan class=\"emphasis\">\u003Cem>&lt;size&gt;\u003C/em>\u003C/span>\u003C/code>: Sets the UDP socket buffer size. Ideally, the sizes are the same on both the client and server. In case that they are different, set this parameter to the value that is smaller: \u003Ccode class=\"literal\">net.core.wmem_max\u003C/code> on the client or \u003Ccode class=\"literal\">net.core.rmem_max\u003C/code> on the server.\n\t\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">--length \u003Cspan class=\"emphasis\">\u003Cem>&lt;size&gt;\u003C/em>\u003C/span>\u003C/code>: Sets the length of the buffer to read and write. Set this option to the largest unfragmented payload. Calculate the ideal value as follows: MTU - IP header (20 bytes for IPv4 and 40 bytes for IPv6) - 8 bytes UDP header.\n\t\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">--bitrate \u003Cspan class=\"emphasis\">\u003Cem>&lt;rate&gt;\u003C/em>\u003C/span>\u003C/code>: Limits the bit rate to the specified value in bits per second. You can specify units, such as \u003Ccode class=\"literal\">2G\u003C/code> for 2 Gbps.\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\t\tSet this parameter to a value that you expect to work and increase it in later measurements. If the server sends packets at a faster rate than the devices on the transmit path or the client can process them, packets can be dropped.\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">--client &lt;server&gt;\u003C/code>: Enables the client mode and sets the IP address or name of the server that runs the \u003Ccode class=\"literal\">iperf3\u003C/code> server.\n\t\t\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tWait until \u003Ccode class=\"literal\">iperf3\u003C/code> completes the test. Both the server and the client display statistics every second and a summary at the end. For example, the following is a summary displayed on a client:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">[ ID] Interval       Transfer      Bitrate         Jitter    Lost/Total Datagrams\n[ 5] 0.00-60.00 sec  14.0 GBytes   2.00 Gbits/sec  0.000 ms  0/10190216 (0%) sender\n[ 5] 0.00-60.04 sec  14.0 GBytes   2.00 Gbits/sec  0.002 ms  0/10190216 (0%) receiver\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIn this example, the average bit rate was 2 Gbps, and no packets were lost.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tOn the server:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tPress \u003Ckbd class=\"keycap\">Ctrl\u003C/kbd>+\u003Ckbd class=\"keycap\">C\u003C/kbd> to stop the \u003Ccode class=\"literal\">iperf3\u003C/code> server.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tClose port 5201 in \u003Ccode class=\"literal\">firewalld\u003C/code>:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>firewall-cmd --remove-port=5201/tcp --remove-port=5201/udp\u003C/strong>\u003C/span>\n# \u003Cspan class=\"strong strong\">\u003Cstrong>firewall-cmd --reload\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ccode class=\"literal\">iperf3(1)\u003C/code> man page on your system\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"impact-of-the-mtu-size-on-udp-traffic-throughput_tuning-udp-connections\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">31.6.3. Impact of the MTU size on UDP traffic throughput\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tIf your application uses a large UDP message size, using jumbo frames can improve the throughput. According to the IEEE 802.3 standard, a default Ethernet frame without Virtual Local Area Network (VLAN) tag has a maximum size of 1518 bytes. Each of these frames includes an 18 bytes header, leaving 1500 bytes for payload. Consequently, for every 1500 bytes of data the server transmits over the network, 18 bytes (1.2%) are overhead.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tJumbo frames are non-standardized frames that have a larger Maximum Transmission Unit (MTU) than the standard Ethernet payload size of 1500 bytes. For example, if you configure jumbo Frames with the maximum allowed MTU of 9000 bytes payload, the overhead of each frame reduces to 0.2%.\n\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\tAll network devices on the transmission path and the involved broadcast domains must support jumbo frames and use the same MTU. Packet fragmentation and reassembly due to inconsistent MTU settings on the transmission path reduces the network throughput.\n\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cp>\n\t\t\t\t\tDifferent connection types have certain MTU limitations:\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tEthernet: the MTU is limited to 9000 bytes.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tIP over InfiniBand (IPoIB) in datagram mode: The MTU is limited to 4 bytes less than the InfiniBand MTU.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tIn-memory networking commonly supports larger MTUs. For details, see the respective documentation.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"impact-of-the-cpu-speed-on-udp-traffic-throughput_tuning-udp-connections\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">31.6.4. Impact of the CPU speed on UDP traffic throughput\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tIn bulk transfers, the UDP protocol is much less efficient than TCP, mainly due to the missing packet aggregation in UDP. By default, the Generic Receive Offload (GRO) and Transmit Segmentation Offload (TSO) features are not enabled. Consequently, the CPU frequency can limit the UDP throughput for bulk transfer on high speed links.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tFor example, on a tuned host with a high Maximum Transmission Unit (MTU) and large socket buffers, a 3 GHz CPU can process the traffic of a 10 GBit NIC that sends or receives UDP traffic at full speed. However, you can expect about 1-2 Gbps speed loss for every 100 MHz CPU speed under 3 GHz when you transmit UDP traffic. Also, if a CPU speed of 3 GHz can closely achieve 10 Gbps, the same CPU restricts UDP traffic on a 40 GBit NIC to roughly 20-25 Gbps.\n\t\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"increasing-the-system-wide-udp-socket-buffers_tuning-udp-connections\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">31.6.5. Increasing the system-wide UDP socket buffers\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tSocket buffers temporarily store data that the kernel has received or should send:\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe read socket buffer holds packets that the kernel has received but which the application has not read yet.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe write socket buffer holds packets that an application has written to the buffer but which the kernel has not passed to the IP stack and network driver yet.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\t\tIf a UDP packet is too large and exceeds the buffer size or packets are sent or received at a too fast rate, the kernel drops any new incoming UDP packet until the data is removed from the buffer. In this case, increasing the socket buffers can prevent packet loss.\n\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\tSetting too large buffer sizes wastes memory. Each socket can be set to the size that the application requests, and the kernel doubles this value. For example, if an application requests a 256 KiB socket buffer size and opens 1 million sockets, the system requires 512 GB RAM (512 KiB x 1 million) only for the potential socket buffer space.\n\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tYou encountered a significant rate of dropped UDP packets.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tCreate the \u003Ccode class=\"literal\">/etc/sysctl.d/10-udp-socket-buffers.conf\u003C/code> file and either set the maximum read or write buffer size, or both, based on your requirements:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">\u003Cspan class=\"strong strong\">\u003Cstrong>net.core.rmem_max = \u003Cspan class=\"emphasis\">\u003Cem>16777216\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\n\u003Cspan class=\"strong strong\">\u003Cstrong>net.core.wmem_max = \u003Cspan class=\"emphasis\">\u003Cem>16777216\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tSpecify the values in bytes. The values in this example set the maximum size of buffers to 16 MiB. The default values of both parameters are \u003Ccode class=\"literal\">212992\u003C/code> bytes (208 KiB).\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tLoad the settings from the \u003Ccode class=\"literal\">/etc/sysctl.d/10-udp-socket-buffers.conf\u003C/code> file:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>sysctl -p /etc/sysctl.d/\u003Cspan class=\"emphasis\">\u003Cem>10-udp-socket-buffers.conf\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tConfigure your applications to use the larger socket buffer sizes.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">net.core.rmem_max\u003C/code> and \u003Ccode class=\"literal\">net.core.wmem_max\u003C/code> parameters define the maximum buffer size that the \u003Ccode class=\"literal\">setsockopt()\u003C/code> function in an application can request. Note that, if you configure your application to not use the \u003Ccode class=\"literal\">setsockopt()\u003C/code> function, the kernel uses the values from the \u003Ccode class=\"literal\">rmem_default\u003C/code> and \u003Ccode class=\"literal\">wmem_default\u003C/code> parameters.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFor further details, see the documentation of the programming language of your application. If you are not the developer of the application, contact the developer.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tRestart the applications to use the new UDP buffer sizes.\n\t\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tMonitor the packet drop statistics using the same method as you used when you encountered the packet drops.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIf packet drops still occur but at a lower rate, increase the buffer sizes further.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/solutions/85913\">What are the implications of changing socket buffer sizes?\u003C/a> (Red Hat Knowledgebase)\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ccode class=\"literal\">udp(7)\u003C/code> and \u003Ccode class=\"literal\">socket(7)\u003C/code> man pages on your system\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"section\" id=\"identifying-application-read-socket-buffer-bottlenecks_tuning-the-network-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">31.7. Identifying application read socket buffer bottlenecks\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tIf TCP applications do not clear the read socket buffers frequently enough, performance can suffer and packets can be lost. Red Hat Enterprise Linux provides different utilities to identify such problems.\n\t\t\t\u003C/p>\u003Csection class=\"section\" id=\"identifying-receive-buffer-collapsing-and-pruning_identifying-application-read-socket-buffer-bottlenecks\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">31.7.1. Identifying receive buffer collapsing and pruning\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tWhen the data in the receive queue exceeds the receive buffer size, the TCP stack tries to free some space by removing unnecessary metadata from the socket buffer. This step is known as collapsing.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tIf collapsing fails to free sufficient space for additional traffic, the kernel prunes new data that arrives. This means that the kernel removes the data from the memory and the packet is lost.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tTo avoid collapsing and pruning operations, monitor whether TCP buffer collapsing and pruning happens on your server and, in this case, tune the TCP buffers.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tUse the \u003Ccode class=\"literal\">nstat\u003C/code> utility to query the \u003Ccode class=\"literal\">TcpExtTCPRcvCollapsed\u003C/code> and \u003Ccode class=\"literal\">TcpExtRcvPruned\u003C/code> counters:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>nstat -az TcpExtTCPRcvCollapsed TcpExtRcvPruned\u003C/strong>\u003C/span>\n#kernel\nTcpExtRcvPruned            0         0.0\nTcpExtTCPRcvCollapsed      612859    0.0\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tWait some time and re-run the \u003Ccode class=\"literal\">nstat\u003C/code> command:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>nstat -az TcpExtTCPRcvCollapsed TcpExtRcvPruned\u003C/strong>\u003C/span>\n#kernel\nTcpExtRcvPruned            0         0.0\nTcpExtTCPRcvCollapsed      620358    0.0\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIf the values of the counters have increased compared to the first run, tuning is required:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tIf the application uses the \u003Ccode class=\"literal\">setsockopt(SO_RCVBUF)\u003C/code> call, consider removing it. With this call, the application only uses the receive buffer size specified in the call and turns off the socket’s ability to auto-tune its size.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tIf the application does not use the \u003Ccode class=\"literal\">setsockopt(SO_RCVBUF)\u003C/code> call, tune the default and maximum values of the TCP read socket buffer.\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tDisplay the receive backlog queue (\u003Ccode class=\"literal\">Recv-Q\u003C/code>):\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ss -nti\u003C/strong>\u003C/span>\nState   Recv-Q   Send-Q   Local Address:Port   Peer Address:Port   Process\nESTAB   0        0        192.0.2.1:443        192.0.2.125:41574\n      :7,7 ... lastrcv:543 ...\nESTAB   78       0        192.0.2.1:443        192.0.2.56:42612\n      :7,7 ... lastrcv:658 ...\nESTAB   88       0        192.0.2.1:443        192.0.2.97:40313\n      :7,7 ... lastrcv:5764 ...\n...\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tRun the \u003Ccode class=\"literal\">ss -nt\u003C/code> command multiple times with a few seconds waiting time between each run.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIf the output lists only one case of a high value in the \u003Ccode class=\"literal\">Recv-Q\u003C/code> column, the application was between two receive operations. However, if the values in \u003Ccode class=\"literal\">Recv-Q\u003C/code> stays constant while \u003Ccode class=\"literal\">lastrcv\u003C/code> continually grows, or \u003Ccode class=\"literal\">Recv-Q\u003C/code> continually increases over time, one of the following problems can be the cause:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tThe application does not check its socket buffers often enough. Contact the application vendor for details about how you can solve this problem.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tThe application does not get enough CPU time. To further debug this problem:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"i\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\t\tDisplay on which CPU cores the application runs:\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ps -eo pid,tid,psr,pcpu,stat,wchan:20,comm\u003C/strong>\u003C/span>\n    PID     TID PSR %CPU STAT WCHAN                COMMAND\n...\n  44594   44594   5  0.0 Ss   do_select            httpd\n  44595   44595   3  0.0 S    skb_wait_for_more_pa httpd\n  44596   44596   5  0.0 Sl   pipe_read            httpd\n  44597   44597   5  0.0 Sl   pipe_read            httpd\n  44602   44602   5  0.0 Sl   pipe_read            httpd\n...\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">PSR\u003C/code> column displays the CPU cores the process is currently assigned to.\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\tIdentify other processes running on the same cores and consider assigning them to other cores.\n\t\t\t\t\t\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"#increasing-the-system-wide-tcp-socket-buffers_tuning-tcp-connections-for-high-throughput\" title=\"31.5.3. Increasing the system-wide TCP socket buffers\">Increasing the system-wide TCP socket buffers\u003C/a>\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"section\" id=\"tuning-applications-with-a-large-number-of-incoming-requests_tuning-the-network-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">31.8. Tuning applications with a large number of incoming requests\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tIf you run an application that handles a large number of incoming requests, such as web servers, it can be necessary to tune Red Hat Enterprise Linux to optimize the performance.\n\t\t\t\u003C/p>\u003Csection class=\"section\" id=\"tuning-the-tcp-listen-backlog-to-process-a-high-number-of-tcp-connection-attempts_tuning-applications-with-a-large-number-of-incoming-requests\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">31.8.1. Tuning the TCP listen backlog to process a high number of TCP connection attempts\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tWhen an application opens a TCP socket in \u003Ccode class=\"literal\">LISTEN\u003C/code> state, the kernel limits the number of accepted client connections this socket can handle. If clients try to establish more connections than the application can process, the new connections get lost or the kernel sends SYN cookies to the client.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tIf the system is under normal workload and too many connections from legitimate clients cause the kernel to send SYN cookies, tune Red Hat Enterprise Linux (RHEL) to avoid them.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tRHEL logs \u003Ccode class=\"literal\">possible SYN flooding on port \u003Cspan class=\"emphasis\">\u003Cem>&lt;ip_address&gt;\u003C/em>\u003C/span>:\u003Cspan class=\"emphasis\">\u003Cem>&lt;port_number&gt;\u003C/em>\u003C/span>\u003C/code> error messages in the Systemd journal.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe high number of connection attempts are from valid sources and not caused by an attack.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tTo verify whether tuning is required, display the statistics for the affected port:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ss -ntl '( sport = :\u003Cspan class=\"emphasis\">\u003Cem>443\u003C/em>\u003C/span> )'\u003C/strong>\u003C/span>\nState    Recv-Q   Send-Q   Local Address:Port   Peer Address:Port  Process\nLISTEN   \u003Cspan class=\"emphasis\">\u003Cem>650\u003C/em>\u003C/span>      \u003Cspan class=\"emphasis\">\u003Cem>500\u003C/em>\u003C/span>      \u003Cspan class=\"emphasis\">\u003Cem>192.0.2.1:443\u003C/em>\u003C/span>        0.0.0.0:*\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIf the current number of connections in the backlog (\u003Ccode class=\"literal\">Recv-Q\u003C/code>) is larger than the socket backlog (\u003Ccode class=\"literal\">Send-Q\u003C/code>), the listen backlog is still not large enough and tuning is required.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tOptional: Display the current TCP listen backlog limit:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>sysctl net.core.somaxconn\u003C/strong>\u003C/span>\nnet.core.somaxconn = \u003Cspan class=\"emphasis\">\u003Cem>4096\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tCreate the \u003Ccode class=\"literal\">/etc/sysctl.d/10-socket-backlog-limit.conf\u003C/code> file, and set a larger listen backlog limit:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">\u003Cspan class=\"strong strong\">\u003Cstrong>net.core.somaxconn = \u003Cspan class=\"emphasis\">\u003Cem>8192\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tNote that applications can request a larger listen backlog than specified in the \u003Ccode class=\"literal\">net.core.somaxconn\u003C/code> kernel parameter but the kernel limits the application to the number you set in this parameter.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tLoad the setting from the \u003Ccode class=\"literal\">/etc/sysctl.d/10-socket-backlog-limit.conf\u003C/code> file:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>sysctl -p /etc/sysctl.d/10-socket-backlog-limit.conf\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tReconfigure the application to use the new listen backlog limit:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tIf the application provides a config option for the limit, update it. For example, the Apache HTTP Server provides the \u003Ccode class=\"literal\">ListenBacklog\u003C/code> configuration option to set the listen backlog limit for this service.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tIf you cannot configure the limit, recompile the application.\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tRestart the application.\n\t\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tMonitor the Systemd journal for further occurrences of \u003Ccode class=\"literal\">possible SYN flooding on port \u003Cspan class=\"emphasis\">\u003Cem>&lt;port_number&gt;\u003C/em>\u003C/span>\u003C/code> error messages.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tMonitor the current number of connections in the backlog and compare it with the socket backlog:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ss -ntl '( sport = :\u003Cspan class=\"emphasis\">\u003Cem>443\u003C/em>\u003C/span> )'\u003C/strong>\u003C/span>\nState    Recv-Q   Send-Q   Local Address:Port   Peer Address:Port  Process\nLISTEN   \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>        \u003Cspan class=\"emphasis\">\u003Cem>500\u003C/em>\u003C/span>      \u003Cspan class=\"emphasis\">\u003Cem>192.0.2.1:443\u003C/em>\u003C/span>        0.0.0.0:*\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIf the current number of connections in the backlog (\u003Ccode class=\"literal\">Recv-Q\u003C/code>) is larger than the socket backlog (\u003Ccode class=\"literal\">Send-Q\u003C/code>), the listen backlog is not large enough and further tuning is required.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/articles/1391433\">kernel: Possible SYN flooding on port #. Sending cookies\u003C/a>\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/solutions/3193562\">Listening TCP server ignores SYN or ACK for new connection handshake\u003C/a> (Red Hat Knowledgebase)\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ccode class=\"literal\">listen(2)\u003C/code> man page on your system\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"section\" id=\"avoiding-listen-queue-lock-contention_tuning-the-network-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">31.9. Avoiding listen queue lock contention\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tQueue lock contention can cause packet drops and higher CPU usage and, consequently, a higher latency. You can avoid queue lock contention on the receive (RX) and transmit (TX) queue by tuning your application and using transmit packet steering.\n\t\t\t\u003C/p>\u003Csection class=\"section\" id=\"avoiding-rx-queue-lock-contention-the-so_reuseport-and-so_reuseport_bpf-socket-options_avoiding-listen-queue-lock-contention\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">31.9.1. Avoiding RX queue lock contention: The SO_REUSEPORT and SO_REUSEPORT_BPF socket options\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tOn a multi-core system, you can improve the performance of multi-threaded network server applications if the application opens the port by using the \u003Ccode class=\"literal\">SO_REUSEPORT\u003C/code> or \u003Ccode class=\"literal\">SO_REUSEPORT_BPF\u003C/code> socket option. If the application does not use one of these socket options, all threads are forced to share a single socket to receive the incoming traffic. Using a single socket causes:\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tSignificant contention on the receive buffer, which can cause packet drops and higher CPU usage.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tA significant increase of CPU usage\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tPossibly packet drops\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"informalfigure\">\u003Cdiv class=\"mediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/4a88b5b3bbe5fb65cf923949642f94e3/lock-contention.png\" alt=\"lock contention\"/>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tWith the \u003Ccode class=\"literal\">SO_REUSEPORT\u003C/code> or \u003Ccode class=\"literal\">SO_REUSEPORT_BPF\u003C/code> socket option, multiple sockets on one host can bind to the same port:\n\t\t\t\t\u003C/p>\u003Cdiv class=\"informalfigure\">\u003Cdiv class=\"mediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/d98510d7449bbab560553bb46e5828fe/so_reuseport.png\" alt=\"so reuseport\"/>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tRed Hat Enterprise Linux provides a code example of how to use the \u003Ccode class=\"literal\">SO_REUSEPORT\u003C/code> socket options in the kernel sources. To access the code example:\n\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tEnable the \u003Ccode class=\"literal\">rhel-9-for-x86_64-baseos-debug-rpms\u003C/code> repository:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>subscription-manager repos --enable rhel-9-for-x86_64-baseos-debug-rpms\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tInstall the \u003Ccode class=\"literal\">kernel-debuginfo-common-x86_64\u003C/code> package:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>dnf install kernel-debuginfo-common-x86_64\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe code example is now available in the \u003Ccode class=\"literal\">/usr/src/debug/kernel-\u003Cspan class=\"emphasis\">\u003Cem>&lt;version&gt;\u003C/em>\u003C/span>/linux-&lt;version&gt;/tools/testing/selftests/net/reuseport_bpf_cpu.c\u003C/code> file.\n\t\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ccode class=\"literal\">socket(7)\u003C/code> man page on your system\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/src/debug/kernel-\u003Cspan class=\"emphasis\">\u003Cem>&lt;version&gt;\u003C/em>\u003C/span>/linux-&lt;version&gt;/tools/testing/selftests/net/reuseport_bpf_cpu.c\u003C/code>\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"avoiding-tx-queue-lock-contention-transmit-packet-steering_avoiding-listen-queue-lock-contention\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">31.9.2. Avoiding TX queue lock contention: Transmit packet steering\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tIn hosts with a network interface controller (NIC) that supports multiple queues, transmit packet steering (XPS) distributes the processing of outgoing network packets among several queues. This enables multiple CPUs to process the outgoing network traffic and to avoid transmit queue lock contention and, consequently, packet drops.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tCertain drivers, such as \u003Ccode class=\"literal\">ixgbe\u003C/code>, \u003Ccode class=\"literal\">i40e\u003C/code>, and \u003Ccode class=\"literal\">mlx5\u003C/code> automatically configure XPS. To identify if the driver supports this capability, consult the documentation of your NIC driver. Consult your NIC driver’s documentation to identify if the driver supports this capability. If the driver does not support XPS auto-tuning, you can manually assign CPU cores to the transmit queues.\n\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\tRed Hat Enterprise Linux does not provide an option to permanently assign transmit queues to CPU cores. Use the commands in a script and run it when the system boots.\n\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe NIC supports multiple queues.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">numactl\u003C/code> package is installed.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tDisplay the count of available queues:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ethtool -l \u003Cspan class=\"emphasis\">\u003Cem>enp1s0\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\nChannel parameters for \u003Cspan class=\"emphasis\">\u003Cem>enp1s0\u003C/em>\u003C/span>:\nPre-set maximums:\nRX:\t\t\u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>\nTX:\t\t\u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>\nOther:\t\t\u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>\nCombined:\t\u003Cspan class=\"emphasis\">\u003Cem>4\u003C/em>\u003C/span>\nCurrent hardware settings:\nRX:\t\t\u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>\nTX:\t\t\u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>\nOther:\t\t\u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>\nCombined:\t\u003Cspan class=\"emphasis\">\u003Cem>1\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">Pre-set maximums\u003C/code> section shows the total number of queues and \u003Ccode class=\"literal\">Current hardware settings\u003C/code> the number of queues that are currently assigned to the receive, transmit, other, or combined queues.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tOptional: If you require queues on specific channels, assign them accordingly. For example, to assign the 4 queues to the \u003Ccode class=\"literal\">Combined\u003C/code> channel, enter:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ethtool -L \u003Cspan class=\"emphasis\">\u003Cem>enp1s0\u003C/em>\u003C/span> combined 4\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tDisplay to which Non-Uniform Memory Access (NUMA) node the NIC is assigned:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>cat /sys/class/net/\u003Cspan class=\"emphasis\">\u003Cem>enp1s0\u003C/em>\u003C/span>/device/numa_node\u003C/strong>\u003C/span>\n0\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIf the file is not found or the command returns \u003Ccode class=\"literal\">-1\u003C/code>, the host is not a NUMA system.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIf the host is a NUMA system, display which CPUs are assigned to which NUMA node:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>lscpu | grep NUMA\u003C/strong>\u003C/span>\nNUMA node(s):       2\nNUMA node0 CPU(s):  0-3\nNUMA node1 CPU(s):  4-7\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIn the example above, the NIC has 4 queues and the NIC is assigned to NUMA node 0. This node uses the CPU cores 0-3. Consequently, map each transmit queue to one of the CPU cores from 0-3:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>echo \u003Cspan class=\"emphasis\">\u003Cem>1\u003C/em>\u003C/span> &gt; /sys/class/net/\u003Cspan class=\"emphasis\">\u003Cem>enp1s0\u003C/em>\u003C/span>/queues/tx-\u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>/xps_cpus\u003C/strong>\u003C/span>\n# \u003Cspan class=\"strong strong\">\u003Cstrong>echo \u003Cspan class=\"emphasis\">\u003Cem>2\u003C/em>\u003C/span> &gt; /sys/class/net/\u003Cspan class=\"emphasis\">\u003Cem>enp1s0\u003C/em>\u003C/span>/queues/tx-\u003Cspan class=\"emphasis\">\u003Cem>1\u003C/em>\u003C/span>/xps_cpus\u003C/strong>\u003C/span>\n# \u003Cspan class=\"strong strong\">\u003Cstrong>echo \u003Cspan class=\"emphasis\">\u003Cem>4\u003C/em>\u003C/span> &gt; /sys/class/net/\u003Cspan class=\"emphasis\">\u003Cem>enp1s0\u003C/em>\u003C/span>/queues/tx-\u003Cspan class=\"emphasis\">\u003Cem>2\u003C/em>\u003C/span>/xps_cpus\u003C/strong>\u003C/span>\n# \u003Cspan class=\"strong strong\">\u003Cstrong>echo \u003Cspan class=\"emphasis\">\u003Cem>8\u003C/em>\u003C/span> &gt; /sys/class/net/\u003Cspan class=\"emphasis\">\u003Cem>enp1s0\u003C/em>\u003C/span>/queues/tx-\u003Cspan class=\"emphasis\">\u003Cem>3\u003C/em>\u003C/span>/xps_cpus\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIf the number of CPU cores and transmit (TX) queues is the same, use a 1 to 1 mapping to avoid any kind of contention on the TX queue. Otherwise, if you map multiple CPUs on the same TX queue, transmit operations on different CPUs will cause TX queue lock contention and negatively impacts the transmit throughput.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tNote that you must pass the bitmap, containing the CPU’s core numbers, to the queues. Use the following command to calculate the bitmap:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>printf %x $((1 &lt;&lt; \u003Cspan class=\"emphasis\">\u003Cem>&lt;core_number&gt;\u003C/em>\u003C/span> ))\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIdentify the process IDs (PIDs) of services that send traffic:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>pidof \u003Cspan class=\"emphasis\">\u003Cem>&lt;process_name&gt;\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\n\u003Cspan class=\"emphasis\">\u003Cem>12345\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>98765\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tPin the PIDs to cores that use XPS:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>numactl -C \u003Cspan class=\"emphasis\">\u003Cem>0-3\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>12345\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>98765\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tMonitor the \u003Ccode class=\"literal\">requeues\u003C/code> counter while the process send traffic:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>tc -s qdisc\u003C/strong>\u003C/span>\n\u003Cspan class=\"emphasis\">\u003Cem>qdisc fq_codel 0: dev enp10s0u1 root refcnt 2 limit 10240p flows 1024 quantum 1514 target 5ms interval 100ms memory_limit 32Mb ecn drop_batch 64\u003C/em>\u003C/span>\n Sent \u003Cspan class=\"emphasis\">\u003Cem>125728849\u003C/em>\u003C/span> bytes \u003Cspan class=\"emphasis\">\u003Cem>1067587\u003C/em>\u003C/span> pkt (dropped \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span>, overlimits \u003Cspan class=\"emphasis\">\u003Cem>0\u003C/em>\u003C/span> requeues \u003Cspan class=\"emphasis\">\u003Cem>30\u003C/em>\u003C/span>)\n backlog \u003Cspan class=\"emphasis\">\u003Cem>0b 0p\u003C/em>\u003C/span> requeues \u003Cspan class=\"emphasis\">\u003Cem>30\u003C/em>\u003C/span>\n ...\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIf the \u003Ccode class=\"literal\">requeues\u003C/code> counter no longer increases at a significant rate, TX queue lock contention no longer happens.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/doc/kernel-doc-_&lt;version&gt;/Documentation/networking/scaling.rst\u003C/code>\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"disabling-the-generic-receive-offload-feature-on-servers-with-high-udp-traffic_avoiding-listen-queue-lock-contention\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">31.9.3. Disabling the Generic Receive Offload feature on servers with high UDP traffic\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tApplications that use high-speed UDP bulk transfer should enable and use UDP Generic Receive Offload (GRO) on the UDP socket. However, you can disable GRO to increase the throughput if the following conditions apply:\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe application does not support GRO and the feature cannot be added.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tTCP throughput is not relevant.\n\t\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition warning\" state=\"danger\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Warning\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\t\tDisabling GRO significantly reduces the receive throughput of TCP traffic. Therefore, do not disable GRO on hosts where TCP performance is relevant.\n\t\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe host mainly processes UDP traffic.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe application does not use GRO.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe host does not use UDP tunnel protocols, such as VXLAN.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe host does not run virtual machines (VMs) or containers.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tOptional: Display the NetworkManager connection profiles:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>nmcli connection show\u003C/strong>\u003C/span>\nNAME     UUID                                  TYPE      DEVICE\n\u003Cspan class=\"emphasis\">\u003Cem>example\u003C/em>\u003C/span>  \u003Cspan class=\"emphasis\">\u003Cem>f2f33f29-bb5c-3a07-9069-be72eaec3ecf\u003C/em>\u003C/span>  \u003Cspan class=\"emphasis\">\u003Cem>ethernet\u003C/em>\u003C/span>  \u003Cspan class=\"emphasis\">\u003Cem>enp1s0\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tDisable GRO support in the connection profile:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>nmcli connection modify \u003Cspan class=\"emphasis\">\u003Cem>example\u003C/em>\u003C/span> ethtool.feature-gro off\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tReactivate the connection profile:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>nmcli connection up \u003Cspan class=\"emphasis\">\u003Cem>example\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tVerify that GRO is disabled:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ethtool -k \u003Cspan class=\"emphasis\">\u003Cem>enp1s0\u003C/em>\u003C/span> | grep generic-receive-offload\u003C/strong>\u003C/span>\ngeneric-receive-offload: off\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tMonitor the throughput on the server. Re-enable GRO in the NetworkManager profile if the setting has negative side effects to other applications on the host.\n\t\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"section\" id=\"tuning-the-device-driver-and-nic_tuning-the-network-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">31.10. Tuning the device driver and NIC\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tIn RHEL, kernel modules provide drivers for network interface controllers (NICs). These modules support parameters to tune and optimize the device driver and the NIC. For example, if the driver supports delaying the generation of receive interrupts, you can reduce the value of the corresponding parameter to avoid running out of receive descriptors.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tNot all modules support custom parameters, and the features depend on the hardware, as well as the driver and firmware version.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Csection class=\"section\" id=\"configuring-custom-nic-driver-parameters_tuning-the-device-driver-and-nic\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">31.10.1. Configuring custom NIC driver parameters\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tMany kernel modules support setting parameters to tune the driver and the network interface controller (NIC). You can customize the settings according to the hardware and the driver.\n\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\tIf you set parameters on a kernel module, RHEL applies these settings to all devices that use this driver.\n\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tA NIC is installed in the host.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe kernel module that provides the driver for the NIC supports the required tuning feature.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tYou are logged in locally or using a network interface that is different from the one that uses the driver for which you want to change the parameters.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIdentify the driver:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ethtool -i \u003Cspan class=\"emphasis\">\u003Cem>enp0s31f6\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\ndriver: \u003Cspan class=\"emphasis\">\u003Cem>e1000e\u003C/em>\u003C/span>\nversion: ...\nfirmware-version: ...\n...\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tNote that certain features can require a specific driver and firmware version.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tDisplay the available parameters of the kernel module:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>modinfo -p \u003Cspan class=\"emphasis\">\u003Cem>e1000e\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\n...\nSmartPowerDownEnable:Enable PHY smart power down (array of int)\nparm:RxIntDelay:Receive Interrupt Delay (array of int)\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFor further details on the parameters, see the kernel module’s documentation. For modules in RHEL, see the documentation in the \u003Ccode class=\"literal\">/usr/share/doc/kernel-doc-\u003Cspan class=\"emphasis\">\u003Cem>&lt;version&gt;\u003C/em>\u003C/span>/Documentation/networking/device_drivers/\u003C/code> directory that is provided by the \u003Ccode class=\"literal\">kernel-doc\u003C/code> package.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tCreate the \u003Ccode class=\"literal\">/etc/modprobe.d/\u003Cspan class=\"emphasis\">\u003Cem>nic-parameters.conf\u003C/em>\u003C/span>\u003C/code> file and specify the parameters for the module:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">options \u003Cspan class=\"emphasis\">\u003Cem>&lt;module_name&gt;\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>&lt;parameter1&gt;\u003C/em>\u003C/span>=\u003Cspan class=\"emphasis\">\u003Cem>&lt;value&gt;\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>&lt;parameter2&gt;\u003C/em>\u003C/span>=\u003Cspan class=\"emphasis\">\u003Cem>&lt;value&gt;\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFor example, to enable the port power saving mechanism and set the generation of receive interrupts to 4 units, enter:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">\u003Cspan class=\"strong strong\">\u003Cstrong>options \u003Cspan class=\"emphasis\">\u003Cem>e1000e SmartPowerDownEnable=1 RxIntDelay=4\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tUnload the module:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>modprobe -r \u003Cspan class=\"emphasis\">\u003Cem>e1000e\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003Crh-alert class=\"admonition warning\" state=\"danger\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Warning\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\t\tUnloading a module that an active network interface uses, immediately terminates the connection and you can lock yourself out of the server.\n\t\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tLoad the module:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>modprobe \u003Cspan class=\"emphasis\">\u003Cem>e1000e\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tReactivate the network connections:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>nmcli connection up \u003Cspan class=\"emphasis\">\u003Cem>&lt;profile_name&gt;\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tDisplay the kernel messages:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>dmesg\u003C/strong>\u003C/span>\n...\n[35309.225765] e1000e 0000:00:1f.6: Transmit Interrupt Delay set to 16\n[35309.225769] e1000e 0000:00:1f.6: PHY Smart Power Down Enabled\n...\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tNote that not all modules log parameter settings to the kernel ring buffer.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tCertain kernel modules create files for each module parameter in the \u003Ccode class=\"literal\">/sys/module/\u003Cspan class=\"emphasis\">\u003Cem>&lt;driver&gt;\u003C/em>\u003C/span>/parameters/\u003C/code> directory. Each of these files contain the current value of this parameter. You can display these files to verify a setting:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>cat /sys/module/\u003Cspan class=\"emphasis\">\u003Cem>&lt;driver_name&gt;\u003C/em>\u003C/span>/parameters/\u003Cspan class=\"emphasis\">\u003Cem>&lt;parameter_name&gt;\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"section\" id=\"configuring-network-adapter-offload-settings_tuning-the-network-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">31.11. Configuring network adapter offload settings\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tTo reduce CPU load, certain network adapters use offloading features which move the network processing load to the network interface controller (NIC). For example, with Encapsulating Security Payload (ESP) offload, the NIC performs ESP operations to accelerate IPsec connections and reduce CPU load.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tBy default, most offloading features in Red Hat Enterprise Linux are enabled. Only disable them in the following cases:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tTemporarily disable offload features for troubleshooting purposes.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tPermanently disable offload features when a specific feature negatively impacts your host.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tIf a performance-related offload feature is not enabled by default in a network driver, you can enable it manually.\n\t\t\t\u003C/p>\u003Csection class=\"section\" id=\"temporarily-setting-an-offload-feature_configuring-network-adapter-offload-settings\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">31.11.1. Temporarily setting an offload feature\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tIf you expect that an offload feature causes problems or reduces the performance of your host, you can attempt to narrow down the cause by temporarily enabling or disabling it, depending on its current state.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tIf you temporarily enable or disable an offload feature, it returns to its previous value on the next reboot.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tThe network card supports offload features.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tDisplay the interface’s available offload features and their current state:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ethtool -k \u003Cspan class=\"emphasis\">\u003Cem>enp1s0\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\n...\n\u003Cspan class=\"emphasis\">\u003Cem>esp-hw-offload: on\u003C/em>\u003C/span>\n\u003Cspan class=\"emphasis\">\u003Cem>ntuple-filters: off\u003C/em>\u003C/span>\n\u003Cspan class=\"emphasis\">\u003Cem>rx-vlan-filter: off [fixed]\u003C/em>\u003C/span>\n...\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe output depends on the capabilities of the hardware and its driver. Note that you cannot change the state of features that are flagged with \u003Ccode class=\"literal\">[fixed]\u003C/code>.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tTemporarily disable an offload feature:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ethtool -K \u003Cspan class=\"emphasis\">\u003Cem>&lt;interface&gt;\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>&lt;feature&gt;\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>[on|off]\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tFor example, to temporarily disable IPsec Encapsulating Security Payload (ESP) offload on the \u003Ccode class=\"literal\">enp10s0u1\u003C/code> interface, enter:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ethtool -K \u003Cspan class=\"emphasis\">\u003Cem>enp10s0u1\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>esp-hw-offload\u003C/em>\u003C/span> off\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tFor example, to temporarily enable accelerated Receive Flow Steering (aRFS) filtering on the \u003Ccode class=\"literal\">enp10s0u1\u003C/code> interface, enter:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ethtool -K \u003Cspan class=\"emphasis\">\u003Cem>enp10s0u1\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>ntuple-filters\u003C/em>\u003C/span> on\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tDisplay the states of the offload features:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ethtool -k \u003Cspan class=\"emphasis\">\u003Cem>enp1s0\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\n...\n\u003Cspan class=\"emphasis\">\u003Cem>esp-hw-offload: off\u003C/em>\u003C/span>\n\u003Cspan class=\"emphasis\">\u003Cem>ntuple-filters: on\u003C/em>\u003C/span>\n...\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tTest whether the problem you encountered before changing the offload feature still exists.\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tIf the problem no longer exists after changing a specific offload feature:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"i\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\tContact \u003Ca class=\"link\" href=\"https://access.redhat.com/support\">Red Hat Support\u003C/a> and report the problem.\n\t\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\tConsider \u003Ca class=\"link\" href=\"#permanently-setting-an-offload-feature_configuring-network-adapter-offload-settings\" title=\"31.11.2. Permanently setting an offload feature\">permanently setting the offload feature\u003C/a> until a fix is available.\n\t\t\t\t\t\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tIf the problem still exists after disabling a specific offload feature:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"i\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\tReset the setting to its previous state by using the \u003Ccode class=\"literal\">ethtool -K \u003Cspan class=\"emphasis\">\u003Cem>&lt;interface&gt;\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>&lt;feature&gt;\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>[on|off]\u003C/em>\u003C/span>\u003C/code> command.\n\t\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\tEnable or disable a different offload feature to narrow down the problem.\n\t\t\t\t\t\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ccode class=\"literal\">ethtool(8)\u003C/code> man page on your system\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"permanently-setting-an-offload-feature_configuring-network-adapter-offload-settings\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">31.11.2. Permanently setting an offload feature\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tIf you have identified a specific offload feature that limits the performance on your host, you can permanently enable or disable it, depending on its current state.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tIf you permanently enable or disable an offload feature, NetworkManager ensures that the feature still has this state after a reboot.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tYou identified a specific offload feature to limit the performance on your host.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIdentify the connection profile that uses the network interface on which you want to change the state of the offload feature:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>nmcli connection show\u003C/strong>\u003C/span>\nNAME     UUID                                  TYPE      DEVICE\n\u003Cspan class=\"emphasis\">\u003Cem>Example\u003C/em>\u003C/span>  \u003Cspan class=\"emphasis\">\u003Cem>a5eb6490-cc20-3668-81f8-0314a27f3f75\u003C/em>\u003C/span>  ethernet  \u003Cspan class=\"emphasis\">\u003Cem>enp1ss0\u003C/em>\u003C/span>\n...\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tPermanently change the state of the offload feature:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>nmcli connection modify \u003Cspan class=\"emphasis\">\u003Cem>&lt;connection_name&gt;\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>&lt;feature&gt;\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>[on|off]\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tFor example, to permanently disable IPsec Encapsulating Security Payload (ESP) offload in the \u003Ccode class=\"literal\">Example\u003C/code> connection profile, enter:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>nmcli connection modify \u003Cspan class=\"emphasis\">\u003Cem>Example\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>ethtool.feature-esp-hw-offload\u003C/em>\u003C/span> off\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tFor example, to permanently enable accelerated Receive Flow Steering (aRFS) filtering in the \u003Ccode class=\"literal\">Example\u003C/code> connection profile, enter:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>nmcli connection modify \u003Cspan class=\"emphasis\">\u003Cem>Example\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>ethtool.feature-ntuple\u003C/em>\u003C/span> on\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tReactivate the connection profile:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>nmcli connection up \u003Cspan class=\"emphasis\">\u003Cem>Example\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tDisplay the output states of the offload features:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ethtool -k \u003Cspan class=\"emphasis\">\u003Cem>enp1s0\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\n...\n\u003Cspan class=\"emphasis\">\u003Cem>esp-hw-offload: off\u003C/em>\u003C/span>\n\u003Cspan class=\"emphasis\">\u003Cem>ntuple-filters: on\u003C/em>\u003C/span>\n...\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ccode class=\"literal\">nm-settings-nmcli(5)\u003C/code> man page on your system\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"section\" id=\"tuning-interrupt-coalescence-settings_tuning-the-network-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">31.12. Tuning interrupt coalescence settings\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tInterrupt coalescence is a mechanism for reducing the number of interrupts generated by a network card. Generally, fewer interrupts can enhance the latency and overall performance of your network.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tTuning the interrupt coalescence settings involves adjusting the parameters that control:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe number of packets that are combined into a single interrupt.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe delay before generating an interrupt.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tThe optimal coalescence settings depend on the specific network conditions and hardware in use. Therefore, it might take several attempts to find the settings that work best for your environment and needs.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Csection class=\"section\" id=\"optimizing-rhel-for-latency-or-throughput-sensitive-services_tuning-interrupt-coalescence-settings\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch4 class=\"title\">31.12.1. Optimizing RHEL for latency or throughput-sensitive services\u003C/h4>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\t\tThe goal of coalesce tuning is to minimize the number of interrupts required for a given workload. In high-throughput situations, the goal is to have as few interrupts as possible while maintaining a high data rate. In low-latency situations, more interrupts can be used to handle traffic quickly.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tYou can adjust the settings on your network card to increase or decrease the number of packets that are combined into a single interrupt. As a result, you can achieve improved throughput or latency for your traffic.\n\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIdentify the network interface that is experiencing the bottleneck:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ethtool -S \u003Cspan class=\"emphasis\">\u003Cem>enp1s0\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\nNIC statistics:\n     rx_packets: 1234\n     tx_packets: 5678\n     rx_bytes: 12345678\n     tx_bytes: 87654321\n     rx_errors: 0\n     tx_errors: 0\n     rx_missed: 0\n     tx_dropped: 0\n     coalesced_pkts: 0\n     coalesced_events: 0\n     coalesced_aborts: 0\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIdentify the packet counters containing \"drop\", \"discard\", or \"error\" in their name. These particular statistics measure the actual packet loss at the network interface card (NIC) packet buffer, which can be caused by NIC coalescence.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tMonitor values of packet counters you identified in the previous step.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tCompare them to the expected values for your network to determine whether any particular interface experiences a bottleneck. Some common signs of a network bottleneck include, but are not limited to:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tMany errors on a network interface\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tHigh packet loss\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tHeavy usage of the network interface\n\t\t\t\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\t\t\t\tOther important factors are for example CPU usage, memory usage, and disk I/O when identifying a network bottleneck.\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tView the current coalescence settings:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ethtool enp1s0\u003C/strong>\u003C/span>\nSettings for enp1s0:\n        Supported ports: [ TP ]\n        Supported link modes:   10baseT/Half 10baseT/Full\n                                100baseT/Half 100baseT/Full\n                                1000baseT/Full\n        Supported pause frame use: No\n        Supports auto-negotiation: Yes\n        Advertised link modes:  10baseT/Half 10baseT/Full\n                                100baseT/Half 100baseT/Full\n                                1000baseT/Full\n        Advertised pause frame use: No\n        Advertised auto-negotiation: Yes\n        Speed: 1000Mb/s\n        Duplex: Full\n        Port: Twisted Pair\n        PHYAD: 0\n        Transceiver: internal\n        Auto-negotiation: on\n        MDI-X: Unknown\n        Supports Wake-on: g\n        Wake-on: g\n        Current message level: 0x00000033 (51)\n                               drv probe link\n        Link detected: yes\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIn this output, monitor the \u003Ccode class=\"literal\">Speed\u003C/code> and \u003Ccode class=\"literal\">Duplex\u003C/code> fields. These fields display information about the network interface operation and whether it is running at its expected values.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tCheck the current interrupt coalescence settings:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ethtool -c enp1s0\u003C/strong>\u003C/span>\nCoalesce parameters for enp1s0:\n        Adaptive RX: off\n        Adaptive TX: off\n        RX usecs: 100\n        RX frames: 8\n        RX usecs irq: 100\n        RX frames irq: 8\n        TX usecs: 100\n        TX frames: 8\n        TX usecs irq: 100\n        TX frames irq: 8\u003C/pre>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">usecs\u003C/code> values refer to the number of microseconds that the receiver or transmitter waits before generating an interrupt.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">frames\u003C/code> values refer to the number of frames that the receiver or transmitter waits before generating an interrupt.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">irq\u003C/code> values are used to configure the interrupt moderation when the network interface is already handling an interrupt.\n\t\t\t\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\t\t\t\tNot all network interface cards support reporting and changing all values from the example output.\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">Adaptive RX/TX\u003C/code> value represents the adaptive interrupt coalescence mechanism, which adjusts the interrupt coalescence settings dynamically. Based on the packet conditions, the NIC driver auto-calculates coalesce values when \u003Ccode class=\"literal\">Adaptive RX/TX\u003C/code> are enabled (the algorithm differs for every NIC driver).\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tModify the coalescence settings as needed. For example:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tWhile \u003Ccode class=\"literal\">ethtool.coalesce-adaptive-rx\u003C/code> is disabled, configure \u003Ccode class=\"literal\">ethtool.coalesce-rx-usecs\u003C/code> to set the delay before generating an interrupt to 100 microseconds for the RX packets:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>nmcli connection modify enp1s0 ethtool.coalesce-rx-usecs \u003Cspan class=\"emphasis\">\u003Cem>100\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tEnable \u003Ccode class=\"literal\">ethtool.coalesce-adaptive-rx\u003C/code> while \u003Ccode class=\"literal\">ethtool.coalesce-rx-usecs\u003C/code> is set to its default value:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>nmcli connection modify enp1s0 ethtool.coalesce-adaptive-rx on\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tModify the Adaptive-RX setting as follows:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\tUsers concerned with low latency (sub-50us) should not enable \u003Ccode class=\"literal\">Adaptive-RX\u003C/code>.\n\t\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\tUsers concerned with throughput can probably enable \u003Ccode class=\"literal\">Adaptive-RX\u003C/code> with no harm. If they do not want to use the adaptive interrupt coalescence mechanism, they can try setting large values like 100us, or 250us to \u003Ccode class=\"literal\">ethtool.coalesce-rx-usecs\u003C/code>.\n\t\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\tUsers unsure about their needs should not modify this setting until an issue occurs.\n\t\t\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tRe-activate the connection:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>nmcli connection up enp1s0\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tMonitor the network performance and check for dropped packets:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ethtool -S enp1s0\u003C/strong>\u003C/span>\nNIC statistics:\n     rx_packets: 1234\n     tx_packets: 5678\n     rx_bytes: 12345678\n     tx_bytes: 87654321\n     rx_errors: 0\n     tx_errors: 0\n     rx_missed: 0\n     tx_dropped: 0\n     coalesced_pkts: 12\n     coalesced_events: 34\n     coalesced_aborts: 56\n...\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe value of the \u003Ccode class=\"literal\">rx_errors\u003C/code>, \u003Ccode class=\"literal\">rx_dropped\u003C/code>, \u003Ccode class=\"literal\">tx_errors\u003C/code>, and \u003Ccode class=\"literal\">tx_dropped\u003C/code> fields should be 0 or close to it (up to few hundreds, depending on the network traffic and system resources). A high value in these fields indicates a network problem. Your counters can have different names. Closely monitor packet counters containing \"drop\", \"discard\", or \"error\" in their name.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe value of the \u003Ccode class=\"literal\">rx_packets\u003C/code>, \u003Ccode class=\"literal\">tx_packets\u003C/code>, \u003Ccode class=\"literal\">rx_bytes\u003C/code>, and \u003Ccode class=\"literal\">tx_bytes\u003C/code> should increase over time. If the values do not increase, there might be a network problem. The packet counters can have different names, depending on your NIC driver.\n\t\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">ethtool\u003C/code> command output can vary depending on the NIC and driver in use.\n\t\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tUsers with focus on extremely low latency can use application-level metrics or the kernel packet time-stamping API for their monitoring purposes.\n\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/articles/1162133\">Initial investigation for any performance issue\u003C/a>\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/solutions/108513\">What are the kernel parameters available for network tuning?\u003C/a> (Red Hat Knowledgebase)\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/solutions/2127401\">How to make NIC ethtool settings persistent (apply automatically at boot)\u003C/a> (Red Hat Knowledgebase)\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://www.kernel.org/doc/html/latest/networking/timestamping.html\">Timestamping\u003C/a>\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"section\" id=\"benefits-of-tcp-timestamps_tuning-the-network-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">31.13. Benefits of TCP Timestamps\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tTCP Timestamps are optional information in the TCP header and an extension of the TCP protocol. By default, TCP Timestamps are enabled in Red Hat Enterprise Linux, and the kernel uses TCP Timestamps to better estimate the round trip time (RTT) in TCP connections. This results in more accurate TCP window and buffer calculations.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tAdditionally, TCP Timestamps provide an alternative method to determine the age and order of a segment, and protect against wrapped sequence numbers. TCP packet headers record the sequence number in a 32-bit field. On a 10 Gbps connection, the value of this field can wrap after 1.7 seconds. Without TCP Timestamps, the receiver could not determine whether a segment with a wrapped sequence number is a new segment or an old duplicate. With TCP Timestamps, however, the receiver can make the correct choice to receive or discard the segment. Therefore, enabling TCP Timestamps on systems with fast network interfaces is essential.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe \u003Ccode class=\"literal\">net.ipv4.tcp_timestamps\u003C/code> kernel parameter can have one of the following values:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">0\u003C/code>: TCP Timestamps are disabled.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">1\u003C/code>: TCP Timestamps are enabled (default).\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">2\u003C/code>: TCP Timestamps are enabled but without random offsets.\n\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\tWithout random offsets for each connection, it is possible to approximately determine the host’s uptime and fingerprint and use this information in attacks.\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tBy default, TCP Timestamps are enabled in Red Hat Enterprise Linux and use random offsets for each connection instead of only storing the current time:\n\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>sysctl net.ipv4.tcp_timestamps\u003C/strong>\u003C/span>\nnet.ipv4.tcp_timestamps = 1\u003C/pre>\u003Cp>\n\t\t\t\tIf the \u003Ccode class=\"literal\">net.ipv4.tcp_timestamps\u003C/code> parameter has a different value than the default (\u003Ccode class=\"literal\">1\u003C/code>), revert the setting in the same way as you set it.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://www.rfc-editor.org/rfc/rfc1323\">RFC 1323: TCP Extensions for High Performance\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"ref_flow-control-in-ethernet-networks_tuning-the-network-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">31.14. Flow control for Ethernet networks\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tOn an Ethernet link, continuous data transmission between a network interface and a switch port can lead to full buffer capacity. Full buffer capacity results in network congestion. In this case, when the sender transmits data at a higher rate than the processing capacity of the receiver, packet loss can occur due to the lower data processing capacity of a network interface on the other end of the link which is a switch port.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe flow control mechanism manages data transmission across the Ethernet link where each sender and receiver has different sending and receiving capacities. To avoid packet loss, the Ethernet flow control mechanism temporarily suspends the packet transmission to manage a higher transmission rate from a switch port. Note that routers do not forward pause frames beyond a switch port.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tWhen receive (RX) buffers become full, a receiver sends pause frames to the transmitter. The transmitter then stops data transmission for a short sub-second time frame, while continuing to buffer incoming data during this pause period. This duration provides enough time for the receiver to empty its interface buffers and prevent buffer overflow.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tEither end of the Ethernet link can send pause frames to another end. If the receive buffers of a network interface are full, the network interface will send pause frames to the switch port. Similarly, when the receive buffers of a switch port are full, the switch port sends pause frames to the network interface.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cp>\n\t\t\t\tBy default, most of the network drivers in Red Hat Enterprise Linux have pause frame support enabled. To display the current settings of a network interface, enter:\n\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ethtool --show-pause \u003Cspan class=\"emphasis\">\u003Cem>enp1s0\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\nPause parameters for enp1s0:\n...\nRX:     on\nTX:     on\n...\u003C/pre>\u003Cp>\n\t\t\t\tVerify with your switch vendor to confirm if your switch supports pause frames.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">ethtool(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/solutions/68817\">What is network link flow control and how does it work in Red Hat Enterprise Linux?\u003C/a> (Red Hat Knowledgebase)\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"factors-affecting-i-o-and-file-system-performance_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 32. Factors affecting I/O and file system performance\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tThe appropriate settings for storage and file system performance are highly dependent on the storage purpose.\n\t\t\u003C/p>\u003Cp>\n\t\t\tI/O and file system performance can be affected by any of the following factors:\n\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\tData write or read patterns\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tSequential or random\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tBuffered or Direct IO\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tData alignment with underlying geometry\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tBlock size\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tFile system size\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tJournal size and location\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tRecording access times\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tEnsuring data reliability\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tPre-fetching data\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tPre-allocating disk space\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tFile fragmentation\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tResource contention\n\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Csection class=\"section\" id=\"tools-for-monitoring-and-diagnosing-i-o-and-file-system-issues_factors-affecting-i-o-and-file-system-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">32.1. Tools for monitoring and diagnosing I/O and file system issues\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe following tools are available in Red Hat Enterprise Linux 9 for monitoring system performance and diagnosing performance problems related to I/O, file systems, and their configuration:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">vmstat\u003C/code> tool reports on processes, memory, paging, block I/O, interrupts, and CPU activity across the entire system. It can help administrators determine whether the I/O subsystem is responsible for any performance issues. If analysis with \u003Ccode class=\"literal\">vmstat\u003C/code> shows that the I/O subsystem is responsible for reduced performance, administrators can use the \u003Ccode class=\"literal\">iostat\u003C/code> tool to determine the responsible I/O device.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">iostat\u003C/code> reports on I/O device load in your system. It is provided by the \u003Ccode class=\"literal\">sysstat\u003C/code> package.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">blktrace\u003C/code> provides detailed information about how time is spent in the I/O subsystem. The companion utility \u003Ccode class=\"literal\">blkparse\u003C/code> reads the raw output from \u003Ccode class=\"literal\">blktrace\u003C/code> and produces a human readable summary of input and output operations recorded by \u003Ccode class=\"literal\">blktrace\u003C/code>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">btt\u003C/code> analyzes \u003Ccode class=\"literal\">blktrace\u003C/code> output and displays the amount of time that data spends in each area of the I/O stack, making it easier to spot bottlenecks in the I/O subsystem. This utility is provided as part of the \u003Ccode class=\"literal\">blktrace\u003C/code> package. Some of the important events tracked by the \u003Ccode class=\"literal\">blktrace\u003C/code> mechanism and analyzed by \u003Ccode class=\"literal\">btt\u003C/code> are:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tQueuing of the I/O event (\u003Ccode class=\"literal\">Q\u003C/code>)\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tDispatch of the I/O to the driver event (\u003Ccode class=\"literal\">D\u003C/code>)\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tCompletion of I/O event (\u003Ccode class=\"literal\">C\u003C/code>)\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">iowatcher\u003C/code> can use the \u003Ccode class=\"literal\">blktrace\u003C/code> output to graph I/O over time. It focuses on the Logical Block Address (LBA) of disk I/O, throughput in megabytes per second, the number of seeks per second, and I/O operations per second. This can help to identify when you are hitting the operations-per-second limit of a device.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tBPF Compiler Collection (BCC) is a library, which facilitates the creation of the extended Berkeley Packet Filter (\u003Ccode class=\"literal\">eBPF\u003C/code>) programs. The \u003Ccode class=\"literal\">eBPF\u003C/code> programs are triggered on events, such as disk I/O, TCP connections, and process creations. The BCC tools are installed in the \u003Ccode class=\"literal\">/usr/share/bcc/tools/\u003C/code> directory. The following \u003Ccode class=\"literal\">bcc-tools\u003C/code> helps to analyze performance:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">biolatency\u003C/code> summarizes the latency in block device I/O (disk I/O) in histogram. This allows the distribution to be studied, including two modes for device cache hits and for cache misses, and latency outliers.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">biosnoop\u003C/code> is a basic block I/O tracing tool for displaying each I/O event along with the issuing process ID, and the I/O latency. Using this tool, you can investigate disk I/O performance issues.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">biotop\u003C/code> is used for block i/o operations in the kernel.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">filelife\u003C/code> tool traces the \u003Ccode class=\"literal\">stat()\u003C/code> syscalls.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">fileslower\u003C/code> traces slow synchronous file reads and writes.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">filetop\u003C/code> displays file reads and writes by process.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">ext4slower\u003C/code>, \u003Ccode class=\"literal\">nfsslower\u003C/code>, and \u003Ccode class=\"literal\">xfsslower\u003C/code> are tools that show file system operations slower than a certain threshold, which defaults to \u003Ccode class=\"literal\">10ms\u003C/code>.\n\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tFor more information, see the \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/managing_monitoring_and_updating_the_kernel/analyzing-system-performance-with-bpf-compiler_collection_managing-monitoring-and-updating-the-kernel\">Analyzing system performance with BPF Compiler Collection\u003C/a>.\n\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">bpftace\u003C/code> is a tracing language for \u003Ccode class=\"literal\">eBPF\u003C/code> used for analyzing performance issues. It also provides trace utilities like BCC for system observation, which is useful for investigating I/O performance issues.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe following \u003Ccode class=\"literal\">SystemTap\u003C/code> scripts may be useful in diagnosing storage or file system performance problems:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">disktop.stp\u003C/code>: Checks the status of reading or writing disk every 5 seconds and outputs the top ten entries during that period.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">iotime.stp\u003C/code>: Prints the amount of time spent on read and write operations, and the number of bytes read and written.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">traceio.stp\u003C/code>: Prints the top ten executable based on cumulative I/O traffic observed, every second.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">traceio2.stp\u003C/code>: Prints the executable name and process identifier as reads and writes to the specified device occur.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">Inodewatch.stp\u003C/code>: Prints the executable name and process identifier each time a read or write occurs to the specified inode on the specified major or minor device.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">inodewatch2.stp\u003C/code>: Prints the executable name, process identifier, and attributes each time the attributes are changed on the specified inode on the specified major or minor device.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">vmstat(8)\u003C/code>, \u003Ccode class=\"literal\">iostat(1)\u003C/code>, \u003Ccode class=\"literal\">blktrace(8)\u003C/code>, \u003Ccode class=\"literal\">blkparse(1)\u003C/code>, \u003Ccode class=\"literal\">btt(1)\u003C/code>, \u003Ccode class=\"literal\">bpftrace\u003C/code>, and \u003Ccode class=\"literal\">iowatcher(1)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index#configuring-an-operating-system-to-optimize-memory-access_monitoring-and-managing-system-status-and-performance\">Analyzing system performance with BPF Compiler Collection\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"available-tuning-options-for-formatting-a-file-system_factors-affecting-i-o-and-file-system-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">32.2. Available tuning options for formatting a file system\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tSome file system configuration decisions cannot be changed after the device is formatted.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe following are the options available before formatting a storage device:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Size\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tCreate an appropriately-sized file system for your workload. Smaller file systems require less time and memory for file system checks. However, if a file system is too small, its performance suffers from high fragmentation.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Block size\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe block is the unit of work for the file system. The block size determines how much data can be stored in a single block, and therefore the smallest amount of data that is written or read at one time.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe default block size is appropriate for most use cases. However, your file system performs better and stores data more efficiently if the block size or the size of multiple blocks is the same as or slightly larger than the amount of data that is typically read or written at one time. A small file still uses an entire block. Files can be spread across multiple blocks, but this can create additional runtime overhead.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tAdditionally, some file systems are limited to a certain number of blocks, which in turn limits the maximum size of the file system. Block size is specified as part of the file system options when formatting a device with the \u003Ccode class=\"literal\">mkfs\u003C/code> command. The parameter that specifies the block size varies with the file system.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Geometry\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFile system geometry is concerned with the distribution of data across a file system. If your system uses striped storage, like RAID, you can improve performance by aligning data and metadata with the underlying storage geometry when you format the device.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tMany devices export recommended geometry, which is then set automatically when the devices are formatted with a particular file system. If your device does not export these recommendations, or you want to change the recommended settings, you must specify geometry manually when you format the device with the \u003Ccode class=\"literal\">mkfs\u003C/code> command.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe parameters that specify file system geometry vary with the file system.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">External journals\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tJournaling file systems document the changes that will be made during a write operation in a journal file prior to the operation being executed. This reduces the likelihood that a storage device will become corrupted in the event of a system crash or power failure, and speeds up the recovery process.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tRed Hat does not recommend using the external journals option.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cp>\n\t\t\t\tMetadata-intensive workloads involve very frequent updates to the journal. A larger journal uses more memory, but reduces the frequency of write operations. Additionally, you can improve the seek time of a device with a metadata-intensive workload by placing its journal on dedicated storage that is as fast as, or faster than, the primary storage.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition warning\" state=\"danger\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Warning\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tEnsure that external journals are reliable. Losing an external journal device causes file system corruption. External journals must be created at format time, with journal devices being specified at mount time.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">mkfs(8)\u003C/code> and \u003Ccode class=\"literal\">mount(8)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_file_systems/index#overview-of-available-file-systems_managing-file-systems\">Overview of available file systems\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"available-tuning-options-for-mounting-a-file-system_factors-affecting-i-o-and-file-system-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">32.3. Available tuning options for mounting a file system\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe following are the options available to most file systems and can be specified as the device is mounted:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Access Time\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tEvery time a file is read, its metadata is updated with the time at which access occurred (\u003Ccode class=\"literal\">atime\u003C/code>). This involves additional write I/O. The \u003Ccode class=\"literal\">relatime\u003C/code> is the default \u003Ccode class=\"literal\">atime\u003C/code> setting for most file systems.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tHowever, if updating this metadata is time consuming, and if accurate access time data is not required, you can mount the file system with the \u003Ccode class=\"literal\">noatime\u003C/code> mount option. This disables updates to metadata when a file is read. It also enables \u003Ccode class=\"literal\">nodiratime\u003C/code> behavior, which disables updates to metadata when a directory is read.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003C/dl>\u003C/div>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tDisabling \u003Ccode class=\"literal\">atime\u003C/code> updates by using the \u003Ccode class=\"literal\">noatime mount\u003C/code> option can break applications that rely on them, for example, backup programs.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Read-ahead\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\u003Ccode class=\"literal\">Read-ahead\u003C/code> behavior speeds up file access by pre-fetching data that is likely to be needed soon and loading it into the page cache, where it can be retrieved more quickly than if it were on disk. The higher the read-ahead value, the further ahead the system pre-fetches data.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tRed Hat Enterprise Linux attempts to set an appropriate read-ahead value based on what it detects about your file system. However, accurate detection is not always possible. For example, if a storage array presents itself to the system as a single LUN, the system detects the single LUN, and does not set the appropriate read-ahead value for an array.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tWorkloads that involve heavy streaming of sequential I/O often benefit from high read-ahead values. The storage-related tuned profiles provided with Red Hat Enterprise Linux raise the read-ahead value, as does using LVM striping, but these adjustments are not always sufficient for all workloads.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">mount(8)\u003C/code>, \u003Ccode class=\"literal\">xfs(5)\u003C/code>, and \u003Ccode class=\"literal\">ext4(5)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"types-of-discarding-unused-blocks_factors-affecting-i-o-and-file-system-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">32.4. Types of discarding unused blocks\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tRegularly discarding blocks that are not in use by the file system is a recommended practice for both solid-state disks and thinly-provisioned storage.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe following are the two methods of discarding unused blocks:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Batch discard\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThis type of discard is part of the \u003Ccode class=\"literal\">fstrim\u003C/code> command. It discards all unused blocks in a file system that match criteria specified by the administrator. Red Hat Enterprise Linux 9 supports batch discard on XFS and ext4 formatted devices that support physical discard operations.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Online discard\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThis type of discard operation is configured at mount time with the discard option, and runs in real time without user intervention. However, it only discards blocks that are transitioning from used to free. Red Hat Enterprise Linux 9 supports online discard on XFS and ext4 formatted devices.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tRed Hat recommends batch discard, except where online discard is required to maintain performance, or where batch discard is not feasible for the system’s workload.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003C/dl>\u003C/div>\u003Cp>\n\t\t\t\tPre-allocation marks disk space as being allocated to a file without writing any data into that space. This can be useful in limiting data fragmentation and poor read performance. Red Hat Enterprise Linux 9 supports pre-allocating space on XFS, ext4, and GFS2 file systems. Applications can also benefit from pre-allocating space by using the \u003Ccode class=\"literal\">fallocate(2) glibc\u003C/code> call.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">mount(8)\u003C/code> and \u003Ccode class=\"literal\">fallocate(2)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"solid-state-disks-tuning-considerations_factors-affecting-i-o-and-file-system-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">32.5. Solid-state disks tuning considerations\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tSolid-state disks (SSD) use NAND flash chips rather than rotating magnetic platters to store persistent data. SSD provides a constant access time for data across their full Logical Block Address range, and does not incur measurable seek costs like their rotating counterparts. They are more expensive per gigabyte of storage space and have a lesser storage density, but they also have lower latency and greater throughput than HDDs.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tPerformance generally degrades as the used blocks on an SSD approach the capacity of the disk. The degree of degradation varies by vendor, but all devices experience degradation in this circumstance. Enabling discard behavior can help to alleviate this degradation. For more information, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance#types-of-discarding-unused-blocks_factors-affecting-i-o-and-file-system-performance\">Types of discarding unused blocks\u003C/a>.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe default I/O scheduler and virtual memory options are suitable for use with SSDs. Consider the following factors when configuring settings that can affect SSD performance:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">I/O Scheduler\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tAny I/O scheduler is expected to perform well with most SSDs. However, as with any other storage type, Red Hat recommends benchmarking to determine the optimal configuration for a given workload. When using SSDs, Red Hat advises changing the I/O scheduler only for benchmarking particular workloads. For instructions on how to switch between I/O schedulers, see the \u003Ccode class=\"literal\">/usr/share/doc/kernel-version/Documentation/block/switching-sched.txt\u003C/code> file.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFor single queue HBA, the default I/O scheduler is \u003Ccode class=\"literal\">deadline\u003C/code>. For multiple queue HBA, the default I/O scheduler is \u003Ccode class=\"literal\">none\u003C/code>. For information about how to set the I/O scheduler, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/setting-the-disk-scheduler_monitoring-and-managing-system-status-and-performance\">Setting the disk scheduler\u003C/a>.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Virtual Memory\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tLike the I/O scheduler, virtual memory (VM) subsystem requires no special tuning. Given the fast nature of I/O on SSD, try turning down the \u003Ccode class=\"literal\">vm_dirty_background_ratio\u003C/code> and \u003Ccode class=\"literal\">vm_dirty_ratio\u003C/code> settings, as increased write-out activity does not usually have a negative impact on the latency of other operations on the disk. However, this tuning can generate more overall I/O, and is therefore not generally recommended without workload-specific testing.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Swap\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tAn SSD can also be used as a swap device, and is likely to produce good page-out and page-in performance.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"generic-block-device-tuning-parameters_factors-affecting-i-o-and-file-system-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">32.6. Generic block device tuning parameters\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe generic tuning parameters listed here are available in the \u003Ccode class=\"literal\">/sys/block/sdX/queue/\u003C/code> directory.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe following listed tuning parameters are separate from I/O scheduler tuning, and are applicable to all I/O schedulers:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">add_random\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tSome I/O events contribute to the entropy pool for the \u003Ccode class=\"literal\">/dev/random\u003C/code>. This parameter can be set to \u003Ccode class=\"literal\">0\u003C/code> if the overhead of these contributions become measurable.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">iostats\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tBy default, \u003Ccode class=\"literal\">iostats\u003C/code> is enabled and the default value is \u003Ccode class=\"literal\">1\u003C/code>. Setting \u003Ccode class=\"literal\">iostats\u003C/code> value to \u003Ccode class=\"literal\">0\u003C/code> disables the gathering of I/O statistics for the device, which removes a small amount of overhead with the I/O path. Setting \u003Ccode class=\"literal\">iostats\u003C/code> to \u003Ccode class=\"literal\">0\u003C/code> might slightly improve performance for very high performance devices, such as certain NVMe solid-state storage devices. It is recommended to leave \u003Ccode class=\"literal\">iostats\u003C/code> enabled unless otherwise specified for the given storage model by the vendor.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIf you disable \u003Ccode class=\"literal\">iostats\u003C/code>, the I/O statistics for the device are no longer present within the \u003Ccode class=\"literal\">/proc/diskstats\u003C/code> file. The content of \u003Ccode class=\"literal\">/sys/diskstats\u003C/code> file is the source of I/O information for monitoring I/O tools, such as \u003Ccode class=\"literal\">sar\u003C/code> or \u003Ccode class=\"literal\">iostats\u003C/code>. Therefore, if you disable the \u003Ccode class=\"literal\">iostats\u003C/code> parameter for a device, the device is no longer present in the output of I/O monitoring tools.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">max_sectors_kb\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tSpecifies the maximum size of an I/O request in kilobytes. The default value is \u003Ccode class=\"literal\">512\u003C/code> KB. The minimum value for this parameter is determined by the logical block size of the storage device. The maximum value for this parameter is determined by the value of the \u003Ccode class=\"literal\">max_hw_sectors_kb\u003C/code>.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tRed Hat recommends \u003Ccode class=\"literal\">max_sectors_kb\u003C/code> to always be a multiple of the optimal I/O size and the internal erase block size. Use a value of \u003Ccode class=\"literal\">logical_block_size\u003C/code> for either parameter if they are zero or not specified by the storage device.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">nomerges\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tMost workloads benefit from request merging. However, disabling merges can be useful for debugging purposes. By default, the \u003Ccode class=\"literal\">nomerges\u003C/code> parameter is set to \u003Ccode class=\"literal\">0\u003C/code>, which enables merging. To disable simple one-hit merging, set \u003Ccode class=\"literal\">nomerges\u003C/code> to \u003Ccode class=\"literal\">1\u003C/code>. To disable all types of merging, set \u003Ccode class=\"literal\">nomerges\u003C/code> to \u003Ccode class=\"literal\">2\u003C/code>.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">nr_requests\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tIt is the maximum allowed number of the queued I/O. If the current I/O scheduler is \u003Ccode class=\"literal\">none\u003C/code>, this number can only be reduced; otherwise the number can be increased or reduced.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">optimal_io_size\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tSome storage devices report an optimal I/O size through this parameter. If this value is reported, Red Hat recommends that applications issue I/O aligned to and in multiples of the optimal I/O size wherever possible.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">read_ahead_kb\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tDefines the maximum number of kilobytes that the operating system may read ahead during a sequential read operation. As a result, the necessary information is already present within the kernel page cache for the next sequential read, which improves read I/O performance.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tDevice mappers often benefit from a high \u003Ccode class=\"literal\">read_ahead_kb\u003C/code> value. \u003Ccode class=\"literal\">128\u003C/code> KB for each device to be mapped is a good starting point, but increasing the \u003Ccode class=\"literal\">read_ahead_kb\u003C/code> value up to request queue’s \u003Ccode class=\"literal\">max_sectors_kb\u003C/code> of the disk might improve performance in application environments where sequential reading of large files takes place.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">rotational\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tSome solid-state disks do not correctly advertise their solid-state status, and are mounted as traditional rotational disks. Manually set the \u003Ccode class=\"literal\">rotational\u003C/code> value to \u003Ccode class=\"literal\">0\u003C/code> to disable unnecessary seek-reducing logic in the scheduler.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">rq_affinity\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe default value of the \u003Ccode class=\"literal\">rq_affinity\u003C/code> is \u003Ccode class=\"literal\">1\u003C/code>. It completes the I/O operations on one CPU core, which is in the same CPU group of the issued CPU core. To perform completions only on the processor that issued the I/O request, set the \u003Ccode class=\"literal\">rq_affinity\u003C/code> to \u003Ccode class=\"literal\">2\u003C/code>. To disable the mentioned two abilities, set it to \u003Ccode class=\"literal\">0\u003C/code>.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">scheduler\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tTo set the scheduler or scheduler preference order for a particular storage device, edit the \u003Ccode class=\"literal\">/sys/block/\u003Cspan class=\"emphasis\">\u003Cem>devname\u003C/em>\u003C/span>/queue/scheduler\u003C/code> file, where \u003Cspan class=\"emphasis\">\u003Cem>devname\u003C/em>\u003C/span> is the name of the device you want to configure.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"assembly_using-systemd-to-manage-resources-used-by-applications_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 33. Using systemd to manage resources used by applications\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\tRHEL 9 moves the resource management settings from the process level to the application level by binding the system of \u003Ccode class=\"literal\">cgroup\u003C/code> hierarchies with the \u003Ccode class=\"literal\">systemd\u003C/code> unit tree. Therefore, you can manage the system resources with the \u003Ccode class=\"literal\">systemctl\u003C/code> command, or by modifying the \u003Ccode class=\"literal\">systemd\u003C/code> unit files.\n\t\t\u003C/p>\u003Cp>\n\t\t\tTo achieve this, \u003Ccode class=\"literal\">systemd\u003C/code> takes various configuration options from the unit files or directly via the \u003Ccode class=\"literal\">systemctl\u003C/code> command. Then \u003Ccode class=\"literal\">systemd\u003C/code> applies those options to specific process groups by using the Linux kernel system calls and features like \u003Ccode class=\"literal\">cgroups\u003C/code> and \u003Ccode class=\"literal\">namespaces\u003C/code>.\n\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\tYou can review the full set of configuration options for \u003Ccode class=\"literal\">systemd\u003C/code> in the following manual pages:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">systemd.resource-control(5)\u003C/code>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">systemd.exec(5)\u003C/code>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/div>\u003C/rh-alert>\u003Csection class=\"section\" id=\"con_role-of-systemd-in-resource-management_assembly_using-systemd-to-manage-resources-used-by-applications\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">33.1. Role of systemd in resource management\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tThe core function of \u003Ccode class=\"literal\">systemd\u003C/code> is service management and supervision. The \u003Ccode class=\"literal\">systemd\u003C/code> system and service manager :\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tensures that managed services start at the right time and in the correct order during the boot process.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tensures that managed services run smoothly to use the underlying hardware platform optimally.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tprovides capabilities to define resource management policies.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tprovides capabilities to tune various options, which can improve the performance of the service.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tIn general, Red Hat recommends you use \u003Ccode class=\"literal\">systemd\u003C/code> for controlling the usage of system resources. You should manually configure the \u003Ccode class=\"literal\">cgroups\u003C/code> virtual file system only in special cases. For example, when you need to use \u003Ccode class=\"literal\">cgroup-v1\u003C/code> controllers that have no equivalents in \u003Ccode class=\"literal\">cgroup-v2\u003C/code> hierarchy.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/section>\u003Csection class=\"section\" id=\"distribution-models-of-system-sources_assembly_using-systemd-to-manage-resources-used-by-applications\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">33.2. Distribution models of system sources\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tTo modify the distribution of system resources, you can apply one or more of the following distribution models:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">Weights\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tYou can distribute the resource by adding up the weights of all sub-groups and giving each sub-group the fraction matching its ratio against the sum.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFor example, if you have 10 cgroups, each with weight of value 100, the sum is 1000. Each cgroup receives one tenth of the resource.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tWeight is usually used to distribute stateless resources. For example the \u003Cspan class=\"emphasis\">\u003Cem>CPUWeight=\u003C/em>\u003C/span> option is an implementation of this resource distribution model.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Limits\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tA cgroup can consume up to the configured amount of the resource. The sum of sub-group limits can exceed the limit of the parent cgroup. Therefore it is possible to overcommit resources in this model.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFor example the \u003Cspan class=\"emphasis\">\u003Cem>MemoryMax=\u003C/em>\u003C/span> option is an implementation of this resource distribution model.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Protections\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tYou can set up a protected amount of a resource for a cgroup. If the resource usage is below the protection boundary, the kernel will try not to penalize this cgroup in favor of other cgroups that compete for the same resource. An overcommit is also possible.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFor example the \u003Cspan class=\"emphasis\">\u003Cem>MemoryLow=\u003C/em>\u003C/span> option is an implementation of this resource distribution model.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Allocations\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tExclusive allocations of an absolute amount of a finite resource. An overcommit is not possible. An example of this resource type in Linux is the real-time budget.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">unit file option\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tA setting for resource control configuration.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFor example, you can configure CPU resource with options like \u003Cspan class=\"emphasis\">\u003Cem>CPUAccounting=\u003C/em>\u003C/span>, or \u003Cspan class=\"emphasis\">\u003Cem>CPUQuota=\u003C/em>\u003C/span>. Similarly, you can configure memory or I/O resources with options like \u003Cspan class=\"emphasis\">\u003Cem>AllowedMemoryNodes=\u003C/em>\u003C/span> and \u003Cspan class=\"emphasis\">\u003Cem>IOAccounting=\u003C/em>\u003C/span>.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003C/dl>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"proc_allocating-system-resources-using-systemd_assembly_using-systemd-to-manage-resources-used-by-applications\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">33.3. Allocating system resources using systemd\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tAllocating system resources by using systemd involves creating &amp; managing systemd services and units. This can be configured to start, stop, or restart at specific times or in response to certain system events.\n\t\t\t\u003C/p>\u003Cdiv class=\"formalpara\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cp>\n\t\t\t\t\tTo change the required value of the unit file option of your service, you can adjust the value in the unit file, or use the \u003Ccode class=\"literal\">systemctl\u003C/code> command:\n\t\t\t\t\u003C/p>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCheck the assigned values for the service of your choice.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl show --property &lt;\u003Cspan class=\"emphasis\">\u003Cem>unit file option\u003C/em>\u003C/span>&gt; &lt;\u003Cspan class=\"emphasis\">\u003Cem>service name\u003C/em>\u003C/span>&gt;\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tSet the required value of the CPU time allocation policy option:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl set-property &lt;\u003Cspan class=\"emphasis\">\u003Cem>service name\u003C/em>\u003C/span>&gt; &lt;\u003Cspan class=\"emphasis\">\u003Cem>unit file option\u003C/em>\u003C/span>&gt;=&lt;\u003Cspan class=\"emphasis\">\u003Cem>value\u003C/em>\u003C/span>&gt;\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCheck the newly assigned values for the service of your choice.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl show --property &lt;\u003Cspan class=\"emphasis\">\u003Cem>unit file option\u003C/em>\u003C/span>&gt; &lt;\u003Cspan class=\"emphasis\">\u003Cem>service name\u003C/em>\u003C/span>&gt;\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">systemd.resource-control(5)\u003C/code> and \u003Ccode class=\"literal\">systemd.exec(5)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"con_overview-of-systemd-hierarchy-for-cgroups_assembly_using-systemd-to-manage-resources-used-by-applications\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">33.4. Overview of systemd hierarchy for cgroups\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tOn the backend, the \u003Ccode class=\"literal\">systemd\u003C/code> system and service manager uses the \u003Ccode class=\"literal\">slice\u003C/code>, the \u003Ccode class=\"literal\">scope\u003C/code>, and the \u003Ccode class=\"literal\">service\u003C/code> units to organize and structure processes in the control groups. You can further modify this hierarchy by creating custom unit files or using the \u003Ccode class=\"literal\">systemctl\u003C/code> command. Also, \u003Ccode class=\"literal\">systemd\u003C/code> automatically mounts hierarchies for important kernel resource controllers at the \u003Ccode class=\"literal\">/sys/fs/cgroup/\u003C/code> directory.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tFor resource control, you can use the following three \u003Ccode class=\"literal\">systemd\u003C/code> unit types:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">Service\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tA process or a group of processes, which \u003Ccode class=\"literal\">systemd\u003C/code> started according to a unit configuration file.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tServices encapsulate the specified processes so that they can be started and stopped as one set. Services are named in the following way:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">\u003Cspan class=\"emphasis\">\u003Cem>&lt;name&gt;\u003C/em>\u003C/span>.service\u003C/pre>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Scope\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tA group of externally created processes. Scopes encapsulate processes that are started and stopped by the arbitrary processes through the \u003Ccode class=\"literal\">fork()\u003C/code> function and then registered by \u003Ccode class=\"literal\">systemd\u003C/code> at runtime. For example, user sessions, containers, and virtual machines are treated as scopes. Scopes are named as follows:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">\u003Cspan class=\"emphasis\">\u003Cem>&lt;name&gt;\u003C/em>\u003C/span>.scope\u003C/pre>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Slice\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tA group of hierarchically organized units. Slices organize a hierarchy in which scopes and services are placed.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe actual processes are contained in scopes or in services. Every name of a slice unit corresponds to the path to a location in the hierarchy.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe dash (\u003Ccode class=\"literal\">-\u003C/code>) character acts as a separator of the path components to a slice from the \u003Ccode class=\"literal\">-.slice\u003C/code> root slice. In the following example:\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">\u003Cspan class=\"emphasis\">\u003Cem>&lt;parent-name&gt;\u003C/em>\u003C/span>.slice\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\u003Ccode class=\"literal\">parent-name.slice\u003C/code> is a sub-slice of \u003Ccode class=\"literal\">parent.slice\u003C/code>, which is a sub-slice of the \u003Ccode class=\"literal\">-.slice\u003C/code> root slice. \u003Ccode class=\"literal\">parent-name.slice\u003C/code> can have its own sub-slice named \u003Ccode class=\"literal\">parent-name-name2.slice\u003C/code>, and so on.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003C/dl>\u003C/div>\u003Cp>\n\t\t\t\tThe \u003Ccode class=\"literal\">service\u003C/code>, the \u003Ccode class=\"literal\">scope\u003C/code>, and the \u003Ccode class=\"literal\">slice\u003C/code> units directly map to objects in the control group hierarchy. When these units are activated, they map directly to control group paths built from the unit names.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe following is an abbreviated example of a control group hierarchy:\n\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">Control group /:\n-.slice\n├─user.slice\n│ ├─user-42.slice\n│ │ ├─session-c1.scope\n│ │ │ ├─ 967 gdm-session-worker [pam/gdm-launch-environment]\n│ │ │ ├─1035 /usr/libexec/gdm-x-session gnome-session --autostart /usr/share/gdm/greeter/autostart\n│ │ │ ├─1054 /usr/libexec/Xorg vt1 -displayfd 3 -auth /run/user/42/gdm/Xauthority -background none -noreset -keeptty -verbose 3\n│ │ │ ├─1212 /usr/libexec/gnome-session-binary --autostart /usr/share/gdm/greeter/autostart\n│ │ │ ├─1369 /usr/bin/gnome-shell\n│ │ │ ├─1732 ibus-daemon --xim --panel disable\n│ │ │ ├─1752 /usr/libexec/ibus-dconf\n│ │ │ ├─1762 /usr/libexec/ibus-x11 --kill-daemon\n│ │ │ ├─1912 /usr/libexec/gsd-xsettings\n│ │ │ ├─1917 /usr/libexec/gsd-a11y-settings\n│ │ │ ├─1920 /usr/libexec/gsd-clipboard\n…​\n├─init.scope\n│ └─1 /usr/lib/systemd/systemd --switched-root --system --deserialize 18\n└─system.slice\n  ├─rngd.service\n  │ └─800 /sbin/rngd -f\n  ├─systemd-udevd.service\n  │ └─659 /usr/lib/systemd/systemd-udevd\n  ├─chronyd.service\n  │ └─823 /usr/sbin/chronyd\n  ├─auditd.service\n  │ ├─761 /sbin/auditd\n  │ └─763 /usr/sbin/sedispatch\n  ├─accounts-daemon.service\n  │ └─876 /usr/libexec/accounts-daemon\n  ├─example.service\n  │ ├─ 929 /bin/bash /home/jdoe/example.sh\n  │ └─4902 sleep 1\n  …​\u003C/pre>\u003Cp>\n\t\t\t\tThe example above shows that services and scopes contain processes and are placed in slices that do not contain processes of their own.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"citetitle citetitle\">\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_basic_system_settings/managing-systemd_configuring-basic-system-settings#managing-system-services-with-systemctl_managing-systemd\">Managing system services with systemctl\u003C/a>\u003C/span>\u003C/em>\u003C/span> in Red Hat Enterprise Linux\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"#what-kernel-resource-controllers-are_setting-limits-for-applications\" title=\"34.2. Introducing kernel resource controllers\">What are kernel resource controllers\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">systemd.resource-control(5)\u003C/code>, \u003Ccode class=\"literal\">systemd.exec(5)\u003C/code>, \u003Ccode class=\"literal\">cgroups(7)\u003C/code>, \u003Ccode class=\"literal\">fork()\u003C/code>, \u003Ccode class=\"literal\">fork(2)\u003C/code> manual pages\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_monitoring_and_updating_the_kernel/index#setting-limits-for-applications_managing-monitoring-and-updating-the-kernel\">Understanding cgroups\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"listing-systemd_units_assembly_using-systemd-to-manage-resources-used-by-applications\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">33.5. Listing systemd units\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tUse the \u003Ccode class=\"literal\">systemd\u003C/code> system and service manager to list its units.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tList all active units on the system with the \u003Ccode class=\"literal\">systemctl\u003C/code> utility. The terminal returns an output similar to the following example:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl\u003C/strong>\u003C/span>\nUNIT                                                LOAD   ACTIVE SUB       DESCRIPTION\n…​\ninit.scope                                          loaded active running   System and Service Manager\nsession-2.scope                                     loaded active running   Session 2 of user jdoe\nabrt-ccpp.service                                   loaded active exited    Install ABRT coredump hook\nabrt-oops.service                                   loaded active running   ABRT kernel log watcher\nabrt-vmcore.service                                 loaded active exited    Harvest vmcores for ABRT\nabrt-xorg.service                                   loaded active running   ABRT Xorg log watcher\n…​\n-.slice                                             loaded active active    Root Slice\nmachine.slice                                       loaded active active    Virtual Machine and Container Slice system-getty.slice                                                                       loaded active active    system-getty.slice\nsystem-lvm2\\x2dpvscan.slice                         loaded active active    system-lvm2\\x2dpvscan.slice\nsystem-sshd\\x2dkeygen.slice                         loaded active active    system-sshd\\x2dkeygen.slice\nsystem-systemd\\x2dhibernate\\x2dresume.slice         loaded active active    system-systemd\\x2dhibernate\\x2dresume&gt;\nsystem-user\\x2druntime\\x2ddir.slice                 loaded active active    system-user\\x2druntime\\x2ddir.slice\nsystem.slice                                        loaded active active    System Slice\nuser-1000.slice                                     loaded active active    User Slice of UID 1000\nuser-42.slice                                       loaded active active    User Slice of UID 42\nuser.slice                                          loaded active active    User and Session Slice\n…​\u003C/pre>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">UNIT\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\tA name of a unit that also reflects the unit position in a control group hierarchy. The units relevant for resource control are a \u003Cspan class=\"emphasis\">\u003Cem>slice\u003C/em>\u003C/span>, a \u003Cspan class=\"emphasis\">\u003Cem>scope\u003C/em>\u003C/span>, and a \u003Cspan class=\"emphasis\">\u003Cem>service\u003C/em>\u003C/span>.\n\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">LOAD\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\tIndicates whether the unit configuration file was properly loaded. If the unit file failed to load, the field contains the state \u003Cspan class=\"emphasis\">\u003Cem>error\u003C/em>\u003C/span> instead of \u003Cspan class=\"emphasis\">\u003Cem>loaded\u003C/em>\u003C/span>. Other unit load states are: \u003Cspan class=\"emphasis\">\u003Cem>stub\u003C/em>\u003C/span>, \u003Cspan class=\"emphasis\">\u003Cem>merged\u003C/em>\u003C/span>, and \u003Cspan class=\"emphasis\">\u003Cem>masked\u003C/em>\u003C/span>.\n\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">ACTIVE\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\tThe high-level unit activation state, which is a generalization of \u003Ccode class=\"literal\">SUB\u003C/code>.\n\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">SUB\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\tThe low-level unit activation state. The range of possible values depends on the unit type.\n\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">DESCRIPTION\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\tThe description of the unit content and functionality.\n\t\t\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tList all active and inactive units:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl --all\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tLimit the amount of information in the output:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl --type service,masked\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">--type\u003C/code> option requires a comma-separated list of unit types such as a \u003Cspan class=\"emphasis\">\u003Cem>service\u003C/em>\u003C/span> and a \u003Cspan class=\"emphasis\">\u003Cem>slice\u003C/em>\u003C/span>, or unit load states such as \u003Cspan class=\"emphasis\">\u003Cem>loaded\u003C/em>\u003C/span> and \u003Cspan class=\"emphasis\">\u003Cem>masked\u003C/em>\u003C/span>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"citetitle citetitle\">\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/configuring_basic_system_settings/managing-systemd_configuring-basic-system-settings#managing-system-services-with-systemctl_managing-systemd\">Managing system services with systemctl\u003C/a>\u003C/span>\u003C/em>\u003C/span> in RHEL\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">systemd.resource-control(5)\u003C/code>, \u003Ccode class=\"literal\">systemd.exec(5)\u003C/code> manual pages\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"viewing-systemd-control-group-hierarchy_assembly_using-systemd-to-manage-resources-used-by-applications\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">33.6. Viewing systemd cgroups hierarchy\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tDisplay control groups (\u003Ccode class=\"literal\">cgroups\u003C/code>) hierarchy and processes running in specific \u003Ccode class=\"literal\">cgroups\u003C/code>.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tDisplay the whole \u003Ccode class=\"literal\">cgroups\u003C/code> hierarchy on your system with the \u003Ccode class=\"literal\">systemd-cgls\u003C/code> command.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemd-cgls\u003C/strong>\u003C/span>\nControl group /:\n-.slice\n├─user.slice\n│ ├─user-42.slice\n│ │ ├─session-c1.scope\n│ │ │ ├─ 965 gdm-session-worker [pam/gdm-launch-environment]\n│ │ │ ├─1040 /usr/libexec/gdm-x-session gnome-session --autostart /usr/share/gdm/greeter/autostart\n…​\n├─init.scope\n│ └─1 /usr/lib/systemd/systemd --switched-root --system --deserialize 18\n└─system.slice\n  …​\n  ├─example.service\n  │ ├─6882 /bin/bash /home/jdoe/example.sh\n  │ └─6902 sleep 1\n  ├─systemd-journald.service\n    └─629 /usr/lib/systemd/systemd-journald\n  …​\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe example output returns the entire \u003Ccode class=\"literal\">cgroups\u003C/code> hierarchy, where the highest level is formed by \u003Cspan class=\"emphasis\">\u003Cem>slices\u003C/em>\u003C/span>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tDisplay the \u003Ccode class=\"literal\">cgroups\u003C/code> hierarchy filtered by a resource controller with the \u003Ccode class=\"literal\">systemd-cgls &lt;\u003Cspan class=\"emphasis\">\u003Cem>resource_controller\u003C/em>\u003C/span>&gt;\u003C/code> command.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemd-cgls memory\u003C/strong>\u003C/span>\nController memory; Control group /:\n├─1 /usr/lib/systemd/systemd --switched-root --system --deserialize 18\n├─user.slice\n│ ├─user-42.slice\n│ │ ├─session-c1.scope\n│ │ │ ├─ 965 gdm-session-worker [pam/gdm-launch-environment]\n…​\n└─system.slice\n  |\n  …​\n  ├─chronyd.service\n  │ └─844 /usr/sbin/chronyd\n  ├─example.service\n  │ ├─8914 /bin/bash /home/jdoe/example.sh\n  │ └─8916 sleep 1\n  …​\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe example output lists the services that interact with the selected controller.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tDisplay detailed information about a certain unit and its part of the \u003Ccode class=\"literal\">cgroups\u003C/code> hierarchy with the \u003Ccode class=\"literal\">systemctl status &lt;\u003Cspan class=\"emphasis\">\u003Cem>system_unit\u003C/em>\u003C/span>&gt;\u003C/code> command.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout white-space-pre\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl status example.service\u003C/strong>\u003C/span>\n● example.service - My example service\n   Loaded: loaded (/usr/lib/systemd/system/example.service; enabled; vendor preset: disabled)\n   Active: active (running) since Tue 2019-04-16 12:12:39 CEST; 3s ago\n Main PID: 17737 (bash)\n    Tasks: 2 (limit: 11522)\n   Memory: 496.0K (limit: 1.5M)\n   CGroup: /system.slice/example.service\n           ├─17737 /bin/bash /home/jdoe/example.sh\n           └─17743 sleep 1\nApr 16 12:12:39 redhat systemd[1]: Started My example service.\nApr 16 12:12:39 redhat bash[17737]: The current time is Tue Apr 16 12:12:39 CEST 2019\nApr 16 12:12:40 redhat bash[17737]: The current time is Tue Apr 16 12:12:40 CEST 2019\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">systemd.resource-control(5)\u003C/code> and \u003Ccode class=\"literal\">cgroups(7)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"proc_viewing-cgroups-of-processes_assembly_using-systemd-to-manage-resources-used-by-applications\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">33.7. Viewing cgroups of processes\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tYou can learn which \u003Cspan class=\"emphasis\">\u003Cem>control group\u003C/em>\u003C/span> (\u003Ccode class=\"literal\">cgroup\u003C/code>) a process belongs to. Then you can check the \u003Ccode class=\"literal\">cgroup\u003C/code> to find which controllers and controller-specific configurations it uses.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo view which \u003Ccode class=\"literal\">cgroup\u003C/code> a process belongs to, run the \u003Ccode class=\"literal\"># cat proc/&lt;\u003Cspan class=\"emphasis\">\u003Cem>PID\u003C/em>\u003C/span>&gt;/cgroup\u003C/code> command:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>cat /proc/2467/cgroup\u003C/strong>\u003C/span>\n0::/system.slice/example.service\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe example output relates to a process of interest. In this case, it is a process identified by \u003Ccode class=\"literal\">PID 2467\u003C/code>, which belongs to the \u003Ccode class=\"literal\">example.service\u003C/code> unit. You can determine whether the process was placed in a correct control group as defined by the \u003Ccode class=\"literal\">systemd\u003C/code> unit file specifications.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo display what controllers and respective configuration files the \u003Ccode class=\"literal\">cgroup\u003C/code> uses, check the \u003Ccode class=\"literal\">cgroup\u003C/code> directory:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>cat /sys/fs/cgroup/system.slice/example.service/cgroup.controllers\u003C/strong>\u003C/span>\nmemory pids\n\n# \u003Cspan class=\"strong strong\">\u003Cstrong>ls /sys/fs/cgroup/system.slice/example.service/\u003C/strong>\u003C/span>\ncgroup.controllers\ncgroup.events\n…​\ncpu.pressure\ncpu.stat\nio.pressure\nmemory.current\nmemory.events\n…​\npids.current\npids.events\npids.max\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tThe version 1 hierarchy of \u003Ccode class=\"literal\">cgroups\u003C/code> uses a per-controller model. Therefore the output from the \u003Ccode class=\"literal\">/proc/\u003Cspan class=\"emphasis\">\u003Cem>PID\u003C/em>\u003C/span>/cgroup\u003C/code> file shows, which \u003Ccode class=\"literal\">cgroups\u003C/code> under each controller the PID belongs to. You can find the respective \u003Ccode class=\"literal\">cgroups\u003C/code> under the controller directories at \u003Ccode class=\"literal\">/sys/fs/cgroup/\u003Cspan class=\"emphasis\">\u003Cem>&lt;controller_name&gt;\u003C/em>\u003C/span>/\u003C/code>.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">cgroups(7)\u003C/code> manual page\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"#what-kernel-resource-controllers-are_setting-limits-for-applications\" title=\"34.2. Introducing kernel resource controllers\">What are kernel resource controllers\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tDocumentation in the \u003Ccode class=\"literal\">/usr/share/doc/kernel-doc-&lt;kernel_version&gt;/Documentation/admin-guide/cgroup-v2.rst\u003C/code> file (after installing the \u003Ccode class=\"literal\">kernel-doc\u003C/code> package)\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"monitoring-resource-consumption_assembly_using-systemd-to-manage-resources-used-by-applications\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">33.8. Monitoring resource consumption\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tView a list of currently running control groups (\u003Ccode class=\"literal\">cgroups\u003C/code>) and their resource consumption in real-time.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tDisplay a dynamic account of currently running \u003Ccode class=\"literal\">cgroups\u003C/code> with the \u003Ccode class=\"literal\">systemd-cgtop\u003C/code> command.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout white-space-pre\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemd-cgtop\u003C/strong>\u003C/span>\nControl Group                            Tasks   %CPU   Memory  Input/s Output/s\n/                                          607   29.8     1.5G        -        -\n/system.slice                              125      -   428.7M        -        -\n/system.slice/ModemManager.service           3      -     8.6M        -        -\n/system.slice/NetworkManager.service         3      -    12.8M        -        -\n/system.slice/accounts-daemon.service        3      -     1.8M        -        -\n/system.slice/boot.mount                     -      -    48.0K        -        -\n/system.slice/chronyd.service                1      -     2.0M        -        -\n/system.slice/cockpit.socket                 -      -     1.3M        -        -\n/system.slice/colord.service                 3      -     3.5M        -        -\n/system.slice/crond.service                  1      -     1.8M        -        -\n/system.slice/cups.service                   1      -     3.1M        -        -\n/system.slice/dev-hugepages.mount            -      -   244.0K        -        -\n/system.slice/dev-mapper-rhel\\x2dswap.swap   -      -   912.0K        -        -\n/system.slice/dev-mqueue.mount               -      -    48.0K        -        -\n/system.slice/example.service                2      -     2.0M        -        -\n/system.slice/firewalld.service              2      -    28.8M        -        -\n...\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe example output displays currently running \u003Ccode class=\"literal\">cgroups\u003C/code> ordered by their resource usage (CPU, memory, disk I/O load). The list refreshes every 1 second by default. Therefore, it offers a dynamic insight into the actual resource usage of each control group.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">systemd-cgtop(1)\u003C/code> manual page\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"proc_using-systemd-unit-files-to-set-limits-for-applications_assembly_using-systemd-to-manage-resources-used-by-applications\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">33.9. Using systemd unit files to set limits for applications\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tThe \u003Ccode class=\"literal\">systemd\u003C/code> service manager supervises each existing or running unit and creates control groups for them. The units have configuration files in the \u003Ccode class=\"literal\">/usr/lib/systemd/system/\u003C/code> directory.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tYou can manually modify the unit files to:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tset limits.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tprioritize.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tcontrol access to hardware resources for groups of processes.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have the \u003Ccode class=\"literal\">root\u003C/code> privileges.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEdit the \u003Ccode class=\"literal\">/usr/lib/systemd/system/example.service\u003C/code> file to limit the memory usage of a service:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">…​\n[Service]\nMemoryMax=1500K\n…​\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe configuration limits the maximum memory that the processes in a control group cannot exceed. The \u003Ccode class=\"literal\">example.service\u003C/code> service is part of such a control group which has imposed limitations. You can use suffixes K, M, G, or T to identify Kilobyte, Megabyte, Gigabyte, or Terabyte as a unit of measurement.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tReload all unit configuration files:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl daemon-reload\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRestart the service:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl restart \u003Cspan class=\"emphasis\">\u003Cem>example.service\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCheck that the changes took effect:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>cat /sys/fs/cgroup/system.slice/example.service/memory.max\u003C/strong>\u003C/span>\n1536000\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe example output shows that the memory consumption was limited at around 1,500 KB.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_monitoring_and_updating_the_kernel/index#setting-limits-for-applications_managing-monitoring-and-updating-the-kernel\">Understanding cgroups\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"citetitle citetitle\">\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_basic_system_settings/managing-systemd_configuring-basic-system-settings#managing-system-services-with-systemctl_managing-systemd\">Managing system services with systemctl\u003C/a>\u003C/span>\u003C/em>\u003C/span> in Red Hat Enterprise Linux\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">systemd.resource-control(5)\u003C/code>, \u003Ccode class=\"literal\">systemd.exec(5)\u003C/code>, and \u003Ccode class=\"literal\">cgroups(7)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"proc_using-systemctl-command-to-set-limits-to-applications_assembly_using-systemd-to-manage-resources-used-by-applications\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">33.10. Using systemctl command to set limits to applications\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tCPU affinity settings help you restrict the access of a particular process to some CPUs. Effectively, the CPU scheduler never schedules the process to run on the CPU that is not in the affinity mask of the process.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe default CPU affinity mask applies to all services managed by \u003Ccode class=\"literal\">systemd\u003C/code>.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tTo configure CPU affinity mask for a particular \u003Ccode class=\"literal\">systemd\u003C/code> service, \u003Ccode class=\"literal\">systemd\u003C/code> provides \u003Ccode class=\"literal\">CPUAffinity=\u003C/code> both as:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\ta unit file option.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\ta configuration option in the [Manager] section of the \u003Ccode class=\"literal\">/etc/systemd/system.conf\u003C/code> file.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tThe \u003Ccode class=\"literal\">CPUAffinity=\u003C/code> unit file option sets a list of CPUs or CPU ranges that are merged and used as the affinity mask.\n\t\t\t\u003C/p>\u003Cdiv class=\"formalpara\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cp>\n\t\t\t\t\tTo set CPU affinity mask for a particular \u003Ccode class=\"literal\">systemd\u003C/code> service using the \u003Ccode class=\"literal\">CPUAffinity\u003C/code> unit file option:\n\t\t\t\t\u003C/p>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCheck the values of the \u003Ccode class=\"literal\">CPUAffinity\u003C/code> unit file option in the service of your choice:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl show --property \u003Cspan class=\"emphasis\">\u003Cem>&lt;CPU affinity configuration option&gt;\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>&lt;service name&gt;\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAs the root user, set the required value of the \u003Ccode class=\"literal\">CPUAffinity\u003C/code> unit file option for the CPU ranges used as the affinity mask:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl set-property \u003Cspan class=\"emphasis\">\u003Cem>&lt;service name&gt;\u003C/em>\u003C/span> CPUAffinity=\u003Cspan class=\"emphasis\">\u003Cem>&lt;value&gt;\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRestart the service to apply the changes.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl restart \u003Cspan class=\"emphasis\">\u003Cem>&lt;service name&gt;\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">systemd.resource-control(5)\u003C/code>, \u003Ccode class=\"literal\">systemd.exec(5)\u003C/code>, \u003Ccode class=\"literal\">cgroups(7)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"proc_setting-global-default-cpu-affinity-through-manager-configuration_assembly_using-systemd-to-manage-resources-used-by-applications\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">33.11. Setting global default CPU affinity through manager configuration\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tThe \u003Ccode class=\"literal\">CPUAffinity\u003C/code> option in the \u003Ccode class=\"literal\">/etc/systemd/system.conf\u003C/code> file defines an affinity mask for the process identification number (PID) 1 and all processes forked off of PID1. You can then override the \u003Ccode class=\"literal\">CPUAffinity\u003C/code> on a per-service basis.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tTo set the default CPU affinity mask for all \u003Ccode class=\"literal\">systemd\u003C/code> services using the \u003Ccode class=\"literal\">/etc/systemd/system.conf\u003C/code> file:\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tSet the CPU numbers for the \u003Ccode class=\"literal\">CPUAffinity=\u003C/code> option in the [Manager] section of the \u003Ccode class=\"literal\">/etc/systemd/system.conf\u003C/code> file.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tSave the edited file and reload the \u003Ccode class=\"literal\">systemd\u003C/code> service:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl daemon-reload\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tReboot the server to apply the changes.\n\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">systemd.resource-control(5)\u003C/code> and \u003Ccode class=\"literal\">systemd.exec(5)\u003C/code> man pages.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"proc_configuring-numa-using-systemd_assembly_using-systemd-to-manage-resources-used-by-applications\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">33.12. Configuring NUMA policies using systemd\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tNon-uniform memory access (NUMA) is a computer memory subsystem design, in which the memory access time depends on the physical memory location relative to the processor.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tMemory close to the CPU has lower latency (local memory) than memory that is local for a different CPU (foreign memory) or is shared between a set of CPUs.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tIn terms of the Linux kernel, NUMA policy governs where (for example, on which NUMA nodes) the kernel allocates physical memory pages for the process.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\u003Ccode class=\"literal\">systemd\u003C/code> provides unit file options \u003Ccode class=\"literal\">NUMAPolicy\u003C/code> and \u003Ccode class=\"literal\">NUMAMask\u003C/code> to control memory allocation policies for services.\n\t\t\t\u003C/p>\u003Cdiv class=\"formalpara\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cp>\n\t\t\t\t\tTo set the NUMA memory policy through the \u003Ccode class=\"literal\">NUMAPolicy\u003C/code> unit file option:\n\t\t\t\t\u003C/p>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCheck the values of the \u003Ccode class=\"literal\">NUMAPolicy\u003C/code> unit file option in the service of your choice:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl show --property \u003Cspan class=\"emphasis\">\u003Cem>&lt;NUMA policy configuration option&gt;\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>&lt;service name&gt;\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAs a root, set the required policy type of the \u003Ccode class=\"literal\">NUMAPolicy\u003C/code> unit file option:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl set-property \u003Cspan class=\"emphasis\">\u003Cem>&lt;service name&gt;\u003C/em>\u003C/span> NUMAPolicy=\u003Cspan class=\"emphasis\">\u003Cem>&lt;value&gt;\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRestart the service to apply the changes.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl restart \u003Cspan class=\"emphasis\">\u003Cem>&lt;service name&gt;\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cp>\n\t\t\t\tTo set a global \u003Ccode class=\"literal\">NUMAPolicy\u003C/code> setting using the [Manager] configuration option:\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tSearch in the \u003Ccode class=\"literal\">/etc/systemd/system.conf\u003C/code> file for the \u003Ccode class=\"literal\">NUMAPolicy\u003C/code> option in the [Manager] section of the file.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tEdit the policy type and save the file.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tReload the \u003Ccode class=\"literal\">systemd\u003C/code> configuration:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemd daemon-reload\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tReboot the server.\n\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tWhen you configure a strict NUMA policy, for example \u003Ccode class=\"literal\">bind\u003C/code>, make sure that you also appropriately set the \u003Ccode class=\"literal\">CPUAffinity=\u003C/code> unit file option.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"#proc_using-systemctl-command-to-set-limits-to-applications_assembly_using-systemd-to-manage-resources-used-by-applications\" title=\"33.10. Using systemctl command to set limits to applications\">Using systemctl command to set limits to applications\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">systemd.resource-control(5)\u003C/code>, \u003Ccode class=\"literal\">systemd.exec(5)\u003C/code>, and \u003Ccode class=\"literal\">set_mempolicy(2)\u003C/code> man pages.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"ref_numa-policy-configuration-options-with-systemd_assembly_using-systemd-to-manage-resources-used-by-applications\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">33.13. NUMA policy configuration options for systemd\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\t\u003Ccode class=\"literal\">Systemd\u003C/code> provides the following options to configure the NUMA policy:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">NUMAPolicy\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tControls the NUMA memory policy of the executed processes. You can use these policy types:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tdefault\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tpreferred\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tbind\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tinterleave\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tlocal\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">NUMAMask\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tControls the NUMA node list which is associated with the selected NUMA policy.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tNote that you do not have to specify the \u003Ccode class=\"literal\">NUMAMask\u003C/code> option for the following policies:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tdefault\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tlocal\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tFor the preferred policy, the list specifies only a single NUMA node.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">systemd.resource-control(5)\u003C/code>, \u003Ccode class=\"literal\">systemd.exec(5)\u003C/code>, and \u003Ccode class=\"literal\">set_mempolicy(2)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"creating-transient-control-groups_assembly_using-systemd-to-manage-resources-used-by-applications\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">33.14. Creating transient cgroups using systemd-run command\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe transient \u003Ccode class=\"literal\">cgroups\u003C/code> set limits on resources consumed by a unit (service or scope) during its runtime.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo create a transient control group, use the \u003Ccode class=\"literal\">systemd-run\u003C/code> command in the following format:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemd-run --unit=\u003Cspan class=\"emphasis\">\u003Cem>&lt;name&gt;\u003C/em>\u003C/span> --slice=\u003Cspan class=\"emphasis\">\u003Cem>&lt;name&gt;\u003C/em>\u003C/span>.slice \u003Cspan class=\"emphasis\">\u003Cem>&lt;command&gt;\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThis command creates and starts a transient service or a scope unit and runs a custom command in such a unit.\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">--unit=&lt;name&gt;\u003C/code> option gives a name to the unit. If \u003Ccode class=\"literal\">--unit\u003C/code> is not specified, the name is generated automatically.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">--slice=&lt;\u003Cspan class=\"emphasis\">\u003Cem>name\u003C/em>\u003C/span>&gt;.slice\u003C/code> option makes your service or scope unit a member of a specified slice. Replace \u003Ccode class=\"literal\">&lt;\u003Cspan class=\"emphasis\">\u003Cem>name\u003C/em>\u003C/span>&gt;.slice\u003C/code> with the name of an existing slice (as shown in the output of \u003Ccode class=\"literal\">systemctl -t slice\u003C/code>), or create a new slice by passing a unique name. By default, services and scopes are created as members of the \u003Ccode class=\"literal\">system.slice\u003C/code>.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tReplace \u003Ccode class=\"literal\">&lt;\u003Cspan class=\"emphasis\">\u003Cem>command\u003C/em>\u003C/span>&gt;\u003C/code> with the command you want to enter in the service or the scope unit.\n\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tThe following message is displayed to confirm that you created and started the service or the scope successfully:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># Running as unit \u003Cspan class=\"emphasis\">\u003Cem>&lt;name&gt;\u003C/em>\u003C/span>.service\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\u003Cspan class=\"emphasis\">\u003Cem>Optional\u003C/em>\u003C/span>: Keep the unit running after its processes finished to collect run-time information:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemd-run --unit=\u003Cspan class=\"emphasis\">\u003Cem>&lt;name&gt;\u003C/em>\u003C/span> --slice=\u003Cspan class=\"emphasis\">\u003Cem>&lt;name&gt;\u003C/em>\u003C/span>.slice --remain-after-exit \u003Cspan class=\"emphasis\">\u003Cem>&lt;command&gt;\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe command creates and starts a transient service unit and runs a custom command in the unit. The \u003Ccode class=\"literal\">--remain-after-exit\u003C/code> option ensures that the service keeps running after its processes have finished.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">systemd-run(1)\u003C/code> manual page\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"removing-transient-control-groups_assembly_using-systemd-to-manage-resources-used-by-applications\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">33.15. Removing transient control groups\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can use the \u003Ccode class=\"literal\">systemd\u003C/code> system and service manager to remove transient control groups (\u003Ccode class=\"literal\">cgroups\u003C/code>) if you no longer need to limit, prioritize, or control access to hardware resources for groups of processes.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tTransient \u003Ccode class=\"literal\">cgroups\u003C/code> are automatically released once all the processes that a service or a scope unit contains finish.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo stop the service unit with all its processes, enter:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl stop &lt;\u003Cspan class=\"emphasis\">\u003Cem>name\u003C/em>\u003C/span>&gt;.service\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo terminate one or more of the unit processes, enter:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>systemctl kill &lt;\u003Cspan class=\"emphasis\">\u003Cem>name\u003C/em>\u003C/span>&gt;.service --kill-who=\u003Cspan class=\"emphasis\">\u003Cem>PID,…​\u003C/em>\u003C/span> --signal=&lt;\u003Cspan class=\"emphasis\">\u003Cem>signal\u003C/em>\u003C/span>&gt;\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe command uses the \u003Ccode class=\"literal\">--kill-who\u003C/code> option to select process(es) from the control group you want to terminate. To kill multiple processes at the same time, pass a comma-separated list of PIDs. The \u003Ccode class=\"literal\">--signal\u003C/code> option determines the type of POSIX signal to be sent to the specified processes. The default signal is \u003Cspan class=\"emphasis\">\u003Cem>SIGTERM\u003C/em>\u003C/span>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"#understanding-control-groups_setting-limits-for-applications\" title=\"34.1. Introducing control groups\">What are control groups\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"#what-kernel-resource-controllers-are_setting-limits-for-applications\" title=\"34.2. Introducing kernel resource controllers\">What are kernel resource controllers\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">systemd.resource-control(5)\u003C/code> and \u003Ccode class=\"literal\">cgroups(7)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/managing_monitoring_and_updating_the_kernel/index#setting-limits-for-applications_managing-monitoring-and-updating-the-kernel\">Understanding control groups\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Cspan class=\"emphasis\">\u003Cem>\u003Cspan class=\"citetitle citetitle\">\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_basic_system_settings/managing-systemd_configuring-basic-system-settings\">Managing systemd\u003C/a>\u003C/span>\u003C/em>\u003C/span> in RHEL\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"setting-limits-for-applications_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 34. Understanding control groups\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tUsing the control groups (\u003Ccode class=\"literal\">cgroups\u003C/code>) kernel functionality, you can control resource usage of applications to use them more efficiently.\n\t\t\u003C/p>\u003Cp>\n\t\t\tYou can use \u003Ccode class=\"literal\">cgroups\u003C/code> for the following tasks:\n\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\tSetting limits for system resource allocation.\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tPrioritizing the allocation of hardware resources to specific processes.\n\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\tIsolating certain processes from obtaining hardware resources.\n\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Csection class=\"section\" id=\"understanding-control-groups_setting-limits-for-applications\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">34.1. Introducing control groups\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tUsing the \u003Cspan class=\"emphasis\">\u003Cem>control groups\u003C/em>\u003C/span> Linux kernel feature, you can organize processes into hierarchically ordered groups - \u003Ccode class=\"literal\">cgroups\u003C/code>. You define the hierarchy (control groups tree) by providing structure to \u003Ccode class=\"literal\">cgroups\u003C/code> virtual file system, mounted by default on the \u003Ccode class=\"literal\">/sys/fs/cgroup/\u003C/code> directory.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe \u003Ccode class=\"literal\">systemd\u003C/code> service manager uses \u003Ccode class=\"literal\">cgroups\u003C/code> to organize all units and services that it governs. Manually, you can manage the hierarchies of \u003Ccode class=\"literal\">cgroups\u003C/code> by creating and removing sub-directories in the \u003Ccode class=\"literal\">/sys/fs/cgroup/\u003C/code> directory.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe resource controllers in the kernel then modify the behavior of processes in \u003Ccode class=\"literal\">cgroups\u003C/code> by limiting, prioritizing or allocating system resources, of those processes. These resources include the following:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tCPU time\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tMemory\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tNetwork bandwidth\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tCombinations of these resources\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tThe primary use case of \u003Ccode class=\"literal\">cgroups\u003C/code> is aggregating system processes and dividing hardware resources among applications and users. This makes it possible to increase the efficiency, stability, and security of your environment.\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">Control groups version 1\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\u003Cspan class=\"emphasis\">\u003Cem>Control groups version 1\u003C/em>\u003C/span> (\u003Ccode class=\"literal\">cgroups-v1\u003C/code>) provide a per-resource controller hierarchy. This means that each resource (such as CPU, memory, or I/O) has its own control group hierarchy. You can combine different control group hierarchies in a way that one controller can coordinate with another in managing their respective resources. However, when the two controllers belong to different process hierarchies, proper coordination is limited.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">cgroups-v1\u003C/code> controllers were developed across a large time span and as a result, the behavior and naming of their control files is not uniform.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Control groups version 2\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\u003Cspan class=\"emphasis\">\u003Cem>Control groups version 2\u003C/em>\u003C/span> (\u003Ccode class=\"literal\">cgroups-v2\u003C/code>) provide a single control group hierarchy against which all resource controllers are mounted.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe control file behavior and naming is consistent among different controllers.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003C/dl>\u003C/div>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tRHEL 9, by default, mounts and uses \u003Ccode class=\"literal\">cgroups-v2\u003C/code>.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"#what-kernel-resource-controllers-are_setting-limits-for-applications\" title=\"34.2. Introducing kernel resource controllers\">Introducing kernel resource controllers\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">cgroups(7)\u003C/code> manual page\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/labs/rhcb/RHEL-9.0/kernel-5.14.0-70.13.1.el9/source/Documentation/admin-guide/cgroup-v1\">cgroups-v1\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/labs/rhcb/RHEL-9.0/kernel-5.14.0-70.13.1.el9/source/blob/Documentation/admin-guide/cgroup-v2.rst\">cgroups-v2\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"what-kernel-resource-controllers-are_setting-limits-for-applications\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">34.2. Introducing kernel resource controllers\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tKernel resource controllers enable the functionality of control groups. RHEL 9 supports various controllers for \u003Cspan class=\"emphasis\">\u003Cem>control groups version 1\u003C/em>\u003C/span> (\u003Ccode class=\"literal\">cgroups-v1\u003C/code>) and \u003Cspan class=\"emphasis\">\u003Cem>control groups version 2\u003C/em>\u003C/span> (\u003Ccode class=\"literal\">cgroups-v2\u003C/code>).\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tA resource controller, also called a control group subsystem, is a kernel subsystem that represents a single resource, such as CPU time, memory, network bandwidth or disk I/O. The Linux kernel provides a range of resource controllers that are mounted automatically by the \u003Ccode class=\"literal\">systemd\u003C/code> service manager. You can find a list of the currently mounted resource controllers in the \u003Ccode class=\"literal\">/proc/cgroups\u003C/code> file.\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cp class=\"title\">\u003Cstrong>Controllers available for \u003Ccode class=\"literal\">cgroups-v1\u003C/code>:\u003C/strong>\u003C/p>\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">blkio\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tSets limits on input/output access to and from block devices.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">cpu\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tAdjusts the parameters of the Completely Fair Scheduler (CFS) for a control group’s tasks. The \u003Ccode class=\"literal\">cpu\u003C/code> controller is mounted together with the \u003Ccode class=\"literal\">cpuacct\u003C/code> controller on the same mount.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">cpuacct\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tCreates automatic reports on CPU resources used by tasks in a control group. The \u003Ccode class=\"literal\">cpuacct\u003C/code> controller is mounted together with the \u003Ccode class=\"literal\">cpu\u003C/code> controller on the same mount.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">cpuset\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tRestricts control group tasks to run only on a specified subset of CPUs and to direct the tasks to use memory only on specified memory nodes.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">devices\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tControls access to devices for tasks in a control group.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">freezer\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tSuspends or resumes tasks in a control group.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">memory\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tSets limits on memory use by tasks in a control group and generates automatic reports on memory resources used by those tasks.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">net_cls\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tTags network packets with a class identifier (\u003Ccode class=\"literal\">classid\u003C/code>) that enables the Linux traffic controller (the \u003Ccode class=\"literal\">tc\u003C/code> command) to identify packets that originate from a particular control group task. A subsystem of \u003Ccode class=\"literal\">net_cls\u003C/code>, the \u003Ccode class=\"literal\">net_filter\u003C/code> (iptables), can also use this tag to perform actions on such packets. The \u003Ccode class=\"literal\">net_filter\u003C/code> tags network sockets with a firewall identifier (\u003Ccode class=\"literal\">fwid\u003C/code>) that allows the Linux firewall to identify packets that originate from a particular control group task (by using the \u003Ccode class=\"literal\">iptables\u003C/code> command).\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">net_prio\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tSets the priority of network traffic.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pids\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tSets limits for a number of processes and their children in a control group.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">perf_event\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tGroups tasks for monitoring by the \u003Ccode class=\"literal\">perf\u003C/code> performance monitoring and reporting utility.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">rdma\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tSets limits on Remote Direct Memory Access/InfiniBand specific resources in a control group.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">hugetlb\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tCan be used to limit the usage of large size virtual memory pages by tasks in a control group.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"variablelist\">\u003Cp class=\"title\">\u003Cstrong>Controllers available for \u003Ccode class=\"literal\">cgroups-v2\u003C/code>:\u003C/strong>\u003C/p>\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">io\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tSets limits on input/output access to and from block devices.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">memory\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tSets limits on memory use by tasks in a control group and generates automatic reports on memory resources used by those tasks.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">pids\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tSets limits for a number of processes and their children in a control group.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">rdma\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tSets limits on Remote Direct Memory Access/InfiniBand specific resources in a control group.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">cpu\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tAdjusts the parameters of the Completely Fair Scheduler (CFS) for a control group’s tasks and creates automatic reports on CPU resources used by tasks in a control group.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">cpuset\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tRestricts control group tasks to run only on a specified subset of CPUs and to direct the tasks to use memory only on specified memory nodes. Supports only the core functionality (\u003Ccode class=\"literal\">cpus{,.effective}\u003C/code>, \u003Ccode class=\"literal\">mems{,.effective}\u003C/code>) with a new partition feature.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">perf_event\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tGroups tasks for monitoring by the \u003Ccode class=\"literal\">perf\u003C/code> performance monitoring and reporting utility. \u003Ccode class=\"literal\">perf_event\u003C/code> is enabled automatically on the v2 hierarchy.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tA resource controller can be used either in a \u003Ccode class=\"literal\">cgroups-v1\u003C/code> hierarchy or a \u003Ccode class=\"literal\">cgroups-v2\u003C/code> hierarchy, not simultaneously in both.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">cgroups(7)\u003C/code> manual page\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tDocumentation in \u003Ccode class=\"literal\">/usr/share/doc/kernel-doc-&lt;kernel_version&gt;/Documentation/cgroups-v1/\u003C/code> directory (after installing the \u003Ccode class=\"literal\">kernel-doc\u003C/code> package).\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"what-namespaces-are_setting-limits-for-applications\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">34.3. Introducing namespaces\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tNamespaces are one of the most important methods for organizing and identifying software objects.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tA namespace wraps a global system resource (for example, a mount point, a network device, or a hostname) in an abstraction that makes it appear to processes within the namespace that they have their own isolated instance of the global resource. One of the most common technologies that use namespaces are containers.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tChanges to a particular global resource are visible only to processes in that namespace and do not affect the rest of the system or other namespaces.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tTo inspect which namespaces a process is a member of, you can check the symbolic links in the \u003Ccode class=\"literal\">/proc/&lt;\u003Cspan class=\"emphasis\">\u003Cem>PID\u003C/em>\u003C/span>&gt;/ns/\u003C/code> directory.\n\t\t\t\u003C/p>\u003Crh-table id=\"idm140280133762384\">\u003Ctable class=\"lt-4-cols lt-7-rows\">\u003Ccaption>Table 34.1. Supported namespaces and resources which they isolate:\u003C/caption>\u003Ccolgroup>\u003Ccol style=\"width: 50%; \" class=\"col_1\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 50%; \" class=\"col_2\">\u003C!--Empty-->\u003C/col>\u003C/colgroup>\u003Cthead>\u003Ctr>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280133757584\" scope=\"col\">Namespace\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280133756496\" scope=\"col\">Isolates\u003C/th>\u003C/tr>\u003C/thead>\u003Ctbody>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280133757584\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>Mount\u003C/strong>\u003C/span>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280133756496\"> \u003Cp>\n\t\t\t\t\t\t\t\tMount points\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280133757584\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>UTS\u003C/strong>\u003C/span>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280133756496\"> \u003Cp>\n\t\t\t\t\t\t\t\tHostname and NIS domain name\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280133757584\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>IPC\u003C/strong>\u003C/span>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280133756496\"> \u003Cp>\n\t\t\t\t\t\t\t\tSystem V IPC, POSIX message queues\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280133757584\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>PID\u003C/strong>\u003C/span>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280133756496\"> \u003Cp>\n\t\t\t\t\t\t\t\tProcess IDs\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280133757584\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>Network\u003C/strong>\u003C/span>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280133756496\"> \u003Cp>\n\t\t\t\t\t\t\t\tNetwork devices, stacks, ports, etc\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280133757584\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>User\u003C/strong>\u003C/span>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280133756496\"> \u003Cp>\n\t\t\t\t\t\t\t\tUser and group IDs\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280133757584\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>Control groups\u003C/strong>\u003C/span>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280133756496\"> \u003Cp>\n\t\t\t\t\t\t\t\tControl group root directory\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\u003C/rh-table>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">namespaces(7)\u003C/code> and \u003Ccode class=\"literal\">cgroup_namespaces(7)\u003C/code> manual pages\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"assembly_using-cgroupfs-to-manually-manage-cgroups_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 35. Using cgroupfs to manually manage cgroups\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\tYou can manage \u003Ccode class=\"literal\">cgroup\u003C/code> hierarchies on your system by creating directories on the \u003Ccode class=\"literal\">cgroupfs\u003C/code> virtual file system. The file system is mounted by default on the \u003Ccode class=\"literal\">/sys/fs/cgroup/\u003C/code> directory and you can specify desired configurations in dedicated control files.\n\t\t\u003C/p>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\tIn general, Red Hat recommends you use \u003Ccode class=\"literal\">systemd\u003C/code> for controlling the usage of system resources. You should manually configure the \u003Ccode class=\"literal\">cgroups\u003C/code> virtual file system only in special cases. For example, when you need to use \u003Ccode class=\"literal\">cgroup-v1\u003C/code> controllers that have no equivalents in \u003Ccode class=\"literal\">cgroup-v2\u003C/code> hierarchy.\n\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Csection class=\"section\" id=\"proc_creating-cgroups-and-enabling-controllers-in-cgroups-v2-file-system_assembly_using-cgroupfs-to-manually-manage-cgroups\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">35.1. Creating cgroups and enabling controllers in cgroups-v2 file system\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tYou can manage the \u003Cspan class=\"emphasis\">\u003Cem>control groups\u003C/em>\u003C/span> (\u003Ccode class=\"literal\">cgroups\u003C/code>) by creating or removing directories and by writing to files in the \u003Ccode class=\"literal\">cgroups\u003C/code> virtual file system. The file system is by default mounted on the \u003Ccode class=\"literal\">/sys/fs/cgroup/\u003C/code> directory. To use settings from the \u003Ccode class=\"literal\">cgroups\u003C/code> controllers, you also need to enable the desired controllers for child \u003Ccode class=\"literal\">cgroups\u003C/code>. The root \u003Ccode class=\"literal\">cgroup\u003C/code> has, by default, enabled the \u003Ccode class=\"literal\">memory\u003C/code> and \u003Ccode class=\"literal\">pids\u003C/code> controllers for its child \u003Ccode class=\"literal\">cgroups\u003C/code>. Therefore, Red Hat recommends to create at least two levels of child \u003Ccode class=\"literal\">cgroups\u003C/code> inside the \u003Ccode class=\"literal\">/sys/fs/cgroup/\u003C/code> root \u003Ccode class=\"literal\">cgroup\u003C/code>. This way you optionally remove the \u003Ccode class=\"literal\">memory\u003C/code> and \u003Ccode class=\"literal\">pids\u003C/code> controllers from the child \u003Ccode class=\"literal\">cgroups\u003C/code> and maintain better organizational clarity of \u003Ccode class=\"literal\">cgroup\u003C/code> files.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have root permissions.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate the \u003Ccode class=\"literal\">/sys/fs/cgroup/Example/\u003C/code> directory:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>mkdir /sys/fs/cgroup/Example/\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">/sys/fs/cgroup/Example/\u003C/code> directory defines a child group. When you create the \u003Ccode class=\"literal\">/sys/fs/cgroup/Example/\u003C/code> directory, some \u003Ccode class=\"literal\">cgroups-v2\u003C/code> interface files are automatically created in the directory. The \u003Ccode class=\"literal\">/sys/fs/cgroup/Example/\u003C/code> directory contains also controller-specific files for the \u003Ccode class=\"literal\">memory\u003C/code> and \u003Ccode class=\"literal\">pids\u003C/code> controllers.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOptional: Inspect the newly created child control group:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ll /sys/fs/cgroup/Example/\u003C/strong>\u003C/span>\n-r—​r—​r--. 1 root root 0 Jun  1 10:33 cgroup.controllers\n-r—​r—​r--. 1 root root 0 Jun  1 10:33 cgroup.events\n-rw-r—​r--. 1 root root 0 Jun  1 10:33 cgroup.freeze\n-rw-r—​r--. 1 root root 0 Jun  1 10:33 cgroup.procs\n…​\n-rw-r—​r--. 1 root root 0 Jun  1 10:33 cgroup.subtree_control\n-r—​r—​r--. 1 root root 0 Jun  1 10:33 memory.events.local\n-rw-r—​r--. 1 root root 0 Jun  1 10:33 memory.high\n-rw-r—​r--. 1 root root 0 Jun  1 10:33 memory.low\n…​\n-r—​r—​r--. 1 root root 0 Jun  1 10:33 pids.current\n-r—​r—​r--. 1 root root 0 Jun  1 10:33 pids.events\n-rw-r—​r--. 1 root root 0 Jun  1 10:33 pids.max\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe example output shows general \u003Ccode class=\"literal\">cgroup\u003C/code> control interface files such as \u003Ccode class=\"literal\">cgroup.procs\u003C/code> or \u003Ccode class=\"literal\">cgroup.controllers\u003C/code>. These files are common to all control groups, regardless of enabled controllers.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe files such as \u003Ccode class=\"literal\">memory.high\u003C/code> and \u003Ccode class=\"literal\">pids.max\u003C/code> relate to the \u003Ccode class=\"literal\">memory\u003C/code> and \u003Ccode class=\"literal\">pids\u003C/code> controllers, which are in the root control group (\u003Ccode class=\"literal\">/sys/fs/cgroup/\u003C/code>), and are enabled by default by \u003Ccode class=\"literal\">systemd\u003C/code>.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tBy default, the newly created child group inherits all settings from the parent \u003Ccode class=\"literal\">cgroup\u003C/code>. In this case, there are no limits from the root \u003Ccode class=\"literal\">cgroup\u003C/code>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify that the desired controllers are available in the \u003Ccode class=\"literal\">/sys/fs/cgroup/cgroup.controllers\u003C/code> file:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>cat /sys/fs/cgroup/cgroup.controllers\u003C/strong>\u003C/span>\ncpuset cpu io memory hugetlb pids rdma\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnable the desired controllers. In this example it is \u003Ccode class=\"literal\">cpu\u003C/code> and \u003Ccode class=\"literal\">cpuset\u003C/code> controllers:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>echo \"+cpu\" &gt;&gt; /sys/fs/cgroup/cgroup.subtree_control\u003C/strong>\u003C/span>\n# \u003Cspan class=\"strong strong\">\u003Cstrong>echo \"+cpuset\" &gt;&gt; /sys/fs/cgroup/cgroup.subtree_control\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThese commands enable the \u003Ccode class=\"literal\">cpu\u003C/code> and \u003Ccode class=\"literal\">cpuset\u003C/code> controllers for the immediate child groups of the \u003Ccode class=\"literal\">/sys/fs/cgroup/\u003C/code> root control group. Including the newly created \u003Ccode class=\"literal\">Example\u003C/code> control group. A \u003Cspan class=\"emphasis\">\u003Cem>child group\u003C/em>\u003C/span> is where you can specify processes and apply control checks to each of the processes based on your criteria.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tUsers can read the contents of the \u003Ccode class=\"literal\">cgroup.subtree_control\u003C/code> file at any level to get an idea of what controllers are going to be available for enablement in the immediate child group.\n\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\tBy default, the \u003Ccode class=\"literal\">/sys/fs/cgroup/cgroup.subtree_control\u003C/code> file in the root control group contains \u003Ccode class=\"literal\">memory\u003C/code> and \u003Ccode class=\"literal\">pids\u003C/code> controllers.\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnable the desired controllers for child \u003Ccode class=\"literal\">cgroups\u003C/code> of the \u003Ccode class=\"literal\">Example\u003C/code> control group:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>echo \"+cpu +cpuset\" &gt;&gt; /sys/fs/cgroup/Example/cgroup.subtree_control\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThis command ensures that the immediate child control group will \u003Cspan class=\"emphasis\">\u003Cem>only\u003C/em>\u003C/span> have controllers relevant to regulate the CPU time distribution - not to \u003Ccode class=\"literal\">memory\u003C/code> or \u003Ccode class=\"literal\">pids\u003C/code> controllers.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate the \u003Ccode class=\"literal\">/sys/fs/cgroup/Example/tasks/\u003C/code> directory:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>mkdir /sys/fs/cgroup/Example/tasks/\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">/sys/fs/cgroup/Example/tasks/\u003C/code> directory defines a child group with files that relate purely to \u003Ccode class=\"literal\">cpu\u003C/code> and \u003Ccode class=\"literal\">cpuset\u003C/code> controllers. You can now assign processes to this control group and utilize \u003Ccode class=\"literal\">cpu\u003C/code> and \u003Ccode class=\"literal\">cpuset\u003C/code> controller options for your processes.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOptional: Inspect the child control group:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ll /sys/fs/cgroup/Example/tasks\u003C/strong>\u003C/span>\n-r—​r—​r--. 1 root root 0 Jun  1 11:45 cgroup.controllers\n-r—​r—​r--. 1 root root 0 Jun  1 11:45 cgroup.events\n-rw-r—​r--. 1 root root 0 Jun  1 11:45 cgroup.freeze\n-rw-r—​r--. 1 root root 0 Jun  1 11:45 cgroup.max.depth\n-rw-r—​r--. 1 root root 0 Jun  1 11:45 cgroup.max.descendants\n-rw-r—​r--. 1 root root 0 Jun  1 11:45 cgroup.procs\n-r—​r—​r--. 1 root root 0 Jun  1 11:45 cgroup.stat\n-rw-r—​r--. 1 root root 0 Jun  1 11:45 cgroup.subtree_control\n-rw-r—​r--. 1 root root 0 Jun  1 11:45 cgroup.threads\n-rw-r—​r--. 1 root root 0 Jun  1 11:45 cgroup.type\n-rw-r—​r--. 1 root root 0 Jun  1 11:45 cpu.max\n-rw-r—​r--. 1 root root 0 Jun  1 11:45 cpu.pressure\n-rw-r—​r--. 1 root root 0 Jun  1 11:45 cpuset.cpus\n-r—​r—​r--. 1 root root 0 Jun  1 11:45 cpuset.cpus.effective\n-rw-r—​r--. 1 root root 0 Jun  1 11:45 cpuset.cpus.partition\n-rw-r—​r--. 1 root root 0 Jun  1 11:45 cpuset.mems\n-r—​r—​r--. 1 root root 0 Jun  1 11:45 cpuset.mems.effective\n-r—​r—​r--. 1 root root 0 Jun  1 11:45 cpu.stat\n-rw-r—​r--. 1 root root 0 Jun  1 11:45 cpu.weight\n-rw-r—​r--. 1 root root 0 Jun  1 11:45 cpu.weight.nice\n-rw-r—​r--. 1 root root 0 Jun  1 11:45 io.pressure\n-rw-r—​r--. 1 root root 0 Jun  1 11:45 memory.pressure\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tThe \u003Ccode class=\"literal\">cpu\u003C/code> controller is only activated if the relevant child control group has at least 2 processes which compete for time on a single CPU.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOptional: confirm that you have created a new \u003Ccode class=\"literal\">cgroup\u003C/code> with only the desired controllers active:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout white-space-pre\"># \u003Cspan class=\"strong strong\">\u003Cstrong>cat /sys/fs/cgroup/Example/tasks/cgroup.controllers\u003C/strong>\u003C/span>\ncpuset cpu\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"#what-kernel-resource-controllers-are_setting-limits-for-applications\" title=\"34.2. Introducing kernel resource controllers\">What are kernel resource controllers\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"#proc_mounting-cgroups-v1_assembly_using-cgroupfs-to-manually-manage-cgroups\" title=\"35.3. Mounting cgroups-v1\">Mounting cgroups-v1\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">cgroups(7)\u003C/code>, \u003Ccode class=\"literal\">sysfs(5)\u003C/code> manual pages\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"proc_controlling-distribution-of-cpu-time-for-applications-by-adjusting-cpu-weight_assembly_using-cgroupfs-to-manually-manage-cgroups\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">35.2. Controlling distribution of CPU time for applications by adjusting CPU weight\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou need to assign values to the relevant files of the \u003Ccode class=\"literal\">cpu\u003C/code> controller to regulate distribution of the CPU time to applications under the specific cgroup tree.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have root permissions.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have applications for which you want to control distribution of CPU time.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tYou created a two level hierarchy of \u003Cspan class=\"emphasis\">\u003Cem>child control groups\u003C/em>\u003C/span> inside the \u003Ccode class=\"literal\">/sys/fs/cgroup/\u003C/code> \u003Cspan class=\"emphasis\">\u003Cem>root control group\u003C/em>\u003C/span> as in the following example:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\">…​\n  ├── Example\n  │   ├── g1\n  │   ├── g2\n  │   └── g3\n…​\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou enabled the \u003Ccode class=\"literal\">cpu\u003C/code> controller in the parent control group and in child control groups similarly as described in \u003Ca class=\"link\" href=\"#proc_creating-cgroups-and-enabling-controllers-in-cgroups-v2-file-system_assembly_using-cgroupfs-to-manually-manage-cgroups\" title=\"35.1. Creating cgroups and enabling controllers in cgroups-v2 file system\">Creating cgroups and enabling controllers in cgroups-v2 file system\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tConfigure desired CPU weights to achieve resource restrictions within the control groups:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>echo \"150\" &gt; /sys/fs/cgroup/Example/g1/cpu.weight\u003C/strong>\u003C/span>\n# \u003Cspan class=\"strong strong\">\u003Cstrong>echo \"100\" &gt; /sys/fs/cgroup/Example/g2/cpu.weight\u003C/strong>\u003C/span>\n# \u003Cspan class=\"strong strong\">\u003Cstrong>echo \"50\" &gt; /sys/fs/cgroup/Example/g3/cpu.weight\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAdd the applications' PIDs to the \u003Ccode class=\"literal\">g1\u003C/code>, \u003Ccode class=\"literal\">g2\u003C/code>, and \u003Ccode class=\"literal\">g3\u003C/code> child groups:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>echo \"33373\" &gt; /sys/fs/cgroup/Example/g1/cgroup.procs\u003C/strong>\u003C/span>\n# \u003Cspan class=\"strong strong\">\u003Cstrong>echo \"33374\" &gt; /sys/fs/cgroup/Example/g2/cgroup.procs\u003C/strong>\u003C/span>\n# \u003Cspan class=\"strong strong\">\u003Cstrong>echo \"33377\" &gt; /sys/fs/cgroup/Example/g3/cgroup.procs\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe example commands ensure that desired applications become members of the \u003Ccode class=\"literal\">Example/g*/\u003C/code> child cgroups and will get their CPU time distributed as per the configuration of those cgroups.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe weights of the children cgroups (\u003Ccode class=\"literal\">g1\u003C/code>, \u003Ccode class=\"literal\">g2\u003C/code>, \u003Ccode class=\"literal\">g3\u003C/code>) that have running processes are summed up at the level of the parent cgroup (\u003Ccode class=\"literal\">Example\u003C/code>). The CPU resource is then distributed proportionally based on the respective weights.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAs a result, when all processes run at the same time, the kernel allocates to each of them the proportionate CPU time based on their respective cgroup’s \u003Ccode class=\"literal\">cpu.weight\u003C/code> file:\n\t\t\t\t\t\u003C/p>\u003Crh-table>\u003Ctable class=\"lt-4-cols lt-7-rows\">\u003Ccolgroup>\u003Ccol style=\"width: 30%; \" class=\"col_1\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 30%; \" class=\"col_2\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 40%; \" class=\"col_3\">\u003C!--Empty-->\u003C/col>\u003C/colgroup>\u003Cthead>\u003Ctr>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280132623312\" scope=\"col\">Child cgroup\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280132622224\" scope=\"col\">\u003Ccode class=\"literal\">cpu.weight\u003C/code> file\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280132620816\" scope=\"col\">CPU time allocation\u003C/th>\u003C/tr>\u003C/thead>\u003Ctbody>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280132623312\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\tg1\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280132622224\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t150\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280132620816\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t~50% (150/300)\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280132623312\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\tg2\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280132622224\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t100\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280132620816\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t~33% (100/300)\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280132623312\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\tg3\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280132622224\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t50\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280132620816\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t~16% (50/300)\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\u003C/rh-table>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe value of the \u003Ccode class=\"literal\">cpu.weight\u003C/code> controller file is not a percentage.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIf one process stopped running, leaving cgroup \u003Ccode class=\"literal\">g2\u003C/code> with no running processes, the calculation would omit the cgroup \u003Ccode class=\"literal\">g2\u003C/code> and only account weights of cgroups \u003Ccode class=\"literal\">g1\u003C/code> and \u003Ccode class=\"literal\">g3\u003C/code>:\n\t\t\t\t\t\u003C/p>\u003Crh-table>\u003Ctable class=\"lt-4-cols lt-7-rows\">\u003Ccolgroup>\u003Ccol style=\"width: 30%; \" class=\"col_1\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 30%; \" class=\"col_2\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 40%; \" class=\"col_3\">\u003C!--Empty-->\u003C/col>\u003C/colgroup>\u003Cthead>\u003Ctr>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280132594192\" scope=\"col\">Child cgroup\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280132593104\" scope=\"col\">\u003Ccode class=\"literal\">cpu.weight\u003C/code> file\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280132591696\" scope=\"col\">CPU time allocation\u003C/th>\u003C/tr>\u003C/thead>\u003Ctbody>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280132594192\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\tg1\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280132593104\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t150\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280132591696\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t~75% (150/200)\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280132594192\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\tg3\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280132593104\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t50\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280132591696\"> \u003Cp>\n\t\t\t\t\t\t\t\t\t\t~25% (50/200)\n\t\t\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\u003C/rh-table>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\tIf a child cgroup had multiple running processes, the CPU time allocated to the respective cgroup would be distributed equally to the member processes of that cgroup.\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify that the applications run in the specified control groups:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>cat /proc/33373/cgroup /proc/33374/cgroup /proc/33377/cgroup\u003C/strong>\u003C/span>\n0::/Example/g1\n0::/Example/g2\n0::/Example/g3\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe command output shows the processes of the specified applications that run in the \u003Ccode class=\"literal\">Example/g*/\u003C/code> child cgroups.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInspect the current CPU consumption of the throttled applications:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout white-space-pre\"># \u003Cspan class=\"strong strong\">\u003Cstrong>top\u003C/strong>\u003C/span>\ntop - 05:17:18 up 1 day, 18:25,  1 user,  load average: 3.03, 3.03, 3.00\nTasks:  95 total,   4 running,  91 sleeping,   0 stopped,   0 zombie\n%Cpu(s): 18.1 us, 81.6 sy,  0.0 ni,  0.0 id,  0.0 wa,  0.3 hi,  0.0 si,  0.0 st\nMiB Mem :   3737.0 total,   3233.7 free,    132.8 used,    370.5 buff/cache\nMiB Swap:   4060.0 total,   4060.0 free,      0.0 used.   3373.1 avail Mem\n\n    PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND\n  33373 root      20   0   18720   1748   1460 R  \u003Cspan class=\"strong strong\">\u003Cstrong>49.5\u003C/strong>\u003C/span>   0.0 415:05.87 sha1sum\n  33374 root      20   0   18720   1756   1464 R  \u003Cspan class=\"strong strong\">\u003Cstrong>32.9\u003C/strong>\u003C/span>   0.0 412:58.33 sha1sum\n  33377 root      20   0   18720   1860   1568 R  \u003Cspan class=\"strong strong\">\u003Cstrong>16.3\u003C/strong>\u003C/span>   0.0 411:03.12 sha1sum\n    760 root      20   0  416620  28540  15296 S   0.3   0.7   0:10.23 tuned\n      1 root      20   0  186328  14108   9484 S   0.0   0.4   0:02.00 systemd\n      2 root      20   0       0      0      0 S   0.0   0.0   0:00.01 kthread\n...\u003C/pre>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\tWe forced all the example processes to run on a single CPU for clearer illustration. The CPU weight applies the same principles also when used on multiple CPUs.\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tNotice that the CPU resource for the \u003Ccode class=\"literal\">PID 33373\u003C/code>, \u003Ccode class=\"literal\">PID 33374\u003C/code>, and \u003Ccode class=\"literal\">PID 33377\u003C/code> was allocated based on the weights, 150, 100, 50, you assigned to the respective child cgroups. The weights correspond to around 50%, 33%, and 16% allocation of CPU time for each application.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"proc_mounting-cgroups-v1_assembly_using-cgroupfs-to-manually-manage-cgroups\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">35.3. Mounting cgroups-v1\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp>\n\t\t\t\tDuring the boot process, RHEL 9 mounts the \u003Ccode class=\"literal\">cgroup-v2\u003C/code> virtual filesystem by default. To utilize \u003Ccode class=\"literal\">cgroup-v1\u003C/code> functionality in limiting resources for your applications, manually configure the system.\n\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tBoth \u003Ccode class=\"literal\">cgroup-v1\u003C/code> and \u003Ccode class=\"literal\">cgroup-v2\u003C/code> are fully enabled in the kernel. There is no default control group version from the kernel point of view, and is decided by \u003Ccode class=\"literal\">systemd\u003C/code> to mount at startup.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have root permissions.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tConfigure the system to mount \u003Ccode class=\"literal\">cgroups-v1\u003C/code> by default during system boot by the \u003Ccode class=\"literal\">systemd\u003C/code> system and service manager:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout white-space-pre\"># \u003Cspan class=\"strong strong\">\u003Cstrong>grubby --update-kernel=/boot/vmlinuz-$(uname -r) --args=\"systemd.unified_cgroup_hierarchy=0 systemd.legacy_systemd_cgroup_controller\"\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThis adds the necessary kernel command-line parameters to the current boot entry.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo add the same parameters to all kernel boot entries:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout white-space-pre\"># \u003Cspan class=\"strong strong\">\u003Cstrong>grubby --update-kernel=ALL --args=\"systemd.unified_cgroup_hierarchy=0 systemd.legacy_systemd_cgroup_controller\"\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tReboot the system for the changes to take effect.\n\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify that the \u003Ccode class=\"literal\">cgroups-v1\u003C/code> filesystem was mounted:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout white-space-pre\"># \u003Cspan class=\"strong strong\">\u003Cstrong>mount -l | grep cgroup\u003C/strong>\u003C/span>\ntmpfs on /sys/fs/cgroup type tmpfs (ro,nosuid,nodev,noexec,seclabel,size=4096k,nr_inodes=1024,mode=755,inode64)\ncgroup on /sys/fs/cgroup/systemd type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,xattr,release_agent=/usr/lib/systemd/systemd-cgroups-agent,name=systemd)\ncgroup on /sys/fs/cgroup/perf_event type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,perf_event)\ncgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,cpu,cpuacct)\ncgroup on /sys/fs/cgroup/pids type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,pids)\ncgroup on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,cpuset)\ncgroup on /sys/fs/cgroup/net_cls,net_prio type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,net_cls,net_prio)\ncgroup on /sys/fs/cgroup/hugetlb type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,hugetlb)\ncgroup on /sys/fs/cgroup/memory type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,memory)\ncgroup on /sys/fs/cgroup/blkio type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,blkio)\ncgroup on /sys/fs/cgroup/devices type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,devices)\ncgroup on /sys/fs/cgroup/misc type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,misc)\ncgroup on /sys/fs/cgroup/freezer type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,freezer)\ncgroup on /sys/fs/cgroup/rdma type cgroup (rw,nosuid,nodev,noexec,relatime,seclabel,rdma)\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">cgroups-v1\u003C/code> filesystems that correspond to various \u003Ccode class=\"literal\">cgroup-v1\u003C/code> controllers, were successfully mounted on the \u003Ccode class=\"literal\">/sys/fs/cgroup/\u003C/code> directory.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInspect the contents of the \u003Ccode class=\"literal\">/sys/fs/cgroup/\u003C/code> directory:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ll /sys/fs/cgroup/\u003C/strong>\u003C/span>\ndr-xr-xr-x. 10 root root  0 Mar 16 09:34 blkio\nlrwxrwxrwx.  1 root root 11 Mar 16 09:34 cpu → cpu,cpuacct\nlrwxrwxrwx.  1 root root 11 Mar 16 09:34 cpuacct → cpu,cpuacct\ndr-xr-xr-x. 10 root root  0 Mar 16 09:34 cpu,cpuacct\ndr-xr-xr-x.  2 root root  0 Mar 16 09:34 cpuset\ndr-xr-xr-x. 10 root root  0 Mar 16 09:34 devices\ndr-xr-xr-x.  2 root root  0 Mar 16 09:34 freezer\ndr-xr-xr-x.  2 root root  0 Mar 16 09:34 hugetlb\ndr-xr-xr-x. 10 root root  0 Mar 16 09:34 memory\ndr-xr-xr-x.  2 root root  0 Mar 16 09:34 misc\nlrwxrwxrwx.  1 root root 16 Mar 16 09:34 net_cls → net_cls,net_prio\ndr-xr-xr-x.  2 root root  0 Mar 16 09:34 net_cls,net_prio\nlrwxrwxrwx.  1 root root 16 Mar 16 09:34 net_prio → net_cls,net_prio\ndr-xr-xr-x.  2 root root  0 Mar 16 09:34 perf_event\ndr-xr-xr-x. 10 root root  0 Mar 16 09:34 pids\ndr-xr-xr-x.  2 root root  0 Mar 16 09:34 rdma\ndr-xr-xr-x. 11 root root  0 Mar 16 09:34 systemd\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">/sys/fs/cgroup/\u003C/code> directory, also called the \u003Cspan class=\"emphasis\">\u003Cem>root control group\u003C/em>\u003C/span>, by default, contains controller-specific directories such as \u003Ccode class=\"literal\">cpuset\u003C/code>. In addition, there are some directories related to \u003Ccode class=\"literal\">systemd\u003C/code>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"#what-kernel-resource-controllers-are_setting-limits-for-applications\" title=\"34.2. Introducing kernel resource controllers\">What are kernel resource controllers\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">cgroups(7)\u003C/code>, \u003Ccode class=\"literal\">sysfs(5)\u003C/code> manual pages\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/9.0_release_notes/index#BZ-1953515\">cgroup-v2 enabled by default in RHEL 9\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"setting-cpu-limits-to-applications-using-cgroups-v1_assembly_using-cgroupfs-to-manually-manage-cgroups\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">35.4. Setting CPU limits to applications using cgroups-v1\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tTo configure CPU limits to an application by using \u003Cspan class=\"emphasis\">\u003Cem>control groups version 1\u003C/em>\u003C/span> (\u003Ccode class=\"literal\">cgroups-v1\u003C/code>), use the \u003Ccode class=\"literal\">/sys/fs/\u003C/code> virtual file system.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have root permissions.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have an application whose CPU consumption you want to restrict.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tYou configured the system to mount \u003Ccode class=\"literal\">cgroups-v1\u003C/code> by default during system boot by the \u003Ccode class=\"literal\">systemd\u003C/code> system and service manager:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout white-space-pre\"># \u003Cspan class=\"strong strong\">\u003Cstrong>grubby --update-kernel=/boot/vmlinuz-$(uname -r) --args=\"systemd.unified_cgroup_hierarchy=0 systemd.legacy_systemd_cgroup_controller\"\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThis adds the necessary kernel command-line parameters to the current boot entry.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIdentify the process ID (PID) of the application that you want to restrict in CPU consumption:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout white-space-pre\"># \u003Cspan class=\"strong strong\">\u003Cstrong>top\u003C/strong>\u003C/span>\ntop - 11:34:09 up 11 min,  1 user,  load average: 0.51, 0.27, 0.22\nTasks: 267 total,   3 running, 264 sleeping,   0 stopped,   0 zombie\n%Cpu(s): 49.0 us,  3.3 sy,  0.0 ni, 47.5 id,  0.0 wa,  0.2 hi,  0.0 si,  0.0 st\nMiB Mem :   1826.8 total,    303.4 free,   1046.8 used,    476.5 buff/cache\nMiB Swap:   1536.0 total,   1396.0 free,    140.0 used.    616.4 avail Mem\n\n  PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND\n 6955 root      20   0  228440   1752   1472 R  \u003Cspan class=\"strong strong\">\u003Cstrong>99.3\u003C/strong>\u003C/span>   0.1   0:32.71 sha1sum\n 5760 jdoe      20   0 3603868 205188  64196 S   3.7  11.0   0:17.19 gnome-shell\n 6448 jdoe      20   0  743648  30640  19488 S   0.7   1.6   0:02.73 gnome-terminal-\n    1 root      20   0  245300   6568   4116 S   0.3   0.4   0:01.87 systemd\n  505 root      20   0       0      0      0 I   0.3   0.0   0:00.75 kworker/u4:4-events_unbound\n...\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThis example output of the \u003Ccode class=\"literal\">top\u003C/code> program reveals that illustrative application \u003Ccode class=\"literal\">sha1sum\u003C/code> with \u003Ccode class=\"literal\">PID 6955\u003C/code> consumes a lot of CPU resources.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a sub-directory in the \u003Ccode class=\"literal\">cpu\u003C/code> resource controller directory:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>mkdir /sys/fs/cgroup/cpu/Example/\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThis directory represents a control group, where you can place specific processes and apply certain CPU limits to the processes. At the same time, a number of \u003Ccode class=\"literal\">cgroups-v1\u003C/code> interface files and \u003Ccode class=\"literal\">cpu\u003C/code> controller-specific files will be created in the directory.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOptional: Inspect the newly created control group:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ll /sys/fs/cgroup/cpu/Example/\u003C/strong>\u003C/span>\n-rw-r—​r--. 1 root root 0 Mar 11 11:42 cgroup.clone_children\n-rw-r—​r--. 1 root root 0 Mar 11 11:42 cgroup.procs\n-r—​r—​r--. 1 root root 0 Mar 11 11:42 cpuacct.stat\n-rw-r—​r--. 1 root root 0 Mar 11 11:42 cpuacct.usage\n-r—​r—​r--. 1 root root 0 Mar 11 11:42 cpuacct.usage_all\n-r—​r—​r--. 1 root root 0 Mar 11 11:42 cpuacct.usage_percpu\n-r—​r—​r--. 1 root root 0 Mar 11 11:42 cpuacct.usage_percpu_sys\n-r—​r—​r--. 1 root root 0 Mar 11 11:42 cpuacct.usage_percpu_user\n-r—​r—​r--. 1 root root 0 Mar 11 11:42 cpuacct.usage_sys\n-r—​r—​r--. 1 root root 0 Mar 11 11:42 cpuacct.usage_user\n-rw-r—​r--. 1 root root 0 Mar 11 11:42 cpu.cfs_period_us\n-rw-r—​r--. 1 root root 0 Mar 11 11:42 cpu.cfs_quota_us\n-rw-r—​r--. 1 root root 0 Mar 11 11:42 cpu.rt_period_us\n-rw-r—​r--. 1 root root 0 Mar 11 11:42 cpu.rt_runtime_us\n-rw-r—​r--. 1 root root 0 Mar 11 11:42 cpu.shares\n-r—​r—​r--. 1 root root 0 Mar 11 11:42 cpu.stat\n-rw-r—​r--. 1 root root 0 Mar 11 11:42 notify_on_release\n-rw-r—​r--. 1 root root 0 Mar 11 11:42 tasks\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThis example output shows files, such as \u003Ccode class=\"literal\">cpuacct.usage\u003C/code>, \u003Ccode class=\"literal\">cpu.cfs._period_us\u003C/code>, that represent specific configurations and/or limits, which can be set for processes in the \u003Ccode class=\"literal\">Example\u003C/code> control group. Note that the respective file names are prefixed with the name of the control group controller to which they belong.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tBy default, the newly created control group inherits access to the system’s entire CPU resources without a limit.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tConfigure CPU limits for the control group:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>echo \"1000000\" &gt; /sys/fs/cgroup/cpu/Example/cpu.cfs_period_us\u003C/strong>\u003C/span>\n# \u003Cspan class=\"strong strong\">\u003Cstrong>echo \"200000\" &gt; /sys/fs/cgroup/cpu/Example/cpu.cfs_quota_us\u003C/strong>\u003C/span>\u003C/pre>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">cpu.cfs_period_us\u003C/code> file represents a period of time in microseconds (µs, represented here as \"us\") for how frequently a control group’s access to CPU resources should be reallocated. The upper limit is 1 000 000 microsecond and the lower limit is 1 000 microseconds.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">cpu.cfs_quota_us\u003C/code> file represents the total amount of time in microseconds for which all processes collectively in a control group can run during one period (as defined by \u003Ccode class=\"literal\">cpu.cfs_period_us\u003C/code>). When processes in a control group, during a single period, use up all the time specified by the quota, they are throttled for the remainder of the period and not allowed to run until the next period. The lower limit is 1 000 microseconds.\n\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tThe example commands above set the CPU time limits so that all processes collectively in the \u003Ccode class=\"literal\">Example\u003C/code> control group will be able to run only for 0.2 seconds (defined by \u003Ccode class=\"literal\">cpu.cfs_quota_us\u003C/code>) out of every 1 second (defined by \u003Ccode class=\"literal\">cpu.cfs_period_us\u003C/code>).\n\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tOptional: Verify the limits:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>cat /sys/fs/cgroup/cpu/Example/cpu.cfs_period_us /sys/fs/cgroup/cpu/Example/cpu.cfs_quota_us\u003C/strong>\u003C/span>\n1000000\n200000\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAdd the application’s PID to the \u003Ccode class=\"literal\">Example\u003C/code> control group:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>echo \"6955\" &gt; /sys/fs/cgroup/cpu/Example/cgroup.procs\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThis command ensures that a specific application becomes a member of the \u003Ccode class=\"literal\">Example\u003C/code> control group and hence does not exceed the CPU limits configured for the \u003Ccode class=\"literal\">Example\u003C/code> control group. The PID should represent an existing process in the system. The \u003Ccode class=\"literal\">PID 6955\u003C/code> here was assigned to process \u003Ccode class=\"literal\">sha1sum /dev/zero &amp;\u003C/code>, used to illustrate the use case of the \u003Ccode class=\"literal\">cpu\u003C/code> controller.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tVerify that the application runs in the specified control group:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>cat /proc/6955/cgroup\u003C/strong>\u003C/span>\n12:cpuset:/\n11:hugetlb:/\n10:net_cls,net_prio:/\n9:memory:/user.slice/user-1000.slice/user@1000.service\n8:devices:/user.slice\n7:blkio:/\n6:freezer:/\n5:rdma:/\n4:pids:/user.slice/user-1000.slice/user@1000.service\n3:perf_event:/\n2:cpu,cpuacct:/Example\n1:name=systemd:/user.slice/user-1000.slice/user@1000.service/gnome-terminal-server.service\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThis example output shows that the process of the desired application runs in the \u003Ccode class=\"literal\">Example\u003C/code> control group, which applies CPU limits to the application’s process.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIdentify the current CPU consumption of your throttled application:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout white-space-pre\"># \u003Cspan class=\"strong strong\">\u003Cstrong>top\u003C/strong>\u003C/span>\ntop - 12:28:42 up  1:06,  1 user,  load average: 1.02, 1.02, 1.00\nTasks: 266 total,   6 running, 260 sleeping,   0 stopped,   0 zombie\n%Cpu(s): 11.0 us,  1.2 sy,  0.0 ni, 87.5 id,  0.0 wa,  0.2 hi,  0.0 si,  0.2 st\nMiB Mem :   1826.8 total,    287.1 free,   1054.4 used,    485.3 buff/cache\nMiB Swap:   1536.0 total,   1396.7 free,    139.2 used.    608.3 avail Mem\n\n  PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND\n 6955 root      20   0  228440   1752   1472 R  \u003Cspan class=\"strong strong\">\u003Cstrong>20.6\u003C/strong>\u003C/span>   0.1  47:11.43 sha1sum\n 5760 jdoe      20   0 3604956 208832  65316 R   2.3  11.2   0:43.50 gnome-shell\n 6448 jdoe      20   0  743836  31736  19488 S   0.7   1.7   0:08.25 gnome-terminal-\n  505 root      20   0       0      0      0 I   0.3   0.0   0:03.39 kworker/u4:4-events_unbound\n 4217 root      20   0   74192   1612   1320 S   0.3   0.1   0:01.19 spice-vdagentd\n...\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tNote that the CPU consumption of the \u003Ccode class=\"literal\">PID 6955\u003C/code> has decreased from 99% to 20%.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tThe \u003Ccode class=\"literal\">cgroups-v2\u003C/code> counterpart for \u003Ccode class=\"literal\">cpu.cfs_period_us\u003C/code> and \u003Ccode class=\"literal\">cpu.cfs_quota_us\u003C/code> is the \u003Ccode class=\"literal\">cpu.max\u003C/code> file. The \u003Ccode class=\"literal\">cpu.max\u003C/code> file is available through the \u003Ccode class=\"literal\">cpu\u003C/code> controller.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"#what-kernel-resource-controllers-are_setting-limits-for-applications\" title=\"34.2. Introducing kernel resource controllers\">Introducing kernel resource controllers\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">cgroups(7)\u003C/code>, \u003Ccode class=\"literal\">sysfs(5)\u003C/code> manual pages\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"analyzing-system-performance-with-bpf-compiler_collection_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 36. Analyzing system performance with BPF Compiler Collection\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tAs a system administrator, you can use the BPF Compiler Collection (BCC) library to create tools for analyzing the performance of your Linux operating system and gathering information, which could be difficult to obtain through other interfaces.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"installing-the-bcc-tools-package_analyzing-system-performance-with-bpf-compiler_collection\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">36.1. Installing the bcc-tools package\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tInstall the \u003Ccode class=\"literal\">bcc-tools\u003C/code> package, which also installs the BPF Compiler Collection (BCC) library as a dependency.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInstall \u003Ccode class=\"literal\">bcc-tools\u003C/code>.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>dnf install bcc-tools\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe BCC tools are installed in the \u003Ccode class=\"literal\">/usr/share/bcc/tools/\u003C/code> directory.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInspect the installed tools:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"literallayout\"># \u003Cspan class=\"strong strong\">\u003Cstrong>ls -l /usr/share/bcc/tools/\u003C/strong>\u003C/span>\n...\n-rwxr-xr-x. 1 root root  4198 Dec 14 17:53 dcsnoop\n-rwxr-xr-x. 1 root root  3931 Dec 14 17:53 dcstat\n-rwxr-xr-x. 1 root root 20040 Dec 14 17:53 deadlock_detector\n-rw-r--r--. 1 root root  7105 Dec 14 17:53 deadlock_detector.c\ndrwxr-xr-x. 3 root root  8192 Mar 11 10:28 doc\n-rwxr-xr-x. 1 root root  7588 Dec 14 17:53 execsnoop\n-rwxr-xr-x. 1 root root  6373 Dec 14 17:53 ext4dist\n-rwxr-xr-x. 1 root root 10401 Dec 14 17:53 ext4slower\n...\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal systemitem\">doc\u003C/code> directory in the listing above contains documentation for each tool.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"using-selected-bcc-tools-for-performance-analyses_analyzing-system-performance-with-bpf-compiler_collection\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">36.2. Using selected bcc-tools for performance analyses\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tUse certain pre-created programs from the BPF Compiler Collection (BCC) library to efficiently and securely analyze the system performance on the per-event basis. The set of pre-created programs in the BCC library can serve as examples for creation of additional programs.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"#installing-the-bcc-tools-package_analyzing-system-performance-with-bpf-compiler_collection\" title=\"36.1. Installing the bcc-tools package\">Installed bcc-tools package\u003C/a>\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tRoot permissions\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"variablelist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">Using execsnoop to examine the system processes\u003C/span>\u003C/dt>\u003Cdd>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tRun the \u003Ccode class=\"literal\">execsnoop\u003C/code> program in one terminal:\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>/usr/share/bcc/tools/execsnoop\u003C/strong>\u003C/span>\u003C/pre>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tIn another terminal run, for example:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>ls /usr/share/bcc/tools/doc/\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tThe above creates a short-lived process of the \u003Ccode class=\"literal\">ls\u003C/code> command.\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tThe terminal running \u003Ccode class=\"literal\">execsnoop\u003C/code> shows the output similar to the following:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">PCOMM\tPID    PPID   RET ARGS\nls   \t8382   8287     0 /usr/bin/ls --color=auto /usr/share/bcc/tools/doc/\n...\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">execsnoop\u003C/code> program prints a line of output for each new process, which consumes system resources. It even detects processes of programs that run very shortly, such as \u003Ccode class=\"literal\">ls\u003C/code>, and most monitoring tools would not register them.\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">execsnoop\u003C/code> output displays the following fields:\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">PCOMM\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe parent process name. (\u003Ccode class=\"literal\">ls\u003C/code>)\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">PID\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe process ID. (\u003Ccode class=\"literal\">8382\u003C/code>)\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">PPID\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe parent process ID. (\u003Ccode class=\"literal\">8287\u003C/code>)\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">RET\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe return value of the \u003Ccode class=\"literal\">exec()\u003C/code> system call (\u003Ccode class=\"literal\">0\u003C/code>), which loads program code into new processes.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">ARGS\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe location of the started program with arguments.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cp>\n\t\t\t\tTo see more details, examples, and options for \u003Ccode class=\"literal\">execsnoop\u003C/code>, refer to the \u003Ccode class=\"literal\">/usr/share/bcc/tools/doc/execsnoop_example.txt\u003C/code> file.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tFor more information about \u003Ccode class=\"literal\">exec()\u003C/code>, see \u003Ccode class=\"literal\">exec(3)\u003C/code> manual pages.\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">Using opensnoop to track what files a command opens\u003C/span>\u003C/dt>\u003Cdd>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tRun the \u003Ccode class=\"literal\">opensnoop\u003C/code> program in one terminal:\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>/usr/share/bcc/tools/opensnoop -n uname\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe above prints output for files, which are opened only by the process of the \u003Ccode class=\"literal\">uname\u003C/code> command.\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tIn another terminal, enter:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>uname\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tThe command above opens certain files, which are captured in the next step.\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tThe terminal running \u003Ccode class=\"literal\">opensnoop\u003C/code> shows the output similar to the following:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">PID    COMM \tFD ERR PATH\n8596   uname \t3  0   /etc/ld.so.cache\n8596   uname \t3  0   /lib64/libc.so.6\n8596   uname \t3  0   /usr/lib/locale/locale-archive\n...\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">opensnoop\u003C/code> program watches the \u003Ccode class=\"literal\">open()\u003C/code> system call across the whole system, and prints a line of output for each file that \u003Ccode class=\"literal\">uname\u003C/code> tried to open along the way.\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">opensnoop\u003C/code> output displays the following fields:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">PID\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\t\t\t\tThe process ID. (\u003Ccode class=\"literal\">8596\u003C/code>)\n\t\t\t\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">COMM\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\t\t\t\tThe process name. (\u003Ccode class=\"literal\">uname\u003C/code>)\n\t\t\t\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">FD\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\t\t\t\tThe file descriptor - a value that \u003Ccode class=\"literal\">open()\u003C/code> returns to refer to the open file. (\u003Ccode class=\"literal\">3\u003C/code>)\n\t\t\t\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">ERR\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\t\t\t\tAny errors.\n\t\t\t\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">PATH\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\t\t\t\tThe location of files that \u003Ccode class=\"literal\">open()\u003C/code> tried to open.\n\t\t\t\t\t\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tIf a command tries to read a non-existent file, then the \u003Ccode class=\"literal\">FD\u003C/code> column returns \u003Ccode class=\"literal\">-1\u003C/code> and the \u003Ccode class=\"literal\">ERR\u003C/code> column prints a value corresponding to the relevant error. As a result, \u003Ccode class=\"literal\">opensnoop\u003C/code> can help you identify an application that does not behave properly.\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003C/dd>\u003C/dl>\u003C/div>\u003Cp>\n\t\t\t\tTo see more details, examples, and options for \u003Ccode class=\"literal\">opensnoop\u003C/code>, refer to the \u003Ccode class=\"literal\">/usr/share/bcc/tools/doc/opensnoop_example.txt\u003C/code> file.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tFor more information about \u003Ccode class=\"literal\">open()\u003C/code>, see \u003Ccode class=\"literal\">open(2)\u003C/code> manual pages.\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">Using biotop to examine the I/O operations on the disk\u003C/span>\u003C/dt>\u003Cdd>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tRun the \u003Ccode class=\"literal\">biotop\u003C/code> program in one terminal:\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ol>\u003C/div>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>/usr/share/bcc/tools/biotop 30\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe command enables you to monitor the top processes, which perform I/O operations on the disk. The argument ensures that the command will produce a 30 second summary.\n\t\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\t\tWhen no argument provided, the output screen by default refreshes every 1 second.\n\t\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tIn another terminal enter, for example :\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>dd if=/dev/vda of=/dev/zero\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tThe command above reads the content from the local hard disk device and writes the output to the \u003Ccode class=\"literal\">/dev/zero\u003C/code> file. This step generates certain I/O traffic to illustrate \u003Ccode class=\"literal\">biotop\u003C/code>.\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tThe terminal running \u003Ccode class=\"literal\">biotop\u003C/code> shows the output similar to the following:\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">PID    COMM             D MAJ MIN DISK       I/O  Kbytes     AVGms\n9568   dd               R 252 0   vda      16294 14440636.0  3.69\n48     kswapd0          W 252 0   vda       1763 120696.0    1.65\n7571   gnome-shell      R 252 0   vda        834 83612.0     0.33\n1891   gnome-shell      R 252 0   vda       1379 19792.0     0.15\n7515   Xorg             R 252 0   vda        280  9940.0     0.28\n7579   llvmpipe-1       R 252 0   vda        228  6928.0     0.19\n9515   gnome-control-c  R 252 0   vda         62  6444.0     0.43\n8112   gnome-terminal-  R 252 0   vda         67  2572.0     1.54\n7807   gnome-software   R 252 0   vda         31  2336.0     0.73\n9578   awk              R 252 0   vda         17  2228.0     0.66\n7578   llvmpipe-0       R 252 0   vda        156  2204.0     0.07\n9581   pgrep            R 252 0   vda         58  1748.0     0.42\n7531   InputThread      R 252 0   vda         30  1200.0     0.48\n7504   gdbus            R 252 0   vda          3  1164.0     0.30\n1983   llvmpipe-1       R 252 0   vda         39   724.0     0.08\n1982   llvmpipe-0       R 252 0   vda         36   652.0     0.06\n...\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">biotop\u003C/code> output displays the following fields:\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">PID\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe process ID. (\u003Ccode class=\"literal\">9568\u003C/code>)\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">COMM\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe process name. (\u003Ccode class=\"literal\">dd\u003C/code>)\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">DISK\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe disk performing the read operations. (\u003Ccode class=\"literal\">vda\u003C/code>)\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">I/O\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe number of read operations performed. (16294)\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Kbytes\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe amount of Kbytes reached by the read operations. (14,440,636)\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">AVGms\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tThe average I/O time of read operations. (3.69)\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cp>\n\t\t\t\tTo see more details, examples, and options for \u003Ccode class=\"literal\">biotop\u003C/code>, refer to the \u003Ccode class=\"literal\">/usr/share/bcc/tools/doc/biotop_example.txt\u003C/code> file.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tFor more information about \u003Ccode class=\"literal\">dd\u003C/code>, see \u003Ccode class=\"literal\">dd(1)\u003C/code> manual pages.\n\t\t\t\u003C/p>\u003Ch5 id=\"using_xfsslower_to_expose_unexpectedly_slow_file_system_operations\">Using xfsslower to expose unexpectedly slow file system operations\u003C/h5>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRun the \u003Ccode class=\"literal\">xfsslower\u003C/code> program in one terminal:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>/usr/share/bcc/tools/xfsslower 1\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe command above measures the time the XFS file system spends in performing read, write, open or sync (\u003Ccode class=\"literal\">fsync\u003C/code>) operations. The \u003Ccode class=\"literal\">1\u003C/code> argument ensures that the program shows only the operations that are slower than 1 ms.\n\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\tWhen no arguments provided, \u003Ccode class=\"literal\">xfsslower\u003C/code> by default displays operations slower than 10 ms.\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIn another terminal enter, for example, the following:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ \u003Cspan class=\"strong strong\">\u003Cstrong>vim text\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe command above creates a text file in the \u003Ccode class=\"literal\">vim\u003C/code> editor to initiate certain interaction with the XFS file system.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe terminal running \u003Ccode class=\"literal\">xfsslower\u003C/code> shows something similar upon saving the file from the previous step:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">TIME     COMM           PID    T BYTES   OFF_KB   LAT(ms) FILENAME\n13:07:14 b'bash'        4754   R 256     0           7.11 b'vim'\n13:07:14 b'vim'         4754   R 832     0           4.03 b'libgpm.so.2.1.0'\n13:07:14 b'vim'         4754   R 32      20          1.04 b'libgpm.so.2.1.0'\n13:07:14 b'vim'         4754   R 1982    0           2.30 b'vimrc'\n13:07:14 b'vim'         4754   R 1393    0           2.52 b'getscriptPlugin.vim'\n13:07:45 b'vim'         4754   S 0       0           6.71 b'text'\n13:07:45 b'pool'        2588   R 16      0           5.58 b'text'\n...\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEach line above represents an operation in the file system, which took more time than a certain threshold. \u003Ccode class=\"literal\">xfsslower\u003C/code> is good at exposing possible file system problems, which can take form of unexpectedly slow operations.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">xfsslower\u003C/code> output displays the following fields:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">COMM\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\tThe process name. (\u003Ccode class=\"literal\">b’bash'\u003C/code>)\n\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">T\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tThe operation type. (\u003Ccode class=\"literal\">R\u003C/code>)\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>R\u003C/strong>\u003C/span>ead\n\t\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>W\u003C/strong>\u003C/span>rite\n\t\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\t\t\u003Cspan class=\"strong strong\">\u003Cstrong>S\u003C/strong>\u003C/span>ync\n\t\t\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">OFF_KB\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\tThe file offset in KB. (0)\n\t\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">FILENAME\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\t\tThe file being read, written, or synced.\n\t\t\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003Cp>\n\t\t\t\tTo see more details, examples, and options for \u003Ccode class=\"literal\">xfsslower\u003C/code>, refer to the \u003Ccode class=\"literal\">/usr/share/bcc/tools/doc/xfsslower_example.txt\u003C/code> file.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tFor more information about \u003Ccode class=\"literal\">fsync\u003C/code>, see \u003Ccode class=\"literal\">fsync(2)\u003C/code> manual pages.\n\t\t\t\u003C/p>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"configuring-an-operating-system-to-optimize-memory-access_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 37. Configuring an operating system to optimize memory access\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tYou can configure the operating system to optimize memory access across workloads with the tools that are included in RHEL\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"tools-for-monitoring-and-diagnosing-system-memory-issues_configuring-an-operating-system-to-optimize-memory-access\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">37.1. Tools for monitoring and diagnosing system memory issues\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe following tools are available in Red Hat Enterprise Linux 9 for monitoring system performance and diagnosing performance problems related to system memory:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">vmstat\u003C/code> tool, provided by the \u003Ccode class=\"literal\">procps-ng\u003C/code> package, displays reports of a system’s processes, memory, paging, block I/O, traps, disks, and CPU activity. It provides an instantaneous report of the average of these events since the machine was last turned on, or since the previous report.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">valgrind\u003C/code> framework provides instrumentation to user-space binaries. Install this tool, using the \u003Ccode class=\"literal\">dnf install valgrind\u003C/code> command. It includes a number of tools, that you can use to profile and analyze program performance, such as:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">memcheck\u003C/code> option is the default \u003Ccode class=\"literal\">valgrind\u003C/code> tool. It detects and reports on a number of memory errors that can be difficult to detect and diagnose, such as:\n\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"square\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\tMemory access that should not occur\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\tUndefined or uninitialized value use\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\tIncorrectly freed heap memory\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\tPointer overlap\n\t\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\tMemory leaks\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\t\t\t\t\tMemcheck can only report these errors, it cannot prevent them from occurring. However, \u003Ccode class=\"literal\">memcheck\u003C/code> logs an error message immediately before the error occurs.\n\t\t\t\t\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">cachegrind\u003C/code> option simulates application interaction with a system’s cache hierarchy and branch predictor. It gathers statistics for the duration of application’s execution and outputs a summary to the console.\n\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">massif\u003C/code> option measures the heap space used by a specified application. It measures both useful space and any additional space allocated for bookkeeping and alignment purposes.\n\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">vmstat(8)\u003C/code> and \u003Ccode class=\"literal\">valgrind(1)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/doc/valgrind-version/valgrind_manual.pdf\u003C/code> file\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"overview-of-a-systems-memory_configuring-an-operating-system-to-optimize-memory-access\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">37.2. Overview of a system’s memory\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe Linux Kernel is designed to maximize the utilization of a system’s memory resources (RAM). Due to these design characteristics, and depending on the memory requirements of the workload, part of the system’s memory is in use within the kernel on behalf of the workload, while a small part of the memory is free. This free memory is reserved for special system allocations, and for other low or high priority system services.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe rest of the system’s memory is dedicated to the workload itself, and divided into the following two categories:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">File memory\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tPages added in this category represent parts of files in permanent storage. These pages, from the page cache, can be mapped or unmapped in an application’s address spaces. You can use applications to map files into their address space using the \u003Ccode class=\"literal\">mmap\u003C/code> system calls, or to operate on files via the buffered I/O read or write system calls.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tBuffered I/O system calls, as well as applications that map pages directly, can re-utilize unmapped pages. As a result, these pages are stored in the cache by the kernel, especially when the system is not running any memory intensive tasks, to avoid re-issuing costly I/O operations over the same set of pages.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Anonymous memory\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tPages in this category are in use by a dynamically allocated process, or are not related to files in permanent storage. This set of pages back up the in-memory control structures of each task, such as the application stack and heap areas.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"figure\" id=\"idm140280130515456\">\u003Cp class=\"title\">\u003Cstrong>Figure 37.1. Memory usage patterns\u003C/strong>\u003C/p>\u003Cdiv class=\"figure-contents\">\u003Cdiv class=\"mediaobject\">\u003Cimg src=\"https://access.redhat.com/webassets/avalon/d/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US/images/81d9c47bcca9529ab234cc7297b69aad/RHEL_Memory_Usage_Patterns.png\" alt=\"RHEL Memory Usage Patterns\"/>\u003C/div>\u003C/div>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"virtual-memory-parameters_configuring-an-operating-system-to-optimize-memory-access\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">37.3. Virtual memory parameters\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe virtual memory parameters are listed in the \u003Ccode class=\"literal\">/proc/sys/vm\u003C/code> directory.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe following are the available virtual memory parameters:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">vm.dirty_ratio\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tIs a percentage value. When this percentage of the total system memory is modified, the system begins writing the modifications to the disk. The default value is \u003Ccode class=\"literal\">20\u003C/code> percent.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">vm.dirty_background_ratio\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tA percentage value. When this percentage of total system memory is modified, the system begins writing the modifications to the disk in the background. The default value is \u003Ccode class=\"literal\">10\u003C/code> percent.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">vm.overcommit_memory\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tDefines the conditions that determine whether a large memory request is accepted or denied.The default value is \u003Ccode class=\"literal\">0\u003C/code>.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tBy default, the kernel performs checks if a virtual memory allocation request fits into the present amount of memory (total + swap) and rejects only large requests. Otherwise virtual memory allocations are granted, and this means they allow memory overcommitment.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tSetting the \u003Ccode class=\"literal\">overcommit_memory\u003C/code> parameter’s value:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tWhen this parameter is set to \u003Ccode class=\"literal\">1\u003C/code>, the kernel performs no memory overcommit handling. This increases the possibility of memory overload, but improves performance for memory-intensive tasks.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tWhen this parameter is set to \u003Ccode class=\"literal\">2\u003C/code>, the kernel denies requests for memory equal to or larger than the sum of the total available swap space and the percentage of physical RAM specified in the \u003Ccode class=\"literal\">overcommit_ratio\u003C/code>. This reduces the risk of overcommitting memory, but is recommended only for systems with swap areas larger than their physical memory.\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">vm.overcommit_ratio\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tSpecifies the percentage of physical RAM considered when \u003Ccode class=\"literal\">overcommit_memory\u003C/code> is set to \u003Ccode class=\"literal\">2\u003C/code>. The default value is \u003Ccode class=\"literal\">50\u003C/code>.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">vm.max_map_count\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDefines the maximum number of memory map areas that a process can use. The default value is \u003Ccode class=\"literal\">65530\u003C/code>. Increase this value if your application needs more memory map areas.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">vm.min_free_kbytes\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tSets the size of the reserved free pages pool. It is also responsible for setting the \u003Ccode class=\"literal\">min_page\u003C/code>, \u003Ccode class=\"literal\">low_page\u003C/code>, and \u003Ccode class=\"literal\">high_page\u003C/code> thresholds that govern the behavior of the Linux kernel’s page reclaim algorithms. It also specifies the minimum number of kilobytes to keep free across the system. This calculates a specific value for each low memory zone, each of which is assigned a number of reserved free pages in proportion to their size.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tSetting the \u003Ccode class=\"literal\">vm.min_free_kbytes\u003C/code> parameter’s value:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tIncreasing the parameter value effectively reduces the application working set usable memory. Therefore, you might want to use it for only kernel-driven workloads, where driver buffers need to be allocated in atomic contexts.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tDecreasing the parameter value might render the kernel unable to service system requests, if memory becomes heavily contended in the system.\n\t\t\t\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition warning\" state=\"danger\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Warning\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\t\t\t\tExtreme values can be detrimental to the system’s performance. Setting the \u003Ccode class=\"literal\">vm.min_free_kbytes\u003C/code> to an extremely low value prevents the system from reclaiming memory effectively, which can result in system crashes and failure to service interrupts or other kernel services. However, setting \u003Ccode class=\"literal\">vm.min_free_kbytes\u003C/code> too high considerably increases system reclaim activity, causing allocation latency due to a false direct reclaim state. This might cause the system to enter an out-of-memory state immediately.\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">vm.min_free_kbytes\u003C/code> parameter also sets a page reclaim watermark, called \u003Ccode class=\"literal\">min_pages\u003C/code>. This watermark is used as a factor when determining the two other memory watermarks, \u003Ccode class=\"literal\">low_pages\u003C/code>, and \u003Ccode class=\"literal\">high_pages\u003C/code>, that govern page reclaim algorithms.\n\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ul>\u003C/div>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">/proc/\u003Cspan class=\"emphasis\">\u003Cem>PID\u003C/em>\u003C/span>/oom_adj\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tIn the event that a system runs out of memory, and the \u003Ccode class=\"literal\">panic_on_oom\u003C/code> parameter is set to \u003Ccode class=\"literal\">0\u003C/code>, the \u003Ccode class=\"literal\">oom_killer\u003C/code> function kills processes, starting with the process that has the highest \u003Ccode class=\"literal\">oom_score\u003C/code>, until the system recovers.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe \u003Ccode class=\"literal\">oom_adj\u003C/code> parameter determines the \u003Ccode class=\"literal\">oom_score\u003C/code> of a process. This parameter is set per process identifier. A value of \u003Ccode class=\"literal\">-17\u003C/code> disables the \u003Ccode class=\"literal\">oom_killer\u003C/code> for that process. Other valid values range from \u003Ccode class=\"literal\">-16\u003C/code> to \u003Ccode class=\"literal\">15\u003C/code>.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003C/dl>\u003C/div>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tProcesses created by an adjusted process inherit the \u003Ccode class=\"literal\">oom_score\u003C/code> of that process.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">vm.swappiness\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe swappiness value, ranging from \u003Ccode class=\"literal\">0\u003C/code> to \u003Ccode class=\"literal\">200\u003C/code>, controls the degree to which the system favors reclaiming memory from the anonymous memory pool, or the page cache memory pool.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tSetting the \u003Ccode class=\"literal\">swappiness\u003C/code> parameter’s value:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tHigher values favor file-mapped driven workloads while swapping out the less actively accessed processes’ anonymous mapped memory of RAM. This is useful for file-servers or streaming applications that depend on data, from files in the storage, to reside on memory to reduce I/O latency for the service requests.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tLow values favor anonymous-mapped driven workloads while reclaiming the page cache (file mapped memory). This setting is useful for applications that do not depend heavily on the file system information, and heavily utilize dynamically allocated and private memory, such as mathematical and number crunching applications, and few hardware virtualization supervisors like QEMU.\n\t\t\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\tThe default value of the \u003Ccode class=\"literal\">vm.swappiness\u003C/code> parameter is \u003Ccode class=\"literal\">60\u003C/code>.\n\t\t\t\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition warning\" state=\"danger\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Warning\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\t\t\t\tSetting the \u003Ccode class=\"literal\">vm.swappiness\u003C/code> to \u003Ccode class=\"literal\">0\u003C/code> aggressively avoids swapping anonymous memory out to a disk, this increases the risk of processes being killed by the \u003Ccode class=\"literal\">oom_killer\u003C/code> function when under memory or I/O intensive workloads.\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003C/ul>\u003C/div>\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">sysctl(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index#setting-memory-related-kernel-parameters_configuring-an-operating-system-to-optimize-memory-access\">Setting memory-related kernel parameters\u003C/a>\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"file-system-parameters_configuring-an-operating-system-to-optimize-memory-access\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">37.4. File system parameters\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe file system parameters are listed in the \u003Ccode class=\"literal\">/proc/sys/fs\u003C/code> directory. The following are the available file system parameters:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">aio-max-nr\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDefines the maximum allowed number of events in all active asynchronous input/output contexts. The default value is \u003Ccode class=\"literal\">65536\u003C/code>, and modifying this value does not pre-allocate or resize any kernel data structures.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">file-max\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tDetermines the maximum number of file handles for the entire system. The default value on Red Hat Enterprise Linux 9 is either \u003Ccode class=\"literal\">8192\u003C/code> or one tenth of the free memory pages available at the time the kernel starts, whichever is higher.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tRaising this value can resolve errors caused by a lack of available file handles.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">sysctl(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"kernel-parameters_configuring-an-operating-system-to-optimize-memory-access\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">37.5. Kernel parameters\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe default values for the kernel parameters are located in the \u003Ccode class=\"literal\">/proc/sys/kernel/\u003C/code> directory. These are set default values provided by the kernel or values specified by a user via \u003Ccode class=\"literal\">sysctl\u003C/code>.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe following are the available kernel parameters used to set up limits for the \u003Ccode class=\"literal\">msg*\u003C/code> and \u003Ccode class=\"literal\">shm*\u003C/code> System V IPC (\u003Ccode class=\"literal\">sysvipc\u003C/code>) system calls:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">msgmax\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDefines the maximum allowed size in bytes of any single message in a message queue. This value must not exceed the size of the queue (\u003Ccode class=\"literal\">msgmnb\u003C/code>). Use the \u003Ccode class=\"literal\">sysctl msgmax\u003C/code> command to determine the current \u003Ccode class=\"literal\">msgmax\u003C/code> value on your system.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">msgmnb\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDefines the maximum size in bytes of a single message queue. Use the \u003Ccode class=\"literal\">sysctl msgmnb\u003C/code> command to determine the current \u003Ccode class=\"literal\">msgmnb\u003C/code> value on your system.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">msgmni\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDefines the maximum number of message queue identifiers, and therefore the maximum number of queues. Use the \u003Ccode class=\"literal\">sysctl msgmni\u003C/code> command to determine the current \u003Ccode class=\"literal\">msgmni\u003C/code> value on your system.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">shmall\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDefines the total amount of shared memory \u003Ccode class=\"literal\">pages\u003C/code> that can be used on the system at one time. For example, a page is \u003Ccode class=\"literal\">4096\u003C/code> bytes on the AMD64 and Intel 64 architecture. Use the \u003Ccode class=\"literal\">sysctl shmall\u003C/code> command to determine the current \u003Ccode class=\"literal\">shmall\u003C/code> value on your system.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">shmmax\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDefines the maximum size in bytes of a single shared memory segment allowed by the kernel. Shared memory segments up to 1Gb are now supported in the kernel. Use the \u003Ccode class=\"literal\">sysctl shmmax\u003C/code> command to determine the current \u003Ccode class=\"literal\">shmmax\u003C/code> value on your system.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">shmmni\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tDefines the system-wide maximum number of shared memory segments. The default value is \u003Ccode class=\"literal\">4096\u003C/code> on all systems.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">sysvipc(7)\u003C/code> and \u003Ccode class=\"literal\">sysctl(8)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"setting-memory-related-kernel-parameters_configuring-an-operating-system-to-optimize-memory-access\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">37.6. Setting memory-related kernel parameters\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tSetting a parameter temporarily is useful for determining the effect the parameter has on a system. You can later set the parameter persistently when you are sure that the parameter value has the desired effect.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThis procedure describes how to set a memory-related kernel parameter temporarily and persistently.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo temporarily set the memory-related kernel parameters, edit the respective files in the \u003Ccode class=\"literal\">/proc\u003C/code> file system or the \u003Ccode class=\"literal\">sysctl\u003C/code> tool.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor example, to temporarily set the \u003Ccode class=\"literal\">vm.overcommit_memory\u003C/code> parameter to \u003Cspan class=\"emphasis\">\u003Cem>1\u003C/em>\u003C/span>:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># echo \u003Cspan class=\"emphasis\">\u003Cem>1\u003C/em>\u003C/span> &gt; /proc/sys/vm/overcommit_memory\n# sysctl -w vm.overcommit_memory=\u003Cspan class=\"emphasis\">\u003Cem>1\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo persistently set the memory-related kernel parameter, edit the \u003Ccode class=\"literal\">/etc/sysctl.conf\u003C/code> file and reload the settings.\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor example, to persistently set the \u003Ccode class=\"literal\">vm.overcommit_memory\u003C/code> parameter to \u003Cspan class=\"emphasis\">\u003Cem>1\u003C/em>\u003C/span>:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tAdd the following content in the \u003Ccode class=\"literal\">/etc/sysctl.conf\u003C/code> file:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">vm.overcommit_memory=\u003Cspan class=\"emphasis\">\u003Cem>1\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tReload the \u003Ccode class=\"literal\">sysctl\u003C/code> settings from the \u003Ccode class=\"literal\">/etc/sysctl.conf\u003C/code> file:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># sysctl -p\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">sysctl(8)\u003C/code> and \u003Ccode class=\"literal\">proc(5)\u003C/code> man pages on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/solutions/3530941\">Tuning Red Hat Enterprise Linux for IBM DB2\u003C/a> (Red Hat Knowledgebase)\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"configuring-huge-pages_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 38. Configuring huge pages\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tPhysical memory is managed in fixed-size chunks called pages. On the x86_64 architecture, supported by Red Hat Enterprise Linux 9, the default size of a memory page is \u003Ccode class=\"literal\">4 KB\u003C/code>. This default page size has proved to be suitable for general-purpose operating systems, such as Red Hat Enterprise Linux, which supports many different kinds of workloads.\n\t\t\u003C/p>\u003Cp>\n\t\t\tHowever, specific applications can benefit from using larger page sizes in certain cases. For example, an application that works with a large and relatively fixed data set of hundreds of megabytes or even dozens of gigabytes can have performance issues when using \u003Ccode class=\"literal\">4 KB\u003C/code> pages. Such data sets can require a huge amount of \u003Ccode class=\"literal\">4 KB\u003C/code> pages, which can lead to overhead in the operating system and the CPU.\n\t\t\u003C/p>\u003Cp>\n\t\t\tThis section provides information about huge pages available in RHEL 9 and how you can configure them.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"available-hugepage-features_configuring-huge-pages\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">38.1. Available huge page features\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tWith Red Hat Enterprise Linux 9, you can use huge pages for applications that work with big data sets, and improve the performance of such applications.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThe following are the huge page methods, which are supported in RHEL 9:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">HugeTLB pages\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tHugeTLB pages are also called static huge pages. There are two ways of reserving HugeTLB pages:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\tAt boot time: It increases the possibility of success because the memory has not yet been significantly fragmented. However, on NUMA machines, the number of pages is automatically split among the NUMA nodes.\n\t\t\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/dd>\u003C/dl>\u003C/div>\u003Cp>\n\t\t\t\tFor more information about parameters that influence HugeTLB page behavior at boot time, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/configuring-huge-pages_monitoring-and-managing-system-status-and-performance#parameters-for-reserving-hugetlb-pages-at-boot-time_configuring-huge-pages\">Parameters for reserving HugeTLB pages at boot time\u003C/a> and how to use these parameters to configure HugeTLB pages at boot time, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/configuring-huge-pages_monitoring-and-managing-system-status-and-performance#configuring-hugetlb-at-boot-time_configuring-huge-pages\">Configuring HugeTLB at boot time\u003C/a>.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tAt run time: It allows you to reserve the huge pages per NUMA node. If the run-time reservation is done as early as possible in the boot process, the probability of memory fragmentation is lower.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cp>\n\t\t\t\tFor more information about parameters that influence HugeTLB page behavior at run time, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/monitoring_and_managing_system_status_and_performance/configuring-huge-pages_monitoring-and-managing-system-status-and-performance#parameters-for-reserving-hugetlb-pages-at-run-time_configuring-huge-pages\">Parameters for reserving HugeTLB pages at run time\u003C/a> and how to use these parameters to configure HugeTLB pages at run time, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/monitoring_and_managing_system_status_and_performance/configuring-huge-pages_monitoring-and-managing-system-status-and-performance#configuring-hugetlb-at-run-time_configuring-huge-pages\">Configuring HugeTLB at run time\u003C/a>.\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">Transparent HugePages (THP)\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tWith THP, the kernel automatically assigns huge pages to processes, and therefore there is no need to manually reserve the static huge pages. The following are the two modes of operation in THP:\n\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">system-wide\u003C/code>: Here, the kernel tries to assign huge pages to a process whenever it is possible to allocate the huge pages and the process is using a large contiguous virtual memory area.\n\t\t\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">per-process\u003C/code>: Here, the kernel only assigns huge pages to the memory areas of individual processes which you can specify using the \u003Ccode class=\"literal\">madvise\u003C/code>() system call.\n\t\t\t\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\t\t\t\tThe THP feature only supports \u003Ccode class=\"literal\">2 MB\u003C/code> pages.\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003C/ul>\u003C/div>\u003C/dd>\u003C/dl>\u003C/div>\u003Cp>\n\t\t\t\tFor more information about parameters that influence HugeTLB page behavior at boot time, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/configuring-huge-pages_monitoring-and-managing-system-status-and-performance#enabling-transparent-hugepages_configuring-huge-pages\">Enabling transparent hugepages\u003C/a> and \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/configuring-huge-pages_monitoring-and-managing-system-status-and-performance#disabling-transparent-hugepages_configuring-huge-pages\">Disabling transparent hugepages\u003C/a>.\n\t\t\t\u003C/p>\u003C/section>\u003Csection class=\"section\" id=\"parameters-for-reserving-hugetlb-pages-at-boot-time_configuring-huge-pages\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">38.2. Parameters for reserving HugeTLB pages at boot time\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tUse the following parameters to influence HugeTLB page behavior at boot time.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tFor more infomration on how to use these parameters to configure HugeTLB pages at boot time, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/monitoring_and_managing_system_status_and_performance/configuring-huge-pages_monitoring-and-managing-system-status-and-performance#configuring-hugetlb-at-boot-time_configuring-huge-pages\">Configuring HugeTLB at boot time\u003C/a>.\n\t\t\t\u003C/p>\u003Crh-table id=\"idm140280129468800\">\u003Ctable class=\"lt-4-cols lt-7-rows\">\u003Ccaption>Table 38.1. Parameters used to configure HugeTLB pages at boot time\u003C/caption>\u003Ccolgroup>\u003Ccol style=\"width: 33%; \" class=\"col_1\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 33%; \" class=\"col_2\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 33%; \" class=\"col_3\">\u003C!--Empty-->\u003C/col>\u003C/colgroup>\u003Cthead>\u003Ctr>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280129463008\" scope=\"col\">Parameter\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280129461920\" scope=\"col\">Description\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280129460832\" scope=\"col\">Default value\u003C/th>\u003C/tr>\u003C/thead>\u003Ctbody>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280129463008\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">hugepages\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280129461920\"> \u003Cp>\n\t\t\t\t\t\t\t\tDefines the number of persistent huge pages configured in the kernel at boot time.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003Cp>\n\t\t\t\t\t\t\t\tIn a NUMA system, huge pages, that have this parameter defined, are divided equally between nodes.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003Cp>\n\t\t\t\t\t\t\t\tYou can assign huge pages to specific nodes at runtime by changing the value of the nodes in the \u003Ccode class=\"literal\">/sys/devices/system/node/node_id/hugepages/hugepages-size/nr_hugepages\u003C/code> file.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280129460832\"> \u003Cp>\n\t\t\t\t\t\t\t\tThe default value is \u003Ccode class=\"literal\">0\u003C/code>.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003Cp>\n\t\t\t\t\t\t\t\tTo update this value at boot, change the value of this parameter in the \u003Ccode class=\"literal\">/proc/sys/vm/nr_hugepages\u003C/code> file.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280129463008\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">hugepagesz\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280129461920\"> \u003Cp>\n\t\t\t\t\t\t\t\tDefines the size of persistent huge pages configured in the kernel at boot time.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280129460832\"> \u003Cp>\n\t\t\t\t\t\t\t\tValid values are \u003Ccode class=\"literal\">2 MB\u003C/code> and \u003Ccode class=\"literal\">1 GB\u003C/code>. The default value is \u003Ccode class=\"literal\">2 MB\u003C/code>.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280129463008\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">default_hugepagesz\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280129461920\"> \u003Cp>\n\t\t\t\t\t\t\t\tDefines the default size of persistent huge pages configured in the kernel at boot time.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280129460832\"> \u003Cp>\n\t\t\t\t\t\t\t\tValid values are \u003Ccode class=\"literal\">2 MB\u003C/code> and \u003Ccode class=\"literal\">1 GB\u003C/code>. The default value is \u003Ccode class=\"literal\">2 MB\u003C/code>.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\u003C/rh-table>\u003C/section>\u003Csection class=\"section\" id=\"configuring-hugetlb-at-boot-time_configuring-huge-pages\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">38.3. Configuring HugeTLB at boot time\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThe page size, which the HugeTLB subsystem supports, depends on the architecture. The x86_64 architecture supports \u003Ccode class=\"literal\">2 MB\u003C/code> huge pages and \u003Ccode class=\"literal\">1 GB\u003C/code> gigantic pages.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThis procedure describes how to reserve a \u003Ccode class=\"literal\">1 GB\u003C/code> page at boot time.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo create a HugeTLB pool for \u003Ccode class=\"literal\">1 GB\u003C/code> pages, enable the \u003Ccode class=\"literal\">default_hugepagesz=1G\u003C/code> and \u003Ccode class=\"literal\">hugepagesz=1G\u003C/code> kernel options:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># grubby --update-kernel=ALL --args=\"default_hugepagesz=1G hugepagesz=1G\"\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a new file called \u003Ccode class=\"literal\">hugetlb-gigantic-pages.service\u003C/code> in the \u003Ccode class=\"literal\">/usr/lib/systemd/system/\u003C/code> directory and add the following content:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">[Unit]\nDescription=HugeTLB Gigantic Pages Reservation\nDefaultDependencies=no\nBefore=dev-hugepages.mount\nConditionPathExists=/sys/devices/system/node\nConditionKernelCommandLine=hugepagesz=1G\n\n[Service]\nType=oneshot\nRemainAfterExit=yes\nExecStart=/usr/lib/systemd/hugetlb-reserve-pages.sh\n\n[Install]\nWantedBy=sysinit.target\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate a new file called \u003Ccode class=\"literal\">hugetlb-reserve-pages.sh\u003C/code> in the \u003Ccode class=\"literal\">/usr/lib/systemd/\u003C/code> directory and add the following content:\n\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tWhile adding the following content, replace \u003Cspan class=\"emphasis\">\u003Cem>number_of_pages\u003C/em>\u003C/span> with the number of 1GB pages you want to reserve, and \u003Cspan class=\"emphasis\">\u003Cem>node\u003C/em>\u003C/span> with the name of the node on which to reserve these pages.\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">#!/bin/sh\n\nnodes_path=/sys/devices/system/node/\nif [ ! -d $nodes_path ]; then\n    echo \"ERROR: $nodes_path does not exist\"\n    exit 1\nfi\n\nreserve_pages()\n{\n    echo $1 &gt; $nodes_path/$2/hugepages/hugepages-1048576kB/nr_hugepages\n}\n\nreserve_pages \u003Cspan class=\"emphasis\">\u003Cem>number_of_pages\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>node\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tFor example, to reserve two \u003Ccode class=\"literal\">1 GB\u003C/code> pages on \u003Cspan class=\"emphasis\">\u003Cem>node0\u003C/em>\u003C/span> and one 1GB page on \u003Cspan class=\"emphasis\">\u003Cem>node1\u003C/em>\u003C/span>, replace the \u003Cspan class=\"emphasis\">\u003Cem>number_of_pages\u003C/em>\u003C/span> with 2 for \u003Cspan class=\"emphasis\">\u003Cem>node0\u003C/em>\u003C/span> and 1 for \u003Cspan class=\"emphasis\">\u003Cem>node1\u003C/em>\u003C/span>:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">reserve_pages 2 node0\nreserve_pages 1 node1\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCreate an executable script:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># chmod +x /usr/lib/systemd/hugetlb-reserve-pages.sh\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnable early boot reservation:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># systemctl enable hugetlb-gigantic-pages\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tYou can try reserving more \u003Ccode class=\"literal\">1 GB\u003C/code> pages at runtime by writing to \u003Ccode class=\"literal\">nr_hugepages\u003C/code> at any time. However, to prevent failures due to memory fragmentation, reserve \u003Ccode class=\"literal\">1 GB\u003C/code> pages early during the boot process.\n\t\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\tReserving static huge pages can effectively reduce the amount of memory available to the system, and prevents it from properly utilizing its full memory capacity. Although a properly sized pool of reserved huge pages can be beneficial to applications that utilize it, an oversized or unused pool of reserved huge pages will eventually be detrimental to overall system performance. When setting a reserved huge page pool, ensure that the system can properly utilize its full memory capacity.\n\t\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">systemd.service(5)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/doc/kernel-doc-kernel_version/Documentation/vm/hugetlbpage.txt\u003C/code> file\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"parameters-for-reserving-hugetlb-pages-at-run-time_configuring-huge-pages\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">38.4. Parameters for reserving HugeTLB pages at run time\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tUse the following parameters to influence HugeTLB page behavior at run time.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tFor more information about how to use these parameters to configure HugeTLB pages at run time, see \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html-single/monitoring_and_managing_system_status_and_performance/configuring-huge-pages_monitoring-and-managing-system-status-and-performance#configuring-hugetlb-at-run-time_configuring-huge-pages\">Configuring HugeTLB at run time\u003C/a>.\n\t\t\t\u003C/p>\u003Crh-table id=\"idm140280129398528\">\u003Ctable class=\"lt-4-cols lt-7-rows\">\u003Ccaption>Table 38.2. Parameters used to configure HugeTLB pages at run time\u003C/caption>\u003Ccolgroup>\u003Ccol style=\"width: 33%; \" class=\"col_1\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 33%; \" class=\"col_2\">\u003C!--Empty-->\u003C/col>\u003Ccol style=\"width: 33%; \" class=\"col_3\">\u003C!--Empty-->\u003C/col>\u003C/colgroup>\u003Cthead>\u003Ctr>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280129392736\" scope=\"col\">Parameter\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280129391648\" scope=\"col\">Description\u003C/th>\u003Cth align=\"left\" valign=\"top\" id=\"idm140280129390560\" scope=\"col\">File name\u003C/th>\u003C/tr>\u003C/thead>\u003Ctbody>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280129392736\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">nr_hugepages\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280129391648\"> \u003Cp>\n\t\t\t\t\t\t\t\tDefines the number of huge pages of a specified size assigned to a specified NUMA node.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280129390560\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">/sys/devices/system/node/node_id/hugepages/hugepages-size/nr_hugepages\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003Ctr>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280129392736\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">nr_overcommit_hugepages\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280129391648\"> \u003Cp>\n\t\t\t\t\t\t\t\tDefines the maximum number of additional huge pages that can be created and used by the system through overcommitting memory.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003Cp>\n\t\t\t\t\t\t\t\tWriting any non-zero value into this file indicates that the system obtains that number of huge pages from the kernel’s normal page pool if the persistent huge page pool is exhausted. As these surplus huge pages become unused, they are then freed and returned to the kernel’s normal page pool.\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003Ctd align=\"left\" valign=\"top\" headers=\"idm140280129390560\"> \u003Cp>\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">/proc/sys/vm/nr_overcommit_hugepages\u003C/code>\n\t\t\t\t\t\t\t\u003C/p>\n\t\t\t\t\t\t\t \u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\u003C/rh-table>\u003C/section>\u003Csection class=\"section\" id=\"configuring-hugetlb-at-run-time_configuring-huge-pages\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">38.5. Configuring HugeTLB at run time\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tThis procedure describes how to add \u003Cspan class=\"emphasis\">\u003Cem>20\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>2048 kB\u003C/em>\u003C/span> huge pages to \u003Cspan class=\"emphasis\">\u003Cem>node2\u003C/em>\u003C/span>.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tTo reserve pages based on your requirements, replace:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Cspan class=\"emphasis\">\u003Cem>20\u003C/em>\u003C/span> with the number of huge pages you wish to reserve,\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Cspan class=\"emphasis\">\u003Cem>2048kB\u003C/em>\u003C/span> with the size of the huge pages,\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Cspan class=\"emphasis\">\u003Cem>node2\u003C/em>\u003C/span> with the node on which you wish to reserve the pages.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tDisplay the memory statistics:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># numastat -cm | egrep 'Node|Huge'\n                 Node 0 Node 1 Node 2 Node 3  Total add\nAnonHugePages         0      2      0      8     10\nHugePages_Total       0      0      0      0      0\nHugePages_Free        0      0      0      0      0\nHugePages_Surp        0      0      0      0      0\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tAdd the number of huge pages of a specified size to the node:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># echo \u003Cspan class=\"emphasis\">\u003Cem>20\u003C/em>\u003C/span> &gt; /sys/devices/system/node/node2/hugepages/hugepages-\u003Cspan class=\"emphasis\">\u003Cem>2048kB\u003C/em>\u003C/span>/nr_hugepages\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnsure that the number of huge pages are added:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># numastat -cm | egrep 'Node|Huge'\n                 Node 0 Node 1 Node 2 Node 3  Total\nAnonHugePages         0      2      0      8     10\nHugePages_Total       0      0     40      0     40\nHugePages_Free        0      0     40      0     40\nHugePages_Surp        0      0      0      0      0\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">numastat(8)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"enabling-transparent-hugepages_configuring-huge-pages\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">38.6. Enabling transparent hugepages\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tTHP is enabled by default in Red Hat Enterprise Linux 9. However, you can enable or disable THP.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThis procedure describes how to enable THP.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCheck the current status of THP:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># cat /sys/kernel/mm/transparent_hugepage/enabled\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEnable THP:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># echo always &gt; /sys/kernel/mm/transparent_hugepage/enabled\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo prevent applications from allocating more memory resources than necessary, disable the system-wide transparent huge pages and only enable them for the applications that explicitly request it through the \u003Ccode class=\"literal\">madvise\u003C/code>:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># echo madvise &gt; /sys/kernel/mm/transparent_hugepage/enabled\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tSometimes, providing low latency to short-lived allocations has higher priority than immediately achieving the best performance with long-lived allocations. In such cases, you can disable direct compaction while leaving THP enabled.\n\t\t\t\t\u003C/p>\u003Cp>\n\t\t\t\t\tDirect compaction is a synchronous memory compaction during the huge page allocation. Disabling direct compaction provides no guarantee of saving memory, but can decrease the risk of higher latencies during frequent page faults. Note that if the workload benefits significantly from THP, the performance decreases. Disable direct compaction:\n\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># echo madvise &gt; /sys/kernel/mm/transparent_hugepage/defrag\u003C/pre>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">madvise(2)\u003C/code> man page on your system\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index#disabling-transparent-hugepages_configuring-huge-pages\">Disabling transparent hugepages\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"disabling-transparent-hugepages_configuring-huge-pages\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">38.7. Disabling transparent hugepages\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tTHP is enabled by default in Red Hat Enterprise Linux 9. However, you can enable or disable THP.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tThis procedure describes how to disable THP.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tCheck the current status of THP:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># cat /sys/kernel/mm/transparent_hugepage/enabled\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tDisable THP:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"impact-of-page-size-on-translation-lookaside-buffer-size_configuring-huge-pages\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">38.8. Impact of page size on translation lookaside buffer size\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tReading address mappings from the page table is time-consuming and resource-expensive, so CPUs are built with a cache for recently-used addresses, called the Translation Lookaside Buffer (TLB). However, the default TLB can only cache a certain number of address mappings.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tIf a requested address mapping is not in the TLB, called a TLB miss, the system still needs to read the page table to determine the physical to virtual address mapping. Because of the relationship between application memory requirements and the size of pages used to cache address mappings, applications with large memory requirements are more likely to suffer performance degradation from TLB misses than applications with minimal memory requirements. It is therefore important to avoid TLB misses wherever possible.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tBoth HugeTLB and Transparent Huge Page features allow applications to use pages larger than \u003Ccode class=\"literal\">4 KB\u003C/code>. This allows addresses stored in the TLB to reference more memory, which reduces TLB misses and improves application performance.\n\t\t\t\u003C/p>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"getting-started-with-systemtap_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 39. Getting started with SystemTap\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tAs a system administrator, you can use SystemTap to identify underlying causes of a bug or performance problem on a running RHEL system.\n\t\t\u003C/p>\u003Cp>\n\t\t\tAs an application developer, you can use SystemTap to monitor in fine detail how your application behaves within the RHEL system.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"the-purpose-of-systemtap_getting-started-with-systemtap\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">39.1. The purpose of SystemTap\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tSystemTap is a tracing and probing tool that you can use to study and monitor the activities of your operating system (particularly, the kernel) in fine detail. SystemTap provides information similar to the output of tools such as \u003Ccode class=\"literal\">netstat\u003C/code>, \u003Ccode class=\"literal\">ps\u003C/code>, \u003Ccode class=\"literal\">top\u003C/code>, and \u003Ccode class=\"literal\">iostat\u003C/code>. However, SystemTap provides more filtering and analysis options for collected information. In SystemTap scripts, you specify the information that SystemTap gathers.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tSystemTap aims to supplement the existing suite of Linux monitoring tools by providing users with the infrastructure to track kernel activity and combining this capability with two attributes:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Cspan class=\"strong strong\">\u003Cstrong>Flexibility\u003C/strong>\u003C/span>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tthe SystemTap framework enables you to develop simple scripts for investigating and monitoring a wide variety of kernel functions, system calls, and other events that occur in kernel space. With this, SystemTap is not so much a tool as it is a system that allows you to develop your own kernel-specific forensic and monitoring tools.\n\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Cspan class=\"strong strong\">\u003Cstrong>Ease-of-Use\u003C/strong>\u003C/span>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tSystemTap enables you to monitor kernel activity without having to recompile the kernel or reboot the system.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"installing-systemtap_getting-started-with-systemtap\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">39.2. Installing SystemTap\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tTo begin using SystemTap, install the required packages. To use SystemTap on more than one kernel where a system has multiple kernels installed, install the corresponding required kernel packages for \u003Cspan class=\"emphasis\">\u003Cem>each\u003C/em>\u003C/span> kernel version.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tYou have enabled debug repositories as described in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/developing_c_and_cpp_applications_in_rhel_9/setting-up-a-development-workstation_developing-applications#enabling-debug-and-source-repositories_setting-up-a-development-workstation\">Enabling debug and source repositories\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInstall the required SystemTap packages:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf install systemtap\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tInstall the required kernel packages:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tUsing \u003Ccode class=\"literal\">stap-prep\u003C/code>:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stap-prep\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tIf \u003Ccode class=\"literal\">stap-prep\u003C/code> does not work, install the required kernel packages manually:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf install kernel-debuginfo-$(uname -r) kernel-debuginfo-common-$(uname -i)-$(uname -r) kernel-devel-$(uname -r)\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\u003Ccode class=\"literal\">$(uname -i)\u003C/code> is automatically replaced with the hardware platform of your system and \u003Ccode class=\"literal\">$(uname -r)\u003C/code> is automatically replaced with the version of your running kernel.\n\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Verification\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tIf the kernel to be probed with SystemTap is currently in use, test if your installation was successful:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stap -v -e 'probe kernel.function(\"vfs_read\") {printf(\"read performed\\n\"); exit()}'\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tA successful SystemTap deployment results in an output similar to the following:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">Pass 1: parsed user script and 45 library script(s) in 340usr/0sys/358real ms.\nPass 2: analyzed script: 1 probe(s), 1 function(s), 0 embed(s), 0 global(s) in 290usr/260sys/568real ms.\nPass 3: translated to C into \"/tmp/stapiArgLX/stap_e5886fa50499994e6a87aacdc43cd392_399.c\" in 490usr/430sys/938real ms.\nPass 4: compiled C into \"stap_e5886fa50499994e6a87aacdc43cd392_399.ko\" in 3310usr/430sys/3714real ms.\nPass 5: starting run. \u003Cspan id=\"CO1-1\">\u003C!--Empty-->\u003C/span>\u003Cspan class=\"callout\">1\u003C/span>\nread performed \u003Cspan id=\"CO1-2\">\u003C!--Empty-->\u003C/span>\u003Cspan class=\"callout\">2\u003C/span>\nPass 5: run completed in 10usr/40sys/73real ms. \u003Cspan id=\"CO1-3\">\u003C!--Empty-->\u003C/span>\u003Cspan class=\"callout\">3\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe last three lines of output (beginning with \u003Ccode class=\"literal\">Pass 5\u003C/code>) indicate that:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"calloutlist\">\u003Cdl class=\"calloutlist\">\u003Cdt>\u003Ca href=\"#CO1-1\">\u003Cspan class=\"callout\">1\u003C/span>\u003C/a> \u003C/dt>\u003Cdd>\u003Cdiv class=\"para\">\n\t\t\t\t\t\t\t\tSystemTap successfully created the instrumentation to probe the kernel and ran the instrumentation.\n\t\t\t\t\t\t\t\u003C/div>\u003C/dd>\u003Cdt>\u003Ca href=\"#CO1-2\">\u003Cspan class=\"callout\">2\u003C/span>\u003C/a> \u003C/dt>\u003Cdd>\u003Cdiv class=\"para\">\n\t\t\t\t\t\t\t\tSystemTap detected the specified event (in this case, A VFS read).\n\t\t\t\t\t\t\t\u003C/div>\u003C/dd>\u003Cdt>\u003Ca href=\"#CO1-3\">\u003Cspan class=\"callout\">3\u003C/span>\u003C/a> \u003C/dt>\u003Cdd>\u003Cdiv class=\"para\">\n\t\t\t\t\t\t\t\tSystemTap executed a valid handler (printed text and then closed it with no errors).\n\t\t\t\t\t\t\t\u003C/div>\u003C/dd>\u003C/dl>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"privileges-to-run-systemtap_getting-started-with-systemtap\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">39.3. Privileges to run SystemTap\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tRunning SystemTap scripts requires elevated system privileges but, in some instances, non-privileged users might need to run SystemTap instrumentation on their machine.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tTo allow users to run SystemTap without root access, add users to \u003Cspan class=\"strong strong\">\u003Cstrong>both\u003C/strong>\u003C/span> of these user groups:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">stapdev\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tMembers of this group can use \u003Ccode class=\"literal\">stap\u003C/code> to run SystemTap scripts, or \u003Ccode class=\"literal\">staprun\u003C/code> to run SystemTap instrumentation modules.\n\t\t\t\t\t\t\u003C/p>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tRunning \u003Ccode class=\"literal\">stap\u003C/code> involves compiling SystemTap scripts into kernel modules and loading them into the kernel. This requires elevated privileges to the system, which are granted to \u003Ccode class=\"literal\">stapdev\u003C/code> members. Unfortunately, such privileges also grant effective root access to \u003Ccode class=\"literal\">stapdev\u003C/code> members. As such, only grant \u003Ccode class=\"literal\">stapdev\u003C/code> group membership to users who can be trusted with root access.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Ccode class=\"literal\">stapusr\u003C/code>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\tMembers of this group can only use \u003Ccode class=\"literal\">staprun\u003C/code> to run SystemTap instrumentation modules. In addition, they can only run those modules from the \u003Ccode class=\"literal\">/lib/modules/\u003Cspan class=\"emphasis\">\u003Cem>kernel_version\u003C/em>\u003C/span>/systemtap/\u003C/code> directory. This directory must be owned only by the root user, and must only be writable by the root user.\n\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"running-systemtap-scripts_getting-started-with-systemtap\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">39.4. Running SystemTap scripts\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tYou can run SystemTap scripts from standard input or from a file.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tSample scripts that are distributed with the installation of SystemTap can be found in the \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-systemtap_monitoring-and-managing-system-status-and-performance#useful-examples-of-systemtap-scripts\">Useful examples of SystemTap scripts\u003C/a> or in the \u003Ccode class=\"literal\">/usr/share/systemtap/examples\u003C/code> directory.\n\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tSystemTap and the associated required kernel packages are installed as described in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-systemtap_monitoring-and-managing-system-status-and-performance#installing-systemtap_getting-started-with-systemtap\">Installing Systemtap\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tTo run SystemTap scripts as a normal user, add the user to the SystemTap groups:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># usermod --append --groups\nstapdev,stapusr \u003Cspan class=\"emphasis\">\u003Cem>user-name\u003C/em>\u003C/span>\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRun the SystemTap script:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"circle\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tFrom standard input:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>stap -e \"probe timer.s(1) {exit()}\"\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tThis command instructs \u003Ccode class=\"literal\">stap -e\u003C/code> to run the script in parenthesis to standard input.\n\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tFrom a file:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>stap \u003Cspan class=\"emphasis\">\u003Cem>file_name\u003C/em>\u003C/span>.stp\u003C/strong>\u003C/span>\u003C/pre>\u003C/li>\u003C/ul>\u003C/div>\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003Csection class=\"section\" id=\"useful-examples-of-systemtap-scripts_getting-started-with-systemtap\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">39.5. Useful examples of SystemTap scripts\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tSample example scripts that are distributed with the installation of SystemTap can be found in the \u003Ccode class=\"literal\">/usr/share/systemtap/examples\u003C/code> directory.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tYou can use the \u003Ccode class=\"literal command\">stap\u003C/code> command to execute different SystemTap scripts:\n\t\t\t\u003C/p>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">Tracing function calls\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tYou can use the \u003Ccode class=\"literal\">para-callgraph.stp\u003C/code> SystemTap script to trace function calls and function returns.\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>stap para-callgraph.stp \u003Cspan class=\"emphasis\">\u003Cem>argument1\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>argument2\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThe script takes two command-line arguments: The name of the function(s) whose entry/exit you are tracing. An optional trigger function, which enables or disables tracing on a per-thread basis. Tracing in each thread will continue as long as the trigger function has not exited yet.\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Monitoring polling applications\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tYou can use the timeout.stp SystemTap script to identify and monitor which applications are polling. Knowing this, you can track unnecessary or excessive polling, which helps you pinpoint areas for improvement in terms of CPU usage and power savings.\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>stap timeout.stp\u003C/strong>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tThis script tracks how many times each application uses \u003Ccode class=\"literal\">poll\u003C/code>, \u003Ccode class=\"literal\">select\u003C/code>, \u003Ccode class=\"literal\">epoll\u003C/code>, \u003Ccode class=\"literal\">itimer\u003C/code>, \u003Ccode class=\"literal\">futex\u003C/code>, \u003Ccode class=\"literal\">nanosleep\u003C/code> and \u003Ccode class=\"literal\">Signal\u003C/code> system calls over time\n\t\t\t\t\t\t\u003C/p>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Tracking system call volume per process\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tYou can use the \u003Ccode class=\"literal\">syscalls_by_proc.stp\u003C/code> SystemTap script to see what processes are performing the highest volume of system calls. It displays the 20 processes performing the most of system calls.\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>stap syscalls_by_proc.stp\u003C/strong>\u003C/span>\u003C/pre>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Tracing functions called in network socket code\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tYou can use the \u003Ccode class=\"literal\">socket-trace.stp\u003C/code> example SystemTap script to trace functions called from the kernel’s net/socket.c file. This helps you identify how each process interacts with the network at the kernel level in fine detail.\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>stap socket-trace.stp\u003C/strong>\u003C/span>\u003C/pre>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Tracking I/O time for each file read or write\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tYou can use the \u003Ccode class=\"literal\">iotime.stp\u003C/code> SystemTap script to monitor the amount of time it takes for each process to read from or write to any file. This helps you to determine what files are slow to load on a system.\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>stap iotime.stp\u003C/strong>\u003C/span>\u003C/pre>\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">Track IRQ’s and other processes stealing cycles from a task\u003C/span>\u003C/dt>\u003Cdd>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\tYou can use the \u003Ccode class=\"literal\">cycle_thief.stp\u003C/code> SystemTap script to track the amount of time a task is running and the amount of time it is not running. This helps you to identify which processes are stealing cycles from a task.\n\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># \u003Cspan class=\"strong strong\">\u003Cstrong>stap cycle_thief.stp -x \u003Cspan class=\"emphasis\">\u003Cem>pid\u003C/em>\u003C/span>\u003C/strong>\u003C/span>\u003C/pre>\u003C/dd>\u003C/dl>\u003C/div>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Note\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tYou can find more examples and information about SystemTap scripts in the \u003Ccode class=\"literal\">/usr/share/systemtap/examples/index.html\u003C/code> file. Open it in a web browser to see a list of all the available scripts and their descriptions.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"itemizedlist _additional-resources\">\u003Cp class=\"title\">\u003Cstrong>Additional resources\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist _additional-resources\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\t\u003Ccode class=\"literal\">/usr/share/systemtap/examples\u003C/code> directory\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003C/section>\u003C/section>\u003Csection class=\"chapter\" id=\"cross-instrumentation-of-systemtap_monitoring-and-managing-system-status-and-performance\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch2 class=\"title\">Chapter 40. Cross-instrumentation of SystemTap\u003C/h2>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\tCross-instrumentation of SystemTap is creating SystemTap instrumentation modules from a SystemTap script on one system to be used on another system that does not have SystemTap fully deployed.\n\t\t\u003C/p>\u003Csection class=\"section\" id=\"systemtap-cross-instrumentation_cross-instrumentation-of-systemtap\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">40.1. SystemTap cross-instrumentation\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tWhen you run a SystemTap script, a kernel module is built out of that script. SystemTap then loads the module into the kernel.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tNormally, SystemTap scripts can run only on systems where SystemTap is deployed. To run SystemTap on ten systems, SystemTap needs to be deployed on all those systems. In some cases, this might be neither feasible nor desired. For example, corporate policy might prohibit you from installing packages that provide compilers or debug information about specific machines, which will prevent the deployment of SystemTap.\n\t\t\t\u003C/p>\u003Cp>\n\t\t\t\tTo work around this, use \u003Cspan class=\"emphasis\">\u003Cem>cross-instrumentation\u003C/em>\u003C/span>. Cross-instrumentation is the process of generating SystemTap instrumentation modules from a SystemTap script on one system to be used on another system. This process offers the following benefits:\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe kernel information packages for various machines can be installed on a single host machine.\n\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\tKernel packaging bugs may prevent the installation. In such cases, the \u003Ccode class=\"literal\">kernel-debuginfo\u003C/code> and \u003Ccode class=\"literal\">kernel-devel\u003C/code> packages for the \u003Cspan class=\"emphasis\">\u003Cem>host system\u003C/em>\u003C/span> and \u003Cspan class=\"emphasis\">\u003Cem>target system\u003C/em>\u003C/span> must match. If a bug occurs, report the bug at \u003Ca class=\"link\" href=\"https://bugzilla.redhat.com/\">https://bugzilla.redhat.com/\u003C/a>.\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tEach \u003Cspan class=\"emphasis\">\u003Cem>target machine\u003C/em>\u003C/span> needs only one package to be installed to use the generated SystemTap instrumentation module: \u003Ccode class=\"literal\">systemtap-runtime\u003C/code>.\n\t\t\t\t\t\u003C/p>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\t\t\tThe \u003Cspan class=\"emphasis\">\u003Cem>host system\u003C/em>\u003C/span> must be the same architecture and running the same distribution of Linux as the \u003Cspan class=\"emphasis\">\u003Cem>target system\u003C/em>\u003C/span> in order for the built \u003Cspan class=\"emphasis\">\u003Cem>instrumentation module\u003C/em>\u003C/span> to work.\n\t\t\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003C/li>\u003C/ul>\u003C/div>\u003Crh-alert class=\"admonition note\" state=\"info\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Terminology\u003C/div>\u003Cdiv>\u003Cdiv class=\"variablelist\">\u003Cdl class=\"variablelist\">\u003Cdt>\u003Cspan class=\"term\">\u003Cspan class=\"emphasis\">\u003Cem>instrumentation module\u003C/em>\u003C/span>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\tThe kernel module built from a SystemTap script; the SystemTap module is built on the \u003Cspan class=\"emphasis\">\u003Cem>host system\u003C/em>\u003C/span>, and will be loaded on the \u003Cspan class=\"emphasis\">\u003Cem>target kernel\u003C/em>\u003C/span> of the \u003Cspan class=\"emphasis\">\u003Cem>target system\u003C/em>\u003C/span>.\n\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Cspan class=\"emphasis\">\u003Cem>host system\u003C/em>\u003C/span>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\tThe system on which the instrumentation modules (from SystemTap scripts) are compiled, to be loaded on \u003Cspan class=\"emphasis\">\u003Cem>target systems\u003C/em>\u003C/span>.\n\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Cspan class=\"emphasis\">\u003Cem>target system\u003C/em>\u003C/span>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\tThe system in which the \u003Cspan class=\"emphasis\">\u003Cem>instrumentation module\u003C/em>\u003C/span> is being built (from SystemTap scripts).\n\t\t\t\t\t\t\t\u003C/dd>\u003Cdt>\u003Cspan class=\"term\">\u003Cspan class=\"emphasis\">\u003Cem>target kernel\u003C/em>\u003C/span>\u003C/span>\u003C/dt>\u003Cdd>\n\t\t\t\t\t\t\t\tThe kernel of the \u003Cspan class=\"emphasis\">\u003Cem>target system\u003C/em>\u003C/span>. This is the kernel that loads and runs the \u003Cspan class=\"emphasis\">\u003Cem>instrumentation module\u003C/em>\u003C/span>.\n\t\t\t\t\t\t\t\u003C/dd>\u003C/dl>\u003C/div>\u003C/div>\u003C/rh-alert>\u003C/section>\u003Csection class=\"section\" id=\"initializing-cross-instrumentation-of-systemtap_cross-instrumentation-of-systemtap\">\u003Cdiv class=\"titlepage\">\u003Cdiv>\u003Cdiv>\u003Ch3 class=\"title\">40.2. Initializing cross-instrumentation of SystemTap\u003C/h3>\u003C/div>\u003C/div>\u003C/div>\u003Cp class=\"_abstract _abstract\">\n\t\t\t\tInitialize cross-instrumentation of SystemTap to build SystemTap instrumentation modules from a SystemTap script on one system and use them on another system that does not have SystemTap fully deployed.\n\t\t\t\u003C/p>\u003Cdiv class=\"itemizedlist\">\u003Cp class=\"title\">\u003Cstrong>Prerequisites\u003C/strong>\u003C/p>\u003Cul class=\"itemizedlist\" type=\"disc\">\u003Cli class=\"listitem\">\n\t\t\t\t\t\tSystemTap is installed on the \u003Cspan class=\"emphasis\">\u003Cem>host system\u003C/em>\u003C/span> as described in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-systemtap_monitoring-and-managing-system-status-and-performance#installing-systemtap_getting-started-with-systemtap\">Installing Systemtap\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tThe \u003Ccode class=\"literal\">systemtap-runtime\u003C/code> package is installed on each \u003Cspan class=\"emphasis\">\u003Cem>target system\u003C/em>\u003C/span>:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># dnf install systemtap-runtime\u003C/pre>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tBoth the \u003Cspan class=\"emphasis\">\u003Cem>host system\u003C/em>\u003C/span> and \u003Cspan class=\"emphasis\">\u003Cem>target system\u003C/em>\u003C/span> are the same architecture.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tBoth the \u003Cspan class=\"emphasis\">\u003Cem>host system\u003C/em>\u003C/span> and \u003Cspan class=\"emphasis\">\u003Cem>target system\u003C/em>\u003C/span> are running the same major version of Red Hat Enterprise Linux (such as Red Hat Enterprise Linux 9).\n\t\t\t\t\t\u003C/li>\u003C/ul>\u003C/div>\u003Crh-alert class=\"admonition important\" state=\"warning\">\u003Cdiv class=\"admonition_header\" slot=\"header\">Important\u003C/div>\u003Cdiv>\u003Cp>\n\t\t\t\t\tKernel packaging bugs may prevent multiple \u003Ccode class=\"literal\">kernel-debuginfo\u003C/code> and \u003Ccode class=\"literal\">kernel-devel\u003C/code> packages from being installed on one system. In such cases, the minor version for the \u003Cspan class=\"emphasis\">\u003Cem>host system\u003C/em>\u003C/span> and \u003Cspan class=\"emphasis\">\u003Cem>target system\u003C/em>\u003C/span> must match. If a bug occurs, report it at \u003Ca class=\"link\" href=\"https://bugzilla.redhat.com/\">https://bugzilla.redhat.com/\u003C/a>.\n\t\t\t\t\u003C/p>\u003C/div>\u003C/rh-alert>\u003Cdiv class=\"orderedlist\">\u003Cp class=\"title\">\u003Cstrong>Procedure\u003C/strong>\u003C/p>\u003Col class=\"orderedlist\" type=\"1\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tDetermine the kernel running on each \u003Cspan class=\"emphasis\">\u003Cem>target system\u003C/em>\u003C/span>:\n\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\">$ uname -r\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\tRepeat this step for each \u003Cspan class=\"emphasis\">\u003Cem>target system\u003C/em>\u003C/span>.\n\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\n\t\t\t\t\t\tOn the \u003Cspan class=\"emphasis\">\u003Cem>host system\u003C/em>\u003C/span>, install the \u003Cspan class=\"emphasis\">\u003Cem>target kernel\u003C/em>\u003C/span> and related packages for each \u003Cspan class=\"emphasis\">\u003Cem>target system\u003C/em>\u003C/span> by the method described in \u003Ca class=\"link\" href=\"https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/getting-started-with-systemtap_monitoring-and-managing-system-status-and-performance#installing-systemtap_getting-started-with-systemtap\">Installing Systemtap\u003C/a>.\n\t\t\t\t\t\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\tBuild an instrumentation module on the \u003Cspan class=\"emphasis\">\u003Cem>host system\u003C/em>\u003C/span>, copy this module to and run this module on on the \u003Cspan class=\"emphasis\">\u003Cem>target system\u003C/em>\u003C/span> either:\n\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"a\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tUsing remote implementation:\n\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stap --remote \u003Cspan class=\"emphasis\">\u003Cem>target_system\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>script\u003C/em>\u003C/span>\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tThis command remotely implements the specified script on the \u003Cspan class=\"emphasis\">\u003Cem>target system\u003C/em>\u003C/span>. You must ensure an SSH connection can be made to the \u003Cspan class=\"emphasis\">\u003Cem>target system\u003C/em>\u003C/span> from the \u003Cspan class=\"emphasis\">\u003Cem>host system\u003C/em>\u003C/span> for this to be successful.\n\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\tManually:\n\t\t\t\t\t\t\t\u003C/p>\u003Cdiv class=\"orderedlist\">\u003Col class=\"orderedlist\" type=\"i\">\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\tBuild the instrumentation module on the \u003Cspan class=\"emphasis\">\u003Cem>host system\u003C/em>\u003C/span>:\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># stap -r \u003Cspan class=\"emphasis\">\u003Cem>kernel_version\u003C/em>\u003C/span> \u003Cspan class=\"emphasis\">\u003Cem>script\u003C/em>\u003C/span> -m \u003Cspan class=\"emphasis\">\u003Cem>module_name\u003C/em>\u003C/span> -p 4\u003C/pre>\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\tHere, \u003Cspan class=\"emphasis\">\u003Cem>kernel_version\u003C/em>\u003C/span> refers to the version of the \u003Cspan class=\"emphasis\">\u003Cem>target kernel\u003C/em>\u003C/span> determined in step 1, \u003Cspan class=\"emphasis\">\u003Cem>script\u003C/em>\u003C/span> refers to the script to be converted into an \u003Cspan class=\"emphasis\">\u003Cem>instrumentation module\u003C/em>\u003C/span>, and \u003Cspan class=\"emphasis\">\u003Cem>module_name\u003C/em>\u003C/span> is the desired name of the \u003Cspan class=\"emphasis\">\u003Cem>instrumentation module\u003C/em>\u003C/span>. The \u003Ccode class=\"literal\">-p4\u003C/code> option tells SystemTap to not load and run the compiled module.\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003C/li>\u003Cli class=\"listitem\">\u003Cp class=\"simpara\">\n\t\t\t\t\t\t\t\t\t\tOnce the \u003Cspan class=\"emphasis\">\u003Cem>instrumentation module\u003C/em>\u003C/span> is compiled, copy it to the target system and load it using the following command:\n\t\t\t\t\t\t\t\t\t\u003C/p>\u003Cpre class=\"screen\"># staprun \u003Cspan class=\"emphasis\">\u003Cem>module_name\u003C/em>\u003C/span>.ko\u003C/pre>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003C/li>\u003C/ol>\u003C/div>\u003C/section>\u003C/section>\u003Cdiv>\u003Cdiv xml:lang=\"en-US\" class=\"legalnotice\" id=\"idm140280140052320\">\u003Ch2 class=\"legalnotice\">Legal Notice\u003C/h2>\u003Cdiv class=\"para\">\n\t\tCopyright \u003Cspan class=\"trademark\">\u003C!--Empty-->\u003C/span>© 2024 Red Hat, Inc.\n\t\u003C/div>\u003Cdiv class=\"para\">\n\t\tThe text of and illustrations in this document are licensed by Red Hat under a Creative Commons Attribution–Share Alike 3.0 Unported license (\"CC-BY-SA\"). An explanation of CC-BY-SA is available at \u003Ca class=\"uri\" href=\"http://creativecommons.org/licenses/by-sa/3.0/\">http://creativecommons.org/licenses/by-sa/3.0/\u003C/a>. In accordance with CC-BY-SA, if you distribute this document or an adaptation of it, you must provide the URL for the original version.\n\t\u003C/div>\u003Cdiv class=\"para\">\n\t\tRed Hat, as the licensor of this document, waives the right to enforce, and agrees not to assert, Section 4d of CC-BY-SA to the fullest extent permitted by applicable law.\n\t\u003C/div>\u003Cdiv class=\"para\">\n\t\tRed Hat, Red Hat Enterprise Linux, the Shadowman logo, the Red Hat logo, JBoss, OpenShift, Fedora, the Infinity logo, and RHCE are trademarks of Red Hat, Inc., registered in the United States and other countries.\n\t\u003C/div>\u003Cdiv class=\"para\">\n\t\t\u003Cspan class=\"trademark\">Linux\u003C/span>® is the registered trademark of Linus Torvalds in the United States and other countries.\n\t\u003C/div>\u003Cdiv class=\"para\">\n\t\t\u003Cspan class=\"trademark\">Java\u003C/span>® is a registered trademark of Oracle and/or its affiliates.\n\t\u003C/div>\u003Cdiv class=\"para\">\n\t\t\u003Cspan class=\"trademark\">XFS\u003C/span>® is a trademark of Silicon Graphics International Corp. or its subsidiaries in the United States and/or other countries.\n\t\u003C/div>\u003Cdiv class=\"para\">\n\t\t\u003Cspan class=\"trademark\">MySQL\u003C/span>® is a registered trademark of MySQL AB in the United States, the European Union and other countries.\n\t\u003C/div>\u003Cdiv class=\"para\">\n\t\t\u003Cspan class=\"trademark\">Node.js\u003C/span>® is an official trademark of Joyent. Red Hat is not formally related to or endorsed by the official Joyent Node.js open source or commercial project.\n\t\u003C/div>\u003Cdiv class=\"para\">\n\t\tThe \u003Cspan class=\"trademark\">OpenStack\u003C/span>® Word Mark and OpenStack logo are either registered trademarks/service marks or trademarks/service marks of the OpenStack Foundation, in the United States and other countries and are used with the OpenStack Foundation's permission. We are not affiliated with, endorsed or sponsored by the OpenStack Foundation, or the OpenStack community.\n\t\u003C/div>\u003Cdiv class=\"para\">\n\t\tAll other trademarks are the property of their respective owners.\n\t\u003C/div>\u003C/div>\u003C/div>\u003C/div>\u003C/body>",[14,21,26,123,188,209,230,296,333,354,379,440,461,494,511,630,647,731,749,779,801,855,877,895,913,931,957,979,993,1007,1021,1057,1107,1313,1343,1409,1427,1449,1463,1493,1531,1557,1571],{"title":11,"visible":15,"weight":16,"urlFragment":17,"anchor":18,"singlePageAnchor":18,"docTitle":19,"url":20},true,1,"index",null,"monitoring_and_managing_system_status_and_performance","#",{"title":22,"visible":15,"weight":23,"urlFragment":24,"anchor":18,"singlePageAnchor":24,"docTitle":19,"url":25},"Providing feedback on Red Hat documentation",2,"proc_providing-feedback-on-red-hat-documentation_monitoring-and-managing-system-status-and-performance","#proc_providing-feedback-on-red-hat-documentation_monitoring-and-managing-system-status-and-performance",{"title":27,"visible":15,"weight":28,"urlFragment":29,"anchor":18,"singlePageAnchor":29,"sections":30,"docTitle":19,"url":122},"1. Getting started with TuneD",3,"getting-started-with-tuned_monitoring-and-managing-system-status-and-performance",[31,35,39,43,48,53,58,63,68,73,78,83,88,93,98,103,117],{"title":32,"visible":15,"weight":16,"urlFragment":29,"anchor":33,"singlePageAnchor":33,"docTitle":19,"url":34},"1.1. The purpose of TuneD","the-purpose-of-tuned_getting-started-with-tuned","#the-purpose-of-tuned_getting-started-with-tuned",{"title":36,"visible":15,"weight":23,"urlFragment":29,"anchor":37,"singlePageAnchor":37,"docTitle":19,"url":38},"1.2. TuneD profiles","tuned-profiles_getting-started-with-tuned","#tuned-profiles_getting-started-with-tuned",{"title":40,"visible":15,"weight":28,"urlFragment":29,"anchor":41,"singlePageAnchor":41,"docTitle":19,"url":42},"1.3. The default TuneD profile","the-default-tuned-profile_getting-started-with-tuned","#the-default-tuned-profile_getting-started-with-tuned",{"title":44,"visible":15,"weight":45,"urlFragment":29,"anchor":46,"singlePageAnchor":46,"docTitle":19,"url":47},"1.4. Merged TuneD profiles",4,"merged-tuned-profiles_getting-started-with-tuned","#merged-tuned-profiles_getting-started-with-tuned",{"title":49,"visible":15,"weight":50,"urlFragment":29,"anchor":51,"singlePageAnchor":51,"docTitle":19,"url":52},"1.5. The location of TuneD profiles",5,"the-location-of-tuned-profiles_getting-started-with-tuned","#the-location-of-tuned-profiles_getting-started-with-tuned",{"title":54,"visible":15,"weight":55,"urlFragment":29,"anchor":56,"singlePageAnchor":56,"docTitle":19,"url":57},"1.6. TuneD profiles distributed with RHEL",6,"tuned-profiles-distributed-with-rhel_getting-started-with-tuned","#tuned-profiles-distributed-with-rhel_getting-started-with-tuned",{"title":59,"visible":15,"weight":60,"urlFragment":29,"anchor":61,"singlePageAnchor":61,"docTitle":19,"url":62},"1.7. TuneD cpu-partitioning profile",7,"tuned-cpu-partitioning-profile_getting-started-with-tuned","#tuned-cpu-partitioning-profile_getting-started-with-tuned",{"title":64,"visible":15,"weight":65,"urlFragment":29,"anchor":66,"singlePageAnchor":66,"docTitle":19,"url":67},"1.8. Using the TuneD cpu-partitioning profile for low-latency tuning",8,"using-the-tuned-cpu-partitioning-profile-for-low-latency-tuning_getting-started-with-tuned","#using-the-tuned-cpu-partitioning-profile-for-low-latency-tuning_getting-started-with-tuned",{"title":69,"visible":15,"weight":70,"urlFragment":29,"anchor":71,"singlePageAnchor":71,"docTitle":19,"url":72},"1.9. Customizing the cpu-partitioning TuneD profile",9,"customizing-the-cpu-partitioning-tuned-profile_getting-started-with-tuned","#customizing-the-cpu-partitioning-tuned-profile_getting-started-with-tuned",{"title":74,"visible":15,"weight":75,"urlFragment":29,"anchor":76,"singlePageAnchor":76,"docTitle":19,"url":77},"1.10. Real-time TuneD profiles distributed with RHEL",10,"real-time-tuned-profiles-distributed-with-rhel_getting-started-with-tuned","#real-time-tuned-profiles-distributed-with-rhel_getting-started-with-tuned",{"title":79,"visible":15,"weight":80,"urlFragment":29,"anchor":81,"singlePageAnchor":81,"docTitle":19,"url":82},"1.11. Static and dynamic tuning in TuneD",11,"static-and-dynamic-tuning-in-tuned_getting-started-with-tuned","#static-and-dynamic-tuning-in-tuned_getting-started-with-tuned",{"title":84,"visible":15,"weight":85,"urlFragment":29,"anchor":86,"singlePageAnchor":86,"docTitle":19,"url":87},"1.12. TuneD no-daemon mode",12,"tuned-no-daemon-mode_getting-started-with-tuned","#tuned-no-daemon-mode_getting-started-with-tuned",{"title":89,"visible":15,"weight":90,"urlFragment":29,"anchor":91,"singlePageAnchor":91,"docTitle":19,"url":92},"1.13. Installing and enabling TuneD",13,"installing-and-enabling-tuned_getting-started-with-tuned","#installing-and-enabling-tuned_getting-started-with-tuned",{"title":94,"visible":15,"weight":95,"urlFragment":29,"anchor":96,"singlePageAnchor":96,"docTitle":19,"url":97},"1.14. Listing available TuneD profiles",14,"listing-available-tuned-profiles_getting-started-with-tuned","#listing-available-tuned-profiles_getting-started-with-tuned",{"title":99,"visible":15,"weight":100,"urlFragment":29,"anchor":101,"singlePageAnchor":101,"docTitle":19,"url":102},"1.15. Setting a TuneD profile",15,"setting-a-tuned-profile_getting-started-with-tuned","#setting-a-tuned-profile_getting-started-with-tuned",{"title":104,"visible":15,"weight":105,"urlFragment":29,"anchor":106,"singlePageAnchor":106,"sections":107,"docTitle":19,"url":116},"1.16. Using the TuneD D-Bus interface",16,"using-the-tuned-d-bus-interface_getting-started-with-tuned",[108,112],{"title":109,"visible":15,"weight":16,"urlFragment":29,"anchor":110,"singlePageAnchor":110,"docTitle":19,"url":111},"1.16.1. Using the TuneD D-Bus interface to show available TuneD D-Bus API methods","using-the-tuned-d-bus-interface-to-show-available-tuned-d-bus-api-methods_using-the-tuned-d-bus-interface","#using-the-tuned-d-bus-interface-to-show-available-tuned-d-bus-api-methods_using-the-tuned-d-bus-interface",{"title":113,"visible":15,"weight":23,"urlFragment":29,"anchor":114,"singlePageAnchor":114,"docTitle":19,"url":115},"1.16.2. Using the TuneD D-Bus interface to change the active TuneD profile","using-the-tuned-d-bus-interface-to-change-the-active-tuned-profile_using-the-tuned-d-bus-interface","#using-the-tuned-d-bus-interface-to-change-the-active-tuned-profile_using-the-tuned-d-bus-interface","#using-the-tuned-d-bus-interface_getting-started-with-tuned",{"title":118,"visible":15,"weight":119,"urlFragment":29,"anchor":120,"singlePageAnchor":120,"docTitle":19,"url":121},"1.17. Disabling TuneD",17,"disabling-tuned_getting-started-with-tuned","#disabling-tuned_getting-started-with-tuned","#getting-started-with-tuned_monitoring-and-managing-system-status-and-performance",{"title":124,"visible":15,"weight":45,"urlFragment":125,"anchor":18,"singlePageAnchor":125,"sections":126,"docTitle":19,"url":187},"2. Customizing TuneD profiles","customizing-tuned-profiles_monitoring-and-managing-system-status-and-performance",[127,131,135,139,143,147,151,155,159,163,167,171,175,179,183],{"title":128,"visible":15,"weight":16,"urlFragment":125,"anchor":129,"singlePageAnchor":129,"docTitle":19,"url":130},"2.1. TuneD profiles","tuned-profiles_customizing-tuned-profiles","#tuned-profiles_customizing-tuned-profiles",{"title":132,"visible":15,"weight":23,"urlFragment":125,"anchor":133,"singlePageAnchor":133,"docTitle":19,"url":134},"2.2. The default TuneD profile","the-default-tuned-profile_customizing-tuned-profiles","#the-default-tuned-profile_customizing-tuned-profiles",{"title":136,"visible":15,"weight":28,"urlFragment":125,"anchor":137,"singlePageAnchor":137,"docTitle":19,"url":138},"2.3. Merged TuneD profiles","merged-tuned-profiles_customizing-tuned-profiles","#merged-tuned-profiles_customizing-tuned-profiles",{"title":140,"visible":15,"weight":45,"urlFragment":125,"anchor":141,"singlePageAnchor":141,"docTitle":19,"url":142},"2.4. The location of TuneD profiles","the-location-of-tuned-profiles_customizing-tuned-profiles","#the-location-of-tuned-profiles_customizing-tuned-profiles",{"title":144,"visible":15,"weight":50,"urlFragment":125,"anchor":145,"singlePageAnchor":145,"docTitle":19,"url":146},"2.5. Inheritance between TuneD profiles","inheritance-between-tuned-profiles_customizing-tuned-profiles","#inheritance-between-tuned-profiles_customizing-tuned-profiles",{"title":148,"visible":15,"weight":55,"urlFragment":125,"anchor":149,"singlePageAnchor":149,"docTitle":19,"url":150},"2.6. Static and dynamic tuning in TuneD","static-and-dynamic-tuning-in-tuned_customizing-tuned-profiles","#static-and-dynamic-tuning-in-tuned_customizing-tuned-profiles",{"title":152,"visible":15,"weight":60,"urlFragment":125,"anchor":153,"singlePageAnchor":153,"docTitle":19,"url":154},"2.7. TuneD plug-ins","tuned-plug-ins_customizing-tuned-profiles","#tuned-plug-ins_customizing-tuned-profiles",{"title":156,"visible":15,"weight":65,"urlFragment":125,"anchor":157,"singlePageAnchor":157,"docTitle":19,"url":158},"2.8. Available TuneD plug-ins","available-tuned-plug-ins_customizing-tuned-profiles","#available-tuned-plug-ins_customizing-tuned-profiles",{"title":160,"visible":15,"weight":70,"urlFragment":125,"anchor":161,"singlePageAnchor":161,"docTitle":19,"url":162},"2.9. Functionalities of the scheduler TuneD plugin","functionalities-of-the-scheduler-tuned-plug-in_customizing-tuned-profiles","#functionalities-of-the-scheduler-tuned-plug-in_customizing-tuned-profiles",{"title":164,"visible":15,"weight":75,"urlFragment":125,"anchor":165,"singlePageAnchor":165,"docTitle":19,"url":166},"2.10. Variables in TuneD profiles","variables-in-tuned-profiles_customizing-tuned-profiles","#variables-in-tuned-profiles_customizing-tuned-profiles",{"title":168,"visible":15,"weight":80,"urlFragment":125,"anchor":169,"singlePageAnchor":169,"docTitle":19,"url":170},"2.11. Built-in functions in TuneD profiles","built-in-functions-in-tuned-profiles_customizing-tuned-profiles","#built-in-functions-in-tuned-profiles_customizing-tuned-profiles",{"title":172,"visible":15,"weight":85,"urlFragment":125,"anchor":173,"singlePageAnchor":173,"docTitle":19,"url":174},"2.12. Built-in functions available in TuneD profiles","built-in-functions-available-in-tuned-profiles_customizing-tuned-profiles","#built-in-functions-available-in-tuned-profiles_customizing-tuned-profiles",{"title":176,"visible":15,"weight":90,"urlFragment":125,"anchor":177,"singlePageAnchor":177,"docTitle":19,"url":178},"2.13. Creating new TuneD profiles","creating-new-tuned-profiles_customizing-tuned-profiles","#creating-new-tuned-profiles_customizing-tuned-profiles",{"title":180,"visible":15,"weight":95,"urlFragment":125,"anchor":181,"singlePageAnchor":181,"docTitle":19,"url":182},"2.14. Modifying existing TuneD profiles","modifying-existing-tuned-profiles_customizing-tuned-profiles","#modifying-existing-tuned-profiles_customizing-tuned-profiles",{"title":184,"visible":15,"weight":100,"urlFragment":125,"anchor":185,"singlePageAnchor":185,"docTitle":19,"url":186},"2.15. Setting the disk scheduler using TuneD","setting-the-disk-scheduler-using-tuned_customizing-tuned-profiles","#setting-the-disk-scheduler-using-tuned_customizing-tuned-profiles","#customizing-tuned-profiles_monitoring-and-managing-system-status-and-performance",{"title":189,"visible":15,"weight":50,"urlFragment":190,"anchor":18,"singlePageAnchor":190,"sections":191,"docTitle":19,"url":208},"3. Reviewing a system by using the tuna interface","reviewing-a-system-using-tuna-interface_monitoring-and-managing-system-status-and-performance",[192,196,200,204],{"title":193,"visible":15,"weight":16,"urlFragment":190,"anchor":194,"singlePageAnchor":194,"docTitle":19,"url":195},"3.1. Installing the tuna tool","installing-tuna-tool_reviewing-a-system-using-tuna-interface","#installing-tuna-tool_reviewing-a-system-using-tuna-interface",{"title":197,"visible":15,"weight":23,"urlFragment":190,"anchor":198,"singlePageAnchor":198,"docTitle":19,"url":199},"3.2. Viewing the system status by using the tuna tool","viewing-the-system-status-using-tuna-tool_reviewing-a-system-using-tuna-interface","#viewing-the-system-status-using-tuna-tool_reviewing-a-system-using-tuna-interface",{"title":201,"visible":15,"weight":28,"urlFragment":190,"anchor":202,"singlePageAnchor":202,"docTitle":19,"url":203},"3.3. Tuning CPUs by using the tuna tool","tuning-cpus-using-tuna-tool_reviewing-a-system-using-tuna-interface","#tuning-cpus-using-tuna-tool_reviewing-a-system-using-tuna-interface",{"title":205,"visible":15,"weight":45,"urlFragment":190,"anchor":206,"singlePageAnchor":206,"docTitle":19,"url":207},"3.4. Tuning IRQs by using the tuna tool","tuning-irqs-using-tuna-tool_reviewing-a-system-using-tuna-interface","#tuning-irqs-using-tuna-tool_reviewing-a-system-using-tuna-interface","#reviewing-a-system-using-tuna-interface_monitoring-and-managing-system-status-and-performance",{"title":210,"visible":15,"weight":55,"urlFragment":211,"anchor":18,"singlePageAnchor":211,"sections":212,"docTitle":19,"url":229},"4. Configuring performance monitoring with PCP by using RHEL system roles","monitoring-performance-by-using-the-metrics-rhel-system-role_monitoring-and-managing-system-status-and-performance",[213,217,221,225],{"title":214,"visible":15,"weight":16,"urlFragment":211,"anchor":215,"singlePageAnchor":215,"docTitle":19,"url":216},"4.1. Configuring Performance Co-Pilot by using the metrics RHEL system role","configuring-performance-co-pilot-by-using-the-metrics-rhel-system-role_monitoring-performance-by-using-the-metrics-rhel-system-role","#configuring-performance-co-pilot-by-using-the-metrics-rhel-system-role_monitoring-performance-by-using-the-metrics-rhel-system-role",{"title":218,"visible":15,"weight":23,"urlFragment":211,"anchor":219,"singlePageAnchor":219,"docTitle":19,"url":220},"4.2. Configuring Performance Co-Pilot with authentication by using the metrics RHEL system role","configuring-performance-co-pilot-with-authentication-by-using-the-metrics-rhel-system-role_monitoring-performance-by-using-the-metrics-rhel-system-role","#configuring-performance-co-pilot-with-authentication-by-using-the-metrics-rhel-system-role_monitoring-performance-by-using-the-metrics-rhel-system-role",{"title":222,"visible":15,"weight":28,"urlFragment":211,"anchor":223,"singlePageAnchor":223,"docTitle":19,"url":224},"4.3. Setting up Grafana by using the metrics RHEL system role to monitor multiple hosts with Performance Co-Pilot","setting-up-grafana-by-using-the-metrics-rhel-system-role-to-monitor-multiple-hosts-with-performance-co-pilot_monitoring-performance-by-using-the-metrics-rhel-system-role","#setting-up-grafana-by-using-the-metrics-rhel-system-role-to-monitor-multiple-hosts-with-performance-co-pilot_monitoring-performance-by-using-the-metrics-rhel-system-role",{"title":226,"visible":15,"weight":45,"urlFragment":211,"anchor":227,"singlePageAnchor":227,"docTitle":19,"url":228},"4.4. Configuring web hooks in Performance Co-Pilot by using the metrics RHEL system role","configuring-web-hooks-in-performance-co-pilot-by-using-the-metrics-rhel-system-role_monitoring-performance-by-using-the-metrics-rhel-system-role","#configuring-web-hooks-in-performance-co-pilot-by-using-the-metrics-rhel-system-role_monitoring-performance-by-using-the-metrics-rhel-system-role","#monitoring-performance-by-using-the-metrics-rhel-system-role_monitoring-and-managing-system-status-and-performance",{"title":231,"visible":15,"weight":60,"urlFragment":232,"anchor":18,"singlePageAnchor":232,"sections":233,"docTitle":19,"url":295},"5. Setting up PCP","setting-up-pcp_monitoring-and-managing-system-status-and-performance",[234,238,242,246,250,254,258,262,266,270,274,291],{"title":235,"visible":15,"weight":16,"urlFragment":232,"anchor":236,"singlePageAnchor":236,"docTitle":19,"url":237},"5.1. Overview of PCP","overview-of-pcp_setting-up-pcp","#overview-of-pcp_setting-up-pcp",{"title":239,"visible":15,"weight":23,"urlFragment":232,"anchor":240,"singlePageAnchor":240,"docTitle":19,"url":241},"5.2. Installing and enabling PCP","installing-and-enabling-pcp_setting-up-pcp","#installing-and-enabling-pcp_setting-up-pcp",{"title":243,"visible":15,"weight":28,"urlFragment":232,"anchor":244,"singlePageAnchor":244,"docTitle":19,"url":245},"5.3. Deploying a minimal PCP setup","deploying-a-minimal-pcp-setup_setting-up-pcp","#deploying-a-minimal-pcp-setup_setting-up-pcp",{"title":247,"visible":15,"weight":45,"urlFragment":232,"anchor":248,"singlePageAnchor":248,"docTitle":19,"url":249},"5.4. System services and tools distributed with PCP","system-services-distributed-with-pcp_setting-up-pcp","#system-services-distributed-with-pcp_setting-up-pcp",{"title":251,"visible":15,"weight":50,"urlFragment":232,"anchor":252,"singlePageAnchor":252,"docTitle":19,"url":253},"5.5. PCP deployment architectures","pcp-deployment-architectures_setting-up-pcp","#pcp-deployment-architectures_setting-up-pcp",{"title":255,"visible":15,"weight":55,"urlFragment":232,"anchor":256,"singlePageAnchor":256,"docTitle":19,"url":257},"5.6. Recommended deployment architecture","recommended-deployment-architecture_setting-up-pcp","#recommended-deployment-architecture_setting-up-pcp",{"title":259,"visible":15,"weight":60,"urlFragment":232,"anchor":260,"singlePageAnchor":260,"docTitle":19,"url":261},"5.7. Sizing factors","sizing-factors_setting-up-pcp","#sizing-factors_setting-up-pcp",{"title":263,"visible":15,"weight":65,"urlFragment":232,"anchor":264,"singlePageAnchor":264,"docTitle":19,"url":265},"5.8. Configuration options for PCP scaling","configuration-options-for-pcp-scaling_setting-up-pcp","#configuration-options-for-pcp-scaling_setting-up-pcp",{"title":267,"visible":15,"weight":70,"urlFragment":232,"anchor":268,"singlePageAnchor":268,"docTitle":19,"url":269},"5.9. Example: Analyzing the centralized logging deployment","example-analyzing-the-centralized-logging-deployment_setting-up-pcp","#example-analyzing-the-centralized-logging-deployment_setting-up-pcp",{"title":271,"visible":15,"weight":75,"urlFragment":232,"anchor":272,"singlePageAnchor":272,"docTitle":19,"url":273},"5.10. Example: Analyzing the federated setup deployment","example-analyzing-the-federated-setup-deployment_setting-up-pcp","#example-analyzing-the-federated-setup-deployment_setting-up-pcp",{"title":275,"visible":15,"weight":80,"urlFragment":232,"anchor":276,"singlePageAnchor":276,"sections":277,"docTitle":19,"url":290},"5.11. Establishing secure PCP connections","establishing-secure-pcp-connections_setting-up-pcp",[278,282,286],{"title":279,"visible":15,"weight":16,"urlFragment":232,"anchor":280,"singlePageAnchor":280,"docTitle":19,"url":281},"5.11.1. Secure PCP connections","secure-pcp-connections_establishing-secure-pcp-connections","#secure-pcp-connections_establishing-secure-pcp-connections",{"title":283,"visible":15,"weight":23,"urlFragment":232,"anchor":284,"singlePageAnchor":284,"docTitle":19,"url":285},"5.11.2. Configuring secure connections for PCP collector components","configuring-secure-connections-for-pcp-collector-components_establishing-secure-pcp-connections","#configuring-secure-connections-for-pcp-collector-components_establishing-secure-pcp-connections",{"title":287,"visible":15,"weight":28,"urlFragment":232,"anchor":288,"singlePageAnchor":288,"docTitle":19,"url":289},"5.11.3. Configuring secure connections for PCP monitoring components","configuring-secure-connections-for-pcp-monitoring-components_establishing-secure-pcp-connections","#configuring-secure-connections-for-pcp-monitoring-components_establishing-secure-pcp-connections","#establishing-secure-pcp-connections_setting-up-pcp",{"title":292,"visible":15,"weight":85,"urlFragment":232,"anchor":293,"singlePageAnchor":293,"docTitle":19,"url":294},"5.12. Troubleshooting high memory usage","troubleshooting-high-memory-usage_setting-up-pcp","#troubleshooting-high-memory-usage_setting-up-pcp","#setting-up-pcp_monitoring-and-managing-system-status-and-performance",{"title":297,"visible":15,"weight":65,"urlFragment":298,"anchor":18,"singlePageAnchor":298,"sections":299,"docTitle":19,"url":332},"6. Logging performance data with pmlogger","logging-performance-data-with-pmlogger_monitoring-and-managing-system-status-and-performance",[300,304,308,312,316,320,324,328],{"title":301,"visible":15,"weight":16,"urlFragment":298,"anchor":302,"singlePageAnchor":302,"docTitle":19,"url":303},"6.1. Modifying the pmlogger configuration file with pmlogconf","modifying-the-pmlogger-configuration-file-with-pmlogconf_logging-performance-data-with-pmlogger","#modifying-the-pmlogger-configuration-file-with-pmlogconf_logging-performance-data-with-pmlogger",{"title":305,"visible":15,"weight":23,"urlFragment":298,"anchor":306,"singlePageAnchor":306,"docTitle":19,"url":307},"6.2. Editing the pmlogger configuration file manually","editing-the-pmlogger-configuration-file-manually_logging-performance-data-with-pmlogger","#editing-the-pmlogger-configuration-file-manually_logging-performance-data-with-pmlogger",{"title":309,"visible":15,"weight":28,"urlFragment":298,"anchor":310,"singlePageAnchor":310,"docTitle":19,"url":311},"6.3. Enabling the pmlogger service","enabling-the-pmlogger-service_logging-performance-data-with-pmlogger","#enabling-the-pmlogger-service_logging-performance-data-with-pmlogger",{"title":313,"visible":15,"weight":45,"urlFragment":298,"anchor":314,"singlePageAnchor":314,"docTitle":19,"url":315},"6.4. Setting up a client system for metrics collection","setting-up-a-client-system-for-metrics-collection_logging-performance-data-with-pmlogger","#setting-up-a-client-system-for-metrics-collection_logging-performance-data-with-pmlogger",{"title":317,"visible":15,"weight":50,"urlFragment":298,"anchor":318,"singlePageAnchor":318,"docTitle":19,"url":319},"6.5. Setting up a central server to collect data","setting-up-the-central-server-to-collect-data_logging-performance-data-with-pmlogger","#setting-up-the-central-server-to-collect-data_logging-performance-data-with-pmlogger",{"title":321,"visible":15,"weight":55,"urlFragment":298,"anchor":322,"singlePageAnchor":322,"docTitle":19,"url":323},"6.6. Systemd units and pmlogger","systemd-units-and-pmlogger_logging-performance-data-with-pmlogger","#systemd-units-and-pmlogger_logging-performance-data-with-pmlogger",{"title":325,"visible":15,"weight":60,"urlFragment":298,"anchor":326,"singlePageAnchor":326,"docTitle":19,"url":327},"6.7. Replaying the PCP log archives with pmrep","replaying-the-pcp-log-archives_logging-performance-data-with-pmlogger","#replaying-the-pcp-log-archives_logging-performance-data-with-pmlogger",{"title":329,"visible":15,"weight":65,"urlFragment":298,"anchor":330,"singlePageAnchor":330,"docTitle":19,"url":331},"6.8. Enabling PCP version 3 archives","enabling-pcp-version-3-archives_logging-performance-data-with-pmlogger","#enabling-pcp-version-3-archives_logging-performance-data-with-pmlogger","#logging-performance-data-with-pmlogger_monitoring-and-managing-system-status-and-performance",{"title":334,"visible":15,"weight":70,"urlFragment":335,"anchor":18,"singlePageAnchor":335,"sections":336,"docTitle":19,"url":353},"7. Monitoring performance with Performance Co-Pilot","monitoring-performance-with-performance-co-pilot_monitoring-and-managing-system-status-and-performance",[337,341,345,349],{"title":338,"visible":15,"weight":16,"urlFragment":335,"anchor":339,"singlePageAnchor":339,"docTitle":19,"url":340},"7.1. Monitoring postfix with pmda-postfix","monitoring-postfix-with-pmda-postfix_monitoring-performance-with-performance-co-pilot","#monitoring-postfix-with-pmda-postfix_monitoring-performance-with-performance-co-pilot",{"title":342,"visible":15,"weight":23,"urlFragment":335,"anchor":343,"singlePageAnchor":343,"docTitle":19,"url":344},"7.2. Visually tracing PCP log archives with the PCP Charts application","visually-tracing-pcp-log-archives-with-pcp-charts_monitoring-performance-with-performance-co-pilot","#visually-tracing-pcp-log-archives-with-pcp-charts_monitoring-performance-with-performance-co-pilot",{"title":346,"visible":15,"weight":28,"urlFragment":335,"anchor":347,"singlePageAnchor":347,"docTitle":19,"url":348},"7.3. Collecting data from SQL server using PCP","collecting-data-from-sql-server-using-pcp_monitoring-performance-with-performance-co-pilot","#collecting-data-from-sql-server-using-pcp_monitoring-performance-with-performance-co-pilot",{"title":350,"visible":15,"weight":45,"urlFragment":335,"anchor":351,"singlePageAnchor":351,"docTitle":19,"url":352},"7.4. Generating PCP archives from sadc archives","proc_generating-pcp-archives-from-sadc-archives_monitoring-performance-with-performance-co-pilot","#proc_generating-pcp-archives-from-sadc-archives_monitoring-performance-with-performance-co-pilot","#monitoring-performance-with-performance-co-pilot_monitoring-and-managing-system-status-and-performance",{"title":355,"visible":15,"weight":75,"urlFragment":356,"anchor":18,"singlePageAnchor":356,"sections":357,"docTitle":19,"url":378},"8. Performance analysis of XFS with PCP","performance-analysis-of-xfs-with-pcp_monitoring-and-managing-system-status-and-performance",[358,362,366,370,374],{"title":359,"visible":15,"weight":16,"urlFragment":356,"anchor":360,"singlePageAnchor":360,"docTitle":19,"url":361},"8.1. Installing XFS PMDA manually","installing-xfs-pmda-manually_performance-analysis-of-xfs-with-pcp","#installing-xfs-pmda-manually_performance-analysis-of-xfs-with-pcp",{"title":363,"visible":15,"weight":23,"urlFragment":356,"anchor":364,"singlePageAnchor":364,"docTitle":19,"url":365},"8.2. Examining XFS performance metrics with pminfo","examining-xfs-performance-metrics-with-pminfo_performance-analysis-of-xfs-with-pcp","#examining-xfs-performance-metrics-with-pminfo_performance-analysis-of-xfs-with-pcp",{"title":367,"visible":15,"weight":28,"urlFragment":356,"anchor":368,"singlePageAnchor":368,"docTitle":19,"url":369},"8.3. Resetting XFS performance metrics with pmstore","resetting-xfs-performance-metrics-with-pmstore_performance-analysis-of-xfs-with-pcp","#resetting-xfs-performance-metrics-with-pmstore_performance-analysis-of-xfs-with-pcp",{"title":371,"visible":15,"weight":45,"urlFragment":356,"anchor":372,"singlePageAnchor":372,"docTitle":19,"url":373},"8.4. PCP metric groups for XFS","pcp-metric-groups-for-xfs_performance-analysis-of-xfs-with-pcp","#pcp-metric-groups-for-xfs_performance-analysis-of-xfs-with-pcp",{"title":375,"visible":15,"weight":50,"urlFragment":356,"anchor":376,"singlePageAnchor":376,"docTitle":19,"url":377},"8.5. Per-device PCP metric groups for XFS","per-device-pcp-metric-groups-for-xfs_performance-analysis-of-xfs-with-pcp","#per-device-pcp-metric-groups-for-xfs_performance-analysis-of-xfs-with-pcp","#performance-analysis-of-xfs-with-pcp_monitoring-and-managing-system-status-and-performance",{"title":380,"visible":15,"weight":80,"urlFragment":381,"anchor":18,"singlePageAnchor":381,"sections":382,"docTitle":19,"url":439},"9. Setting up graphical representation of PCP metrics","setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance",[383,387,391,395,399,403,407,411,415,419,423,427,431,435],{"title":384,"visible":15,"weight":16,"urlFragment":381,"anchor":385,"singlePageAnchor":385,"docTitle":19,"url":386},"9.1. Setting up PCP with pcp-zeroconf","setting-up-pcp-with-pcp-zeroconf_setting-up-graphical-representation-of-pcp-metrics","#setting-up-pcp-with-pcp-zeroconf_setting-up-graphical-representation-of-pcp-metrics",{"title":388,"visible":15,"weight":23,"urlFragment":381,"anchor":389,"singlePageAnchor":389,"docTitle":19,"url":390},"9.2. Setting up a Grafana server","setting-up-a-grafana-server_setting-up-graphical-representation-of-pcp-metrics","#setting-up-a-grafana-server_setting-up-graphical-representation-of-pcp-metrics",{"title":392,"visible":15,"weight":28,"urlFragment":381,"anchor":393,"singlePageAnchor":393,"docTitle":19,"url":394},"9.3. Accessing the Grafana web UI","accessing-the-grafana-web-ui_setting-up-graphical-representation-of-pcp-metrics","#accessing-the-grafana-web-ui_setting-up-graphical-representation-of-pcp-metrics",{"title":396,"visible":15,"weight":45,"urlFragment":381,"anchor":397,"singlePageAnchor":397,"docTitle":19,"url":398},"9.4. Configuring secure connections for Grafana","configuring-secure-connections-for-grafana_setting-up-graphical-representation-of-pcp-metrics","#configuring-secure-connections-for-grafana_setting-up-graphical-representation-of-pcp-metrics",{"title":400,"visible":15,"weight":50,"urlFragment":381,"anchor":401,"singlePageAnchor":401,"docTitle":19,"url":402},"9.5. Configuring PCP Redis","configuring-pcp-redis_setting-up-graphical-representation-of-pcp-metrics","#configuring-pcp-redis_setting-up-graphical-representation-of-pcp-metrics",{"title":404,"visible":15,"weight":55,"urlFragment":381,"anchor":405,"singlePageAnchor":405,"docTitle":19,"url":406},"9.6. Creating panels and alerts in PCP Redis data source","creating-panel-and-alerts-in-pcp-redis-data-source_setting-up-graphical-representation-of-pcp-metrics","#creating-panel-and-alerts-in-pcp-redis-data-source_setting-up-graphical-representation-of-pcp-metrics",{"title":408,"visible":15,"weight":60,"urlFragment":381,"anchor":409,"singlePageAnchor":409,"docTitle":19,"url":410},"9.7. Adding notification channels for alerts","adding-notification-channels-for-alerts_setting-up-graphical-representation-of-pcp-metrics","#adding-notification-channels-for-alerts_setting-up-graphical-representation-of-pcp-metrics",{"title":412,"visible":15,"weight":65,"urlFragment":381,"anchor":413,"singlePageAnchor":413,"docTitle":19,"url":414},"9.8. Setting up authentication between PCP components","setting-up-authentication-between-pcp-components_setting-up-graphical-representation-of-pcp-metrics","#setting-up-authentication-between-pcp-components_setting-up-graphical-representation-of-pcp-metrics",{"title":416,"visible":15,"weight":70,"urlFragment":381,"anchor":417,"singlePageAnchor":417,"docTitle":19,"url":418},"9.9. Installing PCP bpftrace","installing-pcp-bpftrace_setting-up-graphical-representation-of-pcp-metrics","#installing-pcp-bpftrace_setting-up-graphical-representation-of-pcp-metrics",{"title":420,"visible":15,"weight":75,"urlFragment":381,"anchor":421,"singlePageAnchor":421,"docTitle":19,"url":422},"9.10. Viewing the PCP bpftrace System Analysis dashboard","viewing-the-pcp-bpftrace-system-analysis-dashboard_setting-up-graphical-representation-of-pcp-metrics","#viewing-the-pcp-bpftrace-system-analysis-dashboard_setting-up-graphical-representation-of-pcp-metrics",{"title":424,"visible":15,"weight":80,"urlFragment":381,"anchor":425,"singlePageAnchor":425,"docTitle":19,"url":426},"9.11. Installing PCP Vector","installing-pcp-vector_setting-up-graphical-representation-of-pcp-metrics","#installing-pcp-vector_setting-up-graphical-representation-of-pcp-metrics",{"title":428,"visible":15,"weight":85,"urlFragment":381,"anchor":429,"singlePageAnchor":429,"docTitle":19,"url":430},"9.12. Viewing the PCP Vector Checklist","viewing-the-pcp-vector-checklist_setting-up-graphical-representation-of-pcp-metrics","#viewing-the-pcp-vector-checklist_setting-up-graphical-representation-of-pcp-metrics",{"title":432,"visible":15,"weight":90,"urlFragment":381,"anchor":433,"singlePageAnchor":433,"docTitle":19,"url":434},"9.13. Using heatmaps in Grafana","using-heatmaps-in-grafana_setting-up-graphical-representation-of-pcp-metrics","#using-heatmaps-in-grafana_setting-up-graphical-representation-of-pcp-metrics",{"title":436,"visible":15,"weight":95,"urlFragment":381,"anchor":437,"singlePageAnchor":437,"docTitle":19,"url":438},"9.14. Troubleshooting Grafana issues","troubleshooting-grafana-issues_setting-up-graphical-representation-of-pcp-metrics","#troubleshooting-grafana-issues_setting-up-graphical-representation-of-pcp-metrics","#setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance",{"title":441,"visible":15,"weight":85,"urlFragment":442,"anchor":18,"singlePageAnchor":442,"sections":443,"docTitle":19,"url":460},"10. Optimizing the system performance using the web console","using-the-web-console-for-selecting-performance-profiles_monitoring-and-managing-system-status-and-performance",[444,448,452,456],{"title":445,"visible":15,"weight":16,"urlFragment":442,"anchor":446,"singlePageAnchor":446,"docTitle":19,"url":447},"10.1. Performance tuning options in the web console","performance-tuning-options-in-the-web-console_optimizing-the-system-performance-using-the-web-console","#performance-tuning-options-in-the-web-console_optimizing-the-system-performance-using-the-web-console",{"title":449,"visible":15,"weight":23,"urlFragment":442,"anchor":450,"singlePageAnchor":450,"docTitle":19,"url":451},"10.2. Setting a performance profile in the web console","setting-a-performance-profile-in-the-web-console_optimizing-the-system-performance-using-the-web-console","#setting-a-performance-profile-in-the-web-console_optimizing-the-system-performance-using-the-web-console",{"title":453,"visible":15,"weight":28,"urlFragment":442,"anchor":454,"singlePageAnchor":454,"docTitle":19,"url":455},"10.3. Monitoring performance on the local system by using the web console","monitoring-performance-using-the-web-console_optimizing-the-system-performance-using-the-web-console","#monitoring-performance-using-the-web-console_optimizing-the-system-performance-using-the-web-console",{"title":457,"visible":15,"weight":45,"urlFragment":442,"anchor":458,"singlePageAnchor":458,"docTitle":19,"url":459},"10.4. Monitoring performance on several systems by using the web console and Grafana","proc_enabling-performance-metrics-export-with-pcp-from-the-web-console_optimizing-the-system-performance-using-the-web-console","#proc_enabling-performance-metrics-export-with-pcp-from-the-web-console_optimizing-the-system-performance-using-the-web-console","#using-the-web-console-for-selecting-performance-profiles_monitoring-and-managing-system-status-and-performance",{"title":462,"visible":15,"weight":90,"urlFragment":463,"anchor":18,"singlePageAnchor":463,"sections":464,"docTitle":19,"url":493},"11. Setting the disk scheduler","setting-the-disk-scheduler_monitoring-and-managing-system-status-and-performance",[465,469,473,477,481,485,489],{"title":466,"visible":15,"weight":16,"urlFragment":463,"anchor":467,"singlePageAnchor":467,"docTitle":19,"url":468},"11.1. Available disk schedulers","available-disk-schedulers_setting-the-disk-scheduler","#available-disk-schedulers_setting-the-disk-scheduler",{"title":470,"visible":15,"weight":23,"urlFragment":463,"anchor":471,"singlePageAnchor":471,"docTitle":19,"url":472},"11.2. Different disk schedulers for different use cases","different-disk-schedulers-for-different-use-cases_setting-the-disk-scheduler","#different-disk-schedulers-for-different-use-cases_setting-the-disk-scheduler",{"title":474,"visible":15,"weight":28,"urlFragment":463,"anchor":475,"singlePageAnchor":475,"docTitle":19,"url":476},"11.3. The default disk scheduler","the-default-disk-scheduler_setting-the-disk-scheduler","#the-default-disk-scheduler_setting-the-disk-scheduler",{"title":478,"visible":15,"weight":45,"urlFragment":463,"anchor":479,"singlePageAnchor":479,"docTitle":19,"url":480},"11.4. Determining the active disk scheduler","determining-the-active-disk-scheduler_setting-the-disk-scheduler","#determining-the-active-disk-scheduler_setting-the-disk-scheduler",{"title":482,"visible":15,"weight":50,"urlFragment":463,"anchor":483,"singlePageAnchor":483,"docTitle":19,"url":484},"11.5. Setting the disk scheduler using TuneD","setting-the-disk-scheduler-using-tuned_setting-the-disk-scheduler","#setting-the-disk-scheduler-using-tuned_setting-the-disk-scheduler",{"title":486,"visible":15,"weight":55,"urlFragment":463,"anchor":487,"singlePageAnchor":487,"docTitle":19,"url":488},"11.6. Setting the disk scheduler using udev rules","setting-the-disk-scheduler-using-udev-rules_setting-the-disk-scheduler","#setting-the-disk-scheduler-using-udev-rules_setting-the-disk-scheduler",{"title":490,"visible":15,"weight":60,"urlFragment":463,"anchor":491,"singlePageAnchor":491,"docTitle":19,"url":492},"11.7. Temporarily setting a scheduler for a specific disk","temporarily-setting-a-scheduler-for-a-specific-disk_setting-the-disk-scheduler","#temporarily-setting-a-scheduler-for-a-specific-disk_setting-the-disk-scheduler","#setting-the-disk-scheduler_monitoring-and-managing-system-status-and-performance",{"title":495,"visible":15,"weight":95,"urlFragment":496,"anchor":18,"singlePageAnchor":496,"sections":497,"docTitle":19,"url":510},"12. Tuning the performance of a Samba server","assembly_tuning-the-performance-of-a-samba-server_monitoring-and-managing-system-status-and-performance",[498,502,506],{"title":499,"visible":15,"weight":16,"urlFragment":496,"anchor":500,"singlePageAnchor":500,"docTitle":19,"url":501},"12.1. Setting the SMB protocol version","proc_setting-the-smb-protocol-version_assembly_tuning-the-performance-of-a-samba-server","#proc_setting-the-smb-protocol-version_assembly_tuning-the-performance-of-a-samba-server",{"title":503,"visible":15,"weight":23,"urlFragment":496,"anchor":504,"singlePageAnchor":504,"docTitle":19,"url":505},"12.2. Tuning shares with directories that contain a large number of files","proc_tuning-shares-with-directories-that-contain-a-large-number-of-files_assembly_tuning-the-performance-of-a-samba-server","#proc_tuning-shares-with-directories-that-contain-a-large-number-of-files_assembly_tuning-the-performance-of-a-samba-server",{"title":507,"visible":15,"weight":28,"urlFragment":496,"anchor":508,"singlePageAnchor":508,"docTitle":19,"url":509},"12.3. Settings that can have a negative performance impact","con_settings-that-can-have-a-negative-performance-impact_assembly_tuning-the-performance-of-a-samba-server","#con_settings-that-can-have-a-negative-performance-impact_assembly_tuning-the-performance-of-a-samba-server","#assembly_tuning-the-performance-of-a-samba-server_monitoring-and-managing-system-status-and-performance",{"title":512,"visible":15,"weight":100,"urlFragment":513,"anchor":18,"singlePageAnchor":513,"sections":514,"docTitle":19,"url":629},"13. Optimizing virtual machine performance","optimizing-virtual-machine-performance-in-rhel_monitoring-and-managing-system-status-and-performance",[515,519,523,536,575,592,617,621,625],{"title":516,"visible":15,"weight":16,"urlFragment":513,"anchor":517,"singlePageAnchor":517,"docTitle":19,"url":518},"13.1. What influences virtual machine performance","what-influences-virtual-machine-performance_optimizing-virtual-machine-performance-in-rhel","#what-influences-virtual-machine-performance_optimizing-virtual-machine-performance-in-rhel",{"title":520,"visible":15,"weight":23,"urlFragment":513,"anchor":521,"singlePageAnchor":521,"docTitle":19,"url":522},"13.2. Optimizing virtual machine performance by using TuneD","optimizing-virtual-machine-performance-using-tuned_optimizing-virtual-machine-performance-in-rhel","#optimizing-virtual-machine-performance-using-tuned_optimizing-virtual-machine-performance-in-rhel",{"title":524,"visible":15,"weight":28,"urlFragment":513,"anchor":525,"singlePageAnchor":525,"sections":526,"docTitle":19,"url":535},"13.3. Optimizing libvirt daemons","assembly_optimizing-libvirt-daemons_optimizing-virtual-machine-performance-in-rhel",[527,531],{"title":528,"visible":15,"weight":16,"urlFragment":513,"anchor":529,"singlePageAnchor":529,"docTitle":19,"url":530},"13.3.1. Types of libvirt daemons","con_types-of-libvirt-daemons_assembly_optimizing-libvirt-daemons","#con_types-of-libvirt-daemons_assembly_optimizing-libvirt-daemons",{"title":532,"visible":15,"weight":23,"urlFragment":513,"anchor":533,"singlePageAnchor":533,"docTitle":19,"url":534},"13.3.2. Enabling modular libvirt daemons","proc_enabling-modular-libvirt-daemons_assembly_optimizing-libvirt-daemons","#proc_enabling-modular-libvirt-daemons_assembly_optimizing-libvirt-daemons","#assembly_optimizing-libvirt-daemons_optimizing-virtual-machine-performance-in-rhel",{"title":537,"visible":15,"weight":45,"urlFragment":513,"anchor":538,"singlePageAnchor":538,"sections":539,"docTitle":19,"url":574},"13.4. Configuring virtual machine memory","configuring-virtual-machine-ram_optimizing-virtual-machine-performance-in-rhel",[540,544,548,570],{"title":541,"visible":15,"weight":16,"urlFragment":513,"anchor":542,"singlePageAnchor":542,"docTitle":19,"url":543},"13.4.1. Adding and removing virtual machine memory by using the web console","adding-and-removing-virtual-machine-ram-using-the-web-console_configuring-virtual-machine-ram","#adding-and-removing-virtual-machine-ram-using-the-web-console_configuring-virtual-machine-ram",{"title":545,"visible":15,"weight":23,"urlFragment":513,"anchor":546,"singlePageAnchor":546,"docTitle":19,"url":547},"13.4.2. Adding and removing virtual machine memory by using the command-line interface","adding-and-removing-virtual-machine-ram-using-the-command-line-interface_configuring-virtual-machine-ram","#adding-and-removing-virtual-machine-ram-using-the-command-line-interface_configuring-virtual-machine-ram",{"title":549,"visible":15,"weight":28,"urlFragment":513,"anchor":550,"singlePageAnchor":550,"sections":551,"docTitle":19,"url":569},"13.4.3. Adding and removing virtual machine memory by using virtio-mem","adding-and-removing-virtual-machine-memory-by-using-virtio-mem_configuring-virtual-machine-ram",[552,557,561,565],{"title":553,"visible":554,"weight":16,"urlFragment":513,"anchor":555,"singlePageAnchor":555,"docTitle":19,"url":556},"13.4.3.1. Overview of virtio-mem",false,"overview-of-virtio-mem_adding-and-removing-virtual-machine-memory-by-using-virtio-mem","#overview-of-virtio-mem_adding-and-removing-virtual-machine-memory-by-using-virtio-mem",{"title":558,"visible":554,"weight":23,"urlFragment":513,"anchor":559,"singlePageAnchor":559,"docTitle":19,"url":560},"13.4.3.2. Configuring memory onlining in virtual machines","configuring-memory-onlining-in-virtual-machines_adding-and-removing-virtual-machine-memory-by-using-virtio-mem","#configuring-memory-onlining-in-virtual-machines_adding-and-removing-virtual-machine-memory-by-using-virtio-mem",{"title":562,"visible":554,"weight":28,"urlFragment":513,"anchor":563,"singlePageAnchor":563,"docTitle":19,"url":564},"13.4.3.3. Attaching a virtio-mem device to virtual machines","attaching-a-virtio-mem-device-to-virtual-machines_adding-and-removing-virtual-machine-memory-by-using-virtio-mem","#attaching-a-virtio-mem-device-to-virtual-machines_adding-and-removing-virtual-machine-memory-by-using-virtio-mem",{"title":566,"visible":554,"weight":45,"urlFragment":513,"anchor":567,"singlePageAnchor":567,"docTitle":19,"url":568},"13.4.3.4. Comparison of memory onlining configurations","comparison-of-memory-onlining-configurations_adding-and-removing-virtual-machine-memory-by-using-virtio-mem","#comparison-of-memory-onlining-configurations_adding-and-removing-virtual-machine-memory-by-using-virtio-mem","#adding-and-removing-virtual-machine-memory-by-using-virtio-mem_configuring-virtual-machine-ram",{"title":571,"visible":15,"weight":45,"urlFragment":513,"anchor":572,"singlePageAnchor":572,"docTitle":19,"url":573},"13.4.4. Additional resources","additional_resources","#additional_resources","#configuring-virtual-machine-ram_optimizing-virtual-machine-performance-in-rhel",{"title":576,"visible":15,"weight":50,"urlFragment":513,"anchor":577,"singlePageAnchor":577,"sections":578,"docTitle":19,"url":591},"13.5. Optimizing virtual machine I/O performance","optimizing-virtual-machine-i-o-performance_optimizing-virtual-machine-performance-in-rhel",[579,583,587],{"title":580,"visible":15,"weight":16,"urlFragment":513,"anchor":581,"singlePageAnchor":581,"docTitle":19,"url":582},"13.5.1. Tuning block I/O in virtual machines","tuning-block-i-o-in-virtual-machines_optimizing-virtual-machine-i-o-performance","#tuning-block-i-o-in-virtual-machines_optimizing-virtual-machine-i-o-performance",{"title":584,"visible":15,"weight":23,"urlFragment":513,"anchor":585,"singlePageAnchor":585,"docTitle":19,"url":586},"13.5.2. Disk I/O throttling in virtual machines","disk-i-o-throttling-in-virtual-machines_optimizing-virtual-machine-i-o-performance","#disk-i-o-throttling-in-virtual-machines_optimizing-virtual-machine-i-o-performance",{"title":588,"visible":15,"weight":28,"urlFragment":513,"anchor":589,"singlePageAnchor":589,"docTitle":19,"url":590},"13.5.3. Enabling multi-queue virtio-scsi","configuring-multi-queue-virtio-scsi_optimizing-virtual-machine-i-o-performance","#configuring-multi-queue-virtio-scsi_optimizing-virtual-machine-i-o-performance","#optimizing-virtual-machine-i-o-performance_optimizing-virtual-machine-performance-in-rhel",{"title":593,"visible":15,"weight":55,"urlFragment":513,"anchor":594,"singlePageAnchor":594,"sections":595,"docTitle":19,"url":616},"13.6. Optimizing virtual machine CPU performance","optimizing-virtual-machine-cpu-performance_optimizing-virtual-machine-performance-in-rhel",[596,600,604,608,612],{"title":597,"visible":15,"weight":16,"urlFragment":513,"anchor":598,"singlePageAnchor":598,"docTitle":19,"url":599},"13.6.1. Adding and removing virtual CPUs by using the command-line interface","adding-and-removing-virtual-cpus-using-the-command-line-interface_optimizing-virtual-machine-cpu-performance","#adding-and-removing-virtual-cpus-using-the-command-line-interface_optimizing-virtual-machine-cpu-performance",{"title":601,"visible":15,"weight":23,"urlFragment":513,"anchor":602,"singlePageAnchor":602,"docTitle":19,"url":603},"13.6.2. Managing virtual CPUs by using the web console","managing-virtual-cpus-using-the-web-console_optimizing-virtual-machine-cpu-performance","#managing-virtual-cpus-using-the-web-console_optimizing-virtual-machine-cpu-performance",{"title":605,"visible":15,"weight":28,"urlFragment":513,"anchor":606,"singlePageAnchor":606,"docTitle":19,"url":607},"13.6.3. Configuring NUMA in a virtual machine","configuring-numa-in-a-virtual-machine_optimizing-virtual-machine-cpu-performance","#configuring-numa-in-a-virtual-machine_optimizing-virtual-machine-cpu-performance",{"title":609,"visible":15,"weight":45,"urlFragment":513,"anchor":610,"singlePageAnchor":610,"docTitle":19,"url":611},"13.6.4. Sample vCPU performance tuning scenario","sample-vcpu-performance-tuning-scenario_optimizing-virtual-machine-cpu-performance","#sample-vcpu-performance-tuning-scenario_optimizing-virtual-machine-cpu-performance",{"title":613,"visible":15,"weight":50,"urlFragment":513,"anchor":614,"singlePageAnchor":614,"docTitle":19,"url":615},"13.6.5. Enabling and disabling kernel same-page merging","proc_managing-ksm_optimizing-virtual-machine-cpu-performance","#proc_managing-ksm_optimizing-virtual-machine-cpu-performance","#optimizing-virtual-machine-cpu-performance_optimizing-virtual-machine-performance-in-rhel",{"title":618,"visible":15,"weight":60,"urlFragment":513,"anchor":619,"singlePageAnchor":619,"docTitle":19,"url":620},"13.7. Optimizing virtual machine network performance","optimizing-virtual-machine-network-performance_optimizing-virtual-machine-performance-in-rhel","#optimizing-virtual-machine-network-performance_optimizing-virtual-machine-performance-in-rhel",{"title":622,"visible":15,"weight":65,"urlFragment":513,"anchor":623,"singlePageAnchor":623,"docTitle":19,"url":624},"13.8. Virtual machine performance monitoring tools","virtual-machine-performance-monitoring-tools_optimizing-virtual-machine-performance-in-rhel","#virtual-machine-performance-monitoring-tools_optimizing-virtual-machine-performance-in-rhel",{"title":626,"visible":15,"weight":70,"urlFragment":513,"anchor":627,"singlePageAnchor":627,"docTitle":19,"url":628},"13.9. Additional resources","related-information-optimizing-virtual-machine-performance-in-rhel","#related-information-optimizing-virtual-machine-performance-in-rhel","#optimizing-virtual-machine-performance-in-rhel_monitoring-and-managing-system-status-and-performance",{"title":631,"visible":15,"weight":105,"urlFragment":632,"anchor":18,"singlePageAnchor":632,"sections":633,"docTitle":19,"url":646},"14. Importance of power management","importance-of-power-management_monitoring-and-managing-system-status-and-performance",[634,638,642],{"title":635,"visible":15,"weight":16,"urlFragment":632,"anchor":636,"singlePageAnchor":636,"docTitle":19,"url":637},"14.1. Power management basics","power-management-basics_importance-of-power-management","#power-management-basics_importance-of-power-management",{"title":639,"visible":15,"weight":23,"urlFragment":632,"anchor":640,"singlePageAnchor":640,"docTitle":19,"url":641},"14.2. Audit and analysis overview","audit-and-analysis-overview_importance-of-power-management","#audit-and-analysis-overview_importance-of-power-management",{"title":643,"visible":15,"weight":28,"urlFragment":632,"anchor":644,"singlePageAnchor":644,"docTitle":19,"url":645},"14.3. Tools for auditing","tools-for-auditing_importance-of-power-management","#tools-for-auditing_importance-of-power-management","#importance-of-power-management_monitoring-and-managing-system-status-and-performance",{"title":648,"visible":15,"weight":119,"urlFragment":649,"anchor":18,"singlePageAnchor":649,"sections":650,"docTitle":19,"url":730},"15. Managing power consumption with PowerTOP","managing-power-consumption-with-powertop_monitoring-and-managing-system-status-and-performance",[651,655,676,701,705,709],{"title":652,"visible":15,"weight":16,"urlFragment":649,"anchor":653,"singlePageAnchor":653,"docTitle":19,"url":654},"15.1. The purpose of PowerTOP","the-purpose-of-powertop_managing-power-consumption-with-powertop","#the-purpose-of-powertop_managing-power-consumption-with-powertop",{"title":656,"visible":15,"weight":23,"urlFragment":649,"anchor":657,"singlePageAnchor":657,"sections":658,"docTitle":19,"url":675},"15.2. Using PowerTOP","using-powertop_managing-power-consumption-with-powertop",[659,663,667,671],{"title":660,"visible":15,"weight":16,"urlFragment":649,"anchor":661,"singlePageAnchor":661,"docTitle":19,"url":662},"15.2.1. Starting PowerTOP","starting-powertop_using-powertop","#starting-powertop_using-powertop",{"title":664,"visible":15,"weight":23,"urlFragment":649,"anchor":665,"singlePageAnchor":665,"docTitle":19,"url":666},"15.2.2. Calibrating PowerTOP","calibrating-powertop_using-powertop","#calibrating-powertop_using-powertop",{"title":668,"visible":15,"weight":28,"urlFragment":649,"anchor":669,"singlePageAnchor":669,"docTitle":19,"url":670},"15.2.3. Setting the measuring interval","setting-the-measuring-interval_using-powertop","#setting-the-measuring-interval_using-powertop",{"title":672,"visible":15,"weight":45,"urlFragment":649,"anchor":673,"singlePageAnchor":673,"docTitle":19,"url":674},"15.2.4. Additional resources","related-information-using-powertop","#related-information-using-powertop","#using-powertop_managing-power-consumption-with-powertop",{"title":677,"visible":15,"weight":28,"urlFragment":649,"anchor":678,"singlePageAnchor":678,"sections":679,"docTitle":19,"url":700},"15.3. PowerTOP statistics","powertop-statistics_managing-power-consumption-with-powertop",[680,684,688,692,696],{"title":681,"visible":15,"weight":16,"urlFragment":649,"anchor":682,"singlePageAnchor":682,"docTitle":19,"url":683},"15.3.1. The Overview tab","overview-tab_managing-power-consumption-with-powertop","#overview-tab_managing-power-consumption-with-powertop",{"title":685,"visible":15,"weight":23,"urlFragment":649,"anchor":686,"singlePageAnchor":686,"docTitle":19,"url":687},"15.3.2. The Idle stats tab","idle-stats-tab_managing-power-consumption-with-powertop","#idle-stats-tab_managing-power-consumption-with-powertop",{"title":689,"visible":15,"weight":28,"urlFragment":649,"anchor":690,"singlePageAnchor":690,"docTitle":19,"url":691},"15.3.3. The Device stats tab","device-stats-tab_managing-power-consumption-with-powertop","#device-stats-tab_managing-power-consumption-with-powertop",{"title":693,"visible":15,"weight":45,"urlFragment":649,"anchor":694,"singlePageAnchor":694,"docTitle":19,"url":695},"15.3.4. The Tunables tab","tunables-tab_managing-power-consumption-with-powertop","#tunables-tab_managing-power-consumption-with-powertop",{"title":697,"visible":15,"weight":50,"urlFragment":649,"anchor":698,"singlePageAnchor":698,"docTitle":19,"url":699},"15.3.5. The WakeUp tab","wakeup-tab_managing-power-consumption-with-powertop","#wakeup-tab_managing-power-consumption-with-powertop","#powertop-statistics_managing-power-consumption-with-powertop",{"title":702,"visible":15,"weight":45,"urlFragment":649,"anchor":703,"singlePageAnchor":703,"docTitle":19,"url":704},"15.4. Why Powertop does not display Frequency stats values in some instances","con_why-powertop-does-not-display-frequency-stats-values-in-some-instances_managing-power-consumption-with-powertop","#con_why-powertop-does-not-display-frequency-stats-values-in-some-instances_managing-power-consumption-with-powertop",{"title":706,"visible":15,"weight":50,"urlFragment":649,"anchor":707,"singlePageAnchor":707,"docTitle":19,"url":708},"15.5. Generating an HTML output","generating-an-html-output_managing-power-consumption-with-powertop","#generating-an-html-output_managing-power-consumption-with-powertop",{"title":710,"visible":15,"weight":55,"urlFragment":649,"anchor":711,"singlePageAnchor":711,"sections":712,"docTitle":19,"url":729},"15.6. Optimizing power consumption","optimizing-power-consumption_managing-power-consumption-with-powertop",[713,717,721,725],{"title":714,"visible":15,"weight":16,"urlFragment":649,"anchor":715,"singlePageAnchor":715,"docTitle":19,"url":716},"15.6.1. Optimizing power consumption using the powertop service","optimizing-power-consumption-using-the-powertop-service_optimizing-power-consumption","#optimizing-power-consumption-using-the-powertop-service_optimizing-power-consumption",{"title":718,"visible":15,"weight":23,"urlFragment":649,"anchor":719,"singlePageAnchor":719,"docTitle":19,"url":720},"15.6.2. The powertop2tuned utility","powertop2tuned-utility_optimizing-power-consumption","#powertop2tuned-utility_optimizing-power-consumption",{"title":722,"visible":15,"weight":28,"urlFragment":649,"anchor":723,"singlePageAnchor":723,"docTitle":19,"url":724},"15.6.3. Optimizing power consumption using the powertop2tuned utility","optimizing-power-consumption-with-powertop2tuned_optimizing-power-consumption","#optimizing-power-consumption-with-powertop2tuned_optimizing-power-consumption",{"title":726,"visible":15,"weight":45,"urlFragment":649,"anchor":727,"singlePageAnchor":727,"docTitle":19,"url":728},"15.6.4. Comparison of powertop.service and powertop2tuned","con_comparison-of-powertop-service-and-powertop2tuned_optimizing-power-consumption","#con_comparison-of-powertop-service-and-powertop2tuned_optimizing-power-consumption","#optimizing-power-consumption_managing-power-consumption-with-powertop","#managing-power-consumption-with-powertop_monitoring-and-managing-system-status-and-performance",{"title":732,"visible":15,"weight":733,"urlFragment":734,"anchor":18,"singlePageAnchor":734,"sections":735,"docTitle":19,"url":748},"16. Getting started with perf",18,"getting-started-with-perf_monitoring-and-managing-system-status-and-performance",[736,740,744],{"title":737,"visible":15,"weight":16,"urlFragment":734,"anchor":738,"singlePageAnchor":738,"docTitle":19,"url":739},"16.1. Introduction to perf","introduction-to-perf_getting-started-with-perf","#introduction-to-perf_getting-started-with-perf",{"title":741,"visible":15,"weight":23,"urlFragment":734,"anchor":742,"singlePageAnchor":742,"docTitle":19,"url":743},"16.2. Installing perf","installing-perf_getting-started-with-perf","#installing-perf_getting-started-with-perf",{"title":745,"visible":15,"weight":28,"urlFragment":734,"anchor":746,"singlePageAnchor":746,"docTitle":19,"url":747},"16.3. Common perf commands","common-perf-commands_getting-started-with-perf","#common-perf-commands_getting-started-with-perf","#getting-started-with-perf_monitoring-and-managing-system-status-and-performance",{"title":750,"visible":15,"weight":751,"urlFragment":752,"anchor":18,"singlePageAnchor":752,"sections":753,"docTitle":19,"url":778},"17. Profiling CPU usage in real time with perf top",19,"profiling-cpu-usage-in-real-time-with-top_monitoring-and-managing-system-status-and-performance",[754,758,762,766,770,774],{"title":755,"visible":15,"weight":16,"urlFragment":752,"anchor":756,"singlePageAnchor":756,"docTitle":19,"url":757},"17.1. The purpose of perf top","the-purpose-of-perf-top_profiling-cpu-usage-in-real-time-with-top","#the-purpose-of-perf-top_profiling-cpu-usage-in-real-time-with-top",{"title":759,"visible":15,"weight":23,"urlFragment":752,"anchor":760,"singlePageAnchor":760,"docTitle":19,"url":761},"17.2. Profiling CPU usage with perf top","profiling-cpu-usage-with-perf-top_profiling-cpu-usage-in-real-time-with-top","#profiling-cpu-usage-with-perf-top_profiling-cpu-usage-in-real-time-with-top",{"title":763,"visible":15,"weight":28,"urlFragment":752,"anchor":764,"singlePageAnchor":764,"docTitle":19,"url":765},"17.3. Interpretation of perf top output","interpretation-of-perf-top-output_profiling-cpu-usage-in-real-time-with-top","#interpretation-of-perf-top-output_profiling-cpu-usage-in-real-time-with-top",{"title":767,"visible":15,"weight":45,"urlFragment":752,"anchor":768,"singlePageAnchor":768,"docTitle":19,"url":769},"17.4. Why perf displays some function names as raw function addresses","why-perf-displays-some-function-names-as-raw-function-addresses_profiling-cpu-usage-in-real-time-with-top","#why-perf-displays-some-function-names-as-raw-function-addresses_profiling-cpu-usage-in-real-time-with-top",{"title":771,"visible":15,"weight":50,"urlFragment":752,"anchor":772,"singlePageAnchor":772,"docTitle":19,"url":773},"17.5. Enabling debug and source repositories","enabling-debug-and-source-repositories_profiling-cpu-usage-in-real-time-with-top","#enabling-debug-and-source-repositories_profiling-cpu-usage-in-real-time-with-top",{"title":775,"visible":15,"weight":55,"urlFragment":752,"anchor":776,"singlePageAnchor":776,"docTitle":19,"url":777},"17.6. Getting debuginfo packages for an application or library using GDB","getting-debuginfo-packages-for-an-application-or-library-using-gdb_profiling-cpu-usage-in-real-time-with-top","#getting-debuginfo-packages-for-an-application-or-library-using-gdb_profiling-cpu-usage-in-real-time-with-top","#profiling-cpu-usage-in-real-time-with-top_monitoring-and-managing-system-status-and-performance",{"title":780,"visible":15,"weight":781,"urlFragment":782,"anchor":18,"singlePageAnchor":782,"sections":783,"docTitle":19,"url":800},"18. Counting events during process execution with perf stat",20,"counting-events-during-process-execution-with-perf-stat_monitoring-and-managing-system-status-and-performance",[784,788,792,796],{"title":785,"visible":15,"weight":16,"urlFragment":782,"anchor":786,"singlePageAnchor":786,"docTitle":19,"url":787},"18.1. The purpose of perf stat","the-purpose-of-perf-stat_counting-events-during-process-execution-with-perf-stat","#the-purpose-of-perf-stat_counting-events-during-process-execution-with-perf-stat",{"title":789,"visible":15,"weight":23,"urlFragment":782,"anchor":790,"singlePageAnchor":790,"docTitle":19,"url":791},"18.2. Counting events with perf stat","counting-events-with-perf-stat_counting-events-during-process-execution-with-perf-stat","#counting-events-with-perf-stat_counting-events-during-process-execution-with-perf-stat",{"title":793,"visible":15,"weight":28,"urlFragment":782,"anchor":794,"singlePageAnchor":794,"docTitle":19,"url":795},"18.3. Interpretation of perf stat output","interpretation-of-perf-stat-output_counting-events-during-process-execution-with-perf-stat","#interpretation-of-perf-stat-output_counting-events-during-process-execution-with-perf-stat",{"title":797,"visible":15,"weight":45,"urlFragment":782,"anchor":798,"singlePageAnchor":798,"docTitle":19,"url":799},"18.4. Attaching perf stat to a running process","attaching-perf-stat-to-a-running-process_counting-events-during-process-execution-with-perf-stat","#attaching-perf-stat-to-a-running-process_counting-events-during-process-execution-with-perf-stat","#counting-events-during-process-execution-with-perf-stat_monitoring-and-managing-system-status-and-performance",{"title":802,"visible":15,"weight":803,"urlFragment":804,"anchor":18,"singlePageAnchor":804,"sections":805,"docTitle":19,"url":854},"19. Recording and analyzing performance profiles with perf",21,"recording-and-analyzing-performance-profiles-with-perf_monitoring-and-managing-system-status-and-performance",[806,810,814,818,822,826,830,834,838,842,846,850],{"title":807,"visible":15,"weight":16,"urlFragment":804,"anchor":808,"singlePageAnchor":808,"docTitle":19,"url":809},"19.1. The purpose of perf record","the-purpose-of-perf-record_recording-and-analyzing-performance-profiles-with-perf","#the-purpose-of-perf-record_recording-and-analyzing-performance-profiles-with-perf",{"title":811,"visible":15,"weight":23,"urlFragment":804,"anchor":812,"singlePageAnchor":812,"docTitle":19,"url":813},"19.2. Recording a performance profile without root access","recording-a-performance-profile-without-root-access_recording-and-analyzing-performance-profiles-with-perf","#recording-a-performance-profile-without-root-access_recording-and-analyzing-performance-profiles-with-perf",{"title":815,"visible":15,"weight":28,"urlFragment":804,"anchor":816,"singlePageAnchor":816,"docTitle":19,"url":817},"19.3. Recording a performance profile with root access","recording-a-performance-profile-with-root-access_recording-and-analyzing-performance-profiles-with-perf","#recording-a-performance-profile-with-root-access_recording-and-analyzing-performance-profiles-with-perf",{"title":819,"visible":15,"weight":45,"urlFragment":804,"anchor":820,"singlePageAnchor":820,"docTitle":19,"url":821},"19.4. Recording a performance profile in per-CPU mode","recording-a-performance-profile-in-per-cpu-mode_recording-and-analyzing-performance-profiles-with-perf","#recording-a-performance-profile-in-per-cpu-mode_recording-and-analyzing-performance-profiles-with-perf",{"title":823,"visible":15,"weight":50,"urlFragment":804,"anchor":824,"singlePageAnchor":824,"docTitle":19,"url":825},"19.5. Capturing call graph data with perf record","capturing-call-graph-data-with-perf-record_recording-and-analyzing-performance-profiles-with-perf","#capturing-call-graph-data-with-perf-record_recording-and-analyzing-performance-profiles-with-perf",{"title":827,"visible":15,"weight":55,"urlFragment":804,"anchor":828,"singlePageAnchor":828,"docTitle":19,"url":829},"19.6. Analyzing perf.data with perf report","analyzing-perf-data-with-perf-report_recording-and-analyzing-performance-profiles-with-perf","#analyzing-perf-data-with-perf-report_recording-and-analyzing-performance-profiles-with-perf",{"title":831,"visible":15,"weight":60,"urlFragment":804,"anchor":832,"singlePageAnchor":832,"docTitle":19,"url":833},"19.7. Interpretation of perf report output","interpretation-of-perf-report-output_recording-and-analyzing-performance-profiles-with-perf","#interpretation-of-perf-report-output_recording-and-analyzing-performance-profiles-with-perf",{"title":835,"visible":15,"weight":65,"urlFragment":804,"anchor":836,"singlePageAnchor":836,"docTitle":19,"url":837},"19.8. Generating a perf.data file that is readable on a different device","generating-a-perf-data-file-that-is-readable-on-a-different-device_recording-and-analyzing-performance-profiles-with-perf","#generating-a-perf-data-file-that-is-readable-on-a-different-device_recording-and-analyzing-performance-profiles-with-perf",{"title":839,"visible":15,"weight":70,"urlFragment":804,"anchor":840,"singlePageAnchor":840,"docTitle":19,"url":841},"19.9. Analyzing a perf.data file that was created on a different device","analyzing-a-perf-data-file-that-was-created-on-a-different-device_recording-and-analyzing-performance-profiles-with-perf","#analyzing-a-perf-data-file-that-was-created-on-a-different-device_recording-and-analyzing-performance-profiles-with-perf",{"title":843,"visible":15,"weight":75,"urlFragment":804,"anchor":844,"singlePageAnchor":844,"docTitle":19,"url":845},"19.10. Why perf displays some function names as raw function addresses","why-perf-displays-some-function-names-as-raw-function-addresses_recording-and-analyzing-performance-profiles-with-perf","#why-perf-displays-some-function-names-as-raw-function-addresses_recording-and-analyzing-performance-profiles-with-perf",{"title":847,"visible":15,"weight":80,"urlFragment":804,"anchor":848,"singlePageAnchor":848,"docTitle":19,"url":849},"19.11. Enabling debug and source repositories","enabling-debug-and-source-repositories_recording-and-analyzing-performance-profiles-with-perf","#enabling-debug-and-source-repositories_recording-and-analyzing-performance-profiles-with-perf",{"title":851,"visible":15,"weight":85,"urlFragment":804,"anchor":852,"singlePageAnchor":852,"docTitle":19,"url":853},"19.12. Getting debuginfo packages for an application or library using GDB","getting-debuginfo-packages-for-an-application-or-library-using-gdb_recording-and-analyzing-performance-profiles-with-perf","#getting-debuginfo-packages-for-an-application-or-library-using-gdb_recording-and-analyzing-performance-profiles-with-perf","#recording-and-analyzing-performance-profiles-with-perf_monitoring-and-managing-system-status-and-performance",{"title":856,"visible":15,"weight":857,"urlFragment":858,"anchor":18,"singlePageAnchor":858,"sections":859,"docTitle":19,"url":876},"20. Investigating busy CPUs with perf",22,"investigating-busy-cpus-with-perf_monitoring-and-managing-system-status-and-performance",[860,864,868,872],{"title":861,"visible":15,"weight":16,"urlFragment":858,"anchor":862,"singlePageAnchor":862,"docTitle":19,"url":863},"20.1. Displaying which CPU events were counted on with perf stat","displaying-which-cpu-events-were-counted-on-with-perf-stat_investigating-busy-cpus-with-perf","#displaying-which-cpu-events-were-counted-on-with-perf-stat_investigating-busy-cpus-with-perf",{"title":865,"visible":15,"weight":23,"urlFragment":858,"anchor":866,"singlePageAnchor":866,"docTitle":19,"url":867},"20.2. Displaying which CPU samples were taken on with perf report","displaying-which-cpu-samples-were-taken-on-with-perf-report_investigating-busy-cpus-with-perf","#displaying-which-cpu-samples-were-taken-on-with-perf-report_investigating-busy-cpus-with-perf",{"title":869,"visible":15,"weight":28,"urlFragment":858,"anchor":870,"singlePageAnchor":870,"docTitle":19,"url":871},"20.3. Displaying specific CPUs during profiling with perf top","displaying-specific-cpus-during-profiling-with-perf-top_investigating-busy-cpus-with-perf","#displaying-specific-cpus-during-profiling-with-perf-top_investigating-busy-cpus-with-perf",{"title":873,"visible":15,"weight":45,"urlFragment":858,"anchor":874,"singlePageAnchor":874,"docTitle":19,"url":875},"20.4. Monitoring specific CPUs with perf record and perf report","monitoring-specific-cpus-with-perf-record-and-perf-report_investigating-busy-cpus-with-perf","#monitoring-specific-cpus-with-perf-record-and-perf-report_investigating-busy-cpus-with-perf","#investigating-busy-cpus-with-perf_monitoring-and-managing-system-status-and-performance",{"title":878,"visible":15,"weight":879,"urlFragment":880,"anchor":18,"singlePageAnchor":880,"sections":881,"docTitle":19,"url":894},"21. Monitoring application performance with perf",23,"monitoring-application-performance-with-perf_monitoring-and-managing-system-status-and-performance",[882,886,890],{"title":883,"visible":15,"weight":16,"urlFragment":880,"anchor":884,"singlePageAnchor":884,"docTitle":19,"url":885},"21.1. Attaching perf record to a running process","attaching-perf-record-to-a-running-process_monitoring-application-performance-with-perf","#attaching-perf-record-to-a-running-process_monitoring-application-performance-with-perf",{"title":887,"visible":15,"weight":23,"urlFragment":880,"anchor":888,"singlePageAnchor":888,"docTitle":19,"url":889},"21.2. Capturing call graph data with perf record","capturing-call-graph-data-with-perf-record_monitoring-application-performance-with-perf","#capturing-call-graph-data-with-perf-record_monitoring-application-performance-with-perf",{"title":891,"visible":15,"weight":28,"urlFragment":880,"anchor":892,"singlePageAnchor":892,"docTitle":19,"url":893},"21.3. Analyzing perf.data with perf report","analyzing-perf-data-with-perf-report_monitoring-application-performance-with-perf","#analyzing-perf-data-with-perf-report_monitoring-application-performance-with-perf","#monitoring-application-performance-with-perf_monitoring-and-managing-system-status-and-performance",{"title":896,"visible":15,"weight":897,"urlFragment":898,"anchor":18,"singlePageAnchor":898,"sections":899,"docTitle":19,"url":912},"22. Creating uprobes with perf",24,"creating-uprobes-with-perf_monitoring-and-managing-system-status-and-performance",[900,904,908],{"title":901,"visible":15,"weight":16,"urlFragment":898,"anchor":902,"singlePageAnchor":902,"docTitle":19,"url":903},"22.1. Creating uprobes at the function level with perf","proc_creating-uprobes-at-the-fucntion-level-with-perf_assembly_creating-uprobes-with-perf","#proc_creating-uprobes-at-the-fucntion-level-with-perf_assembly_creating-uprobes-with-perf",{"title":905,"visible":15,"weight":23,"urlFragment":898,"anchor":906,"singlePageAnchor":906,"docTitle":19,"url":907},"22.2. Creating uprobes on lines within a function with perf","proc_creating-uprobes-on-lines-within-a-function-with-perf_assembly_creating-uprobes-with-perf","#proc_creating-uprobes-on-lines-within-a-function-with-perf_assembly_creating-uprobes-with-perf",{"title":909,"visible":15,"weight":28,"urlFragment":898,"anchor":910,"singlePageAnchor":910,"docTitle":19,"url":911},"22.3. Perf script output of data recorded over uprobes","ref_perf-script-output-of-a-perf-data-file-generated-over-uprobes_assembly_creating-uprobes-with-perf","#ref_perf-script-output-of-a-perf-data-file-generated-over-uprobes_assembly_creating-uprobes-with-perf","#creating-uprobes-with-perf_monitoring-and-managing-system-status-and-performance",{"title":914,"visible":15,"weight":915,"urlFragment":916,"anchor":18,"singlePageAnchor":916,"sections":917,"docTitle":19,"url":930},"23. Profiling memory accesses with perf mem",25,"profiling-memory-accesses-with-perf-mem_monitoring-and-managing-system-status-and-performance",[918,922,926],{"title":919,"visible":15,"weight":16,"urlFragment":916,"anchor":920,"singlePageAnchor":920,"docTitle":19,"url":921},"23.1. The purpose of perf mem","the-purpose-of-perf-mem_profiling-memory-accesses-with-perf-mem","#the-purpose-of-perf-mem_profiling-memory-accesses-with-perf-mem",{"title":923,"visible":15,"weight":23,"urlFragment":916,"anchor":924,"singlePageAnchor":924,"docTitle":19,"url":925},"23.2. Sampling memory access with perf mem","sampling-memory-access-with-perf-mem_profiling-memory-accesses-with-perf-mem","#sampling-memory-access-with-perf-mem_profiling-memory-accesses-with-perf-mem",{"title":927,"visible":15,"weight":28,"urlFragment":916,"anchor":928,"singlePageAnchor":928,"docTitle":19,"url":929},"23.3. Interpretation of perf mem report output","interpretation-of-perf-mem-report-output_profiling-memory-accesses-with-perf-mem","#interpretation-of-perf-mem-report-output_profiling-memory-accesses-with-perf-mem","#profiling-memory-accesses-with-perf-mem_monitoring-and-managing-system-status-and-performance",{"title":932,"visible":15,"weight":933,"urlFragment":934,"anchor":18,"singlePageAnchor":934,"sections":935,"docTitle":19,"url":956},"24. Detecting false sharing",26,"detecting-false-sharing_monitoring-and-managing-system-status-and-performance",[936,940,944,948,952],{"title":937,"visible":15,"weight":16,"urlFragment":934,"anchor":938,"singlePageAnchor":938,"docTitle":19,"url":939},"24.1. The purpose of perf c2c","the-purpose-of-perf-c2c_detecting-false-sharing","#the-purpose-of-perf-c2c_detecting-false-sharing",{"title":941,"visible":15,"weight":23,"urlFragment":934,"anchor":942,"singlePageAnchor":942,"docTitle":19,"url":943},"24.2. Detecting cache-line contention with perf c2c","detecting-cache-line-contention-with-perf-c2c_detecting-false-sharing","#detecting-cache-line-contention-with-perf-c2c_detecting-false-sharing",{"title":945,"visible":15,"weight":28,"urlFragment":934,"anchor":946,"singlePageAnchor":946,"docTitle":19,"url":947},"24.3. Visualizing a perf.data file recorded with perf c2c record","visualizing-a-perf-data-file-recorded-with-perf-c2c-record_detecting-false-sharing","#visualizing-a-perf-data-file-recorded-with-perf-c2c-record_detecting-false-sharing",{"title":949,"visible":15,"weight":45,"urlFragment":934,"anchor":950,"singlePageAnchor":950,"docTitle":19,"url":951},"24.4. Interpretation of perf c2c report output","interpretation-of-perf-c2c-report-output_detecting-false-sharing","#interpretation-of-perf-c2c-report-output_detecting-false-sharing",{"title":953,"visible":15,"weight":50,"urlFragment":934,"anchor":954,"singlePageAnchor":954,"docTitle":19,"url":955},"24.5. Detecting false sharing with perf c2c","detecting-false-sharing-with-perf-c2c_detecting-false-sharing","#detecting-false-sharing-with-perf-c2c_detecting-false-sharing","#detecting-false-sharing_monitoring-and-managing-system-status-and-performance",{"title":958,"visible":15,"weight":959,"urlFragment":960,"anchor":18,"singlePageAnchor":960,"sections":961,"docTitle":19,"url":978},"25. Getting started with flamegraphs",27,"getting-started-with-flamegraphs_monitoring-and-managing-system-status-and-performance",[962,966,970,974],{"title":963,"visible":15,"weight":16,"urlFragment":960,"anchor":964,"singlePageAnchor":964,"docTitle":19,"url":965},"25.1. Installing flamegraphs","installing-flamegraphs_getting-started-with-flamegraphs","#installing-flamegraphs_getting-started-with-flamegraphs",{"title":967,"visible":15,"weight":23,"urlFragment":960,"anchor":968,"singlePageAnchor":968,"docTitle":19,"url":969},"25.2. Creating flamegraphs over the entire system","creating-flamegraphs-over-the-entire-system_getting-started-with-flamegraphs","#creating-flamegraphs-over-the-entire-system_getting-started-with-flamegraphs",{"title":971,"visible":15,"weight":28,"urlFragment":960,"anchor":972,"singlePageAnchor":972,"docTitle":19,"url":973},"25.3. Creating flamegraphs over specific processes","creating-flamegraphs-over-specific-processes_getting-started-with-flamegraphs","#creating-flamegraphs-over-specific-processes_getting-started-with-flamegraphs",{"title":975,"visible":15,"weight":45,"urlFragment":960,"anchor":976,"singlePageAnchor":976,"docTitle":19,"url":977},"25.4. Interpreting flamegraphs","interpreting-flamegraphs_getting-started-with-flamegraphs","#interpreting-flamegraphs_getting-started-with-flamegraphs","#getting-started-with-flamegraphs_monitoring-and-managing-system-status-and-performance",{"title":980,"visible":15,"weight":981,"urlFragment":982,"anchor":18,"singlePageAnchor":982,"sections":983,"docTitle":19,"url":992},"26. Monitoring processes for performance bottlenecks using perf circular buffers",28,"creating-custom-circular-buffers-to-collect-specific-data-with-perf_monitoring-and-managing-system-status-and-performance",[984,988],{"title":985,"visible":15,"weight":16,"urlFragment":982,"anchor":986,"singlePageAnchor":986,"docTitle":19,"url":987},"26.1. Circular buffers and event-specific snapshots with perf","circular-buffers-and-event-specific-snapshots_assembly_creating-custom-circular-buffers-to-collect-specific-data-with-perf","#circular-buffers-and-event-specific-snapshots_assembly_creating-custom-circular-buffers-to-collect-specific-data-with-perf",{"title":989,"visible":15,"weight":23,"urlFragment":982,"anchor":990,"singlePageAnchor":990,"docTitle":19,"url":991},"26.2. Collecting specific data to monitor for performance bottlenecks using perf circular buffers","using-perf-to-create-custom-circular-buffers-that-perform-event-specific-snapshots_assembly_creating-custom-circular-buffers-to-collect-specific-data-with-perf","#using-perf-to-create-custom-circular-buffers-that-perform-event-specific-snapshots_assembly_creating-custom-circular-buffers-to-collect-specific-data-with-perf","#creating-custom-circular-buffers-to-collect-specific-data-with-perf_monitoring-and-managing-system-status-and-performance",{"title":994,"visible":15,"weight":995,"urlFragment":996,"anchor":18,"singlePageAnchor":996,"sections":997,"docTitle":19,"url":1006},"27. Adding and removing tracepoints from a running perf collector without stopping or restarting perf",29,"turning-tracepoints-on-and-off-without-stopping-or-restarting-perf_monitoring-and-managing-system-status-and-performance",[998,1002],{"title":999,"visible":15,"weight":16,"urlFragment":996,"anchor":1000,"singlePageAnchor":1000,"docTitle":19,"url":1001},"27.1. Adding tracepoints to a running perf collector without stopping or restarting perf","adding-tracepoints-to-a-running-perf-collector-without-stopping-or-restarting-perf_turning-tracepoints-on-and-off-without-stopping-or-restarting-perf","#adding-tracepoints-to-a-running-perf-collector-without-stopping-or-restarting-perf_turning-tracepoints-on-and-off-without-stopping-or-restarting-perf",{"title":1003,"visible":15,"weight":23,"urlFragment":996,"anchor":1004,"singlePageAnchor":1004,"docTitle":19,"url":1005},"27.2. Removing tracepoints from a running perf collector without stopping or restarting perf","removing-tracepoints-from-a-running-perf-collector-without-stopping-or-restarting-perf_turning-tracepoints-on-and-off-without-stopping-or-restarting-perf","#removing-tracepoints-from-a-running-perf-collector-without-stopping-or-restarting-perf_turning-tracepoints-on-and-off-without-stopping-or-restarting-perf","#turning-tracepoints-on-and-off-without-stopping-or-restarting-perf_monitoring-and-managing-system-status-and-performance",{"title":1008,"visible":15,"weight":1009,"urlFragment":1010,"anchor":18,"singlePageAnchor":1010,"sections":1011,"docTitle":19,"url":1020},"28. Profiling memory allocation with numastat",30,"profiling-memory-allocation-with-numastat_monitoring-and-managing-system-status-and-performance",[1012,1016],{"title":1013,"visible":15,"weight":16,"urlFragment":1010,"anchor":1014,"singlePageAnchor":1014,"docTitle":19,"url":1015},"28.1. Default numastat statistics","default-numastat-statistics_profiling-memory-allocation-with-numastat","#default-numastat-statistics_profiling-memory-allocation-with-numastat",{"title":1017,"visible":15,"weight":23,"urlFragment":1010,"anchor":1018,"singlePageAnchor":1018,"docTitle":19,"url":1019},"28.2. Viewing memory allocation with numastat","viewing-memory-allocation-with-numastat_profiling-memory-allocation-with-numastat","#viewing-memory-allocation-with-numastat_profiling-memory-allocation-with-numastat","#profiling-memory-allocation-with-numastat_monitoring-and-managing-system-status-and-performance",{"title":1022,"visible":15,"weight":1023,"urlFragment":1024,"anchor":18,"singlePageAnchor":1024,"sections":1025,"docTitle":19,"url":1056},"29. Configuring an operating system to optimize CPU utilization",31,"configuring-an-operating-system-to-optimize-cpu-utilization_monitoring-and-managing-system-status-and-performance",[1026,1030,1039,1043],{"title":1027,"visible":15,"weight":16,"urlFragment":1024,"anchor":1028,"singlePageAnchor":1028,"docTitle":19,"url":1029},"29.1. Tools for monitoring and diagnosing processor issues","tools-for-monitoring-and-diagnosing-processor-issues_configuring-an-operating-system-to-optimize-cpu-utilization","#tools-for-monitoring-and-diagnosing-processor-issues_configuring-an-operating-system-to-optimize-cpu-utilization",{"title":1031,"visible":15,"weight":23,"urlFragment":1024,"anchor":1032,"singlePageAnchor":1032,"sections":1033,"docTitle":19,"url":1038},"29.2. Types of system topology","types-of-system-topology_configuring-an-operating-system-to-optimize-cpu-utilization",[1034],{"title":1035,"visible":15,"weight":16,"urlFragment":1024,"anchor":1036,"singlePageAnchor":1036,"docTitle":19,"url":1037},"29.2.1. Displaying system topologies","displaying-system-topologies_configuring-an-operating-system-to-optimize-cpu-utilization","#displaying-system-topologies_configuring-an-operating-system-to-optimize-cpu-utilization","#types-of-system-topology_configuring-an-operating-system-to-optimize-cpu-utilization",{"title":1040,"visible":15,"weight":28,"urlFragment":1024,"anchor":1041,"singlePageAnchor":1041,"docTitle":19,"url":1042},"29.3. Configuring kernel tick time","configuring-kernel-tick-time_configuring-an-operating-system-to-optimize-cpu-utilization","#configuring-kernel-tick-time_configuring-an-operating-system-to-optimize-cpu-utilization",{"title":1044,"visible":15,"weight":45,"urlFragment":1024,"anchor":1045,"singlePageAnchor":1045,"sections":1046,"docTitle":19,"url":1055},"29.4. Overview of an interrupt request","overview-of-an-interrupt-request_configuring-an-operating-system-to-optimize-cpu-utilization",[1047,1051],{"title":1048,"visible":15,"weight":16,"urlFragment":1024,"anchor":1049,"singlePageAnchor":1049,"docTitle":19,"url":1050},"29.4.1. Balancing interrupts manually","balancing-interrupts-manually_configuring-an-operating-system-to-optimize-cpu-utilization","#balancing-interrupts-manually_configuring-an-operating-system-to-optimize-cpu-utilization",{"title":1052,"visible":15,"weight":23,"urlFragment":1024,"anchor":1053,"singlePageAnchor":1053,"docTitle":19,"url":1054},"29.4.2. Setting the smp_affinity mask","setting-the-smp_affinity-mask_configuring-an-operating-system-to-optimize-cpu-utilization","#setting-the-smp_affinity-mask_configuring-an-operating-system-to-optimize-cpu-utilization","#overview-of-an-interrupt-request_configuring-an-operating-system-to-optimize-cpu-utilization","#configuring-an-operating-system-to-optimize-cpu-utilization_monitoring-and-managing-system-status-and-performance",{"title":1058,"visible":15,"weight":1059,"urlFragment":1060,"anchor":18,"singlePageAnchor":1060,"sections":1061,"docTitle":19,"url":1106},"30. Tuning scheduling policy",32,"tuning-scheduling-policy_monitoring-and-managing-system-status-and-performance",[1062,1066,1070,1074,1078,1082,1086,1090,1094,1098,1102],{"title":1063,"visible":15,"weight":16,"urlFragment":1060,"anchor":1064,"singlePageAnchor":1064,"docTitle":19,"url":1065},"30.1. Categories of scheduling policies","con_categories-of-scheduling-policies_tuning-scheduling-policy","#con_categories-of-scheduling-policies_tuning-scheduling-policy",{"title":1067,"visible":15,"weight":23,"urlFragment":1060,"anchor":1068,"singlePageAnchor":1068,"docTitle":19,"url":1069},"30.2. Static priority scheduling with SCHED_FIFO","static-priority-scheduling-with-SCHED_FIFO_tuning-scheduling-policy","#static-priority-scheduling-with-SCHED_FIFO_tuning-scheduling-policy",{"title":1071,"visible":15,"weight":28,"urlFragment":1060,"anchor":1072,"singlePageAnchor":1072,"docTitle":19,"url":1073},"30.3. Round robin priority scheduling with SCHED_RR","round-robin-priority-scheduling-with-sched_rr_tuning-scheduling-policy","#round-robin-priority-scheduling-with-sched_rr_tuning-scheduling-policy",{"title":1075,"visible":15,"weight":45,"urlFragment":1060,"anchor":1076,"singlePageAnchor":1076,"docTitle":19,"url":1077},"30.4. Normal scheduling with SCHED_OTHER","normal-scheduling-with-sched_other_tuning-scheduling-policy","#normal-scheduling-with-sched_other_tuning-scheduling-policy",{"title":1079,"visible":15,"weight":50,"urlFragment":1060,"anchor":1080,"singlePageAnchor":1080,"docTitle":19,"url":1081},"30.5. Setting scheduler policies","setting-scheduler-policies_tuning-scheduling-policy","#setting-scheduler-policies_tuning-scheduling-policy",{"title":1083,"visible":15,"weight":55,"urlFragment":1060,"anchor":1084,"singlePageAnchor":1084,"docTitle":19,"url":1085},"30.6. Policy options for the chrt command","policy-options-for-the-chrt-command_tuning-scheduling-policy","#policy-options-for-the-chrt-command_tuning-scheduling-policy",{"title":1087,"visible":15,"weight":60,"urlFragment":1060,"anchor":1088,"singlePageAnchor":1088,"docTitle":19,"url":1089},"30.7. Changing the priority of services during the boot process","changing-the-priority-of-service-during-the-boot-process_tuning-scheduling-policy","#changing-the-priority-of-service-during-the-boot-process_tuning-scheduling-policy",{"title":1091,"visible":15,"weight":65,"urlFragment":1060,"anchor":1092,"singlePageAnchor":1092,"docTitle":19,"url":1093},"30.8. Priority map","priority-map_tuning-scheduling-policy","#priority-map_tuning-scheduling-policy",{"title":1095,"visible":15,"weight":70,"urlFragment":1060,"anchor":1096,"singlePageAnchor":1096,"docTitle":19,"url":1097},"30.9. TuneD cpu-partitioning profile","tuned-cpu-partitioning-profile_tuning-scheduling-policy","#tuned-cpu-partitioning-profile_tuning-scheduling-policy",{"title":1099,"visible":15,"weight":75,"urlFragment":1060,"anchor":1100,"singlePageAnchor":1100,"docTitle":19,"url":1101},"30.10. Using the TuneD cpu-partitioning profile for low-latency tuning","using-the-tuned-cpu-partitioning-profile-for-low-latency-tuning_tuning-scheduling-policy","#using-the-tuned-cpu-partitioning-profile-for-low-latency-tuning_tuning-scheduling-policy",{"title":1103,"visible":15,"weight":80,"urlFragment":1060,"anchor":1104,"singlePageAnchor":1104,"docTitle":19,"url":1105},"30.11. Customizing the cpu-partitioning TuneD profile","customizing-the-cpu-partitioning-tuned-profile_tuning-scheduling-policy","#customizing-the-cpu-partitioning-tuned-profile_tuning-scheduling-policy","#tuning-scheduling-policy_monitoring-and-managing-system-status-and-performance",{"title":1108,"visible":15,"weight":1109,"urlFragment":1110,"anchor":18,"singlePageAnchor":1110,"sections":1111,"docTitle":19,"url":1312},"31. Tuning the network performance",33,"tuning-the-network-performance_monitoring-and-managing-system-status-and-performance",[1112,1129,1154,1175,1188,1213,1238,1247,1256,1273,1282,1295,1304,1308],{"title":1113,"visible":15,"weight":16,"urlFragment":1110,"anchor":1114,"singlePageAnchor":1114,"sections":1115,"docTitle":19,"url":1128},"31.1. Tuning network adapter settings","tuning-network-adapter-settings_tuning-the-network-performance",[1116,1120,1124],{"title":1117,"visible":15,"weight":16,"urlFragment":1110,"anchor":1118,"singlePageAnchor":1118,"docTitle":19,"url":1119},"31.1.1. Increasing the ring buffer size to reduce a high packet drop rate by using nmcli","increasing-the-ring-buffers-to-reduce-a-high-packet-drop-rate_tuning-network-adapter-settings","#increasing-the-ring-buffers-to-reduce-a-high-packet-drop-rate_tuning-network-adapter-settings",{"title":1121,"visible":15,"weight":23,"urlFragment":1110,"anchor":1122,"singlePageAnchor":1122,"docTitle":19,"url":1123},"31.1.2. Tuning the network device backlog queue to avoid packet drops","tuning-the-network-device-backlog-queue-to-avoid-packet-drops_tuning-network-adapter-settings","#tuning-the-network-device-backlog-queue-to-avoid-packet-drops_tuning-network-adapter-settings",{"title":1125,"visible":15,"weight":28,"urlFragment":1110,"anchor":1126,"singlePageAnchor":1126,"docTitle":19,"url":1127},"31.1.3. Increasing the transmit queue length of a NIC to reduce the number of transmit errors","increasing-the-transmit-queue-length-of-a-nic-to-reduce-the-number-of-transmit-errors_tuning-network-adapter-settings","#increasing-the-transmit-queue-length-of-a-nic-to-reduce-the-number-of-transmit-errors_tuning-network-adapter-settings","#tuning-network-adapter-settings_tuning-the-network-performance",{"title":1130,"visible":15,"weight":23,"urlFragment":1110,"anchor":1131,"singlePageAnchor":1131,"sections":1132,"docTitle":19,"url":1153},"31.2. Tuning IRQ balancing","tuning-irq-balancing_tuning-the-network-performance",[1133,1137,1141,1145,1149],{"title":1134,"visible":15,"weight":16,"urlFragment":1110,"anchor":1135,"singlePageAnchor":1135,"docTitle":19,"url":1136},"31.2.1. Interrupts and interrupt handlers","interrupts-and-interrupt-handlers_tuning-irq-balancing","#interrupts-and-interrupt-handlers_tuning-irq-balancing",{"title":1138,"visible":15,"weight":23,"urlFragment":1110,"anchor":1139,"singlePageAnchor":1139,"docTitle":19,"url":1140},"31.2.2. Software interrupt requests","software-interrupt-requests_tuning-irq-balancing","#software-interrupt-requests_tuning-irq-balancing",{"title":1142,"visible":15,"weight":28,"urlFragment":1110,"anchor":1143,"singlePageAnchor":1143,"docTitle":19,"url":1144},"31.2.3. NAPI Polling","napi-polling_tuning-irq-balancing","#napi-polling_tuning-irq-balancing",{"title":1146,"visible":15,"weight":45,"urlFragment":1110,"anchor":1147,"singlePageAnchor":1147,"docTitle":19,"url":1148},"31.2.4. The irqbalance service","the-irqbalance-service_tuning-irq-balancing","#the-irqbalance-service_tuning-irq-balancing",{"title":1150,"visible":15,"weight":50,"urlFragment":1110,"anchor":1151,"singlePageAnchor":1151,"docTitle":19,"url":1152},"31.2.5. Increasing the time SoftIRQs can run on the CPU","increasing-the-time-softirqs-can-run-on-the-cpu_tuning-irq-balancing","#increasing-the-time-softirqs-can-run-on-the-cpu_tuning-irq-balancing","#tuning-irq-balancing_tuning-the-network-performance",{"title":1155,"visible":15,"weight":28,"urlFragment":1110,"anchor":1156,"singlePageAnchor":1156,"sections":1157,"docTitle":19,"url":1174},"31.3. Improving the network latency","improving-the-network-latency_tuning-the-network-performance",[1158,1162,1166,1170],{"title":1159,"visible":15,"weight":16,"urlFragment":1110,"anchor":1160,"singlePageAnchor":1160,"docTitle":19,"url":1161},"31.3.1. How the CPU power states influence the network latency","how-the-cpu-power-states-influence-the-network-latency_improving-the-network-latency","#how-the-cpu-power-states-influence-the-network-latency_improving-the-network-latency",{"title":1163,"visible":15,"weight":23,"urlFragment":1110,"anchor":1164,"singlePageAnchor":1164,"docTitle":19,"url":1165},"31.3.2. C-state settings in the EFI firmware","c-state-settings-in-the-efi-firmware_improving-the-network-latency","#c-state-settings-in-the-efi-firmware_improving-the-network-latency",{"title":1167,"visible":15,"weight":28,"urlFragment":1110,"anchor":1168,"singlePageAnchor":1168,"docTitle":19,"url":1169},"31.3.3. Disabling C-states by using a custom TuneD profile","disabling-c-states-by-using-a-custom-tuned-profile_improving-the-network-latency","#disabling-c-states-by-using-a-custom-tuned-profile_improving-the-network-latency",{"title":1171,"visible":15,"weight":45,"urlFragment":1110,"anchor":1172,"singlePageAnchor":1172,"docTitle":19,"url":1173},"31.3.4. Disabling C-states by using a kernel command line option","disabling-c-states-by-using-a-kernel-command-line-option_improving-the-network-latency","#disabling-c-states-by-using-a-kernel-command-line-option_improving-the-network-latency","#improving-the-network-latency_tuning-the-network-performance",{"title":1176,"visible":15,"weight":45,"urlFragment":1110,"anchor":1177,"singlePageAnchor":1177,"sections":1178,"docTitle":19,"url":1187},"31.4. Improving the throughput of large amounts of contiguous data streams","improving-the-throughput-of-large-amounts-of-contiguous-data-streams_tuning-the-network-performance",[1179,1183],{"title":1180,"visible":15,"weight":16,"urlFragment":1110,"anchor":1181,"singlePageAnchor":1181,"docTitle":19,"url":1182},"31.4.1. Considerations before configuring jumbo frames","considerations-before-configuring-jumbo-frames_improving-the-throughput-of-large-amounts-of-contiguous-data-streams","#considerations-before-configuring-jumbo-frames_improving-the-throughput-of-large-amounts-of-contiguous-data-streams",{"title":1184,"visible":15,"weight":23,"urlFragment":1110,"anchor":1185,"singlePageAnchor":1185,"docTitle":19,"url":1186},"31.4.2. Configuring the MTU in an existing NetworkManager connection profile","configuring-the-mtu-in-an-existing-networkmanager-connection-profile_improving-the-throughput-of-large-amounts-of-contiguous-data-streams","#configuring-the-mtu-in-an-existing-networkmanager-connection-profile_improving-the-throughput-of-large-amounts-of-contiguous-data-streams","#improving-the-throughput-of-large-amounts-of-contiguous-data-streams_tuning-the-network-performance",{"title":1189,"visible":15,"weight":50,"urlFragment":1110,"anchor":1190,"singlePageAnchor":1190,"sections":1191,"docTitle":19,"url":1212},"31.5. Tuning TCP connections for high throughput","tuning-tcp-connections-for-high-throughput_tuning-the-network-performance",[1192,1196,1200,1204,1208],{"title":1193,"visible":15,"weight":16,"urlFragment":1110,"anchor":1194,"singlePageAnchor":1194,"docTitle":19,"url":1195},"31.5.1. Testing the TCP throughput using iperf3","testing-the-tcp-throughput-using-iperf3_tuning-tcp-connections-for-high-throughput","#testing-the-tcp-throughput-using-iperf3_tuning-tcp-connections-for-high-throughput",{"title":1197,"visible":15,"weight":23,"urlFragment":1110,"anchor":1198,"singlePageAnchor":1198,"docTitle":19,"url":1199},"31.5.2. The system-wide TCP socket buffer settings","the-system-wide-tcp-socket-buffer-settings_tuning-tcp-connections-for-high-throughput","#the-system-wide-tcp-socket-buffer-settings_tuning-tcp-connections-for-high-throughput",{"title":1201,"visible":15,"weight":28,"urlFragment":1110,"anchor":1202,"singlePageAnchor":1202,"docTitle":19,"url":1203},"31.5.3. Increasing the system-wide TCP socket buffers","increasing-the-system-wide-tcp-socket-buffers_tuning-tcp-connections-for-high-throughput","#increasing-the-system-wide-tcp-socket-buffers_tuning-tcp-connections-for-high-throughput",{"title":1205,"visible":15,"weight":45,"urlFragment":1110,"anchor":1206,"singlePageAnchor":1206,"docTitle":19,"url":1207},"31.5.4. TCP Window Scaling","tcp-window-scaling_tuning-tcp-connections-for-high-throughput","#tcp-window-scaling_tuning-tcp-connections-for-high-throughput",{"title":1209,"visible":15,"weight":50,"urlFragment":1110,"anchor":1210,"singlePageAnchor":1210,"docTitle":19,"url":1211},"31.5.5. How TCP SACK reduces the packet drop rate","how-tcp-sack-reduces-the-packet-drop-rate_tuning-tcp-connections-for-high-throughput","#how-tcp-sack-reduces-the-packet-drop-rate_tuning-tcp-connections-for-high-throughput","#tuning-tcp-connections-for-high-throughput_tuning-the-network-performance",{"title":1214,"visible":15,"weight":55,"urlFragment":1110,"anchor":1215,"singlePageAnchor":1215,"sections":1216,"docTitle":19,"url":1237},"31.6. Tuning UDP connections","tuning-udp-connections_tuning-the-network-performance",[1217,1221,1225,1229,1233],{"title":1218,"visible":15,"weight":16,"urlFragment":1110,"anchor":1219,"singlePageAnchor":1219,"docTitle":19,"url":1220},"31.6.1. Detecting packet drops","detecting-packet-drops_tuning-udp-connections","#detecting-packet-drops_tuning-udp-connections",{"title":1222,"visible":15,"weight":23,"urlFragment":1110,"anchor":1223,"singlePageAnchor":1223,"docTitle":19,"url":1224},"31.6.2. Testing the UDP throughput using iperf3","testing-the-udp-throughput-using-iperf3_tuning-udp-connections","#testing-the-udp-throughput-using-iperf3_tuning-udp-connections",{"title":1226,"visible":15,"weight":28,"urlFragment":1110,"anchor":1227,"singlePageAnchor":1227,"docTitle":19,"url":1228},"31.6.3. Impact of the MTU size on UDP traffic throughput","impact-of-the-mtu-size-on-udp-traffic-throughput_tuning-udp-connections","#impact-of-the-mtu-size-on-udp-traffic-throughput_tuning-udp-connections",{"title":1230,"visible":15,"weight":45,"urlFragment":1110,"anchor":1231,"singlePageAnchor":1231,"docTitle":19,"url":1232},"31.6.4. Impact of the CPU speed on UDP traffic throughput","impact-of-the-cpu-speed-on-udp-traffic-throughput_tuning-udp-connections","#impact-of-the-cpu-speed-on-udp-traffic-throughput_tuning-udp-connections",{"title":1234,"visible":15,"weight":50,"urlFragment":1110,"anchor":1235,"singlePageAnchor":1235,"docTitle":19,"url":1236},"31.6.5. Increasing the system-wide UDP socket buffers","increasing-the-system-wide-udp-socket-buffers_tuning-udp-connections","#increasing-the-system-wide-udp-socket-buffers_tuning-udp-connections","#tuning-udp-connections_tuning-the-network-performance",{"title":1239,"visible":15,"weight":60,"urlFragment":1110,"anchor":1240,"singlePageAnchor":1240,"sections":1241,"docTitle":19,"url":1246},"31.7. Identifying application read socket buffer bottlenecks","identifying-application-read-socket-buffer-bottlenecks_tuning-the-network-performance",[1242],{"title":1243,"visible":15,"weight":16,"urlFragment":1110,"anchor":1244,"singlePageAnchor":1244,"docTitle":19,"url":1245},"31.7.1. Identifying receive buffer collapsing and pruning","identifying-receive-buffer-collapsing-and-pruning_identifying-application-read-socket-buffer-bottlenecks","#identifying-receive-buffer-collapsing-and-pruning_identifying-application-read-socket-buffer-bottlenecks","#identifying-application-read-socket-buffer-bottlenecks_tuning-the-network-performance",{"title":1248,"visible":15,"weight":65,"urlFragment":1110,"anchor":1249,"singlePageAnchor":1249,"sections":1250,"docTitle":19,"url":1255},"31.8. Tuning applications with a large number of incoming requests","tuning-applications-with-a-large-number-of-incoming-requests_tuning-the-network-performance",[1251],{"title":1252,"visible":15,"weight":16,"urlFragment":1110,"anchor":1253,"singlePageAnchor":1253,"docTitle":19,"url":1254},"31.8.1. Tuning the TCP listen backlog to process a high number of TCP connection attempts","tuning-the-tcp-listen-backlog-to-process-a-high-number-of-tcp-connection-attempts_tuning-applications-with-a-large-number-of-incoming-requests","#tuning-the-tcp-listen-backlog-to-process-a-high-number-of-tcp-connection-attempts_tuning-applications-with-a-large-number-of-incoming-requests","#tuning-applications-with-a-large-number-of-incoming-requests_tuning-the-network-performance",{"title":1257,"visible":15,"weight":70,"urlFragment":1110,"anchor":1258,"singlePageAnchor":1258,"sections":1259,"docTitle":19,"url":1272},"31.9. Avoiding listen queue lock contention","avoiding-listen-queue-lock-contention_tuning-the-network-performance",[1260,1264,1268],{"title":1261,"visible":15,"weight":16,"urlFragment":1110,"anchor":1262,"singlePageAnchor":1262,"docTitle":19,"url":1263},"31.9.1. Avoiding RX queue lock contention: The SO_REUSEPORT and SO_REUSEPORT_BPF socket options","avoiding-rx-queue-lock-contention-the-so_reuseport-and-so_reuseport_bpf-socket-options_avoiding-listen-queue-lock-contention","#avoiding-rx-queue-lock-contention-the-so_reuseport-and-so_reuseport_bpf-socket-options_avoiding-listen-queue-lock-contention",{"title":1265,"visible":15,"weight":23,"urlFragment":1110,"anchor":1266,"singlePageAnchor":1266,"docTitle":19,"url":1267},"31.9.2. Avoiding TX queue lock contention: Transmit packet steering","avoiding-tx-queue-lock-contention-transmit-packet-steering_avoiding-listen-queue-lock-contention","#avoiding-tx-queue-lock-contention-transmit-packet-steering_avoiding-listen-queue-lock-contention",{"title":1269,"visible":15,"weight":28,"urlFragment":1110,"anchor":1270,"singlePageAnchor":1270,"docTitle":19,"url":1271},"31.9.3. Disabling the Generic Receive Offload feature on servers with high UDP traffic","disabling-the-generic-receive-offload-feature-on-servers-with-high-udp-traffic_avoiding-listen-queue-lock-contention","#disabling-the-generic-receive-offload-feature-on-servers-with-high-udp-traffic_avoiding-listen-queue-lock-contention","#avoiding-listen-queue-lock-contention_tuning-the-network-performance",{"title":1274,"visible":15,"weight":75,"urlFragment":1110,"anchor":1275,"singlePageAnchor":1275,"sections":1276,"docTitle":19,"url":1281},"31.10. Tuning the device driver and NIC","tuning-the-device-driver-and-nic_tuning-the-network-performance",[1277],{"title":1278,"visible":15,"weight":16,"urlFragment":1110,"anchor":1279,"singlePageAnchor":1279,"docTitle":19,"url":1280},"31.10.1. Configuring custom NIC driver parameters","configuring-custom-nic-driver-parameters_tuning-the-device-driver-and-nic","#configuring-custom-nic-driver-parameters_tuning-the-device-driver-and-nic","#tuning-the-device-driver-and-nic_tuning-the-network-performance",{"title":1283,"visible":15,"weight":80,"urlFragment":1110,"anchor":1284,"singlePageAnchor":1284,"sections":1285,"docTitle":19,"url":1294},"31.11. Configuring network adapter offload settings","configuring-network-adapter-offload-settings_tuning-the-network-performance",[1286,1290],{"title":1287,"visible":15,"weight":16,"urlFragment":1110,"anchor":1288,"singlePageAnchor":1288,"docTitle":19,"url":1289},"31.11.1. Temporarily setting an offload feature","temporarily-setting-an-offload-feature_configuring-network-adapter-offload-settings","#temporarily-setting-an-offload-feature_configuring-network-adapter-offload-settings",{"title":1291,"visible":15,"weight":23,"urlFragment":1110,"anchor":1292,"singlePageAnchor":1292,"docTitle":19,"url":1293},"31.11.2. Permanently setting an offload feature","permanently-setting-an-offload-feature_configuring-network-adapter-offload-settings","#permanently-setting-an-offload-feature_configuring-network-adapter-offload-settings","#configuring-network-adapter-offload-settings_tuning-the-network-performance",{"title":1296,"visible":15,"weight":85,"urlFragment":1110,"anchor":1297,"singlePageAnchor":1297,"sections":1298,"docTitle":19,"url":1303},"31.12. Tuning interrupt coalescence settings","tuning-interrupt-coalescence-settings_tuning-the-network-performance",[1299],{"title":1300,"visible":15,"weight":16,"urlFragment":1110,"anchor":1301,"singlePageAnchor":1301,"docTitle":19,"url":1302},"31.12.1. Optimizing RHEL for latency or throughput-sensitive services","optimizing-rhel-for-latency-or-throughput-sensitive-services_tuning-interrupt-coalescence-settings","#optimizing-rhel-for-latency-or-throughput-sensitive-services_tuning-interrupt-coalescence-settings","#tuning-interrupt-coalescence-settings_tuning-the-network-performance",{"title":1305,"visible":15,"weight":90,"urlFragment":1110,"anchor":1306,"singlePageAnchor":1306,"docTitle":19,"url":1307},"31.13. Benefits of TCP Timestamps","benefits-of-tcp-timestamps_tuning-the-network-performance","#benefits-of-tcp-timestamps_tuning-the-network-performance",{"title":1309,"visible":15,"weight":95,"urlFragment":1110,"anchor":1310,"singlePageAnchor":1310,"docTitle":19,"url":1311},"31.14. Flow control for Ethernet networks","ref_flow-control-in-ethernet-networks_tuning-the-network-performance","#ref_flow-control-in-ethernet-networks_tuning-the-network-performance","#tuning-the-network-performance_monitoring-and-managing-system-status-and-performance",{"title":1314,"visible":15,"weight":1315,"urlFragment":1316,"anchor":18,"singlePageAnchor":1316,"sections":1317,"docTitle":19,"url":1342},"32. Factors affecting I/O and file system performance",34,"factors-affecting-i-o-and-file-system-performance_monitoring-and-managing-system-status-and-performance",[1318,1322,1326,1330,1334,1338],{"title":1319,"visible":15,"weight":16,"urlFragment":1316,"anchor":1320,"singlePageAnchor":1320,"docTitle":19,"url":1321},"32.1. Tools for monitoring and diagnosing I/O and file system issues","tools-for-monitoring-and-diagnosing-i-o-and-file-system-issues_factors-affecting-i-o-and-file-system-performance","#tools-for-monitoring-and-diagnosing-i-o-and-file-system-issues_factors-affecting-i-o-and-file-system-performance",{"title":1323,"visible":15,"weight":23,"urlFragment":1316,"anchor":1324,"singlePageAnchor":1324,"docTitle":19,"url":1325},"32.2. Available tuning options for formatting a file system","available-tuning-options-for-formatting-a-file-system_factors-affecting-i-o-and-file-system-performance","#available-tuning-options-for-formatting-a-file-system_factors-affecting-i-o-and-file-system-performance",{"title":1327,"visible":15,"weight":28,"urlFragment":1316,"anchor":1328,"singlePageAnchor":1328,"docTitle":19,"url":1329},"32.3. Available tuning options for mounting a file system","available-tuning-options-for-mounting-a-file-system_factors-affecting-i-o-and-file-system-performance","#available-tuning-options-for-mounting-a-file-system_factors-affecting-i-o-and-file-system-performance",{"title":1331,"visible":15,"weight":45,"urlFragment":1316,"anchor":1332,"singlePageAnchor":1332,"docTitle":19,"url":1333},"32.4. Types of discarding unused blocks","types-of-discarding-unused-blocks_factors-affecting-i-o-and-file-system-performance","#types-of-discarding-unused-blocks_factors-affecting-i-o-and-file-system-performance",{"title":1335,"visible":15,"weight":50,"urlFragment":1316,"anchor":1336,"singlePageAnchor":1336,"docTitle":19,"url":1337},"32.5. Solid-state disks tuning considerations","solid-state-disks-tuning-considerations_factors-affecting-i-o-and-file-system-performance","#solid-state-disks-tuning-considerations_factors-affecting-i-o-and-file-system-performance",{"title":1339,"visible":15,"weight":55,"urlFragment":1316,"anchor":1340,"singlePageAnchor":1340,"docTitle":19,"url":1341},"32.6. Generic block device tuning parameters","generic-block-device-tuning-parameters_factors-affecting-i-o-and-file-system-performance","#generic-block-device-tuning-parameters_factors-affecting-i-o-and-file-system-performance","#factors-affecting-i-o-and-file-system-performance_monitoring-and-managing-system-status-and-performance",{"title":1344,"visible":15,"weight":1345,"urlFragment":1346,"anchor":18,"singlePageAnchor":1346,"sections":1347,"docTitle":19,"url":1408},"33. Using systemd to manage resources used by applications",35,"assembly_using-systemd-to-manage-resources-used-by-applications_monitoring-and-managing-system-status-and-performance",[1348,1352,1356,1360,1364,1368,1372,1376,1380,1384,1388,1392,1396,1400,1404],{"title":1349,"visible":15,"weight":16,"urlFragment":1346,"anchor":1350,"singlePageAnchor":1350,"docTitle":19,"url":1351},"33.1. Role of systemd in resource management","con_role-of-systemd-in-resource-management_assembly_using-systemd-to-manage-resources-used-by-applications","#con_role-of-systemd-in-resource-management_assembly_using-systemd-to-manage-resources-used-by-applications",{"title":1353,"visible":15,"weight":23,"urlFragment":1346,"anchor":1354,"singlePageAnchor":1354,"docTitle":19,"url":1355},"33.2. Distribution models of system sources","distribution-models-of-system-sources_assembly_using-systemd-to-manage-resources-used-by-applications","#distribution-models-of-system-sources_assembly_using-systemd-to-manage-resources-used-by-applications",{"title":1357,"visible":15,"weight":28,"urlFragment":1346,"anchor":1358,"singlePageAnchor":1358,"docTitle":19,"url":1359},"33.3. Allocating system resources using systemd","proc_allocating-system-resources-using-systemd_assembly_using-systemd-to-manage-resources-used-by-applications","#proc_allocating-system-resources-using-systemd_assembly_using-systemd-to-manage-resources-used-by-applications",{"title":1361,"visible":15,"weight":45,"urlFragment":1346,"anchor":1362,"singlePageAnchor":1362,"docTitle":19,"url":1363},"33.4. Overview of systemd hierarchy for cgroups","con_overview-of-systemd-hierarchy-for-cgroups_assembly_using-systemd-to-manage-resources-used-by-applications","#con_overview-of-systemd-hierarchy-for-cgroups_assembly_using-systemd-to-manage-resources-used-by-applications",{"title":1365,"visible":15,"weight":50,"urlFragment":1346,"anchor":1366,"singlePageAnchor":1366,"docTitle":19,"url":1367},"33.5. Listing systemd units","listing-systemd_units_assembly_using-systemd-to-manage-resources-used-by-applications","#listing-systemd_units_assembly_using-systemd-to-manage-resources-used-by-applications",{"title":1369,"visible":15,"weight":55,"urlFragment":1346,"anchor":1370,"singlePageAnchor":1370,"docTitle":19,"url":1371},"33.6. Viewing systemd cgroups hierarchy","viewing-systemd-control-group-hierarchy_assembly_using-systemd-to-manage-resources-used-by-applications","#viewing-systemd-control-group-hierarchy_assembly_using-systemd-to-manage-resources-used-by-applications",{"title":1373,"visible":15,"weight":60,"urlFragment":1346,"anchor":1374,"singlePageAnchor":1374,"docTitle":19,"url":1375},"33.7. Viewing cgroups of processes","proc_viewing-cgroups-of-processes_assembly_using-systemd-to-manage-resources-used-by-applications","#proc_viewing-cgroups-of-processes_assembly_using-systemd-to-manage-resources-used-by-applications",{"title":1377,"visible":15,"weight":65,"urlFragment":1346,"anchor":1378,"singlePageAnchor":1378,"docTitle":19,"url":1379},"33.8. Monitoring resource consumption","monitoring-resource-consumption_assembly_using-systemd-to-manage-resources-used-by-applications","#monitoring-resource-consumption_assembly_using-systemd-to-manage-resources-used-by-applications",{"title":1381,"visible":15,"weight":70,"urlFragment":1346,"anchor":1382,"singlePageAnchor":1382,"docTitle":19,"url":1383},"33.9. Using systemd unit files to set limits for applications","proc_using-systemd-unit-files-to-set-limits-for-applications_assembly_using-systemd-to-manage-resources-used-by-applications","#proc_using-systemd-unit-files-to-set-limits-for-applications_assembly_using-systemd-to-manage-resources-used-by-applications",{"title":1385,"visible":15,"weight":75,"urlFragment":1346,"anchor":1386,"singlePageAnchor":1386,"docTitle":19,"url":1387},"33.10. Using systemctl command to set limits to applications","proc_using-systemctl-command-to-set-limits-to-applications_assembly_using-systemd-to-manage-resources-used-by-applications","#proc_using-systemctl-command-to-set-limits-to-applications_assembly_using-systemd-to-manage-resources-used-by-applications",{"title":1389,"visible":15,"weight":80,"urlFragment":1346,"anchor":1390,"singlePageAnchor":1390,"docTitle":19,"url":1391},"33.11. Setting global default CPU affinity through manager configuration","proc_setting-global-default-cpu-affinity-through-manager-configuration_assembly_using-systemd-to-manage-resources-used-by-applications","#proc_setting-global-default-cpu-affinity-through-manager-configuration_assembly_using-systemd-to-manage-resources-used-by-applications",{"title":1393,"visible":15,"weight":85,"urlFragment":1346,"anchor":1394,"singlePageAnchor":1394,"docTitle":19,"url":1395},"33.12. Configuring NUMA policies using systemd","proc_configuring-numa-using-systemd_assembly_using-systemd-to-manage-resources-used-by-applications","#proc_configuring-numa-using-systemd_assembly_using-systemd-to-manage-resources-used-by-applications",{"title":1397,"visible":15,"weight":90,"urlFragment":1346,"anchor":1398,"singlePageAnchor":1398,"docTitle":19,"url":1399},"33.13. NUMA policy configuration options for systemd","ref_numa-policy-configuration-options-with-systemd_assembly_using-systemd-to-manage-resources-used-by-applications","#ref_numa-policy-configuration-options-with-systemd_assembly_using-systemd-to-manage-resources-used-by-applications",{"title":1401,"visible":15,"weight":95,"urlFragment":1346,"anchor":1402,"singlePageAnchor":1402,"docTitle":19,"url":1403},"33.14. Creating transient cgroups using systemd-run command","creating-transient-control-groups_assembly_using-systemd-to-manage-resources-used-by-applications","#creating-transient-control-groups_assembly_using-systemd-to-manage-resources-used-by-applications",{"title":1405,"visible":15,"weight":100,"urlFragment":1346,"anchor":1406,"singlePageAnchor":1406,"docTitle":19,"url":1407},"33.15. Removing transient control groups","removing-transient-control-groups_assembly_using-systemd-to-manage-resources-used-by-applications","#removing-transient-control-groups_assembly_using-systemd-to-manage-resources-used-by-applications","#assembly_using-systemd-to-manage-resources-used-by-applications_monitoring-and-managing-system-status-and-performance",{"title":1410,"visible":15,"weight":1411,"urlFragment":1412,"anchor":18,"singlePageAnchor":1412,"sections":1413,"docTitle":19,"url":1426},"34. Understanding control groups",36,"setting-limits-for-applications_monitoring-and-managing-system-status-and-performance",[1414,1418,1422],{"title":1415,"visible":15,"weight":16,"urlFragment":1412,"anchor":1416,"singlePageAnchor":1416,"docTitle":19,"url":1417},"34.1. Introducing control groups","understanding-control-groups_setting-limits-for-applications","#understanding-control-groups_setting-limits-for-applications",{"title":1419,"visible":15,"weight":23,"urlFragment":1412,"anchor":1420,"singlePageAnchor":1420,"docTitle":19,"url":1421},"34.2. Introducing kernel resource controllers","what-kernel-resource-controllers-are_setting-limits-for-applications","#what-kernel-resource-controllers-are_setting-limits-for-applications",{"title":1423,"visible":15,"weight":28,"urlFragment":1412,"anchor":1424,"singlePageAnchor":1424,"docTitle":19,"url":1425},"34.3. Introducing namespaces","what-namespaces-are_setting-limits-for-applications","#what-namespaces-are_setting-limits-for-applications","#setting-limits-for-applications_monitoring-and-managing-system-status-and-performance",{"title":1428,"visible":15,"weight":1429,"urlFragment":1430,"anchor":18,"singlePageAnchor":1430,"sections":1431,"docTitle":19,"url":1448},"35. Using cgroupfs to manually manage cgroups",37,"assembly_using-cgroupfs-to-manually-manage-cgroups_monitoring-and-managing-system-status-and-performance",[1432,1436,1440,1444],{"title":1433,"visible":15,"weight":16,"urlFragment":1430,"anchor":1434,"singlePageAnchor":1434,"docTitle":19,"url":1435},"35.1. Creating cgroups and enabling controllers in cgroups-v2 file system","proc_creating-cgroups-and-enabling-controllers-in-cgroups-v2-file-system_assembly_using-cgroupfs-to-manually-manage-cgroups","#proc_creating-cgroups-and-enabling-controllers-in-cgroups-v2-file-system_assembly_using-cgroupfs-to-manually-manage-cgroups",{"title":1437,"visible":15,"weight":23,"urlFragment":1430,"anchor":1438,"singlePageAnchor":1438,"docTitle":19,"url":1439},"35.2. Controlling distribution of CPU time for applications by adjusting CPU weight","proc_controlling-distribution-of-cpu-time-for-applications-by-adjusting-cpu-weight_assembly_using-cgroupfs-to-manually-manage-cgroups","#proc_controlling-distribution-of-cpu-time-for-applications-by-adjusting-cpu-weight_assembly_using-cgroupfs-to-manually-manage-cgroups",{"title":1441,"visible":15,"weight":28,"urlFragment":1430,"anchor":1442,"singlePageAnchor":1442,"docTitle":19,"url":1443},"35.3. Mounting cgroups-v1","proc_mounting-cgroups-v1_assembly_using-cgroupfs-to-manually-manage-cgroups","#proc_mounting-cgroups-v1_assembly_using-cgroupfs-to-manually-manage-cgroups",{"title":1445,"visible":15,"weight":45,"urlFragment":1430,"anchor":1446,"singlePageAnchor":1446,"docTitle":19,"url":1447},"35.4. Setting CPU limits to applications using cgroups-v1","setting-cpu-limits-to-applications-using-cgroups-v1_assembly_using-cgroupfs-to-manually-manage-cgroups","#setting-cpu-limits-to-applications-using-cgroups-v1_assembly_using-cgroupfs-to-manually-manage-cgroups","#assembly_using-cgroupfs-to-manually-manage-cgroups_monitoring-and-managing-system-status-and-performance",{"title":1450,"visible":15,"weight":1451,"urlFragment":1452,"anchor":18,"singlePageAnchor":1452,"sections":1453,"docTitle":19,"url":1462},"36. Analyzing system performance with BPF Compiler Collection",38,"analyzing-system-performance-with-bpf-compiler_collection_monitoring-and-managing-system-status-and-performance",[1454,1458],{"title":1455,"visible":15,"weight":16,"urlFragment":1452,"anchor":1456,"singlePageAnchor":1456,"docTitle":19,"url":1457},"36.1. Installing the bcc-tools package","installing-the-bcc-tools-package_analyzing-system-performance-with-bpf-compiler_collection","#installing-the-bcc-tools-package_analyzing-system-performance-with-bpf-compiler_collection",{"title":1459,"visible":15,"weight":23,"urlFragment":1452,"anchor":1460,"singlePageAnchor":1460,"docTitle":19,"url":1461},"36.2. Using selected bcc-tools for performance analyses","using-selected-bcc-tools-for-performance-analyses_analyzing-system-performance-with-bpf-compiler_collection","#using-selected-bcc-tools-for-performance-analyses_analyzing-system-performance-with-bpf-compiler_collection","#analyzing-system-performance-with-bpf-compiler_collection_monitoring-and-managing-system-status-and-performance",{"title":1464,"visible":15,"weight":1465,"urlFragment":1466,"anchor":18,"singlePageAnchor":1466,"sections":1467,"docTitle":19,"url":1492},"37. Configuring an operating system to optimize memory access",39,"configuring-an-operating-system-to-optimize-memory-access_monitoring-and-managing-system-status-and-performance",[1468,1472,1476,1480,1484,1488],{"title":1469,"visible":15,"weight":16,"urlFragment":1466,"anchor":1470,"singlePageAnchor":1470,"docTitle":19,"url":1471},"37.1. Tools for monitoring and diagnosing system memory issues","tools-for-monitoring-and-diagnosing-system-memory-issues_configuring-an-operating-system-to-optimize-memory-access","#tools-for-monitoring-and-diagnosing-system-memory-issues_configuring-an-operating-system-to-optimize-memory-access",{"title":1473,"visible":15,"weight":23,"urlFragment":1466,"anchor":1474,"singlePageAnchor":1474,"docTitle":19,"url":1475},"37.2. Overview of a system’s memory","overview-of-a-systems-memory_configuring-an-operating-system-to-optimize-memory-access","#overview-of-a-systems-memory_configuring-an-operating-system-to-optimize-memory-access",{"title":1477,"visible":15,"weight":28,"urlFragment":1466,"anchor":1478,"singlePageAnchor":1478,"docTitle":19,"url":1479},"37.3. Virtual memory parameters","virtual-memory-parameters_configuring-an-operating-system-to-optimize-memory-access","#virtual-memory-parameters_configuring-an-operating-system-to-optimize-memory-access",{"title":1481,"visible":15,"weight":45,"urlFragment":1466,"anchor":1482,"singlePageAnchor":1482,"docTitle":19,"url":1483},"37.4. File system parameters","file-system-parameters_configuring-an-operating-system-to-optimize-memory-access","#file-system-parameters_configuring-an-operating-system-to-optimize-memory-access",{"title":1485,"visible":15,"weight":50,"urlFragment":1466,"anchor":1486,"singlePageAnchor":1486,"docTitle":19,"url":1487},"37.5. Kernel parameters","kernel-parameters_configuring-an-operating-system-to-optimize-memory-access","#kernel-parameters_configuring-an-operating-system-to-optimize-memory-access",{"title":1489,"visible":15,"weight":55,"urlFragment":1466,"anchor":1490,"singlePageAnchor":1490,"docTitle":19,"url":1491},"37.6. Setting memory-related kernel parameters","setting-memory-related-kernel-parameters_configuring-an-operating-system-to-optimize-memory-access","#setting-memory-related-kernel-parameters_configuring-an-operating-system-to-optimize-memory-access","#configuring-an-operating-system-to-optimize-memory-access_monitoring-and-managing-system-status-and-performance",{"title":1494,"visible":15,"weight":1495,"urlFragment":1496,"anchor":18,"singlePageAnchor":1496,"sections":1497,"docTitle":19,"url":1530},"38. Configuring huge pages",40,"configuring-huge-pages_monitoring-and-managing-system-status-and-performance",[1498,1502,1506,1510,1514,1518,1522,1526],{"title":1499,"visible":15,"weight":16,"urlFragment":1496,"anchor":1500,"singlePageAnchor":1500,"docTitle":19,"url":1501},"38.1. Available huge page features","available-hugepage-features_configuring-huge-pages","#available-hugepage-features_configuring-huge-pages",{"title":1503,"visible":15,"weight":23,"urlFragment":1496,"anchor":1504,"singlePageAnchor":1504,"docTitle":19,"url":1505},"38.2. Parameters for reserving HugeTLB pages at boot time","parameters-for-reserving-hugetlb-pages-at-boot-time_configuring-huge-pages","#parameters-for-reserving-hugetlb-pages-at-boot-time_configuring-huge-pages",{"title":1507,"visible":15,"weight":28,"urlFragment":1496,"anchor":1508,"singlePageAnchor":1508,"docTitle":19,"url":1509},"38.3. Configuring HugeTLB at boot time","configuring-hugetlb-at-boot-time_configuring-huge-pages","#configuring-hugetlb-at-boot-time_configuring-huge-pages",{"title":1511,"visible":15,"weight":45,"urlFragment":1496,"anchor":1512,"singlePageAnchor":1512,"docTitle":19,"url":1513},"38.4. Parameters for reserving HugeTLB pages at run time","parameters-for-reserving-hugetlb-pages-at-run-time_configuring-huge-pages","#parameters-for-reserving-hugetlb-pages-at-run-time_configuring-huge-pages",{"title":1515,"visible":15,"weight":50,"urlFragment":1496,"anchor":1516,"singlePageAnchor":1516,"docTitle":19,"url":1517},"38.5. Configuring HugeTLB at run time","configuring-hugetlb-at-run-time_configuring-huge-pages","#configuring-hugetlb-at-run-time_configuring-huge-pages",{"title":1519,"visible":15,"weight":55,"urlFragment":1496,"anchor":1520,"singlePageAnchor":1520,"docTitle":19,"url":1521},"38.6. Enabling transparent hugepages","enabling-transparent-hugepages_configuring-huge-pages","#enabling-transparent-hugepages_configuring-huge-pages",{"title":1523,"visible":15,"weight":60,"urlFragment":1496,"anchor":1524,"singlePageAnchor":1524,"docTitle":19,"url":1525},"38.7. Disabling transparent hugepages","disabling-transparent-hugepages_configuring-huge-pages","#disabling-transparent-hugepages_configuring-huge-pages",{"title":1527,"visible":15,"weight":65,"urlFragment":1496,"anchor":1528,"singlePageAnchor":1528,"docTitle":19,"url":1529},"38.8. Impact of page size on translation lookaside buffer size","impact-of-page-size-on-translation-lookaside-buffer-size_configuring-huge-pages","#impact-of-page-size-on-translation-lookaside-buffer-size_configuring-huge-pages","#configuring-huge-pages_monitoring-and-managing-system-status-and-performance",{"title":1532,"visible":15,"weight":1533,"urlFragment":1534,"anchor":18,"singlePageAnchor":1534,"sections":1535,"docTitle":19,"url":1556},"39. Getting started with SystemTap",41,"getting-started-with-systemtap_monitoring-and-managing-system-status-and-performance",[1536,1540,1544,1548,1552],{"title":1537,"visible":15,"weight":16,"urlFragment":1534,"anchor":1538,"singlePageAnchor":1538,"docTitle":19,"url":1539},"39.1. The purpose of SystemTap","the-purpose-of-systemtap_getting-started-with-systemtap","#the-purpose-of-systemtap_getting-started-with-systemtap",{"title":1541,"visible":15,"weight":23,"urlFragment":1534,"anchor":1542,"singlePageAnchor":1542,"docTitle":19,"url":1543},"39.2. Installing SystemTap","installing-systemtap_getting-started-with-systemtap","#installing-systemtap_getting-started-with-systemtap",{"title":1545,"visible":15,"weight":28,"urlFragment":1534,"anchor":1546,"singlePageAnchor":1546,"docTitle":19,"url":1547},"39.3. Privileges to run SystemTap","privileges-to-run-systemtap_getting-started-with-systemtap","#privileges-to-run-systemtap_getting-started-with-systemtap",{"title":1549,"visible":15,"weight":45,"urlFragment":1534,"anchor":1550,"singlePageAnchor":1550,"docTitle":19,"url":1551},"39.4. Running SystemTap scripts","running-systemtap-scripts_getting-started-with-systemtap","#running-systemtap-scripts_getting-started-with-systemtap",{"title":1553,"visible":15,"weight":50,"urlFragment":1534,"anchor":1554,"singlePageAnchor":1554,"docTitle":19,"url":1555},"39.5. Useful examples of SystemTap scripts","useful-examples-of-systemtap-scripts_getting-started-with-systemtap","#useful-examples-of-systemtap-scripts_getting-started-with-systemtap","#getting-started-with-systemtap_monitoring-and-managing-system-status-and-performance",{"title":1558,"visible":15,"weight":1559,"urlFragment":1560,"anchor":18,"singlePageAnchor":1560,"sections":1561,"docTitle":19,"url":1570},"40. Cross-instrumentation of SystemTap",42,"cross-instrumentation-of-systemtap_monitoring-and-managing-system-status-and-performance",[1562,1566],{"title":1563,"visible":15,"weight":16,"urlFragment":1560,"anchor":1564,"singlePageAnchor":1564,"docTitle":19,"url":1565},"40.1. SystemTap cross-instrumentation","systemtap-cross-instrumentation_cross-instrumentation-of-systemtap","#systemtap-cross-instrumentation_cross-instrumentation-of-systemtap",{"title":1567,"visible":15,"weight":23,"urlFragment":1560,"anchor":1568,"singlePageAnchor":1568,"docTitle":19,"url":1569},"40.2. Initializing cross-instrumentation of SystemTap","initializing-cross-instrumentation-of-systemtap_cross-instrumentation-of-systemtap","#initializing-cross-instrumentation-of-systemtap_cross-instrumentation-of-systemtap","#cross-instrumentation-of-systemtap_monitoring-and-managing-system-status-and-performance",{"title":1572,"visible":15,"weight":1573,"urlFragment":1574,"anchor":18,"singlePageAnchor":1575,"docTitle":19,"url":1576},"Legal Notice",43,"legal-notice","idm140280140052320","#idm140280140052320",[1578,1581,1584],{"text":1579,"link":1580},"Red Hat Enterprise Linux","/documentation/red_hat_enterprise_linux/",{"text":1582,"link":1583},"9","/documentation/red_hat_enterprise_linux/9/",{"text":11},{"name":11,"translations":1586,"productVersion":1587,"singlePage":1588,"pdf":1591,"publishingStatus":1593},[5,6,7,8,9],{"name":1582},{"contentUrl":1589,"name":11,"new":1590,"url":19},"https://d2bhdhkti9t3uj.cloudfront.net/html/c4f60d42-94bc-4c39-9c6f-6c06620794e7/3689d31e09421d7bcedb49f599ee3b9a.html","https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index",{"url":1592},"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9/pdf/monitoring_and_managing_system_status_and_performance/Red_Hat_Enterprise_Linux-9-Monitoring_and_managing_system_status_and_performance-en-US.pdf","PUBLISHED",[1595,1600,1603,1607,1611,1615,1619],{"name":1596,"new":1597,"url":1598,"urlAliases":1599},"10.0-Beta","https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/10-beta","10-beta",[],{"name":1582,"new":1601,"url":1582,"urlAliases":1602},"https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/9",[],{"name":1604,"new":1605,"url":1604,"urlAliases":1606},"8","https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/8",[],{"name":1608,"new":1609,"url":1608,"urlAliases":1610},"7","https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/7",[],{"name":1612,"new":1613,"url":1612,"urlAliases":1614},"6","https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/6",[],{"name":1616,"new":1617,"url":1616,"urlAliases":1618},"5","https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/5",[],{"name":1620,"new":1621,"url":1620,"urlAliases":1622},"4","https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/4",[],{"monitoring_and_managing_system_status_and_performance/index":1624,"monitoring_and_managing_system_status_and_performance/proc_providing-feedback-on-red-hat-documentation_monitoring-and-managing-system-status-and-performance":1625,"monitoring_and_managing_system_status_and_performance/getting-started-with-tuned_monitoring-and-managing-system-status-and-performance":1626,"monitoring_and_managing_system_status_and_performance/customizing-tuned-profiles_monitoring-and-managing-system-status-and-performance":1627,"monitoring_and_managing_system_status_and_performance/reviewing-a-system-using-tuna-interface_monitoring-and-managing-system-status-and-performance":1628,"monitoring_and_managing_system_status_and_performance/monitoring-performance-by-using-the-metrics-rhel-system-role_monitoring-and-managing-system-status-and-performance":1629,"monitoring_and_managing_system_status_and_performance/setting-up-pcp_monitoring-and-managing-system-status-and-performance":1630,"monitoring_and_managing_system_status_and_performance/logging-performance-data-with-pmlogger_monitoring-and-managing-system-status-and-performance":1631,"monitoring_and_managing_system_status_and_performance/monitoring-performance-with-performance-co-pilot_monitoring-and-managing-system-status-and-performance":1632,"monitoring_and_managing_system_status_and_performance/performance-analysis-of-xfs-with-pcp_monitoring-and-managing-system-status-and-performance":1633,"monitoring_and_managing_system_status_and_performance/setting-up-graphical-representation-of-pcp-metrics_monitoring-and-managing-system-status-and-performance":1634,"monitoring_and_managing_system_status_and_performance/using-the-web-console-for-selecting-performance-profiles_monitoring-and-managing-system-status-and-performance":1635,"monitoring_and_managing_system_status_and_performance/setting-the-disk-scheduler_monitoring-and-managing-system-status-and-performance":1636,"monitoring_and_managing_system_status_and_performance/assembly_tuning-the-performance-of-a-samba-server_monitoring-and-managing-system-status-and-performance":1637,"monitoring_and_managing_system_status_and_performance/optimizing-virtual-machine-performance-in-rhel_monitoring-and-managing-system-status-and-performance":1638,"monitoring_and_managing_system_status_and_performance/importance-of-power-management_monitoring-and-managing-system-status-and-performance":1639,"monitoring_and_managing_system_status_and_performance/managing-power-consumption-with-powertop_monitoring-and-managing-system-status-and-performance":1640,"monitoring_and_managing_system_status_and_performance/getting-started-with-perf_monitoring-and-managing-system-status-and-performance":1641,"monitoring_and_managing_system_status_and_performance/profiling-cpu-usage-in-real-time-with-top_monitoring-and-managing-system-status-and-performance":1642,"monitoring_and_managing_system_status_and_performance/counting-events-during-process-execution-with-perf-stat_monitoring-and-managing-system-status-and-performance":1643,"monitoring_and_managing_system_status_and_performance/recording-and-analyzing-performance-profiles-with-perf_monitoring-and-managing-system-status-and-performance":1644,"monitoring_and_managing_system_status_and_performance/investigating-busy-cpus-with-perf_monitoring-and-managing-system-status-and-performance":1645,"monitoring_and_managing_system_status_and_performance/monitoring-application-performance-with-perf_monitoring-and-managing-system-status-and-performance":1646,"monitoring_and_managing_system_status_and_performance/creating-uprobes-with-perf_monitoring-and-managing-system-status-and-performance":1647,"monitoring_and_managing_system_status_and_performance/profiling-memory-accesses-with-perf-mem_monitoring-and-managing-system-status-and-performance":1648,"monitoring_and_managing_system_status_and_performance/detecting-false-sharing_monitoring-and-managing-system-status-and-performance":1649,"monitoring_and_managing_system_status_and_performance/getting-started-with-flamegraphs_monitoring-and-managing-system-status-and-performance":1650,"monitoring_and_managing_system_status_and_performance/creating-custom-circular-buffers-to-collect-specific-data-with-perf_monitoring-and-managing-system-status-and-performance":1651,"monitoring_and_managing_system_status_and_performance/turning-tracepoints-on-and-off-without-stopping-or-restarting-perf_monitoring-and-managing-system-status-and-performance":1652,"monitoring_and_managing_system_status_and_performance/profiling-memory-allocation-with-numastat_monitoring-and-managing-system-status-and-performance":1653,"monitoring_and_managing_system_status_and_performance/configuring-an-operating-system-to-optimize-cpu-utilization_monitoring-and-managing-system-status-and-performance":1654,"monitoring_and_managing_system_status_and_performance/tuning-scheduling-policy_monitoring-and-managing-system-status-and-performance":1655,"monitoring_and_managing_system_status_and_performance/tuning-the-network-performance_monitoring-and-managing-system-status-and-performance":1656,"monitoring_and_managing_system_status_and_performance/factors-affecting-i-o-and-file-system-performance_monitoring-and-managing-system-status-and-performance":1657,"monitoring_and_managing_system_status_and_performance/assembly_using-systemd-to-manage-resources-used-by-applications_monitoring-and-managing-system-status-and-performance":1658,"monitoring_and_managing_system_status_and_performance/setting-limits-for-applications_monitoring-and-managing-system-status-and-performance":1659,"monitoring_and_managing_system_status_and_performance/assembly_using-cgroupfs-to-manually-manage-cgroups_monitoring-and-managing-system-status-and-performance":1660,"monitoring_and_managing_system_status_and_performance/analyzing-system-performance-with-bpf-compiler_collection_monitoring-and-managing-system-status-and-performance":1661,"monitoring_and_managing_system_status_and_performance/configuring-an-operating-system-to-optimize-memory-access_monitoring-and-managing-system-status-and-performance":1662,"monitoring_and_managing_system_status_and_performance/configuring-huge-pages_monitoring-and-managing-system-status-and-performance":1663,"monitoring_and_managing_system_status_and_performance/getting-started-with-systemtap_monitoring-and-managing-system-status-and-performance":1664,"monitoring_and_managing_system_status_and_performance/cross-instrumentation-of-systemtap_monitoring-and-managing-system-status-and-performance":1665,"monitoring_and_managing_system_status_and_performance/legal-notice":1666},{"prevt":18,"next":24},{"prevt":17,"next":29},{"prevt":18,"next":29},{"prevt":18,"next":125},{"prevt":18,"next":190},{"prevt":18,"next":211},{"prevt":18,"next":232},{"prevt":18,"next":298},{"prevt":18,"next":335},{"prevt":18,"next":356},{"prevt":18,"next":381},{"prevt":18,"next":442},{"prevt":18,"next":463},{"prevt":18,"next":496},{"prevt":18,"next":513},{"prevt":18,"next":632},{"prevt":18,"next":649},{"prevt":18,"next":734},{"prevt":18,"next":752},{"prevt":18,"next":782},{"prevt":18,"next":804},{"prevt":18,"next":858},{"prevt":18,"next":880},{"prevt":18,"next":898},{"prevt":18,"next":916},{"prevt":18,"next":934},{"prevt":18,"next":960},{"prevt":18,"next":982},{"prevt":18,"next":996},{"prevt":18,"next":1010},{"prevt":18,"next":1024},{"prevt":18,"next":1060},{"prevt":18,"next":18},{"prevt":18,"next":1316},{"prevt":18,"next":1346},{"prevt":18,"next":1412},{"prevt":18,"next":1430},{"prevt":18,"next":1452},{"prevt":18,"next":1466},{"prevt":18,"next":1496},{"prevt":18,"next":1534},{"prevt":18,"next":1560},{"prevt":1560,"next":18},{"product":18,"version":18},{"monitoring_and_managing_system_status_and_performance":1669},[1590],{"products":1671},[1672,1673,1674,1675,1676,1677,1678,1679,1680,1681,1682,1683,1684],"builds_for_red_hat_openshift","migration_toolkit_for_virtualization","openshift_container_platform","openshift_sandboxed_containers","red_hat_advanced_cluster_security_for_kubernetes","red_hat_advanced_cluster_management_for_kubernetes","red_hat_openshift_data_foundation","red_hat_openshift_dev_spaces","red_hat_openshift_gitops","red_hat_openshift_local","red_hat_openshift_pipelines","red_hat_openshift_serverless","workload_availability_for_red_hat_openshift",[],{"default":1687},[1688,1697,1703,1712,1720,1728,1735,1743,1750],{"nid":1689,"type":1690,"langcode":1691,"Published":16,"title":1692,"Created":1693,"Updated":1694,"body_value":18,"field_documentation banner_text_value":18,"field_documentation banner_text_format":18,"field_paths_value":1695,"field_documentation_training_url_uri":18,"field_title_title_id":18,"field_rebrand banner_link_uri":1696},580,"rebrand banner","en","OpenShift Container Storage is now OpenShift Data Foundation starting with version 4.9.","2023-01-11 15:38:32","2023-01-11 15:40:04","/documentation/red_hat_openshift_container_storage\r\n/documentation/red_hat_openshift_container_storage/\r\n/documentation/red_hat_openshift_container_storage/*","internal:/documentation/red_hat_openshift_data_foundation/",{"nid":1698,"type":1690,"langcode":1691,"Published":16,"title":1692,"Created":1699,"Updated":1700,"body_value":18,"field_documentation banner_text_value":18,"field_documentation banner_text_format":18,"field_paths_value":1701,"field_documentation_training_url_uri":18,"field_title_title_id":18,"field_rebrand banner_link_uri":1702},581,"2023-01-11 15:41:31","2023-01-11 15:42:04","/documentation/red_hat_openshift_data_foundation/4.9\r\n/documentation/red_hat_openshift_data_foundation/4.9/\r\n/documentation/red_hat_openshift_data_foundation/4.9/*\r\n/documentation/red_hat_openshift_data_foundation/4.10\r\n/documentation/red_hat_openshift_data_foundation/4.10/\r\n/documentation/red_hat_openshift_data_foundation/4.10/*\r\n/documentation/red_hat_openshift_data_foundation/4.11\r\n/documentation/red_hat_openshift_data_foundation/4.11/\r\n/documentation/red_hat_openshift_data_foundation/4.11/*","internal:/documentation/red_hat_openshift_container_storage/",{"nid":1704,"type":1705,"langcode":1691,"Published":16,"title":1706,"Created":1707,"Updated":1708,"body_value":18,"field_documentation banner_text_value":1709,"field_documentation banner_text_format":1710,"field_paths_value":1711,"field_documentation_training_url_uri":18,"field_title_title_id":18,"field_rebrand banner_link_uri":18},582,"developer preview banner","MicroShift is Developer Preview software only","2023-01-11 15:50:24","2023-01-30 19:00:52","\u003Cp slot=header>MicroShift is Developer Preview software only.\u003C/p>For more information about the support scope of Red Hat Developer Preview software, see \u003Ca href=\"https://access.redhat.com/support/offerings/devpreview/\">Developer Preview Support Scope\u003C/a>.","documentation banner","/documentation/microshift/4.12\r\n/documentation/microshift/4.12/*\r\n/documentation/red_hat_build_of_microshift/4.12\r\n/documentation/red_hat_build_of_microshift/4.12/*",{"nid":1713,"type":1714,"langcode":1691,"Published":16,"title":1715,"Created":1716,"Updated":1717,"body_value":18,"field_documentation banner_text_value":1718,"field_documentation banner_text_format":1710,"field_paths_value":1719,"field_documentation_training_url_uri":18,"field_title_title_id":18,"field_rebrand banner_link_uri":18},583,"obsolete documentation banner","RHACS EOL - DAT-3433","2023-01-23 16:36:43","2023-01-23 16:39:14","\u003Cp slot=header>You are viewing documentation for a release that is no longer maintained. To view the documentation for the most recent version, see the \u003Ca href=\"/documentation/red_hat_advanced_cluster_security_for_kubernetes/\">latest RHACS docs\u003C/a>.\u003C/p>","/documentation/red_hat_advanced_cluster_security_for_kubernetes/3.69\r\n/documentation/red_hat_advanced_cluster_security_for_kubernetes/3.69/*\r\n/documentation/red_hat_advanced_cluster_security_for_kubernetes/3.70\r\n/documentation/red_hat_advanced_cluster_security_for_kubernetes/3.70/*\r\n/documentation/red_hat_advanced_cluster_security_for_kubernetes/3.71\r\n/documentation/red_hat_advanced_cluster_security_for_kubernetes/3.71/*",{"nid":1721,"type":1722,"langcode":1691,"Published":16,"title":1723,"Created":1724,"Updated":1725,"body_value":18,"field_documentation banner_text_value":1726,"field_documentation banner_text_format":1710,"field_paths_value":1727,"field_documentation_training_url_uri":18,"field_title_title_id":18,"field_rebrand banner_link_uri":18},584,"end of life banner","EOL banner for RHV","2023-05-23 14:58:05","2023-05-24 15:19:42","\u003Cp slot=header>The Red Hat Virtualization\u003C/p>Maintenance Phase runs until August 31, 2024, followed by the Extended Life Phase with no more software fixes through August 31, 2026. See \u003Ca href=\"https://access.redhat.com/articles/6975303\">Migration Paths for OpenShift Container Platform deployed on Red Hat Virtualization\u003C/a> for details.","/documentation/red_hat_virtualization/4.4",{"nid":1729,"type":1722,"langcode":1691,"Published":16,"title":1730,"Created":1731,"Updated":1732,"body_value":18,"field_documentation banner_text_value":1733,"field_documentation banner_text_format":1710,"field_paths_value":1734,"field_documentation_training_url_uri":18,"field_title_title_id":18,"field_rebrand banner_link_uri":18},585,"RHHI-V EOL","2023-06-01 16:52:57","2023-06-01 17:03:44","\u003Cp slot=header>Red Hat Hyperconverged Infrastructure for Virtualization\u003C/p> is in the \u003Ca href=\"https://access.redhat.com/support/policy/updates/rhhiv\">Maintenance Support Phase\u003C/a> of its lifecycle until October 31, 2024. After that date, the product will be End of Life. See the \u003Ca href=\"https://access.redhat.com/announcements/6972521\">RHHI-V announcement\u003C/a> for next steps.","/documentation/red_hat_hyperconverged_infrastructure_for_virtualization/1.8",{"nid":1736,"type":1737,"langcode":1691,"Published":16,"title":1738,"Created":1739,"Updated":1740,"body_value":18,"field_documentation banner_text_value":1741,"field_documentation banner_text_format":1710,"field_paths_value":1742,"field_documentation_training_url_uri":18,"field_title_title_id":18,"field_rebrand banner_link_uri":18},586,"preview banner","MicroShift is Technology Preview software only","2024-03-18 16:53:05","2024-03-18 16:54:56","\u003Cp slot=header>MicroShift is Technology Preview software only.\u003C/p>For more information about the support scope of Red Hat Technology Preview software, see \u003Ca href=\"https://access.redhat.com/support/offerings/techpreview/\">Technology Preview Support Scope\u003C/a>.","/documentation/red_hat_build_of_microshift/4.13\r\n/documentation/red_hat_build_of_microshift/4.13/*",{"nid":1744,"type":1737,"langcode":1691,"Published":16,"title":1745,"Created":1746,"Updated":1747,"body_value":18,"field_documentation banner_text_value":1748,"field_documentation banner_text_format":1710,"field_paths_value":1749,"field_documentation_training_url_uri":18,"field_title_title_id":18,"field_rebrand banner_link_uri":18},588,"Ansible 2.5 upgrade limitation","2024-09-30 16:53:05","2024-10-28 16:54:56","\u003Cp slot=\"header\">Support added for upgrades from 2.4\u003C/p>Ansible Automation Platform 2.5-3, released on October 28, 2024, adds support for upgrades from 2.4. See the upgrade documentation for more information.","",{"nid":1751,"alertType":1752,"type":1753,"langcode":1691,"Published":16,"title":1754,"Created":1749,"Updated":1749,"body_value":18,"field_documentation banner_text_value":1755,"field_documentation banner_text_format":1710,"field_paths_value":1756,"field_documentation_training_url_uri":18,"field_title_title_id":18,"field_rebrand banner_link_uri":18},587,"warning","Warning banner","Red Hat build of Apache Camel K","\u003Cp slot=header>Red Hat Camel K is deprecated\u003C/p>Red Hat Camel K is deprecated and the End of Life date for this product is June 30, 2025. For help migrating to the current go-to solution, \u003Ca target=_blank href=\"https://docs.redhat.com/en/documentation/red_hat_build_of_apache_camel\">Red Hat build of Apache Camel\u003C/a>, see the \u003Ca target=_blank href=\"https://docs.redhat.com/en/documentation/red_hat_build_of_apache_camel_k/1.10.7/html/migration_guide_camel_k_to_camel_extensions_for_quarkus/index\">Migration Guide\u003C/a>.","/documentation/red_hat_build_of_apache_camel_k/*",{"product":1579},["Reactive",1759],{"$snuxt-i18n-meta":1760,"$sisLoading":554,"$sisSinglePage":15,"$sisInFocusMode":554,"$smobileTocOpen":554,"$sisLargeTOC":554,"$scurrentChapter":17,"$scurrentSection":17,"$scurrentSubSection":1749},{},["Set"],["ShallowReactive",1763],{"s8LoCEfG4A":18,"rFVLKcOK8e":18,"uUstF4AIyn":18,"MdHNSZP4nR":18,"Pn02PlJOas":18},"/en/documentation/red_hat_enterprise_linux/9/html-single/monitoring_and_managing_system_status_and_performance/index"]</script>
<script>window.__NUXT__={};window.__NUXT__.config={public:{contentEnv:"",collectFeedback:true,i18n:{baseUrl:"",defaultLocale:"en",defaultDirection:"ltr",strategy:"prefix",lazy:false,rootRedirect:"",routesNameSeparator:"___",defaultLocaleRouteNameSuffix:"default",skipSettingLocaleOnNavigate:false,differentDomains:false,trailingSlash:false,configLocales:[{code:"en",name:"English",iso:"en-US"},{code:"fr",name:"Français",iso:"fr-FR"},{code:"ko",name:"한국어",iso:"ko-KR"},{code:"ja",name:"日本語",iso:"ja-JP"},{code:"zh-cn",name:"中文 (中国)",iso:"zh-CN"},{code:"de",name:"Deutsch",iso:"de_DE"},{code:"it",name:"Italiano",iso:"it_IT"},{code:"pt-br",name:"Português",iso:"pt_BR"},{code:"es",name:"Español",iso:"es-ES"}],locales:{en:{domain:""},fr:{domain:""},ko:{domain:""},ja:{domain:""},"zh-cn":{domain:""},de:{domain:""},it:{domain:""},"pt-br":{domain:""},es:{domain:""}},detectBrowserLanguage:{alwaysRedirect:false,cookieCrossOrigin:false,cookieDomain:"",cookieKey:"i18n_redirected",cookieSecure:false,fallbackLocale:"",redirectOn:"root",useCookie:true},experimental:{localeDetector:"",switchLocalePathLinkSSR:false,autoImportTranslationFunctions:false}}},app:{baseURL:"/",buildId:"5ff82c51-785e-4a7d-aca6-77d6692e8c7a",buildAssetsDir:"/_nuxt/",cdnURL:""}}</script></body></html>
